<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Leverage Power of Machine Learning with ONNX</title>
    <meta name="description" content="Like the Machines need our help to take over the world">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/ml_ron.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Leverage Power of Machine Learning with ONNX | Conf42"/>
    <meta property="og:description" content="Have you ever wanted to make your apps "smarter"? This session will cover what every ML/AI developer should know about Open Neural Network Exchange (ONNX) . Why it's important and how it can reduce friction in incorporating machine learning models to your apps. We will show how to train models using the framework of your choice, save or convert models into ONNX, and deploy to cloud and edge using a high-performance runtime."/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2021_Ron_Lyle_Dagdag_Leverage_Power_ONNX"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/KUBE2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Kube Native 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-09-26
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/kubenative2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday London
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2021 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Like the Machines need our help to take over the world
 -->
              <script>
                const event_date = new Date("2021-07-29T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2021-07-29T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "vGhBnFUzem8"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "h6kzwaBwrCY"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrD02X7IKNNxFMy_K8oEejAu" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Good morning, good afternoon, good evening,", "timestamp": "00:00:22,250", "timestamp_s": 22.0}, {"text": "wherever you are at our virtual world.", "timestamp": "00:00:25,730", "timestamp_s": 25.0}, {"text": "My name is Ron Dagdag. I\u0027m a", "timestamp": "00:00:29,420", "timestamp_s": 29.0}, {"text": "lead software engineer at Spacey. Today I will", "timestamp": "00:00:32,684", "timestamp_s": 32.0}, {"text": "be talking about leverage the power of machine learning with", "timestamp": "00:00:36,092", "timestamp_s": 36.0}, {"text": "Onnx. For all you Pokemon", "timestamp": "00:00:39,772", "timestamp_s": 39.0}, {"text": "fans out there, I will not be talking about the", "timestamp": "00:00:43,090", "timestamp_s": 43.0}, {"text": "Pokemon onyx, nor I will be talking about the", "timestamp": "00:00:46,348", "timestamp_s": 46.0}, {"text": "mineral onyx. I will be talking about", "timestamp": "00:00:50,252", "timestamp_s": 50.0}, {"text": "Onyx on NX open neural network", "timestamp": "00:00:53,508", "timestamp_s": 53.0}, {"text": "exchange. All right, let\u0027s go back to basics.", "timestamp": "00:00:57,946", "timestamp_s": 57.0}, {"text": "What is programming? Programming,", "timestamp": "00:01:01,410", "timestamp_s": 61.0}, {"text": "traditionally you have an input.", "timestamp": "00:01:04,510", "timestamp_s": 64.0}, {"text": "You write an algorithm, you combine them together,", "timestamp": "00:01:07,374", "timestamp_s": 67.0}, {"text": "run it, and it will spit out answers for you.", "timestamp": "00:01:11,430", "timestamp_s": 71.0}, {"text": "In machine learning world, you have an input,", "timestamp": "00:01:14,488", "timestamp_s": 74.0}, {"text": "you have examples of what the answers would be,", "timestamp": "00:01:18,146", "timestamp_s": 78.0}, {"text": "and the computer\u0027s goal is to", "timestamp": "00:01:22,284", "timestamp_s": 82.0}, {"text": "provide an algorithm for you. So as a primer,", "timestamp": "00:01:25,852", "timestamp_s": 85.0}, {"text": "you have your programming, traditional programming at the right,", "timestamp": "00:01:29,686", "timestamp_s": 89.0}, {"text": "machine learning on the left still", "timestamp": "00:01:33,230", "timestamp_s": 93.0}, {"text": "have your input, answers, and your algorithm machine", "timestamp": "00:01:37,872", "timestamp_s": 97.0}, {"text": "learning world, we call", "timestamp": "00:01:41,098", "timestamp_s": 101.0}, {"text": "the input and the answers as your training data.", "timestamp": "00:01:44,690", "timestamp_s": 104.0}, {"text": "You have to use a training framework in order", "timestamp": "00:01:49,090", "timestamp_s": 109.0}, {"text": "to get a machine learning model.", "timestamp": "00:01:52,840", "timestamp_s": 112.0}, {"text": "And based from that model you would", "timestamp": "00:01:56,392", "timestamp_s": 116.0}, {"text": "substitute or use that into your", "timestamp": "00:01:59,992", "timestamp_s": 119.0}, {"text": "application, and that\u0027s what we call inferencing.", "timestamp": "00:02:03,400", "timestamp_s": 123.0}, {"text": "And you would use a runtime to", "timestamp": "00:02:08,010", "timestamp_s": 128.0}, {"text": "be able to process your input and your model, and it would give", "timestamp": "00:02:12,492", "timestamp_s": 132.0}, {"text": "you the answers. And now that you have more", "timestamp": "00:02:15,772", "timestamp_s": 135.0}, {"text": "answers, it could be a good feedback loop to improve", "timestamp": "00:02:19,392", "timestamp_s": 139.0}, {"text": "your training data.", "timestamp": "00:02:22,822", "timestamp_s": 142.0}, {"text": "So typically data scientists would", "timestamp": "00:02:25,630", "timestamp_s": 145.0}, {"text": "program, or would create a program", "timestamp": "00:02:30,452", "timestamp_s": 150.0}, {"text": "in Pytorch. They would run it locally on their machine", "timestamp": "00:02:34,196", "timestamp_s": 154.0}, {"text": "using the cpu. And then of course,", "timestamp": "00:02:38,930", "timestamp_s": 158.0}, {"text": "if you are a JavaScript developer and you\u0027ve", "timestamp": "00:02:42,770", "timestamp_s": 162.0}, {"text": "seen all these different Javascript frameworks", "timestamp": "00:02:47,242", "timestamp_s": 167.0}, {"text": "and all these different ways, and how you", "timestamp": "00:02:50,922", "timestamp_s": 170.0}, {"text": "can create applications or", "timestamp": "00:02:55,028", "timestamp_s": 175.0}, {"text": "web applications the same way as in machine", "timestamp": "00:02:58,572", "timestamp_s": 178.0}, {"text": "learning world. There\u0027s all these different machine", "timestamp": "00:03:03,122", "timestamp_s": 183.0}, {"text": "learning frameworks, training frameworks that you can use,", "timestamp": "00:03:06,642", "timestamp_s": 186.0}, {"text": "and the ecosystem is growing.", "timestamp": "00:03:10,332", "timestamp_s": 190.0}, {"text": "And of course we\u0027re not just limited in deploying it locally", "timestamp": "00:03:14,278", "timestamp_s": 194.0}, {"text": "on our devices, not just on", "timestamp": "00:03:18,166", "timestamp_s": 198.0}, {"text": "our laptops. Also, you have to sometimes use a phone or", "timestamp": "00:03:22,052", "timestamp_s": 202.0}, {"text": "deploy it in the cloud. Sometimes you want better", "timestamp": "00:03:26,468", "timestamp_s": 206.0}, {"text": "performance. You run it through a GPU or", "timestamp": "00:03:30,436", "timestamp_s": 210.0}, {"text": "FPGA or ASIC, or you", "timestamp": "00:03:34,950", "timestamp_s": 214.0}, {"text": "can also run it, you might wanted to also run it on", "timestamp": "00:03:39,928", "timestamp_s": 219.0}, {"text": "a microcontroller.", "timestamp": "00:03:43,272", "timestamp_s": 223.0}, {"text": "And that\u0027s when Onnx comes into", "timestamp": "00:03:47,930", "timestamp_s": 227.0}, {"text": "the picture. Onyx is the bridge between how", "timestamp": "00:03:51,148", "timestamp_s": 231.0}, {"text": "you get trained and where to deploy.", "timestamp": "00:03:54,972", "timestamp_s": 234.0}, {"text": "Onnx is short for open", "timestamp": "00:03:58,990", "timestamp_s": 238.0}, {"text": "neural network exchange. It is an open format", "timestamp": "00:04:02,672", "timestamp_s": 242.0}, {"text": "for machine learning models. Notice that it\u0027s not just limited", "timestamp": "00:04:06,582", "timestamp_s": 246.0}, {"text": "to neural networks, it\u0027s also capable", "timestamp": "00:04:10,182", "timestamp_s": 250.0}, {"text": "of your traditional machine learning models too. It is on", "timestamp": "00:04:13,610", "timestamp_s": 253.0}, {"text": "GitHub, GitHub.com onyx", "timestamp": "00:04:17,620", "timestamp_s": 257.0}, {"text": "and best place to learn more about Onnx about", "timestamp": "00:04:21,258", "timestamp_s": 261.0}, {"text": "Onnx is through Onyx AI. And when you go", "timestamp": "00:04:25,412", "timestamp_s": 265.0}, {"text": "to this website, you\u0027ll notice that every time I would go", "timestamp": "00:04:29,128", "timestamp_s": 269.0}, {"text": "in there\u0027s new partners coming in and be", "timestamp": "00:04:32,648", "timestamp_s": 272.0}, {"text": "able to improve that ecosystem.", "timestamp": "00:04:36,108", "timestamp_s": 276.0}, {"text": "We just started between partnership between Microsoft and", "timestamp": "00:04:39,770", "timestamp_s": 279.0}, {"text": "Facebook and I\u0027ve noticed that more and", "timestamp": "00:04:43,036", "timestamp_s": 283.0}, {"text": "more there\u0027s partners", "timestamp": "00:04:46,092", "timestamp_s": 286.0}, {"text": "using this application on GitHub", "timestamp": "00:04:51,550", "timestamp_s": 291.0}, {"text": "about 10.9 what, 11,000 GitHub stars", "timestamp": "00:04:56,190", "timestamp_s": 296.0}, {"text": "pull request about almost 2000 pull request about", "timestamp": "00:05:00,670", "timestamp_s": 300.0}, {"text": "200 contributors about 2000 GitHub", "timestamp": "00:05:04,452", "timestamp_s": 304.0}, {"text": "forks and there\u0027s also model zoo. Onnx is", "timestamp": "00:05:08,522", "timestamp_s": 308.0}, {"text": "available out there. It is a graduate project of", "timestamp": "00:05:14,712", "timestamp_s": 314.0}, {"text": "Linux Foundation AI.", "timestamp": "00:05:18,664", "timestamp_s": 318.0}, {"text": "And so it\u0027s becoming more,", "timestamp": "00:05:22,630", "timestamp_s": 322.0}, {"text": "there\u0027s a lot of traction going on for these Onyx", "timestamp": "00:05:28,810", "timestamp_s": 328.0}, {"text": "application. When would you use Onnx?", "timestamp": "00:05:33,746", "timestamp_s": 333.0}, {"text": "Is when you have something", "timestamp": "00:05:38,910", "timestamp_s": 338.0}, {"text": "that\u0027s trained in Python and you want to deploy it to a", "timestamp": "00:05:42,272", "timestamp_s": 342.0}, {"text": "C sharp application, or maybe you want to incorporate", "timestamp": "00:05:46,144", "timestamp_s": 346.0}, {"text": "it to your Java application or JavaScript application when", "timestamp": "00:05:49,558", "timestamp_s": 349.0}, {"text": "you have high inferency latency", "timestamp": "00:05:54,308", "timestamp_s": 354.0}, {"text": "that you want for production use. So, meaning if it\u0027s", "timestamp": "00:05:58,938", "timestamp_s": 358.0}, {"text": "too slow to run it or if you want", "timestamp": "00:06:02,634", "timestamp_s": 362.0}, {"text": "performance so that you can use it for production.", "timestamp": "00:06:06,472", "timestamp_s": 366.0}, {"text": "Because let\u0027s say if you have it in some training", "timestamp": "00:06:09,886", "timestamp_s": 369.0}, {"text": "platform or training framework and it\u0027s", "timestamp": "00:06:15,930", "timestamp_s": 375.0}, {"text": "not good enough and you want to improve,", "timestamp": "00:06:19,858", "timestamp_s": 379.0}, {"text": "if you have high inferency, that would be a good use case for", "timestamp": "00:06:25,370", "timestamp_s": 385.0}, {"text": "it. If you want to deploy it to an IoT device or", "timestamp": "00:06:28,668", "timestamp_s": 388.0}, {"text": "an edge device, it might make sense to convert it", "timestamp": "00:06:31,808", "timestamp_s": 391.0}, {"text": "to Onyx and be able to deploy it to those devices", "timestamp": "00:06:35,264", "timestamp_s": 395.0}, {"text": "when it\u0027s trained on a different", "timestamp": "00:06:39,446", "timestamp_s": 399.0}, {"text": "OS. And if you want to run that model into a different", "timestamp": "00:06:43,490", "timestamp_s": 403.0}, {"text": "OS or different hardware, that is a good use case", "timestamp": "00:06:46,916", "timestamp_s": 406.0}, {"text": "for it. When you want to combine", "timestamp": "00:06:50,692", "timestamp_s": 410.0}, {"text": "the models, let\u0027s say you have a team of data scientists.", "timestamp": "00:06:55,102", "timestamp_s": 415.0}, {"text": "Some of your models were created on, let\u0027s say Pytorch and some", "timestamp": "00:07:02,390", "timestamp_s": 422.0}, {"text": "of the models were created in keras. And you want to create a", "timestamp": "00:07:06,408", "timestamp_s": 426.0}, {"text": "pipeline and you want to combine these models that", "timestamp": "00:07:09,724", "timestamp_s": 429.0}, {"text": "is trained from different frameworks. That is another way.", "timestamp": "00:07:13,868", "timestamp_s": 433.0}, {"text": "Another one is through training, takes too", "timestamp": "00:07:17,630", "timestamp_s": 437.0}, {"text": "long. And that\u0027s when you start talking about transformer", "timestamp": "00:07:21,392", "timestamp_s": 441.0}, {"text": "models. Let\u0027s say if you want to train it locally", "timestamp": "00:07:25,462", "timestamp_s": 445.0}, {"text": "at the edge, that is one way that you can use", "timestamp": "00:07:30,030", "timestamp_s": 450.0}, {"text": "Onyx too. All right, so we", "timestamp": "00:07:33,732", "timestamp_s": 453.0}, {"text": "did talk about what is Onyx. One thing I", "timestamp": "00:07:37,188", "timestamp_s": 457.0}, {"text": "want to point out, one good way of to describe", "timestamp": "00:07:40,868", "timestamp_s": 460.0}, {"text": "Onnx, it\u0027s kind of like PDF, right?", "timestamp": "00:07:44,862", "timestamp_s": 464.0}, {"text": "You create your Word document in", "timestamp": "00:07:48,248", "timestamp_s": 468.0}, {"text": "Microsoft Word. Or you create your documents", "timestamp": "00:07:53,190", "timestamp_s": 473.0}, {"text": "in Microsoft Word or some word processing", "timestamp": "00:07:58,410", "timestamp_s": 478.0}, {"text": "application, you convert it to PDF.", "timestamp": "00:08:03,058", "timestamp_s": 483.0}, {"text": "Now you can display it on different types of devices using", "timestamp": "00:08:06,354", "timestamp_s": 486.0}, {"text": "acrobat or PDF viewer.", "timestamp": "00:08:12,190", "timestamp_s": 492.0}, {"text": "And then we did talk about when", "timestamp": "00:08:15,790", "timestamp_s": 495.0}, {"text": "to use Onnx. And then we\u0027ll talk", "timestamp": "00:08:18,992", "timestamp_s": 498.0}, {"text": "more about how to create the Onyx models", "timestamp": "00:08:22,692", "timestamp_s": 502.0}, {"text": "and how to deploy onnx models,", "timestamp": "00:08:25,978", "timestamp_s": 505.0}, {"text": "how to create Onyx models, step one. And then we\u0027ll", "timestamp": "00:08:30,050", "timestamp_s": 510.0}, {"text": "talk more about step two. Step one. Let\u0027s focus on that. Have you", "timestamp": "00:08:33,454", "timestamp_s": 513.0}, {"text": "ever baked a cake? And of course there\u0027s a", "timestamp": "00:08:37,128", "timestamp_s": 517.0}, {"text": "lot of different ingredients, different procedures.", "timestamp": "00:08:40,504", "timestamp_s": 520.0}, {"text": "Of course bakers specializes on this.", "timestamp": "00:08:45,370", "timestamp_s": 525.0}, {"text": "My analogy in this is that bakers", "timestamp": "00:08:49,610", "timestamp_s": 529.0}, {"text": "or your data scientist,", "timestamp": "00:08:55,050", "timestamp_s": 535.0}, {"text": "your team, they\u0027re the ones who make the", "timestamp": "00:08:57,870", "timestamp_s": 537.0}, {"text": "secret recipe for your business. They try", "timestamp": "00:09:01,856", "timestamp_s": 541.0}, {"text": "different tweaks and different ingredients and different procedures", "timestamp": "00:09:05,872", "timestamp_s": 545.0}, {"text": "and how to create these AI", "timestamp": "00:09:10,506", "timestamp_s": 550.0}, {"text": "models, which is going to be your secret recipe.", "timestamp": "00:09:14,682", "timestamp_s": 554.0}, {"text": "So how do you create these Onyx models? One way is to export", "timestamp": "00:09:18,850", "timestamp_s": 558.0}, {"text": "or using Onyx model zoo.", "timestamp": "00:09:23,274", "timestamp_s": 563.0}, {"text": "Onyx model zoo. There\u0027s existing", "timestamp": "00:09:28,390", "timestamp_s": 568.0}, {"text": "models out there that you can just download off the Internet and start using", "timestamp": "00:09:32,870", "timestamp_s": 572.0}, {"text": "incorporating to your application. You can use Azure custom", "timestamp": "00:09:36,684", "timestamp_s": 576.0}, {"text": "vision or some service that exports to", "timestamp": "00:09:40,796", "timestamp_s": 580.0}, {"text": "Onyx. You can convert an existing model and", "timestamp": "00:09:44,652", "timestamp_s": 584.0}, {"text": "also you can train models in azure machine", "timestamp": "00:09:49,312", "timestamp_s": 589.0}, {"text": "learning or some automated machine learning. So Onnx", "timestamp": "00:09:52,902", "timestamp_s": 592.0}, {"text": "model zoo allows you to be able to just,", "timestamp": "00:09:56,598", "timestamp_s": 596.0}, {"text": "someone already pre converted all these different", "timestamp": "00:10:01,490", "timestamp_s": 601.0}, {"text": "popular AI models out there or machine learning", "timestamp": "00:10:05,124", "timestamp_s": 605.0}, {"text": "models out there. If you\u0027re interested in Restnet, it\u0027s already converted", "timestamp": "00:10:09,076", "timestamp_s": 609.0}, {"text": "to Onyx for you and you can just download it.", "timestamp": "00:10:13,278", "timestamp_s": 613.0}, {"text": "These are some examples of the different sizes", "timestamp": "00:10:17,350", "timestamp_s": 617.0}, {"text": "of that model once it\u0027s converted to onnx.", "timestamp": "00:10:21,750", "timestamp_s": 621.0}, {"text": "So it\u0027s not just limited in image, there\u0027s also sound.", "timestamp": "00:10:25,770", "timestamp_s": 625.0}, {"text": "There\u0027s different models out there", "timestamp": "00:10:29,130", "timestamp_s": 629.0}, {"text": "you can just download. Another one is through custom", "timestamp": "00:10:32,492", "timestamp_s": 632.0}, {"text": "vision, which allows you to do low code vision", "timestamp": "00:10:36,380", "timestamp_s": 636.0}, {"text": "service where you would upload some photos,", "timestamp": "00:10:41,382", "timestamp_s": 641.0}, {"text": "you tag them, start tagging them, you train", "timestamp": "00:10:45,110", "timestamp_s": 645.0}, {"text": "to create a machine learning model for you", "timestamp": "00:10:50,370", "timestamp_s": 650.0}, {"text": "and then you can export it to Onyx.", "timestamp": "00:10:54,180", "timestamp_s": 654.0}, {"text": "Another way is to convert the model", "timestamp": "00:10:57,890", "timestamp_s": 657.0}, {"text": "from the existing training frameworks.", "timestamp": "00:11:02,390", "timestamp_s": 662.0}, {"text": "So let\u0027s say you", "timestamp": "00:11:06,190", "timestamp_s": 666.0}, {"text": "have it in Pytorch or keras or Tensorflow or Scikitlearn.", "timestamp": "00:11:10,232", "timestamp_s": 670.0}, {"text": "There\u0027s a way you can convert it to an Onyx model. Of course there\u0027s three", "timestamp": "00:11:14,990", "timestamp_s": 674.0}, {"text": "steps loaded in existing model into memory.", "timestamp": "00:11:18,652", "timestamp_s": 678.0}, {"text": "Convert to an Onyx and save that Onyx model.", "timestamp": "00:11:22,410", "timestamp_s": 682.0}, {"text": "Here\u0027s an example of how you would use and", "timestamp": "00:11:28,270", "timestamp_s": 688.0}, {"text": "convert from Pytorch to onnx.", "timestamp": "00:11:32,352", "timestamp_s": 692.0}, {"text": "So you would load that model", "timestamp": "00:11:38,350", "timestamp_s": 698.0}, {"text": "and provide some sample input and use this torch onnx", "timestamp": "00:11:43,010", "timestamp_s": 703.0}, {"text": "to export it. Another way is know", "timestamp": "00:11:47,082", "timestamp_s": 707.0}, {"text": "if you have it in keras. Same steps.", "timestamp": "00:11:50,580", "timestamp_s": 710.0}, {"text": "You load the Keras model, convert the Keras model into", "timestamp": "00:11:53,726", "timestamp_s": 713.0}, {"text": "Onyx, and then save it as", "timestamp": "00:11:57,096", "timestamp_s": 717.0}, {"text": "a protoblock. And there", "timestamp": "00:12:01,032", "timestamp_s": 721.0}, {"text": "is onyxml tools that", "timestamp": "00:12:05,608", "timestamp_s": 725.0}, {"text": "you can do to pip install. You can also", "timestamp": "00:12:09,228", "timestamp_s": 729.0}, {"text": "convert the Tensorflow model using command line.", "timestamp": "00:12:13,356", "timestamp_s": 733.0}, {"text": "So where you specify, of course, your input, where\u0027s your", "timestamp": "00:12:17,210", "timestamp_s": 737.0}, {"text": "saved model and then your output. A lot of good", "timestamp": "00:12:21,520", "timestamp_s": 741.0}, {"text": "examples how you would do this on", "timestamp": "00:12:24,992", "timestamp_s": 744.0}, {"text": "GitHub. This one is through ScikitLearn.", "timestamp": "00:12:28,608", "timestamp_s": 748.0}, {"text": "Notice that there\u0027s an SKL to onnx", "timestamp": "00:12:32,986", "timestamp_s": 752.0}, {"text": "where you can convert scikitlearn into", "timestamp": "00:12:37,010", "timestamp_s": 757.0}, {"text": "an Onyx application or to onnx", "timestamp": "00:12:42,276", "timestamp_s": 762.0}, {"text": "format. I keep", "timestamp": "00:12:46,062", "timestamp_s": 766.0}, {"text": "on talking about Onyx. Let me go back real quick.", "timestamp": "00:12:49,128", "timestamp_s": 769.0}, {"text": "There\u0027s this tool called nettron app", "timestamp": "00:12:53,190", "timestamp_s": 773.0}, {"text": "that visualizes this Onyx model for you.", "timestamp": "00:12:58,108", "timestamp_s": 778.0}, {"text": "And it also helps software", "timestamp": "00:13:02,730", "timestamp_s": 782.0}, {"text": "engineers to kind of know what\u0027s", "timestamp": "00:13:06,482", "timestamp_s": 786.0}, {"text": "the input and output of that existing model without going", "timestamp": "00:13:10,582", "timestamp_s": 790.0}, {"text": "back to the data scientist, going back to the original", "timestamp": "00:13:14,448", "timestamp_s": 794.0}, {"text": "code where it was trained from to know how to use can Onyx", "timestamp": "00:13:18,422", "timestamp_s": 798.0}, {"text": "model. It visualizes the inputs and then", "timestamp": "00:13:21,962", "timestamp_s": 801.0}, {"text": "be able to kind of visualize what the graph of operations", "timestamp": "00:13:25,412", "timestamp_s": 805.0}, {"text": "would look like. If you go to Netron", "timestamp": "00:13:29,354", "timestamp_s": 809.0}, {"text": "app, open an Onyx file there,", "timestamp": "00:13:34,574", "timestamp_s": 814.0}, {"text": "and you can visualize it. All right.", "timestamp": "00:13:37,576", "timestamp_s": 817.0}, {"text": "You can also use onnx as an intermediary format", "timestamp": "00:13:42,950", "timestamp_s": 822.0}, {"text": "intermediate. Let\u0027s say if you", "timestamp": "00:13:47,710", "timestamp_s": 827.0}, {"text": "have a Pytorch model and you want to convert it to Tensorflow, you can convert", "timestamp": "00:13:51,228", "timestamp_s": 831.0}, {"text": "from Pytorch to Onyx and Onyx to Tensorflow.", "timestamp": "00:13:55,362", "timestamp_s": 835.0}, {"text": "That is one way. Also,", "timestamp": "00:13:59,062", "timestamp_s": 839.0}, {"text": "there\u0027s Onyx to core ML that you can", "timestamp": "00:14:02,000", "timestamp_s": 842.0}, {"text": "use. There\u0027s ways also you", "timestamp": "00:14:05,408", "timestamp_s": 845.0}, {"text": "can fine tune, can onyx model create", "timestamp": "00:14:08,928", "timestamp_s": 848.0}, {"text": "and do transfer learning on an existing onnx model.", "timestamp": "00:14:13,028", "timestamp_s": 853.0}, {"text": "If you\u0027re interested, of course", "timestamp": "00:14:16,660", "timestamp_s": 856.0}, {"text": "you can train models in the cloud.", "timestamp": "00:14:20,788", "timestamp_s": 860.0}, {"text": "You have a GPU clusters.", "timestamp": "00:14:24,376", "timestamp_s": 864.0}, {"text": "But the important part here for me, and I wanted to talk more,", "timestamp": "00:14:27,270", "timestamp_s": 867.0}, {"text": "this is your typical end to end machine learning process,", "timestamp": "00:14:31,032", "timestamp_s": 871.0}, {"text": "where you have your experiments and you\u0027re building your", "timestamp": "00:14:34,360", "timestamp_s": 874.0}, {"text": "base from your different iDe, or you create", "timestamp": "00:14:38,170", "timestamp_s": 878.0}, {"text": "your training application. Once you train it,", "timestamp": "00:14:43,130", "timestamp_s": 883.0}, {"text": "you would have a machine learning model.", "timestamp": "00:14:47,950", "timestamp_s": 887.0}, {"text": "You register it somewhere in the cloud and", "timestamp": "00:14:52,670", "timestamp_s": 892.0}, {"text": "manage these models. You can have these versionings and", "timestamp": "00:14:56,432", "timestamp_s": 896.0}, {"text": "then based from that, kind of like when you have a", "timestamp": "00:15:00,228", "timestamp_s": 900.0}, {"text": "docker image, you have kind of like Docker hub where you", "timestamp": "00:15:04,164", "timestamp_s": 904.0}, {"text": "can store all these images.", "timestamp": "00:15:07,908", "timestamp_s": 907.0}, {"text": "Also as your machine learning,", "timestamp": "00:15:10,930", "timestamp_s": 910.0}, {"text": "as a way you can manage your models, you can upload these", "timestamp": "00:15:14,692", "timestamp_s": 914.0}, {"text": "models there and be able to version", "timestamp": "00:15:18,248", "timestamp_s": 918.0}, {"text": "them and also build a pipeline to create", "timestamp": "00:15:21,982", "timestamp_s": 921.0}, {"text": "and to download these and incorporate it and create the image.", "timestamp": "00:15:26,524", "timestamp_s": 926.0}, {"text": "So we did talk about step one,", "timestamp": "00:15:32,570", "timestamp_s": 932.0}, {"text": "creating. Once we have an Onnx model,", "timestamp": "00:15:35,820", "timestamp_s": 935.0}, {"text": "start deploying them.", "timestamp": "00:15:39,950", "timestamp_s": 939.0}, {"text": "Okay, so we did talk about,", "timestamp": "00:15:42,430", "timestamp_s": 942.0}, {"text": "as your data scientist, building kind of like a", "timestamp": "00:15:46,112", "timestamp_s": 946.0}, {"text": "chef or a baker building your secret recipe.", "timestamp": "00:15:49,792", "timestamp_s": 949.0}, {"text": "Now, let me ask you one thing. What is the difference between", "timestamp": "00:15:53,610", "timestamp_s": 953.0}, {"text": "a baker and starting a bakery?", "timestamp": "00:15:57,380", "timestamp_s": 957.0}, {"text": "Main difference is they all have different skill set.", "timestamp": "00:16:01,170", "timestamp_s": 961.0}, {"text": "In order to create a successful business", "timestamp": "00:16:05,990", "timestamp_s": 965.0}, {"text": "or successful bakery, you need both.", "timestamp": "00:16:09,768", "timestamp_s": 969.0}, {"text": "Need the baker and also you", "timestamp": "00:16:12,696", "timestamp_s": 972.0}, {"text": "need someone that actually manages the bakery.", "timestamp": "00:16:16,108", "timestamp_s": 976.0}, {"text": "Software engineers are", "timestamp": "00:16:19,850", "timestamp_s": 979.0}, {"text": "great at looking into how to", "timestamp": "00:16:23,596", "timestamp_s": 983.0}, {"text": "start a bakery. They know where to put the cash here,", "timestamp": "00:16:27,148", "timestamp_s": 987.0}, {"text": "how to collect money, right. How to create", "timestamp": "00:16:30,604", "timestamp_s": 990.0}, {"text": "these pipelines and how you would display or", "timestamp": "00:16:34,512", "timestamp_s": 994.0}, {"text": "use the application and be able to create", "timestamp": "00:16:37,632", "timestamp_s": 997.0}, {"text": "those different areas of the business system,", "timestamp": "00:16:41,748", "timestamp_s": 1001.0}, {"text": "how you would use the", "timestamp": "00:16:45,650", "timestamp_s": 1005.0}, {"text": "machine learning model or how to create the whole application itself.", "timestamp": "00:16:49,572", "timestamp_s": 1009.0}, {"text": "What is the customer experience in all these different", "timestamp": "00:16:53,492", "timestamp_s": 1013.0}, {"text": "things? So it", "timestamp": "00:16:57,352", "timestamp_s": 1017.0}, {"text": "is important, whenever we create these machine learning", "timestamp": "00:17:02,408", "timestamp_s": 1022.0}, {"text": "models, it is important where we\u0027re going to", "timestamp": "00:17:06,376", "timestamp_s": 1026.0}, {"text": "deploy them. Some things to think about, right?", "timestamp": "00:17:09,708", "timestamp_s": 1029.0}, {"text": "You deploy it on a VM, you might want to deploy it on", "timestamp": "00:17:14,410", "timestamp_s": 1034.0}, {"text": "a Windows device or a Linux device or a Mac,", "timestamp": "00:17:17,808", "timestamp_s": 1037.0}, {"text": "you can deploy it on it. Edge devices or", "timestamp": "00:17:21,910", "timestamp_s": 1041.0}, {"text": "phones, different ways. How you would deploy", "timestamp": "00:17:26,030", "timestamp_s": 1046.0}, {"text": "and create these AI models and", "timestamp": "00:17:30,326", "timestamp_s": 1050.0}, {"text": "use these AI models. Of course,", "timestamp": "00:17:34,628", "timestamp_s": 1054.0}, {"text": "every time we think about deployment,", "timestamp": "00:17:38,130", "timestamp_s": 1058.0}, {"text": "think about where we can deploy this. We\u0027re going to deploy this to the cloud", "timestamp": "00:17:41,946", "timestamp_s": 1061.0}, {"text": "or at the edge. Edge meaning how close it is to", "timestamp": "00:17:45,464", "timestamp_s": 1065.0}, {"text": "your customers or your users.", "timestamp": "00:17:49,032", "timestamp_s": 1069.0}, {"text": "The analogy in that is McDonald\u0027s and", "timestamp": "00:17:52,790", "timestamp_s": 1072.0}, {"text": "subway. What\u0027s the difference in how they make the bread?", "timestamp": "00:17:56,252", "timestamp_s": 1076.0}, {"text": "Right. McDonald\u0027s most likely it\u0027s", "timestamp": "00:18:00,018", "timestamp_s": 1080.0}, {"text": "in not a warehouse, but it\u0027s outsourced.", "timestamp": "00:18:03,858", "timestamp_s": 1083.0}, {"text": "It\u0027s not at the edge, meaning it\u0027s not", "timestamp": "00:18:08,418", "timestamp_s": 1088.0}, {"text": "at the store, just compared to a", "timestamp": "00:18:13,230", "timestamp_s": 1093.0}, {"text": "subway, where you", "timestamp": "00:18:16,432", "timestamp_s": 1096.0}, {"text": "bake the bread at the store. So it\u0027s", "timestamp": "00:18:20,528", "timestamp_s": 1100.0}, {"text": "a different experience. Right. So what I\u0027m trying to", "timestamp": "00:18:23,978", "timestamp_s": 1103.0}, {"text": "get at is whenever we talk about deployment, where we\u0027re going to run", "timestamp": "00:18:27,428", "timestamp_s": 1107.0}, {"text": "these AI models, where do we want to run them?", "timestamp": "00:18:33,410", "timestamp_s": 1113.0}, {"text": "Do we send the data to the cloud and then we run the inferencing", "timestamp": "00:18:37,592", "timestamp_s": 1117.0}, {"text": "at the cloud and then return the results to us,", "timestamp": "00:18:41,886", "timestamp_s": 1121.0}, {"text": "or at the edge, meaning closer to the user. Maybe it\u0027s on", "timestamp": "00:18:45,292", "timestamp_s": 1125.0}, {"text": "the phone, or maybe it\u0027s on the camera", "timestamp": "00:18:48,668", "timestamp_s": 1128.0}, {"text": "itself, or in a gateway", "timestamp": "00:18:51,906", "timestamp_s": 1131.0}, {"text": "closer to the user. So those", "timestamp": "00:18:55,570", "timestamp_s": 1135.0}, {"text": "are things we have to consider when we", "timestamp": "00:18:58,828", "timestamp_s": 1138.0}, {"text": "deploy these machine learning models,", "timestamp": "00:19:02,384", "timestamp_s": 1142.0}, {"text": "especially in the Onnx model. Of course,", "timestamp": "00:19:05,878", "timestamp_s": 1145.0}, {"text": "you can also deploy them in the cloud, how you would deploy them,", "timestamp": "00:19:10,030", "timestamp_s": 1150.0}, {"text": "since you already have registered in", "timestamp": "00:19:13,444", "timestamp_s": 1153.0}, {"text": "your machine learning model or your Onyx models in the cloud. As you", "timestamp": "00:19:17,970", "timestamp_s": 1157.0}, {"text": "build your image, you create your pipeline.", "timestamp": "00:19:21,588", "timestamp_s": 1161.0}, {"text": "That is one way where you", "timestamp": "00:19:24,494", "timestamp_s": 1164.0}, {"text": "can deploy it through a service, an app service.", "timestamp": "00:19:29,704", "timestamp_s": 1169.0}, {"text": "You can deploy it and run it in a", "timestamp": "00:19:33,080", "timestamp_s": 1173.0}, {"text": "docker container or in Kubernetes service.", "timestamp": "00:19:36,556", "timestamp_s": 1176.0}, {"text": "Speaking of docker images,", "timestamp": "00:19:41,850", "timestamp_s": 1181.0}, {"text": "there are Onyx Docker images that you can start using.", "timestamp": "00:19:45,770", "timestamp_s": 1185.0}, {"text": "There\u0027s an Onyx base that has minimal dependency that you", "timestamp": "00:19:50,110", "timestamp_s": 1190.0}, {"text": "can use it. If you want to run", "timestamp": "00:19:54,208", "timestamp_s": 1194.0}, {"text": "use onyx into your application. There\u0027s Onyx ecosystem", "timestamp": "00:19:58,190", "timestamp_s": 1198.0}, {"text": "that allows you to be able to convert without", "timestamp": "00:20:02,922", "timestamp_s": 1202.0}, {"text": "an installer, right? So let\u0027s say", "timestamp": "00:20:06,868", "timestamp_s": 1206.0}, {"text": "if you just want to convert an existing Onyx model,", "timestamp": "00:20:10,468", "timestamp_s": 1210.0}, {"text": "an existing application or an", "timestamp": "00:20:14,470", "timestamp_s": 1214.0}, {"text": "existing machine learning model, let\u0027s say it was written in Pytorch.", "timestamp": "00:20:17,832", "timestamp_s": 1217.0}, {"text": "You don\u0027t want to download all", "timestamp": "00:20:21,854", "timestamp_s": 1221.0}, {"text": "the converters locally in your machine. You can just", "timestamp": "00:20:25,868", "timestamp_s": 1225.0}, {"text": "use these docker", "timestamp": "00:20:29,356", "timestamp_s": 1229.0}, {"text": "images. So whenever we", "timestamp": "00:20:34,730", "timestamp_s": 1234.0}, {"text": "talk about edge, what is the edge?", "timestamp": "00:20:38,028", "timestamp_s": 1238.0}, {"text": "Remember the definition is how close it is to your customers", "timestamp": "00:20:41,718", "timestamp_s": 1241.0}, {"text": "or to your users. But of course, every time we", "timestamp": "00:20:45,488", "timestamp_s": 1245.0}, {"text": "think about the edge, we\u0027ll talk about", "timestamp": "00:20:48,992", "timestamp_s": 1248.0}, {"text": "deployment. When we deploy it to the cloud,", "timestamp": "00:20:52,372", "timestamp_s": 1252.0}, {"text": "most likely it\u0027s just you\u0027re deploying to the data centers. Maybe it\u0027s thousands", "timestamp": "00:20:56,308", "timestamp_s": 1256.0}, {"text": "of devices. If we talk about we\u0027re going to deploy it", "timestamp": "00:21:00,698", "timestamp_s": 1260.0}, {"text": "in 5g infrastructure where", "timestamp": "00:21:04,648", "timestamp_s": 1264.0}, {"text": "we deploy it to the fog, which is maybe", "timestamp": "00:21:09,432", "timestamp_s": 1269.0}, {"text": "just millions of devices, millions of", "timestamp": "00:21:13,976", "timestamp_s": 1273.0}, {"text": "models where you\u0027re going to deploy these. And of course, when you talk about edge", "timestamp": "00:21:17,884", "timestamp_s": 1277.0}, {"text": "might be billions of devices depending on the", "timestamp": "00:21:22,330", "timestamp_s": 1282.0}, {"text": "need, because each", "timestamp": "00:21:25,932", "timestamp_s": 1285.0}, {"text": "device may have those different deployment structure.", "timestamp": "00:21:30,432", "timestamp_s": 1290.0}, {"text": "So why would you want to deploy your machine learning", "timestamp": "00:21:35,710", "timestamp_s": 1295.0}, {"text": "model on the edge or run it on the", "timestamp": "00:21:39,376", "timestamp_s": 1299.0}, {"text": "edge? One is low latency.", "timestamp": "00:21:42,708", "timestamp_s": 1302.0}, {"text": "Think about, let\u0027s say you\u0027re collecting videos, right?", "timestamp": "00:21:45,706", "timestamp_s": 1305.0}, {"text": "You\u0027re doing inferencing based from", "timestamp": "00:21:48,852", "timestamp_s": 1308.0}, {"text": "video or sound. You want it faster,", "timestamp": "00:21:52,452", "timestamp_s": 1312.0}, {"text": "so it makes sense to run it locally on", "timestamp": "00:21:57,630", "timestamp_s": 1317.0}, {"text": "that device itself. So it\u0027s load in.", "timestamp": "00:22:01,912", "timestamp_s": 1321.0}, {"text": "See, think about it. If you have to ship that to the cloud,", "timestamp": "00:22:05,192", "timestamp_s": 1325.0}, {"text": "you have to ship each images, each frame.", "timestamp": "00:22:08,972", "timestamp_s": 1328.0}, {"text": "That might cost you money and of course produce scalability.", "timestamp": "00:22:12,330", "timestamp_s": 1332.0}, {"text": "So it might make sense to run it at the edge", "timestamp": "00:22:16,594", "timestamp_s": 1336.0}, {"text": "to provide scalability. Another one is flexibility.", "timestamp": "00:22:21,070", "timestamp_s": 1341.0}, {"text": "So it might make sense to run it locally", "timestamp": "00:22:25,230", "timestamp_s": 1345.0}, {"text": "so you don\u0027t have the need for Internet connection.", "timestamp": "00:22:28,822", "timestamp_s": 1348.0}, {"text": "Also rules, privacy rules,", "timestamp": "00:22:32,690", "timestamp_s": 1352.0}, {"text": "want to send any", "timestamp": "00:22:37,170", "timestamp_s": 1357.0}, {"text": "personally identify Pii information or", "timestamp": "00:22:42,690", "timestamp_s": 1362.0}, {"text": "might make sense to local laws that", "timestamp": "00:22:48,530", "timestamp_s": 1368.0}, {"text": "it\u0027s limited to certain geographical", "timestamp": "00:22:52,404", "timestamp_s": 1372.0}, {"text": "areas. So it might make sense to. It gives", "timestamp": "00:22:57,826", "timestamp_s": 1377.0}, {"text": "you that flexibility where you want to deploy", "timestamp": "00:23:01,068", "timestamp_s": 1381.0}, {"text": "and where you want to run this inferencing.", "timestamp": "00:23:04,970", "timestamp_s": 1384.0}, {"text": "There is Onyx runtime where you can run it\u0027s a", "timestamp": "00:23:09,470", "timestamp_s": 1389.0}, {"text": "high performance inference engine for", "timestamp": "00:23:13,168", "timestamp_s": 1393.0}, {"text": "your onnx models. It is actually open", "timestamp": "00:23:16,656", "timestamp_s": 1396.0}, {"text": "sourced by Microsoft under MIT license. So it\u0027s", "timestamp": "00:23:20,212", "timestamp_s": 1400.0}, {"text": "not just limited to neural networks.", "timestamp": "00:23:24,298", "timestamp_s": 1404.0}, {"text": "Also for traditional machine learning spec it has", "timestamp": "00:23:27,946", "timestamp_s": 1407.0}, {"text": "extensible architecture that allows to", "timestamp": "00:23:32,116", "timestamp_s": 1412.0}, {"text": "have different hardware accelerators.", "timestamp": "00:23:35,432", "timestamp_s": 1415.0}, {"text": "It\u0027s part of Windows ten as", "timestamp": "00:23:38,790", "timestamp_s": 1418.0}, {"text": "Winml. And if you want to learn more about Onyx Runtime,", "timestamp": "00:23:42,280", "timestamp_s": 1422.0}, {"text": "there\u0027s Onnx runtime AI website.", "timestamp": "00:23:46,222", "timestamp_s": 1426.0}, {"text": "The good thing about this is there\u0027s", "timestamp": "00:23:52,090", "timestamp_s": 1432.0}, {"text": "this part where I think it\u0027s pretty neat or", "timestamp": "00:23:56,738", "timestamp_s": 1436.0}, {"text": "let\u0027s say if you want to use different platforms,", "timestamp": "00:24:00,016", "timestamp_s": 1440.0}, {"text": "let\u0027s say I\u0027m going to create a Linux application and I", "timestamp": "00:24:04,038", "timestamp_s": 1444.0}, {"text": "want to create a C sharp using C", "timestamp": "00:24:07,728", "timestamp_s": 1447.0}, {"text": "sharp API and this architecture X", "timestamp": "00:24:11,572", "timestamp_s": 1451.0}, {"text": "86. If you want to run ARM 64, you can", "timestamp": "00:24:14,772", "timestamp_s": 1454.0}, {"text": "select them and then you have these different architecture,", "timestamp": "00:24:18,052", "timestamp_s": 1458.0}, {"text": "different hardware accelerators. So if you want to use the gpu,", "timestamp": "00:24:21,730", "timestamp_s": 1461.0}, {"text": "select CUDA, or you can just use default cpu and it will", "timestamp": "00:24:25,502", "timestamp_s": 1465.0}, {"text": "give you instructions how you can incorporate it to", "timestamp": "00:24:29,128", "timestamp_s": 1469.0}, {"text": "your application.", "timestamp": "00:24:32,824", "timestamp_s": 1472.0}, {"text": "Notice that there\u0027s different hardware accelerators. So like", "timestamp": "00:24:36,150", "timestamp_s": 1476.0}, {"text": "for example if you wanted to run Openvino, you have to convert", "timestamp": "00:24:39,932", "timestamp_s": 1479.0}, {"text": "it. You don\u0027t have to convert let\u0027s say a Pytorch", "timestamp": "00:24:43,218", "timestamp_s": 1483.0}, {"text": "model to something that\u0027s compatible with Openvino.", "timestamp": "00:24:46,402", "timestamp_s": 1486.0}, {"text": "You can go Pytorch to Onyx and", "timestamp": "00:24:50,694", "timestamp_s": 1490.0}, {"text": "then use Onyx runtime with the Openvino", "timestamp": "00:24:54,448", "timestamp_s": 1494.0}, {"text": "hardware accelerator.", "timestamp": "00:24:59,318", "timestamp_s": 1499.0}, {"text": "Like I said, onnx runtime ships with Windows AI", "timestamp": "00:25:02,610", "timestamp_s": 1502.0}, {"text": "platform. So if you\u0027re", "timestamp": "00:25:06,442", "timestamp_s": 1506.0}, {"text": "as part of the Winml API,", "timestamp": "00:25:10,530", "timestamp_s": 1510.0}, {"text": "which is a practical, a simple model based API", "timestamp": "00:25:13,810", "timestamp_s": 1513.0}, {"text": "for inferencing in Windows. So let\u0027s say if you have can existing", "timestamp": "00:25:17,806", "timestamp_s": 1517.0}, {"text": "forms application and you want to add machine", "timestamp": "00:25:22,286", "timestamp_s": 1522.0}, {"text": "learning model, or you want to add", "timestamp": "00:25:26,142", "timestamp_s": 1526.0}, {"text": "machine learning to a windforms", "timestamp": "00:25:29,864", "timestamp_s": 1529.0}, {"text": "application, this allows you to be able to do that.", "timestamp": "00:25:33,294", "timestamp_s": 1533.0}, {"text": "There\u0027s also direct ML API,", "timestamp": "00:25:37,870", "timestamp_s": 1537.0}, {"text": "so that if you\u0027re creating a game, there is a way", "timestamp": "00:25:41,790", "timestamp_s": 1541.0}, {"text": "to be able to use direct ML that runs on", "timestamp": "00:25:45,696", "timestamp_s": 1545.0}, {"text": "top of DirectX twelve which has a real", "timestamp": "00:25:49,024", "timestamp_s": 1549.0}, {"text": "time high control machine learning operator API.", "timestamp": "00:25:52,736", "timestamp_s": 1552.0}, {"text": "And of course you have these robust driver models that", "timestamp": "00:25:58,050", "timestamp_s": 1558.0}, {"text": "it automatically knows if you have a gpu,", "timestamp": "00:26:01,828", "timestamp_s": 1561.0}, {"text": "a VPU or XPU fully defined,", "timestamp": "00:26:05,130", "timestamp_s": 1565.0}, {"text": "but it automatically switches. If it can", "timestamp": "00:26:08,974", "timestamp_s": 1568.0}, {"text": "run a cpu it would use it. If it can run in", "timestamp": "00:26:12,488", "timestamp_s": 1572.0}, {"text": "any one of these, then you\u0027ll be able to use that. That\u0027s how", "timestamp": "00:26:15,628", "timestamp_s": 1575.0}, {"text": "it\u0027s able to access those", "timestamp": "00:26:19,548", "timestamp_s": 1579.0}, {"text": "drivers. There is also Onnx JS", "timestamp": "00:26:22,716", "timestamp_s": 1582.0}, {"text": "which is a JavaScript library to run Onnx models in the", "timestamp": "00:26:27,130", "timestamp_s": 1587.0}, {"text": "browser or even in node it\u0027s using WebGL", "timestamp": "00:26:31,008", "timestamp_s": 1591.0}, {"text": "and webassembly and it could automatically", "timestamp": "00:26:35,558", "timestamp_s": 1595.0}, {"text": "use CPU or GPU. So think about", "timestamp": "00:26:39,526", "timestamp_s": 1599.0}, {"text": "let\u0027s say you have it in your browser.", "timestamp": "00:26:42,884", "timestamp_s": 1602.0}, {"text": "What it had to do is it would download the", "timestamp": "00:26:46,130", "timestamp_s": 1606.0}, {"text": "Onnx model to the browser", "timestamp": "00:26:50,276", "timestamp_s": 1610.0}, {"text": "locally and then use onyxjs to be", "timestamp": "00:26:54,630", "timestamp_s": 1614.0}, {"text": "able to use inferencing.", "timestamp": "00:26:58,408", "timestamp_s": 1618.0}, {"text": "So instead of sending it to cloud, the Onnx model", "timestamp": "00:27:03,270", "timestamp_s": 1623.0}, {"text": "is actually locally on the Chrome browser or", "timestamp": "00:27:07,612", "timestamp_s": 1627.0}, {"text": "on that browser itself and doing", "timestamp": "00:27:11,612", "timestamp_s": 1631.0}, {"text": "inferencing that way. It is compatible with Chrome", "timestamp": "00:27:16,476", "timestamp_s": 1636.0}, {"text": "Edge, Firefox, Opera. If you want", "timestamp": "00:27:20,310", "timestamp_s": 1640.0}, {"text": "an electron app, you can also integrate it with your node application.", "timestamp": "00:27:23,568", "timestamp_s": 1643.0}, {"text": "It\u0027s not just desktop, also mobile,", "timestamp": "00:27:28,110", "timestamp_s": 1648.0}, {"text": "Chrome Edge Firefox you can use too.", "timestamp": "00:27:33,010", "timestamp_s": 1653.0}, {"text": "All right, I\u0027ll do a little bit of demo. If you\u0027re interested in", "timestamp": "00:27:37,250", "timestamp_s": 1657.0}, {"text": "getting what I\u0027m using to demo, here is", "timestamp": "00:27:41,570", "timestamp_s": 1661.0}, {"text": "the link and I will show that later. Again,", "timestamp": "00:27:44,968", "timestamp_s": 1664.0}, {"text": "let me pull this application", "timestamp": "00:27:49,110", "timestamp_s": 1669.0}, {"text": "for you back there.", "timestamp": "00:27:54,470", "timestamp_s": 1674.0}, {"text": "Okay. So if you go to that link, it will get you this", "timestamp": "00:27:59,050", "timestamp_s": 1679.0}, {"text": "application or this website.", "timestamp": "00:28:04,716", "timestamp_s": 1684.0}, {"text": "If you want to try out our demo today,", "timestamp": "00:28:08,590", "timestamp_s": 1688.0}, {"text": "you click this out to try it out.", "timestamp": "00:28:12,736", "timestamp_s": 1692.0}, {"text": "And what it\u0027ll do is it would pull up the", "timestamp": "00:28:16,910", "timestamp_s": 1696.0}, {"text": "docker file and create an instance of", "timestamp": "00:28:22,210", "timestamp_s": 1702.0}, {"text": "a Jupyter notebook using binder.", "timestamp": "00:28:28,788", "timestamp_s": 1708.0}, {"text": "This is what it looks like.", "timestamp": "00:28:32,790", "timestamp_s": 1712.0}, {"text": "So now that the kernel is ready, this is a c sharp application.", "timestamp": "00:28:37,990", "timestamp_s": 1717.0}, {"text": "So what I have here is running Jupyter notebook using.", "timestamp": "00:28:41,528", "timestamp_s": 1721.0}, {"text": "Net interactive so I can have a c sharp application.", "timestamp": "00:28:46,188", "timestamp_s": 1726.0}, {"text": "And what I want to demo here today is I wanted", "timestamp": "00:28:50,172", "timestamp_s": 1730.0}, {"text": "to convert a", "timestamp": "00:28:53,692", "timestamp_s": 1733.0}, {"text": "model trained in ML. Net into", "timestamp": "00:28:58,048", "timestamp_s": 1738.0}, {"text": "Onyx. So this is how I would get", "timestamp": "00:29:01,824", "timestamp_s": 1741.0}, {"text": "some nuget packages and download", "timestamp": "00:29:05,824", "timestamp_s": 1745.0}, {"text": "them. While it\u0027s downloading,", "timestamp": "00:29:09,606", "timestamp_s": 1749.0}, {"text": "let me kind of talk a little bit about the code.", "timestamp": "00:29:12,698", "timestamp_s": 1752.0}, {"text": "So this one right here is system", "timestamp": "00:29:16,930", "timestamp_s": 1756.0}, {"text": "IO. I\u0027m using system IO,", "timestamp": "00:29:21,492", "timestamp_s": 1761.0}, {"text": "Microsoft data analysis Xplot", "timestamp": "00:29:24,618", "timestamp_s": 1764.0}, {"text": "plotly. And this one right here allows", "timestamp": "00:29:28,362", "timestamp_s": 1768.0}, {"text": "me to be able to format it properly, to display it", "timestamp": "00:29:32,638", "timestamp_s": 1772.0}, {"text": "properly on this Jupiter notebook.", "timestamp": "00:29:36,232", "timestamp_s": 1776.0}, {"text": "So it\u0027s just a library. Okay,", "timestamp": "00:29:39,970", "timestamp_s": 1779.0}, {"text": "let\u0027s wait until that one\u0027s done. So this", "timestamp": "00:29:43,260", "timestamp_s": 1783.0}, {"text": "one right here, I have a CSV file, salary CSV.", "timestamp": "00:29:46,892", "timestamp_s": 1786.0}, {"text": "Let me try to open that for you. So this is what", "timestamp": "00:29:52,102", "timestamp_s": 1792.0}, {"text": "it looks like. I have two columns on this csv file,", "timestamp": "00:29:55,728", "timestamp_s": 1795.0}, {"text": "years of experience and salary. I want the", "timestamp": "00:29:59,126", "timestamp_s": 1799.0}, {"text": "simplest example. I mean, this is not the best example if", "timestamp": "00:30:02,308", "timestamp_s": 1802.0}, {"text": "you\u0027re going to create a machine learning application. But I want to", "timestamp": "00:30:06,164", "timestamp_s": 1806.0}, {"text": "one input and one output. Input is your", "timestamp": "00:30:09,970", "timestamp_s": 1809.0}, {"text": "years experience. Output is salary.", "timestamp": "00:30:13,512", "timestamp_s": 1813.0}, {"text": "So we want to create a machine", "timestamp": "00:30:16,942", "timestamp_s": 1816.0}, {"text": "learning model that when you", "timestamp": "00:30:20,862", "timestamp_s": 1820.0}, {"text": "create years of experience, your input is years of experience.", "timestamp": "00:30:24,568", "timestamp_s": 1824.0}, {"text": "It would kind of guess how much is the salary based from that experience.", "timestamp": "00:30:28,044", "timestamp_s": 1828.0}, {"text": "It\u0027s just a contrived example.", "timestamp": "00:30:32,012", "timestamp_s": 1832.0}, {"text": "Okay, let\u0027s go back here.", "timestamp": "00:30:35,450", "timestamp_s": 1835.0}, {"text": "Now that that one is done, it was able to download all my nuget", "timestamp": "00:30:38,908", "timestamp_s": 1838.0}, {"text": "packages. Now I\u0027m using to run this system.", "timestamp": "00:30:42,838", "timestamp_s": 1842.0}, {"text": "I\u0027m going to run this to your application right here so that", "timestamp": "00:30:46,830", "timestamp_s": 1846.0}, {"text": "I can load the csv file using data frame.", "timestamp": "00:30:50,228", "timestamp_s": 1850.0}, {"text": "And based on that, this is what my data looks like,", "timestamp": "00:30:54,850", "timestamp_s": 1854.0}, {"text": "right? Notice that as", "timestamp": "00:30:58,916", "timestamp_s": 1858.0}, {"text": "the years increases the salary.", "timestamp": "00:31:02,292", "timestamp_s": 1862.0}, {"text": "So it\u0027s just simple example and", "timestamp": "00:31:06,710", "timestamp_s": 1866.0}, {"text": "looking at this description, then it gives me", "timestamp": "00:31:10,856", "timestamp_s": 1870.0}, {"text": "what\u0027s the min, the max. Right now I only have", "timestamp": "00:31:14,408", "timestamp_s": 1874.0}, {"text": "30 items on my list. And so at the", "timestamp": "00:31:18,410", "timestamp_s": 1878.0}, {"text": "end of the day, what this one is trying to do using ML net,", "timestamp": "00:31:21,724", "timestamp_s": 1881.0}, {"text": "I want to create a pipeline to be", "timestamp": "00:31:25,468", "timestamp_s": 1885.0}, {"text": "able to train a model.", "timestamp": "00:31:28,608", "timestamp_s": 1888.0}, {"text": "Whereas in order to train, there\u0027s two things you have to", "timestamp": "00:31:31,808", "timestamp_s": 1891.0}, {"text": "do. You have to use ML net and once you have that context,", "timestamp": "00:31:34,944", "timestamp_s": 1894.0}, {"text": "you create the pipeline and then you do fit", "timestamp": "00:31:39,970", "timestamp_s": 1899.0}, {"text": "and transform. There\u0027s always that pair.", "timestamp": "00:31:43,860", "timestamp_s": 1903.0}, {"text": "So once you have a transformer model,", "timestamp": "00:31:47,170", "timestamp_s": 1907.0}, {"text": "it\u0027ll create that model for", "timestamp": "00:31:50,930", "timestamp_s": 1910.0}, {"text": "you. So what I want", "timestamp": "00:31:54,648", "timestamp_s": 1914.0}, {"text": "to do now is now that I have that", "timestamp": "00:31:58,088", "timestamp_s": 1918.0}, {"text": "model, I want to convert it to", "timestamp": "00:32:01,496", "timestamp_s": 1921.0}, {"text": "Onyx. So I", "timestamp": "00:32:05,292", "timestamp_s": 1925.0}, {"text": "use context model convert", "timestamp": "00:32:09,212", "timestamp_s": 1929.0}, {"text": "to onyx. I pass in the stream", "timestamp": "00:32:12,818", "timestamp_s": 1932.0}, {"text": "and my data and", "timestamp": "00:32:17,790", "timestamp_s": 1937.0}, {"text": "what it\u0027ll do is it would create these", "timestamp": "00:32:21,216", "timestamp_s": 1941.0}, {"text": "model onyx for me.", "timestamp": "00:32:26,848", "timestamp_s": 1946.0}, {"text": "See where that one is?", "timestamp": "00:32:30,110", "timestamp_s": 1950.0}, {"text": "Model onyx. Put it in here.", "timestamp": "00:32:33,150", "timestamp_s": 1953.0}, {"text": "So let\u0027s try to open it again.", "timestamp": "00:32:40,610", "timestamp_s": 1960.0}, {"text": "There you go. See, I noticed Onyx", "timestamp": "00:32:43,650", "timestamp_s": 1963.0}, {"text": "model was generated for me.", "timestamp": "00:32:47,534", "timestamp_s": 1967.0}, {"text": "Think I can open that Onyx model?", "timestamp": "00:32:50,950", "timestamp_s": 1970.0}, {"text": "Okay, so now that I have an Onyx model,", "timestamp": "00:32:55,130", "timestamp_s": 1975.0}, {"text": "let me try to verify it and see how I can run.", "timestamp": "00:33:00,410", "timestamp_s": 1980.0}, {"text": "I\u0027m going to open another project. This time I", "timestamp": "00:33:04,730", "timestamp_s": 1984.0}, {"text": "have this Onyx inference Python notebook.", "timestamp": "00:33:08,592", "timestamp_s": 1988.0}, {"text": "This is not a c sharp application,", "timestamp": "00:33:13,950", "timestamp_s": 1993.0}, {"text": "so I want to change my kernel.", "timestamp": "00:33:18,910", "timestamp_s": 1998.0}, {"text": "Let\u0027s change this kernel into a python.", "timestamp": "00:33:23,570", "timestamp_s": 2003.0}, {"text": "So this time I want to use Onyx runtime in Python", "timestamp": "00:33:29,250", "timestamp_s": 2009.0}, {"text": "to do the inferencing on that model onyx", "timestamp": "00:33:34,230", "timestamp_s": 2014.0}, {"text": "file. So I do pip install onyx", "timestamp": "00:33:38,270", "timestamp_s": 2018.0}, {"text": "runtime. And what I\u0027ll do is it would download all the necessary", "timestamp": "00:33:42,542", "timestamp_s": 2022.0}, {"text": "requirements to install to get", "timestamp": "00:33:46,610", "timestamp_s": 2026.0}, {"text": "Onyx runtime library. Of course,", "timestamp": "00:33:50,028", "timestamp_s": 2030.0}, {"text": "here I\u0027m just importing them and I create", "timestamp": "00:33:53,692", "timestamp_s": 2033.0}, {"text": "this inference session.", "timestamp": "00:33:57,532", "timestamp_s": 2037.0}, {"text": "So notice that this model Onyx,", "timestamp": "00:34:00,270", "timestamp_s": 2040.0}, {"text": "if you go to netron app, it would display something", "timestamp": "00:34:04,182", "timestamp_s": 2044.0}, {"text": "like this where you can view the", "timestamp": "00:34:07,952", "timestamp_s": 2047.0}, {"text": "contents of your onnx model. And notice", "timestamp": "00:34:11,312", "timestamp_s": 2051.0}, {"text": "that it gives me the input and then the output.", "timestamp": "00:34:14,842", "timestamp_s": 2054.0}, {"text": "This input gives me the years of experience and", "timestamp": "00:34:18,730", "timestamp_s": 2058.0}, {"text": "salary. The output is like this.", "timestamp": "00:34:21,972", "timestamp_s": 2061.0}, {"text": "So whatever we\u0027re interested in is input. In this", "timestamp": "00:34:25,800", "timestamp_s": 2065.0}, {"text": "case, it\u0027s only years of experience salary.", "timestamp": "00:34:29,112", "timestamp_s": 2069.0}, {"text": "That\u0027s the one. We\u0027re trying to guess this point when you\u0027re doing inferencing.", "timestamp": "00:34:32,254", "timestamp_s": 2072.0}, {"text": "So it would be ignored, but it would use all", "timestamp": "00:34:36,306", "timestamp_s": 2076.0}, {"text": "your inputs. So even if you place a", "timestamp": "00:34:40,268", "timestamp_s": 2080.0}, {"text": "number here, it would be ignored, it won\u0027t", "timestamp": "00:34:43,644", "timestamp_s": 2083.0}, {"text": "be used. Notice how that one is not connected.", "timestamp": "00:34:47,570", "timestamp_s": 2087.0}, {"text": "So it\u0027s only using years experience. He\u0027s using feature vectorizer", "timestamp": "00:34:51,590", "timestamp_s": 2091.0}, {"text": "to be able to create this linear regressor", "timestamp": "00:34:56,134", "timestamp_s": 2096.0}, {"text": "to get the output. Of course,", "timestamp": "00:35:01,490", "timestamp_s": 2101.0}, {"text": "here, all these are not going to be used anyway.", "timestamp": "00:35:04,756", "timestamp_s": 2104.0}, {"text": "It\u0027s just going to be stub. What we\u0027re interested is the output", "timestamp": "00:35:07,876", "timestamp_s": 2107.0}, {"text": "right here. Okay,", "timestamp": "00:35:12,710", "timestamp_s": 2112.0}, {"text": "so this one, what I wanted", "timestamp": "00:35:15,750", "timestamp_s": 2115.0}, {"text": "to do is to get the name, the shape", "timestamp": "00:35:19,896", "timestamp_s": 2119.0}, {"text": "and the type of years experience,", "timestamp": "00:35:23,822", "timestamp_s": 2123.0}, {"text": "input, years, shape and type. This one is", "timestamp": "00:35:28,810", "timestamp_s": 2128.0}, {"text": "for another one for the salary.", "timestamp": "00:35:32,396", "timestamp_s": 2132.0}, {"text": "Years salary shape and type", "timestamp": "00:35:36,490", "timestamp_s": 2136.0}, {"text": "kind of gives me the descriptor and of course the", "timestamp": "00:35:40,528", "timestamp_s": 2140.0}, {"text": "output gives me the shape and type.", "timestamp": "00:35:44,032", "timestamp_s": 2144.0}, {"text": "In this case, how did I get four?", "timestamp": "00:35:48,750", "timestamp_s": 2148.0}, {"text": "It\u0027s the fourth of the output.", "timestamp": "00:35:52,770", "timestamp_s": 2152.0}, {"text": "So 01234.", "timestamp": "00:35:56,130", "timestamp_s": 2156.0}, {"text": "Right. So that\u0027s the fourth output.", "timestamp": "00:35:59,332", "timestamp_s": 2159.0}, {"text": "Let\u0027s run this one too. So now that I have", "timestamp": "00:36:03,190", "timestamp_s": 2163.0}, {"text": "that I can pass in that data,", "timestamp": "00:36:06,872", "timestamp_s": 2166.0}, {"text": "in this case pass in input experience,", "timestamp": "00:36:11,670", "timestamp_s": 2171.0}, {"text": "input salary, and it specify the years because", "timestamp": "00:36:15,240", "timestamp_s": 2175.0}, {"text": "I know the type and I need to", "timestamp": "00:36:19,196", "timestamp_s": 2179.0}, {"text": "place them into these array.", "timestamp": "00:36:23,290", "timestamp_s": 2183.0}, {"text": "So I got the years salary.", "timestamp": "00:36:28,750", "timestamp_s": 2188.0}, {"text": "Notice how I put zero because it\u0027s going to be ignored anyway. So let\u0027s say", "timestamp": "00:36:32,430", "timestamp_s": 2192.0}, {"text": "I change this to ten and", "timestamp": "00:36:36,128", "timestamp_s": 2196.0}, {"text": "the output would be identified", "timestamp": "00:36:41,490", "timestamp_s": 2201.0}, {"text": "here. And notice that if", "timestamp": "00:36:44,810", "timestamp_s": 2204.0}, {"text": "I have ten, that would be the value of", "timestamp": "00:36:48,068", "timestamp_s": 2208.0}, {"text": "the result. And now I can grab that", "timestamp": "00:36:54,870", "timestamp_s": 2214.0}, {"text": "one and that would be my output.", "timestamp": "00:36:58,152", "timestamp_s": 2218.0}, {"text": "So if I change it again to say three", "timestamp": "00:37:03,190", "timestamp_s": 2223.0}, {"text": "years, three and a half years, see what", "timestamp": "00:37:08,156", "timestamp_s": 2228.0}, {"text": "happens, and then I\u0027ll have a different output.", "timestamp": "00:37:11,532", "timestamp_s": 2231.0}, {"text": "Okay, so what happened so far?", "timestamp": "00:37:16,250", "timestamp_s": 2236.0}, {"text": "What I did was to train", "timestamp": "00:37:19,470", "timestamp_s": 2239.0}, {"text": "a model, export it to", "timestamp": "00:37:23,280", "timestamp_s": 2243.0}, {"text": "an Onyx file using ML net in", "timestamp": "00:37:27,632", "timestamp_s": 2247.0}, {"text": "c sharp. And based from that Onyx model,", "timestamp": "00:37:32,932", "timestamp_s": 2252.0}, {"text": "I use Onyx runtime to", "timestamp": "00:37:37,570", "timestamp_s": 2257.0}, {"text": "use it in my python application and", "timestamp": "00:37:41,890", "timestamp_s": 2261.0}, {"text": "do inferencing that way.", "timestamp": "00:37:47,430", "timestamp_s": 2267.0}, {"text": "This is how it feels like after learning all these things.", "timestamp": "00:37:53,510", "timestamp_s": 2273.0}, {"text": "Now it kind of connects all the different,", "timestamp": "00:37:57,450", "timestamp_s": 2277.0}, {"text": "how I can just easily", "timestamp": "00:38:02,570", "timestamp_s": 2282.0}, {"text": "use an existing Onnx is", "timestamp": "00:38:06,626", "timestamp_s": 2286.0}, {"text": "a way for us to be able lead software engineer to", "timestamp": "00:38:10,688", "timestamp_s": 2290.0}, {"text": "be able to talk to data scientists and", "timestamp": "00:38:14,064", "timestamp_s": 2294.0}, {"text": "also data scientists to talk lead lead software", "timestamp": "00:38:17,408", "timestamp_s": 2297.0}, {"text": "engineer that we can use these secret", "timestamp": "00:38:21,366", "timestamp_s": 2301.0}, {"text": "recipes, right, use these machine learning models and", "timestamp": "00:38:25,126", "timestamp_s": 2305.0}, {"text": "integrate it to our application. At the end of the day,", "timestamp": "00:38:28,852", "timestamp_s": 2308.0}, {"text": "all our best effort and", "timestamp": "00:38:34,470", "timestamp_s": 2314.0}, {"text": "all our programs. Actually,", "timestamp": "00:38:38,630", "timestamp_s": 2318.0}, {"text": "as long as we can integrate it to our application,", "timestamp": "00:38:43,270", "timestamp_s": 2323.0}, {"text": "not just existing application or any greenfield application,", "timestamp": "00:38:46,876", "timestamp_s": 2326.0}, {"text": "we can start incorporating these machine learning models", "timestamp": "00:38:52,170", "timestamp_s": 2332.0}, {"text": "through Onnx. So we did talk about as a recap,", "timestamp": "00:38:57,470", "timestamp_s": 2337.0}, {"text": "what is onyx? It\u0027s an open standard.", "timestamp": "00:39:01,158", "timestamp_s": 2341.0}, {"text": "Use the right tool for the right job and how", "timestamp": "00:39:05,310", "timestamp_s": 2345.0}, {"text": "you can efficiently run it on a target platform.", "timestamp": "00:39:08,656", "timestamp_s": 2348.0}, {"text": "It separates out how you train it and how you", "timestamp": "00:39:12,548", "timestamp_s": 2352.0}, {"text": "would run and do inferencing on that", "timestamp": "00:39:16,068", "timestamp_s": 2356.0}, {"text": "model. How you would create Onnx model.", "timestamp": "00:39:20,308", "timestamp_s": 2360.0}, {"text": "I did show you how to download it from the Onnx model", "timestamp": "00:39:23,656", "timestamp_s": 2363.0}, {"text": "zoo. You can create it and convert using", "timestamp": "00:39:27,176", "timestamp_s": 2367.0}, {"text": "some of the Onyx convert.", "timestamp": "00:39:31,910", "timestamp_s": 2371.0}, {"text": "There\u0027s different ways how you can create can onnx model. You can", "timestamp": "00:39:37,370", "timestamp_s": 2377.0}, {"text": "also deploy Onnx model.", "timestamp": "00:39:41,292", "timestamp_s": 2381.0}, {"text": "You can deploy it through Windows. NET JavaScript", "timestamp": "00:39:45,020", "timestamp_s": 2385.0}, {"text": "using Onyx. JS did", "timestamp": "00:39:49,430", "timestamp_s": 2389.0}, {"text": "a demo how you would use Onyx Runtime in Python to", "timestamp": "00:39:53,696", "timestamp_s": 2393.0}, {"text": "it in high performance. All right,", "timestamp": "00:40:00,110", "timestamp_s": 2400.0}, {"text": "if you want to learn more about me, my name is Ron Dagdag.", "timestamp": "00:40:05,250", "timestamp_s": 2405.0}, {"text": "I\u0027m a lead software engineer at Spacey. I\u0027m a 50 year Microsoft", "timestamp": "00:40:08,170", "timestamp_s": 2408.0}, {"text": "MVP. The best way to contact me is", "timestamp": "00:40:12,154", "timestamp_s": 2412.0}, {"text": "through LinkedIn or Twitter at Ron Dagdag", "timestamp": "00:40:15,348", "timestamp_s": 2415.0}, {"text": "I appreciate you geeking out with me about Onnx,", "timestamp": "00:40:19,530", "timestamp_s": 2419.0}, {"text": "Onnx Runtime, about Jupyter notebooks,", "timestamp": "00:40:23,914", "timestamp_s": 2423.0}, {"text": "about bakeries, bakers and breads.", "timestamp": "00:40:29,210", "timestamp_s": 2429.0}, {"text": "Thank you very much. Have a good day.", "timestamp": "00:40:33,850", "timestamp_s": 2433.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'vGhBnFUzem8',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Leverage Power of Machine Learning with ONNX
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Have you ever wanted to make your apps &ldquo;smarter&rdquo;? This session will cover what every ML/AI developer should know about Open Neural Network Exchange (ONNX) . Why it&rsquo;s important and how it can reduce friction in incorporating machine learning models to your apps. We will show how to train models using the framework of your choice, save or convert models into ONNX, and deploy to cloud and edge using a high-performance runtime.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Onnx is short for open neural network exchange. It is an open format for machine learning models. Best place to learn more about Onnx about Onyx is through Onyx AI.

              </li>
              
              <li>
                Onnx is kind of like PDF, right? You create your Word document in Microsoft Word. Now you can display it on different types of devices using acrobat or PDF viewer. How to create Onyx models, step one. And then we'll talk more about step two.

              </li>
              
              <li>
                Onnx model zoo allows you to export or using Onyx model zoo. There's existing models out there that you can just download off the Internet and start using incorporating to your application. Once you train it, you can have a typical end to end machine learning process.

              </li>
              
              <li>
                In order to create a successful business or successful bakery, you need both. Where we create these machine learning models, it is important where we're going to deploy them. Edge meaning how close it is to your customers or your users.

              </li>
              
              <li>
                There is Onyx runtime where you can run it's a high performance inference engine for your onnx models. It's open sourced by Microsoft under MIT license. It has extensible architecture that allows to have different hardware accelerators. It gives you that flexibility where you want to deploy and run this inferencing.

              </li>
              
              <li>
                Using ML Net, I wanted to convert a model trained in ML. Net into Onyx. I have two columns on this csv file, years of experience and salary. It would kind of guess how much is the salary based from that experience. Here's a simple example to show you how to do it.

              </li>
              
              <li>
                As long as we can integrate it to our application, not just existing application or any greenfield application, we can start incorporating these machine learning models through Onnx. Use the right tool for the right job and how you can efficiently run it on a target platform.

              </li>
              
              <li>
                Ron Dagdag is a lead software engineer at Spacey. He is a 50 year Microsoft MVP. The best way to contact him is through LinkedIn or Twitter. Have a good day.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/vGhBnFUzem8.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:22,250'); seek(22.0)">
              Good morning, good afternoon, good evening,
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:25,730'); seek(25.0)">
              wherever you are at our virtual world.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:29,420'); seek(29.0)">
              My name is Ron Dagdag. I'm a
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,684'); seek(32.0)">
              lead software engineer at Spacey. Today I will
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:36,092'); seek(36.0)">
              be talking about leverage the power of machine learning with
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,772'); seek(39.0)">
              Onnx. For all you Pokemon
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:43,090'); seek(43.0)">
              fans out there, I will not be talking about the
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:46,348'); seek(46.0)">
              Pokemon onyx, nor I will be talking about the
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:50,252'); seek(50.0)">
              mineral onyx. I will be talking about
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:53,508'); seek(53.0)">
              Onyx on NX open neural network
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:57,946'); seek(57.0)">
              exchange. All right, let's go back to basics.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:01,410'); seek(61.0)">
              What is programming? Programming,
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:04,510'); seek(64.0)">
              traditionally you have an input.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:07,374'); seek(67.0)">
              You write an algorithm, you combine them together,
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:11,430'); seek(71.0)">
              run it, and it will spit out answers for you.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:14,488'); seek(74.0)">
              In machine learning world, you have an input,
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:18,146'); seek(78.0)">
              you have examples of what the answers would be,
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:22,284'); seek(82.0)">
              and the computer's goal is to
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:25,852'); seek(85.0)">
              provide an algorithm for you. So as a primer,
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:29,686'); seek(89.0)">
              you have your programming, traditional programming at the right,
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:33,230'); seek(93.0)">
              machine learning on the left still
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:37,872'); seek(97.0)">
              have your input, answers, and your algorithm machine
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:41,098'); seek(101.0)">
              learning world, we call
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:44,690'); seek(104.0)">
              the input and the answers as your training data.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:49,090'); seek(109.0)">
              You have to use a training framework in order
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:52,840'); seek(112.0)">
              to get a machine learning model.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:56,392'); seek(116.0)">
              And based from that model you would
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:59,992'); seek(119.0)">
              substitute or use that into your
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:03,400'); seek(123.0)">
              application, and that's what we call inferencing.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:08,010'); seek(128.0)">
              And you would use a runtime to
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:12,492'); seek(132.0)">
              be able to process your input and your model, and it would give
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:15,772'); seek(135.0)">
              you the answers. And now that you have more
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:19,392'); seek(139.0)">
              answers, it could be a good feedback loop to improve
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:22,822'); seek(142.0)">
              your training data.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:25,630'); seek(145.0)">
              So typically data scientists would
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:30,452'); seek(150.0)">
              program, or would create a program
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:34,196'); seek(154.0)">
              in Pytorch. They would run it locally on their machine
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:38,930'); seek(158.0)">
              using the cpu. And then of course,
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:42,770'); seek(162.0)">
              if you are a JavaScript developer and you've
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:47,242'); seek(167.0)">
              seen all these different Javascript frameworks
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:50,922'); seek(170.0)">
              and all these different ways, and how you
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:55,028'); seek(175.0)">
              can create applications or
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:58,572'); seek(178.0)">
              web applications the same way as in machine
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:03,122'); seek(183.0)">
              learning world. There's all these different machine
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:06,642'); seek(186.0)">
              learning frameworks, training frameworks that you can use,
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:10,332'); seek(190.0)">
              and the ecosystem is growing.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:14,278'); seek(194.0)">
              And of course we're not just limited in deploying it locally
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:18,166'); seek(198.0)">
              on our devices, not just on
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:22,052'); seek(202.0)">
              our laptops. Also, you have to sometimes use a phone or
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:26,468'); seek(206.0)">
              deploy it in the cloud. Sometimes you want better
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:30,436'); seek(210.0)">
              performance. You run it through a GPU or
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:34,950'); seek(214.0)">
              FPGA or ASIC, or you
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:39,928'); seek(219.0)">
              can also run it, you might wanted to also run it on
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:43,272'); seek(223.0)">
              a microcontroller.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:47,930'); seek(227.0)">
              And that's when Onnx comes into
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:51,148'); seek(231.0)">
              the picture. Onyx is the bridge between how
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:54,972'); seek(234.0)">
              you get trained and where to deploy.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:58,990'); seek(238.0)">
              Onnx is short for open
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:02,672'); seek(242.0)">
              neural network exchange. It is an open format
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:06,582'); seek(246.0)">
              for machine learning models. Notice that it's not just limited
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:10,182'); seek(250.0)">
              to neural networks, it's also capable
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:13,610'); seek(253.0)">
              of your traditional machine learning models too. It is on
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:17,620'); seek(257.0)">
              GitHub, GitHub.com onyx
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:21,258'); seek(261.0)">
              and best place to learn more about Onnx about
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:25,412'); seek(265.0)">
              Onnx is through Onyx AI. And when you go
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:29,128'); seek(269.0)">
              to this website, you'll notice that every time I would go
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:32,648'); seek(272.0)">
              in there's new partners coming in and be
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:36,108'); seek(276.0)">
              able to improve that ecosystem.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:39,770'); seek(279.0)">
              We just started between partnership between Microsoft and
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:43,036'); seek(283.0)">
              Facebook and I've noticed that more and
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:46,092'); seek(286.0)">
              more there's partners
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:51,550'); seek(291.0)">
              using this application on GitHub
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:56,190'); seek(296.0)">
              about 10.9 what, 11,000 GitHub stars
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:00,670'); seek(300.0)">
              pull request about almost 2000 pull request about
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:04,452'); seek(304.0)">
              200 contributors about 2000 GitHub
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:08,522'); seek(308.0)">
              forks and there's also model zoo. Onnx is
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:14,712'); seek(314.0)">
              available out there. It is a graduate project of
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:18,664'); seek(318.0)">
              Linux Foundation AI.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:22,630'); seek(322.0)">
              And so it's becoming more,
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:28,810'); seek(328.0)">
              there's a lot of traction going on for these Onyx
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:33,746'); seek(333.0)">
              application. When would you use Onnx?
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:38,910'); seek(338.0)">
              Is when you have something
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:42,272'); seek(342.0)">
              that's trained in Python and you want to deploy it to a
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:46,144'); seek(346.0)">
              C sharp application, or maybe you want to incorporate
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:49,558'); seek(349.0)">
              it to your Java application or JavaScript application when
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:54,308'); seek(354.0)">
              you have high inferency latency
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:58,938'); seek(358.0)">
              that you want for production use. So, meaning if it's
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:02,634'); seek(362.0)">
              too slow to run it or if you want
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:06,472'); seek(366.0)">
              performance so that you can use it for production.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:09,886'); seek(369.0)">
              Because let's say if you have it in some training
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:15,930'); seek(375.0)">
              platform or training framework and it's
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:19,858'); seek(379.0)">
              not good enough and you want to improve,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:25,370'); seek(385.0)">
              if you have high inferency, that would be a good use case for
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:28,668'); seek(388.0)">
              it. If you want to deploy it to an IoT device or
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:31,808'); seek(391.0)">
              an edge device, it might make sense to convert it
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:35,264'); seek(395.0)">
              to Onyx and be able to deploy it to those devices
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:39,446'); seek(399.0)">
              when it's trained on a different
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:43,490'); seek(403.0)">
              OS. And if you want to run that model into a different
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:46,916'); seek(406.0)">
              OS or different hardware, that is a good use case
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:50,692'); seek(410.0)">
              for it. When you want to combine
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:55,102'); seek(415.0)">
              the models, let's say you have a team of data scientists.
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:07:02,390'); seek(422.0)">
              Some of your models were created on, let's say Pytorch and some
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:07:06,408'); seek(426.0)">
              of the models were created in keras. And you want to create a
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:09,724'); seek(429.0)">
              pipeline and you want to combine these models that
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:13,868'); seek(433.0)">
              is trained from different frameworks. That is another way.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:17,630'); seek(437.0)">
              Another one is through training, takes too
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:21,392'); seek(441.0)">
              long. And that's when you start talking about transformer
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:25,462'); seek(445.0)">
              models. Let's say if you want to train it locally
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:30,030'); seek(450.0)">
              at the edge, that is one way that you can use
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:33,732'); seek(453.0)">
              Onyx too. All right, so we
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:37,188'); seek(457.0)">
              did talk about what is Onyx. One thing I
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:40,868'); seek(460.0)">
              want to point out, one good way of to describe
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:44,862'); seek(464.0)">
              Onnx, it's kind of like PDF, right?
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:48,248'); seek(468.0)">
              You create your Word document in
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:53,190'); seek(473.0)">
              Microsoft Word. Or you create your documents
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:58,410'); seek(478.0)">
              in Microsoft Word or some word processing
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:08:03,058'); seek(483.0)">
              application, you convert it to PDF.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:06,354'); seek(486.0)">
              Now you can display it on different types of devices using
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:12,190'); seek(492.0)">
              acrobat or PDF viewer.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:15,790'); seek(495.0)">
              And then we did talk about when
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:18,992'); seek(498.0)">
              to use Onnx. And then we'll talk
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:22,692'); seek(502.0)">
              more about how to create the Onyx models
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:25,978'); seek(505.0)">
              and how to deploy onnx models,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:30,050'); seek(510.0)">
              how to create Onyx models, step one. And then we'll
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:33,454'); seek(513.0)">
              talk more about step two. Step one. Let's focus on that. Have you
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:37,128'); seek(517.0)">
              ever baked a cake? And of course there's a
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:40,504'); seek(520.0)">
              lot of different ingredients, different procedures.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:45,370'); seek(525.0)">
              Of course bakers specializes on this.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:49,610'); seek(529.0)">
              My analogy in this is that bakers
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:55,050'); seek(535.0)">
              or your data scientist,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:57,870'); seek(537.0)">
              your team, they're the ones who make the
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:09:01,856'); seek(541.0)">
              secret recipe for your business. They try
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:09:05,872'); seek(545.0)">
              different tweaks and different ingredients and different procedures
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:10,506'); seek(550.0)">
              and how to create these AI
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:14,682'); seek(554.0)">
              models, which is going to be your secret recipe.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:18,850'); seek(558.0)">
              So how do you create these Onyx models? One way is to export
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:23,274'); seek(563.0)">
              or using Onyx model zoo.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:28,390'); seek(568.0)">
              Onyx model zoo. There's existing
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:32,870'); seek(572.0)">
              models out there that you can just download off the Internet and start using
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:36,684'); seek(576.0)">
              incorporating to your application. You can use Azure custom
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:40,796'); seek(580.0)">
              vision or some service that exports to
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:44,652'); seek(584.0)">
              Onyx. You can convert an existing model and
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:49,312'); seek(589.0)">
              also you can train models in azure machine
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:52,902'); seek(592.0)">
              learning or some automated machine learning. So Onnx
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:56,598'); seek(596.0)">
              model zoo allows you to be able to just,
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:10:01,490'); seek(601.0)">
              someone already pre converted all these different
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:10:05,124'); seek(605.0)">
              popular AI models out there or machine learning
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:10:09,076'); seek(609.0)">
              models out there. If you're interested in Restnet, it's already converted
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:10:13,278'); seek(613.0)">
              to Onyx for you and you can just download it.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:17,350'); seek(617.0)">
              These are some examples of the different sizes
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:21,750'); seek(621.0)">
              of that model once it's converted to onnx.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:25,770'); seek(625.0)">
              So it's not just limited in image, there's also sound.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:29,130'); seek(629.0)">
              There's different models out there
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:32,492'); seek(632.0)">
              you can just download. Another one is through custom
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:36,380'); seek(636.0)">
              vision, which allows you to do low code vision
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:41,382'); seek(641.0)">
              service where you would upload some photos,
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:45,110'); seek(645.0)">
              you tag them, start tagging them, you train
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:50,370'); seek(650.0)">
              to create a machine learning model for you
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:54,180'); seek(654.0)">
              and then you can export it to Onyx.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:57,890'); seek(657.0)">
              Another way is to convert the model
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:11:02,390'); seek(662.0)">
              from the existing training frameworks.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:11:06,190'); seek(666.0)">
              So let's say you
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:11:10,232'); seek(670.0)">
              have it in Pytorch or keras or Tensorflow or Scikitlearn.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:14,990'); seek(674.0)">
              There's a way you can convert it to an Onyx model. Of course there's three
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:18,652'); seek(678.0)">
              steps loaded in existing model into memory.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:22,410'); seek(682.0)">
              Convert to an Onyx and save that Onyx model.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:28,270'); seek(688.0)">
              Here's an example of how you would use and
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:32,352'); seek(692.0)">
              convert from Pytorch to onnx.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:38,350'); seek(698.0)">
              So you would load that model
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:43,010'); seek(703.0)">
              and provide some sample input and use this torch onnx
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:47,082'); seek(707.0)">
              to export it. Another way is know
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:50,580'); seek(710.0)">
              if you have it in keras. Same steps.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:53,726'); seek(713.0)">
              You load the Keras model, convert the Keras model into
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:57,096'); seek(717.0)">
              Onyx, and then save it as
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:12:01,032'); seek(721.0)">
              a protoblock. And there
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:12:05,608'); seek(725.0)">
              is onyxml tools that
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:12:09,228'); seek(729.0)">
              you can do to pip install. You can also
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:12:13,356'); seek(733.0)">
              convert the Tensorflow model using command line.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:17,210'); seek(737.0)">
              So where you specify, of course, your input, where's your
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:21,520'); seek(741.0)">
              saved model and then your output. A lot of good
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:24,992'); seek(744.0)">
              examples how you would do this on
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:28,608'); seek(748.0)">
              GitHub. This one is through ScikitLearn.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:32,986'); seek(752.0)">
              Notice that there's an SKL to onnx
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:37,010'); seek(757.0)">
              where you can convert scikitlearn into
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:42,276'); seek(762.0)">
              an Onyx application or to onnx
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:46,062'); seek(766.0)">
              format. I keep
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:49,128'); seek(769.0)">
              on talking about Onyx. Let me go back real quick.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:53,190'); seek(773.0)">
              There's this tool called nettron app
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:58,108'); seek(778.0)">
              that visualizes this Onyx model for you.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:13:02,730'); seek(782.0)">
              And it also helps software
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:13:06,482'); seek(786.0)">
              engineers to kind of know what's
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:13:10,582'); seek(790.0)">
              the input and output of that existing model without going
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:13:14,448'); seek(794.0)">
              back to the data scientist, going back to the original
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:18,422'); seek(798.0)">
              code where it was trained from to know how to use can Onyx
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:21,962'); seek(801.0)">
              model. It visualizes the inputs and then
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:25,412'); seek(805.0)">
              be able to kind of visualize what the graph of operations
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:29,354'); seek(809.0)">
              would look like. If you go to Netron
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:34,574'); seek(814.0)">
              app, open an Onyx file there,
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:37,576'); seek(817.0)">
              and you can visualize it. All right.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:42,950'); seek(822.0)">
              You can also use onnx as an intermediary format
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:47,710'); seek(827.0)">
              intermediate. Let's say if you
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:51,228'); seek(831.0)">
              have a Pytorch model and you want to convert it to Tensorflow, you can convert
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:55,362'); seek(835.0)">
              from Pytorch to Onyx and Onyx to Tensorflow.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:59,062'); seek(839.0)">
              That is one way. Also,
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:14:02,000'); seek(842.0)">
              there's Onyx to core ML that you can
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:14:05,408'); seek(845.0)">
              use. There's ways also you
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:14:08,928'); seek(848.0)">
              can fine tune, can onyx model create
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:14:13,028'); seek(853.0)">
              and do transfer learning on an existing onnx model.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:16,660'); seek(856.0)">
              If you're interested, of course
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:20,788'); seek(860.0)">
              you can train models in the cloud.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:24,376'); seek(864.0)">
              You have a GPU clusters.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:27,270'); seek(867.0)">
              But the important part here for me, and I wanted to talk more,
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:31,032'); seek(871.0)">
              this is your typical end to end machine learning process,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:34,360'); seek(874.0)">
              where you have your experiments and you're building your
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:38,170'); seek(878.0)">
              base from your different iDe, or you create
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:43,130'); seek(883.0)">
              your training application. Once you train it,
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:47,950'); seek(887.0)">
              you would have a machine learning model.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:52,670'); seek(892.0)">
              You register it somewhere in the cloud and
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:56,432'); seek(896.0)">
              manage these models. You can have these versionings and
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:15:00,228'); seek(900.0)">
              then based from that, kind of like when you have a
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:15:04,164'); seek(904.0)">
              docker image, you have kind of like Docker hub where you
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:15:07,908'); seek(907.0)">
              can store all these images.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:15:10,930'); seek(910.0)">
              Also as your machine learning,
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:14,692'); seek(914.0)">
              as a way you can manage your models, you can upload these
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:18,248'); seek(918.0)">
              models there and be able to version
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:21,982'); seek(921.0)">
              them and also build a pipeline to create
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:26,524'); seek(926.0)">
              and to download these and incorporate it and create the image.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:32,570'); seek(932.0)">
              So we did talk about step one,
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:35,820'); seek(935.0)">
              creating. Once we have an Onnx model,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:39,950'); seek(939.0)">
              start deploying them.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:42,430'); seek(942.0)">
              Okay, so we did talk about,
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:46,112'); seek(946.0)">
              as your data scientist, building kind of like a
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:49,792'); seek(949.0)">
              chef or a baker building your secret recipe.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:53,610'); seek(953.0)">
              Now, let me ask you one thing. What is the difference between
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:57,380'); seek(957.0)">
              a baker and starting a bakery?
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:16:01,170'); seek(961.0)">
              Main difference is they all have different skill set.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:16:05,990'); seek(965.0)">
              In order to create a successful business
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:16:09,768'); seek(969.0)">
              or successful bakery, you need both.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:12,696'); seek(972.0)">
              Need the baker and also you
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:16,108'); seek(976.0)">
              need someone that actually manages the bakery.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:19,850'); seek(979.0)">
              Software engineers are
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:23,596'); seek(983.0)">
              great at looking into how to
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:27,148'); seek(987.0)">
              start a bakery. They know where to put the cash here,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:30,604'); seek(990.0)">
              how to collect money, right. How to create
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:34,512'); seek(994.0)">
              these pipelines and how you would display or
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:37,632'); seek(997.0)">
              use the application and be able to create
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:41,748'); seek(1001.0)">
              those different areas of the business system,
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:45,650'); seek(1005.0)">
              how you would use the
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:49,572'); seek(1009.0)">
              machine learning model or how to create the whole application itself.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:53,492'); seek(1013.0)">
              What is the customer experience in all these different
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:57,352'); seek(1017.0)">
              things? So it
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:17:02,408'); seek(1022.0)">
              is important, whenever we create these machine learning
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:17:06,376'); seek(1026.0)">
              models, it is important where we're going to
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:17:09,708'); seek(1029.0)">
              deploy them. Some things to think about, right?
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:14,410'); seek(1034.0)">
              You deploy it on a VM, you might want to deploy it on
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:17,808'); seek(1037.0)">
              a Windows device or a Linux device or a Mac,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:21,910'); seek(1041.0)">
              you can deploy it on it. Edge devices or
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:26,030'); seek(1046.0)">
              phones, different ways. How you would deploy
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:30,326'); seek(1050.0)">
              and create these AI models and
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:34,628'); seek(1054.0)">
              use these AI models. Of course,
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:38,130'); seek(1058.0)">
              every time we think about deployment,
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:41,946'); seek(1061.0)">
              think about where we can deploy this. We're going to deploy this to the cloud
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:45,464'); seek(1065.0)">
              or at the edge. Edge meaning how close it is to
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:49,032'); seek(1069.0)">
              your customers or your users.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:52,790'); seek(1072.0)">
              The analogy in that is McDonald's and
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:56,252'); seek(1076.0)">
              subway. What's the difference in how they make the bread?
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:18:00,018'); seek(1080.0)">
              Right. McDonald's most likely it's
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:18:03,858'); seek(1083.0)">
              in not a warehouse, but it's outsourced.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:18:08,418'); seek(1088.0)">
              It's not at the edge, meaning it's not
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:18:13,230'); seek(1093.0)">
              at the store, just compared to a
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:16,432'); seek(1096.0)">
              subway, where you
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:20,528'); seek(1100.0)">
              bake the bread at the store. So it's
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:23,978'); seek(1103.0)">
              a different experience. Right. So what I'm trying to
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:27,428'); seek(1107.0)">
              get at is whenever we talk about deployment, where we're going to run
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:33,410'); seek(1113.0)">
              these AI models, where do we want to run them?
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:37,592'); seek(1117.0)">
              Do we send the data to the cloud and then we run the inferencing
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:41,886'); seek(1121.0)">
              at the cloud and then return the results to us,
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:45,292'); seek(1125.0)">
              or at the edge, meaning closer to the user. Maybe it's on
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:48,668'); seek(1128.0)">
              the phone, or maybe it's on the camera
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:51,906'); seek(1131.0)">
              itself, or in a gateway
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:55,570'); seek(1135.0)">
              closer to the user. So those
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:58,828'); seek(1138.0)">
              are things we have to consider when we
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:19:02,384'); seek(1142.0)">
              deploy these machine learning models,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:19:05,878'); seek(1145.0)">
              especially in the Onnx model. Of course,
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:10,030'); seek(1150.0)">
              you can also deploy them in the cloud, how you would deploy them,
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:13,444'); seek(1153.0)">
              since you already have registered in
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:17,970'); seek(1157.0)">
              your machine learning model or your Onyx models in the cloud. As you
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:21,588'); seek(1161.0)">
              build your image, you create your pipeline.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:24,494'); seek(1164.0)">
              That is one way where you
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:29,704'); seek(1169.0)">
              can deploy it through a service, an app service.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:33,080'); seek(1173.0)">
              You can deploy it and run it in a
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:36,556'); seek(1176.0)">
              docker container or in Kubernetes service.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:41,850'); seek(1181.0)">
              Speaking of docker images,
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:45,770'); seek(1185.0)">
              there are Onyx Docker images that you can start using.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:50,110'); seek(1190.0)">
              There's an Onyx base that has minimal dependency that you
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:54,208'); seek(1194.0)">
              can use it. If you want to run
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:58,190'); seek(1198.0)">
              use onyx into your application. There's Onyx ecosystem
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:20:02,922'); seek(1202.0)">
              that allows you to be able to convert without
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:06,868'); seek(1206.0)">
              an installer, right? So let's say
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:10,468'); seek(1210.0)">
              if you just want to convert an existing Onyx model,
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:14,470'); seek(1214.0)">
              an existing application or an
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:17,832'); seek(1217.0)">
              existing machine learning model, let's say it was written in Pytorch.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:21,854'); seek(1221.0)">
              You don't want to download all
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:25,868'); seek(1225.0)">
              the converters locally in your machine. You can just
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:29,356'); seek(1229.0)">
              use these docker
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:34,730'); seek(1234.0)">
              images. So whenever we
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:38,028'); seek(1238.0)">
              talk about edge, what is the edge?
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:41,718'); seek(1241.0)">
              Remember the definition is how close it is to your customers
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:45,488'); seek(1245.0)">
              or to your users. But of course, every time we
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:48,992'); seek(1248.0)">
              think about the edge, we'll talk about
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:52,372'); seek(1252.0)">
              deployment. When we deploy it to the cloud,
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:56,308'); seek(1256.0)">
              most likely it's just you're deploying to the data centers. Maybe it's thousands
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:21:00,698'); seek(1260.0)">
              of devices. If we talk about we're going to deploy it
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:21:04,648'); seek(1264.0)">
              in 5g infrastructure where
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:09,432'); seek(1269.0)">
              we deploy it to the fog, which is maybe
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:13,976'); seek(1273.0)">
              just millions of devices, millions of
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:17,884'); seek(1277.0)">
              models where you're going to deploy these. And of course, when you talk about edge
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:22,330'); seek(1282.0)">
              might be billions of devices depending on the
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:25,932'); seek(1285.0)">
              need, because each
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:30,432'); seek(1290.0)">
              device may have those different deployment structure.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:35,710'); seek(1295.0)">
              So why would you want to deploy your machine learning
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:39,376'); seek(1299.0)">
              model on the edge or run it on the
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:42,708'); seek(1302.0)">
              edge? One is low latency.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:45,706'); seek(1305.0)">
              Think about, let's say you're collecting videos, right?
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:48,852'); seek(1308.0)">
              You're doing inferencing based from
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:52,452'); seek(1312.0)">
              video or sound. You want it faster,
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:57,630'); seek(1317.0)">
              so it makes sense to run it locally on
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:22:01,912'); seek(1321.0)">
              that device itself. So it's load in.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:22:05,192'); seek(1325.0)">
              See, think about it. If you have to ship that to the cloud,
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:22:08,972'); seek(1328.0)">
              you have to ship each images, each frame.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:22:12,330'); seek(1332.0)">
              That might cost you money and of course produce scalability.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:22:16,594'); seek(1336.0)">
              So it might make sense to run it at the edge
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:21,070'); seek(1341.0)">
              to provide scalability. Another one is flexibility.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:25,230'); seek(1345.0)">
              So it might make sense to run it locally
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:28,822'); seek(1348.0)">
              so you don't have the need for Internet connection.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:32,690'); seek(1352.0)">
              Also rules, privacy rules,
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:37,170'); seek(1357.0)">
              want to send any
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:42,690'); seek(1362.0)">
              personally identify Pii information or
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:48,530'); seek(1368.0)">
              might make sense to local laws that
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:52,404'); seek(1372.0)">
              it's limited to certain geographical
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:57,826'); seek(1377.0)">
              areas. So it might make sense to. It gives
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:23:01,068'); seek(1381.0)">
              you that flexibility where you want to deploy
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:23:04,970'); seek(1384.0)">
              and where you want to run this inferencing.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:23:09,470'); seek(1389.0)">
              There is Onyx runtime where you can run it's a
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:23:13,168'); seek(1393.0)">
              high performance inference engine for
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:23:16,656'); seek(1396.0)">
              your onnx models. It is actually open
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:20,212'); seek(1400.0)">
              sourced by Microsoft under MIT license. So it's
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:23:24,298'); seek(1404.0)">
              not just limited to neural networks.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:27,946'); seek(1407.0)">
              Also for traditional machine learning spec it has
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:32,116'); seek(1412.0)">
              extensible architecture that allows to
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:35,432'); seek(1415.0)">
              have different hardware accelerators.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:38,790'); seek(1418.0)">
              It's part of Windows ten as
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:42,280'); seek(1422.0)">
              Winml. And if you want to learn more about Onyx Runtime,
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:46,222'); seek(1426.0)">
              there's Onnx runtime AI website.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:52,090'); seek(1432.0)">
              The good thing about this is there's
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:56,738'); seek(1436.0)">
              this part where I think it's pretty neat or
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:24:00,016'); seek(1440.0)">
              let's say if you want to use different platforms,
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:24:04,038'); seek(1444.0)">
              let's say I'm going to create a Linux application and I
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:24:07,728'); seek(1447.0)">
              want to create a C sharp using C
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:24:11,572'); seek(1451.0)">
              sharp API and this architecture X
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:24:14,772'); seek(1454.0)">
              86. If you want to run ARM 64, you can
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:24:18,052'); seek(1458.0)">
              select them and then you have these different architecture,
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:21,730'); seek(1461.0)">
              different hardware accelerators. So if you want to use the gpu,
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:24:25,502'); seek(1465.0)">
              select CUDA, or you can just use default cpu and it will
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:29,128'); seek(1469.0)">
              give you instructions how you can incorporate it to
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:32,824'); seek(1472.0)">
              your application.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:36,150'); seek(1476.0)">
              Notice that there's different hardware accelerators. So like
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:39,932'); seek(1479.0)">
              for example if you wanted to run Openvino, you have to convert
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:43,218'); seek(1483.0)">
              it. You don't have to convert let's say a Pytorch
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:46,402'); seek(1486.0)">
              model to something that's compatible with Openvino.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:50,694'); seek(1490.0)">
              You can go Pytorch to Onyx and
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:54,448'); seek(1494.0)">
              then use Onyx runtime with the Openvino
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:59,318'); seek(1499.0)">
              hardware accelerator.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:25:02,610'); seek(1502.0)">
              Like I said, onnx runtime ships with Windows AI
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:25:06,442'); seek(1506.0)">
              platform. So if you're
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:25:10,530'); seek(1510.0)">
              as part of the Winml API,
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:25:13,810'); seek(1513.0)">
              which is a practical, a simple model based API
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:25:17,806'); seek(1517.0)">
              for inferencing in Windows. So let's say if you have can existing
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:25:22,286'); seek(1522.0)">
              forms application and you want to add machine
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:25:26,142'); seek(1526.0)">
              learning model, or you want to add
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:29,864'); seek(1529.0)">
              machine learning to a windforms
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:33,294'); seek(1533.0)">
              application, this allows you to be able to do that.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:37,870'); seek(1537.0)">
              There's also direct ML API,
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:41,790'); seek(1541.0)">
              so that if you're creating a game, there is a way
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:45,696'); seek(1545.0)">
              to be able to use direct ML that runs on
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:49,024'); seek(1549.0)">
              top of DirectX twelve which has a real
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:52,736'); seek(1552.0)">
              time high control machine learning operator API.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:58,050'); seek(1558.0)">
              And of course you have these robust driver models that
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:26:01,828'); seek(1561.0)">
              it automatically knows if you have a gpu,
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:26:05,130'); seek(1565.0)">
              a VPU or XPU fully defined,
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:26:08,974'); seek(1568.0)">
              but it automatically switches. If it can
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:26:12,488'); seek(1572.0)">
              run a cpu it would use it. If it can run in
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:26:15,628'); seek(1575.0)">
              any one of these, then you'll be able to use that. That's how
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:26:19,548'); seek(1579.0)">
              it's able to access those
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:26:22,716'); seek(1582.0)">
              drivers. There is also Onnx JS
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:26:27,130'); seek(1587.0)">
              which is a JavaScript library to run Onnx models in the
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:26:31,008'); seek(1591.0)">
              browser or even in node it's using WebGL
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:35,558'); seek(1595.0)">
              and webassembly and it could automatically
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:39,526'); seek(1599.0)">
              use CPU or GPU. So think about
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:42,884'); seek(1602.0)">
              let's say you have it in your browser.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:46,130'); seek(1606.0)">
              What it had to do is it would download the
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:50,276'); seek(1610.0)">
              Onnx model to the browser
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:54,630'); seek(1614.0)">
              locally and then use onyxjs to be
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:58,408'); seek(1618.0)">
              able to use inferencing.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:27:03,270'); seek(1623.0)">
              So instead of sending it to cloud, the Onnx model
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:27:07,612'); seek(1627.0)">
              is actually locally on the Chrome browser or
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:27:11,612'); seek(1631.0)">
              on that browser itself and doing
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:27:16,476'); seek(1636.0)">
              inferencing that way. It is compatible with Chrome
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:27:20,310'); seek(1640.0)">
              Edge, Firefox, Opera. If you want
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:27:23,568'); seek(1643.0)">
              an electron app, you can also integrate it with your node application.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:27:28,110'); seek(1648.0)">
              It's not just desktop, also mobile,
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:33,010'); seek(1653.0)">
              Chrome Edge Firefox you can use too.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:37,250'); seek(1657.0)">
              All right, I'll do a little bit of demo. If you're interested in
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:41,570'); seek(1661.0)">
              getting what I'm using to demo, here is
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:44,968'); seek(1664.0)">
              the link and I will show that later. Again,
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:49,110'); seek(1669.0)">
              let me pull this application
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:54,470'); seek(1674.0)">
              for you back there.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:59,050'); seek(1679.0)">
              Okay. So if you go to that link, it will get you this
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:28:04,716'); seek(1684.0)">
              application or this website.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:28:08,590'); seek(1688.0)">
              If you want to try out our demo today,
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:28:12,736'); seek(1692.0)">
              you click this out to try it out.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:28:16,910'); seek(1696.0)">
              And what it'll do is it would pull up the
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:28:22,210'); seek(1702.0)">
              docker file and create an instance of
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:28:28,788'); seek(1708.0)">
              a Jupyter notebook using binder.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:28:32,790'); seek(1712.0)">
              This is what it looks like.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:28:37,990'); seek(1717.0)">
              So now that the kernel is ready, this is a c sharp application.
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:28:41,528'); seek(1721.0)">
              So what I have here is running Jupyter notebook using.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:28:46,188'); seek(1726.0)">
              Net interactive so I can have a c sharp application.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:50,172'); seek(1730.0)">
              And what I want to demo here today is I wanted
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:53,692'); seek(1733.0)">
              to convert a
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:58,048'); seek(1738.0)">
              model trained in ML. Net into
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:29:01,824'); seek(1741.0)">
              Onyx. So this is how I would get
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:29:05,824'); seek(1745.0)">
              some nuget packages and download
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:29:09,606'); seek(1749.0)">
              them. While it's downloading,
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:29:12,698'); seek(1752.0)">
              let me kind of talk a little bit about the code.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:29:16,930'); seek(1756.0)">
              So this one right here is system
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:29:21,492'); seek(1761.0)">
              IO. I'm using system IO,
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:29:24,618'); seek(1764.0)">
              Microsoft data analysis Xplot
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:29:28,362'); seek(1768.0)">
              plotly. And this one right here allows
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:29:32,638'); seek(1772.0)">
              me to be able to format it properly, to display it
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:29:36,232'); seek(1776.0)">
              properly on this Jupiter notebook.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:29:39,970'); seek(1779.0)">
              So it's just a library. Okay,
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:29:43,260'); seek(1783.0)">
              let's wait until that one's done. So this
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:29:46,892'); seek(1786.0)">
              one right here, I have a CSV file, salary CSV.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:52,102'); seek(1792.0)">
              Let me try to open that for you. So this is what
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:55,728'); seek(1795.0)">
              it looks like. I have two columns on this csv file,
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:59,126'); seek(1799.0)">
              years of experience and salary. I want the
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:30:02,308'); seek(1802.0)">
              simplest example. I mean, this is not the best example if
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:30:06,164'); seek(1806.0)">
              you're going to create a machine learning application. But I want to
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:30:09,970'); seek(1809.0)">
              one input and one output. Input is your
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:30:13,512'); seek(1813.0)">
              years experience. Output is salary.
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:30:16,942'); seek(1816.0)">
              So we want to create a machine
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:30:20,862'); seek(1820.0)">
              learning model that when you
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:30:24,568'); seek(1824.0)">
              create years of experience, your input is years of experience.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:30:28,044'); seek(1828.0)">
              It would kind of guess how much is the salary based from that experience.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:30:32,012'); seek(1832.0)">
              It's just a contrived example.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:30:35,450'); seek(1835.0)">
              Okay, let's go back here.
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:30:38,908'); seek(1838.0)">
              Now that that one is done, it was able to download all my nuget
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:30:42,838'); seek(1842.0)">
              packages. Now I'm using to run this system.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:46,830'); seek(1846.0)">
              I'm going to run this to your application right here so that
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:50,228'); seek(1850.0)">
              I can load the csv file using data frame.
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:54,850'); seek(1854.0)">
              And based on that, this is what my data looks like,
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:58,916'); seek(1858.0)">
              right? Notice that as
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:31:02,292'); seek(1862.0)">
              the years increases the salary.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:31:06,710'); seek(1866.0)">
              So it's just simple example and
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:31:10,856'); seek(1870.0)">
              looking at this description, then it gives me
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:31:14,408'); seek(1874.0)">
              what's the min, the max. Right now I only have
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:31:18,410'); seek(1878.0)">
              30 items on my list. And so at the
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:31:21,724'); seek(1881.0)">
              end of the day, what this one is trying to do using ML net,
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:31:25,468'); seek(1885.0)">
              I want to create a pipeline to be
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:31:28,608'); seek(1888.0)">
              able to train a model.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:31:31,808'); seek(1891.0)">
              Whereas in order to train, there's two things you have to
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:31:34,944'); seek(1894.0)">
              do. You have to use ML net and once you have that context,
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:31:39,970'); seek(1899.0)">
              you create the pipeline and then you do fit
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:31:43,860'); seek(1903.0)">
              and transform. There's always that pair.
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:47,170'); seek(1907.0)">
              So once you have a transformer model,
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:50,930'); seek(1910.0)">
              it'll create that model for
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:54,648'); seek(1914.0)">
              you. So what I want
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:58,088'); seek(1918.0)">
              to do now is now that I have that
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:32:01,496'); seek(1921.0)">
              model, I want to convert it to
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:32:05,292'); seek(1925.0)">
              Onyx. So I
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:32:09,212'); seek(1929.0)">
              use context model convert
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:32:12,818'); seek(1932.0)">
              to onyx. I pass in the stream
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:32:17,790'); seek(1937.0)">
              and my data and
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:32:21,216'); seek(1941.0)">
              what it'll do is it would create these
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:32:26,848'); seek(1946.0)">
              model onyx for me.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:32:30,110'); seek(1950.0)">
              See where that one is?
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:32:33,150'); seek(1953.0)">
              Model onyx. Put it in here.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:32:40,610'); seek(1960.0)">
              So let's try to open it again.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:32:43,650'); seek(1963.0)">
              There you go. See, I noticed Onyx
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:47,534'); seek(1967.0)">
              model was generated for me.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:50,950'); seek(1970.0)">
              Think I can open that Onyx model?
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:55,130'); seek(1975.0)">
              Okay, so now that I have an Onyx model,
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:33:00,410'); seek(1980.0)">
              let me try to verify it and see how I can run.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:33:04,730'); seek(1984.0)">
              I'm going to open another project. This time I
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:33:08,592'); seek(1988.0)">
              have this Onyx inference Python notebook.
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:33:13,950'); seek(1993.0)">
              This is not a c sharp application,
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:33:18,910'); seek(1998.0)">
              so I want to change my kernel.
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:33:23,570'); seek(2003.0)">
              Let's change this kernel into a python.
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:33:29,250'); seek(2009.0)">
              So this time I want to use Onyx runtime in Python
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:33:34,230'); seek(2014.0)">
              to do the inferencing on that model onyx
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:33:38,270'); seek(2018.0)">
              file. So I do pip install onyx
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:33:42,542'); seek(2022.0)">
              runtime. And what I'll do is it would download all the necessary
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:33:46,610'); seek(2026.0)">
              requirements to install to get
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:33:50,028'); seek(2030.0)">
              Onyx runtime library. Of course,
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:33:53,692'); seek(2033.0)">
              here I'm just importing them and I create
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:33:57,532'); seek(2037.0)">
              this inference session.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:34:00,270'); seek(2040.0)">
              So notice that this model Onyx,
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:34:04,182'); seek(2044.0)">
              if you go to netron app, it would display something
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:34:07,952'); seek(2047.0)">
              like this where you can view the
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:34:11,312'); seek(2051.0)">
              contents of your onnx model. And notice
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:34:14,842'); seek(2054.0)">
              that it gives me the input and then the output.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:34:18,730'); seek(2058.0)">
              This input gives me the years of experience and
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:34:21,972'); seek(2061.0)">
              salary. The output is like this.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:34:25,800'); seek(2065.0)">
              So whatever we're interested in is input. In this
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:34:29,112'); seek(2069.0)">
              case, it's only years of experience salary.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:34:32,254'); seek(2072.0)">
              That's the one. We're trying to guess this point when you're doing inferencing.
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:34:36,306'); seek(2076.0)">
              So it would be ignored, but it would use all
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:34:40,268'); seek(2080.0)">
              your inputs. So even if you place a
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:34:43,644'); seek(2083.0)">
              number here, it would be ignored, it won't
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:34:47,570'); seek(2087.0)">
              be used. Notice how that one is not connected.
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:34:51,590'); seek(2091.0)">
              So it's only using years experience. He's using feature vectorizer
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:34:56,134'); seek(2096.0)">
              to be able to create this linear regressor
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:35:01,490'); seek(2101.0)">
              to get the output. Of course,
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:35:04,756'); seek(2104.0)">
              here, all these are not going to be used anyway.
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:35:07,876'); seek(2107.0)">
              It's just going to be stub. What we're interested is the output
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:35:12,710'); seek(2112.0)">
              right here. Okay,
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:35:15,750'); seek(2115.0)">
              so this one, what I wanted
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:35:19,896'); seek(2119.0)">
              to do is to get the name, the shape
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:35:23,822'); seek(2123.0)">
              and the type of years experience,
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:35:28,810'); seek(2128.0)">
              input, years, shape and type. This one is
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:35:32,396'); seek(2132.0)">
              for another one for the salary.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:35:36,490'); seek(2136.0)">
              Years salary shape and type
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:35:40,528'); seek(2140.0)">
              kind of gives me the descriptor and of course the
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:35:44,032'); seek(2144.0)">
              output gives me the shape and type.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:35:48,750'); seek(2148.0)">
              In this case, how did I get four?
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:35:52,770'); seek(2152.0)">
              It's the fourth of the output.
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:35:56,130'); seek(2156.0)">
              So 01234.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:35:59,332'); seek(2159.0)">
              Right. So that's the fourth output.
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:36:03,190'); seek(2163.0)">
              Let's run this one too. So now that I have
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:36:06,872'); seek(2166.0)">
              that I can pass in that data,
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:36:11,670'); seek(2171.0)">
              in this case pass in input experience,
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:36:15,240'); seek(2175.0)">
              input salary, and it specify the years because
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:36:19,196'); seek(2179.0)">
              I know the type and I need to
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:36:23,290'); seek(2183.0)">
              place them into these array.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:36:28,750'); seek(2188.0)">
              So I got the years salary.
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:36:32,430'); seek(2192.0)">
              Notice how I put zero because it's going to be ignored anyway. So let's say
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:36:36,128'); seek(2196.0)">
              I change this to ten and
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:36:41,490'); seek(2201.0)">
              the output would be identified
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:36:44,810'); seek(2204.0)">
              here. And notice that if
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:36:48,068'); seek(2208.0)">
              I have ten, that would be the value of
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:36:54,870'); seek(2214.0)">
              the result. And now I can grab that
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:36:58,152'); seek(2218.0)">
              one and that would be my output.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:37:03,190'); seek(2223.0)">
              So if I change it again to say three
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:37:08,156'); seek(2228.0)">
              years, three and a half years, see what
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:37:11,532'); seek(2231.0)">
              happens, and then I'll have a different output.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:37:16,250'); seek(2236.0)">
              Okay, so what happened so far?
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:37:19,470'); seek(2239.0)">
              What I did was to train
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:37:23,280'); seek(2243.0)">
              a model, export it to
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:37:27,632'); seek(2247.0)">
              an Onyx file using ML net in
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:37:32,932'); seek(2252.0)">
              c sharp. And based from that Onyx model,
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:37:37,570'); seek(2257.0)">
              I use Onyx runtime to
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:37:41,890'); seek(2261.0)">
              use it in my python application and
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:37:47,430'); seek(2267.0)">
              do inferencing that way.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:37:53,510'); seek(2273.0)">
              This is how it feels like after learning all these things.
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:37:57,450'); seek(2277.0)">
              Now it kind of connects all the different,
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:38:02,570'); seek(2282.0)">
              how I can just easily
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:38:06,626'); seek(2286.0)">
              use an existing Onnx is
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:38:10,688'); seek(2290.0)">
              a way for us to be able lead software engineer to
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:38:14,064'); seek(2294.0)">
              be able to talk to data scientists and
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:38:17,408'); seek(2297.0)">
              also data scientists to talk lead lead software
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:38:21,366'); seek(2301.0)">
              engineer that we can use these secret
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:38:25,126'); seek(2305.0)">
              recipes, right, use these machine learning models and
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:38:28,852'); seek(2308.0)">
              integrate it to our application. At the end of the day,
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:38:34,470'); seek(2314.0)">
              all our best effort and
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:38:38,630'); seek(2318.0)">
              all our programs. Actually,
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:38:43,270'); seek(2323.0)">
              as long as we can integrate it to our application,
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:38:46,876'); seek(2326.0)">
              not just existing application or any greenfield application,
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:38:52,170'); seek(2332.0)">
              we can start incorporating these machine learning models
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:38:57,470'); seek(2337.0)">
              through Onnx. So we did talk about as a recap,
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:39:01,158'); seek(2341.0)">
              what is onyx? It's an open standard.
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:39:05,310'); seek(2345.0)">
              Use the right tool for the right job and how
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:39:08,656'); seek(2348.0)">
              you can efficiently run it on a target platform.
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:39:12,548'); seek(2352.0)">
              It separates out how you train it and how you
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:39:16,068'); seek(2356.0)">
              would run and do inferencing on that
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:39:20,308'); seek(2360.0)">
              model. How you would create Onnx model.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:39:23,656'); seek(2363.0)">
              I did show you how to download it from the Onnx model
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:39:27,176'); seek(2367.0)">
              zoo. You can create it and convert using
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:39:31,910'); seek(2371.0)">
              some of the Onyx convert.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:39:37,370'); seek(2377.0)">
              There's different ways how you can create can onnx model. You can
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:39:41,292'); seek(2381.0)">
              also deploy Onnx model.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:39:45,020'); seek(2385.0)">
              You can deploy it through Windows. NET JavaScript
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:39:49,430'); seek(2389.0)">
              using Onyx. JS did
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:39:53,696'); seek(2393.0)">
              a demo how you would use Onyx Runtime in Python to
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:40:00,110'); seek(2400.0)">
              it in high performance. All right,
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:40:05,250'); seek(2405.0)">
              if you want to learn more about me, my name is Ron Dagdag.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:40:08,170'); seek(2408.0)">
              I'm a lead software engineer at Spacey. I'm a 50 year Microsoft
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:40:12,154'); seek(2412.0)">
              MVP. The best way to contact me is
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:40:15,348'); seek(2415.0)">
              through LinkedIn or Twitter at Ron Dagdag
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:40:19,530'); seek(2419.0)">
              I appreciate you geeking out with me about Onnx,
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:40:23,914'); seek(2423.0)">
              Onnx Runtime, about Jupyter notebooks,
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:40:29,210'); seek(2429.0)">
              about bakeries, bakers and breads.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:40:33,850'); seek(2433.0)">
              Thank you very much. Have a good day.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Machine%20Learning%202021%20Slides%20-%20Ron%20Lyle%20Dagdag.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Machine%20Learning%202021%20Slides%20-%20Ron%20Lyle%20Dagdag.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2021" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 23 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/ml_ron.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Ron Lyle Dagdag
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Lead Software Engineer @ Spacee
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/rondagdag/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Ron Lyle Dagdag's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@rondagdag" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Ron Lyle Dagdag's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @rondagdag"
                  data-url="https://www.conf42.com/ml2021"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2021"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Machine Learning"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday London 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>