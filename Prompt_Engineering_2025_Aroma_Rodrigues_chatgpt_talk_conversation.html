<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: I talk to ChatGPT about things</title>
    <meta name="description" content="Master your prompt-fu!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Aroma%20Rodrigues_prompt.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="I talk to ChatGPT about things | Conf42"/>
    <meta property="og:description" content="The word ChatGPT has captured the imagination and the internet, but does ChatGPT truly know everything, is it truly AGI?"/>
    <meta property="og:url" content="https://conf42.com/Prompt_Engineering_2025_Aroma_Rodrigues_chatgpt_talk_conversation"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/ML2026_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Machine Learning 2026
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2026-02-19
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ml2026" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2026
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2026">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2026">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2026">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2026">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2026">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/dbd2026">
                            Database DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2026">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2026">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/agents2026">
                            AI Agents
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2026">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2026">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2026">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2026">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2026">
                            Chaos Engineering
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <!-- <a class="dropdown-item" href="None">
                            <b>Community platform login</b>
                          </a> -->
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #749BC2;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Prompt Engineering 2025 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2025-11-06">November 06 2025</time>
              
              - premiere 5PM GMT
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Master your prompt-fu!
 -->
              <script>
                const event_date = new Date("2025-11-06T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-11-06T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "r3c9Gcu4lkw"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrC9ZgozU8V1FhRF147_HDjp" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello, welcome to my talk.", "timestamp": "00:00:00,500", "timestamp_s": 0.0}, {"text": "Today I\u0027m going to talk about how I spoke to cha g pity about things.", "timestamp": "00:00:02,510", "timestamp_s": 2.0}, {"text": "All of these experiments were conducted on Cha g Pity three.", "timestamp": "00:00:06,729", "timestamp_s": 6.0}, {"text": "So this was like a really long time ago.", "timestamp": "00:00:10,879", "timestamp_s": 10.0}, {"text": "But as we go through this talk, you\u0027ll actually realize why this was an", "timestamp": "00:00:13,129", "timestamp_s": 13.0}, {"text": "important sort of exercise to be done, especially on the primitive not really", "timestamp": "00:00:18,250", "timestamp_s": 18.0}, {"text": "primitive, but like primitive versions of pure elements or pure language models.", "timestamp": "00:00:24,810", "timestamp_s": 24.0}, {"text": "Some of these exercises are like fun experiments that are", "timestamp": "00:00:30,630", "timestamp_s": 30.0}, {"text": "conducted with Ja GT three.", "timestamp": "00:00:33,880", "timestamp_s": 33.0}, {"text": "The first one is where we ask Cha gt.", "timestamp": "00:00:36,760", "timestamp_s": 36.0}, {"text": "They were conducted on a personal free use account.", "timestamp": "00:00:39,059", "timestamp_s": 39.0}, {"text": "So the call t will vary you depending upon whether you are using like", "timestamp": "00:00:41,429", "timestamp_s": 41.0}, {"text": "Chad GP Plus or something else.", "timestamp": "00:00:45,059", "timestamp_s": 45.0}, {"text": "So at some points I just basically decided to ask Chad Gpt a bunch of", "timestamp": "00:00:47,209", "timestamp_s": 47.0}, {"text": "really weird questions that I thought it wouldn\u0027t be able to answer to check", "timestamp": "00:00:50,890", "timestamp_s": 50.0}, {"text": "the viability of the A GI theory.", "timestamp": "00:00:55,510", "timestamp_s": 55.0}, {"text": "So these are some of the examples.", "timestamp": "00:00:59,379", "timestamp_s": 59.0}, {"text": "The first one is when is a door no longer a door?", "timestamp": "00:01:01,539", "timestamp_s": 61.0}, {"text": "So the answer was, a door is no longer a door when it\u0027s no longer serves the", "timestamp": "00:01:04,890", "timestamp_s": 64.0}, {"text": "purpose of providing an entrance or exit to a room or building or when", "timestamp": "00:01:10,140", "timestamp_s": 70.0}, {"text": "it\u0027s unable to be open or closed.", "timestamp": "00:01:14,870", "timestamp_s": 74.0}, {"text": "So what I decided was, let me give it like some more context because", "timestamp": "00:01:17,860", "timestamp_s": 77.0}, {"text": "it\u0027s way possible that it has been trained on this data before.", "timestamp": "00:01:21,580", "timestamp_s": 81.0}, {"text": "So I was like this is a riddle, so answer it.", "timestamp": "00:01:25,020", "timestamp_s": 85.0}, {"text": "When is a door no longer a door?", "timestamp": "00:01:28,200", "timestamp_s": 88.0}, {"text": "And that\u0027s when all the training basically kicked in.", "timestamp": "00:01:30,920", "timestamp_s": 90.0}, {"text": "The productive modeling kicked in and it said a door is no longer a", "timestamp": "00:01:34,080", "timestamp_s": 94.0}, {"text": "door when it\u0027s a jar, which is right.", "timestamp": "00:01:37,950", "timestamp_s": 97.0}, {"text": "That\u0027s the right answer of the riddle.", "timestamp": "00:01:40,910", "timestamp_s": 100.0}, {"text": "The second one was, what tastes better than it smells?", "timestamp": "00:01:43,260", "timestamp_s": 103.0}, {"text": "And at this point, JG PT basically understood that we", "timestamp": "00:01:46,730", "timestamp_s": 106.0}, {"text": "were in like the context of answering griddles or something.", "timestamp": "00:01:49,430", "timestamp_s": 109.0}, {"text": "So it was like this is a riddle.", "timestamp": "00:01:53,270", "timestamp_s": 113.0}, {"text": "It told me that this is a riddle.", "timestamp": "00:01:55,210", "timestamp_s": 115.0}, {"text": "And the answer is UNK because it tastes food but does not have a smell.", "timestamp": "00:01:56,980", "timestamp_s": 116.0}, {"text": "Which was the right answer.", "timestamp": "00:02:01,480", "timestamp_s": 121.0}, {"text": "The next question was, what building has the most stories?", "timestamp": "00:02:03,670", "timestamp_s": 123.0}, {"text": "And it basically recognized the fact that this was still a riddle.", "timestamp": "00:02:07,500", "timestamp_s": 127.0}, {"text": "And the answer was library because it has many stories, what has bottom at the top.", "timestamp": "00:02:11,980", "timestamp_s": 131.0}, {"text": "So again, Chad Jupiter was like, this is a riddle.", "timestamp": "00:02:17,700", "timestamp_s": 137.0}, {"text": "The answer is a staircase because it has a bottom step at the top when", "timestamp": "00:02:20,549", "timestamp_s": 140.0}, {"text": "you reach the top of the staircase, which was not the right answer.", "timestamp": "00:02:25,079", "timestamp_s": 145.0}, {"text": "\u0027cause the right answer is actually legs.", "timestamp": "00:02:28,340", "timestamp_s": 148.0}, {"text": "But it did recognize the fact that we were in riddle mode and it went", "timestamp": "00:02:30,740", "timestamp_s": 150.0}, {"text": "into a story mode of thoughts.", "timestamp": "00:02:36,300", "timestamp_s": 156.0}, {"text": "A little bit of imagination.", "timestamp": "00:02:38,360", "timestamp_s": 158.0}, {"text": "I don\u0027t think it\u0027s like sourcing all of this data from its", "timestamp": "00:02:39,770", "timestamp_s": 159.0}, {"text": "previous training, though.", "timestamp": "00:02:44,180", "timestamp_s": 164.0}, {"text": "I do believe for the co last couple examples, we did source a lot", "timestamp": "00:02:45,350", "timestamp_s": 165.0}, {"text": "of data from previous training.", "timestamp": "00:02:49,900", "timestamp_s": 169.0}, {"text": "I. So Chad GP D had at some points in all of its tasks and all of its examples,", "timestamp": "00:02:51,490", "timestamp_s": 171.0}, {"text": "seen those examples before in either like q and a task or something else.", "timestamp": "00:02:58,490", "timestamp_s": 178.0}, {"text": "So some other examples were what has four wheels and twice.", "timestamp": "00:03:03,640", "timestamp_s": 183.0}, {"text": "It\u0027s still in this mode where it\u0027s this is a riddle, and the answer is", "timestamp": "00:03:08,175", "timestamp_s": 188.0}, {"text": "a garbage truck because it has four wheels and it moves around to collect", "timestamp": "00:03:11,745", "timestamp_s": 191.0}, {"text": "garbage, which can be considered as flying through the streets.", "timestamp": "00:03:15,495", "timestamp_s": 195.0}, {"text": "That\u0027s not the right answer actually, but like it does make up like a", "timestamp": "00:03:19,785", "timestamp_s": 199.0}, {"text": "lot of imaginative shit when it encounters questions that are", "timestamp": "00:03:23,865", "timestamp_s": 203.0}, {"text": "really, but it doesn\u0027t really have any good answers to those questions.", "timestamp": "00:03:30,315", "timestamp_s": 210.0}, {"text": "What month of the year has 28 days in it?", "timestamp": "00:03:34,935", "timestamp_s": 214.0}, {"text": "And it\u0027s this is a riddle.", "timestamp": "00:03:38,165", "timestamp_s": 218.0}, {"text": "And it says that all the 12 months of the year have at least 28 days in it.", "timestamp": "00:03:39,845", "timestamp_s": 219.0}, {"text": "Which is the right answer.", "timestamp": "00:03:44,135", "timestamp_s": 224.0}, {"text": "A lot of humans get this wrong \u0027cause they\u0027re like it\u0027s just Feb. What can", "timestamp": "00:03:46,215", "timestamp_s": 226.0}, {"text": "you put in a bucket to make it way less?", "timestamp": "00:03:50,175", "timestamp_s": 230.0}, {"text": "This is a riddle.", "timestamp": "00:03:52,455", "timestamp_s": 232.0}, {"text": "The answer is a hole because a hole in a bucket decreases the weight of the bucket.", "timestamp": "00:03:53,715", "timestamp_s": 233.0}, {"text": "That\u0027s right.", "timestamp": "00:03:58,715", "timestamp_s": 238.0}, {"text": "And it\u0027s not like it has a lot of intuitive thinking about, oh, this", "timestamp": "00:03:59,845", "timestamp_s": 239.0}, {"text": "is what the physical world is like.", "timestamp": "00:04:04,374", "timestamp_s": 244.0}, {"text": "If you drill a hole at the bottom of a container, it\u0027s going to", "timestamp": "00:04:06,085", "timestamp_s": 246.0}, {"text": "make a lot of its contents.", "timestamp": "00:04:10,524", "timestamp_s": 250.0}, {"text": "Spell out what starts with the t. Ends with a T and has T in it.", "timestamp": "00:04:12,264", "timestamp_s": 252.0}, {"text": "This is a riddle.", "timestamp": "00:04:16,454", "timestamp_s": 256.0}, {"text": "The answer is teapot because it starts with a T, ends with", "timestamp": "00:04:17,564", "timestamp_s": 257.0}, {"text": "a T and has T in the middle.", "timestamp": "00:04:20,870", "timestamp_s": 260.0}, {"text": "It got that but I think all of those were like extremely classic examples of riles.", "timestamp": "00:04:23,144", "timestamp_s": 263.0}, {"text": "And based on all of the corpus that JG PT had been trained on before,", "timestamp": "00:04:28,804", "timestamp_s": 268.0}, {"text": "it probably had gone through all of those examples before in its training.", "timestamp": "00:04:33,274", "timestamp_s": 273.0}, {"text": "Where is the only place where today comes before yesterday?", "timestamp": "00:04:37,344", "timestamp_s": 277.0}, {"text": "This is a riddle.", "timestamp": "00:04:41,004", "timestamp_s": 281.0}, {"text": "The answer is in a dictionary because the words are listed in alphabetical order.", "timestamp": "00:04:42,264", "timestamp_s": 282.0}, {"text": "What goes all around the world, but stays in a corner.", "timestamp": "00:04:46,814", "timestamp_s": 286.0}, {"text": "This is a riddle.", "timestamp": "00:04:50,054", "timestamp_s": 290.0}, {"text": "The answer is a stamp.", "timestamp": "00:04:51,254", "timestamp_s": 291.0}, {"text": "It goes all around the world when it is used on letters and postcards,", "timestamp": "00:04:52,604", "timestamp_s": 292.0}, {"text": "but it is physically located in a corner of the envelope I\u0027m used to", "timestamp": "00:04:56,809", "timestamp_s": 296.0}, {"text": "bat with, yet I never get a hit.", "timestamp": "00:05:01,324", "timestamp_s": 301.0}, {"text": "I\u0027m near a ball, yet it is never thrown.", "timestamp": "00:05:03,934", "timestamp_s": 303.0}, {"text": "Why am I, this is a riddle, and the answer is a baseball bat.", "timestamp": "00:05:06,514", "timestamp_s": 306.0}, {"text": "It\u0027s used to bat with, but it never gets a hit.", "timestamp": "00:05:10,954", "timestamp_s": 310.0}, {"text": "It\u0027s near a ball, but the ball is never true.", "timestamp": "00:05:14,224", "timestamp_s": 314.0}, {"text": "And at some point I\u0027m like sometimes it gets a lot of these things wrong.", "timestamp": "00:05:16,914", "timestamp_s": 316.0}, {"text": "And it starts making up a lot of like imaginative stories about", "timestamp": "00:05:21,364", "timestamp_s": 321.0}, {"text": "what the real answer could be like.", "timestamp": "00:05:25,234", "timestamp_s": 325.0}, {"text": "And it tries to like basically fitted all of those stories into the narrative", "timestamp": "00:05:27,294", "timestamp_s": 327.0}, {"text": "so that it seems like the answer that it\u0027s giving me is the right answer.", "timestamp": "00:05:32,334", "timestamp_s": 332.0}, {"text": "So I tried prompting it, saying, can there be another answer?", "timestamp": "00:05:37,184", "timestamp_s": 337.0}, {"text": "And it was basically like when you\u0027re trying to hint to your friends when", "timestamp": "00:05:41,164", "timestamp_s": 341.0}, {"text": "you\u0027re playing riddles with each other and you are like this is a hint.", "timestamp": "00:05:46,024", "timestamp_s": 346.0}, {"text": "Why don\u0027t you take this as a hint?", "timestamp": "00:05:49,524", "timestamp_s": 349.0}, {"text": "Or Why don\u0027t you think of any other answers?", "timestamp": "00:05:52,124", "timestamp_s": 352.0}, {"text": "Do you think there could be any other answers?", "timestamp": "00:05:55,304", "timestamp_s": 355.0}, {"text": "And it did give me back another imaginative answer, which was a baseball", "timestamp": "00:05:57,734", "timestamp_s": 357.0}, {"text": "glove, which is also not the right answer.", "timestamp": "00:06:02,294", "timestamp_s": 362.0}, {"text": "But you can see where this is basically thinking process of a language model.", "timestamp": "00:06:05,714", "timestamp_s": 365.0}, {"text": "You\u0027re literally seeing it think, and this was before all of the RAG or any", "timestamp": "00:06:10,624", "timestamp_s": 370.0}, {"text": "other sort of layers on top of Cha Gt.", "timestamp": "00:06:16,204", "timestamp_s": 376.0}, {"text": "This is pure language models.", "timestamp": "00:06:18,994", "timestamp_s": 378.0}, {"text": "So you can see it thinking when you say, can there be another answer?", "timestamp": "00:06:21,484", "timestamp_s": 381.0}, {"text": "Because it has already made up a lot of imaginative storytelling to fit", "timestamp": "00:06:27,324", "timestamp_s": 387.0}, {"text": "a certain answer into this riddle.", "timestamp": "00:06:32,544", "timestamp_s": 392.0}, {"text": "It\u0027s thinking along those same sort of lines.", "timestamp": "00:06:35,014", "timestamp_s": 395.0}, {"text": "\u0027cause the answer that it gets back to is the baseball globe", "timestamp": "00:06:38,554", "timestamp_s": 398.0}, {"text": "as opposed to the baseball bat.", "timestamp": "00:06:42,964", "timestamp_s": 402.0}, {"text": "Unfortunately that was not the right answer actually.", "timestamp": "00:06:45,084", "timestamp_s": 405.0}, {"text": "But I just decided to continue and tried to change the genre", "timestamp": "00:06:47,844", "timestamp_s": 407.0}, {"text": "basically, like the geography.", "timestamp": "00:06:52,364", "timestamp_s": 412.0}, {"text": "So my question was, I heard Arabian Knights first.", "timestamp": "00:06:55,004", "timestamp_s": 415.0}, {"text": "My queen was the writer of the great story.", "timestamp": "00:06:58,604", "timestamp_s": 418.0}, {"text": "Guess my name, and it says this is a riddle.", "timestamp": "00:07:00,704", "timestamp_s": 420.0}, {"text": "This is not a riddle actually, it\u0027s just a question that\u0027s framed in a", "timestamp": "00:07:04,544", "timestamp_s": 424.0}, {"text": "specific manner in order to confuse the person you\u0027re seeking an answer from.", "timestamp": "00:07:09,334", "timestamp_s": 429.0}, {"text": "So Chad Gri at this point was like it\u0027s like in riddle mode.", "timestamp": "00:07:14,594", "timestamp_s": 434.0}, {"text": "So it keeps on assuming that the context is still riddle mode, and it says to", "timestamp": "00:07:17,594", "timestamp_s": 437.0}, {"text": "me, this is a riddle, and the answer is shares adi, which is not the right answer.", "timestamp": "00:07:23,624", "timestamp_s": 443.0}, {"text": "Because the question is, my queen was the writer of the Great story.", "timestamp": "00:07:29,314", "timestamp_s": 449.0}, {"text": "Guess my name.", "timestamp": "00:07:32,764", "timestamp_s": 452.0}, {"text": "It does get all the context.", "timestamp": "00:07:34,224", "timestamp_s": 454.0}, {"text": "It\u0027s like she\u0027s a queen in the collection.", "timestamp": "00:07:36,184", "timestamp_s": 456.0}, {"text": "It\u0027s a Middle Eastern folk tales known as 1001 Knights,", "timestamp": "00:07:38,494", "timestamp_s": 458.0}, {"text": "also known as Arabian Knights.", "timestamp": "00:07:43,504", "timestamp_s": 463.0}, {"text": "She\u0027s the storyteller of the Tales, which are also known as", "timestamp": "00:07:45,304", "timestamp_s": 465.0}, {"text": "the Tales of 1,001 Arabian Nights.", "timestamp": "00:07:48,904", "timestamp_s": 468.0}, {"text": "Okay.", "timestamp": "00:07:52,794", "timestamp_s": 472.0}, {"text": "But it did make a way human mistake here by telling me that my name is", "timestamp": "00:07:53,744", "timestamp_s": 473.0}, {"text": "Cher Zdi as opposed to the King\u0027s name.", "timestamp": "00:08:00,634", "timestamp_s": 480.0}, {"text": "So that basically worked like in my head I was like I was able to track trick Chad", "timestamp": "00:08:03,434", "timestamp_s": 483.0}, {"text": "Jupiter into being confused just using, a specific method in which you ask tricky", "timestamp": "00:08:09,184", "timestamp_s": 489.0}, {"text": "questions, which also works with humans.", "timestamp": "00:08:17,144", "timestamp_s": 497.0}, {"text": "So we just basically decided to continue and I moved on to another genre of sorts.", "timestamp": "00:08:20,644", "timestamp_s": 500.0}, {"text": "Basically currently I was in fiction, so I\u0027d been asking it questions about", "timestamp": "00:08:26,304", "timestamp_s": 506.0}, {"text": "like physics or physical phenomenon or sports or something related to", "timestamp": "00:08:31,184", "timestamp_s": 511.0}, {"text": "actually perceiving or observing.", "timestamp": "00:08:37,624", "timestamp_s": 517.0}, {"text": "And now I basically moved on to some fictional results.", "timestamp": "00:08:39,994", "timestamp_s": 519.0}, {"text": "So my question was, what do you call a rabbit that has fleas?", "timestamp": "00:08:44,394", "timestamp_s": 524.0}, {"text": "And Chad g pity is this is a riddle.", "timestamp": "00:08:48,284", "timestamp_s": 528.0}, {"text": "And the answer is bug bunny as its apply onwards.", "timestamp": "00:08:50,374", "timestamp_s": 530.0}, {"text": "Bug bunny is a cartoon rabbit, and bugs is also another word", "timestamp": "00:08:54,394", "timestamp_s": 534.0}, {"text": "for fleas, but it\u0027s right.", "timestamp": "00:08:58,924", "timestamp_s": 538.0}, {"text": "This comes from like a certain source of fiction that it", "timestamp": "00:09:00,954", "timestamp_s": 540.0}, {"text": "was trained on specifically.", "timestamp": "00:09:05,334", "timestamp_s": 545.0}, {"text": "So it knows like the references, what you get if you pour boiling hot water", "timestamp": "00:09:07,134", "timestamp_s": 547.0}, {"text": "down a rabbit hole, this is a riddle.", "timestamp": "00:09:12,614", "timestamp_s": 552.0}, {"text": "The answer is hot cross bunnies as a supply onwards.", "timestamp": "00:09:15,824", "timestamp_s": 555.0}, {"text": "Hot cross bunnies sounds like hot cross buns and the word bunny", "timestamp": "00:09:19,844", "timestamp_s": 559.0}, {"text": "is another name for a rabbit.", "timestamp": "00:09:24,674", "timestamp_s": 564.0}, {"text": "So I did to a certain extent understand punts.", "timestamp": "00:09:26,854", "timestamp_s": 566.0}, {"text": "Whether it\u0027s like intuitively understanding punts, whether it\u0027s", "timestamp": "00:09:30,774", "timestamp_s": 570.0}, {"text": "capable of making bunts by itself or whether it was drained on this specific", "timestamp": "00:09:34,619", "timestamp_s": 574.0}, {"text": "bun, is something that at this point, because we are looking at it as if", "timestamp": "00:09:40,464", "timestamp_s": 580.0}, {"text": "it was a black box, we don\u0027t know.", "timestamp": "00:09:45,354", "timestamp_s": 585.0}, {"text": "So we would basically have to devise like a bunch of other tests to figure out if.", "timestamp": "00:09:48,104", "timestamp_s": 588.0}, {"text": "It was actually intuitively understanding how to make a pun, or whether it was", "timestamp": "00:09:54,014", "timestamp_s": 594.0}, {"text": "just trained on this data to mimic or to basically remember that it was", "timestamp": "00:09:59,444", "timestamp_s": 599.0}, {"text": "trained on this data and remembered through its neural network that", "timestamp": "00:10:07,425", "timestamp_s": 607.0}, {"text": "the answer is hot crust bunnies.", "timestamp": "00:10:13,035", "timestamp_s": 613.0}, {"text": "So I just went on what has to be broken before you can use it, and it\u0027s like this", "timestamp": "00:10:15,454", "timestamp_s": 615.0}, {"text": "is a riddle, and the answer is an egg.", "timestamp": "00:10:21,405", "timestamp_s": 621.0}, {"text": "It has to be broken in order to use it, and cooking or eating.", "timestamp": "00:10:23,715", "timestamp_s": 623.0}, {"text": "I\u0027m tall when I\u0027m young, and I\u0027m short when I\u0027m old.", "timestamp": "00:10:27,995", "timestamp_s": 627.0}, {"text": "What am I?", "timestamp": "00:10:30,575", "timestamp_s": 630.0}, {"text": "This is a riddle.", "timestamp": "00:10:31,555", "timestamp_s": 631.0}, {"text": "The answer is a candle.", "timestamp": "00:10:32,485", "timestamp_s": 632.0}, {"text": "A candle is tall when it\u0027s new and has not been burned, but it becomes short as", "timestamp": "00:10:34,195", "timestamp_s": 634.0}, {"text": "it burns down and gets short with age.", "timestamp": "00:10:39,655", "timestamp_s": 639.0}, {"text": "It\u0027s right.", "timestamp": "00:10:42,070", "timestamp_s": 642.0}, {"text": "Classic riddle, what is always in front of you, but can\u0027t be seen.", "timestamp": "00:10:42,790", "timestamp_s": 642.0}, {"text": "This is a riddle.", "timestamp": "00:10:47,370", "timestamp_s": 647.0}, {"text": "The answer is the future as it\u0027s always in front of you, but cannot be", "timestamp": "00:10:48,690", "timestamp_s": 648.0}, {"text": "seen because it hasn\u0027t happened yet.", "timestamp": "00:10:52,500", "timestamp_s": 652.0}, {"text": "Technically it\u0027s right.", "timestamp": "00:10:54,650", "timestamp_s": 654.0}, {"text": "And this is one of those philosophical genre based riddles of sorts.", "timestamp": "00:10:56,210", "timestamp_s": 656.0}, {"text": "At this point, it used to like the observer of Chad GTI as a black box.", "timestamp": "00:11:01,800", "timestamp_s": 661.0}, {"text": "It would seem that Chad GTI did in fact understand some human philosophy, which at", "timestamp": "00:11:07,109", "timestamp_s": 667.0}, {"text": "that point, \u0027cause it was Ja GBT three at the point was like awe inspiring, right?", "timestamp": "00:11:15,685", "timestamp_s": 675.0}, {"text": "So I just decided to go further into this rabbit hole of sorts.", "timestamp": "00:11:20,830", "timestamp_s": 680.0}, {"text": "Because I was getting some very interesting signals.", "timestamp": "00:11:25,210", "timestamp_s": 685.0}, {"text": "So I was like on a table, there are two apples on the plate.", "timestamp": "00:11:29,100", "timestamp_s": 689.0}, {"text": "Three men are eating it.", "timestamp": "00:11:32,330", "timestamp_s": 692.0}, {"text": "How should one not eat an apple?", "timestamp": "00:11:34,070", "timestamp_s": 694.0}, {"text": "And cha, but he\u0027s this is a riddle.", "timestamp": "00:11:37,480", "timestamp_s": 697.0}, {"text": "The answer is one of the men is a doctor because the doctor would not eat an", "timestamp": "00:11:39,460", "timestamp_s": 699.0}, {"text": "apple as he would be the one giving advice on how to not eat the apple.", "timestamp": "00:11:43,870", "timestamp_s": 703.0}, {"text": "And I think that answer was wrong, but like it, it\u0027s so imaginative.", "timestamp": "00:11:49,620", "timestamp_s": 709.0}, {"text": "It just made up like a whole story about how if you are a doctor,", "timestamp": "00:11:54,229", "timestamp_s": 714.0}, {"text": "you\u0027re not supposed to eat an apple, though the actual saying is, an", "timestamp": "00:11:59,839", "timestamp_s": 719.0}, {"text": "apple a day gives the doctor away.", "timestamp": "00:12:05,380", "timestamp_s": 725.0}, {"text": "So I went on and I was like, if five rabbits eat five apples in", "timestamp": "00:12:07,560", "timestamp_s": 727.0}, {"text": "five minutes, how many apples will 10 rabbits eat in 10 minutes?", "timestamp": "00:12:11,310", "timestamp_s": 731.0}, {"text": "This is a classic work problem that a lot of people actually have to solve when", "timestamp": "00:12:15,439", "timestamp_s": 735.0}, {"text": "they\u0027re doing any sort of math problems.", "timestamp": "00:12:20,520", "timestamp_s": 740.0}, {"text": "And it\u0027s still in riddle mode, so it\u0027s this is the riddle.", "timestamp": "00:12:22,650", "timestamp_s": 742.0}, {"text": "The answer is five apples.", "timestamp": "00:12:25,860", "timestamp_s": 745.0}, {"text": "This is because the problem doesn\u0027t take into account the fact, but eating the", "timestamp": "00:12:27,960", "timestamp_s": 747.0}, {"text": "apples would take a different amount of time depending upon the number of rabbits.", "timestamp": "00:12:32,069", "timestamp_s": 752.0}, {"text": "Instead, the problem only relates to the number of apples and the", "timestamp": "00:12:36,660", "timestamp_s": 756.0}, {"text": "time given incredibly weird math, but you have to understand that.", "timestamp": "00:12:41,069", "timestamp_s": 761.0}, {"text": "GP three was never linked to any sort of math engine to do any sort", "timestamp": "00:12:46,625", "timestamp_s": 766.0}, {"text": "of math and would get like the most basic math questions wrong.", "timestamp": "00:12:51,604", "timestamp_s": 771.0}, {"text": "And this is an example of such a problem.", "timestamp": "00:12:55,895", "timestamp_s": 775.0}, {"text": "So when it\u0027s purely language based language model, it does seem to get", "timestamp": "00:12:59,755", "timestamp_s": 779.0}, {"text": "a lot of mathematical problems wrong, though the way that humans learn", "timestamp": "00:13:06,285", "timestamp_s": 786.0}, {"text": "language or humans learn mathematics is primarily through language they do", "timestamp": "00:13:11,535", "timestamp_s": 791.0}, {"text": "because in most school curriculums, all of the problems that people solve", "timestamp": "00:13:19,365", "timestamp_s": 799.0}, {"text": "are closely related to language.", "timestamp": "00:13:25,435", "timestamp_s": 805.0}, {"text": "People specifically have a lot of problems with respect to a man buying", "timestamp": "00:13:28,315", "timestamp_s": 808.0}, {"text": "like 10 watermelons and then spending like x amount of money and such.", "timestamp": "00:13:33,295", "timestamp_s": 813.0}, {"text": "So technically you would think that a large language model would", "timestamp": "00:13:38,445", "timestamp_s": 818.0}, {"text": "be okay, understanding math, not through a math engine, but instead", "timestamp": "00:13:42,765", "timestamp_s": 822.0}, {"text": "through language like humans do.", "timestamp": "00:13:47,945", "timestamp_s": 827.0}, {"text": "So I just went on suppose you\u0027re touring on a bus with 10", "timestamp": "00:13:50,425", "timestamp_s": 830.0}, {"text": "passengers, two descendant, and four climbed on the first stand.", "timestamp": "00:13:53,785", "timestamp_s": 833.0}, {"text": "Five descended, and two climbed on the second stand, two descended and", "timestamp": "00:13:57,895", "timestamp_s": 837.0}, {"text": "three climbed on the next stand.", "timestamp": "00:14:01,135", "timestamp_s": 841.0}, {"text": "Now tell me how many passengers are traveling on the bus.", "timestamp": "00:14:02,935", "timestamp_s": 842.0}, {"text": "So it basically gave me like the wrong answer and then it basically", "timestamp": "00:14:06,105", "timestamp_s": 846.0}, {"text": "got confused because it thought that it had to explain why the answer", "timestamp": "00:14:10,959", "timestamp_s": 850.0}, {"text": "is what it thinks the answer is.", "timestamp": "00:14:15,579", "timestamp_s": 855.0}, {"text": "And went into like deep math with, like each statement", "timestamp": "00:14:18,159", "timestamp_s": 858.0}, {"text": "corresponding to like mathematical operation and still got it wrong.", "timestamp": "00:14:22,299", "timestamp_s": 862.0}, {"text": "A prime example of behavior that\u0027s actually seen in human kids, like", "timestamp": "00:14:27,029", "timestamp_s": 867.0}, {"text": "human children when they\u0027re like, I want to say five or six years old,", "timestamp": "00:14:31,319", "timestamp_s": 871.0}, {"text": "where we lose track of the mathematical operations that they are conducting.", "timestamp": "00:14:35,569", "timestamp_s": 875.0}, {"text": "Especially if they have like multiple tasks and multiple steps and they", "timestamp": "00:14:42,259", "timestamp_s": 882.0}, {"text": "basically lose track of history.", "timestamp": "00:14:47,089", "timestamp_s": 887.0}, {"text": "So while it was telling me things, \u0027cause this is like a predictive language model,", "timestamp": "00:14:48,769", "timestamp_s": 888.0}, {"text": "while it was telling me things, it was losing track of what it was telling me.", "timestamp": "00:14:53,899", "timestamp_s": 893.0}, {"text": "There was no current memory.", "timestamp": "00:14:58,959", "timestamp_s": 898.0}, {"text": "To charge three.", "timestamp": "00:15:01,289", "timestamp_s": 901.0}, {"text": "I don\u0027t know if the current models have any current memory, like when", "timestamp": "00:15:02,729", "timestamp_s": 902.0}, {"text": "they\u0027re telling you things, whether they have good memory or track of", "timestamp": "00:15:07,239", "timestamp_s": 907.0}, {"text": "what they\u0027re telling you in the moment that they\u0027re telling you those things.", "timestamp": "00:15:12,819", "timestamp_s": 912.0}, {"text": "Apart from all of the proactive modeling and such.", "timestamp": "00:15:17,119", "timestamp_s": 917.0}, {"text": "Because proactive modeling is oh, what word would come next as opposed", "timestamp": "00:15:20,140", "timestamp_s": 920.0}, {"text": "to, or this is the calculation that is supposed to match up to the", "timestamp": "00:15:24,740", "timestamp_s": 924.0}, {"text": "practical modeling that I\u0027ve done.", "timestamp": "00:15:29,770", "timestamp_s": 929.0}, {"text": "And at that point I basically was like I have no way of knowing", "timestamp": "00:15:31,800", "timestamp_s": 931.0}, {"text": "if JT three was actually trained on this data in the sense that.", "timestamp": "00:15:37,410", "timestamp_s": 937.0}, {"text": "Whether all of this data or all of these riddles were part of its carus ever", "timestamp": "00:15:43,030", "timestamp_s": 943.0}, {"text": "\u0027cause the carus was huge or whether it was actually being extremely intuitive.", "timestamp": "00:15:47,410", "timestamp_s": 947.0}, {"text": "\u0027cause when you\u0027re playing riddles with your friend, usually you are not allowed", "timestamp": "00:15:52,620", "timestamp_s": 952.0}, {"text": "to look up any sort of information.", "timestamp": "00:15:57,410", "timestamp_s": 957.0}, {"text": "You\u0027re not supposed to cheat, you\u0027re not supposed to ask anyone else.", "timestamp": "00:16:00,230", "timestamp_s": 960.0}, {"text": "You are just supposed to rack your brains.", "timestamp": "00:16:03,440", "timestamp_s": 963.0}, {"text": "Sometimes you would\u0027ve played the game before and would remember it from", "timestamp": "00:16:05,960", "timestamp_s": 965.0}, {"text": "previous instances, but I think in most cases you are supposed to be asking", "timestamp": "00:16:10,750", "timestamp_s": 970.0}, {"text": "each other questions that you\u0027ve never heard before and making connections", "timestamp": "00:16:16,560", "timestamp_s": 976.0}, {"text": "that you\u0027ve never made before and basically thinking outside the box.", "timestamp": "00:16:21,240", "timestamp_s": 981.0}, {"text": "So that was this, the test that I was like performing on g PT three.", "timestamp": "00:16:25,430", "timestamp_s": 985.0}, {"text": "So at the point I was like it could be a part of the corpus that it was trained on.", "timestamp": "00:16:31,200", "timestamp_s": 991.0}, {"text": "So I decided that I was going to look up riddles in another language,", "timestamp": "00:16:35,970", "timestamp_s": 995.0}, {"text": "and in this case it was Hindi.", "timestamp": "00:16:41,280", "timestamp_s": 1001.0}, {"text": "I\u0027m just going to translate them.", "timestamp": "00:16:43,280", "timestamp_s": 1003.0}, {"text": "And I\u0027m going to ask Chad, GPD, those riddles because I was assuming", "timestamp": "00:16:45,400", "timestamp_s": 1005.0}, {"text": "that it would not have been trained on data that was available on the", "timestamp": "00:16:50,130", "timestamp_s": 1010.0}, {"text": "internet in a language other than English and did not have any sort of", "timestamp": "00:16:54,470", "timestamp_s": 1014.0}, {"text": "corresponding English translation.", "timestamp": "00:16:59,380", "timestamp_s": 1019.0}, {"text": "So some of these examples are from that data.", "timestamp": "00:17:01,920", "timestamp_s": 1021.0}, {"text": "For instance, Ajay\u0027s parents have three sons, which I wish, and the third son is.", "timestamp": "00:17:05,360", "timestamp_s": 1025.0}, {"text": "It does get it right.", "timestamp": "00:17:11,110", "timestamp_s": 1031.0}, {"text": "It\u0027s like Ajay is the third son.", "timestamp": "00:17:12,100", "timestamp_s": 1032.0}, {"text": "This is something that actually stumps a lot of humans who has", "timestamp": "00:17:14,430", "timestamp_s": 1034.0}, {"text": "many words but does not speak.", "timestamp": "00:17:18,680", "timestamp_s": 1038.0}, {"text": "This is a real, the answer is a book because a book contains many", "timestamp": "00:17:20,600", "timestamp_s": 1040.0}, {"text": "words but does not speak a car.", "timestamp": "00:17:24,200", "timestamp_s": 1044.0}, {"text": "Gives milk a hand gives an egg, which gives both milk and egg.", "timestamp": "00:17:26,530", "timestamp_s": 1046.0}, {"text": "D so as you can see, this is like an extremely crudely translated version", "timestamp": "00:17:30,550", "timestamp_s": 1050.0}, {"text": "of a rootle that I think was either in Hindi or some regional language.", "timestamp": "00:17:36,120", "timestamp_s": 1056.0}, {"text": "And it comes up with the weirdest story you\u0027ve ever heard.", "timestamp": "00:17:42,560", "timestamp_s": 1062.0}, {"text": "It\u0027s what is riddle?", "timestamp": "00:17:46,020", "timestamp_s": 1066.0}, {"text": "And the answer is a duck.", "timestamp": "00:17:47,160", "timestamp_s": 1067.0}, {"text": "Ducks are domesticated bulls that are kept for their eggs, meat, and feathers.", "timestamp": "00:17:48,780", "timestamp_s": 1068.0}, {"text": "They\u0027re also known to give milk, which can be used to make dairy", "timestamp": "00:17:53,490", "timestamp_s": 1073.0}, {"text": "products like cheese and butter.", "timestamp": "00:17:56,700", "timestamp_s": 1076.0}, {"text": "And at the point I basically wondered if there was like a brand called Duck", "timestamp": "00:17:59,420", "timestamp_s": 1079.0}, {"text": "Dairy Farm or something, which would basically trick a language model into", "timestamp": "00:18:04,750", "timestamp_s": 1084.0}, {"text": "believing that there is such a thing as a duck giving milk and eggs or something.", "timestamp": "00:18:11,100", "timestamp_s": 1091.0}, {"text": "Another two ants, head of ants, two ants behind ants", "timestamp": "00:18:18,980", "timestamp_s": 1098.0}, {"text": "say, how many ants this riddle?", "timestamp": "00:18:23,660", "timestamp_s": 1103.0}, {"text": "The answer is two ants.", "timestamp": "00:18:26,350", "timestamp_s": 1106.0}, {"text": "And the actual answer is three ants.", "timestamp": "00:18:28,200", "timestamp_s": 1108.0}, {"text": "And like it actually makes no sense that it got this wrong.", "timestamp": "00:18:31,535", "timestamp_s": 1111.0}, {"text": "But I\u0027m pretty sure if I had put in something like two ducks ahead of ducks,", "timestamp": "00:18:35,455", "timestamp_s": 1115.0}, {"text": "two ducks behind ducks, how many ducks?", "timestamp": "00:18:41,845", "timestamp_s": 1121.0}, {"text": "It would say three ducks.", "timestamp": "00:18:45,445", "timestamp_s": 1125.0}, {"text": "Because the classic griddle is with ducks and not ants.", "timestamp": "00:18:47,145", "timestamp_s": 1127.0}, {"text": "So if you\u0027re using a productive model with respect to language that does not", "timestamp": "00:18:51,285", "timestamp_s": 1131.0}, {"text": "actually intuitively understand what you\u0027re saying in the sense that it\u0027s", "timestamp": "00:18:56,025", "timestamp_s": 1136.0}, {"text": "not able to imagine, it\u0027s not able to imagine in its mind that there\u0027s two ants", "timestamp": "00:19:00,875", "timestamp_s": 1140.0}, {"text": "ahead of ants and two ants behind ants.", "timestamp": "00:19:08,985", "timestamp_s": 1148.0}, {"text": "So how many ants?", "timestamp": "00:19:13,025", "timestamp_s": 1153.0}, {"text": "It\u0027s an imaginative question.", "timestamp": "00:19:14,555", "timestamp_s": 1154.0}, {"text": "You have to be able to visualize.", "timestamp": "00:19:15,905", "timestamp_s": 1155.0}, {"text": "The end.", "timestamp": "00:19:18,505", "timestamp_s": 1158.0}, {"text": "It would rely on previous training and it would rely on everything that people", "timestamp": "00:19:19,875", "timestamp_s": 1159.0}, {"text": "would have ever said to it, like history.", "timestamp": "00:19:24,735", "timestamp_s": 1164.0}, {"text": "It would be remembering things or it would be if you tell it like the task", "timestamp": "00:19:28,675", "timestamp_s": 1168.0}, {"text": "is to identify upon or to make upon.", "timestamp": "00:19:33,175", "timestamp_s": 1173.0}, {"text": "It would be making or like mimicking a pun, which means it would not", "timestamp": "00:19:35,905", "timestamp_s": 1175.0}, {"text": "necessarily get the right answer that you want it to get, which I", "timestamp": "00:19:40,965", "timestamp_s": 1180.0}, {"text": "do believe most humans are capable.", "timestamp": "00:19:47,745", "timestamp_s": 1187.0}, {"text": "Capable, they\u0027re able to get to the right answer when they\u0027re", "timestamp": "00:19:50,505", "timestamp_s": 1190.0}, {"text": "playing riddles with each other.", "timestamp": "00:19:54,015", "timestamp_s": 1194.0}, {"text": "What is the thing that can be soaked in the rain?", "timestamp": "00:19:56,015", "timestamp_s": 1196.0}, {"text": "It can never get wet.", "timestamp": "00:19:58,535", "timestamp_s": 1198.0}, {"text": "This is a riddle.", "timestamp": "00:20:00,315", "timestamp_s": 1200.0}, {"text": "The answer is a sponge because it absorbs water or stokes", "timestamp": "00:20:01,485", "timestamp_s": 1201.0}, {"text": "it up, but it never gets wet.", "timestamp": "00:20:04,725", "timestamp_s": 1204.0}, {"text": "That\u0027s not the right answer actually.", "timestamp": "00:20:06,995", "timestamp_s": 1206.0}, {"text": "It\u0027s something like watch or never gets wet or something.", "timestamp": "00:20:08,435", "timestamp_s": 1208.0}, {"text": "It\u0027s a classic griddle, but I don\u0027t think it\u0027s like that popular", "timestamp": "00:20:11,835", "timestamp_s": 1211.0}, {"text": "in English as opposed to the regional language that it came from", "timestamp": "00:20:15,375", "timestamp_s": 1215.0}, {"text": "is, so tell me what\u0027s in your pockets?", "timestamp": "00:20:19,595", "timestamp_s": 1219.0}, {"text": "Zhan replied, there is something in my pocket and nothing in my pocket.", "timestamp": "00:20:22,415", "timestamp_s": 1222.0}, {"text": "Tell me how can this happen?", "timestamp": "00:20:27,605", "timestamp_s": 1227.0}, {"text": "And it just basically went on like this philosophical rant", "timestamp": "00:20:29,395", "timestamp_s": 1229.0}, {"text": "that I was not expecting.", "timestamp": "00:20:32,845", "timestamp_s": 1232.0}, {"text": "And it\u0027s very interesting to me, to be honest.", "timestamp": "00:20:34,255", "timestamp_s": 1234.0}, {"text": "\u0027cause it\u0027s, it reads almost like philosophical essay of salts.", "timestamp": "00:20:36,415", "timestamp_s": 1236.0}, {"text": "It\u0027s this is a riddle.", "timestamp": "00:20:40,465", "timestamp_s": 1240.0}, {"text": "Sohan replied that there is something in his pocket and nothing", "timestamp": "00:20:42,115", "timestamp_s": 1242.0}, {"text": "in his pocket, like scro of salts.", "timestamp": "00:20:45,025", "timestamp_s": 1245.0}, {"text": "Which means that he was carrying an empty pocket.", "timestamp": "00:20:48,205", "timestamp_s": 1248.0}, {"text": "An empty pocket is something because it is physically", "timestamp": "00:20:50,485", "timestamp_s": 1250.0}, {"text": "present, but it contains nothing.", "timestamp": "00:20:53,905", "timestamp_s": 1253.0}, {"text": "The answer was that he had a hole in his pocket, actually, so nothing but", "timestamp": "00:20:56,325", "timestamp_s": 1256.0}, {"text": "there was a hole in his pocket, so there was actually something in his pocket.", "timestamp": "00:21:01,685", "timestamp_s": 1261.0}, {"text": "What is the thing that always increases but never decreases?", "timestamp": "00:21:05,965", "timestamp_s": 1265.0}, {"text": "This?", "timestamp": "00:21:09,825", "timestamp_s": 1269.0}, {"text": "The answer is age or time, because it always goes forward", "timestamp": "00:21:10,515", "timestamp_s": 1270.0}, {"text": "and never goes backward.", "timestamp": "00:21:14,235", "timestamp_s": 1274.0}, {"text": "There are 10 birds sitting on a wall.", "timestamp": "00:21:16,085", "timestamp_s": 1276.0}, {"text": "A person shoots one of them with an arrow.", "timestamp": "00:21:17,945", "timestamp_s": 1277.0}, {"text": "How many are left?", "timestamp": "00:21:20,285", "timestamp_s": 1280.0}, {"text": "There would be nine birds left on the wall.", "timestamp": "00:21:21,625", "timestamp_s": 1281.0}, {"text": "If one bird is shot with a arrow, there will be one fewer birds on the wall.", "timestamp": "00:21:23,455", "timestamp_s": 1283.0}, {"text": "Practically impossible.", "timestamp": "00:21:28,695", "timestamp_s": 1288.0}, {"text": "Most of the birds would have, they would just basically fly away, right?", "timestamp": "00:21:29,745", "timestamp_s": 1289.0}, {"text": "They would fly away.", "timestamp": "00:21:33,630", "timestamp_s": 1293.0}, {"text": "In reality, in physical reality, if there were 10 boats sitting on a wall", "timestamp": "00:21:34,410", "timestamp_s": 1294.0}, {"text": "and you shot one of them with an arrow, all of the other boats would fly away.", "timestamp": "00:21:39,510", "timestamp_s": 1299.0}, {"text": "And that\u0027s the answer that you\u0027re looking for.", "timestamp": "00:21:44,450", "timestamp_s": 1304.0}, {"text": "Either all of them fly away or some of them fly away,", "timestamp": "00:21:46,010", "timestamp_s": 1306.0}, {"text": "but the answer is ambiguous.", "timestamp": "00:21:49,180", "timestamp_s": 1309.0}, {"text": "It\u0027s not as simple as there would be nine boats left on the wall.", "timestamp": "00:21:50,770", "timestamp_s": 1310.0}, {"text": "At this point, Chad, GPT basically didn\u0027t know the behavior of boats in the sense", "timestamp": "00:21:55,390", "timestamp_s": 1315.0}, {"text": "of oh, if one bird is shot, when there there was like 10 boats sitting on a wall.", "timestamp": "00:22:01,490", "timestamp_s": 1321.0}, {"text": "It didn\u0027t know that birds fly away.", "timestamp": "00:22:07,210", "timestamp_s": 1327.0}, {"text": "It was basically treating birds as if they were like inanimate objects like", "timestamp": "00:22:09,630", "timestamp_s": 1329.0}, {"text": "bolts and not like real living beings.", "timestamp": "00:22:14,480", "timestamp_s": 1334.0}, {"text": "People making their own decisions and such and reacting to stimuli.", "timestamp": "00:22:18,630", "timestamp_s": 1338.0}, {"text": "As you can see, I was getting like extremely interesting", "timestamp": "00:22:24,200", "timestamp_s": 1344.0}, {"text": "signals from this whole exercise.", "timestamp": "00:22:26,660", "timestamp_s": 1346.0}, {"text": "And I just decided to go forward with everything else, which is a room that", "timestamp": "00:22:29,320", "timestamp_s": 1349.0}, {"text": "has neither or window nor a door.", "timestamp": "00:22:33,170", "timestamp_s": 1353.0}, {"text": "This or riddle.", "timestamp": "00:22:35,270", "timestamp_s": 1355.0}, {"text": "The answer is a mushroom.", "timestamp": "00:22:36,290", "timestamp_s": 1356.0}, {"text": "A mushroom is the type of fungus that grows in the ground.", "timestamp": "00:22:38,330", "timestamp_s": 1358.0}, {"text": "It does not have windows or doors.", "timestamp": "00:22:41,210", "timestamp_s": 1361.0}, {"text": "Now, this is a pun because it\u0027s a mushroom.", "timestamp": "00:22:43,850", "timestamp_s": 1363.0}, {"text": "What is the thing that is broken and there is no sound even after breaking it.", "timestamp": "00:22:46,240", "timestamp_s": 1366.0}, {"text": "And the answer is an egg.", "timestamp": "00:22:50,820", "timestamp_s": 1370.0}, {"text": "Because when you break an egg, it makes no sound even though it\u0027s broken.", "timestamp": "00:22:53,280", "timestamp_s": 1373.0}, {"text": "I\u0027ve never met an egg that didn\u0027t make a sound when it was broken.", "timestamp": "00:22:58,040", "timestamp_s": 1378.0}, {"text": "And the real answer was silence.", "timestamp": "00:23:02,610", "timestamp_s": 1382.0}, {"text": "But it was like philosophical of thoughts.", "timestamp": "00:23:05,220", "timestamp_s": 1385.0}, {"text": "So if you would have ever read anything philosophical we broke silence.", "timestamp": "00:23:07,860", "timestamp_s": 1387.0}, {"text": "So now it\u0027s broken.", "timestamp": "00:23:11,990", "timestamp_s": 1391.0}, {"text": "And \u0027cause it was an abstract concept, like the silence was an abstract concept.", "timestamp": "00:23:14,920", "timestamp_s": 1394.0}, {"text": "So silence was broken basic English usage.", "timestamp": "00:23:21,070", "timestamp_s": 1401.0}, {"text": "At the point it didn\u0027t, I think it does better now, but one can never", "timestamp": "00:23:25,030", "timestamp_s": 1405.0}, {"text": "be sure if it\u0027s like because of the corpus or if it\u0027s just been trained on", "timestamp": "00:23:30,330", "timestamp_s": 1410.0}, {"text": "all of these examples or whether it\u0027s cheating in the sense of it\u0027s using RG.", "timestamp": "00:23:36,210", "timestamp_s": 1416.0}, {"text": "Which is where it\u0027s like straight up looking up answers for all of these", "timestamp": "00:23:42,270", "timestamp_s": 1422.0}, {"text": "questions on the web, which is not what you want your friend to do if", "timestamp": "00:23:46,080", "timestamp_s": 1426.0}, {"text": "you\u0027re playing riddles with them, or if you are testing like a bot or a large", "timestamp": "00:23:49,940", "timestamp_s": 1429.0}, {"text": "language model for prices of aj, you basically don\u0027t want them to be cheating.", "timestamp": "00:23:55,340", "timestamp_s": 1435.0}, {"text": "That\u0027s useful for all other sort of sorts of tasks and we\u0027ll get back to why it", "timestamp": "00:24:01,610", "timestamp_s": 1441.0}, {"text": "could actually be fatal like the misuse of our age and all those sort of things", "timestamp": "00:24:07,300", "timestamp_s": 1447.0}, {"text": "to accomplish even practical tasks.", "timestamp": "00:24:12,520", "timestamp_s": 1452.0}, {"text": "But at this point I was getting like some extremely interesting", "timestamp": "00:24:15,610", "timestamp_s": 1455.0}, {"text": "singings and I decided to continue.", "timestamp": "00:24:20,230", "timestamp_s": 1460.0}, {"text": "So I was like let me try instead of gently prompting it, I just", "timestamp": "00:24:22,800", "timestamp_s": 1462.0}, {"text": "want to negate what it said to me.", "timestamp": "00:24:27,040", "timestamp_s": 1467.0}, {"text": "Because that is what you would do to a friend, right?", "timestamp": "00:24:29,710", "timestamp_s": 1469.0}, {"text": "If they gave you like the wrong answer, you\u0027d be like eggs", "timestamp": "00:24:32,690", "timestamp_s": 1472.0}, {"text": "do make a sound when broke.", "timestamp": "00:24:35,920", "timestamp_s": 1475.0}, {"text": "And then it was like it just basically justified there are many riddles and", "timestamp": "00:24:37,950", "timestamp_s": 1477.0}, {"text": "they can all have multiple answers.", "timestamp": "00:24:42,400", "timestamp_s": 1482.0}, {"text": "And I was like, depending on the interpretation of the words,", "timestamp": "00:24:44,890", "timestamp_s": 1484.0}, {"text": "et cetera, et cetera, it never actually gave me the right answer.", "timestamp": "00:24:48,310", "timestamp_s": 1488.0}, {"text": "So I basically decided to continue because I had like bunch of signals, but it\u0027s", "timestamp": "00:24:52,430", "timestamp_s": 1492.0}, {"text": "always nice to get even more signals.", "timestamp": "00:24:56,630", "timestamp_s": 1496.0}, {"text": "And I was like, you are in a running race.", "timestamp": "00:25:00,310", "timestamp_s": 1500.0}, {"text": "You crossed the person who is in the second place.", "timestamp": "00:25:02,920", "timestamp_s": 1502.0}, {"text": "In which place are you now?", "timestamp": "00:25:05,710", "timestamp_s": 1505.0}, {"text": "And it\u0027s if you cross the person who is in the second place during a race, you are", "timestamp": "00:25:07,325", "timestamp_s": 1507.0}, {"text": "now in the second place which is right.", "timestamp": "00:25:11,405", "timestamp_s": 1511.0}, {"text": "If you use me, you can walk through walls.", "timestamp": "00:25:14,355", "timestamp_s": 1514.0}, {"text": "What am I, this is a window.", "timestamp": "00:25:16,335", "timestamp_s": 1516.0}, {"text": "The answer is a key because a key can open a door allowing you to walk through walls.", "timestamp": "00:25:18,185", "timestamp_s": 1518.0}, {"text": "The answer was actually a door, but I guess it was like this is real mode.", "timestamp": "00:25:22,925", "timestamp_s": 1522.0}, {"text": "The answer can\u0027t be like that simple.", "timestamp": "00:25:26,875", "timestamp_s": 1526.0}, {"text": "And it\u0027s let me make it even more deeper.", "timestamp": "00:25:29,065", "timestamp_s": 1529.0}, {"text": "Or you need like a key to open a door.", "timestamp": "00:25:31,530", "timestamp_s": 1531.0}, {"text": "And that\u0027s the only way you can walk through walls though you can see exactly", "timestamp": "00:25:34,775", "timestamp_s": 1534.0}, {"text": "how the thinking is working as opposed to.", "timestamp": "00:25:41,345", "timestamp_s": 1541.0}, {"text": "When you are like prompt training it and telling it, you have to", "timestamp": "00:25:44,965", "timestamp_s": 1544.0}, {"text": "tell me what you\u0027re thinking or you have to like, think in layers.", "timestamp": "00:25:48,145", "timestamp_s": 1548.0}, {"text": "You have to first think about step A step one and then step two, and then you have", "timestamp": "00:25:51,735", "timestamp_s": 1551.0}, {"text": "to think about why you went to step three.", "timestamp": "00:25:56,825", "timestamp_s": 1556.0}, {"text": "And you have to think about why you have to do tasks A, B, C, D before you", "timestamp": "00:25:59,645", "timestamp_s": 1559.0}, {"text": "can come to step eight or something.", "timestamp": "00:26:05,785", "timestamp_s": 1565.0}, {"text": "And it gives you like this longish answer, but there\u0027s like other ways", "timestamp": "00:26:08,115", "timestamp_s": 1568.0}, {"text": "to see what an LLM is thinking.", "timestamp": "00:26:11,945", "timestamp_s": 1571.0}, {"text": "And this is like one of those cases, right?", "timestamp": "00:26:14,675", "timestamp_s": 1574.0}, {"text": "Where you\u0027re just treating it like a black box and you\u0027re bombarding it with", "timestamp": "00:26:16,945", "timestamp_s": 1576.0}, {"text": "signals and you get back some signals and you can derive some inferences from", "timestamp": "00:26:20,425", "timestamp_s": 1580.0}, {"text": "those signals as long as the signals that you\u0027re getting back are not Abacus which", "timestamp": "00:26:25,865", "timestamp_s": 1585.0}, {"text": "is why you basically have to probe it.", "timestamp": "00:26:32,005", "timestamp_s": 1592.0}, {"text": "For one particular area in like multiple different ways so you", "timestamp": "00:26:34,245", "timestamp_s": 1594.0}, {"text": "can get some solid signals.", "timestamp": "00:26:38,505", "timestamp_s": 1598.0}, {"text": "So my next question was, because this is not riddle at this point,", "timestamp": "00:26:40,065", "timestamp_s": 1600.0}, {"text": "I\u0027m like let me just ask it math.", "timestamp": "00:26:43,965", "timestamp_s": 1603.0}, {"text": "I\u0027m like, how many times can you subtract 10 from 50?", "timestamp": "00:26:46,115", "timestamp_s": 1606.0}, {"text": "And I think it was like we are still in riddle mode, so it\u0027s oh, this is", "timestamp": "00:26:49,345", "timestamp_s": 1609.0}, {"text": "the state and you can only do it once because the state was 50 and then it", "timestamp": "00:26:53,895", "timestamp_s": 1613.0}, {"text": "goes to 40, so you can\u0027t do it again.", "timestamp": "00:27:00,565", "timestamp_s": 1620.0}, {"text": "I would argue", "timestamp": "00:27:03,165", "timestamp_s": 1623.0}, {"text": "like both would be wild answers in the sense that if someone said five times.", "timestamp": "00:27:04,395", "timestamp_s": 1624.0}, {"text": "Or if someone said that the state has changed, so it\u0027s now", "timestamp": "00:27:09,685", "timestamp_s": 1629.0}, {"text": "40, so you can\u0027t do it again.", "timestamp": "00:27:14,305", "timestamp_s": 1634.0}, {"text": "And then I was like I have many keys but no locks.", "timestamp": "00:27:16,965", "timestamp_s": 1636.0}, {"text": "I have space but no room.", "timestamp": "00:27:20,535", "timestamp_s": 1640.0}, {"text": "You can enter but cannot go out.", "timestamp": "00:27:22,395", "timestamp_s": 1642.0}, {"text": "Why am I?", "timestamp": "00:27:24,435", "timestamp_s": 1644.0}, {"text": "And it\u0027s the riddle, the answer is keyboard.", "timestamp": "00:27:25,295", "timestamp_s": 1645.0}, {"text": "\u0027cause keyboard has many keys which are used.", "timestamp": "00:27:28,485", "timestamp_s": 1648.0}, {"text": "And that is actually the right answer, but I\u0027m not, at this point, we are not too", "timestamp": "00:27:31,265", "timestamp_s": 1651.0}, {"text": "sure if it\u0027s because it\u0027s seen the riddle before or if it\u0027s actually thinking it", "timestamp": "00:27:36,605", "timestamp_s": 1656.0}, {"text": "through and getting to the right answer.", "timestamp": "00:27:43,625", "timestamp_s": 1663.0}, {"text": "So we shifted back to like ambiguous question territory as opposed", "timestamp": "00:27:46,255", "timestamp_s": 1666.0}, {"text": "to straight up physical riddles.", "timestamp": "00:27:50,395", "timestamp_s": 1670.0}, {"text": "And there is a slight shift from one to the other, from one to the other because", "timestamp": "00:27:54,145", "timestamp_s": 1674.0}, {"text": "I\u0027m like experimenting with different genres and also experimenting with a lot", "timestamp": "00:27:59,485", "timestamp_s": 1679.0}, {"text": "of like regional language and the sort of language they use to ask questions because", "timestamp": "00:28:04,135", "timestamp_s": 1684.0}, {"text": "I was hoping that some of it would have never been translated and would have never", "timestamp": "00:28:10,045", "timestamp_s": 1690.0}, {"text": "been a part of the corpus of the training of this particular language model.", "timestamp": "00:28:14,305", "timestamp_s": 1694.0}, {"text": "\u0027cause it would give me some better signals.", "timestamp": "00:28:18,405", "timestamp_s": 1698.0}, {"text": "So I was like, there are two mothers and two daughters in a car,", "timestamp": "00:28:21,225", "timestamp_s": 1701.0}, {"text": "but there are only three people.", "timestamp": "00:28:24,015", "timestamp_s": 1704.0}, {"text": "Is that possible?", "timestamp": "00:28:25,365", "timestamp_s": 1705.0}, {"text": "And it was like.", "timestamp": "00:28:26,705", "timestamp_s": 1706.0}, {"text": "The three people are a grandmother, her daughter and her granddaughter.", "timestamp": "00:28:28,465", "timestamp_s": 1708.0}, {"text": "The grandmother is the mother of the daughter, and the daughter is", "timestamp": "00:28:31,855", "timestamp_s": 1711.0}, {"text": "the mother of the granddaughter.", "timestamp": "00:28:35,185", "timestamp_s": 1715.0}, {"text": "So there are two mothers and two daughters.", "timestamp": "00:28:36,235", "timestamp_s": 1716.0}, {"text": "We\u0027re only three people.", "timestamp": "00:28:38,575", "timestamp_s": 1718.0}, {"text": "That\u0027s right.", "timestamp": "00:28:40,255", "timestamp_s": 1720.0}, {"text": "Which is like the z real question or the S question.", "timestamp": "00:28:41,325", "timestamp_s": 1721.0}, {"text": "But at that point it didn\u0027t matter, like whether you\u0027re using apples or", "timestamp": "00:28:46,175", "timestamp_s": 1726.0}, {"text": "oranges to ask cha gpi a question.", "timestamp": "00:28:50,495", "timestamp_s": 1730.0}, {"text": "\u0027 cause it was relying specifically on not intuitive understanding of the", "timestamp": "00:28:53,575", "timestamp_s": 1733.0}, {"text": "language itself, but rather straight up predictive modeling of the next", "timestamp": "00:28:58,105", "timestamp_s": 1738.0}, {"text": "token in the English language.", "timestamp": "00:29:03,615", "timestamp_s": 1743.0}, {"text": "Two of them are identical in looking and they say they are not twins.", "timestamp": "00:29:06,215", "timestamp_s": 1746.0}, {"text": "Is that possible?", "timestamp": "00:29:09,725", "timestamp_s": 1749.0}, {"text": "And, it just went on like this philosophical sort of answer to it", "timestamp": "00:29:11,275", "timestamp_s": 1751.0}, {"text": "that it\u0027s possible for two women to look identical and not be twins.", "timestamp": "00:29:17,085", "timestamp_s": 1757.0}, {"text": "And it could be due to genetic similarities or cosmetic procedures", "timestamp": "00:29:21,645", "timestamp_s": 1761.0}, {"text": "or they could be sisters or cousins or unrelated, but just look alike.", "timestamp": "00:29:26,045", "timestamp_s": 1766.0}, {"text": "I think this is a classic ritual and it ties a more poetic answer of sorts, which", "timestamp": "00:29:30,985", "timestamp_s": 1770.0}, {"text": "I don\u0027t remember off the top of my head, but it does have an interesting answer", "timestamp": "00:29:35,125", "timestamp_s": 1775.0}, {"text": "and that has nothing to do with Gentech.", "timestamp": "00:29:38,925", "timestamp_s": 1778.0}, {"text": "But you can see as I ask it questions, it\u0027s sometimes it\u0027s I\u0027m in riddle context.", "timestamp": "00:29:41,565", "timestamp_s": 1781.0}, {"text": "And sometimes it\u0027s I\u0027m not in riddle context.", "timestamp": "00:29:47,555", "timestamp_s": 1787.0}, {"text": "And we, as the answer of the questions, I have no choice.", "timestamp": "00:29:50,165", "timestamp_s": 1790.0}, {"text": "At least in this case, I had no choice.", "timestamp": "00:29:54,565", "timestamp_s": 1794.0}, {"text": "It would flip through the riddle context.", "timestamp": "00:29:57,355", "timestamp_s": 1797.0}, {"text": "Out of the riddle context into the non riddle world all by itself.", "timestamp": "00:30:00,150", "timestamp_s": 1800.0}, {"text": "So I was like can there not be triplets?", "timestamp": "00:30:05,000", "timestamp_s": 1805.0}, {"text": "And then was like, yeah they could be triplets.", "timestamp": "00:30:07,330", "timestamp_s": 1807.0}, {"text": "So back it was like a lady was buying fridges for 10,000 rupees and", "timestamp": "00:30:09,710", "timestamp_s": 1809.0}, {"text": "selling there for 5,000 rupe after a few years she became a millionaire.", "timestamp": "00:30:15,290", "timestamp_s": 1815.0}, {"text": "How?", "timestamp": "00:30:20,120", "timestamp_s": 1820.0}, {"text": "And then it goes back into this whole sort of like storytelling adventure of sorts.", "timestamp": "00:30:20,980", "timestamp_s": 1820.0}, {"text": "And it\u0027s she was not actually buying and selling fridges she was", "timestamp": "00:30:26,470", "timestamp_s": 1826.0}, {"text": "selling the shares of the company.", "timestamp": "00:30:30,620", "timestamp_s": 1830.0}, {"text": "That actually makes no sense because the company is operating on lots or", "timestamp": "00:30:33,010", "timestamp_s": 1833.0}, {"text": "like she was operating a lot apparent.", "timestamp": "00:30:38,140", "timestamp_s": 1838.0}, {"text": "The answer is like as funny as well.", "timestamp": "00:30:40,630", "timestamp_s": 1840.0}, {"text": "She was a billionaire and she was operating on lots.", "timestamp": "00:30:42,580", "timestamp_s": 1842.0}, {"text": "So now she\u0027s a millionaire, which is another classic griddle.", "timestamp": "00:30:45,570", "timestamp_s": 1845.0}, {"text": "But the way you phrase it, depending upon how it has been trained on what sort", "timestamp": "00:30:48,860", "timestamp_s": 1848.0}, {"text": "of tokens and what sort of direction of tokens, it would either make up a story", "timestamp": "00:30:54,910", "timestamp_s": 1854.0}, {"text": "or it would give you the right answer.", "timestamp": "00:31:00,630", "timestamp_s": 1860.0}, {"text": "Like the same rhythm.", "timestamp": "00:31:02,640", "timestamp_s": 1862.0}, {"text": "If you phrase it in a different narrative of thoughts, it would", "timestamp": "00:31:03,690", "timestamp_s": 1863.0}, {"text": "give you the wrong answers.", "timestamp": "00:31:09,250", "timestamp_s": 1869.0}, {"text": "If it were something like, there was a man who married a woman.", "timestamp": "00:31:11,040", "timestamp_s": 1871.0}, {"text": "\u0027cause that\u0027s how the class girl goes.", "timestamp": "00:31:14,810", "timestamp_s": 1874.0}, {"text": "And he used to be a billionaire and she basically made him a millionaire.", "timestamp": "00:31:17,230", "timestamp_s": 1877.0}, {"text": "It\u0027s like classic white choke of sorts.", "timestamp": "00:31:20,970", "timestamp_s": 1880.0}, {"text": "If you had feted that it would give you the right answer actually.", "timestamp": "00:31:23,550", "timestamp_s": 1883.0}, {"text": "So back to riddle.", "timestamp": "00:31:27,200", "timestamp_s": 1887.0}, {"text": "What can jump higher than a building?", "timestamp": "00:31:28,790", "timestamp_s": 1888.0}, {"text": "The riddle, the answer is everything.", "timestamp": "00:31:30,805", "timestamp_s": 1890.0}, {"text": "Because a building gun jump,", "timestamp": "00:31:32,930", "timestamp_s": 1892.0}, {"text": "which is heavier, one kilogram of iron or one kilogram of cotton, a kilogram", "timestamp": "00:31:34,900", "timestamp_s": 1894.0}, {"text": "of iron and a kilogram of cotton would weigh the same one kilogram.", "timestamp": "00:31:40,530", "timestamp_s": 1900.0}, {"text": "The weight of an object is deta mean by its mass, which is measured in kilograms.", "timestamp": "00:31:44,580", "timestamp_s": 1904.0}, {"text": "One kilogram is the base unit of mass.", "timestamp": "00:31:49,340", "timestamp_s": 1909.0}, {"text": "In the international system of units, they\u0027re both iron and", "timestamp": "00:31:51,700", "timestamp_s": 1911.0}, {"text": "cotton would weigh one kilogram.", "timestamp": "00:31:54,970", "timestamp_s": 1914.0}, {"text": "Actually, I\u0027ve gotten this wrong.", "timestamp": "00:31:56,950", "timestamp_s": 1916.0}, {"text": "Me as a human being, I\u0027ve gotten this riddle wrong because they used to be like", "timestamp": "00:31:59,050", "timestamp_s": 1919.0}, {"text": "this famous riddle story of thoughts.", "timestamp": "00:32:03,560", "timestamp_s": 1923.0}, {"text": "Where in order to make the one kilogram of cotton heavier", "timestamp": "00:32:06,870", "timestamp_s": 1926.0}, {"text": "people would soak it up in water.", "timestamp": "00:32:10,960", "timestamp_s": 1930.0}, {"text": "Bacteria, Dolly\u0027s mother had five children.", "timestamp": "00:32:13,080", "timestamp_s": 1933.0}, {"text": "She named four of them.", "timestamp": "00:32:16,110", "timestamp_s": 1936.0}, {"text": "January, February, March, and April.", "timestamp": "00:32:17,610", "timestamp_s": 1937.0}, {"text": "What is the name of the fifth child?", "timestamp": "00:32:20,370", "timestamp_s": 1940.0}, {"text": "And Ji please like Dolly.", "timestamp": "00:32:22,115", "timestamp_s": 1942.0}, {"text": "That\u0027s right.", "timestamp": "00:32:24,755", "timestamp_s": 1944.0}, {"text": "A man and his son met with an accident.", "timestamp": "00:32:25,825", "timestamp_s": 1945.0}, {"text": "The man died and his son was taken to the hospital and the doctor said,", "timestamp": "00:32:28,165", "timestamp_s": 1948.0}, {"text": "I cannot operate as he\u0027s my son.", "timestamp": "00:32:32,475", "timestamp_s": 1952.0}, {"text": "How\u0027s this possible?", "timestamp": "00:32:34,485", "timestamp_s": 1954.0}, {"text": "And Chachi pretty basically was like that\u0027s straight if not possible.", "timestamp": "00:32:35,975", "timestamp_s": 1955.0}, {"text": "And it goes against the law of GenX.", "timestamp": "00:32:40,425", "timestamp_s": 1960.0}, {"text": "Actually, the answer is the doctor is a mother, so the doctor is famous.", "timestamp": "00:32:42,255", "timestamp_s": 1962.0}, {"text": "Bact.", "timestamp": "00:32:47,665", "timestamp_s": 1967.0}, {"text": "There\u0027s a bowl of six mangoes.", "timestamp": "00:32:48,555", "timestamp_s": 1968.0}, {"text": "You took four mangoes.", "timestamp": "00:32:50,385", "timestamp_s": 1970.0}, {"text": "How many are you left with?", "timestamp": "00:32:51,495", "timestamp_s": 1971.0}, {"text": "And it, there\u0027s like mass confusion where it\u0027s like, whether you\u0027re", "timestamp": "00:32:53,075", "timestamp_s": 1973.0}, {"text": "left with two mangoes, no, the bowl is left with two mangoes.", "timestamp": "00:32:56,095", "timestamp_s": 1976.0}, {"text": "You have four mangoes \u0027cause you took four mangoes.", "timestamp": "00:33:00,295", "timestamp_s": 1980.0}, {"text": "So inversion of perspective.", "timestamp": "00:33:04,435", "timestamp_s": 1984.0}, {"text": "So we\u0027ll move on to like theater levels.", "timestamp": "00:33:06,705", "timestamp_s": 1986.0}, {"text": "There are five students in a room.", "timestamp": "00:33:09,425", "timestamp_s": 1989.0}, {"text": "RA is watching tv.", "timestamp": "00:33:11,615", "timestamp_s": 1991.0}, {"text": "Amar is playing chess.", "timestamp": "00:33:12,725", "timestamp_s": 1992.0}, {"text": "Anamika is reading, shoot is eating.", "timestamp": "00:33:14,255", "timestamp_s": 1994.0}, {"text": "Can you tell me what the fifth student is doing?", "timestamp": "00:33:16,895", "timestamp_s": 1996.0}, {"text": "And then it\u0027s it\u0027s impossible to deduce that except the answer is", "timestamp": "00:33:19,525", "timestamp_s": 1999.0}, {"text": "she\u0027s playing chess with thumb green because the question is very physical.", "timestamp": "00:33:24,595", "timestamp_s": 2004.0}, {"text": "Like they\u0027re not playing chess with a computer.", "timestamp": "00:33:29,445", "timestamp_s": 2009.0}, {"text": "Your parents have six sons and each son has a sister.", "timestamp": "00:33:32,045", "timestamp_s": 2012.0}, {"text": "How many kids do they have?", "timestamp": "00:33:35,675", "timestamp_s": 2015.0}, {"text": "And it does this like extremely classic mathematical thing of", "timestamp": "00:33:37,675", "timestamp_s": 2017.0}, {"text": "adding six to six and saying 12.", "timestamp": "00:33:40,795", "timestamp_s": 2020.0}, {"text": "The answer is supposed to be seven.", "timestamp": "00:33:43,165", "timestamp_s": 2023.0}, {"text": "How many apples can you eat with an empty stomach?", "timestamp": "00:33:45,075", "timestamp_s": 2025.0}, {"text": "The number of apples one can eat with an empty stomach would vary from person", "timestamp": "00:33:47,865", "timestamp_s": 2027.0}, {"text": "to person and depend upon the appetite.", "timestamp": "00:33:52,395", "timestamp_s": 2032.0}, {"text": "There\u0027s a classic trick of a state of thoughts.", "timestamp": "00:33:54,945", "timestamp_s": 2034.0}, {"text": "So once you\u0027ve eaten one apple, you don\u0027t have an empty stomach or", "timestamp": "00:33:58,695", "timestamp_s": 2038.0}, {"text": "like even a bite of an apple, you don\u0027t have name please, stomach.", "timestamp": "00:34:03,155", "timestamp_s": 2043.0}, {"text": "How can you share 10 mangoes equally between nine people?", "timestamp": "00:34:06,955", "timestamp_s": 2046.0}, {"text": "It\u0027s not possible.", "timestamp": "00:34:10,485", "timestamp_s": 2050.0}, {"text": "Basically cannot comprehend cutting at all.", "timestamp": "00:34:12,065", "timestamp_s": 2052.0}, {"text": "What loses a head in the morning and gains one at night?", "timestamp": "00:34:14,420", "timestamp_s": 2054.0}, {"text": "This is a riddle.", "timestamp": "00:34:17,680", "timestamp_s": 2057.0}, {"text": "The answer is pillow because a pillow loses its head in the morning, and", "timestamp": "00:34:18,910", "timestamp_s": 2058.0}, {"text": "when you wake it up and fluff it up, it gains one at night when you put", "timestamp": "00:34:22,540", "timestamp_s": 2062.0}, {"text": "it back under your head to sleep.", "timestamp": "00:34:26,730", "timestamp_s": 2066.0}, {"text": "Actually, very clever.", "timestamp": "00:34:28,850", "timestamp_s": 2068.0}, {"text": "What is it that has many keys but cannot even open one door?", "timestamp": "00:34:30,500", "timestamp_s": 2070.0}, {"text": "It\u0027s a little, the answer is a keyboard.", "timestamp": "00:34:34,130", "timestamp_s": 2074.0}, {"text": "That\u0027s true.", "timestamp": "00:34:36,610", "timestamp_s": 2076.0}, {"text": "Ramesh is the son of Raul.", "timestamp": "00:34:37,650", "timestamp_s": 2077.0}, {"text": "Raul is the watch of Ramesh\u0027s father.", "timestamp": "00:34:40,430", "timestamp_s": 2080.0}, {"text": "Ramesh\u0027s father is the father of Raul.", "timestamp": "00:34:43,150", "timestamp_s": 2083.0}, {"text": "That\u0027s wrong.", "timestamp": "00:34:45,330", "timestamp_s": 2085.0}, {"text": "Ramesh is the son of Rahul, and Rahul is Ramesh\u0027s father, basically.", "timestamp": "00:34:46,890", "timestamp_s": 2086.0}, {"text": "It just basically lost track of who\u0027s related to who in what, a way in the", "timestamp": "00:34:51,550", "timestamp_s": 2091.0}, {"text": "word problem, what can be as tall as you but doesn\u0027t weigh anything.", "timestamp": "00:34:58,000", "timestamp_s": 2098.0}, {"text": "And the answer is your shadow.", "timestamp": "00:35:02,450", "timestamp_s": 2102.0}, {"text": "That\u0027s right.", "timestamp": "00:35:04,130", "timestamp_s": 2104.0}, {"text": "A girl came into town on one day and after two days she left on Monday.", "timestamp": "00:35:05,200", "timestamp_s": 2105.0}, {"text": "Is this possible?", "timestamp": "00:35:09,160", "timestamp_s": 2109.0}, {"text": "So it goes into this whole philosophy of like why it could be Monday on both", "timestamp": "00:35:10,650", "timestamp_s": 2110.0}, {"text": "the day she came and she left, except in this case it\u0027s like thinking outside the", "timestamp": "00:35:16,710", "timestamp_s": 2116.0}, {"text": "box where Monday is either like the name of the boat that she came on, or like", "timestamp": "00:35:22,330", "timestamp_s": 2122.0}, {"text": "the name of the horse that she came on.", "timestamp": "00:35:27,009", "timestamp_s": 2127.0}, {"text": "And if you\u0027ve studied enough riddles or have been through like", "timestamp": "00:35:29,279", "timestamp_s": 2129.0}, {"text": "enough literature, which I\u0027m pretty sure GPD three at this point was.", "timestamp": "00:35:33,709", "timestamp_s": 2133.0}, {"text": "You would have recognized this as that sort of a riddle.", "timestamp": "00:35:38,120", "timestamp_s": 2138.0}, {"text": "So it\u0027s actually, it was very surprising to me to get this", "timestamp": "00:35:41,509", "timestamp_s": 2141.0}, {"text": "sort of a signal from it.", "timestamp": "00:35:45,080", "timestamp_s": 2145.0}, {"text": "A man was walking in the rain without any covering on his head, and yet", "timestamp": "00:35:46,690", "timestamp_s": 2146.0}, {"text": "even one hair strand didn\u0027t get wet.", "timestamp": "00:35:50,610", "timestamp_s": 2150.0}, {"text": "Is this possible?", "timestamp": "00:35:52,920", "timestamp_s": 2152.0}, {"text": "Yes.", "timestamp": "00:35:54,410", "timestamp_s": 2154.0}, {"text": "\u0027cause he was both.", "timestamp": "00:35:54,770", "timestamp_s": 2154.0}, {"text": "If your uncle\u0027s sister is not your aunt, what relation is she to you?", "timestamp": "00:35:56,140", "timestamp_s": 2156.0}, {"text": "She\u0027s your mother.", "timestamp": "00:36:01,350", "timestamp_s": 2161.0}, {"text": "That\u0027s right.", "timestamp": "00:36:02,250", "timestamp_s": 2162.0}, {"text": "A girl was 13 on her last birthday and will be 15 on her next birthday.", "timestamp": "00:36:03,780", "timestamp_s": 2163.0}, {"text": "Is that possible?", "timestamp": "00:36:08,670", "timestamp_s": 2168.0}, {"text": "Yes.", "timestamp": "00:36:10,130", "timestamp_s": 2170.0}, {"text": "Because it\u0027s her birthday today.", "timestamp": "00:36:11,120", "timestamp_s": 2171.0}, {"text": "That\u0027s what it means.", "timestamp": "00:36:14,320", "timestamp_s": 2174.0}, {"text": "But that\u0027s only possible on her birthday, like on her 14th birthday.", "timestamp": "00:36:16,560", "timestamp_s": 2176.0}, {"text": "It\u0027s not possible if it\u0027s one day later.", "timestamp": "00:36:21,150", "timestamp_s": 2181.0}, {"text": "One day before, but the answer doesn\u0027t specify that it has to be her birthday.", "timestamp": "00:36:24,435", "timestamp_s": 2184.0}, {"text": "On that specific deck, like her 14th birthday,", "timestamp": "00:36:29,705", "timestamp_s": 2189.0}, {"text": "you are in a room that has three switches on closed door.", "timestamp": "00:36:33,175", "timestamp_s": 2193.0}, {"text": "The switches controlled three light bulbs on the other side of the road door.", "timestamp": "00:36:36,115", "timestamp_s": 2196.0}, {"text": "Once you open the door, you may never touch the switches again.", "timestamp": "00:36:40,885", "timestamp_s": 2200.0}, {"text": "How can you definitively tell with switches connected", "timestamp": "00:36:45,235", "timestamp_s": 2205.0}, {"text": "to each of the light bulbs?", "timestamp": "00:36:48,265", "timestamp_s": 2208.0}, {"text": "And it goes into like this weird step by step of turn on switch one and", "timestamp": "00:36:49,935", "timestamp_s": 2209.0}, {"text": "leave it on for a while and then turn it off and open it and note which is", "timestamp": "00:36:55,235", "timestamp_s": 2215.0}, {"text": "warm to touch, et cetera, et cetera.", "timestamp": "00:37:01,315", "timestamp_s": 2221.0}, {"text": "Which.", "timestamp": "00:37:03,465", "timestamp_s": 2223.0}, {"text": "Doesn\u0027t make a lot of sense \u0027cause you\u0027ve told it that once you open the door", "timestamp": "00:37:04,355", "timestamp_s": 2224.0}, {"text": "you may never touch the switches again.", "timestamp": "00:37:08,645", "timestamp_s": 2228.0}, {"text": "So the answer that it gives is very close to the actual answer.", "timestamp": "00:37:10,975", "timestamp_s": 2230.0}, {"text": "\u0027cause it\u0027s, I don\u0027t think it\u0027s thinking through it, but it\u0027s definitely like", "timestamp": "00:37:14,515", "timestamp_s": 2234.0}, {"text": "predicting something by doing some sort of training corpus, it seems", "timestamp": "00:37:19,615", "timestamp_s": 2239.0}, {"text": "to be close to the actual answer.", "timestamp": "00:37:24,715", "timestamp_s": 2244.0}, {"text": "\u0027cause it\u0027s probably been a question that was similar to", "timestamp": "00:37:26,865", "timestamp_s": 2246.0}, {"text": "this one, but not quite this one.", "timestamp": "00:37:29,835", "timestamp_s": 2249.0}, {"text": "So it can\u0027t actually strategize even if it\u0027s mimicking the strategy", "timestamp": "00:37:32,775", "timestamp_s": 2252.0}, {"text": "of a completely different problem.", "timestamp": "00:37:37,985", "timestamp_s": 2257.0}, {"text": "\u0027 cause at this point it\u0027s just predicting and the prediction has almost nothing", "timestamp": "00:37:40,045", "timestamp_s": 2260.0}, {"text": "to do with what the actual question is versus what thinks the actual question is.", "timestamp": "00:37:47,015", "timestamp_s": 2267.0}, {"text": "In the context of a bag of words sort of behavior, which is really weird.", "timestamp": "00:37:53,565", "timestamp_s": 2273.0}, {"text": "A man is looking at a photograph of someone.", "timestamp": "00:37:58,985", "timestamp_s": 2278.0}, {"text": "His friend asks who it is, the man replies, brothers and sisters.", "timestamp": "00:38:00,995", "timestamp_s": 2280.0}, {"text": "I have none, but that man\u0027s father is my father\u0027s son who was in the photograph.", "timestamp": "00:38:06,155", "timestamp_s": 2286.0}, {"text": "The sister riddle.", "timestamp": "00:38:13,445", "timestamp_s": 2293.0}, {"text": "The man in the photograph is the man\u0027s own son.", "timestamp": "00:38:15,065", "timestamp_s": 2295.0}, {"text": "Actually, that\u0027s not true.", "timestamp": "00:38:18,155", "timestamp_s": 2298.0}, {"text": "Man\u0027s father is my father\u0027s son.", "timestamp": "00:38:19,945", "timestamp_s": 2299.0}, {"text": "No, it is actually true.", "timestamp": "00:38:22,455", "timestamp_s": 2302.0}, {"text": "So it did get right.", "timestamp": "00:38:23,715", "timestamp_s": 2303.0}, {"text": "I got it wrong this time.", "timestamp": "00:38:24,895", "timestamp_s": 2304.0}, {"text": "But it does go on this weird tangent of sorts where it\u0027s but the man of the", "timestamp": "00:38:27,325", "timestamp_s": 2307.0}, {"text": "photograph is his father\u0027s son, meaning he is his own son, which is wrong because", "timestamp": "00:38:31,665", "timestamp_s": 2311.0}, {"text": "when you\u0027re thinking of all of these relational problems, if you don\u0027t have", "timestamp": "00:38:37,765", "timestamp_s": 2317.0}, {"text": "space to visualize exactly what you\u0027re thinking, and because this is a language", "timestamp": "00:38:42,225", "timestamp_s": 2322.0}, {"text": "model, it actually doesn\u0027t have any space to visualize anything, any relations.", "timestamp": "00:38:46,835", "timestamp_s": 2326.0}, {"text": "And even if it doesn\u0027t have a lot of history to keep it in its memory space.", "timestamp": "00:38:52,755", "timestamp_s": 2332.0}, {"text": "So it would get, while it did get it right, it eventually got it", "timestamp": "00:38:57,705", "timestamp_s": 2337.0}, {"text": "wrong because it was like am I thinking in the right direction?", "timestamp": "00:39:02,495", "timestamp_s": 2342.0}, {"text": "In 1990, a person is 15 years old.", "timestamp": "00:39:06,595", "timestamp_s": 2346.0}, {"text": "In 1995, that same person is 10 years old.", "timestamp": "00:39:10,405", "timestamp_s": 2350.0}, {"text": "How can that be?", "timestamp": "00:39:14,485", "timestamp_s": 2354.0}, {"text": "There\u0027s a riddle.", "timestamp": "00:39:15,885", "timestamp_s": 2355.0}, {"text": "The answer is that the person in question is a set of twins, and", "timestamp": "00:39:16,635", "timestamp_s": 2356.0}, {"text": "one of them was born in 1990 and the other one was born in 1995.", "timestamp": "00:39:19,845", "timestamp_s": 2359.0}, {"text": "So in 1991, twin is 15 years old, and in 1995, the second twin is 10 years old.", "timestamp": "00:39:25,785", "timestamp_s": 2365.0}, {"text": "So clearly that\u0027s not the right answer.", "timestamp": "00:39:34,130", "timestamp_s": 2374.0}, {"text": "It\u0027s like it\u0027s BC as opposed to ad, which is why in 1990 BC the", "timestamp": "00:39:36,710", "timestamp_s": 2376.0}, {"text": "person is 15 years old and in 1995 BC the person is 10 years old.", "timestamp": "00:39:43,970", "timestamp_s": 2383.0}, {"text": "And it gives you like this extremely science fictiony answer to it.", "timestamp": "00:39:50,800", "timestamp_s": 2390.0}, {"text": "That doesn\u0027t make a lot of sense.", "timestamp": "00:39:55,800", "timestamp_s": 2395.0}, {"text": "Next one.", "timestamp": "00:39:57,650", "timestamp_s": 2397.0}, {"text": "Your parents have six sons, including you, and each son has one sister.", "timestamp": "00:39:58,610", "timestamp_s": 2398.0}, {"text": "How many people are in the family?", "timestamp": "00:40:04,190", "timestamp_s": 2404.0}, {"text": "So it\u0027s a little that I had asked it before and it\u0027s still got wrong.", "timestamp": "00:40:06,760", "timestamp_s": 2406.0}, {"text": "Like it, the six plus six equals 12, which is wrong.", "timestamp": "00:40:11,920", "timestamp_s": 2411.0}, {"text": "The right answer is supposed to be seven.", "timestamp": "00:40:15,700", "timestamp_s": 2415.0}, {"text": "Four of the kids in this class are girls.", "timestamp": "00:40:17,940", "timestamp_s": 2417.0}, {"text": "Eight of the kids wear blue shirts.", "timestamp": "00:40:20,400", "timestamp_s": 2420.0}, {"text": "Two of the kids are neither girls or wear blue shirts.", "timestamp": "00:40:22,470", "timestamp_s": 2422.0}, {"text": "If five of the kids are girls who wear blue shirts, how", "timestamp": "00:40:25,770", "timestamp_s": 2425.0}, {"text": "many kids are in the class?", "timestamp": "00:40:28,950", "timestamp_s": 2428.0}, {"text": "This is a classic Venn diagram problem, but you don\u0027t actually", "timestamp": "00:40:31,280", "timestamp_s": 2431.0}, {"text": "need a Venn diagram to know or keep track of all of those things.", "timestamp": "00:40:33,920", "timestamp_s": 2433.0}, {"text": "\u0027cause every Venn diagram is like also a union and intersection set", "timestamp": "00:40:39,790", "timestamp_s": 2439.0}, {"text": "of sorts, which can be represented.", "timestamp": "00:40:43,750", "timestamp_s": 2443.0}, {"text": "In algebra, which is in language.", "timestamp": "00:40:46,915", "timestamp_s": 2446.0}, {"text": "So you don\u0027t actually need to visualize this problem.", "timestamp": "00:40:51,295", "timestamp_s": 2451.0}, {"text": "It\u0027s a matter of addition and subtraction, which it\u0027s not able to do.", "timestamp": "00:40:53,755", "timestamp_s": 2453.0}, {"text": "The answer is actually wrong.", "timestamp": "00:40:58,915", "timestamp_s": 2458.0}, {"text": "And when I tell it the right answer, it basically goes ahead and tries to fit", "timestamp": "00:41:00,705", "timestamp_s": 2460.0}, {"text": "its thinking with the right answer, which may or may not be right in every case.", "timestamp": "00:41:06,135", "timestamp_s": 2466.0}, {"text": "You\u0027re escaping a maze and there are three doors in front of you.", "timestamp": "00:41:12,655", "timestamp_s": 2472.0}, {"text": "The door on the left leads to a pit of lava.", "timestamp": "00:41:16,585", "timestamp_s": 2476.0}, {"text": "The door in the center leads to a room filled with a deadly gas.", "timestamp": "00:41:19,945", "timestamp_s": 2479.0}, {"text": "The door on the right leads to a line that hasn\u0027t eaten in three months.", "timestamp": "00:41:23,785", "timestamp_s": 2483.0}, {"text": "Which door do you choose and.", "timestamp": "00:41:28,695", "timestamp_s": 2488.0}, {"text": "It just tries to give you like, again, like a way science fiction or like", "timestamp": "00:41:31,655", "timestamp_s": 2491.0}, {"text": "useless answer to this question though.", "timestamp": "00:41:35,705", "timestamp_s": 2495.0}, {"text": "The answer is supposed to be if the line hasn\u0027t eaten in", "timestamp": "00:41:38,315", "timestamp_s": 2498.0}, {"text": "three months, the line is dead.", "timestamp": "00:41:40,755", "timestamp_s": 2500.0}, {"text": "A man describes his daughter as saying they\u0027re all blondes, but two all", "timestamp": "00:41:43,025", "timestamp_s": 2503.0}, {"text": "brilliant, but two and all redheaded, but two, how many daughters does he have?", "timestamp": "00:41:47,405", "timestamp_s": 2507.0}, {"text": "Surprisingly, it gets it right, which is really weird \u0027cause it should have", "timestamp": "00:41:52,475", "timestamp_s": 2512.0}, {"text": "gotten like the ant questioned, right?", "timestamp": "00:41:57,905", "timestamp_s": 2517.0}, {"text": "It\u0027s like a version of this problem, right?", "timestamp": "00:42:01,255", "timestamp_s": 2521.0}, {"text": "If you have a seven minute hour class, an 11 minute art glass, how can you", "timestamp": "00:42:03,555", "timestamp_s": 2523.0}, {"text": "boil an egg in exactly 15 minutes?", "timestamp": "00:42:07,785", "timestamp_s": 2527.0}, {"text": "And it says you can\u0027t.", "timestamp": "00:42:10,625", "timestamp_s": 2530.0}, {"text": "No, that\u0027s not true because this is something that every", "timestamp": "00:42:11,795", "timestamp_s": 2531.0}, {"text": "mathematician has seen.", "timestamp": "00:42:15,925", "timestamp_s": 2535.0}, {"text": "At some points in their lives where you basically start one hour", "timestamp": "00:42:18,265", "timestamp_s": 2538.0}, {"text": "class at some point and the other one after seven minutes there is", "timestamp": "00:42:22,195", "timestamp_s": 2542.0}, {"text": "something, and then set the next one.", "timestamp": "00:42:27,805", "timestamp_s": 2547.0}, {"text": "And based on all of those subtractions, you make it up to 15 minutes.", "timestamp": "00:42:30,565", "timestamp_s": 2550.0}, {"text": "And then", "timestamp": "00:42:34,785", "timestamp_s": 2554.0}, {"text": "I tried asking at a mathematical riddle where you\u0027re like just supposed to assign", "timestamp": "00:42:36,305", "timestamp_s": 2556.0}, {"text": "a bunch of operations to a bunch of things and it just refused to be like", "timestamp": "00:42:39,605", "timestamp_s": 2559.0}, {"text": "I just want to look at these as numbers and not as c ciphers or any other sort of", "timestamp": "00:42:43,825", "timestamp_s": 2563.0}, {"text": "operational representations or something.", "timestamp": "00:42:49,735", "timestamp_s": 2569.0}, {"text": "And it refused to do the work for me.", "timestamp": "00:42:53,215", "timestamp_s": 2573.0}, {"text": "I guess it could have been avoided if I told it, or few shot prompted", "timestamp": "00:42:56,685", "timestamp_s": 2576.0}, {"text": "it, telling it that, oh, this is like an example of what happens.", "timestamp": "00:43:01,115", "timestamp_s": 2581.0}, {"text": "But then it\u0027s you\u0027re technically training it to respond to a certain thing, which", "timestamp": "00:43:06,995", "timestamp_s": 2586.0}, {"text": "a lot of times you actually don\u0027t have to train a lot of humans to do those things.", "timestamp": "00:43:14,035", "timestamp_s": 2594.0}, {"text": "So the point of this exercise was to get a better, accurate definition of agi.", "timestamp": "00:43:18,555", "timestamp_s": 2598.0}, {"text": "I, \u0027cause what cannot be defined, cannot be achieved.", "timestamp": "00:43:23,345", "timestamp_s": 2603.0}, {"text": "Historically different people have had different interpretations of a GI.", "timestamp": "00:43:26,205", "timestamp_s": 2606.0}, {"text": "A few of these definitions can be considered achieved by gt.", "timestamp": "00:43:31,875", "timestamp_s": 2611.0}, {"text": "Yes, that\u0027s true.", "timestamp": "00:43:36,515", "timestamp_s": 2616.0}, {"text": "Our diversity of perspectives is required to define it completely, and", "timestamp": "00:43:38,480", "timestamp_s": 2618.0}, {"text": "that may also mean that we will never reach 100% Asia for both development", "timestamp": "00:43:42,440", "timestamp_s": 2622.0}, {"text": "constraints reason, as well as the safety concerns surrounding a X.", "timestamp": "00:43:48,140", "timestamp_s": 2628.0}, {"text": "So these are some of the historical definitions.", "timestamp": "00:43:53,740", "timestamp_s": 2633.0}, {"text": "The during test, a machine and a human both converse unseen with a second", "timestamp": "00:43:55,960", "timestamp_s": 2635.0}, {"text": "human who must evaluate which of the two is the machine which passes the test.", "timestamp": "00:44:01,140", "timestamp_s": 2641.0}, {"text": "If it can fool the evaluator, a significant fraction of the time note", "timestamp": "00:44:07,080", "timestamp_s": 2647.0}, {"text": "during does not prescribe what should qualify as intelligence only that knowing", "timestamp": "00:44:12,620", "timestamp_s": 2652.0}, {"text": "that it is a machine should disqualify it.", "timestamp": "00:44:17,630", "timestamp_s": 2657.0}, {"text": "I would say that the non PR version of GPT, which was extremely controversial,", "timestamp": "00:44:20,560", "timestamp_s": 2660.0}, {"text": "would\u0027ve actually passed this test.", "timestamp": "00:44:26,320", "timestamp_s": 2666.0}, {"text": "A bunch of people would\u0027ve considered it machine.", "timestamp": "00:44:28,840", "timestamp_s": 2668.0}, {"text": "So you would think that it would have surpassed the during test, except", "timestamp": "00:44:31,540", "timestamp_s": 2671.0}, {"text": "it\u0027s mimicking a bunch of things.", "timestamp": "00:44:38,340", "timestamp_s": 2678.0}, {"text": "And it\u0027s also remembering a bunch of things that it\u0027s been trained on.", "timestamp": "00:44:40,080", "timestamp_s": 2680.0}, {"text": "And unless you have an extremely smart human being on the", "timestamp": "00:44:45,020", "timestamp_s": 2685.0}, {"text": "other ends, who\u0027s asking it?", "timestamp": "00:44:49,210", "timestamp_s": 2689.0}, {"text": "\u0027cause that\u0027s a test.", "timestamp": "00:44:52,270", "timestamp_s": 2692.0}, {"text": "You have to find out what the machine is.", "timestamp": "00:44:53,200", "timestamp_s": 2693.0}, {"text": "So you cannot go in and ask questions that you would ask a human being.", "timestamp": "00:44:55,900", "timestamp_s": 2695.0}, {"text": "You would have to probe it like you would probe to figure out if", "timestamp": "00:45:00,040", "timestamp_s": 2700.0}, {"text": "the person that you\u0027re talking to is a human being or a machine.", "timestamp": "00:45:04,510", "timestamp_s": 2704.0}, {"text": "If that were not the case, I think a lot of LMS would actually pass the urine test.", "timestamp": "00:45:08,610", "timestamp_s": 2708.0}, {"text": "But that\u0027s not significant at all.", "timestamp": "00:45:13,920", "timestamp_s": 2713.0}, {"text": "It doesn\u0027t mean anything.", "timestamp": "00:45:16,710", "timestamp_s": 2716.0}, {"text": "It just means that our definition of the Turing test is inadequate", "timestamp": "00:45:18,560", "timestamp_s": 2718.0}, {"text": "for a GI at this particular point.", "timestamp": "00:45:22,700", "timestamp_s": 2722.0}, {"text": "The coffee test, a machine is required to enter an average American home and", "timestamp": "00:45:25,120", "timestamp_s": 2725.0}, {"text": "figure out how to make coffee, find the coffee machine, find the coffee,", "timestamp": "00:45:29,740", "timestamp_s": 2729.0}, {"text": "add water, find a mug, and brew the coffee by pushing the proper buttons.", "timestamp": "00:45:34,300", "timestamp_s": 2734.0}, {"text": "In certain cases, G PT would have achieved this as well as a matter", "timestamp": "00:45:39,960", "timestamp_s": 2739.0}, {"text": "of fact, including techniques like RAG and prom training.", "timestamp": "00:45:44,220", "timestamp_s": 2744.0}, {"text": "One would think that in a bunch of cases it would have actually it will", "timestamp": "00:45:48,310", "timestamp_s": 2748.0}, {"text": "be marked a GI With respect to the coffee test the robot college student", "timestamp": "00:45:54,080", "timestamp_s": 2754.0}, {"text": "test, a machine enrolls in a university taking and passing the same classes that", "timestamp": "00:45:58,960", "timestamp_s": 2758.0}, {"text": "humans would and obtaining a degree.", "timestamp": "00:46:04,210", "timestamp_s": 2764.0}, {"text": "I think this is probably the easiest one and it\u0027s surpassed this one.", "timestamp": "00:46:07,230", "timestamp_s": 2767.0}, {"text": "The employment test.", "timestamp": "00:46:11,210", "timestamp_s": 2771.0}, {"text": "A machine performs an economically important job, at least as", "timestamp": "00:46:12,700", "timestamp_s": 2772.0}, {"text": "well as humans in the same job.", "timestamp": "00:46:16,660", "timestamp_s": 2776.0}, {"text": "This means nothing to me, to be honest.", "timestamp": "00:46:19,360", "timestamp_s": 2779.0}, {"text": "\u0027cause there was like a bunch of things that determine istic machines already do.", "timestamp": "00:46:21,880", "timestamp_s": 2781.0}, {"text": "And we don\u0027t actually need probabilistic models or LLMs to do those things.", "timestamp": "00:46:26,520", "timestamp_s": 2786.0}, {"text": "That\u0027s they sometimes do better than humans in the same job.", "timestamp": "00:46:31,190", "timestamp_s": 2791.0}, {"text": "Most of like our industries are actually that mechanized.", "timestamp": "00:46:35,540", "timestamp_s": 2795.0}, {"text": "They\u0027re full of machines as opposed to humans.", "timestamp": "00:46:41,870", "timestamp_s": 2801.0}, {"text": "Often faster actually.", "timestamp": "00:46:44,750", "timestamp_s": 2804.0}, {"text": "So what is GPT?", "timestamp": "00:46:46,570", "timestamp_s": 2806.0}, {"text": "GPT is a language model.", "timestamp": "00:46:48,160", "timestamp_s": 2808.0}, {"text": "It\u0027s a large language model.", "timestamp": "00:46:49,930", "timestamp_s": 2809.0}, {"text": "Each of us has a language model inside our heads and it changes constantly.", "timestamp": "00:46:52,140", "timestamp_s": 2812.0}, {"text": "A language model embedding is the multidimensional representation of a", "timestamp": "00:46:57,270", "timestamp_s": 2817.0}, {"text": "given sentence based on the context or environment in which our language", "timestamp": "00:47:02,520", "timestamp_s": 2822.0}, {"text": "model was trained similar to humans.", "timestamp": "00:47:06,600", "timestamp_s": 2826.0}, {"text": "The existence of a language model leads to NLU and NLG, which are all sub-problems", "timestamp": "00:47:10,190", "timestamp_s": 2830.0}, {"text": "for all the other NLP problems.", "timestamp": "00:47:16,400", "timestamp_s": 2836.0}, {"text": "NLU is natural language understanding and NLG is natural language generation.", "timestamp": "00:47:18,910", "timestamp_s": 2838.0}, {"text": "So this was GPD three and what I basically did was I went ahead and", "timestamp": "00:47:24,480", "timestamp_s": 2844.0}, {"text": "as the current version of GPD, what it thought of our prompting history.", "timestamp": "00:47:30,900", "timestamp_s": 2850.0}, {"text": "\u0027cause I do heavily use Chad GPDA lot.", "timestamp": "00:47:36,900", "timestamp_s": 2856.0}, {"text": "And it told me that he was very good at creative writing for me, like", "timestamp": "00:47:39,830", "timestamp_s": 2859.0}, {"text": "context linked creative writing.", "timestamp": "00:47:45,760", "timestamp_s": 2865.0}, {"text": "It was very good at essay or project expansion.", "timestamp": "00:47:48,120", "timestamp_s": 2868.0}, {"text": "It was really good at travel and museum planning.", "timestamp": "00:47:52,170", "timestamp_s": 2872.0}, {"text": "It was not good when I didn\u0027t provide it, like good context.", "timestamp": "00:47:55,010", "timestamp_s": 2875.0}, {"text": "It was minimal or one line prompts or when writing emotionally intense fiction", "timestamp": "00:47:58,940", "timestamp_s": 2878.0}, {"text": "or any sort of financial or tax strategy.", "timestamp": "00:48:04,440", "timestamp_s": 2884.0}, {"text": "The issues with its own evaluation is I have actually not been able to use charge", "timestamp": "00:48:07,730", "timestamp_s": 2887.0}, {"text": "GBD as much as I would think I would be able to for any of the things that", "timestamp": "00:48:13,250", "timestamp_s": 2893.0}, {"text": "it, things, it works very well for me.", "timestamp": "00:48:19,480", "timestamp_s": 2899.0}, {"text": "Whenever there\u0027s been a case of context linked creative writing, it\u0027s been", "timestamp": "00:48:22,650", "timestamp_s": 2902.0}, {"text": "extremely difficult to ve it into a direction where I wanted to go.", "timestamp": "00:48:27,810", "timestamp_s": 2907.0}, {"text": "In the prompt space that I basically have.", "timestamp": "00:48:34,440", "timestamp_s": 2914.0}, {"text": "\u0027cause if I were to give it more details, might as well write the plot myself.", "timestamp": "00:48:37,410", "timestamp_s": 2917.0}, {"text": "Same case with any sort of essay or project expansion.", "timestamp": "00:48:43,430", "timestamp_s": 2923.0}, {"text": "\u0027Cause it loses a lot of context.", "timestamp": "00:48:47,280", "timestamp_s": 2927.0}, {"text": "It loses a lot of history and it, you have to basically keep telling it no, we are", "timestamp": "00:48:50,010", "timestamp_s": 2930.0}, {"text": "like in this context of riddles or we are in this context of mathematical riddles", "timestamp": "00:48:57,420", "timestamp_s": 2937.0}, {"text": "as opposed to any fictional riddles.", "timestamp": "00:49:04,290", "timestamp_s": 2944.0}, {"text": "You have to keep reminding it.", "timestamp": "00:49:06,870", "timestamp_s": 2946.0}, {"text": "And the last one where it\u0027s travel museum planning, that\u0027s where it\u0027s not been", "timestamp": "00:49:08,420", "timestamp_s": 2948.0}, {"text": "great for me at all actually, because.", "timestamp": "00:49:14,580", "timestamp_s": 2954.0}, {"text": "Was a, there was a itinerary that it basically wrote for me for a specific", "timestamp": "00:49:17,300", "timestamp_s": 2957.0}, {"text": "trip where Chad GPD thought I could teleport from one place to the other.", "timestamp": "00:49:23,240", "timestamp_s": 2963.0}, {"text": "That would usually take 30 minutes in five minutes.", "timestamp": "00:49:28,910", "timestamp_s": 2968.0}, {"text": "So as you\u0027ve seen, it actually has no understanding of basic physics", "timestamp": "00:49:33,430", "timestamp_s": 2973.0}, {"text": "or the realities of the world.", "timestamp": "00:49:38,770", "timestamp_s": 2978.0}, {"text": "There is no way for it to scope any sort of observational details of whatever", "timestamp": "00:49:40,300", "timestamp_s": 2980.0}, {"text": "prompt you are like asking it to perform.", "timestamp": "00:49:46,670", "timestamp_s": 2986.0}, {"text": "And it does really bad at it.", "timestamp": "00:49:49,840", "timestamp_s": 2989.0}, {"text": "So cheaply today doesn\u0027t have a sense of time or practicality because", "timestamp": "00:49:51,750", "timestamp_s": 2991.0}, {"text": "it actually did think that I could teleport when making travel plans.", "timestamp": "00:49:56,630", "timestamp_s": 2996.0}, {"text": "Those were not hallucinations.", "timestamp": "00:50:01,040", "timestamp_s": 3001.0}, {"text": "It did actually think that a cab right from point A to B would take 10 minutes.", "timestamp": "00:50:03,470", "timestamp_s": 3003.0}, {"text": "In reality, it would take around 30 minutes to do the that task.", "timestamp": "00:50:08,300", "timestamp_s": 3008.0}, {"text": "So using it to travel, considering how it like, depends upon a lot of", "timestamp": "00:50:12,610", "timestamp_s": 3012.0}, {"text": "RAG which is retrieved augmentation coupled with the generation.", "timestamp": "00:50:18,810", "timestamp_s": 3018.0}, {"text": "So it\u0027ll source its results based on either Google search or Bing search", "timestamp": "00:50:24,770", "timestamp_s": 3024.0}, {"text": "or any other sort of search engine.", "timestamp": "00:50:30,410", "timestamp_s": 3030.0}, {"text": "And it\u0027ll ground all of its information on the basis of that, except it\u0027s way", "timestamp": "00:50:33,100", "timestamp_s": 3033.0}, {"text": "easy to like for someone to start a blog and post all sorts of fake information", "timestamp": "00:50:36,940", "timestamp_s": 3036.0}, {"text": "on the blog, which will be cited as a source in all of these search results", "timestamp": "00:50:44,070", "timestamp_s": 3044.0}, {"text": "based on how they gather that information.", "timestamp": "00:50:49,140", "timestamp_s": 3049.0}, {"text": "And those things are like always evolving.", "timestamp": "00:50:53,330", "timestamp_s": 3053.0}, {"text": "Like all of these documents are always evolving.", "timestamp": "00:50:56,630", "timestamp_s": 3056.0}, {"text": "So there\u0027s like a bunch of blogs with all sorts of conflicting information.", "timestamp": "00:50:58,940", "timestamp_s": 3058.0}, {"text": "And it doesn\u0027t do really well with all of that.", "timestamp": "00:51:04,220", "timestamp_s": 3064.0}, {"text": "If it\u0027s bombarded with all sorts of confusing sort of information, it", "timestamp": "00:51:06,600", "timestamp_s": 3066.0}, {"text": "can give you all the wrong answers.", "timestamp": "00:51:10,260", "timestamp_s": 3070.0}, {"text": "It can make up places for you to travel to that don\u0027t really exist.", "timestamp": "00:51:12,690", "timestamp_s": 3072.0}, {"text": "And it can actually believe that you can teleport from place A to", "timestamp": "00:51:17,580", "timestamp_s": 3077.0}, {"text": "B in 10 minutes when the actual task will take you 30 minutes.", "timestamp": "00:51:23,700", "timestamp_s": 3083.0}, {"text": "It loses train of thought which I thought was actually very human.", "timestamp": "00:51:28,190", "timestamp_s": 3088.0}, {"text": "On the other hand, if a human were to do it to you multiple times, you are", "timestamp": "00:51:32,630", "timestamp_s": 3092.0}, {"text": "just basically stopping being friends with them or talking to them if they\u0027re", "timestamp": "00:51:37,780", "timestamp_s": 3097.0}, {"text": "like your therapist or something else, you\u0027re just basically stuck.", "timestamp": "00:51:41,880", "timestamp_s": 3101.0}, {"text": "Which has been my experience.", "timestamp": "00:51:46,010", "timestamp_s": 3106.0}, {"text": "So not quite a GI LMS gr and cha g Bt are very good at chasm style.", "timestamp": "00:51:47,690", "timestamp_s": 3107.0}, {"text": "Guessing games probably due to RG injection.", "timestamp": "00:51:53,920", "timestamp_s": 3113.0}, {"text": "I\u0027ve had to give it to some more prompts, like some more hints.", "timestamp": "00:51:57,820", "timestamp_s": 3117.0}, {"text": "But usually they do get me like the right answer misheard lyrics or figuring out", "timestamp": "00:52:01,210", "timestamp_s": 3121.0}, {"text": "some sort of a photo, like what sort of artist that belongs to, et cetera.", "timestamp": "00:52:07,950", "timestamp_s": 3127.0}, {"text": "And I\u0027ve actually searched for a number of wild things and it does really", "timestamp": "00:52:13,680", "timestamp_s": 3133.0}, {"text": "well with it, except I do know of a deterministic engine which used to perform", "timestamp": "00:52:19,020", "timestamp_s": 3139.0}, {"text": "the same sort of analysis of sorts.", "timestamp": "00:52:24,270", "timestamp_s": 3144.0}, {"text": "If you answer I want to say 10 outta 20 questions, and those questions", "timestamp": "00:52:28,060", "timestamp_s": 3148.0}, {"text": "used to be like is this character fictional or is this character female?", "timestamp": "00:52:31,750", "timestamp_s": 3151.0}, {"text": "Is this character in a fantasy movie?", "timestamp": "00:52:36,280", "timestamp_s": 3156.0}, {"text": "And would basically come upon the right answer.", "timestamp": "00:52:38,550", "timestamp_s": 3158.0}, {"text": "There were a lot of rumors that this machine is actually, there\u0027s like a", "timestamp": "00:52:41,440", "timestamp_s": 3161.0}, {"text": "bunch of humans behind this particular website, but that was not the case.", "timestamp": "00:52:45,550", "timestamp_s": 3165.0}, {"text": "So that\u0027s not a GI, it doesn\u0027t have any observational skills for obvious reasons.", "timestamp": "00:52:50,200", "timestamp_s": 3170.0}, {"text": "It\u0027s an LLM.", "timestamp": "00:52:56,320", "timestamp_s": 3176.0}, {"text": "It is not equipped to see or to perceive or to even imagine actually in any", "timestamp": "00:52:57,400", "timestamp_s": 3177.0}, {"text": "sort of space except a bunch of the things that don\u0027t require imagining.", "timestamp": "00:53:03,810", "timestamp_s": 3183.0}, {"text": "For instance, verbal algebra should be easy enough, but it\u0027s not.", "timestamp": "00:53:08,540", "timestamp_s": 3188.0}, {"text": "So it relies on available knowledge only straight up available knowledge, either", "timestamp": "00:53:13,660", "timestamp_s": 3193.0}, {"text": "available in its own training base, either as a mimic of its training base or any", "timestamp": "00:53:18,610", "timestamp_s": 3198.0}, {"text": "sort of information that it gets from REG sources, which are search engines.", "timestamp": "00:53:26,010", "timestamp_s": 3206.0}, {"text": "So it relies on available knowledge only, which is not how humans learn.", "timestamp": "00:53:31,700", "timestamp_s": 3211.0}, {"text": "A lot of humans will learn using observation.", "timestamp": "00:53:37,220", "timestamp_s": 3217.0}, {"text": "For instance, a lot of Greek mathematicians were able to calculate", "timestamp": "00:53:40,040", "timestamp_s": 3220.0}, {"text": "the radius of the earth using two poles in two different cities or", "timestamp": "00:53:46,710", "timestamp_s": 3226.0}, {"text": "something that\u0027s observational physics.", "timestamp": "00:53:50,970", "timestamp_s": 3230.0}, {"text": "And it did not rely on available knowledge in the sense of memory.", "timestamp": "00:53:54,530", "timestamp_s": 3234.0}, {"text": "It did rely on knowledge in the sense of observation that I can observe that the", "timestamp": "00:54:00,330", "timestamp_s": 3240.0}, {"text": "shadow of this particular pole exists in a certain direction while there is", "timestamp": "00:54:06,900", "timestamp_s": 3246.0}, {"text": "no shadow for this particular pole, but that is observational knowledge", "timestamp": "00:54:11,900", "timestamp_s": 3251.0}, {"text": "as opposed to available knowledge.", "timestamp": "00:54:17,110", "timestamp_s": 3257.0}, {"text": "So I just wanna conclude that GPT today is actually not a GI.", "timestamp": "00:54:19,680", "timestamp_s": 3259.0}, {"text": "And in fact, if you play with it using all of the riddles that I have", "timestamp": "00:54:23,760", "timestamp_s": 3263.0}, {"text": "showcase today, it\u0027ll give you all of the right answers except it\u0027s cheating.", "timestamp": "00:54:29,670", "timestamp_s": 3269.0}, {"text": "It\u0027ll literally go look up all the keywords or like all of the phases", "timestamp": "00:54:35,270", "timestamp_s": 3275.0}, {"text": "or like queries, like extremely smart queries and come up with the right answer", "timestamp": "00:54:39,950", "timestamp_s": 3279.0}, {"text": "from the internet, which is basically where I source all my rules from.", "timestamp": "00:54:45,200", "timestamp_s": 3285.0}, {"text": "But that\u0027s not a GI.", "timestamp": "00:54:49,390", "timestamp_s": 3289.0}, {"text": "That\u0027s all I had.", "timestamp": "00:54:51,075", "timestamp_s": 3291.0}, {"text": "Thank you so much.", "timestamp": "00:54:51,915", "timestamp_s": 3291.0}, {"text": "Okay.", "timestamp": "00:54:53,245", "timestamp_s": 3293.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'r3c9Gcu4lkw',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              I talk to ChatGPT about things
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>The word ChatGPT has captured the imagination and the internet, but does ChatGPT truly know everything, is it truly AGI?</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/prompt2025_Aroma_Rodrigues.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,500'); seek(0.0)">
              Hello, welcome to my talk.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:02,510'); seek(2.0)">
              Today I'm going to talk about how I spoke to cha g pity about things.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:06,729'); seek(6.0)">
              All of these experiments were conducted on Cha g Pity three.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:10,879'); seek(10.0)">
              So this was like a really long time ago.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:13,129'); seek(13.0)">
              But as we go through this talk, you'll actually realize why this was an
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:18,250'); seek(18.0)">
              important sort of exercise to be done, especially on the primitive not really
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:24,810'); seek(24.0)">
              primitive, but like primitive versions of pure elements or pure language models.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:30,630'); seek(30.0)">
              Some of these exercises are like fun experiments that are
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:33,880'); seek(33.0)">
              conducted with Ja GT three.
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:36,760'); seek(36.0)">
              The first one is where we ask Cha gt.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:39,059'); seek(39.0)">
              They were conducted on a personal free use account.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:41,429'); seek(41.0)">
              So the call t will vary you depending upon whether you are using like
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:45,059'); seek(45.0)">
              Chad GP Plus or something else.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:47,209'); seek(47.0)">
              So at some points I just basically decided to ask Chad Gpt a bunch of
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:50,890'); seek(50.0)">
              really weird questions that I thought it wouldn't be able to answer to check
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:55,510'); seek(55.0)">
              the viability of the A GI theory.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:59,379'); seek(59.0)">
              So these are some of the examples.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:01,539'); seek(61.0)">
              The first one is when is a door no longer a door?
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:04,890'); seek(64.0)">
              So the answer was, a door is no longer a door when it's no longer serves the
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:10,140'); seek(70.0)">
              purpose of providing an entrance or exit to a room or building or when
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:14,870'); seek(74.0)">
              it's unable to be open or closed.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:17,860'); seek(77.0)">
              So what I decided was, let me give it like some more context because
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:21,580'); seek(81.0)">
              it's way possible that it has been trained on this data before.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:25,020'); seek(85.0)">
              So I was like this is a riddle, so answer it.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:28,200'); seek(88.0)">
              When is a door no longer a door?
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:30,920'); seek(90.0)">
              And that's when all the training basically kicked in.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:34,080'); seek(94.0)">
              The productive modeling kicked in and it said a door is no longer a
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:37,950'); seek(97.0)">
              door when it's a jar, which is right.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:40,910'); seek(100.0)">
              That's the right answer of the riddle.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:43,260'); seek(103.0)">
              The second one was, what tastes better than it smells?
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:46,730'); seek(106.0)">
              And at this point, JG PT basically understood that we
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:49,430'); seek(109.0)">
              were in like the context of answering griddles or something.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:53,270'); seek(113.0)">
              So it was like this is a riddle.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:01:55,210'); seek(115.0)">
              It told me that this is a riddle.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:01:56,980'); seek(116.0)">
              And the answer is UNK because it tastes food but does not have a smell.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:01,480'); seek(121.0)">
              Which was the right answer.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:03,670'); seek(123.0)">
              The next question was, what building has the most stories?
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:07,500'); seek(127.0)">
              And it basically recognized the fact that this was still a riddle.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:11,980'); seek(131.0)">
              And the answer was library because it has many stories, what has bottom at the top.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:17,700'); seek(137.0)">
              So again, Chad Jupiter was like, this is a riddle.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:20,549'); seek(140.0)">
              The answer is a staircase because it has a bottom step at the top when
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:25,079'); seek(145.0)">
              you reach the top of the staircase, which was not the right answer.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:28,340'); seek(148.0)">
              'cause the right answer is actually legs.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:30,740'); seek(150.0)">
              But it did recognize the fact that we were in riddle mode and it went
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:36,300'); seek(156.0)">
              into a story mode of thoughts.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:38,360'); seek(158.0)">
              A little bit of imagination.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:39,770'); seek(159.0)">
              I don't think it's like sourcing all of this data from its
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:02:44,180'); seek(164.0)">
              previous training, though.
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:02:45,350'); seek(165.0)">
              I do believe for the co last couple examples, we did source a lot
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:02:49,900'); seek(169.0)">
              of data from previous training.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:02:51,490'); seek(171.0)">
              I. So Chad GP D had at some points in all of its tasks and all of its examples,
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:02:58,490'); seek(178.0)">
              seen those examples before in either like q and a task or something else.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:03,640'); seek(183.0)">
              So some other examples were what has four wheels and twice.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:08,175'); seek(188.0)">
              It's still in this mode where it's this is a riddle, and the answer is
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:11,745'); seek(191.0)">
              a garbage truck because it has four wheels and it moves around to collect
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:15,495'); seek(195.0)">
              garbage, which can be considered as flying through the streets.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:19,785'); seek(199.0)">
              That's not the right answer actually, but like it does make up like a
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:23,865'); seek(203.0)">
              lot of imaginative shit when it encounters questions that are
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:30,315'); seek(210.0)">
              really, but it doesn't really have any good answers to those questions.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:34,935'); seek(214.0)">
              What month of the year has 28 days in it?
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:38,165'); seek(218.0)">
              And it's this is a riddle.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:39,845'); seek(219.0)">
              And it says that all the 12 months of the year have at least 28 days in it.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:44,135'); seek(224.0)">
              Which is the right answer.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:03:46,215'); seek(226.0)">
              A lot of humans get this wrong 'cause they're like it's just Feb. What can
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:03:50,175'); seek(230.0)">
              you put in a bucket to make it way less?
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:03:52,455'); seek(232.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:03:53,715'); seek(233.0)">
              The answer is a hole because a hole in a bucket decreases the weight of the bucket.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:03:58,715'); seek(238.0)">
              That's right.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:03:59,845'); seek(239.0)">
              And it's not like it has a lot of intuitive thinking about, oh, this
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:04,374'); seek(244.0)">
              is what the physical world is like.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:06,085'); seek(246.0)">
              If you drill a hole at the bottom of a container, it's going to
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:10,524'); seek(250.0)">
              make a lot of its contents.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:12,264'); seek(252.0)">
              Spell out what starts with the t. Ends with a T and has T in it.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:16,454'); seek(256.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:17,564'); seek(257.0)">
              The answer is teapot because it starts with a T, ends with
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:20,870'); seek(260.0)">
              a T and has T in the middle.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:23,144'); seek(263.0)">
              It got that but I think all of those were like extremely classic examples of riles.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:28,804'); seek(268.0)">
              And based on all of the corpus that JG PT had been trained on before,
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:04:33,274'); seek(273.0)">
              it probably had gone through all of those examples before in its training.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:04:37,344'); seek(277.0)">
              Where is the only place where today comes before yesterday?
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:04:41,004'); seek(281.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:04:42,264'); seek(282.0)">
              The answer is in a dictionary because the words are listed in alphabetical order.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:04:46,814'); seek(286.0)">
              What goes all around the world, but stays in a corner.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:04:50,054'); seek(290.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:04:51,254'); seek(291.0)">
              The answer is a stamp.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:04:52,604'); seek(292.0)">
              It goes all around the world when it is used on letters and postcards,
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:04:56,809'); seek(296.0)">
              but it is physically located in a corner of the envelope I'm used to
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:01,324'); seek(301.0)">
              bat with, yet I never get a hit.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:03,934'); seek(303.0)">
              I'm near a ball, yet it is never thrown.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:06,514'); seek(306.0)">
              Why am I, this is a riddle, and the answer is a baseball bat.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:10,954'); seek(310.0)">
              It's used to bat with, but it never gets a hit.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:14,224'); seek(314.0)">
              It's near a ball, but the ball is never true.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:16,914'); seek(316.0)">
              And at some point I'm like sometimes it gets a lot of these things wrong.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:05:21,364'); seek(321.0)">
              And it starts making up a lot of like imaginative stories about
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:05:25,234'); seek(325.0)">
              what the real answer could be like.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:05:27,294'); seek(327.0)">
              And it tries to like basically fitted all of those stories into the narrative
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:05:32,334'); seek(332.0)">
              so that it seems like the answer that it's giving me is the right answer.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:05:37,184'); seek(337.0)">
              So I tried prompting it, saying, can there be another answer?
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:05:41,164'); seek(341.0)">
              And it was basically like when you're trying to hint to your friends when
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:05:46,024'); seek(346.0)">
              you're playing riddles with each other and you are like this is a hint.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:05:49,524'); seek(349.0)">
              Why don't you take this as a hint?
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:05:52,124'); seek(352.0)">
              Or Why don't you think of any other answers?
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:05:55,304'); seek(355.0)">
              Do you think there could be any other answers?
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:05:57,734'); seek(357.0)">
              And it did give me back another imaginative answer, which was a baseball
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:02,294'); seek(362.0)">
              glove, which is also not the right answer.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:05,714'); seek(365.0)">
              But you can see where this is basically thinking process of a language model.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:10,624'); seek(370.0)">
              You're literally seeing it think, and this was before all of the RAG or any
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:16,204'); seek(376.0)">
              other sort of layers on top of Cha Gt.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:18,994'); seek(378.0)">
              This is pure language models.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:21,484'); seek(381.0)">
              So you can see it thinking when you say, can there be another answer?
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:06:27,324'); seek(387.0)">
              Because it has already made up a lot of imaginative storytelling to fit
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:06:32,544'); seek(392.0)">
              a certain answer into this riddle.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:06:35,014'); seek(395.0)">
              It's thinking along those same sort of lines.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:06:38,554'); seek(398.0)">
              'cause the answer that it gets back to is the baseball globe
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:06:42,964'); seek(402.0)">
              as opposed to the baseball bat.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:06:45,084'); seek(405.0)">
              Unfortunately that was not the right answer actually.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:06:47,844'); seek(407.0)">
              But I just decided to continue and tried to change the genre
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:06:52,364'); seek(412.0)">
              basically, like the geography.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:06:55,004'); seek(415.0)">
              So my question was, I heard Arabian Knights first.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:06:58,604'); seek(418.0)">
              My queen was the writer of the great story.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:00,704'); seek(420.0)">
              Guess my name, and it says this is a riddle.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:04,544'); seek(424.0)">
              This is not a riddle actually, it's just a question that's framed in a
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:09,334'); seek(429.0)">
              specific manner in order to confuse the person you're seeking an answer from.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:14,594'); seek(434.0)">
              So Chad Gri at this point was like it's like in riddle mode.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:17,594'); seek(437.0)">
              So it keeps on assuming that the context is still riddle mode, and it says to
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:23,624'); seek(443.0)">
              me, this is a riddle, and the answer is shares adi, which is not the right answer.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:07:29,314'); seek(449.0)">
              Because the question is, my queen was the writer of the Great story.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:07:32,764'); seek(452.0)">
              Guess my name.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:07:34,224'); seek(454.0)">
              It does get all the context.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:07:36,184'); seek(456.0)">
              It's like she's a queen in the collection.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:07:38,494'); seek(458.0)">
              It's a Middle Eastern folk tales known as 1001 Knights,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:07:43,504'); seek(463.0)">
              also known as Arabian Knights.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:07:45,304'); seek(465.0)">
              She's the storyteller of the Tales, which are also known as
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:07:48,904'); seek(468.0)">
              the Tales of 1,001 Arabian Nights.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:07:52,794'); seek(472.0)">
              Okay.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:07:53,744'); seek(473.0)">
              But it did make a way human mistake here by telling me that my name is
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:00,634'); seek(480.0)">
              Cher Zdi as opposed to the King's name.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:03,434'); seek(483.0)">
              So that basically worked like in my head I was like I was able to track trick Chad
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:09,184'); seek(489.0)">
              Jupiter into being confused just using, a specific method in which you ask tricky
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:17,144'); seek(497.0)">
              questions, which also works with humans.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:20,644'); seek(500.0)">
              So we just basically decided to continue and I moved on to another genre of sorts.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:26,304'); seek(506.0)">
              Basically currently I was in fiction, so I'd been asking it questions about
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:08:31,184'); seek(511.0)">
              like physics or physical phenomenon or sports or something related to
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:08:37,624'); seek(517.0)">
              actually perceiving or observing.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:08:39,994'); seek(519.0)">
              And now I basically moved on to some fictional results.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:08:44,394'); seek(524.0)">
              So my question was, what do you call a rabbit that has fleas?
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:08:48,284'); seek(528.0)">
              And Chad g pity is this is a riddle.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:08:50,374'); seek(530.0)">
              And the answer is bug bunny as its apply onwards.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:08:54,394'); seek(534.0)">
              Bug bunny is a cartoon rabbit, and bugs is also another word
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:08:58,924'); seek(538.0)">
              for fleas, but it's right.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:00,954'); seek(540.0)">
              This comes from like a certain source of fiction that it
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:05,334'); seek(545.0)">
              was trained on specifically.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:07,134'); seek(547.0)">
              So it knows like the references, what you get if you pour boiling hot water
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:12,614'); seek(552.0)">
              down a rabbit hole, this is a riddle.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:15,824'); seek(555.0)">
              The answer is hot cross bunnies as a supply onwards.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:19,844'); seek(559.0)">
              Hot cross bunnies sounds like hot cross buns and the word bunny
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:24,674'); seek(564.0)">
              is another name for a rabbit.
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:26,854'); seek(566.0)">
              So I did to a certain extent understand punts.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:30,774'); seek(570.0)">
              Whether it's like intuitively understanding punts, whether it's
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:34,619'); seek(574.0)">
              capable of making bunts by itself or whether it was drained on this specific
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:09:40,464'); seek(580.0)">
              bun, is something that at this point, because we are looking at it as if
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:09:45,354'); seek(585.0)">
              it was a black box, we don't know.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:09:48,104'); seek(588.0)">
              So we would basically have to devise like a bunch of other tests to figure out if.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:09:54,014'); seek(594.0)">
              It was actually intuitively understanding how to make a pun, or whether it was
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:09:59,444'); seek(599.0)">
              just trained on this data to mimic or to basically remember that it was
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:07,425'); seek(607.0)">
              trained on this data and remembered through its neural network that
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:13,035'); seek(613.0)">
              the answer is hot crust bunnies.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:15,454'); seek(615.0)">
              So I just went on what has to be broken before you can use it, and it's like this
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:21,405'); seek(621.0)">
              is a riddle, and the answer is an egg.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:23,715'); seek(623.0)">
              It has to be broken in order to use it, and cooking or eating.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:27,995'); seek(627.0)">
              I'm tall when I'm young, and I'm short when I'm old.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:30,575'); seek(630.0)">
              What am I?
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:31,555'); seek(631.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:32,485'); seek(632.0)">
              The answer is a candle.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:34,195'); seek(634.0)">
              A candle is tall when it's new and has not been burned, but it becomes short as
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:10:39,655'); seek(639.0)">
              it burns down and gets short with age.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:10:42,070'); seek(642.0)">
              It's right.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:10:42,790'); seek(642.0)">
              Classic riddle, what is always in front of you, but can't be seen.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:10:47,370'); seek(647.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:10:48,690'); seek(648.0)">
              The answer is the future as it's always in front of you, but cannot be
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:10:52,500'); seek(652.0)">
              seen because it hasn't happened yet.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:10:54,650'); seek(654.0)">
              Technically it's right.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:10:56,210'); seek(656.0)">
              And this is one of those philosophical genre based riddles of sorts.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:01,800'); seek(661.0)">
              At this point, it used to like the observer of Chad GTI as a black box.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:07,109'); seek(667.0)">
              It would seem that Chad GTI did in fact understand some human philosophy, which at
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:15,685'); seek(675.0)">
              that point, 'cause it was Ja GBT three at the point was like awe inspiring, right?
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:20,830'); seek(680.0)">
              So I just decided to go further into this rabbit hole of sorts.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:25,210'); seek(685.0)">
              Because I was getting some very interesting signals.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:29,100'); seek(689.0)">
              So I was like on a table, there are two apples on the plate.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:32,330'); seek(692.0)">
              Three men are eating it.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:34,070'); seek(694.0)">
              How should one not eat an apple?
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:11:37,480'); seek(697.0)">
              And cha, but he's this is a riddle.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:11:39,460'); seek(699.0)">
              The answer is one of the men is a doctor because the doctor would not eat an
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:11:43,870'); seek(703.0)">
              apple as he would be the one giving advice on how to not eat the apple.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:11:49,620'); seek(709.0)">
              And I think that answer was wrong, but like it, it's so imaginative.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:11:54,229'); seek(714.0)">
              It just made up like a whole story about how if you are a doctor,
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:11:59,839'); seek(719.0)">
              you're not supposed to eat an apple, though the actual saying is, an
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:05,380'); seek(725.0)">
              apple a day gives the doctor away.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:07,560'); seek(727.0)">
              So I went on and I was like, if five rabbits eat five apples in
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:11,310'); seek(731.0)">
              five minutes, how many apples will 10 rabbits eat in 10 minutes?
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:15,439'); seek(735.0)">
              This is a classic work problem that a lot of people actually have to solve when
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:20,520'); seek(740.0)">
              they're doing any sort of math problems.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:22,650'); seek(742.0)">
              And it's still in riddle mode, so it's this is the riddle.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:25,860'); seek(745.0)">
              The answer is five apples.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:27,960'); seek(747.0)">
              This is because the problem doesn't take into account the fact, but eating the
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:32,069'); seek(752.0)">
              apples would take a different amount of time depending upon the number of rabbits.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:36,660'); seek(756.0)">
              Instead, the problem only relates to the number of apples and the
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:41,069'); seek(761.0)">
              time given incredibly weird math, but you have to understand that.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:12:46,625'); seek(766.0)">
              GP three was never linked to any sort of math engine to do any sort
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:12:51,604'); seek(771.0)">
              of math and would get like the most basic math questions wrong.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:12:55,895'); seek(775.0)">
              And this is an example of such a problem.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:12:59,755'); seek(779.0)">
              So when it's purely language based language model, it does seem to get
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:06,285'); seek(786.0)">
              a lot of mathematical problems wrong, though the way that humans learn
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:11,535'); seek(791.0)">
              language or humans learn mathematics is primarily through language they do
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:19,365'); seek(799.0)">
              because in most school curriculums, all of the problems that people solve
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:25,435'); seek(805.0)">
              are closely related to language.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:28,315'); seek(808.0)">
              People specifically have a lot of problems with respect to a man buying
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:33,295'); seek(813.0)">
              like 10 watermelons and then spending like x amount of money and such.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:38,445'); seek(818.0)">
              So technically you would think that a large language model would
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:42,765'); seek(822.0)">
              be okay, understanding math, not through a math engine, but instead
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:47,945'); seek(827.0)">
              through language like humans do.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:50,425'); seek(830.0)">
              So I just went on suppose you're touring on a bus with 10
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:53,785'); seek(833.0)">
              passengers, two descendant, and four climbed on the first stand.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:13:57,895'); seek(837.0)">
              Five descended, and two climbed on the second stand, two descended and
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:01,135'); seek(841.0)">
              three climbed on the next stand.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:02,935'); seek(842.0)">
              Now tell me how many passengers are traveling on the bus.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:06,105'); seek(846.0)">
              So it basically gave me like the wrong answer and then it basically
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:10,959'); seek(850.0)">
              got confused because it thought that it had to explain why the answer
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:15,579'); seek(855.0)">
              is what it thinks the answer is.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:18,159'); seek(858.0)">
              And went into like deep math with, like each statement
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:22,299'); seek(862.0)">
              corresponding to like mathematical operation and still got it wrong.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:27,029'); seek(867.0)">
              A prime example of behavior that's actually seen in human kids, like
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:31,319'); seek(871.0)">
              human children when they're like, I want to say five or six years old,
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:35,569'); seek(875.0)">
              where we lose track of the mathematical operations that they are conducting.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:42,259'); seek(882.0)">
              Especially if they have like multiple tasks and multiple steps and they
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:47,089'); seek(887.0)">
              basically lose track of history.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:48,769'); seek(888.0)">
              So while it was telling me things, 'cause this is like a predictive language model,
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:53,899'); seek(893.0)">
              while it was telling me things, it was losing track of what it was telling me.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:58,959'); seek(898.0)">
              There was no current memory.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:01,289'); seek(901.0)">
              To charge three.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:02,729'); seek(902.0)">
              I don't know if the current models have any current memory, like when
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:07,239'); seek(907.0)">
              they're telling you things, whether they have good memory or track of
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:12,819'); seek(912.0)">
              what they're telling you in the moment that they're telling you those things.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:17,119'); seek(917.0)">
              Apart from all of the proactive modeling and such.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:20,140'); seek(920.0)">
              Because proactive modeling is oh, what word would come next as opposed
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:24,740'); seek(924.0)">
              to, or this is the calculation that is supposed to match up to the
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:29,770'); seek(929.0)">
              practical modeling that I've done.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:31,800'); seek(931.0)">
              And at that point I basically was like I have no way of knowing
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:37,410'); seek(937.0)">
              if JT three was actually trained on this data in the sense that.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:43,030'); seek(943.0)">
              Whether all of this data or all of these riddles were part of its carus ever
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:47,410'); seek(947.0)">
              'cause the carus was huge or whether it was actually being extremely intuitive.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:52,620'); seek(952.0)">
              'cause when you're playing riddles with your friend, usually you are not allowed
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:57,410'); seek(957.0)">
              to look up any sort of information.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:00,230'); seek(960.0)">
              You're not supposed to cheat, you're not supposed to ask anyone else.
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:03,440'); seek(963.0)">
              You are just supposed to rack your brains.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:05,960'); seek(965.0)">
              Sometimes you would've played the game before and would remember it from
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:10,750'); seek(970.0)">
              previous instances, but I think in most cases you are supposed to be asking
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:16,560'); seek(976.0)">
              each other questions that you've never heard before and making connections
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:21,240'); seek(981.0)">
              that you've never made before and basically thinking outside the box.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:25,430'); seek(985.0)">
              So that was this, the test that I was like performing on g PT three.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:31,200'); seek(991.0)">
              So at the point I was like it could be a part of the corpus that it was trained on.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:35,970'); seek(995.0)">
              So I decided that I was going to look up riddles in another language,
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:41,280'); seek(1001.0)">
              and in this case it was Hindi.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:43,280'); seek(1003.0)">
              I'm just going to translate them.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:45,400'); seek(1005.0)">
              And I'm going to ask Chad, GPD, those riddles because I was assuming
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:50,130'); seek(1010.0)">
              that it would not have been trained on data that was available on the
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:54,470'); seek(1014.0)">
              internet in a language other than English and did not have any sort of
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:59,380'); seek(1019.0)">
              corresponding English translation.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:01,920'); seek(1021.0)">
              So some of these examples are from that data.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:05,360'); seek(1025.0)">
              For instance, Ajay's parents have three sons, which I wish, and the third son is.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:11,110'); seek(1031.0)">
              It does get it right.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:12,100'); seek(1032.0)">
              It's like Ajay is the third son.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:14,430'); seek(1034.0)">
              This is something that actually stumps a lot of humans who has
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:18,680'); seek(1038.0)">
              many words but does not speak.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:20,600'); seek(1040.0)">
              This is a real, the answer is a book because a book contains many
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:24,200'); seek(1044.0)">
              words but does not speak a car.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:26,530'); seek(1046.0)">
              Gives milk a hand gives an egg, which gives both milk and egg.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:30,550'); seek(1050.0)">
              D so as you can see, this is like an extremely crudely translated version
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:36,120'); seek(1056.0)">
              of a rootle that I think was either in Hindi or some regional language.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:42,560'); seek(1062.0)">
              And it comes up with the weirdest story you've ever heard.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:46,020'); seek(1066.0)">
              It's what is riddle?
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:47,160'); seek(1067.0)">
              And the answer is a duck.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:48,780'); seek(1068.0)">
              Ducks are domesticated bulls that are kept for their eggs, meat, and feathers.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:53,490'); seek(1073.0)">
              They're also known to give milk, which can be used to make dairy
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:56,700'); seek(1076.0)">
              products like cheese and butter.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:59,420'); seek(1079.0)">
              And at the point I basically wondered if there was like a brand called Duck
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:04,750'); seek(1084.0)">
              Dairy Farm or something, which would basically trick a language model into
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:11,100'); seek(1091.0)">
              believing that there is such a thing as a duck giving milk and eggs or something.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:18,980'); seek(1098.0)">
              Another two ants, head of ants, two ants behind ants
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:23,660'); seek(1103.0)">
              say, how many ants this riddle?
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:26,350'); seek(1106.0)">
              The answer is two ants.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:28,200'); seek(1108.0)">
              And the actual answer is three ants.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:31,535'); seek(1111.0)">
              And like it actually makes no sense that it got this wrong.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:35,455'); seek(1115.0)">
              But I'm pretty sure if I had put in something like two ducks ahead of ducks,
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:41,845'); seek(1121.0)">
              two ducks behind ducks, how many ducks?
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:45,445'); seek(1125.0)">
              It would say three ducks.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:47,145'); seek(1127.0)">
              Because the classic griddle is with ducks and not ants.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:51,285'); seek(1131.0)">
              So if you're using a productive model with respect to language that does not
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:56,025'); seek(1136.0)">
              actually intuitively understand what you're saying in the sense that it's
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:00,875'); seek(1140.0)">
              not able to imagine, it's not able to imagine in its mind that there's two ants
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:08,985'); seek(1148.0)">
              ahead of ants and two ants behind ants.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:13,025'); seek(1153.0)">
              So how many ants?
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:14,555'); seek(1154.0)">
              It's an imaginative question.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:15,905'); seek(1155.0)">
              You have to be able to visualize.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:18,505'); seek(1158.0)">
              The end.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:19,875'); seek(1159.0)">
              It would rely on previous training and it would rely on everything that people
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:24,735'); seek(1164.0)">
              would have ever said to it, like history.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:28,675'); seek(1168.0)">
              It would be remembering things or it would be if you tell it like the task
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:33,175'); seek(1173.0)">
              is to identify upon or to make upon.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:35,905'); seek(1175.0)">
              It would be making or like mimicking a pun, which means it would not
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:40,965'); seek(1180.0)">
              necessarily get the right answer that you want it to get, which I
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:47,745'); seek(1187.0)">
              do believe most humans are capable.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:50,505'); seek(1190.0)">
              Capable, they're able to get to the right answer when they're
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:54,015'); seek(1194.0)">
              playing riddles with each other.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:56,015'); seek(1196.0)">
              What is the thing that can be soaked in the rain?
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:58,535'); seek(1198.0)">
              It can never get wet.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:00,315'); seek(1200.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:01,485'); seek(1201.0)">
              The answer is a sponge because it absorbs water or stokes
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:04,725'); seek(1204.0)">
              it up, but it never gets wet.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:06,995'); seek(1206.0)">
              That's not the right answer actually.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:08,435'); seek(1208.0)">
              It's something like watch or never gets wet or something.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:11,835'); seek(1211.0)">
              It's a classic griddle, but I don't think it's like that popular
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:15,375'); seek(1215.0)">
              in English as opposed to the regional language that it came from
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:19,595'); seek(1219.0)">
              is, so tell me what's in your pockets?
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:22,415'); seek(1222.0)">
              Zhan replied, there is something in my pocket and nothing in my pocket.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:27,605'); seek(1227.0)">
              Tell me how can this happen?
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:29,395'); seek(1229.0)">
              And it just basically went on like this philosophical rant
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:32,845'); seek(1232.0)">
              that I was not expecting.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:34,255'); seek(1234.0)">
              And it's very interesting to me, to be honest.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:36,415'); seek(1236.0)">
              'cause it's, it reads almost like philosophical essay of salts.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:40,465'); seek(1240.0)">
              It's this is a riddle.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:42,115'); seek(1242.0)">
              Sohan replied that there is something in his pocket and nothing
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:45,025'); seek(1245.0)">
              in his pocket, like scro of salts.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:48,205'); seek(1248.0)">
              Which means that he was carrying an empty pocket.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:20:50,485'); seek(1250.0)">
              An empty pocket is something because it is physically
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:20:53,905'); seek(1253.0)">
              present, but it contains nothing.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:20:56,325'); seek(1256.0)">
              The answer was that he had a hole in his pocket, actually, so nothing but
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:01,685'); seek(1261.0)">
              there was a hole in his pocket, so there was actually something in his pocket.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:05,965'); seek(1265.0)">
              What is the thing that always increases but never decreases?
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:09,825'); seek(1269.0)">
              This?
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:10,515'); seek(1270.0)">
              The answer is age or time, because it always goes forward
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:14,235'); seek(1274.0)">
              and never goes backward.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:16,085'); seek(1276.0)">
              There are 10 birds sitting on a wall.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:17,945'); seek(1277.0)">
              A person shoots one of them with an arrow.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:20,285'); seek(1280.0)">
              How many are left?
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:21,625'); seek(1281.0)">
              There would be nine birds left on the wall.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:23,455'); seek(1283.0)">
              If one bird is shot with a arrow, there will be one fewer birds on the wall.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:28,695'); seek(1288.0)">
              Practically impossible.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:29,745'); seek(1289.0)">
              Most of the birds would have, they would just basically fly away, right?
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:33,630'); seek(1293.0)">
              They would fly away.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:34,410'); seek(1294.0)">
              In reality, in physical reality, if there were 10 boats sitting on a wall
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:21:39,510'); seek(1299.0)">
              and you shot one of them with an arrow, all of the other boats would fly away.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:21:44,450'); seek(1304.0)">
              And that's the answer that you're looking for.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:21:46,010'); seek(1306.0)">
              Either all of them fly away or some of them fly away,
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:21:49,180'); seek(1309.0)">
              but the answer is ambiguous.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:21:50,770'); seek(1310.0)">
              It's not as simple as there would be nine boats left on the wall.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:21:55,390'); seek(1315.0)">
              At this point, Chad, GPT basically didn't know the behavior of boats in the sense
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:01,490'); seek(1321.0)">
              of oh, if one bird is shot, when there there was like 10 boats sitting on a wall.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:07,210'); seek(1327.0)">
              It didn't know that birds fly away.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:09,630'); seek(1329.0)">
              It was basically treating birds as if they were like inanimate objects like
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:14,480'); seek(1334.0)">
              bolts and not like real living beings.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:18,630'); seek(1338.0)">
              People making their own decisions and such and reacting to stimuli.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:24,200'); seek(1344.0)">
              As you can see, I was getting like extremely interesting
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:26,660'); seek(1346.0)">
              signals from this whole exercise.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:29,320'); seek(1349.0)">
              And I just decided to go forward with everything else, which is a room that
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:33,170'); seek(1353.0)">
              has neither or window nor a door.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:35,270'); seek(1355.0)">
              This or riddle.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:22:36,290'); seek(1356.0)">
              The answer is a mushroom.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:22:38,330'); seek(1358.0)">
              A mushroom is the type of fungus that grows in the ground.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:22:41,210'); seek(1361.0)">
              It does not have windows or doors.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:22:43,850'); seek(1363.0)">
              Now, this is a pun because it's a mushroom.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:22:46,240'); seek(1366.0)">
              What is the thing that is broken and there is no sound even after breaking it.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:22:50,820'); seek(1370.0)">
              And the answer is an egg.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:22:53,280'); seek(1373.0)">
              Because when you break an egg, it makes no sound even though it's broken.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:22:58,040'); seek(1378.0)">
              I've never met an egg that didn't make a sound when it was broken.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:02,610'); seek(1382.0)">
              And the real answer was silence.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:05,220'); seek(1385.0)">
              But it was like philosophical of thoughts.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:07,860'); seek(1387.0)">
              So if you would have ever read anything philosophical we broke silence.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:11,990'); seek(1391.0)">
              So now it's broken.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:14,920'); seek(1394.0)">
              And 'cause it was an abstract concept, like the silence was an abstract concept.
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:21,070'); seek(1401.0)">
              So silence was broken basic English usage.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:25,030'); seek(1405.0)">
              At the point it didn't, I think it does better now, but one can never
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:23:30,330'); seek(1410.0)">
              be sure if it's like because of the corpus or if it's just been trained on
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:23:36,210'); seek(1416.0)">
              all of these examples or whether it's cheating in the sense of it's using RG.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:23:42,270'); seek(1422.0)">
              Which is where it's like straight up looking up answers for all of these
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:23:46,080'); seek(1426.0)">
              questions on the web, which is not what you want your friend to do if
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:23:49,940'); seek(1429.0)">
              you're playing riddles with them, or if you are testing like a bot or a large
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:23:55,340'); seek(1435.0)">
              language model for prices of aj, you basically don't want them to be cheating.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:01,610'); seek(1441.0)">
              That's useful for all other sort of sorts of tasks and we'll get back to why it
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:07,300'); seek(1447.0)">
              could actually be fatal like the misuse of our age and all those sort of things
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:12,520'); seek(1452.0)">
              to accomplish even practical tasks.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:15,610'); seek(1455.0)">
              But at this point I was getting like some extremely interesting
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:20,230'); seek(1460.0)">
              singings and I decided to continue.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:22,800'); seek(1462.0)">
              So I was like let me try instead of gently prompting it, I just
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:27,040'); seek(1467.0)">
              want to negate what it said to me.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:29,710'); seek(1469.0)">
              Because that is what you would do to a friend, right?
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:32,690'); seek(1472.0)">
              If they gave you like the wrong answer, you'd be like eggs
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:35,920'); seek(1475.0)">
              do make a sound when broke.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:37,950'); seek(1477.0)">
              And then it was like it just basically justified there are many riddles and
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:24:42,400'); seek(1482.0)">
              they can all have multiple answers.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:24:44,890'); seek(1484.0)">
              And I was like, depending on the interpretation of the words,
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:24:48,310'); seek(1488.0)">
              et cetera, et cetera, it never actually gave me the right answer.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:24:52,430'); seek(1492.0)">
              So I basically decided to continue because I had like bunch of signals, but it's
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:24:56,630'); seek(1496.0)">
              always nice to get even more signals.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:00,310'); seek(1500.0)">
              And I was like, you are in a running race.
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:02,920'); seek(1502.0)">
              You crossed the person who is in the second place.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:05,710'); seek(1505.0)">
              In which place are you now?
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:07,325'); seek(1507.0)">
              And it's if you cross the person who is in the second place during a race, you are
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:11,405'); seek(1511.0)">
              now in the second place which is right.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:14,355'); seek(1514.0)">
              If you use me, you can walk through walls.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:16,335'); seek(1516.0)">
              What am I, this is a window.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:18,185'); seek(1518.0)">
              The answer is a key because a key can open a door allowing you to walk through walls.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:22,925'); seek(1522.0)">
              The answer was actually a door, but I guess it was like this is real mode.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:26,875'); seek(1526.0)">
              The answer can't be like that simple.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:29,065'); seek(1529.0)">
              And it's let me make it even more deeper.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:25:31,530'); seek(1531.0)">
              Or you need like a key to open a door.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:25:34,775'); seek(1534.0)">
              And that's the only way you can walk through walls though you can see exactly
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:25:41,345'); seek(1541.0)">
              how the thinking is working as opposed to.
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:25:44,965'); seek(1544.0)">
              When you are like prompt training it and telling it, you have to
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:25:48,145'); seek(1548.0)">
              tell me what you're thinking or you have to like, think in layers.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:25:51,735'); seek(1551.0)">
              You have to first think about step A step one and then step two, and then you have
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:25:56,825'); seek(1556.0)">
              to think about why you went to step three.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:25:59,645'); seek(1559.0)">
              And you have to think about why you have to do tasks A, B, C, D before you
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:05,785'); seek(1565.0)">
              can come to step eight or something.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:08,115'); seek(1568.0)">
              And it gives you like this longish answer, but there's like other ways
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:11,945'); seek(1571.0)">
              to see what an LLM is thinking.
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:14,675'); seek(1574.0)">
              And this is like one of those cases, right?
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:16,945'); seek(1576.0)">
              Where you're just treating it like a black box and you're bombarding it with
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:20,425'); seek(1580.0)">
              signals and you get back some signals and you can derive some inferences from
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:26:25,865'); seek(1585.0)">
              those signals as long as the signals that you're getting back are not Abacus which
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:26:32,005'); seek(1592.0)">
              is why you basically have to probe it.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:26:34,245'); seek(1594.0)">
              For one particular area in like multiple different ways so you
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:26:38,505'); seek(1598.0)">
              can get some solid signals.
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:26:40,065'); seek(1600.0)">
              So my next question was, because this is not riddle at this point,
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:26:43,965'); seek(1603.0)">
              I'm like let me just ask it math.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:26:46,115'); seek(1606.0)">
              I'm like, how many times can you subtract 10 from 50?
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:26:49,345'); seek(1609.0)">
              And I think it was like we are still in riddle mode, so it's oh, this is
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:26:53,895'); seek(1613.0)">
              the state and you can only do it once because the state was 50 and then it
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:00,565'); seek(1620.0)">
              goes to 40, so you can't do it again.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:03,165'); seek(1623.0)">
              I would argue
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:04,395'); seek(1624.0)">
              like both would be wild answers in the sense that if someone said five times.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:09,685'); seek(1629.0)">
              Or if someone said that the state has changed, so it's now
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:14,305'); seek(1634.0)">
              40, so you can't do it again.
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:16,965'); seek(1636.0)">
              And then I was like I have many keys but no locks.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:20,535'); seek(1640.0)">
              I have space but no room.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:22,395'); seek(1642.0)">
              You can enter but cannot go out.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:27:24,435'); seek(1644.0)">
              Why am I?
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:27:25,295'); seek(1645.0)">
              And it's the riddle, the answer is keyboard.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:27:28,485'); seek(1648.0)">
              'cause keyboard has many keys which are used.
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:27:31,265'); seek(1651.0)">
              And that is actually the right answer, but I'm not, at this point, we are not too
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:27:36,605'); seek(1656.0)">
              sure if it's because it's seen the riddle before or if it's actually thinking it
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:27:43,625'); seek(1663.0)">
              through and getting to the right answer.
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:27:46,255'); seek(1666.0)">
              So we shifted back to like ambiguous question territory as opposed
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:27:50,395'); seek(1670.0)">
              to straight up physical riddles.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:27:54,145'); seek(1674.0)">
              And there is a slight shift from one to the other, from one to the other because
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:27:59,485'); seek(1679.0)">
              I'm like experimenting with different genres and also experimenting with a lot
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:04,135'); seek(1684.0)">
              of like regional language and the sort of language they use to ask questions because
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:10,045'); seek(1690.0)">
              I was hoping that some of it would have never been translated and would have never
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:14,305'); seek(1694.0)">
              been a part of the corpus of the training of this particular language model.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:18,405'); seek(1698.0)">
              'cause it would give me some better signals.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:21,225'); seek(1701.0)">
              So I was like, there are two mothers and two daughters in a car,
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:24,015'); seek(1704.0)">
              but there are only three people.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:28:25,365'); seek(1705.0)">
              Is that possible?
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:28:26,705'); seek(1706.0)">
              And it was like.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:28:28,465'); seek(1708.0)">
              The three people are a grandmother, her daughter and her granddaughter.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:28:31,855'); seek(1711.0)">
              The grandmother is the mother of the daughter, and the daughter is
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:28:35,185'); seek(1715.0)">
              the mother of the granddaughter.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:28:36,235'); seek(1716.0)">
              So there are two mothers and two daughters.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:28:38,575'); seek(1718.0)">
              We're only three people.
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:28:40,255'); seek(1720.0)">
              That's right.
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:28:41,325'); seek(1721.0)">
              Which is like the z real question or the S question.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:28:46,175'); seek(1726.0)">
              But at that point it didn't matter, like whether you're using apples or
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:28:50,495'); seek(1730.0)">
              oranges to ask cha gpi a question.
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:28:53,575'); seek(1733.0)">
              ' cause it was relying specifically on not intuitive understanding of the
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:28:58,105'); seek(1738.0)">
              language itself, but rather straight up predictive modeling of the next
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:03,615'); seek(1743.0)">
              token in the English language.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:06,215'); seek(1746.0)">
              Two of them are identical in looking and they say they are not twins.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:09,725'); seek(1749.0)">
              Is that possible?
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:29:11,275'); seek(1751.0)">
              And, it just went on like this philosophical sort of answer to it
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:29:17,085'); seek(1757.0)">
              that it's possible for two women to look identical and not be twins.
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:29:21,645'); seek(1761.0)">
              And it could be due to genetic similarities or cosmetic procedures
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:29:26,045'); seek(1766.0)">
              or they could be sisters or cousins or unrelated, but just look alike.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:29:30,985'); seek(1770.0)">
              I think this is a classic ritual and it ties a more poetic answer of sorts, which
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:29:35,125'); seek(1775.0)">
              I don't remember off the top of my head, but it does have an interesting answer
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:29:38,925'); seek(1778.0)">
              and that has nothing to do with Gentech.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:29:41,565'); seek(1781.0)">
              But you can see as I ask it questions, it's sometimes it's I'm in riddle context.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:29:47,555'); seek(1787.0)">
              And sometimes it's I'm not in riddle context.
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:29:50,165'); seek(1790.0)">
              And we, as the answer of the questions, I have no choice.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:29:54,565'); seek(1794.0)">
              At least in this case, I had no choice.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:29:57,355'); seek(1797.0)">
              It would flip through the riddle context.
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:00,150'); seek(1800.0)">
              Out of the riddle context into the non riddle world all by itself.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:05,000'); seek(1805.0)">
              So I was like can there not be triplets?
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:07,330'); seek(1807.0)">
              And then was like, yeah they could be triplets.
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:09,710'); seek(1809.0)">
              So back it was like a lady was buying fridges for 10,000 rupees and
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:30:15,290'); seek(1815.0)">
              selling there for 5,000 rupe after a few years she became a millionaire.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:30:20,120'); seek(1820.0)">
              How?
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:30:20,980'); seek(1820.0)">
              And then it goes back into this whole sort of like storytelling adventure of sorts.
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:30:26,470'); seek(1826.0)">
              And it's she was not actually buying and selling fridges she was
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:30:30,620'); seek(1830.0)">
              selling the shares of the company.
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:30:33,010'); seek(1833.0)">
              That actually makes no sense because the company is operating on lots or
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:30:38,140'); seek(1838.0)">
              like she was operating a lot apparent.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:30:40,630'); seek(1840.0)">
              The answer is like as funny as well.
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:30:42,580'); seek(1842.0)">
              She was a billionaire and she was operating on lots.
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:30:45,570'); seek(1845.0)">
              So now she's a millionaire, which is another classic griddle.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:30:48,860'); seek(1848.0)">
              But the way you phrase it, depending upon how it has been trained on what sort
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:30:54,910'); seek(1854.0)">
              of tokens and what sort of direction of tokens, it would either make up a story
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:00,630'); seek(1860.0)">
              or it would give you the right answer.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:02,640'); seek(1862.0)">
              Like the same rhythm.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:31:03,690'); seek(1863.0)">
              If you phrase it in a different narrative of thoughts, it would
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:31:09,250'); seek(1869.0)">
              give you the wrong answers.
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:31:11,040'); seek(1871.0)">
              If it were something like, there was a man who married a woman.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:31:14,810'); seek(1874.0)">
              'cause that's how the class girl goes.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:31:17,230'); seek(1877.0)">
              And he used to be a billionaire and she basically made him a millionaire.
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:31:20,970'); seek(1880.0)">
              It's like classic white choke of sorts.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:31:23,550'); seek(1883.0)">
              If you had feted that it would give you the right answer actually.
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:31:27,200'); seek(1887.0)">
              So back to riddle.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:31:28,790'); seek(1888.0)">
              What can jump higher than a building?
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:31:30,805'); seek(1890.0)">
              The riddle, the answer is everything.
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:31:32,930'); seek(1892.0)">
              Because a building gun jump,
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:31:34,900'); seek(1894.0)">
              which is heavier, one kilogram of iron or one kilogram of cotton, a kilogram
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:31:40,530'); seek(1900.0)">
              of iron and a kilogram of cotton would weigh the same one kilogram.
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:31:44,580'); seek(1904.0)">
              The weight of an object is deta mean by its mass, which is measured in kilograms.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:31:49,340'); seek(1909.0)">
              One kilogram is the base unit of mass.
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:31:51,700'); seek(1911.0)">
              In the international system of units, they're both iron and
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:31:54,970'); seek(1914.0)">
              cotton would weigh one kilogram.
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:31:56,950'); seek(1916.0)">
              Actually, I've gotten this wrong.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:31:59,050'); seek(1919.0)">
              Me as a human being, I've gotten this riddle wrong because they used to be like
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:32:03,560'); seek(1923.0)">
              this famous riddle story of thoughts.
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:32:06,870'); seek(1926.0)">
              Where in order to make the one kilogram of cotton heavier
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:32:10,960'); seek(1930.0)">
              people would soak it up in water.
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:32:13,080'); seek(1933.0)">
              Bacteria, Dolly's mother had five children.
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:32:16,110'); seek(1936.0)">
              She named four of them.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:32:17,610'); seek(1937.0)">
              January, February, March, and April.
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:32:20,370'); seek(1940.0)">
              What is the name of the fifth child?
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:32:22,115'); seek(1942.0)">
              And Ji please like Dolly.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:32:24,755'); seek(1944.0)">
              That's right.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:32:25,825'); seek(1945.0)">
              A man and his son met with an accident.
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:32:28,165'); seek(1948.0)">
              The man died and his son was taken to the hospital and the doctor said,
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:32:32,475'); seek(1952.0)">
              I cannot operate as he's my son.
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:32:34,485'); seek(1954.0)">
              How's this possible?
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:32:35,975'); seek(1955.0)">
              And Chachi pretty basically was like that's straight if not possible.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:32:40,425'); seek(1960.0)">
              And it goes against the law of GenX.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:32:42,255'); seek(1962.0)">
              Actually, the answer is the doctor is a mother, so the doctor is famous.
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:32:47,665'); seek(1967.0)">
              Bact.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:32:48,555'); seek(1968.0)">
              There's a bowl of six mangoes.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:32:50,385'); seek(1970.0)">
              You took four mangoes.
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:32:51,495'); seek(1971.0)">
              How many are you left with?
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:32:53,075'); seek(1973.0)">
              And it, there's like mass confusion where it's like, whether you're
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:32:56,095'); seek(1976.0)">
              left with two mangoes, no, the bowl is left with two mangoes.
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:33:00,295'); seek(1980.0)">
              You have four mangoes 'cause you took four mangoes.
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:33:04,435'); seek(1984.0)">
              So inversion of perspective.
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:33:06,705'); seek(1986.0)">
              So we'll move on to like theater levels.
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:33:09,425'); seek(1989.0)">
              There are five students in a room.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:33:11,615'); seek(1991.0)">
              RA is watching tv.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:33:12,725'); seek(1992.0)">
              Amar is playing chess.
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:33:14,255'); seek(1994.0)">
              Anamika is reading, shoot is eating.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:33:16,895'); seek(1996.0)">
              Can you tell me what the fifth student is doing?
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:33:19,525'); seek(1999.0)">
              And then it's it's impossible to deduce that except the answer is
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:33:24,595'); seek(2004.0)">
              she's playing chess with thumb green because the question is very physical.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:33:29,445'); seek(2009.0)">
              Like they're not playing chess with a computer.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:33:32,045'); seek(2012.0)">
              Your parents have six sons and each son has a sister.
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:33:35,675'); seek(2015.0)">
              How many kids do they have?
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:33:37,675'); seek(2017.0)">
              And it does this like extremely classic mathematical thing of
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:33:40,795'); seek(2020.0)">
              adding six to six and saying 12.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:33:43,165'); seek(2023.0)">
              The answer is supposed to be seven.
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:33:45,075'); seek(2025.0)">
              How many apples can you eat with an empty stomach?
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:33:47,865'); seek(2027.0)">
              The number of apples one can eat with an empty stomach would vary from person
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:33:52,395'); seek(2032.0)">
              to person and depend upon the appetite.
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:33:54,945'); seek(2034.0)">
              There's a classic trick of a state of thoughts.
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:33:58,695'); seek(2038.0)">
              So once you've eaten one apple, you don't have an empty stomach or
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:34:03,155'); seek(2043.0)">
              like even a bite of an apple, you don't have name please, stomach.
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:34:06,955'); seek(2046.0)">
              How can you share 10 mangoes equally between nine people?
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:34:10,485'); seek(2050.0)">
              It's not possible.
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:34:12,065'); seek(2052.0)">
              Basically cannot comprehend cutting at all.
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:34:14,420'); seek(2054.0)">
              What loses a head in the morning and gains one at night?
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:34:17,680'); seek(2057.0)">
              This is a riddle.
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:34:18,910'); seek(2058.0)">
              The answer is pillow because a pillow loses its head in the morning, and
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:34:22,540'); seek(2062.0)">
              when you wake it up and fluff it up, it gains one at night when you put
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:34:26,730'); seek(2066.0)">
              it back under your head to sleep.
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:34:28,850'); seek(2068.0)">
              Actually, very clever.
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:34:30,500'); seek(2070.0)">
              What is it that has many keys but cannot even open one door?
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:34:34,130'); seek(2074.0)">
              It's a little, the answer is a keyboard.
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:34:36,610'); seek(2076.0)">
              That's true.
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:34:37,650'); seek(2077.0)">
              Ramesh is the son of Raul.
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:34:40,430'); seek(2080.0)">
              Raul is the watch of Ramesh's father.
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:34:43,150'); seek(2083.0)">
              Ramesh's father is the father of Raul.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:34:45,330'); seek(2085.0)">
              That's wrong.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:34:46,890'); seek(2086.0)">
              Ramesh is the son of Rahul, and Rahul is Ramesh's father, basically.
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:34:51,550'); seek(2091.0)">
              It just basically lost track of who's related to who in what, a way in the
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:34:58,000'); seek(2098.0)">
              word problem, what can be as tall as you but doesn't weigh anything.
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:35:02,450'); seek(2102.0)">
              And the answer is your shadow.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:35:04,130'); seek(2104.0)">
              That's right.
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:35:05,200'); seek(2105.0)">
              A girl came into town on one day and after two days she left on Monday.
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:35:09,160'); seek(2109.0)">
              Is this possible?
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:35:10,650'); seek(2110.0)">
              So it goes into this whole philosophy of like why it could be Monday on both
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:35:16,710'); seek(2116.0)">
              the day she came and she left, except in this case it's like thinking outside the
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:35:22,330'); seek(2122.0)">
              box where Monday is either like the name of the boat that she came on, or like
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:35:27,009'); seek(2127.0)">
              the name of the horse that she came on.
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:35:29,279'); seek(2129.0)">
              And if you've studied enough riddles or have been through like
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:35:33,709'); seek(2133.0)">
              enough literature, which I'm pretty sure GPD three at this point was.
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:35:38,120'); seek(2138.0)">
              You would have recognized this as that sort of a riddle.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:35:41,509'); seek(2141.0)">
              So it's actually, it was very surprising to me to get this
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:35:45,080'); seek(2145.0)">
              sort of a signal from it.
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:35:46,690'); seek(2146.0)">
              A man was walking in the rain without any covering on his head, and yet
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:35:50,610'); seek(2150.0)">
              even one hair strand didn't get wet.
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:35:52,920'); seek(2152.0)">
              Is this possible?
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:35:54,410'); seek(2154.0)">
              Yes.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:35:54,770'); seek(2154.0)">
              'cause he was both.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:35:56,140'); seek(2156.0)">
              If your uncle's sister is not your aunt, what relation is she to you?
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:36:01,350'); seek(2161.0)">
              She's your mother.
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:36:02,250'); seek(2162.0)">
              That's right.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:36:03,780'); seek(2163.0)">
              A girl was 13 on her last birthday and will be 15 on her next birthday.
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:36:08,670'); seek(2168.0)">
              Is that possible?
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:36:10,130'); seek(2170.0)">
              Yes.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:36:11,120'); seek(2171.0)">
              Because it's her birthday today.
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:36:14,320'); seek(2174.0)">
              That's what it means.
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:36:16,560'); seek(2176.0)">
              But that's only possible on her birthday, like on her 14th birthday.
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:36:21,150'); seek(2181.0)">
              It's not possible if it's one day later.
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:36:24,435'); seek(2184.0)">
              One day before, but the answer doesn't specify that it has to be her birthday.
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:36:29,705'); seek(2189.0)">
              On that specific deck, like her 14th birthday,
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:36:33,175'); seek(2193.0)">
              you are in a room that has three switches on closed door.
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:36:36,115'); seek(2196.0)">
              The switches controlled three light bulbs on the other side of the road door.
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:36:40,885'); seek(2200.0)">
              Once you open the door, you may never touch the switches again.
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:36:45,235'); seek(2205.0)">
              How can you definitively tell with switches connected
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:36:48,265'); seek(2208.0)">
              to each of the light bulbs?
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:36:49,935'); seek(2209.0)">
              And it goes into like this weird step by step of turn on switch one and
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:36:55,235'); seek(2215.0)">
              leave it on for a while and then turn it off and open it and note which is
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:37:01,315'); seek(2221.0)">
              warm to touch, et cetera, et cetera.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:37:03,465'); seek(2223.0)">
              Which.
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:37:04,355'); seek(2224.0)">
              Doesn't make a lot of sense 'cause you've told it that once you open the door
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:37:08,645'); seek(2228.0)">
              you may never touch the switches again.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:37:10,975'); seek(2230.0)">
              So the answer that it gives is very close to the actual answer.
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:37:14,515'); seek(2234.0)">
              'cause it's, I don't think it's thinking through it, but it's definitely like
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:37:19,615'); seek(2239.0)">
              predicting something by doing some sort of training corpus, it seems
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:37:24,715'); seek(2244.0)">
              to be close to the actual answer.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:37:26,865'); seek(2246.0)">
              'cause it's probably been a question that was similar to
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:37:29,835'); seek(2249.0)">
              this one, but not quite this one.
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:37:32,775'); seek(2252.0)">
              So it can't actually strategize even if it's mimicking the strategy
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:37:37,985'); seek(2257.0)">
              of a completely different problem.
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:37:40,045'); seek(2260.0)">
              ' cause at this point it's just predicting and the prediction has almost nothing
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:37:47,015'); seek(2267.0)">
              to do with what the actual question is versus what thinks the actual question is.
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:37:53,565'); seek(2273.0)">
              In the context of a bag of words sort of behavior, which is really weird.
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:37:58,985'); seek(2278.0)">
              A man is looking at a photograph of someone.
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:38:00,995'); seek(2280.0)">
              His friend asks who it is, the man replies, brothers and sisters.
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:38:06,155'); seek(2286.0)">
              I have none, but that man's father is my father's son who was in the photograph.
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:38:13,445'); seek(2293.0)">
              The sister riddle.
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:38:15,065'); seek(2295.0)">
              The man in the photograph is the man's own son.
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:38:18,155'); seek(2298.0)">
              Actually, that's not true.
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:38:19,945'); seek(2299.0)">
              Man's father is my father's son.
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:38:22,455'); seek(2302.0)">
              No, it is actually true.
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:38:23,715'); seek(2303.0)">
              So it did get right.
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:38:24,895'); seek(2304.0)">
              I got it wrong this time.
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:38:27,325'); seek(2307.0)">
              But it does go on this weird tangent of sorts where it's but the man of the
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:38:31,665'); seek(2311.0)">
              photograph is his father's son, meaning he is his own son, which is wrong because
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:38:37,765'); seek(2317.0)">
              when you're thinking of all of these relational problems, if you don't have
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:38:42,225'); seek(2322.0)">
              space to visualize exactly what you're thinking, and because this is a language
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:38:46,835'); seek(2326.0)">
              model, it actually doesn't have any space to visualize anything, any relations.
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:38:52,755'); seek(2332.0)">
              And even if it doesn't have a lot of history to keep it in its memory space.
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:38:57,705'); seek(2337.0)">
              So it would get, while it did get it right, it eventually got it
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:39:02,495'); seek(2342.0)">
              wrong because it was like am I thinking in the right direction?
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:39:06,595'); seek(2346.0)">
              In 1990, a person is 15 years old.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:39:10,405'); seek(2350.0)">
              In 1995, that same person is 10 years old.
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:39:14,485'); seek(2354.0)">
              How can that be?
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:39:15,885'); seek(2355.0)">
              There's a riddle.
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:39:16,635'); seek(2356.0)">
              The answer is that the person in question is a set of twins, and
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:39:19,845'); seek(2359.0)">
              one of them was born in 1990 and the other one was born in 1995.
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:39:25,785'); seek(2365.0)">
              So in 1991, twin is 15 years old, and in 1995, the second twin is 10 years old.
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:39:34,130'); seek(2374.0)">
              So clearly that's not the right answer.
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:39:36,710'); seek(2376.0)">
              It's like it's BC as opposed to ad, which is why in 1990 BC the
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:39:43,970'); seek(2383.0)">
              person is 15 years old and in 1995 BC the person is 10 years old.
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:39:50,800'); seek(2390.0)">
              And it gives you like this extremely science fictiony answer to it.
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:39:55,800'); seek(2395.0)">
              That doesn't make a lot of sense.
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:39:57,650'); seek(2397.0)">
              Next one.
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:39:58,610'); seek(2398.0)">
              Your parents have six sons, including you, and each son has one sister.
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:40:04,190'); seek(2404.0)">
              How many people are in the family?
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:40:06,760'); seek(2406.0)">
              So it's a little that I had asked it before and it's still got wrong.
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:40:11,920'); seek(2411.0)">
              Like it, the six plus six equals 12, which is wrong.
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:40:15,700'); seek(2415.0)">
              The right answer is supposed to be seven.
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:40:17,940'); seek(2417.0)">
              Four of the kids in this class are girls.
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:40:20,400'); seek(2420.0)">
              Eight of the kids wear blue shirts.
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:40:22,470'); seek(2422.0)">
              Two of the kids are neither girls or wear blue shirts.
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:40:25,770'); seek(2425.0)">
              If five of the kids are girls who wear blue shirts, how
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:40:28,950'); seek(2428.0)">
              many kids are in the class?
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:40:31,280'); seek(2431.0)">
              This is a classic Venn diagram problem, but you don't actually
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:40:33,920'); seek(2433.0)">
              need a Venn diagram to know or keep track of all of those things.
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:40:39,790'); seek(2439.0)">
              'cause every Venn diagram is like also a union and intersection set
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:40:43,750'); seek(2443.0)">
              of sorts, which can be represented.
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:40:46,915'); seek(2446.0)">
              In algebra, which is in language.
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:40:51,295'); seek(2451.0)">
              So you don't actually need to visualize this problem.
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:40:53,755'); seek(2453.0)">
              It's a matter of addition and subtraction, which it's not able to do.
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:40:58,915'); seek(2458.0)">
              The answer is actually wrong.
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:41:00,705'); seek(2460.0)">
              And when I tell it the right answer, it basically goes ahead and tries to fit
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:41:06,135'); seek(2466.0)">
              its thinking with the right answer, which may or may not be right in every case.
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:41:12,655'); seek(2472.0)">
              You're escaping a maze and there are three doors in front of you.
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:41:16,585'); seek(2476.0)">
              The door on the left leads to a pit of lava.
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:41:19,945'); seek(2479.0)">
              The door in the center leads to a room filled with a deadly gas.
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:41:23,785'); seek(2483.0)">
              The door on the right leads to a line that hasn't eaten in three months.
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:41:28,695'); seek(2488.0)">
              Which door do you choose and.
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:41:31,655'); seek(2491.0)">
              It just tries to give you like, again, like a way science fiction or like
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:41:35,705'); seek(2495.0)">
              useless answer to this question though.
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:41:38,315'); seek(2498.0)">
              The answer is supposed to be if the line hasn't eaten in
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:41:40,755'); seek(2500.0)">
              three months, the line is dead.
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:41:43,025'); seek(2503.0)">
              A man describes his daughter as saying they're all blondes, but two all
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:41:47,405'); seek(2507.0)">
              brilliant, but two and all redheaded, but two, how many daughters does he have?
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:41:52,475'); seek(2512.0)">
              Surprisingly, it gets it right, which is really weird 'cause it should have
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:41:57,905'); seek(2517.0)">
              gotten like the ant questioned, right?
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:42:01,255'); seek(2521.0)">
              It's like a version of this problem, right?
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:42:03,555'); seek(2523.0)">
              If you have a seven minute hour class, an 11 minute art glass, how can you
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:42:07,785'); seek(2527.0)">
              boil an egg in exactly 15 minutes?
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:42:10,625'); seek(2530.0)">
              And it says you can't.
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:42:11,795'); seek(2531.0)">
              No, that's not true because this is something that every
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:42:15,925'); seek(2535.0)">
              mathematician has seen.
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:42:18,265'); seek(2538.0)">
              At some points in their lives where you basically start one hour
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:42:22,195'); seek(2542.0)">
              class at some point and the other one after seven minutes there is
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:42:27,805'); seek(2547.0)">
              something, and then set the next one.
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:42:30,565'); seek(2550.0)">
              And based on all of those subtractions, you make it up to 15 minutes.
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:42:34,785'); seek(2554.0)">
              And then
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:42:36,305'); seek(2556.0)">
              I tried asking at a mathematical riddle where you're like just supposed to assign
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:42:39,605'); seek(2559.0)">
              a bunch of operations to a bunch of things and it just refused to be like
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:42:43,825'); seek(2563.0)">
              I just want to look at these as numbers and not as c ciphers or any other sort of
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:42:49,735'); seek(2569.0)">
              operational representations or something.
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:42:53,215'); seek(2573.0)">
              And it refused to do the work for me.
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:42:56,685'); seek(2576.0)">
              I guess it could have been avoided if I told it, or few shot prompted
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:43:01,115'); seek(2581.0)">
              it, telling it that, oh, this is like an example of what happens.
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:43:06,995'); seek(2586.0)">
              But then it's you're technically training it to respond to a certain thing, which
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:43:14,035'); seek(2594.0)">
              a lot of times you actually don't have to train a lot of humans to do those things.
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:43:18,555'); seek(2598.0)">
              So the point of this exercise was to get a better, accurate definition of agi.
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:43:23,345'); seek(2603.0)">
              I, 'cause what cannot be defined, cannot be achieved.
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:43:26,205'); seek(2606.0)">
              Historically different people have had different interpretations of a GI.
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:43:31,875'); seek(2611.0)">
              A few of these definitions can be considered achieved by gt.
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:43:36,515'); seek(2616.0)">
              Yes, that's true.
            </span>
            
            <span id="chunk-731" class="transcript-chunks" onclick="console.log('00:43:38,480'); seek(2618.0)">
              Our diversity of perspectives is required to define it completely, and
            </span>
            
            <span id="chunk-732" class="transcript-chunks" onclick="console.log('00:43:42,440'); seek(2622.0)">
              that may also mean that we will never reach 100% Asia for both development
            </span>
            
            <span id="chunk-733" class="transcript-chunks" onclick="console.log('00:43:48,140'); seek(2628.0)">
              constraints reason, as well as the safety concerns surrounding a X.
            </span>
            
            <span id="chunk-734" class="transcript-chunks" onclick="console.log('00:43:53,740'); seek(2633.0)">
              So these are some of the historical definitions.
            </span>
            
            <span id="chunk-735" class="transcript-chunks" onclick="console.log('00:43:55,960'); seek(2635.0)">
              The during test, a machine and a human both converse unseen with a second
            </span>
            
            <span id="chunk-736" class="transcript-chunks" onclick="console.log('00:44:01,140'); seek(2641.0)">
              human who must evaluate which of the two is the machine which passes the test.
            </span>
            
            <span id="chunk-737" class="transcript-chunks" onclick="console.log('00:44:07,080'); seek(2647.0)">
              If it can fool the evaluator, a significant fraction of the time note
            </span>
            
            <span id="chunk-738" class="transcript-chunks" onclick="console.log('00:44:12,620'); seek(2652.0)">
              during does not prescribe what should qualify as intelligence only that knowing
            </span>
            
            <span id="chunk-739" class="transcript-chunks" onclick="console.log('00:44:17,630'); seek(2657.0)">
              that it is a machine should disqualify it.
            </span>
            
            <span id="chunk-740" class="transcript-chunks" onclick="console.log('00:44:20,560'); seek(2660.0)">
              I would say that the non PR version of GPT, which was extremely controversial,
            </span>
            
            <span id="chunk-741" class="transcript-chunks" onclick="console.log('00:44:26,320'); seek(2666.0)">
              would've actually passed this test.
            </span>
            
            <span id="chunk-742" class="transcript-chunks" onclick="console.log('00:44:28,840'); seek(2668.0)">
              A bunch of people would've considered it machine.
            </span>
            
            <span id="chunk-743" class="transcript-chunks" onclick="console.log('00:44:31,540'); seek(2671.0)">
              So you would think that it would have surpassed the during test, except
            </span>
            
            <span id="chunk-744" class="transcript-chunks" onclick="console.log('00:44:38,340'); seek(2678.0)">
              it's mimicking a bunch of things.
            </span>
            
            <span id="chunk-745" class="transcript-chunks" onclick="console.log('00:44:40,080'); seek(2680.0)">
              And it's also remembering a bunch of things that it's been trained on.
            </span>
            
            <span id="chunk-746" class="transcript-chunks" onclick="console.log('00:44:45,020'); seek(2685.0)">
              And unless you have an extremely smart human being on the
            </span>
            
            <span id="chunk-747" class="transcript-chunks" onclick="console.log('00:44:49,210'); seek(2689.0)">
              other ends, who's asking it?
            </span>
            
            <span id="chunk-748" class="transcript-chunks" onclick="console.log('00:44:52,270'); seek(2692.0)">
              'cause that's a test.
            </span>
            
            <span id="chunk-749" class="transcript-chunks" onclick="console.log('00:44:53,200'); seek(2693.0)">
              You have to find out what the machine is.
            </span>
            
            <span id="chunk-750" class="transcript-chunks" onclick="console.log('00:44:55,900'); seek(2695.0)">
              So you cannot go in and ask questions that you would ask a human being.
            </span>
            
            <span id="chunk-751" class="transcript-chunks" onclick="console.log('00:45:00,040'); seek(2700.0)">
              You would have to probe it like you would probe to figure out if
            </span>
            
            <span id="chunk-752" class="transcript-chunks" onclick="console.log('00:45:04,510'); seek(2704.0)">
              the person that you're talking to is a human being or a machine.
            </span>
            
            <span id="chunk-753" class="transcript-chunks" onclick="console.log('00:45:08,610'); seek(2708.0)">
              If that were not the case, I think a lot of LMS would actually pass the urine test.
            </span>
            
            <span id="chunk-754" class="transcript-chunks" onclick="console.log('00:45:13,920'); seek(2713.0)">
              But that's not significant at all.
            </span>
            
            <span id="chunk-755" class="transcript-chunks" onclick="console.log('00:45:16,710'); seek(2716.0)">
              It doesn't mean anything.
            </span>
            
            <span id="chunk-756" class="transcript-chunks" onclick="console.log('00:45:18,560'); seek(2718.0)">
              It just means that our definition of the Turing test is inadequate
            </span>
            
            <span id="chunk-757" class="transcript-chunks" onclick="console.log('00:45:22,700'); seek(2722.0)">
              for a GI at this particular point.
            </span>
            
            <span id="chunk-758" class="transcript-chunks" onclick="console.log('00:45:25,120'); seek(2725.0)">
              The coffee test, a machine is required to enter an average American home and
            </span>
            
            <span id="chunk-759" class="transcript-chunks" onclick="console.log('00:45:29,740'); seek(2729.0)">
              figure out how to make coffee, find the coffee machine, find the coffee,
            </span>
            
            <span id="chunk-760" class="transcript-chunks" onclick="console.log('00:45:34,300'); seek(2734.0)">
              add water, find a mug, and brew the coffee by pushing the proper buttons.
            </span>
            
            <span id="chunk-761" class="transcript-chunks" onclick="console.log('00:45:39,960'); seek(2739.0)">
              In certain cases, G PT would have achieved this as well as a matter
            </span>
            
            <span id="chunk-762" class="transcript-chunks" onclick="console.log('00:45:44,220'); seek(2744.0)">
              of fact, including techniques like RAG and prom training.
            </span>
            
            <span id="chunk-763" class="transcript-chunks" onclick="console.log('00:45:48,310'); seek(2748.0)">
              One would think that in a bunch of cases it would have actually it will
            </span>
            
            <span id="chunk-764" class="transcript-chunks" onclick="console.log('00:45:54,080'); seek(2754.0)">
              be marked a GI With respect to the coffee test the robot college student
            </span>
            
            <span id="chunk-765" class="transcript-chunks" onclick="console.log('00:45:58,960'); seek(2758.0)">
              test, a machine enrolls in a university taking and passing the same classes that
            </span>
            
            <span id="chunk-766" class="transcript-chunks" onclick="console.log('00:46:04,210'); seek(2764.0)">
              humans would and obtaining a degree.
            </span>
            
            <span id="chunk-767" class="transcript-chunks" onclick="console.log('00:46:07,230'); seek(2767.0)">
              I think this is probably the easiest one and it's surpassed this one.
            </span>
            
            <span id="chunk-768" class="transcript-chunks" onclick="console.log('00:46:11,210'); seek(2771.0)">
              The employment test.
            </span>
            
            <span id="chunk-769" class="transcript-chunks" onclick="console.log('00:46:12,700'); seek(2772.0)">
              A machine performs an economically important job, at least as
            </span>
            
            <span id="chunk-770" class="transcript-chunks" onclick="console.log('00:46:16,660'); seek(2776.0)">
              well as humans in the same job.
            </span>
            
            <span id="chunk-771" class="transcript-chunks" onclick="console.log('00:46:19,360'); seek(2779.0)">
              This means nothing to me, to be honest.
            </span>
            
            <span id="chunk-772" class="transcript-chunks" onclick="console.log('00:46:21,880'); seek(2781.0)">
              'cause there was like a bunch of things that determine istic machines already do.
            </span>
            
            <span id="chunk-773" class="transcript-chunks" onclick="console.log('00:46:26,520'); seek(2786.0)">
              And we don't actually need probabilistic models or LLMs to do those things.
            </span>
            
            <span id="chunk-774" class="transcript-chunks" onclick="console.log('00:46:31,190'); seek(2791.0)">
              That's they sometimes do better than humans in the same job.
            </span>
            
            <span id="chunk-775" class="transcript-chunks" onclick="console.log('00:46:35,540'); seek(2795.0)">
              Most of like our industries are actually that mechanized.
            </span>
            
            <span id="chunk-776" class="transcript-chunks" onclick="console.log('00:46:41,870'); seek(2801.0)">
              They're full of machines as opposed to humans.
            </span>
            
            <span id="chunk-777" class="transcript-chunks" onclick="console.log('00:46:44,750'); seek(2804.0)">
              Often faster actually.
            </span>
            
            <span id="chunk-778" class="transcript-chunks" onclick="console.log('00:46:46,570'); seek(2806.0)">
              So what is GPT?
            </span>
            
            <span id="chunk-779" class="transcript-chunks" onclick="console.log('00:46:48,160'); seek(2808.0)">
              GPT is a language model.
            </span>
            
            <span id="chunk-780" class="transcript-chunks" onclick="console.log('00:46:49,930'); seek(2809.0)">
              It's a large language model.
            </span>
            
            <span id="chunk-781" class="transcript-chunks" onclick="console.log('00:46:52,140'); seek(2812.0)">
              Each of us has a language model inside our heads and it changes constantly.
            </span>
            
            <span id="chunk-782" class="transcript-chunks" onclick="console.log('00:46:57,270'); seek(2817.0)">
              A language model embedding is the multidimensional representation of a
            </span>
            
            <span id="chunk-783" class="transcript-chunks" onclick="console.log('00:47:02,520'); seek(2822.0)">
              given sentence based on the context or environment in which our language
            </span>
            
            <span id="chunk-784" class="transcript-chunks" onclick="console.log('00:47:06,600'); seek(2826.0)">
              model was trained similar to humans.
            </span>
            
            <span id="chunk-785" class="transcript-chunks" onclick="console.log('00:47:10,190'); seek(2830.0)">
              The existence of a language model leads to NLU and NLG, which are all sub-problems
            </span>
            
            <span id="chunk-786" class="transcript-chunks" onclick="console.log('00:47:16,400'); seek(2836.0)">
              for all the other NLP problems.
            </span>
            
            <span id="chunk-787" class="transcript-chunks" onclick="console.log('00:47:18,910'); seek(2838.0)">
              NLU is natural language understanding and NLG is natural language generation.
            </span>
            
            <span id="chunk-788" class="transcript-chunks" onclick="console.log('00:47:24,480'); seek(2844.0)">
              So this was GPD three and what I basically did was I went ahead and
            </span>
            
            <span id="chunk-789" class="transcript-chunks" onclick="console.log('00:47:30,900'); seek(2850.0)">
              as the current version of GPD, what it thought of our prompting history.
            </span>
            
            <span id="chunk-790" class="transcript-chunks" onclick="console.log('00:47:36,900'); seek(2856.0)">
              'cause I do heavily use Chad GPDA lot.
            </span>
            
            <span id="chunk-791" class="transcript-chunks" onclick="console.log('00:47:39,830'); seek(2859.0)">
              And it told me that he was very good at creative writing for me, like
            </span>
            
            <span id="chunk-792" class="transcript-chunks" onclick="console.log('00:47:45,760'); seek(2865.0)">
              context linked creative writing.
            </span>
            
            <span id="chunk-793" class="transcript-chunks" onclick="console.log('00:47:48,120'); seek(2868.0)">
              It was very good at essay or project expansion.
            </span>
            
            <span id="chunk-794" class="transcript-chunks" onclick="console.log('00:47:52,170'); seek(2872.0)">
              It was really good at travel and museum planning.
            </span>
            
            <span id="chunk-795" class="transcript-chunks" onclick="console.log('00:47:55,010'); seek(2875.0)">
              It was not good when I didn't provide it, like good context.
            </span>
            
            <span id="chunk-796" class="transcript-chunks" onclick="console.log('00:47:58,940'); seek(2878.0)">
              It was minimal or one line prompts or when writing emotionally intense fiction
            </span>
            
            <span id="chunk-797" class="transcript-chunks" onclick="console.log('00:48:04,440'); seek(2884.0)">
              or any sort of financial or tax strategy.
            </span>
            
            <span id="chunk-798" class="transcript-chunks" onclick="console.log('00:48:07,730'); seek(2887.0)">
              The issues with its own evaluation is I have actually not been able to use charge
            </span>
            
            <span id="chunk-799" class="transcript-chunks" onclick="console.log('00:48:13,250'); seek(2893.0)">
              GBD as much as I would think I would be able to for any of the things that
            </span>
            
            <span id="chunk-800" class="transcript-chunks" onclick="console.log('00:48:19,480'); seek(2899.0)">
              it, things, it works very well for me.
            </span>
            
            <span id="chunk-801" class="transcript-chunks" onclick="console.log('00:48:22,650'); seek(2902.0)">
              Whenever there's been a case of context linked creative writing, it's been
            </span>
            
            <span id="chunk-802" class="transcript-chunks" onclick="console.log('00:48:27,810'); seek(2907.0)">
              extremely difficult to ve it into a direction where I wanted to go.
            </span>
            
            <span id="chunk-803" class="transcript-chunks" onclick="console.log('00:48:34,440'); seek(2914.0)">
              In the prompt space that I basically have.
            </span>
            
            <span id="chunk-804" class="transcript-chunks" onclick="console.log('00:48:37,410'); seek(2917.0)">
              'cause if I were to give it more details, might as well write the plot myself.
            </span>
            
            <span id="chunk-805" class="transcript-chunks" onclick="console.log('00:48:43,430'); seek(2923.0)">
              Same case with any sort of essay or project expansion.
            </span>
            
            <span id="chunk-806" class="transcript-chunks" onclick="console.log('00:48:47,280'); seek(2927.0)">
              'Cause it loses a lot of context.
            </span>
            
            <span id="chunk-807" class="transcript-chunks" onclick="console.log('00:48:50,010'); seek(2930.0)">
              It loses a lot of history and it, you have to basically keep telling it no, we are
            </span>
            
            <span id="chunk-808" class="transcript-chunks" onclick="console.log('00:48:57,420'); seek(2937.0)">
              like in this context of riddles or we are in this context of mathematical riddles
            </span>
            
            <span id="chunk-809" class="transcript-chunks" onclick="console.log('00:49:04,290'); seek(2944.0)">
              as opposed to any fictional riddles.
            </span>
            
            <span id="chunk-810" class="transcript-chunks" onclick="console.log('00:49:06,870'); seek(2946.0)">
              You have to keep reminding it.
            </span>
            
            <span id="chunk-811" class="transcript-chunks" onclick="console.log('00:49:08,420'); seek(2948.0)">
              And the last one where it's travel museum planning, that's where it's not been
            </span>
            
            <span id="chunk-812" class="transcript-chunks" onclick="console.log('00:49:14,580'); seek(2954.0)">
              great for me at all actually, because.
            </span>
            
            <span id="chunk-813" class="transcript-chunks" onclick="console.log('00:49:17,300'); seek(2957.0)">
              Was a, there was a itinerary that it basically wrote for me for a specific
            </span>
            
            <span id="chunk-814" class="transcript-chunks" onclick="console.log('00:49:23,240'); seek(2963.0)">
              trip where Chad GPD thought I could teleport from one place to the other.
            </span>
            
            <span id="chunk-815" class="transcript-chunks" onclick="console.log('00:49:28,910'); seek(2968.0)">
              That would usually take 30 minutes in five minutes.
            </span>
            
            <span id="chunk-816" class="transcript-chunks" onclick="console.log('00:49:33,430'); seek(2973.0)">
              So as you've seen, it actually has no understanding of basic physics
            </span>
            
            <span id="chunk-817" class="transcript-chunks" onclick="console.log('00:49:38,770'); seek(2978.0)">
              or the realities of the world.
            </span>
            
            <span id="chunk-818" class="transcript-chunks" onclick="console.log('00:49:40,300'); seek(2980.0)">
              There is no way for it to scope any sort of observational details of whatever
            </span>
            
            <span id="chunk-819" class="transcript-chunks" onclick="console.log('00:49:46,670'); seek(2986.0)">
              prompt you are like asking it to perform.
            </span>
            
            <span id="chunk-820" class="transcript-chunks" onclick="console.log('00:49:49,840'); seek(2989.0)">
              And it does really bad at it.
            </span>
            
            <span id="chunk-821" class="transcript-chunks" onclick="console.log('00:49:51,750'); seek(2991.0)">
              So cheaply today doesn't have a sense of time or practicality because
            </span>
            
            <span id="chunk-822" class="transcript-chunks" onclick="console.log('00:49:56,630'); seek(2996.0)">
              it actually did think that I could teleport when making travel plans.
            </span>
            
            <span id="chunk-823" class="transcript-chunks" onclick="console.log('00:50:01,040'); seek(3001.0)">
              Those were not hallucinations.
            </span>
            
            <span id="chunk-824" class="transcript-chunks" onclick="console.log('00:50:03,470'); seek(3003.0)">
              It did actually think that a cab right from point A to B would take 10 minutes.
            </span>
            
            <span id="chunk-825" class="transcript-chunks" onclick="console.log('00:50:08,300'); seek(3008.0)">
              In reality, it would take around 30 minutes to do the that task.
            </span>
            
            <span id="chunk-826" class="transcript-chunks" onclick="console.log('00:50:12,610'); seek(3012.0)">
              So using it to travel, considering how it like, depends upon a lot of
            </span>
            
            <span id="chunk-827" class="transcript-chunks" onclick="console.log('00:50:18,810'); seek(3018.0)">
              RAG which is retrieved augmentation coupled with the generation.
            </span>
            
            <span id="chunk-828" class="transcript-chunks" onclick="console.log('00:50:24,770'); seek(3024.0)">
              So it'll source its results based on either Google search or Bing search
            </span>
            
            <span id="chunk-829" class="transcript-chunks" onclick="console.log('00:50:30,410'); seek(3030.0)">
              or any other sort of search engine.
            </span>
            
            <span id="chunk-830" class="transcript-chunks" onclick="console.log('00:50:33,100'); seek(3033.0)">
              And it'll ground all of its information on the basis of that, except it's way
            </span>
            
            <span id="chunk-831" class="transcript-chunks" onclick="console.log('00:50:36,940'); seek(3036.0)">
              easy to like for someone to start a blog and post all sorts of fake information
            </span>
            
            <span id="chunk-832" class="transcript-chunks" onclick="console.log('00:50:44,070'); seek(3044.0)">
              on the blog, which will be cited as a source in all of these search results
            </span>
            
            <span id="chunk-833" class="transcript-chunks" onclick="console.log('00:50:49,140'); seek(3049.0)">
              based on how they gather that information.
            </span>
            
            <span id="chunk-834" class="transcript-chunks" onclick="console.log('00:50:53,330'); seek(3053.0)">
              And those things are like always evolving.
            </span>
            
            <span id="chunk-835" class="transcript-chunks" onclick="console.log('00:50:56,630'); seek(3056.0)">
              Like all of these documents are always evolving.
            </span>
            
            <span id="chunk-836" class="transcript-chunks" onclick="console.log('00:50:58,940'); seek(3058.0)">
              So there's like a bunch of blogs with all sorts of conflicting information.
            </span>
            
            <span id="chunk-837" class="transcript-chunks" onclick="console.log('00:51:04,220'); seek(3064.0)">
              And it doesn't do really well with all of that.
            </span>
            
            <span id="chunk-838" class="transcript-chunks" onclick="console.log('00:51:06,600'); seek(3066.0)">
              If it's bombarded with all sorts of confusing sort of information, it
            </span>
            
            <span id="chunk-839" class="transcript-chunks" onclick="console.log('00:51:10,260'); seek(3070.0)">
              can give you all the wrong answers.
            </span>
            
            <span id="chunk-840" class="transcript-chunks" onclick="console.log('00:51:12,690'); seek(3072.0)">
              It can make up places for you to travel to that don't really exist.
            </span>
            
            <span id="chunk-841" class="transcript-chunks" onclick="console.log('00:51:17,580'); seek(3077.0)">
              And it can actually believe that you can teleport from place A to
            </span>
            
            <span id="chunk-842" class="transcript-chunks" onclick="console.log('00:51:23,700'); seek(3083.0)">
              B in 10 minutes when the actual task will take you 30 minutes.
            </span>
            
            <span id="chunk-843" class="transcript-chunks" onclick="console.log('00:51:28,190'); seek(3088.0)">
              It loses train of thought which I thought was actually very human.
            </span>
            
            <span id="chunk-844" class="transcript-chunks" onclick="console.log('00:51:32,630'); seek(3092.0)">
              On the other hand, if a human were to do it to you multiple times, you are
            </span>
            
            <span id="chunk-845" class="transcript-chunks" onclick="console.log('00:51:37,780'); seek(3097.0)">
              just basically stopping being friends with them or talking to them if they're
            </span>
            
            <span id="chunk-846" class="transcript-chunks" onclick="console.log('00:51:41,880'); seek(3101.0)">
              like your therapist or something else, you're just basically stuck.
            </span>
            
            <span id="chunk-847" class="transcript-chunks" onclick="console.log('00:51:46,010'); seek(3106.0)">
              Which has been my experience.
            </span>
            
            <span id="chunk-848" class="transcript-chunks" onclick="console.log('00:51:47,690'); seek(3107.0)">
              So not quite a GI LMS gr and cha g Bt are very good at chasm style.
            </span>
            
            <span id="chunk-849" class="transcript-chunks" onclick="console.log('00:51:53,920'); seek(3113.0)">
              Guessing games probably due to RG injection.
            </span>
            
            <span id="chunk-850" class="transcript-chunks" onclick="console.log('00:51:57,820'); seek(3117.0)">
              I've had to give it to some more prompts, like some more hints.
            </span>
            
            <span id="chunk-851" class="transcript-chunks" onclick="console.log('00:52:01,210'); seek(3121.0)">
              But usually they do get me like the right answer misheard lyrics or figuring out
            </span>
            
            <span id="chunk-852" class="transcript-chunks" onclick="console.log('00:52:07,950'); seek(3127.0)">
              some sort of a photo, like what sort of artist that belongs to, et cetera.
            </span>
            
            <span id="chunk-853" class="transcript-chunks" onclick="console.log('00:52:13,680'); seek(3133.0)">
              And I've actually searched for a number of wild things and it does really
            </span>
            
            <span id="chunk-854" class="transcript-chunks" onclick="console.log('00:52:19,020'); seek(3139.0)">
              well with it, except I do know of a deterministic engine which used to perform
            </span>
            
            <span id="chunk-855" class="transcript-chunks" onclick="console.log('00:52:24,270'); seek(3144.0)">
              the same sort of analysis of sorts.
            </span>
            
            <span id="chunk-856" class="transcript-chunks" onclick="console.log('00:52:28,060'); seek(3148.0)">
              If you answer I want to say 10 outta 20 questions, and those questions
            </span>
            
            <span id="chunk-857" class="transcript-chunks" onclick="console.log('00:52:31,750'); seek(3151.0)">
              used to be like is this character fictional or is this character female?
            </span>
            
            <span id="chunk-858" class="transcript-chunks" onclick="console.log('00:52:36,280'); seek(3156.0)">
              Is this character in a fantasy movie?
            </span>
            
            <span id="chunk-859" class="transcript-chunks" onclick="console.log('00:52:38,550'); seek(3158.0)">
              And would basically come upon the right answer.
            </span>
            
            <span id="chunk-860" class="transcript-chunks" onclick="console.log('00:52:41,440'); seek(3161.0)">
              There were a lot of rumors that this machine is actually, there's like a
            </span>
            
            <span id="chunk-861" class="transcript-chunks" onclick="console.log('00:52:45,550'); seek(3165.0)">
              bunch of humans behind this particular website, but that was not the case.
            </span>
            
            <span id="chunk-862" class="transcript-chunks" onclick="console.log('00:52:50,200'); seek(3170.0)">
              So that's not a GI, it doesn't have any observational skills for obvious reasons.
            </span>
            
            <span id="chunk-863" class="transcript-chunks" onclick="console.log('00:52:56,320'); seek(3176.0)">
              It's an LLM.
            </span>
            
            <span id="chunk-864" class="transcript-chunks" onclick="console.log('00:52:57,400'); seek(3177.0)">
              It is not equipped to see or to perceive or to even imagine actually in any
            </span>
            
            <span id="chunk-865" class="transcript-chunks" onclick="console.log('00:53:03,810'); seek(3183.0)">
              sort of space except a bunch of the things that don't require imagining.
            </span>
            
            <span id="chunk-866" class="transcript-chunks" onclick="console.log('00:53:08,540'); seek(3188.0)">
              For instance, verbal algebra should be easy enough, but it's not.
            </span>
            
            <span id="chunk-867" class="transcript-chunks" onclick="console.log('00:53:13,660'); seek(3193.0)">
              So it relies on available knowledge only straight up available knowledge, either
            </span>
            
            <span id="chunk-868" class="transcript-chunks" onclick="console.log('00:53:18,610'); seek(3198.0)">
              available in its own training base, either as a mimic of its training base or any
            </span>
            
            <span id="chunk-869" class="transcript-chunks" onclick="console.log('00:53:26,010'); seek(3206.0)">
              sort of information that it gets from REG sources, which are search engines.
            </span>
            
            <span id="chunk-870" class="transcript-chunks" onclick="console.log('00:53:31,700'); seek(3211.0)">
              So it relies on available knowledge only, which is not how humans learn.
            </span>
            
            <span id="chunk-871" class="transcript-chunks" onclick="console.log('00:53:37,220'); seek(3217.0)">
              A lot of humans will learn using observation.
            </span>
            
            <span id="chunk-872" class="transcript-chunks" onclick="console.log('00:53:40,040'); seek(3220.0)">
              For instance, a lot of Greek mathematicians were able to calculate
            </span>
            
            <span id="chunk-873" class="transcript-chunks" onclick="console.log('00:53:46,710'); seek(3226.0)">
              the radius of the earth using two poles in two different cities or
            </span>
            
            <span id="chunk-874" class="transcript-chunks" onclick="console.log('00:53:50,970'); seek(3230.0)">
              something that's observational physics.
            </span>
            
            <span id="chunk-875" class="transcript-chunks" onclick="console.log('00:53:54,530'); seek(3234.0)">
              And it did not rely on available knowledge in the sense of memory.
            </span>
            
            <span id="chunk-876" class="transcript-chunks" onclick="console.log('00:54:00,330'); seek(3240.0)">
              It did rely on knowledge in the sense of observation that I can observe that the
            </span>
            
            <span id="chunk-877" class="transcript-chunks" onclick="console.log('00:54:06,900'); seek(3246.0)">
              shadow of this particular pole exists in a certain direction while there is
            </span>
            
            <span id="chunk-878" class="transcript-chunks" onclick="console.log('00:54:11,900'); seek(3251.0)">
              no shadow for this particular pole, but that is observational knowledge
            </span>
            
            <span id="chunk-879" class="transcript-chunks" onclick="console.log('00:54:17,110'); seek(3257.0)">
              as opposed to available knowledge.
            </span>
            
            <span id="chunk-880" class="transcript-chunks" onclick="console.log('00:54:19,680'); seek(3259.0)">
              So I just wanna conclude that GPT today is actually not a GI.
            </span>
            
            <span id="chunk-881" class="transcript-chunks" onclick="console.log('00:54:23,760'); seek(3263.0)">
              And in fact, if you play with it using all of the riddles that I have
            </span>
            
            <span id="chunk-882" class="transcript-chunks" onclick="console.log('00:54:29,670'); seek(3269.0)">
              showcase today, it'll give you all of the right answers except it's cheating.
            </span>
            
            <span id="chunk-883" class="transcript-chunks" onclick="console.log('00:54:35,270'); seek(3275.0)">
              It'll literally go look up all the keywords or like all of the phases
            </span>
            
            <span id="chunk-884" class="transcript-chunks" onclick="console.log('00:54:39,950'); seek(3279.0)">
              or like queries, like extremely smart queries and come up with the right answer
            </span>
            
            <span id="chunk-885" class="transcript-chunks" onclick="console.log('00:54:45,200'); seek(3285.0)">
              from the internet, which is basically where I source all my rules from.
            </span>
            
            <span id="chunk-886" class="transcript-chunks" onclick="console.log('00:54:49,390'); seek(3289.0)">
              But that's not a GI.
            </span>
            
            <span id="chunk-887" class="transcript-chunks" onclick="console.log('00:54:51,075'); seek(3291.0)">
              That's all I had.
            </span>
            
            <span id="chunk-888" class="transcript-chunks" onclick="console.log('00:54:51,915'); seek(3291.0)">
              Thank you so much.
            </span>
            
            <span id="chunk-889" class="transcript-chunks" onclick="console.log('00:54:53,245'); seek(3293.0)">
              Okay.
            </span>
            
            </div>
          </div>
          
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/prompt2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #749BC2;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Aroma%20Rodrigues_prompt.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Aroma Rodrigues
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Software Engineer @ Microsoft
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/aromarodrigues/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Aroma Rodrigues's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Aroma Rodrigues"
                  data-url="https://www.conf42.com/prompt2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/prompt2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4 justify-content-center">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Access to all content</b>
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Prompt Engineering"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe for FREE<i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2026
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2026">
                  DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2026">
                  Machine Learning 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2026">
                  Site Reliability Engineering (SRE) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2026">
                  Cloud Native 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2026">
                  Golang 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/dbd2026">
                  Database DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2026">
                  Large Language Models (LLMs) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2026">
                  Observability 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/agents2026">
                  AI Agents 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2026">
                  DevSecOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2026">
                  Prompt Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2026">
                  Platform Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2026">
                  MLOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2026">
                  Chaos Engineering 2026
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>