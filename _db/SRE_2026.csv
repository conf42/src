Featured,Track,Name1,JobTitle1,Company1,Name2,JobTitle2,Company2,Title,Abstract,LinkedIn1,Twitter1,LinkedIn2,Twitter2,Slides,Picture,YouTube,Keywords,Duration
Yes,,Uma Mukkara,Head of Chaos Engineering,Harness,,,,Why Is Resilience Testing Non-Negotiable in an Enterprise SDLC?,"In _Resilience Testing Is Non-Negotiable in SDLC_, Uma Mukkara, Head of Harness Resilience Testing and Co-Creator of LitmusChaos, explains why resilience must be built and tested throughout the Software Development Life Cycle, not treated as something to address after production issues occur.

He defines resilience as the ability of business services to withstand system failures, high load, and disasters, and shows how reduced resilience increases operational and business risk. The keynote introduces AI-powered resilience testing to help teams quantify risk, identify weaknesses early, and continuously measure, mitigate, and improve reliability across SDLC phases.

By combining chaos testing, load testing, and disaster recovery testing into a unified resilience strategy, Uma emphasizes that resilience is not optional. It must be proactively validated as a core practice of modern software delivery.",https://www.linkedin.com/in/uma-mukkara/,,,,,Uma Mukkara_sre.png,,,
No,main,Gleb Reshetnev,Software Engineer,Yandex,,,,Node.js SRE: Degradation Before Downtime,"Node.js services crash under load spikes — not from OOM, but from slow DB calls, memory leaks, or DDoS. Gleb shares prod patterns from high-load services that ""degrade gracefully"" instead of 500s.

Battle-tested resilience:
- AbortController + AbortSignal: Kill slow requests before they poison queues
- Graceful degradation: Fallback caches, feature flags, synthetic monitoring
- Circuit breakers + rate limits: Hystrix patterns in Node (Promoetheus + Redis)
- Load shedding: Queue prioritization, health checks that lie (good lie!)
- Live demo: 10k RPS → controlled degradation without restarts
Real metrics: 99.9% uptime under DDoS, 3x faster recovery. 
Code on GitHub.  
No theory, just configs you copy Monday morning.
",https://www.linkedin.com/in/reshetnev-gb/,,,,,Gleb Reshetnev_sre.png,,,
No,main,Cynthia Akiotu,Associate Manager – Security–Data Protection Architect – Accenture Microsoft Business Group,Accenture,,,,From Users to Agents: Rethinking Security and Reliability for AI-Driven Systems,"AI-driven systems don’t just automate - they decide. As autonomous agents enter production, SREs face new challenges in resilience, observability, incident response, and recovery. This talk explores how agent behaviour reshapes reliability long before uptime ever drops.",https://www.linkedin.com/in/cynthia-akiotu/,,,,,Cynthia Akiotu_sre.png,,,
No,main,Abhimanyu Narwal,Engineering Team Lead,Bloomberg LP,,,,The Failures You Don’t See on Dashboards - A reliability case study in workflow latency and response time,"Site Reliability Engineering teams often rely on service-level metrics, tracing, and alerting to help keep systems available. However, some of the most impactful failures aren’t outages — they are partial and quiet, and they slow down human workflows without triggering traditional alarms. In this talk, we share a case study from the world of security operations, where reduced clarity and missing signals increased time to diagnose and respond, despite systems being technically up.

Using anonymized examples, we revisit familiar SRE practices and show how they apply (and can sometimes fall short) in environments where workflows span multiple products and involve human decision-making. We explore measuring health in terms of workflow latency, tracing at a workflow level, and recognizing operational patterns driven by user behavior as key indicators of friction.

Attendees will gain practical strategies for defining meaningful SLIs and SLOs, understanding 'silent' failure modes, and designing systems that fail visibly and explain themselves under pressure.",https://www.linkedin.com/in/anarwal/,,,,,Abhimanyu Narwal_sre.png,,,
No,main,Abhiram Potharaju,Senior Software Engineer,Wells Fargo Bank N.A.,,,,Reliable AI for Clinical Handoffs: SRE Lessons for Safer Care Transitions,"Clinical handoffs are one of the most failure-prone moments in healthcare delivery. Communication breakdowns are widely recognized as a leading contributor to serious adverse events in hospitals, with shift handoffs identified as a major risk factor. While standardized frameworks like SBAR (Situation-Background-Assessment-Recommendation) exist, real-world adoption remains inconsistent due to cognitive overload, time pressure, and fragmented Electronic Health Record (EHR) data.

This session examines the design of an AI-augmented clinical handoff system through a Site Reliability Engineering lens: how to build AI-assisted workflows that are dependable under pressure, resilient to incomplete inputs, and safe when they fail. The system integrates directly with EHR platforms and supports—rather than replaces—clinician judgment by synthesizing key patient updates from structured and unstructured clinical data, including vital sign trends, medication changes, laboratory deviations, and recent care plans. By continuously monitoring these signals, it highlights early indicators of clinical deterioration, addressing a well-documented patient safety challenge in acute care.

The AI generates SBAR-aligned handoff summaries to reduce variability while preserving clinician oversight. The talk emphasizes human-AI collaboration, focusing on explainable outputs, transparency in recommendations, and clinician-controlled review loops to strengthen trust and accountability. Attendees will gain architectural insights into integrating AI with EHR systems, understand governance considerations for clinical deployment, and learn how AI-supported handoffs can improve continuity of care without automating clinical decision-making.",http://linkedin.com/in/abhiramchow,,,,,Abhiram Potharaju_sre.png,,,
No,main,Abhishek Suman,Senior Software Engineer,Microsoft Corporation,,,,Compute-Sharded Stream Processing for Petabyte-Scale Real-Time Cybersecurity Analytics,"Enterprise cybersecurity systems increasingly operate at petabyte-scale data volumes while facing adversaries that move with speed and automation. Traditional batch-oriented Security Information and Event Management (SIEM) architectures introduce processing delays that create detection gaps, allowing attackers to complete lateral movement and persistence activities before alerts are generated. Detection latency has become a dominant factor in determining the effectiveness of modern cyber defense.

This session presents a horizontally scalable, compute-sharded stream processing architecture designed for real-time cybersecurity analytics at extreme scale. The system distributes both data and computation across independent processing nodes using consistent hashing, enabling parallel processing while reducing centralized bottlenecks. A schema-agnostic ingestion layer supports heterogeneous security telemetry without requiring predefined schemas or heavy preprocessing, enabling faster integration of new data sources.

Continuous stream processing replaces scheduled batch cycles, enabling near-real-time correlation and analysis. The architecture integrates rule-based detection with machine learning driven anomaly identification to detect both known attack patterns and previously unseen behaviors. Multi-region deployment supports geographic resilience, fault tolerance, and localized processing while maintaining consistency across distributed environments.

Validation results described in the work demonstrate major reductions in detection and response latency compared to batch-based architectures, along with improved throughput sustainability and resource utilization under increasing workloads. Deployment case studies across multiple industry sectors further demonstrate operational viability and measurable improvements in incident response effectiveness.

Attendees will gain practical SRE-focused insights into architecture design principles, implementation trade-offs, scalability strategies, and operational lessons learned for building reliable real-time cybersecurity analytics pipelines at petabyte scale.",https://www.linkedin.com/in/sumanabhishek,,,,,Abhishek Suman_sre.png,,,
No,main,Ajay Athitya Ramanathan,Data & AI Engineer,FourthSquare,,,,Autonomy with Guardrails: Operating Agentic Automation in High-Risk Production Systems,"Agentic automation is increasingly deployed into production workflows with real financial, operational, and compliance impact. In these environments, failures don’t look like model errors they surface as exception backlogs, reconciliation effort, repeated overrides, and on-call escalations. For SRE teams, agentic systems introduce a new class of reliability risk: probabilistic decision-making embedded directly into critical workflows.

This session examines agentic automation through a site reliability engineering lens, focusing on how autonomy must be deliberately constrained, observed, and operated in high-stakes systems. We begin by analyzing real-world operational signals that indicate automation is failing silently rather than fast, including rising manual intervention rates, inconsistent downstream behavior, and escalation fatigue. These signals illustrate why agentic systems designed for low-risk or exploratory use cases often break when exposed to regulated or financially sensitive processes.

The core of the talk presents reliability-oriented design patterns for agentic workflows. Rather than treating autonomy as a binary choice, autonomy is framed as a tunable parameter based on risk and blast radius. Key patterns include explicit risk classification of agent outputs, exception-first workflow modeling, and separation of deterministic validation steps from probabilistic reasoning. Practical examples show how these patterns reduce error propagation, simplify rollback, and preserve service-level objectives while still capturing automation benefits.

The session also explores human-in-the-loop controls as reliability mechanisms, not process overhead. Escalation thresholds, review queues, and approval checkpoints are discussed as tools for limiting impact and enabling safe recovery under uncertainty. Finally, the talk emphasizes traceability and auditability as SRE fundamentals, highlighting decision provenance, structured logging, and reproducible reasoning paths as essential for incident investigation, postmortems, and continuous improvement.

Attendees will leave with a pragmatic framework for operating agentic automation in high-stakes environments equipped with concrete patterns that help SRE teams balance autonomy with control, contain failure modes, and build systems that can be trusted under real production pressure.",https://www.linkedin.com/in/ajayathitya/,,,,,Ajay Athitya Ramanathan_sre.png,,,
No,main,Ajay Srinivas Kiran Gemidi,Sr Systems Engineer,Valuguard Solutions LLC,,,,Reliability-First Architectures for AI Analytics in Mission-Critical Platforms,"As AI-enabled analytics move closer to real-time execution paths, mission-critical platforms are increasingly exposed to new reliability risks. Predictive models, automated decisions, and inference pipelines introduce bursty compute demand, opaque execution paths, and extended data lifecycles that frequently show up in post-incident reviews as latency spikes, cascading failures, and reduced observability. For Site Reliability Engineers, AI becomes a reliability problem long before it becomes a modeling problem.

This session presents a reliability-first, architecture-driven approach to running AI analytics in mission-critical data platforms. Drawing from real-world enterprise incidents across cloud and hybrid environments, it examines how uncontrolled analytical workloads undermine SLOs, amplify tail latency, and create governance blind spots. The talk focuses on architectural guardrails that SREs can influence early: workload isolation boundaries, deterministic execution paths, and performance constraints that prevent non-linear resource consumption.

The session also explores decision traceability and execution lineage as operational tools, enabling post-incident analysis, auditability, and faster root-cause investigation. Security, access control, and monitoring are examined as inherited reliability properties rather than afterthoughts. Finally, the talk addresses long-term operability, including managing model drift, controlled rollout strategies, and preserving human oversight in automated decision systems.

Attendees will gain practical architectural patterns and SRE-aligned strategies for supporting AI analytics at scale without sacrificing availability, predictability, or trust in mission-critical systems.",https://www.linkedin.com/in/ajay-g-a49a9635,,,,,Ajay Srinivas Kiran Gemidi_sre.png,,,
No,main,Amogha Tenneti,Senior Associate Scientist,Eurofins PSS,,,,SRE-Driven Automation of FLEX2 Analytics in AMBR250 Upstream Biologics Workflows,"High-throughput microbioreactor platforms such as the Sartorius AMBR250 are widely used in upstream biologics process development, yet analytical workflows often remain dependent on manual sampling and operator-driven execution. This creates reliability risks, variability, and operational overhead that scale poorly in regulated environments. This presentation describes the operational integration of the BioProfile FLEX2 automated cell culture analyzer into daily AMBR250 workflows within a regulated upstream development environment supporting Janssen, a Johnson and Johnson company.

Between December 2022 and August 2024, the FLEX2 analyzer was independently evaluated, qualified, validated, and implemented to support routine AMBR250 analytical operations. The integrated workflow enabled automated multi-parameter analysis, including metabolites, blood gases, electrolytes, osmolality, and cell health metrics, while aligning with existing upstream operational and compliance requirements.

To ensure controlled adoption and maintain data integrity, four structured equivalency experiments were designed and executed to demonstrate analytical comparability between FLEX2 and existing standard analyzers, supporting a validated transition to automation. Operational implementation reduced manual labor during AMBR workflows by approximately 40 percent, improving consistency, throughput, and data reliability.

Scalability was supported through structured enablement: 8 super users were trained at the Malvern, Pennsylvania site and 4 super users at the Spring House, Pennsylvania site, enabling independent operation and troubleshooting across multiple Janssen locations. Qualification and validation protocols were authored and executed for both AMBR systems and the FLEX2 analyzer as part of advanced manufacturing technology initiatives.

This case study provides a practical example of how automation, validation, and standardized operational ownership can improve reliability and scalability in high-throughput biologics development analytics.",https://www.linkedin.com/in/amoghat/,,,,,Amogha Tenneti_sre.png,,,
No,main,Asif Eqbal,Software Engineer,Meta,,,,Building Robust Technical Systems for Real-Time Video in Immersive Technologies,"This topic explores the unique challenges and solutions involved in developing distributed systems that power real-time video experiences for immersive technologies such as augmented reality (AR) and virtual reality (VR). The session will cover architectural patterns and best practices for ensuring low-latency, high-reliability video streaming and processing in environments where user experience is highly sensitive to delays and disruptions. Attendees will learn about scalable backend designs, real-time data pipelines, and synchronization techniques that enable seamless video integration in AR/VR applications. The talk will also highlight practical considerations, such as optimizing for diverse hardware, handling large-scale concurrent users, and ensuring data privacy and security. Real-world examples and lessons learned from deploying these systems in production will provide actionable insights for engineers and product leaders working at the intersection of distributed systems and immersive media.

",https://www.linkedin.com/in/asif-eqbal-4a617a46/,,,,,Asif Eqbal_sre.png,,,
No,main,Bhargavaram Potharaju,Senior Infrastructure Engineer,Wells Fargo,,,,"SRE for National-Scale Regulatory Reporting: HA, DR, and Audit-Ready Design","National-scale regulatory reporting platforms are compliance-critical systems where reliability failures can directly impact financial stability, institutional solvency, and regulator confidence. As regulatory datasets grow rapidly per reporting cycle and submission windows become increasingly compressed, many legacy enterprise architectures fail to meet core SRE requirements: high availability, predictable performance under peak load, accurate processing, auditable outcomes, and disaster resilience.

This session presents a high-availability infrastructure framework for regulatory reporting systems operating at national scale, positioning infrastructure and reliability engineering as direct drivers of compliance outcomes—not passive operational concerns. Grounded in modern cloud and hybrid platform engineering principles, the framework addresses end-to-end workloads spanning ingestion, validation, transformation, submission, and audit replay during peak regulatory conditions.

Drawing from real-world regulatory implementations, the session highlights measurable improvements in processing throughput, reductions in end-to-end reporting cycle latency, consistently high data accuracy, and minimal unplanned downtime during peak regulatory windows. The talk introduces a repeatable, compliance-aware reference architecture designed for federal and enterprise regulatory ecosystems, with high availability, disaster recovery, and audit readiness treated as first-class design constraints.",https://www.linkedin.com/in/bhargavaram-potharaju-81b26a132/,,,,,Bhargavaram Potharaju_sre.png,,,
No,main,Dipta Rakshit,Staff Software Engineer,Walmart Global Tech,,,,Building Reliable AI-Driven Mobile Platforms for Healthcare and Commerce,"Modern mobile platforms increasingly span both healthcare and e-commerce domains, placing extreme demands on reliability, scalability, and regulatory compliance. This session examines how unified mobile systems can deliver prescription management and retail experiences across human, vision, and pet care—without compromising uptime, data integrity, or user trust.

Drawing on over 20 years of mobile platform design experience, the talk explores how AI-driven personalization, predictive analytics, and accessibility frameworks operate reliably at scale. Using real-world implementations such as Walmart’s mobile platform, the session demonstrates measurable outcomes: a 30–35% improvement in prescription adherence, a 40% increase in repeat purchases, and sustained user satisfaction gains through AR-based virtual try-on and personalized promotions.

From an SRE perspective, the presentation focuses on the architectural foundations that enable these results: HIPAA- and GDPR-compliant APIs, resilient microservice architectures, and fault-tolerant integrations across pharmacy, insurance, and retail systems. Predictive models anticipate prescription refills and personalize offers in real time, requiring low-latency inference, graceful degradation, and consistent data synchronization to prevent missed doses or service disruptions.

Accessibility and inclusivity are treated as reliability concerns, with ADA-compliant design and multilingual localization ensuring consistent service quality across diverse user populations. Attendees will gain practical insights into designing and operating mobile ecosystems that balance AI personalization with compliance, observability, and scalability—demonstrating how reliability engineering directly enables both clinical impact and commercial performance.",https://www.linkedin.com/in/diptarakshit/,,,,,Dipta Rakshit_sre.png,,,
No,main,Harsh Singh,"Senior Vice President, CFO - Open Banking, Customer Acquisition and Engagement and CTO Services",Mastercard International,,,,Human-AI Collaboration for SRE: Predictive Analytics in Financial Systems,"The integration of artificial intelligence (AI) into Financial Planning and Analysis (FP&A) systems presents critical challenges and opportunities for Site Reliability Engineering. This presentation examines a strategic framework for deploying AI-driven analytics in financial infrastructure while maintaining system reliability, performance, and operational excellence.
Recent advancements demonstrate measurable improvements in predictive capabilities, with AI models significantly enhancing forecasting accuracy and reducing errors compared to traditional methods. Validated AI-driven forecasting frameworks indicate substantial benefits, including notable error reduction and increased prediction precision. Complementary studies reveal that phased implementation strategies reduce failure rates and improve adoption, while human oversight mechanisms enhance system reliability and decision quality.
The SRE implications extend beyond performance metrics to infrastructure resilience and operational outcomes. Research shows that organizations embracing emerging FP&A technologies achieve improvements in predictive accuracy and operational efficiency. Advanced natural language processing systems accelerate market response capabilities and reduce analysis time. These gains require robust monitoring, observability, and incident response capabilities.
This presentation concludes that successful deployment demands reliable infrastructure, comprehensive monitoring frameworks, and structured governance. SRE teams must balance innovation with stability, implementing effective change management and deployment strategies. Organizations that integrate advanced analytics with human expertise can achieve higher system reliability, mitigate operational risks, and maintain service level objectives while leveraging AI capabilities in financial systems.",https://www.linkedin.com/in/harshsingh29,,,,,Harsh Singh_sre.png,,,
No,main,Yury Lysak,Head of Strategic Projects,Lionsoul Global,,,,Beyond Observability: Proactive SRE for AI-Driven Personalisation,"Financial pricing systems are SRE's ultimate test: sub-50ms decisions, regulatory audits, market volatility, zero-downtime model updates. At Lionsoul Global (WealthTech), I've engineered pricing engines for HNWI portfolios that survive black swan events - blending telco-scale patterns with fintech constraints.

AI personalisation engines (recommendations, dynamic pricing, client journeys) fail silently - model drift kills LTV silently too. At Lionsoul Global (WealthTech), I run SRE for AI pipelines powering HNWI portfolios, proactively catching issues before revenue impact.

Key patterns:

- Proactive signals: Custom metrics beyond golden signals — propensity drift, uplift decay, A/B divergence alerts (Grafana + ClickHouse)

- Small-data SRE: Bayesian priors + relationship manager feedback loops when training data = dozens of clients (not millions)

- Experiment resilience: Chaos engineering for model swaps, canary deploys preserving personalization continuity

- Compliance automation: Audit trails for AI decisions, human-in-loop guardrails via LLM copilots

Real impact: 25% LTV uplift sustained across model versions; 15% incremental revenue from telco-scale patterns adapted to fintech. Code frameworks + alerting configs included.

Walk away with SRE patterns that keep AI personalisation profitable when the models inevitably start decaying.",https://www.linkedin.com/in/yury-lysak-7905a122,,,,,Yury Lysak_sre.png,,,
No,main,Jyothish Sreedharan,Vice President,Independent Researcher,,,,AI-Governed Lakehouse Ingestion with Flink on Kubernetes for Reliable DataOps,"Modern cloud lakehouse platforms ingest data from heterogeneous sources such as transactional databases, event streams, APIs, and unstructured text, each evolving independently. Traditional ETL and schema registry-driven pipelines struggle to handle schema drift, semantic inconsistency, and cross-format variability without frequent manual intervention. Prior research shows that static schema validation captures only a limited subset of semantic data quality issues, particularly in continuously evolving distributed systems.

This talk presents an AI-governed multi-modal data sourcing architecture designed to autonomously adapt to structural and semantic change while improving reliability and reducing operational toil in ingestion pipelines. The approach introduces semantic contracts that encode learned value distributions, attribute relationships, and temporal patterns derived from historical data, extending validation beyond syntactic correctness. Building on statistical validation and temporal modeling techniques documented in streaming and data warehousing literature, the framework enables real-time semantic coherence assessment without rigid schema enforcement.

A self-evolving schema intelligence layer leverages large language models and embedding-based similarity scoring to interpret schema evolution events, infer semantic equivalence across heterogeneous sources, and generate transformation logic automatically. These capabilities align with previously published work on few-shot learning, automated schema matching, and contextual embeddings.

The system unifies structured, semi-structured, and unstructured inputs using AI-based extraction, recursive parsing, and event-time alignment following the Dataflow model. Apache Flink provides exactly-once stream processing and state management, while Kubernetes enables elastic scaling, automated recovery, and zero-disruption operator updates using asynchronous snapshots.

This session focuses on reliability-driven design tradeoffs, resilience patterns, and operational lessons learned when integrating AI-driven governance into distributed streaming pipelines.",https://www.linkedin.com/in/jyothish-sreedharan/,,,,,Jyothish Sreedharan_sre.png,,,
No,main,Khushboo Nigam,Principal Cloud Architect,Oracle,,,,Correlation Over Collection: A Layered Observability Framework for SREs,"In modern cloud-native systems, we don’t have a data problem; we have a clarity problem. When an incident strikes, SREs are often buried under a mountain of ""critical"" alerts, metrics, and traces that all seem equally urgent, forcing engineers to piece together context under pressure. The most important question, “What changed?”, is frequently the hardest one to answer.

This session presents a Layered Observability Framework that organizes telemetry by decision value rather than volume. Instead of ""monitoring everything,"" the framework enables SREs to observe intentionally, structuring signals around the questions that matter most during incidents.

Using a retail microservices application running on managed Kubernetes, the talk walks through three complementary layers:
• Application traces that reveal user impact and request flow, pinpointing where failures occur within a transaction
• Kubernetes metrics and events that reveal platform health and pod states, helping separate infrastructure instability from application faults
• CI/CD telemetry that records deployment events, version changes, and pipeline outcomes, providing critical change context during incident analysis

This session demonstrates how structuring telemetry across these three layers creates a clearer investigation path during incidents. By defining how to pivot systematically across these layers—linking application versions to platform events and deployment logs—the session shows how raw telemetry becomes a structured hierarchy of evidence. 
The session also clarifies the shared responsibility model in managed Kubernetes—helping SRE teams understand what they can fix directly versus when to escalate to the platform provider.
Attendees will leave with a reusable platform-agnostic three-layer framework for structuring observability data so alerts support understanding, not confusion, during incidents.

",https://linkedin.com/in/khushboo-nigam,,,,,Khushboo Nigam_sre.png,,,
No,main,Makarand Gujarathi,Senior Software Engineer,Walmart,,,,AI-Assisted Incident Response Using LLMs and MCP in Distributed Systems,"Diagnosing production incidents in modern distributed systems is a core SRE challenge. Large-scale microservices environments often consist of dozens or hundreds of independently deployed services, where a single user-facing failure can span 5–10 backend components, heterogeneous telemetry schemas, and timestamp skew ranging from hundreds of milliseconds to several seconds. In practice, engineers investigating moderate-complexity incidents routinely spend 2–4 hours writing 15–30 SQL queries and manually correlating logs, metrics, and traces across multiple observability stores. The system knowledge required to do this effectively often takes months to acquire, creating on-call bottlenecks and operational risk.

This session presents a production-tested incident response architecture that applies Large Language Models (LLMs) together with the Model Context Protocol (MCP) to automate distributed systems diagnostics. MCP provides a standardized interface that allows AI agents to safely introspect schemas and execute queries against observability data warehouses containing hundreds of telemetry tables and large volumes of historical data. Given a natural-language incident description, AI agents generate investigative SQL queries, iteratively refine them based on intermediate results, and correlate telemetry across multiple services to reconstruct end-to-end request flows.

The talk introduces context engineering as a foundational SRE practice for reliable AI-assisted diagnostics, covering the use of extensive schema documentation, curated query libraries, architecture diagrams, and incident pattern catalogs to ground model behavior in real production systems. Drawing from over 200 production incidents, we examine how these workflows reduce investigative effort, shorten time to resolution, and enable less-experienced engineers to perform advanced diagnostics while preserving human oversight and operational trust.

Attendees will leave with concrete architectural patterns and operational lessons for integrating AI into real-world SRE incident response.",https://www.linkedin.com/in/makarand-gujarathi-20817847/,,,,,Makarand Gujarathi_sre.png,,,
No,main,Mariem Sboui,Senior Site Reliability Engineer,gridX,,,,Why Kubernetes Default Load Balancing Doesn’t Work for HTTP/2 Traffic,"When we introduced HTTP/2 traffic into our Kubernetes environment, we observed a puzzling incident: one backend pod consistently showed high CPU usage and latency, while others remained almost completely idle. Node and cluster metrics indicated sufficient capacity, yet performance degradation persisted.

The root cause was a misunderstanding of how Kubernetes Services and kube-proxy handle traffic. By default, Kubernetes performs Layer-4 (TCP) load balancing at the connection level. While this works well for HTTP/1.x with short-lived connections, HTTP/2 multiplexing allows many requests over a single connection — causing all traffic to be routed to one pod.

In this talk, I’ll break down what happened, why traditional assumptions about load balancing failed, and how introducing Layer-7 routing through a service mesh resolved the issue. Attendees will gain practical insights into HTTP/2 behavior, kube-proxy limitations, and real-world traffic engineering lessons.",https://www.linkedin.com/in/mariam-s-76906711b/,,,,,astronaut_sre.png,,,
No,main,Michael Levan,AI Architect,solo.io,,,,From Black Box to See-Through: Observing and Troubleshooting k8s & Agents with Kagent,"This session will showcase how to reinvent the way we look at performance optimization and observability within environments using kagent, an open-source tool designed to run AI Agents declaratively and natively on Kubernetes.",https://www.linkedin.com/in/michaellevan/,TheNJDevOpsGuy,,,,Michael Levan_sre.png,,,
No,main,Mukul Kumar Gaur,Senior Principal - Product Management • Product Engineering,Accelya Group,,,,SRE-Ready NDC Shopping: Caching at Scale Without Pricing Drift,"As airlines adopt offer- and order–based retailing, NDC shopping platforms are increasingly expected to handle millions of search requests from metasearch engines, OTAs, agencies, and direct digital channels. Running full real-time pricing logic—inventory evaluation, continuous pricing, fare rules, taxes, and ancillaries—on every request can introduce latency, amplify infrastructure load, and drive cloud costs, especially when much of the traffic is non-transactional.

This session examines cache-based shopping as an SRE-critical scalability pattern for high-volume NDC environments. By serving repetitive or low-value requests from precomputed Offers, airlines can reduce Offer Engine load while maintaining sub-second response times that support conversion and user experience, particularly on mobile.

The talk explores multiple caching strategies, including full Offer caches, hybrid anchored caches, and partial component caches, and evaluates how each impacts reliability, performance, and operational stability during demand spikes such as peak seasons and promotional events. Special focus is placed on retail integrity controls: cache freshness thresholds, high-elasticity market handling, continuous pricing alignment, and real-time cache invalidation to prevent stale pricing and settlement discrepancies.

Finally, the session outlines governance approaches using request quality scoring, partner-level cache controls, and BI-driven monitoring to balance speed with correctness. Attendees will leave with practical guidance on using intelligent caching to scale NDC retailing without sacrificing pricing transparency, commercial trust, or long-term revenue performance.",https://www.linkedin.com/in/mukul-gaur-b507a816,,,,,Mukul Kumar Gaur_sre.png,,,
No,main,Murali Varma,Senior Staff Software Engineer,Galileo Financial Technologies LLC,,,,SRE Driven Frontend Architecture for High Performance and Reliable Web Systems,"Frontend architecture has experienced a significant transformation over the past decade as web systems scale to meet increasing demands for performance, reliability, and global accessibility. Early Single Page Application architectures enabled rich client side interactivity but often delivered JavaScript bundles of 2 to 3 MB, leading to first contentful paint times of 3 to 4 seconds on mobile networks. Empirical studies referenced in this work show that 53 percent of users abandon applications that exceed 3 seconds of load time, with abandonment rising to 71 percent beyond 4 seconds, underscoring the need for more efficient architectural models.

This presentation examines the evolution from Virtual DOM based rendering toward server centric architectures, including Server Components, streaming server side rendering, and hybrid rendering models. Reported results demonstrate up to 60 percent reductions in JavaScript bundle size, 45 percent faster initial page loads, and 42 percent improvements in Time to First Meaningful Paint when server driven rendering strategies are applied. Longitudinal production metrics further show server response times improving from 300 ms to 150 ms and cache hit rates increasing from 65 percent to 89 percent across multiple deployment cycles.

The talk also explores innovations in build systems that support modern frontend architectures, highlighting Rust based tooling such as Turbopack, which achieves up to 10x faster cold starts and improved build stability. Enterprise adoption evidence indicates a 35 percent reduction in time to market and a 47 percent increase in developer productivity when these architectural patterns are combined with performance driven development practices.",https://www.linkedin.com/in/murlax,,,,,Murali Varma_sre.png,,,
No,main,Naveen Prakash,Sr. Software Engineer,Yahoo Inc.,,,,From Outages to Uptime: Practical Lessons in Site Reliability Engineering,"Ensuring system reliability in today’s fast-paced, cloud-native environments requires more than just monitoring and incident response—it demands proactive design, automation, and collaboration. In this session, we will explore practical strategies SRE teams use to improve system resilience, reduce downtime, and streamline incident management. Topics include:
Designing fault-tolerant systems and scalable architectures
Implementing robust monitoring and alerting practices
Leveraging automation for repetitive tasks and faster recovery
Best practices for collaboration between SRE, DevOps, and engineering teams
Attendees will leave with actionable insights and frameworks to enhance reliability and operational efficiency in their own organizations",https://linkedin.com/in/naveenprakash82,,,,,Naveen Prakash_sre.png,,,
No,main,Neal Iyer,Director of Product,Splunk - a Cisco company,,,,Guardrails First: Designing Reliable AI Agents for Resilient and Secure Operations,"Discover how to build AI agents that boost reliability without breaking trust. This talk unveils the “Guardrails-First” framework blending resilience, observability, and automation to deploy safe, accountable AI in high-stakes security and SRE environments.",https://www.linkedin.com/in/nealiyer/,,,,,Neal Iyer_sre.png,,,
No,main,Oreoluwa Omoike,Site Reliability Engineer,JPMorgan Chase & CO,,,,AI-Driven Risk-Aware Decision-Making for Scalable Reliability Systems,"Resilience in Site Reliability Engineering encompasses more than just failure detection; it also includes the ability to make informed choices amidst uncertainty. This talk delves into how AI-driven, risk-aware decision-making extends automation, optimizes risk management, and guarantees the construction of scalable, high-reliability systems.",https://linkedin.com/in/oreoluwa-omoike,,,,,Oreoluwa Omoike_sre.png,,,
No,main,Prajakta Talathi,Marketing Analytics Manager,College Ave,,,,Operating Predictive Analytics at Scale: Reliability Engineering for Data-Driven Education Finance,"As education finance platforms become increasingly dependent on predictive analytics, reliability and operational resilience become just as critical as model accuracy. Institutions now run forecasting, risk assessment, and decision systems that must remain highly available, observable, and trustworthy under variable data quality, changing demand, and regulatory constraints.

This session examines how Site Reliability Engineering (SRE) principles can be applied to operate predictive analytics systems reliably in education finance environments. Using real-world implementations, the talk explores how financial and student performance data pipelines are designed for fault tolerance, scalability, and graceful degradation ensuring predictive services continue to support planning and decision-making even under system stress.

A central focus is the operationalization of predictive models for risk assessment and resource allocation. The presentation covers reliability challenges such as data drift, model degradation, pipeline failures, and automation errors, and shows how SRE practices, including SLIs/SLOs, monitoring, alerting, and automated remediation, help maintain system stability and confidence in predictions.

The session also highlights how automation and AI-enabled workflows improve operational reliability across finance processes such as loan processing, grant disbursement, and compliance tracking. By reducing manual intervention and increasing observability, teams can detect anomalies earlier, prevent cascading failures, and scale systems without sacrificing correctness or transparency.

Looking ahead, the talk demonstrates how combining predictive intelligence with SRE discipline enables a shift from reactive incident response to proactive, resilient operations. Attendees will gain practical insights into running data-driven financial systems as reliable production services where real-time analytics, automation, and reliability engineering work together to support long-term sustainability and student success.",https://www.linkedin.com/in/prajaktatalathi/,,,,,Prajakta Talathi_sre.png,,,
No,main,Prakash Easwaran,Implementation Manager,ZeOmega Inc,,,,Reliable AI-Driven UM Letters: Automating Compliance in Healthcare Systems,"In healthcare Utilization Management (UM), letters are a critical yet fragile communication pathway between systems and members. Approval and Denial Letters must meet strict regulatory turnaround times, include precise authorization data, and be reliably delivered to external fulfillment centers. From an SRE perspective, even minor failures across APIs, business rules, or correspondence engines can cascade into compliance violations and operational risk.

This session examines the design and operation of a fully automated UM Letters architecture within Jiva, built for reliability, observability, and regulatory resilience. The system enables end-to-end automation for Approval Letters with zero manual intervention by dynamically retrieving authorization data in real time, generating correspondence deterministically, and securely transmitting letters to external print-and-mail vendors. A bidirectional integration returns mailing confirmations and tracking data, creating a complete, auditable feedback loop that supports regulatory reporting and incident investigation.

For Denial Letters, the session explores the controlled use of Generative AI to improve clarity and member understanding without sacrificing correctness. The AI component analyzes the full authorization lifecycle—including clinical notes and medical rationales—and translates complex medical decisions into member-readable language aligned with health literacy standards. To preserve safety and compliance, the workflow includes a human-in-the-loop verification step before release.

Attendees will learn how SRE principles—fault isolation, automation, traceability, and defensive design—can be applied to AI-enabled correspondence systems in highly regulated healthcare environments, improving reliability while reducing appeals and enhancing the member experience.",https://www.linkedin.com/in/prakasheaswaran/,,,,,Prakash Easwaran_sre.png,,,
No,main,Rajesh Kumar Balusu,Database Architect,AGAP Technologies Inc,,,,Building Highly Available Databases with Cloud Native Reliability Practices,"As organizations modernize production systems, database reliability becomes a critical concern for site reliability engineers responsible for uptime, resilience, and operational predictability. This session focuses on practical cloud native techniques for designing and operating highly available database infrastructure, with an emphasis on measurable reliability objectives, architectural tradeoffs, and controlled migration strategies.

The session begins with reliability focused assessment and planning. Existing database environments are evaluated against defined service level objectives, including target uptime levels such as five nines, recovery time objectives, recovery point objectives, and latency thresholds. Infrastructure reviews identify single points of failure, aging components, workload saturation risks, and security gaps. Capacity planning is driven by observable metrics such as CPU and memory utilization, peak transaction rates, and concurrency patterns to balance cost efficiency with reliability headroom. Traffic distribution and failover mechanisms using tools such as NGINX or HAProxy are discussed as foundational reliability controls.

The session then examines how cloud native platforms support SRE outcomes. Topics include container based consistency, Kubernetes orchestration for self healing and automated recovery, scaling policies tied to workload signals, and CI CD pipelines with defined rollback criteria. These practices are mapped to operational metrics such as deployment frequency, mean time to recovery, and change failure rate.

Finally, the session outlines a structured database migration approach using the 6 Rs framework, covering dependency analysis, total cost evaluation, phased execution, and post migration optimization. High availability principles including redundancy, automated failover, data replication, and resilience testing are presented as core reliability requirements.",https://www.linkedin.com/in/awsoracle,,,,,Rajesh Kumar Balusu_sre.png,,,
No,main,Rakesh Kumar Kavsari Gopal,Technical Architect,"Osmania University, India",,,,Resilient AI Platforms for Crisis-Ready Health and Financial Systems,"Extreme weather events, pandemics, and economic shocks continue to strain healthcare and financial systems, particularly in vulnerable communities. For Site Reliability Engineering teams, ensuring uninterrupted access to critical services during crises is both a technical and ethical responsibility. This session presents a resilient AI-driven enterprise platform designed to maintain availability, scalability, and compliance in crisis-responsive environments.

The platform applies AI-driven predictive load balancing, context-aware service reconfiguration, and edge intelligence to sustain essential services under extreme demand and infrastructure instability. Its software stack includes AI-enabled load balancers, financial transaction processors, mobile-first applications for aid distribution, and disaster equity protocols that prioritize vulnerable populations. The hardware layer integrates resilient edge clusters, ruggedized servers for disaster-prone regions, and low-latency networking devices that support both offline-first and cloud environments.

From an SRE perspective, the architecture emphasizes dynamic capacity planning to handle millions of concurrent users, decentralized and encrypted data storage across cloud and edge nodes, and compliance with global data protection standards. Migration from legacy systems follows a staged hybrid approach, enabling offline-first systems to run alongside existing platforms while AI-driven modules progressively assume mission-critical workloads. Fallback protocols and service-level agreements reinforce reliability during unpredictable disruptions.

Organizations adopting this approach can reduce service delivery times by up to 60 percent during crises and achieve financial improvements of 20 to 30 percent through optimized resource allocation and reduced disruption costs. By aligning reliability engineering practices with disaster resilience frameworks, these platforms establish a dependable foundation for crisis-ready healthcare and financial ecosystems.",https://www.linkedin.com/in/rakesh-kumar-kavsari-gopal-ba136453/,,,,,Rakesh Kumar Kavsari Gopal_sre.png,,,
No,main,Raman Tehlan,Cloud Native Consultant,Zurich Lab,Shubham Rai,Engineering,Truefoundry,Unlocking Just-in-Time CPU Optimization with In-Place Pod Resize,"Kubernetes clusters are often over-provisioned at the pod level, yet some workloads still experience CPU throttling. This usually comes from static CPU requests that are sized for worst-case behavior and rarely revisited once workloads are running. Recommendation-based systems exist, but applying frequent changes in production has traditionally been difficult due to restarts and operational risk.

In-place pod resize makes it possible to update CPU requests without recreating pods, and PSI (Pressure Stall Indicator) metrics provide a clearer signal of real CPU contention. Together, these enable a different approach: making small, frequent, just-in-time corrections instead of relying on long-term prediction.

In this talk, we share how we built CruiseKube, a runtime CPU optimization system that continuously right-sizes pods in place and takes node context into account. We discuss the key design choices, tradeoffs, and lessons learned from running this approach in real clusters.",https://linkedin.com/in/ramantehlan,,https://www.linkedin.com/in/shubham-rai-132a25a3,,,Raman Tehlan & Shubham Rai_sre.png,,,
No,main,Ran Tao,Cloud Support Engineer,"Amazon Web Services, Inc.",,,,"Migration from On-Prem Messaging System to The Cloud: What, How and Why","The race to the cloud is on, with enterprises everywhere migrating core infrastructure to stay competitive and cost effective. But when it comes to the messaging systems that power cross-component communications, a simple “lift and shift” isn’t adequate and can be a recipe for failure. The migration path is riddled with complex decisions and design pitfalls unique to every use case. In this session, AWS Cloud Support expert Tom will walk you through the critical stages of rehosting, replatforming, and refactoring, showing you how to unlock maximum performance and reliability for messaging systems. Additionally, Tom will compare traditional message brokers with more modernized serverless messaging services on AWS. By the end of the session, you will have a much more comprehensive understanding of the migration prcess, key questions to ask and some best practices for harnessing the benefits of Cloud.",https://www.linkedin.com/in/tomtaoran/,,,,,Ran Tao_sre.png,,,
No,main,Rohit Wadhwa,Senior Software Engineer,Walmart Inc,,,,Predictive Workflow Integrity for SRE: Autonomous Triage at Global Scale,"Modern enterprise platforms rely on event-driven microservices deployed across globally distributed regions. While this architecture enables scale and rapid delivery, it also introduces SRE challenges around state divergence, latency variability, and cascading workflow failures that are difficult to detect using service-level signals alone. In environments operating across thousands of nodes and high-volume event streams, reactive approaches based on manual monitoring often lead to delayed detection and extended recovery times.

This session presents Predictive Workflow Integrity (PWI), a reliability model that shifts observability and resilience from individual services to end-to-end business workflows. Workflows are modeled as distributed state machines, with transitions continuously evaluated for anomalies such as delayed convergence, conflicting ownership, and abnormal execution paths. In enterprise deployments, this workflow-centric approach reduced mean time to detection from approximately 12 minutes to under 1 minute, while mean time to mitigation dropped from roughly 45–50 minutes to 10–12 minutes. False-positive alert rates were reduced from around 18% to approximately 4%, improving operator trust and on-call effectiveness.

To operationalize PWI, the talk introduces an Autonomous Incident Triage mechanism that correlates logs, metrics, and traces into a unified, event-driven causal graph. This enables real-time impact assessment and supports automated remediation actions aligned with SRE objectives. The session also covers Ring-Based Geolocation Routing, a strategy that localizes event processing and decision-making to improve determinism during regional degradation. This routing model reduced edge-to-cloud latency from roughly 5 seconds to under 1 second for latency-sensitive workflows.

Attendees will gain a practical, SRE-focused perspective on designing predictive, self-regulating resilience for large-scale, distributed systems.",https://www.linkedin.com/in/rohit-wadhwa-5a304b22/,,,,,Rohit Wadhwa_sre.png,,,
No,main,Sanjay Basu,Global Head for AI / GenAI Products,TCS,,,,"Operationalizing LLMs at Scale: Reliability, Resilience, and Cognitive Commerce in Grocery Retail","Large Language Models (LLMs) are rapidly transitioning from experimental innovation to mission-critical infrastructure within grocery retail and e-commerce ecosystems. For Site Reliability Engineers, this shift introduces a fundamentally new operational challenge: probabilistic, multimodal AI systems must now meet strict expectations for availability, latency, cost efficiency, security, and regulatory compliance in high-volume, real-time production environments.

Unlike traditional deterministic services, LLM-driven architectures produce non-deterministic outputs, exhibit token-level latency variability, and depend on evolving prompts, embeddings, and context windows. These characteristics require rethinking conventional SRE practices around service-level objectives (SLOs), monitoring, incident response, and failure containment. Operating LLM-powered systems in retail—where peak traffic, substitutions, personalization, and inventory accuracy directly affect revenue and customer trust—demands robust reliability engineering patterns and resilient system design.

This session explores how to operationalize LLMs across customer experience, merchandising, and supply chain workflows while maintaining production-grade reliability. We will examine architectural strategies such as graceful degradation, fallback orchestration, guardrail enforcement, hybrid rule-based and AI decision layers, and human-in-the-loop escalation models. The discussion will also cover observability frameworks for AI systems, including prompt telemetry, semantic evaluation pipelines, hallucination detection, cost-aware scaling, and drift monitoring.

Finally, the presentation addresses the operational implications of agentic LLM architectures in logistics, fulfillment centers, and last-mile delivery systems, where autonomous reasoning must be bounded by strict reliability constraints. By grounding cognitive commerce in core SRE principles—fault tolerance, resilience engineering, performance optimization, and measurable SLO governance—this talk provides a pragmatic framework for running LLM-powered platforms at scale in environments where downtime, inconsistency, or model failure directly impact operational continuity and customer confidence.",https://www.linkedin.com/in/basusanjay/,,,,,Sanjay Basu_sre.png,,,
No,main,Savi Grover,Site Reliability Engineer,Tekskills Inc,,,,"From Alerts to Answers: Modern SRE with Observability, AI, and Agentic Ops","Traditional monitoring tells us something is broken—modern observability tells us why. This talk explores how SRE teams can evolve from reactive alert handling to proactive reliability engineering using distributed tracing, golden signals, and AI-powered agents. We’ll discuss real-world patterns for reducing MTTR, eliminating alert fatigue, and using agent-based systems to triage incidents automatically in cloud-native environments.
",https://www.linkedin.com/in/savi-grover/,,,,,Savi Grover_sre.png,,,
No,main,Shankara Krishna Teja Arra,Sr DevOps Engineer II,o9 Solutions Inc,,,,Reducing MTTR with Agentic AI: An Intelligent Assistant for Modern SRE Teams,"Site Reliability Engineering teams operate in high-pressure environments where fragmented operational knowledge increases cognitive load and delays incident resolution. Runbooks, logs, dashboards, and historical tickets often live in disconnected systems, forcing engineers to manually search for context during critical outages. As systems scale, this fragmentation directly impacts MTTR, error budgets, and overall service reliability.

This session presents the design and real-world implementation of an Agentic AI-powered operational assistant built to support SRE workflows. Leveraging large language models, vector search, and event-driven microservices, the system transforms static documentation and troubleshooting artifacts into actionable, conversational workflows. The assistant retrieves context-aware insights, correlates logs with historical incidents, guides runbook execution, and can trigger controlled remediation tasks within secure governance boundaries.

We will explore architectural patterns, integration with observability and CI/CD pipelines, and production lessons learned around reliability, security, and adoption. The results demonstrate measurable improvements in MTTR, faster onboarding of SREs, and improved knowledge reuse across incident response cycles.

By embedding intelligent automation directly into reliability workflows, this approach reduces cognitive load, preserves institutional knowledge, and strengthens operational resilience helping SRE teams move from reactive firefighting toward proactive reliability engineering.",https://www.linkedin.com/in/krishna-venkataa/,,,,,Shankara Krishna Teja Arra_sre.png,,,
No,main,Shivam Tiwari,Principal Data Science,Discover Financial Services,,,,Data Science–Driven Transaction Monitoring at Scale: From Rules to Real-Time Systems,"Financial institutions operate transaction monitoring platforms under extreme scale, latency, and regulatory constraints—conditions familiar to any DevOps-driven organization. Yet many systems still rely on static, rule-based logic that generates excessive false positives while failing to adapt to evolving financial crime patterns.

This talk presents a data science–driven transaction monitoring framework designed with production realities in mind. The framework replaces brittle rules with adaptive, observable, and governable systems that align with modern DevOps principles.

Behavioral profiling using unsupervised learning establishes individualized customer baselines, enabling context-aware monitoring that evolves over time rather than relying on static thresholds. Network analytics and graph-based methods surface coordinated activity and hidden relationships that traditional pipelines cannot detect, even across distributed payment ecosystems. Real-time anomaly detection processes continuous transaction streams using statistical and neural techniques, supporting low-latency detection without sacrificing system stability. Automated preliminary investigation tools streamline compliance workflows by producing structured, machine-assisted assessments.

The session also addresses implementation challenges DevOps teams care about: regulatory constraints, system interoperability, model governance, and operational sustainability. Dynamic risk scoring combines multiple signals into ensemble-based assessments, while intelligent alert prioritization reduces noise and improves downstream workload management.

Attendees will leave with practical strategies for operating machine learning–powered detection systems in production—balancing reliability, compliance, and adaptability—while shifting financial crime monitoring from reactive rule execution to proactive, system-level prevention.",https://www.linkedin.com/in/shivamtiwari23/,,,,,Shivam Tiwari_sre.png,,,
No,main,Shruthi Rajashekar,Engineering Manager,Broadcom Inc,,,,Reducing On-Call Pain in Hybrid Platforms: Operating VMs and Containers Reliably on Kubernetes,"SRE teams are often responsible for platforms that run a mix of containerized services and long-lived virtual machines each with different failure modes, tooling, and operational runbooks. This fragmentation increases operational risk, complicates incident response, and makes it harder to meet SLOs.

This talk explores how treating virtual machines as first-class resources in Kubernetes, via VM Service, can simplify reliability and operations for hybrid platforms. We’ll examine how a unified, declarative control plane reduces cognitive load, standardizes lifecycle management, and improves consistency across alerts, remediation, and capacity planning.

Drawing from large-scale production environments, the session will highlight real reliability lessons around failure isolation, rollout safety, policy enforcement, and day-2 operations when running VMs and containers together. We’ll also discuss observability signals and operational patterns SREs use to detect issues early and limit blast radius.

Attendees will leave with practical guidance on building and operating hybrid Kubernetes platforms that are easier to support on-call, more predictable under failure, and better aligned with SRE reliability goals.",https://www.linkedin.com/in/shruthi-rajashekar-23860926/,,,,,Shruthi Rajashekar_sre.png,,,
No,main,Shruthi Sepuri,Software Developer Engineer,TATA Consultancy Services(TCS),,,,From Testing to Reliability: Strengthening Regulated Production Systems,"In regulated industries such as insurance and financial services, system failures extend beyond technical inconvenience—they can directly impact compliance, audit outcomes, and operational risk. While testing validates functionality before release, long-term production reliability requires a broader, continuous approach.

This session explores how principles from Site Reliability Engineering (SRE) can complement traditional testing practices to strengthen regulated production systems. Rather than focusing solely on infrastructure uptime, the discussion emphasizes reliability at the business workflow level, including claims processing, underwriting, policy adjustments, and other compliance-sensitive operations.

The presentation outlines practical methods to:

Connect pre-release testing outcomes to production reliability goals

Identify and monitor failures that carry regulatory or business impact

Prevent silent defects in rule-driven or automated workflows

Improve incident response readiness in compliance-critical environments

Establish feedback loops between testing, monitoring, and operational support

Using real-world enterprise scenarios, this talk provides a structured yet accessible approach for engineers and QA professionals seeking to extend testing practices into sustained production reliability. Attendees will gain a foundational understanding of how reliability engineering can enhance governance, reduce compliance exposure, and support resilient operations in regulated systems.",https://www.linkedin.com/in/shruthi-s-a8384b167/,,,,,astronaut_sre.png,,,
No,main,Sonali Galhotra,Sr. Engineering Program Manager,Apple Inc.,,,,Profitability as a Reliability Signal: Tesla vs. GM Through an SRE Lens,"In large-scale, complex systems, reliability is inseparable from sustainability. This talk examines how financial performance metrics can act as high-level signals of operational resilience by comparing Tesla Inc. and General Motors through a longitudinal analysis of profitability ratios derived from published financial statements.

Using gross, operating, and net profit ratios, the study evaluates how different strategic and operational models manifest in measurable outcomes over time. Tesla’s stronger gross profitability reflects an innovation-driven approach and vertically integrated model, while its operating and net margins show notable volatility associated with aggressive investment, rapid scaling, and ongoing system expansion. General Motors, by contrast, demonstrates more stable operating and net profitability, consistent with a mature, scale-driven production system and diversified portfolio.

Statistical analysis shows that differences in gross profitability between the two firms are significant, while operating and net profitability differences are not statistically distinct. For SRE practitioners, these findings offer a macro-level analogy to system behavior: innovation-heavy architectures can deliver strong top-line efficiency but introduce variability, while established systems often trade peak performance for predictability.

The session invites SREs to think beyond traditional telemetry by exploring how financial metrics mirror system design choices, risk tolerance, and long-term sustainability in large socio-technical systems.",https://www.linkedin.com/in/sonali-g-87489174/,,,,,Sonali Galhotra_sre.png,,,
No,main,Spiros Economakis,Founder & CEO,NOFire AI,,,,How AI is redefining SRE and Customer Experience,"AI is reshaping SRE, but the real opportunity isn’t faster RCA, it’s building proactive, customer-centered reliability. This talk explores how AI and culture together move us from firefighting to foresight.",https://www.linkedin.com/in/spirosoik/,spirosoik,,,,Spiros Economakis_sre.png,,,
No,main,Stuart Clark,Senior Developer Advocate,Spotify,,,,Scale or Fail as Spotify's Growth Exposed the Abstraction Paradox,"At Spotify, serving 675M users, hyper-growth in 2014 created system fragmentation that made onboarding engineers difficult. Our abstractions oversimplified complexity, hindering incident response. We learned effective abstraction teaches complexity rather than hiding it.",https://www.linkedin.com/in/stuarteclark/,bigevilbeard,,,,Stuart Clark_sre.png,,,
No,main,Suganya Nagarajan,Software Development Manager,Amazon.com LLC,,,,Human-Governed Automation Loops for Reliable AI at Planet Scale,"Modern AI-driven systems operate at extreme scale, executing decisions across millions of requests while meeting strict SRE requirements for latency, availability, and fault isolation. In domains such as real time experimentation, personalization, and automated decisioning, automation is no longer optional it is a prerequisite for operating at scale. Yet as autonomy increases, failures propagate faster, affect larger blast radii, and become harder to contain, especially in always-on distributed systems where objectives evolve and feedback is delayed or incomplete.
This talk introduces Human-Governed Automation Loops (HGAL), a systems-level architecture designed to address a critical reliability gap in large-scale AI platforms: the lack of runtime governance. Existing approaches—such as human-in-the-loop learning, governance frameworks, and policy-based controls typically operate offline, asynchronously, or at system boundaries. They do not map cleanly to high-throughput environments where decisions are continuous, interdependent, and time-sensitive, and where errors can impact production systems before humans can intervene.
HGAL reframes automation by explicitly separating decision generation from decision authorization. AI components continuously propose actions at scale, while governance mechanisms defined, observed, and evolved by humans determine whether those actions are allowed to execute. This allows systems to remain fully online without blocking decision flow, while still enforcing human authority when uncertainty, impact radius, or reliability risk is high.
A core concept in HGAL is decision delegation boundaries, which define when automation may act independently and when escalation, constraint, or rollback is required. These boundaries operate across dimensions such as confidence, historical reliability, impact scope, and contextual constraints, allowing autonomy to expand gradually and safely rather than uniformly across all decisions.
By embedding governance directly into the automation control plane, HGAL turns human oversight into a scalable, programmable, and observable reliability mechanism. The result is an architecture that enables high-throughput AI systems to scale without sacrificing control, accountability, or resilience.
Attendees will learn how to:
Design delegation boundaries that limit blast radius in automated systems
Embed governance into control planes without blocking execution
Apply HGAL to real-world platforms such as experimentation, recommendations, and notifications
Scale AI automation while preserving reliability, trust, and operational resilience",https://www.linkedin.com/in/suganya-nagarajan-a4185617,,,,,Suganya Nagarajan_sre.png,,,
No,main,Sylvain Kalache,Head of AI Labs,Rootly,,,,From Vibes to Outages: When AI Writes the Code You Debug,"AI-assisted coding is exploding. But this acceleration doesn't translate into reliability. Quite the opposite.

This talk dives into the quirks of LLM-assisted development with real-world examples: hard-to-trace bugs, AI-generated tests that mirror flawed logic, and hallucinated dependencies that open security gaps. We'll examine the operational fallout: skyrocketing code churn, higher incident rates, and large batch deployments that make debugging harder.

As developers become less familiar with their own code, leaner SRE teams deal with the consequences. We'll explore actionable strategies, from AI-powered incident tools to ""incident vibing.""",https://www.linkedin.com/in/sylvainkalache/,,,,,Sylvain Kalache_sre.png,,,
No,main,Venkata Kundavaram,IT DEVELOPMENT MANAGER,GOODWILL EASTER SEALS MINNESOTA,,,,Reliable Data at Scale: ETL vs. Unified Platforms in Modern SRE,"As data systems grow in scale and complexity, Site Reliability Engineering (SRE) teams face increasing pressure to ensure reliability, scalability, and low-latency performance across data pipelines. This session presents a comparative analysis of traditional ETL tools and unified data platforms through the lens of reliability engineering and operational resilience.
Drawing on structured research across peer-reviewed literature and industry reports, the session evaluates three dimensions critical to SRE practice: scalability under load, data handling flexibility, and operational cost efficiency. Traditional ETL tools perform well in stable, structured, batch-oriented environments, offering predictable transformations and lower upfront costs. However, batch processing models introduce latency and transformation bottlenecks that can impact system availability and real-time reliability objectives.
In contrast, unified data platforms built on distributed, horizontally scalable architectures better support continuous ingestion, real-time analytics, and diverse data types. Their integrated approach enhances observability, governance, and fault tolerance, though often with greater operational complexity and investment.
The session concludes with practical decision frameworks based on scale, reliability targets, integration needs, and total cost of ownership equipping SRE leaders to align data architecture choices with service reliability and long-term growth objectives.",https://www.linkedin.com/in/venkata-kundavaram-66a67a20/,,,,,Venkata Kundavaram_sre.png,,,
No,main,Vishal Shah,Staff Software engineer - 2,Visa,,,,Reliable API Support: Human-in-the-Loop Agentic RAG for SRE,"Modern developer support systems often prioritize speed over reliability, creating risk when API documentation is outdated or contextually incomplete. For SRE teams, this trade-off can lead to production misconfigurations, incident amplification, and erosion of trust in internal knowledge systems. This session presents Reliable API Support, an Agentic Retrieval-Augmented Generation (RAG) framework designed to improve operational accuracy through structured human governance.

At the core of the architecture is an Agentic Knowledge Orchestrator that combines multi-source RAG synthesis across documentation, prior discussions, and internal knowledge artifacts with a Human-in-the-Loop validation layer embedded directly within enterprise collaboration platforms such as Microsoft Teams. When a developer submits an API query, the agent generates a provisional response that is routed to the API ownership team for real-time expert verification before publication, ensuring correctness at the point of dissemination.

The framework incorporates explicit reliability feedback loops. Expert corrections captured during approval are reintegrated into the knowledge base, strengthening supervised learning grounded in domain authority. Post-release signals from user acceptance provide downstream validation, enabling controlled self-improvement over time. This approach reduces hallucination risk, enforces accountability, and aligns AI-assisted support with SRE principles of observability, feedback, and continuous improvement.

Attendees will gain architectural insights into designing AI-driven support systems that scale across enterprise environments while maintaining operational integrity, governance, and trust.",https://www.linkedin.com/in/vishal-s-b99b9725/,,,,,Vishal Shah_sre.png,,,
No,main,Vladyslav Budichenko,Senior Software Engineer,Vocaly AI,,,,"AI Agents for Incident Response: The Good, the Bad, and the Ugly","AI agents are joining your on-call team - but can you trust them? This talk exposes where they supercharge incident response, where they cause chaos, and how to use them safely with tools like MCP. Real lessons, no AI hype.",https://www.linkedin.com/in/vladyslav-budichenko/,,,,,Vladyslav Budichenko_sre.png,,,