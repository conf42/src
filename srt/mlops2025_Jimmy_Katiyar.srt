1
00:00:01,140 --> 00:00:02,910
Hey all, thanks for being here.

2
00:00:03,630 --> 00:00:07,380
My name is Jimmy Kaar and I'm a
senior manager at C-X-M-U-S-A.

3
00:00:08,189 --> 00:00:10,830
Today I'll be talking about
building scalable ML ops

4
00:00:10,830 --> 00:00:12,720
pipelines for enterprise systems.

5
00:00:13,470 --> 00:00:16,770
This topic is critical because
most machine learning projects

6
00:00:16,770 --> 00:00:18,390
don't fail due to poor models.

7
00:00:18,750 --> 00:00:21,030
They fail when trying to
scale them in production.

8
00:00:21,975 --> 00:00:25,935
I'll share how at C xm, we build
systems that can support millions

9
00:00:25,935 --> 00:00:27,705
of daily transactions reliably.

10
00:00:28,335 --> 00:00:31,845
The aim is to provide you with a mix of
theory and practical insights that you

11
00:00:31,845 --> 00:00:33,855
can apply in your own organizations.

12
00:00:35,894 --> 00:00:36,855
Here's our agenda.

13
00:00:37,394 --> 00:00:39,945
We'll begin with the
challenges enterprise face.

14
00:00:39,975 --> 00:00:44,025
In deploying ml, I'll show you
why traditional IT deployment

15
00:00:44,025 --> 00:00:47,685
approaches, uh, break down when
applied to machine learning.

16
00:00:48,165 --> 00:00:50,775
Next, we'll dive into the
architecture fundamentals.

17
00:00:52,530 --> 00:00:56,220
These are the building blocks that
every production ready EML systems need.

18
00:00:56,325 --> 00:01:01,635
Okay, then I'll explain the implementation
framework, a step-by-step way to

19
00:01:01,635 --> 00:01:03,675
automate and streamline deployments.

20
00:01:04,004 --> 00:01:08,655
After that, I'll share some real world
impact metrics from Sirius xm, so

21
00:01:08,655 --> 00:01:10,695
you can see the measurable benefits.

22
00:01:11,085 --> 00:01:15,315
Finally, closing with the strategic
roadmap so you know how to bring

23
00:01:15,315 --> 00:01:18,465
these practices into your own
organization incrementally.

24
00:01:21,015 --> 00:01:23,460
Now let's talk about the
enterprise ML challenge.

25
00:01:24,450 --> 00:01:27,420
Many organizations still
rely on manual processes.

26
00:01:27,930 --> 00:01:29,460
Deployments are done by hand.

27
00:01:29,700 --> 00:01:32,790
Environments don't match between
development and production,

28
00:01:33,000 --> 00:01:34,560
and teams work in silos.

29
00:01:35,160 --> 00:01:39,300
As a result, the deployments can take
months, incidents occur frequently,

30
00:01:39,360 --> 00:01:40,770
and compliance is difficult.

31
00:01:41,190 --> 00:01:44,160
This isn't just a technical
issue, it's a business one.

32
00:01:44,760 --> 00:01:49,200
When it takes 60 to 90 days to put a
model into production, you lose agility.

33
00:01:50,190 --> 00:01:52,020
Competitors can trade faster with.

34
00:01:53,175 --> 00:01:54,435
And will outperform you.

35
00:01:54,884 --> 00:01:57,914
So the gap between data science,
experimentation, and production

36
00:01:57,914 --> 00:01:59,925
requirements become a major obstacle.

37
00:02:02,115 --> 00:02:05,804
Here we see the ML Ops
maturity journey at Level Zero.

38
00:02:05,865 --> 00:02:07,245
Things are completely manual.

39
00:02:07,634 --> 00:02:11,325
Deployments are ad hoc, and
monitoring is almost non-existent.

40
00:02:11,985 --> 00:02:15,195
Level one introduces some
partial automation, maybe a few

41
00:02:15,195 --> 00:02:17,115
scripts, or a basic CICD setup.

42
00:02:17,865 --> 00:02:20,715
At level two, you can start
continuously delivering models

43
00:02:20,715 --> 00:02:22,425
with pipelines and some monitoring.

44
00:02:23,130 --> 00:02:25,710
Finally at level three,
everything is automated.

45
00:02:25,980 --> 00:02:29,790
You have self-healing systems
and robust monitoring in place.

46
00:02:30,510 --> 00:02:34,650
At Sirius xm, we went from level one
to level three in just 18 months.

47
00:02:35,160 --> 00:02:40,110
That shift reduced deployment times from
weeks to ours while ensuring stability

48
00:02:40,110 --> 00:02:42,180
for millions of daily transactions.

49
00:02:44,820 --> 00:02:47,195
These are the four pillars
of ML Lops Architecture.

50
00:02:48,030 --> 00:02:50,190
First automated model Val.

51
00:02:50,370 --> 00:02:54,630
Validation ensures only high quality
compliant models get deployed.

52
00:02:55,260 --> 00:02:59,910
Second, CICD pipelines, standardized
deployments, and make rollbacks easy.

53
00:03:00,600 --> 00:03:04,350
Third, monitoring systems keep
track of model performance, data

54
00:03:04,350 --> 00:03:06,120
drift and overall system health.

55
00:03:06,120 --> 00:03:11,070
Finally, scalable infrastructure
such as Kubernetes allows us to

56
00:03:11,070 --> 00:03:12,300
manage workloads dynamically.

57
00:03:13,305 --> 00:03:13,725
Together.

58
00:03:13,725 --> 00:03:17,655
These pillars are what make scaling to
hundreds of production models possible.

59
00:03:19,575 --> 00:03:24,165
At Series xm, we built an automated
validation framework to ensure that only

60
00:03:24,165 --> 00:03:25,755
production ready models make it live.

61
00:03:26,475 --> 00:03:32,295
This framework ensures models on three
dimensions, statistical performance,

62
00:03:32,955 --> 00:03:35,265
operational readiness, and compliance.

63
00:03:36,345 --> 00:03:40,935
Statistical checks cover
accuracy, precision recall.

64
00:03:41,430 --> 00:03:43,680
F1 score and business KPIs.

65
00:03:44,549 --> 00:03:48,990
Operational readiness checks,
latency, scalability, and throughput

66
00:03:49,740 --> 00:03:55,950
compliance ensures explainability bias
detection and regulatory alignment.

67
00:03:56,730 --> 00:04:00,894
By putting these gates in place,
we reduce production issues by 94%.

68
00:04:01,315 --> 00:04:03,630
That's a massive
improvement in reliability.

69
00:04:06,870 --> 00:04:09,660
This diagram illustrates
our CICD pipeline.

70
00:04:10,020 --> 00:04:13,980
It starts with version control, not
just for code, but also for data

71
00:04:13,980 --> 00:04:16,740
sets, configurations and artifacts.

72
00:04:17,250 --> 00:04:21,150
The build and test stage uses
containerization, performance

73
00:04:21,150 --> 00:04:23,010
benchmarks, and security scanning.

74
00:04:23,820 --> 00:04:28,380
Staging is where we do shadow
deployments and AB testing to ensure

75
00:04:28,380 --> 00:04:30,330
the model behaves correctly under load.

76
00:04:30,990 --> 00:04:34,380
Finally, in production, we
rely on candidate deployments,

77
00:04:34,409 --> 00:04:37,020
automated rollbacks and audit logs.

78
00:04:37,620 --> 00:04:43,229
The result we brought deployment times
down from 45 days to just four hours.

79
00:04:44,340 --> 00:04:47,190
That's the power of automation
and a standardization.

80
00:04:49,919 --> 00:04:53,039
Monitoring is essential because
models degrade over time.

81
00:04:53,700 --> 00:04:55,710
We monitor across four dimensions.

82
00:04:55,979 --> 00:04:57,914
Model performance, data quality.

83
00:04:58,710 --> 00:05:01,050
System operations and business impact.

84
00:05:01,800 --> 00:05:06,750
That means looking at accuracy and
KPIs, checking for data drift, watching

85
00:05:06,750 --> 00:05:10,890
latency and error, and finally,
measuring revenue or conversion impact.

86
00:05:12,960 --> 00:05:16,289
In the first year alone, our
monitoring system detected 28

87
00:05:16,289 --> 00:05:19,260
critical drift incidents before
they could affect customers.

88
00:05:19,830 --> 00:05:23,670
This kind of proactive monitoring helps
prevent costly business disruptions.

89
00:05:27,150 --> 00:05:31,230
Enterprise ML workloads are
unpredictable, so infrastructure has

90
00:05:31,230 --> 00:05:32,760
to be both powerful and flexible.

91
00:05:33,510 --> 00:05:38,880
We use Kubernetes for container
orchestration and autoscaling Apache Spark

92
00:05:38,880 --> 00:05:43,800
for distributed data processing and load
balanced interfer interference services.

93
00:05:43,800 --> 00:05:47,490
For ancy security is equally important.

94
00:05:47,760 --> 00:05:51,450
We enforce strict access controls,
encryption, and audit logging.

95
00:05:52,110 --> 00:05:55,530
As a result, our system now
handles 3.5 million inference

96
00:05:55,530 --> 00:06:00,810
requests daily with 99.99% uptime
and sub 50 millisecond latency.

97
00:06:01,500 --> 00:06:03,990
That's production grade
infrastructure at scale.

98
00:06:07,320 --> 00:06:10,200
Of course, technology alone,
alone doesn't solve everything.

99
00:06:10,200 --> 00:06:14,940
Organizations fail face challenges
like mismatch skill sets.

100
00:06:15,285 --> 00:06:19,005
Fragmented tools and
inconsistent success metrics.

101
00:06:19,635 --> 00:06:23,565
Often engineers and data scientists
simply don't speak the same language.

102
00:06:24,075 --> 00:06:28,875
The solution we found at CSXM was to unify
development environments, standardized

103
00:06:28,875 --> 00:06:31,335
workflows, and create shared KPIs.

104
00:06:32,265 --> 00:06:34,035
Cross-functional collaboration was key.

105
00:06:34,845 --> 00:06:39,645
In fact, our VP of AI engineering
said the biggest win wasn't technical.

106
00:06:40,155 --> 00:06:42,735
It was getting both sides
to speak the same language.

107
00:06:47,385 --> 00:06:50,445
This chart compares metrics
before and after M lops.

108
00:06:50,895 --> 00:06:55,635
Before deployments were slow,
expensive, and error prone.

109
00:06:56,205 --> 00:07:00,465
After implementing M Lops, deployment
timelines dropped dramatically.

110
00:07:00,975 --> 00:07:05,385
Incidents were fewer, iterations
became easier, and costs went down.

111
00:07:06,105 --> 00:07:09,195
The takeaway is that ML Ops
isn't just about engineering.

112
00:07:09,915 --> 00:07:13,335
It directly translates into
business efficiency and agility.

113
00:07:16,979 --> 00:07:19,830
Here's the roadmap we recommend
for implementing ML ops.

114
00:07:20,370 --> 00:07:25,770
Phase one is about laying the
foundation, standardized environments,

115
00:07:25,979 --> 00:07:28,020
version control, and basic pipelines.

116
00:07:29,250 --> 00:07:34,860
Phase two introduces automation with CI
c. D pipelines, validation dashboards,

117
00:07:35,130 --> 00:07:37,025
model registry, and metadata tracking.

118
00:07:38,490 --> 00:07:39,420
Phase three scales.

119
00:07:39,420 --> 00:07:44,130
The system with Kubernetes orchestration
and advanced monitoring, along with

120
00:07:44,130 --> 00:07:48,870
data drift detection systems and
establishing automated rollback mechanism.

121
00:07:50,790 --> 00:07:55,170
Finally, phase four focuses on
optimization, implement advanced

122
00:07:55,170 --> 00:07:59,460
features, stores self-healing
infrastructure, features, stores

123
00:07:59,820 --> 00:08:01,409
restraining and governance.

124
00:08:01,980 --> 00:08:05,340
The key is not to attempt a full
transformation overnight, but

125
00:08:05,340 --> 00:08:06,810
to deliver increment values.

126
00:08:07,200 --> 00:08:08,040
In phases.

127
00:08:11,760 --> 00:08:17,130
Now let's look at common pitfalls
First, don't become tool obsessed.

128
00:08:17,730 --> 00:08:20,370
Tools should serve workflows
not the other way around.

129
00:08:21,120 --> 00:08:24,030
Second, don't underestimate
the cultural cha.

130
00:08:24,030 --> 00:08:25,080
Change required.

131
00:08:25,620 --> 00:08:28,290
If teams don't adapt, the
initiative will stall.

132
00:08:29,190 --> 00:08:32,159
And third, don't over
complicate your first steps.

133
00:08:32,400 --> 00:08:35,100
Start small, prove value, and then scale.

134
00:08:35,880 --> 00:08:38,969
The most successful implementation,
start with a single high value

135
00:08:38,969 --> 00:08:40,650
use case and expand from there.

136
00:08:43,289 --> 00:08:47,610
To summarize, ML Lops provides
a real competitive edge.

137
00:08:48,390 --> 00:08:52,380
Organizations that do this
well can deploy models 20 to 30

138
00:08:52,380 --> 00:08:53,969
times faster than their peers.

139
00:08:54,689 --> 00:08:59,850
The four pillars, validation, pipeline
monitoring, and infrastructure are your

140
00:08:59,850 --> 00:09:03,959
foundation, but equally important is
bridging the cultural gap between teams.

141
00:09:04,365 --> 00:09:09,255
Finally remember, start small,
focus on value and scale quickly.

142
00:09:09,585 --> 00:09:13,215
Once you have proven success,
this approach will maximize both

143
00:09:13,215 --> 00:09:16,635
technical and business outcomes
from your ML investments.

144
00:09:18,495 --> 00:09:20,445
That brings us to the end of the session.

145
00:09:22,035 --> 00:09:24,915
I hope you're walking away with
not just theoretical knowledge,

146
00:09:24,915 --> 00:09:28,515
but also practical steps for
building scalable ML lops pipelines.

147
00:09:29,115 --> 00:09:31,605
Thank you so much for your
time and attention and have

148
00:09:31,605 --> 00:09:32,595
a great rest of your day.

