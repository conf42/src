1
00:00:00,500 --> 00:00:01,220
Hi everyone.

2
00:00:01,220 --> 00:00:01,520
I'm bna.

3
00:00:01,850 --> 00:00:03,290
Thanks for joining me for the session.

4
00:00:03,600 --> 00:00:05,850
Today I'm going to talk
about how to accelerate your

5
00:00:05,850 --> 00:00:07,689
career via experimentation.

6
00:00:08,049 --> 00:00:09,910
Think of the session as a field guide.

7
00:00:10,090 --> 00:00:13,840
We'll hit experiment design patterns
that work in the wild, the platform

8
00:00:13,840 --> 00:00:18,040
pieces that make experimentation fast
and trustworthy, and the career moves

9
00:00:18,040 --> 00:00:19,659
that turn your work into impact.

10
00:00:20,080 --> 00:00:22,389
My goal is that you leave with a playbook.

11
00:00:22,689 --> 00:00:24,459
You can start using this week.

12
00:00:25,435 --> 00:00:28,884
Before we jump into the session let
me take a minute and talk about myself

13
00:00:28,884 --> 00:00:30,835
and why this topic matters to me.

14
00:00:31,345 --> 00:00:35,845
I've spent over a decade helping teams
design and scale experimentation using

15
00:00:35,845 --> 00:00:40,195
data to build products and solve business
problems, not just report on them.

16
00:00:40,465 --> 00:00:44,875
My core craft is experimentation and
casual inference, choosing right design

17
00:00:44,875 --> 00:00:48,955
for the constraint, measuring impact,
credibility, and translating results into

18
00:00:48,955 --> 00:00:54,205
decisions On systems side, I design and
operationalize experimentation platforms.

19
00:00:54,505 --> 00:00:57,625
So the tests are reproducible,
observable, and cheap to run.

20
00:00:58,015 --> 00:01:01,705
And strategically, I'm obsessed with
connecting insights to outcomes,

21
00:01:02,125 --> 00:01:06,475
turning analysis into decisions
leaders can trust, and building a

22
00:01:06,475 --> 00:01:09,205
culture where data informed is default.

23
00:01:09,955 --> 00:01:14,035
That combination, methodology,
platform, and business impact is

24
00:01:14,035 --> 00:01:15,354
what I'll share with you today.

25
00:01:16,115 --> 00:01:17,465
Let's quickly look at the agenda.

26
00:01:17,910 --> 00:01:21,600
For today, we'll start with why
AB testing matters for your career

27
00:01:22,020 --> 00:01:25,380
where experimentation experiments
create value, and how to choose

28
00:01:25,380 --> 00:01:26,669
the right experiment design.

29
00:01:26,999 --> 00:01:31,900
And we'll dive into some basic
statistical concepts and understand

30
00:01:31,900 --> 00:01:35,810
some of the techniques that you can
use to speed up your experimentation

31
00:01:35,810 --> 00:01:40,640
and then pivot to talking about how can
you build experimentation portfolio.

32
00:01:40,820 --> 00:01:44,410
What are some of the tips for
interview success strategies And, we

33
00:01:44,410 --> 00:01:46,060
will end this with an action plan.

34
00:01:46,914 --> 00:01:51,285
Now let's start the session by
talking about why expertise in

35
00:01:51,285 --> 00:01:52,425
the experimentation matters.

36
00:01:52,425 --> 00:01:54,715
Now this is a high demand skill.

37
00:01:55,085 --> 00:01:57,455
It's sought, highly sought after.

38
00:01:57,725 --> 00:02:00,755
It's a combination of data science,
experiment design, and business

39
00:02:00,755 --> 00:02:02,435
strategy in a measurable way.

40
00:02:02,665 --> 00:02:06,664
Companies across all the industries
are desperately seeking for

41
00:02:06,664 --> 00:02:10,144
professionals who can design,
implement, and interpret experiments

42
00:02:10,144 --> 00:02:12,364
that drive real business outcomes.

43
00:02:12,704 --> 00:02:17,655
And additionally, with advancements
in the large language models LMS are

44
00:02:17,655 --> 00:02:19,905
being used in every part of the life.

45
00:02:20,105 --> 00:02:23,225
It becomes crucial to validate the
results through experimentation.

46
00:02:23,555 --> 00:02:27,845
Experimentation helps evaluate
prompts effectiveness, measure

47
00:02:27,845 --> 00:02:31,445
change in the response quality,
detect biases, understand the

48
00:02:31,445 --> 00:02:33,155
overall model behavior at scale.

49
00:02:33,725 --> 00:02:35,805
Professionals who have
this are indispensable.

50
00:02:36,790 --> 00:02:41,020
And the value of understanding core
principles of AB testing benefits

51
00:02:41,020 --> 00:02:43,270
everyone, not just data analyst.

52
00:02:43,420 --> 00:02:46,300
Engineers can build smarter
experiment ready systems.

53
00:02:46,390 --> 00:02:51,910
Product managers can make evidence ba
based features and roadmap decisions.

54
00:02:52,330 --> 00:02:56,100
It also has strategic impact through
cross functional collaboration

55
00:02:56,340 --> 00:02:57,390
experimentation, bridges.

56
00:02:58,165 --> 00:03:02,665
Data engineering decision design and
product teams helping you communicate

57
00:03:02,665 --> 00:03:06,835
insights effectively and influencing
decision making across the organization.

58
00:03:07,225 --> 00:03:11,035
The skill makes you indispensable
as the translator between technical

59
00:03:11,035 --> 00:03:12,120
complexity and the business value.

60
00:03:12,460 --> 00:03:12,490
Okay.

61
00:03:13,360 --> 00:03:16,480
Now let's see where the
experiment creates value.

62
00:03:16,930 --> 00:03:20,020
The answer is every department
in the modern organization can

63
00:03:20,020 --> 00:03:23,200
leverage experimentation to
make data-driven decisions.

64
00:03:23,480 --> 00:03:25,790
You can see some of the
examples here on the slide.

65
00:03:26,060 --> 00:03:30,420
These are only a few examples, but
the key here is understanding which

66
00:03:30,420 --> 00:03:35,310
experiment approach work best for
each use case and business context.

67
00:03:36,000 --> 00:03:38,310
And now how do we choose
the right experiment design?

68
00:03:38,670 --> 00:03:39,940
And let's look at what all.

69
00:03:40,355 --> 00:03:42,485
Experiment designs are
available right now.

70
00:03:42,905 --> 00:03:43,505
The start.

71
00:03:43,695 --> 00:03:46,455
The first one is AB
testing, which is a classic.

72
00:03:46,765 --> 00:03:52,015
This compares variance simultaneously
grade for feature releases and UI changes.

73
00:03:52,395 --> 00:03:56,905
And the multivariate and factorial
is used to test multiple elements

74
00:03:56,935 --> 00:03:58,584
and learn interaction effects.

75
00:03:58,975 --> 00:04:00,535
Holdout studies are used.

76
00:04:00,764 --> 00:04:05,424
To measure long term and network
effects that ac that accrue over

77
00:04:05,424 --> 00:04:08,064
weeks, months, and sometimes a year.

78
00:04:08,604 --> 00:04:12,174
Business constraints should pick
the design not the other way around.

79
00:04:12,654 --> 00:04:16,044
When the traffic patterns and the
platform complicate things, switch

80
00:04:16,044 --> 00:04:22,499
designs switchback experiments are used
to rotate by the time so that the same

81
00:04:22,499 --> 00:04:24,959
unit cycles through both the variants.

82
00:04:25,294 --> 00:04:28,174
Idle for marketplaces
and two-sided platforms.

83
00:04:28,774 --> 00:04:32,374
Geo experiments randomized
by the region when user level

84
00:04:32,374 --> 00:04:34,654
randomizations risk spillovers.

85
00:04:34,894 --> 00:04:37,189
Useful for location-based
features and marketing.

86
00:04:37,689 --> 00:04:43,339
If true randomization is not possible, use
credible alternatives such as difference

87
00:04:43,339 --> 00:04:47,879
indifference interrupted time series,
synthetic controls difference indifference

88
00:04:48,029 --> 00:04:52,199
compares before and after changes in
the treated group against a similar

89
00:04:52,199 --> 00:04:54,134
control group that didn't get the change.

90
00:04:54,854 --> 00:04:59,204
Interrupted time series looks at
the structural break, right when

91
00:04:59,204 --> 00:05:03,104
the in intervention happened,
if the level or the slope jumps

92
00:05:03,104 --> 00:05:04,934
at that point and nowhere else.

93
00:05:04,934 --> 00:05:07,004
That's the signal synthetic control.

94
00:05:07,244 --> 00:05:12,054
When you change something in one
big unit, say state or city build

95
00:05:12,054 --> 00:05:15,714
a weighted virtual control from
the other units that didn't change.

96
00:05:16,014 --> 00:05:18,084
So the pre-print matches yours.

97
00:05:18,474 --> 00:05:20,094
Expert judgment matters.

98
00:05:20,334 --> 00:05:22,614
Choose designs based on constraint.

99
00:05:22,769 --> 00:05:27,209
Technical capability and interventions
nature, know when to deviate

100
00:05:27,209 --> 00:05:28,649
from the pure randomization.

101
00:05:29,149 --> 00:05:34,070
Okay, now let's jump and take a
look at the statistical concepts.

102
00:05:34,470 --> 00:05:36,120
I wanna take a different direction here.

103
00:05:36,740 --> 00:05:39,830
In talking about basic statistical
concepts, there are a lot of excellent

104
00:05:39,830 --> 00:05:44,930
resources online that can teach you
about what exactly this concept is.

105
00:05:45,170 --> 00:05:46,850
But today I wanna spend some time.

106
00:05:47,200 --> 00:05:51,159
Talking about tying these concepts
to the business and why it's

107
00:05:51,159 --> 00:05:55,119
important for business, how
can you think in those lines?

108
00:05:55,569 --> 00:05:57,249
First hypothesis testing.

109
00:05:57,669 --> 00:05:59,049
This drives clarity.

110
00:05:59,379 --> 00:06:03,159
Knowing how to form good hypothesis
teaches structure, thinking.

111
00:06:03,249 --> 00:06:07,539
It's not about is it better,
but what outcomes and why.

112
00:06:07,939 --> 00:06:13,039
The mindset helps align experiments with
business strategy and ensures test has

113
00:06:13,039 --> 00:06:15,859
clear success criteria before the launch.

114
00:06:16,504 --> 00:06:18,844
Second one is the
confidence and uncertainty.

115
00:06:19,234 --> 00:06:20,254
This builds trust.

116
00:06:20,434 --> 00:06:24,934
Communicating uncertainty transparently
builds stakeholder confidence.

117
00:06:25,054 --> 00:06:26,644
Leaders don't expect perfection.

118
00:06:27,004 --> 00:06:29,254
They expect honest ranges and risk.

119
00:06:29,794 --> 00:06:33,804
A this skill separates strategic
thinkers from report generators,

120
00:06:34,194 --> 00:06:35,034
effect size and power.

121
00:06:35,514 --> 00:06:37,434
This helps you prioritize what matters.

122
00:06:37,734 --> 00:06:41,454
Understanding these concepts help
you focus on impactful changes,

123
00:06:41,454 --> 00:06:43,014
not statistically trivial ones.

124
00:06:43,584 --> 00:06:47,634
The multiple testing disciplines
today, we run hundreds and thousands

125
00:06:47,634 --> 00:06:51,684
of experiments every month with number
of experiments and variance we test.

126
00:06:51,894 --> 00:06:54,474
There comes a need to control
the false positive rate.

127
00:06:54,874 --> 00:06:57,994
This protects business from
false wins and bad rollouts.

128
00:06:58,484 --> 00:06:59,984
The last, not, but not the least.

129
00:07:00,034 --> 00:07:02,434
The fifth one is sequential and thinking.

130
00:07:02,954 --> 00:07:05,774
In today's world, we see a need
for faster experimentation.

131
00:07:06,274 --> 00:07:10,264
To improve velocity of experimentation
and get continuous learnings, we

132
00:07:10,264 --> 00:07:14,374
need modern techniques like SQL
Ambition to support adaptive learning.

133
00:07:14,954 --> 00:07:17,924
We've look, now that we have looked
at sequential ambition, which

134
00:07:17,924 --> 00:07:22,064
drives experimentation velocity,
let's also look at other techniques

135
00:07:22,564 --> 00:07:24,664
in traditional experiment setup.

136
00:07:24,814 --> 00:07:27,634
We have to wait for the larger samples.

137
00:07:27,964 --> 00:07:31,504
This delay is experiment time, insight,
and thereby product development.

138
00:07:31,894 --> 00:07:35,744
If you look at sample size formula
here the sample size is directly

139
00:07:35,744 --> 00:07:37,244
proportional to the variance.

140
00:07:37,544 --> 00:07:41,314
Thereby if you reduce the variance
by half, you'll reduce the sample

141
00:07:41,314 --> 00:07:43,654
size by half by implementing.

142
00:07:44,144 --> 00:07:47,834
Variance reduction techniques,
you can achieve statistical

143
00:07:47,834 --> 00:07:50,294
significance faster with fewer users.

144
00:07:50,564 --> 00:07:54,944
This translates to quicker decision
making, accelerated product iteration

145
00:07:54,944 --> 00:07:59,114
and more experiments run overall
driving rapid innovation and growth.

146
00:07:59,635 --> 00:08:03,174
Now that we have looked at the concept
of the variance reduction, let's look

147
00:08:03,174 --> 00:08:05,155
at some variance reduction techniques.

148
00:08:05,655 --> 00:08:09,195
So the first one, which is regression
adjustment with three period covariate.

149
00:08:09,195 --> 00:08:11,655
This is an umbrella for Cupid and co-op.

150
00:08:11,655 --> 00:08:15,255
Pre-post we pick one or
two strong pre-treatment

151
00:08:15,255 --> 00:08:17,534
predictors at just the outcome.

152
00:08:17,835 --> 00:08:19,395
This will help lower the variance.

153
00:08:19,675 --> 00:08:22,655
We will look at cupid in
detail in the next slide.

154
00:08:23,115 --> 00:08:24,975
Now let's go to the second
one, which is balance.

155
00:08:24,975 --> 00:08:28,735
Assignment at launch is
blocking or stratification.

156
00:08:28,955 --> 00:08:30,245
While you're randomizing.

157
00:08:30,635 --> 00:08:34,205
So treatment and controls start
equal on the stuff that matters.

158
00:08:34,705 --> 00:08:35,905
Third one is metric engineering.

159
00:08:36,500 --> 00:08:40,790
Noise enumerators and denominators
and heavy tails blow up variance

160
00:08:40,970 --> 00:08:46,210
instead of aggregating per user or
in aggregated per user cluster level

161
00:08:46,550 --> 00:08:51,690
wind rise, extreme outliers, and lock,
transform the right skew metrics.

162
00:08:52,110 --> 00:08:55,780
Cluster aware estimations
for geos or switchback tests.

163
00:08:55,840 --> 00:09:01,090
Analyze cluster, block level or
use cluster robot robust standard

164
00:09:01,090 --> 00:09:06,110
errors, exposure and eligibility
hygiene count only truly eligible

165
00:09:06,110 --> 00:09:07,610
and actually expose users.

166
00:09:07,910 --> 00:09:11,250
Freezing events definitions
prior to the experiment.

167
00:09:11,400 --> 00:09:13,800
These are some, a few
variance reduction techniques.

168
00:09:14,070 --> 00:09:15,990
Now let's look at Cupid in detail.

169
00:09:16,490 --> 00:09:20,450
Cupid is one of the vastly used
variance reduction techniques in Cupid,

170
00:09:20,690 --> 00:09:25,760
we reduce the variance by using the
pre-ex experiment data that can help

171
00:09:25,820 --> 00:09:27,740
explain variance post experiment.

172
00:09:28,130 --> 00:09:29,210
Let's look at an example.

173
00:09:29,510 --> 00:09:35,720
Say we want to run a test to see if people
run slower with weights attached to them.

174
00:09:36,255 --> 00:09:37,005
The experiment.

175
00:09:37,005 --> 00:09:40,245
Mile time is a metric we get
when we run the experiment.

176
00:09:40,605 --> 00:09:44,895
And corresponding row will tell you if
the weight were, the weights were added.

177
00:09:45,225 --> 00:09:48,525
By looking at the data on the
right, you can already see that the

178
00:09:48,525 --> 00:09:53,365
experiment, mile time is influenced
by how fast the runners already were

179
00:09:53,885 --> 00:09:56,085
which is a baseline baseline my time.

180
00:09:56,585 --> 00:10:00,635
In this case, we can leverage the
average baseline mile time to help

181
00:10:00,635 --> 00:10:05,075
explain the difference in the variance
and use the change column, which is

182
00:10:05,075 --> 00:10:08,465
a difference between the baseline
mile time and experiment mile time to

183
00:10:08,465 --> 00:10:10,475
understand the impact of adding weights.

184
00:10:10,905 --> 00:10:15,525
What we are doing here is using pre-ex
experiment data to reduce the variance.

185
00:10:15,785 --> 00:10:16,925
That was explainable.

186
00:10:17,345 --> 00:10:21,075
Some of the best practices are
using the variable that has high

187
00:10:21,075 --> 00:10:23,655
correlation to the variable of interest.

188
00:10:23,905 --> 00:10:27,995
When we are applying cupid there is no
need to stick with just one variable

189
00:10:28,385 --> 00:10:29,585
from the pre-ex experiment period.

190
00:10:29,585 --> 00:10:32,495
We can use multiple variables if
you believe that could reduce the

191
00:10:32,495 --> 00:10:36,755
variance, effectively use baselines
that reflect the normal behavior.

192
00:10:37,110 --> 00:10:43,380
Make sure the data only is from the prior
to the experiment period, not from the

193
00:10:43,380 --> 00:10:45,450
period where the experiment is running.

194
00:10:45,760 --> 00:10:48,670
You can handle missing data
by imputing the values.

195
00:10:49,450 --> 00:10:51,310
A call out for people who are interested.

196
00:10:51,700 --> 00:10:52,240
There are.

197
00:10:52,585 --> 00:10:57,985
Some advancements, toin methodology called
qac, where in place of using regression

198
00:10:57,985 --> 00:11:02,425
model and single or multiple covariates
from the pre-ex experiment period.

199
00:11:02,895 --> 00:11:07,065
QAC uses machine learning models
to predict the baseline metrics

200
00:11:07,215 --> 00:11:10,335
by leveraging multiple variables
from the pre-ex experiment period.

201
00:11:10,695 --> 00:11:14,625
For those interested, I have
attached a link to this at

202
00:11:14,625 --> 00:11:15,795
the end of the presentation.

203
00:11:15,795 --> 00:11:16,850
Please feel free to take a look.

204
00:11:17,350 --> 00:11:21,640
Now in this new era, we are,
it's also essential to master the

205
00:11:21,640 --> 00:11:25,650
experimentation with experimentation
on LMS and prompt engineering.

206
00:11:26,190 --> 00:11:29,220
So let's take a look at a couple
of use cases where we can leverage

207
00:11:29,220 --> 00:11:34,990
experimentation to optimize large language
models and optimize the prompts that we

208
00:11:34,990 --> 00:11:36,940
are giving the la large language models.

209
00:11:37,690 --> 00:11:42,170
So the first one is prompt optimization
systematically comparing templates

210
00:11:42,360 --> 00:11:45,900
few short examples and system
instructions to achieve superior

211
00:11:45,900 --> 00:11:47,790
outcome, quality, and relevance.

212
00:11:47,970 --> 00:11:51,700
The second use case for
experimentation is model benchmarking.

213
00:11:52,110 --> 00:11:57,090
Evaluating performance across different
LLM architectures or fine tuned

214
00:11:57,090 --> 00:11:59,340
versions of some effective models.

215
00:11:59,880 --> 00:12:02,130
And third one is RA pipeline enhancements.

216
00:12:02,280 --> 00:12:06,280
Optimizing RA by testing
retrieval strategies, chunking

217
00:12:06,280 --> 00:12:08,390
methods, and ranking algorithms.

218
00:12:09,110 --> 00:12:11,390
Fourth one is personalization
and contextualization.

219
00:12:11,630 --> 00:12:15,860
Assessing how dynamic content
windows and user specific data define

220
00:12:15,860 --> 00:12:17,540
models and boost user engagement.

221
00:12:18,095 --> 00:12:22,835
The last one is proactively identifying
and mitigating harmful outputs,

222
00:12:22,835 --> 00:12:26,135
biases and hallucinations through
comprehensive and systematic testing.

223
00:12:26,375 --> 00:12:29,255
So there are a lot of use cases,
even within large language

224
00:12:29,255 --> 00:12:30,995
models and prompt optimization.

225
00:12:31,375 --> 00:12:34,425
And thinking about which
kind of experimentation

226
00:12:34,425 --> 00:12:35,175
methodologies can you apply?

227
00:12:36,175 --> 00:12:40,835
You can leverage normal AB testing,
multivariate testing, or contextual

228
00:12:40,835 --> 00:12:44,635
bandwidths, depending upon the
requirement and the evaluation that you

229
00:12:44,635 --> 00:12:49,705
wanna perform for offline evaluation,
you can use automated frameworks.

230
00:12:49,855 --> 00:12:55,255
Syn synthetic data can be leveraged
and we can use the LLM as a judge

231
00:12:55,255 --> 00:12:59,595
method to to for the faster iterations.

232
00:12:59,645 --> 00:12:59,675
Okay.

233
00:13:00,215 --> 00:13:04,735
Now that we have an idea of what
experimentation is, basics of the

234
00:13:04,735 --> 00:13:08,575
experimentation and how to improve the
speed of the experimentation, let's

235
00:13:08,575 --> 00:13:09,985
look at some of the common pitfalls.

236
00:13:10,405 --> 00:13:13,525
If it seems too good to
be true, it probably is.

237
00:13:13,795 --> 00:13:17,335
Whenever you find results that
are extreme, it's always good to

238
00:13:17,335 --> 00:13:19,075
check against common pitfalls.

239
00:13:19,465 --> 00:13:22,755
Now we can think of common
footfalls in four broad categories.

240
00:13:23,125 --> 00:13:25,495
The first one is technical
implementation issues.

241
00:13:25,735 --> 00:13:28,525
That is sample ratio,
mismatch logging gaps.

242
00:13:28,885 --> 00:13:31,525
When a unit of randomization
is different from the unit of

243
00:13:31,525 --> 00:13:33,805
analysis, it inflates variance.

244
00:13:34,255 --> 00:13:39,685
The second one is experiment, design,
floss interference and contamination.

245
00:13:39,865 --> 00:13:43,345
Because the units in the control
and treatment have impact on one

246
00:13:43,345 --> 00:13:48,185
other statistical analysis errors,
if you have a need to peak at just

247
00:13:48,185 --> 00:13:51,875
the false positive rate so that
there is no room for p hacking.

248
00:13:52,175 --> 00:13:55,085
Fourth one is contextual challenges
and some additional challenges like

249
00:13:55,325 --> 00:13:57,855
metric grift, seasonality et cetera.

250
00:13:58,845 --> 00:13:59,885
Now we have covered, oh.

251
00:14:00,385 --> 00:14:02,035
Common pitfalls and e testing.

252
00:14:02,095 --> 00:14:05,775
Let's look at how to use this
to accelerate your career.

253
00:14:06,465 --> 00:14:10,125
Understanding and partic practicing
these concepts will enhance your

254
00:14:10,425 --> 00:14:14,535
analytical maturity, your shift,
your mindset from reactive to

255
00:14:14,535 --> 00:14:16,215
proactive experimentation strategy.

256
00:14:16,815 --> 00:14:18,375
This will also help you challenge.

257
00:14:18,765 --> 00:14:22,365
Opinions of leaders with evidence
and guide strategic decisions,

258
00:14:22,665 --> 00:14:24,075
you will become a person.

259
00:14:24,265 --> 00:14:27,505
Bridging the gap between
cross-functional teams, translating

260
00:14:27,505 --> 00:14:28,825
stats into business impact.

261
00:14:29,245 --> 00:14:33,475
All this will differentiate you in
the market and make you invaluable.

262
00:14:33,945 --> 00:14:36,645
Now let's look at how to build
the experimentation portfolio.

263
00:14:37,065 --> 00:14:41,425
If you're just starting out there
are three key steps to building

264
00:14:41,425 --> 00:14:42,685
experimentation portfolio.

265
00:14:43,425 --> 00:14:45,765
Working and documenting
realistic scenarios.

266
00:14:46,215 --> 00:14:51,045
Document the process, showing problem
identification, hypothesis development,

267
00:14:51,225 --> 00:14:55,305
experimental design choices, statistical
methods with the CRE business rational.

268
00:14:55,885 --> 00:14:59,925
Start by contributing to o open
source contribute to experimentation,

269
00:14:59,930 --> 00:15:04,095
frameworks and statistical libraries
like a stats model, PMC, cetera.

270
00:15:04,780 --> 00:15:06,350
Show business impact.

271
00:15:06,380 --> 00:15:08,330
Think about end-to-end demonstration.

272
00:15:08,750 --> 00:15:11,720
Develop a mindset to I trade
an idea instead of one and

273
00:15:11,720 --> 00:15:13,070
done kind of experiments.

274
00:15:13,580 --> 00:15:17,280
I also wanna share some success
strategies for interviews.

275
00:15:17,640 --> 00:15:20,550
Interview Success in the
experimentation field requires

276
00:15:20,820 --> 00:15:21,930
not only technical expertise.

277
00:15:22,490 --> 00:15:26,510
But also mastery of concepts
and being able to explain it in

278
00:15:26,510 --> 00:15:27,980
simple terms to stakeholders.

279
00:15:28,350 --> 00:15:32,040
Prepare specific examples where
your experimentation work drove

280
00:15:32,040 --> 00:15:33,450
measurable business outcomes.

281
00:15:33,960 --> 00:15:36,810
End-to-end experimentation
knowledge on how experimentation

282
00:15:36,810 --> 00:15:40,650
fits into larger ecosystem and
how to run experiments at scale.

283
00:15:41,545 --> 00:15:45,995
A combination of these three would
help you be successful in interviews.

284
00:15:46,445 --> 00:15:50,325
For anybody who is starting out you
must be curious on how the trajectory

285
00:15:50,595 --> 00:15:54,725
of an IC looks in their science field
specializing in experimentation.

286
00:15:55,145 --> 00:15:56,375
So here is an outlook.

287
00:15:56,375 --> 00:16:00,040
This is a broad, I broad view of
how the TRA trajectory would look.

288
00:16:00,450 --> 00:16:05,410
An entry level candidate would be
expected to have rock solid AB testing

289
00:16:05,410 --> 00:16:09,340
fundamentals, clean hypothesis,
reproducible analysis, and clear writing.

290
00:16:10,150 --> 00:16:13,830
When you think about the mid-level,
it's, the person in this role will

291
00:16:13,830 --> 00:16:18,030
be leading multiple experiments,
mentoring analysts diving into

292
00:16:18,030 --> 00:16:20,620
sequential and standardizing guardrails.

293
00:16:21,040 --> 00:16:26,200
A senior would set experimentation
strategy partner with engineering to.

294
00:16:26,575 --> 00:16:30,805
Drive the platform experimentation
platform drive cross function.

295
00:16:30,805 --> 00:16:36,245
Cross org decisions with quantified impact
principal or staff would shape the system.

296
00:16:36,615 --> 00:16:40,945
Pla develop roadmaps, contribute to
open sources, conference talks teach

297
00:16:41,155 --> 00:16:43,165
the organization on how to learn faster.

298
00:16:43,665 --> 00:16:47,545
So this is a general idea of
how the trajectory would look.

299
00:16:47,935 --> 00:16:51,845
Now to summarize everything that we
have looked at till now there are

300
00:16:51,875 --> 00:16:56,285
three key takeaways and the first one
is develop deep technical expertise.

301
00:16:56,885 --> 00:16:59,795
The second one is pair it
with strong business acumen.

302
00:17:00,275 --> 00:17:04,565
Last but not the least, is master
end-to-end experimentation ecosystem.

303
00:17:05,045 --> 00:17:08,165
Together, these three form
foundation of successful career.

304
00:17:08,665 --> 00:17:10,725
I will end my talk with the action plan.

305
00:17:10,825 --> 00:17:15,025
I would highly encourage for the people
exploring data science carriers to

306
00:17:15,025 --> 00:17:19,375
specialize in experimentation to start
today, engage with community, share the

307
00:17:19,375 --> 00:17:21,445
learnings, and learn from the community.

308
00:17:21,715 --> 00:17:24,715
Stay current with emerging
trends in experimentation.

309
00:17:24,955 --> 00:17:28,675
The experimentation field evolves
rapidly with new statistical methods.

310
00:17:28,925 --> 00:17:31,775
Staying current would
differentiate you from others.

311
00:17:32,225 --> 00:17:35,085
And with that I'll end the presentation.

312
00:17:35,425 --> 00:17:36,355
Thanks for being here.

313
00:17:36,445 --> 00:17:37,375
Thanks for taking time.

314
00:17:37,705 --> 00:17:41,715
Please reach out to me on LinkedIn if you
have any questions or simply wanna chat

315
00:17:41,715 --> 00:17:45,955
about experimentation or career, or if
you wanna, I'll talk about anything else.

316
00:17:45,955 --> 00:17:46,260
I'll be happy to.

317
00:17:46,930 --> 00:17:47,320
Connect.

318
00:17:47,460 --> 00:17:48,150
Thanks for the time.

319
00:17:48,150 --> 00:17:48,570
Thank.

320
00:17:48,630 --> 00:17:49,085
Thanks everyone.

