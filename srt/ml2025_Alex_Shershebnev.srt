1
00:00:00,750 --> 00:00:01,530
Hello everyone.

2
00:00:01,599 --> 00:00:02,500
My name is Alex.

3
00:00:02,559 --> 00:00:05,080
I'm head of Ops and DevOps at Z Coder.

4
00:00:05,230 --> 00:00:09,870
I also double l de and in general, what I
like to call they have asked me anything.

5
00:00:10,200 --> 00:00:12,360
It's a startup, so you
have to wear many hats.

6
00:00:12,910 --> 00:00:16,990
Today I will be talking with you about
AI coding agents how you can code

7
00:00:16,990 --> 00:00:22,180
them, how you can use them, how you
can leverage them to make your everyday

8
00:00:22,180 --> 00:00:25,840
life easier and be more productive Now.

9
00:00:26,695 --> 00:00:31,225
Recently you might have come
across headlines like this where

10
00:00:31,315 --> 00:00:35,305
in this case, mark Zuckerberg said,
mentioned in his interview that

11
00:00:35,335 --> 00:00:37,135
AI will soon replace developers.

12
00:00:37,195 --> 00:00:42,215
And in this particular case, he even
went as far as saying that mid-level

13
00:00:42,215 --> 00:00:44,245
engineers will be replaced pretty soon.

14
00:00:45,085 --> 00:00:48,265
Now there are two main sort of sources.

15
00:00:49,045 --> 00:00:49,975
For those headlines.

16
00:00:50,055 --> 00:00:51,975
First of all, of course, new models.

17
00:00:52,095 --> 00:00:56,565
New AI or LLM models are
coming up being released.

18
00:00:56,665 --> 00:01:00,725
For example here the recent release
from Google of Gemini 2.5 Pro,

19
00:01:01,235 --> 00:01:05,485
and they of course show that new
they are new model beats all the

20
00:01:05,485 --> 00:01:09,005
previous models on the benchmarks
which is always the case, right?

21
00:01:09,575 --> 00:01:13,325
Now for us for coordin agents in
particular, we are mostly interested

22
00:01:13,335 --> 00:01:17,685
in the three code related benchmarks,
which I highlighted here in red.

23
00:01:18,185 --> 00:01:22,565
Now the problem with benchmarks is
while it is good to see that models

24
00:01:22,595 --> 00:01:26,985
are becoming better on them it's a good
way to compare models with each other.

25
00:01:27,535 --> 00:01:30,145
It's all those benchmarks are not always.

26
00:01:31,280 --> 00:01:33,830
Transferable one-to-one to the real world.

27
00:01:34,160 --> 00:01:38,910
What I mean by that is for example, if
we look at either gl the main idea behind

28
00:01:38,910 --> 00:01:44,760
this data set is that the LLM or AI is
presented with a list of tasks and it

29
00:01:44,760 --> 00:01:46,320
essentially needs to create a function.

30
00:01:46,320 --> 00:01:50,420
It create needs to create a class or
method that would fulfill that task.

31
00:01:50,910 --> 00:01:53,810
So essentially it's one or
single file modification.

32
00:01:54,635 --> 00:01:59,205
However reality of software
development is not that simple, right?

33
00:01:59,205 --> 00:02:03,015
So usually you need to modify at
least multiple files inside the

34
00:02:03,015 --> 00:02:07,695
repository, or sometimes you might
even need to modify files across

35
00:02:07,695 --> 00:02:09,435
multiple repositories at the same time.

36
00:02:10,335 --> 00:02:15,075
So basically, even though there are
improvements in the quality of AI of LLM.

37
00:02:15,885 --> 00:02:20,075
They're not always transferable
one-to-one on in the real life world.

38
00:02:20,525 --> 00:02:23,935
So you might not see as big
of an improvement as you

39
00:02:23,935 --> 00:02:25,075
would see on the benchmarks.

40
00:02:25,895 --> 00:02:27,975
So that's one source of those headlines.

41
00:02:27,975 --> 00:02:31,305
And the second one is AI
agents, which is the main topic

42
00:02:31,305 --> 00:02:33,315
of the day of today's stock.

43
00:02:34,200 --> 00:02:37,800
So basically, we'll, we will
first cover what is AI agent.

44
00:02:37,880 --> 00:02:42,230
Then we'll go through a live
coding session where we'll see

45
00:02:42,230 --> 00:02:46,519
how we can, how you can create the
coding agent on your own right.

46
00:02:46,519 --> 00:02:49,549
And you will see how they can
also interact with each other

47
00:02:49,619 --> 00:02:51,069
for multi agent collaboration.

48
00:02:51,429 --> 00:02:56,019
And then briefly talk about what is
next for the developers, what all those.

49
00:02:57,100 --> 00:02:59,970
New improvements, what all
those new changes mean for the

50
00:02:59,970 --> 00:03:01,410
future of software development.

51
00:03:03,239 --> 00:03:08,589
So yeah, basically by the end of the talk,
we will potentially build an ai, which

52
00:03:08,640 --> 00:03:10,739
might probably replace you or maybe not.

53
00:03:10,739 --> 00:03:11,130
We'll see.

54
00:03:12,354 --> 00:03:16,274
So first things first let's
define what is AI agent.

55
00:03:16,604 --> 00:03:21,884
Now, AI agent can be defined as a software
that performs tasks on behalf of a user.

56
00:03:22,454 --> 00:03:26,004
And you might say here that
any software performs tasks

57
00:03:26,004 --> 00:03:27,384
on behalf of the user, right?

58
00:03:27,684 --> 00:03:30,564
Especially if we're talking about
current generation of coding systems.

59
00:03:31,284 --> 00:03:35,004
And they essentially perform tasks
of code generation on your behalf.

60
00:03:35,304 --> 00:03:37,904
They perform tasks of documentation
generation on your behalf.

61
00:03:38,309 --> 00:03:42,739
And, you can just essentially tap, tap
tab get a thousand slice of code in a

62
00:03:42,739 --> 00:03:47,409
couple minutes, and then spend some time
on the bag in that the bag in that code.

63
00:03:48,549 --> 00:03:53,929
Now the main difference between AI
agents and classic software is that AI

64
00:03:53,929 --> 00:03:57,369
agents follow multiple design patterns
which you can see here on the side.

65
00:03:57,729 --> 00:04:00,519
So first of all they have
what's called tool use.

66
00:04:00,609 --> 00:04:04,869
So they can basically, can have
access to the tools, to the

67
00:04:04,869 --> 00:04:06,339
list of tools at a disposal.

68
00:04:06,369 --> 00:04:08,889
And those tools could
be pretty much anything.

69
00:04:09,339 --> 00:04:13,839
It could be doing the web search, it
could be accessing some local file system.

70
00:04:13,889 --> 00:04:17,289
It could be accessing
restful APIs and so on.

71
00:04:17,379 --> 00:04:21,779
So basically any tool LLM can
use to gather information to

72
00:04:21,809 --> 00:04:23,009
perform actions and so on.

73
00:04:23,069 --> 00:04:23,669
It can use it.

74
00:04:24,494 --> 00:04:27,734
Then of course, AI agents
can also do some planning.

75
00:04:27,734 --> 00:04:31,504
So they don't just blindly perform
the task, perform code generation.

76
00:04:31,804 --> 00:04:36,945
They can first come up with a plan on how
to tackle these specific task at hand.

77
00:04:37,515 --> 00:04:40,575
And they then will follow that plan.

78
00:04:41,085 --> 00:04:45,254
They can also reflect on their own
work, on their own planning step

79
00:04:45,284 --> 00:04:51,444
on their, output or they can also
reflect on work of other agents.

80
00:04:51,474 --> 00:04:54,364
And this is where we come to
this fourth design pattern, which

81
00:04:54,394 --> 00:04:56,014
is multi-agent collaboration.

82
00:04:56,494 --> 00:05:00,585
So basically you can have multiple agents
working together towards the same goal.

83
00:05:00,644 --> 00:05:05,744
And those could be either working
together as in colleagues where they

84
00:05:05,794 --> 00:05:09,604
for example, one agent, performs half
of the task, and then the other agent

85
00:05:09,604 --> 00:05:11,014
performs the second half of the task.

86
00:05:11,464 --> 00:05:13,144
Or they can also critique each other.

87
00:05:13,204 --> 00:05:17,404
So for example, you could have one
agent, which critiques the work of the

88
00:05:17,404 --> 00:05:22,294
second agent, and then the second agent
iterates on this critique and so on.

89
00:05:23,069 --> 00:05:28,179
But basically yeah, those patterns are
what differentiates AI agents from the

90
00:05:28,179 --> 00:05:30,039
typical or from the classical software.

91
00:05:30,549 --> 00:05:34,749
And you can think about AI agents like
a, I guess a Roomba vacuum cleaner.

92
00:05:35,150 --> 00:05:40,340
The software itself on the vacuum cleaner
is an AI agent, however, to perform.

93
00:05:40,440 --> 00:05:43,260
To perform the task of
clean the house, right?

94
00:05:43,260 --> 00:05:46,170
It needs also multi some
things on top of that.

95
00:05:46,710 --> 00:05:48,180
So just software is not enough.

96
00:05:48,280 --> 00:05:52,440
The vacuum cleaners, they also have
tools, so that could be brushes that

97
00:05:52,440 --> 00:05:54,750
could be wheels to move around and so on.

98
00:05:55,080 --> 00:05:59,070
They can also do playing and for
some reason charge GPT thinks that

99
00:05:59,130 --> 00:06:03,219
robot vacuum cleaners are moving
this weirdly shaped pattern.

100
00:06:04,030 --> 00:06:09,989
But it is AI being a AI, there is no
steel yet multi agent collaboration unless

101
00:06:09,989 --> 00:06:12,359
you count these for the vacuum cleaners.

102
00:06:12,759 --> 00:06:16,029
But maybe in the future they will be
able to also talk with each other.

103
00:06:16,059 --> 00:06:19,119
They will be able to talk with the
other home appliances and so on.

104
00:06:20,019 --> 00:06:22,270
Yeah, basically now.

105
00:06:23,364 --> 00:06:24,684
Why is this important?

106
00:06:24,784 --> 00:06:31,324
To answer that question, let's first
talk about what we as developers spend

107
00:06:31,384 --> 00:06:33,484
our time on during the work hours.

108
00:06:34,114 --> 00:06:36,454
And I will give you a few
seconds to think about this.

109
00:06:36,504 --> 00:06:42,784
Spoiler alert, it's not drinking
coffee in reality, and this study was

110
00:06:42,784 --> 00:06:46,559
done actually 10 years ago, however,
I don't think much has changed.

111
00:06:47,329 --> 00:06:52,619
Since then now in reality 70% of the
time developers spend on understanding

112
00:06:53,069 --> 00:06:55,589
that could be understanding
the code base, understanding

113
00:06:55,589 --> 00:06:57,299
the requirements understanding.

114
00:06:57,629 --> 00:06:58,379
Tasks and so on.

115
00:06:58,919 --> 00:07:03,059
So basically most of the time developers
are not spending on writing the code.

116
00:07:03,159 --> 00:07:05,079
They are spending on understanding.

117
00:07:06,049 --> 00:07:09,679
Now if we juxtapose this with the
adjunct design patterns, which we

118
00:07:09,679 --> 00:07:12,829
just discussed, we will see that,
for example, for the tool use.

119
00:07:13,199 --> 00:07:14,679
We of course, have editing.

120
00:07:14,739 --> 00:07:16,689
We need to use tools to edit the code.

121
00:07:16,749 --> 00:07:21,509
We need to use tools when we are outside
of ID and on Googling something and so on.

122
00:07:22,079 --> 00:07:24,519
And of course for UI interactions,
we also need to use tools.

123
00:07:25,979 --> 00:07:29,999
Then of course for planning we need
to understand the task at hand.

124
00:07:30,299 --> 00:07:31,649
We need to understand the requirements.

125
00:07:31,699 --> 00:07:35,464
Because otherwise it's hard to
do planning of the work, right?

126
00:07:35,955 --> 00:07:36,885
There is also reflection.

127
00:07:36,885 --> 00:07:41,695
Of course, we can, we don't just blindly.

128
00:07:42,175 --> 00:07:43,165
Follow the requirements.

129
00:07:43,200 --> 00:07:45,190
Don't just blindly follow the task.

130
00:07:45,250 --> 00:07:51,240
I hope we also can think about
different ways, solve the task.

131
00:07:51,240 --> 00:07:53,875
We can think about different
ways to tackle the problem.

132
00:07:55,060 --> 00:07:55,570
And so on.

133
00:07:55,630 --> 00:07:58,690
And of course we don't
usually work in a vacuum.

134
00:07:59,050 --> 00:08:03,130
We have colleagues with whom we can
work together, we can collaborate.

135
00:08:03,190 --> 00:08:06,370
And this is where basically
multi collaboration comes in.

136
00:08:06,670 --> 00:08:11,350
And of course, for that follow that
you'll need to have a good understanding.

137
00:08:11,840 --> 00:08:14,310
You probably also need to
navigate the code base.

138
00:08:14,310 --> 00:08:17,010
You need to spend something
outside of ID in Slack or whatever.

139
00:08:17,775 --> 00:08:22,505
But basically all of the design print
principles can be directly juxtaposed

140
00:08:22,535 --> 00:08:27,065
with what developers do in their free,
or, sorry, not free, but of course

141
00:08:27,145 --> 00:08:29,465
what they do in their work time.

142
00:08:31,055 --> 00:08:36,375
Now, with that let me switch the sides
and let's finally do some coding.

143
00:08:37,195 --> 00:08:40,315
All of the code, which I will
be showing today, is available

144
00:08:40,315 --> 00:08:42,075
on this, repository over here.

145
00:08:42,165 --> 00:08:44,595
I done Q code or the link below.

146
00:08:45,555 --> 00:08:50,565
And the way I structure the coding session
is I will go through several stages and

147
00:08:50,835 --> 00:08:55,105
hopefully not those stages but basically
I will go through several stages.

148
00:08:55,105 --> 00:08:58,715
We'll start with a simple
baseline where we won't have

149
00:08:58,720 --> 00:09:02,105
any agenda egen patterns at all.

150
00:09:02,225 --> 00:09:07,425
And then we will slowly build on top of,
on top of the previous stages to come to

151
00:09:07,425 --> 00:09:12,295
the final step of multi-agent multi-agent
system, which will work together to,

152
00:09:12,580 --> 00:09:14,080
to fulfill the task on our behalf.

153
00:09:15,670 --> 00:09:22,975
So let me switch here to the to
the Jupiter notebook I have here.

154
00:09:23,215 --> 00:09:24,925
Let's see.

155
00:09:26,680 --> 00:09:27,340
Alright,

156
00:09:29,920 --> 00:09:32,140
so let's start with our baseline, right?

157
00:09:32,440 --> 00:09:37,660
And if you used AI in any capacity,
if you used any LLM, like open AI or

158
00:09:37,660 --> 00:09:42,230
cloudy you probably have experienced
something similar to what we will

159
00:09:42,230 --> 00:09:43,610
see right now in the baseline.

160
00:09:44,000 --> 00:09:49,440
But basically, and again, if you are not
familiar with Python it's not a problem.

161
00:09:49,560 --> 00:09:51,120
All of the code is pretty simple.

162
00:09:52,080 --> 00:09:52,860
Pretty simple to it.

163
00:09:52,860 --> 00:09:55,520
And, pretty sim pretty easy to understand.

164
00:09:56,030 --> 00:10:01,130
Now, over here on this baseline basically
what I do is I will be using the most

165
00:10:01,130 --> 00:10:04,340
recent model from Open ai, namely GT 4.1.

166
00:10:05,210 --> 00:10:09,530
And basically over here, I'm just
defining the code to query the model so

167
00:10:09,530 --> 00:10:15,350
that this function will send the input
from us, from user to the LLM and we

168
00:10:15,350 --> 00:10:18,160
will get the response from GPT-4 0.1.

169
00:10:19,330 --> 00:10:24,135
Now, the problem with the L LMS
is that they are leaving the,

170
00:10:24,135 --> 00:10:27,675
somewhere in the cloud and they
don't have access to real life world.

171
00:10:28,015 --> 00:10:31,635
What I mean by that is for example,
they can't give us the response time for

172
00:10:31,635 --> 00:10:34,200
Google or for any website for that matter.

173
00:10:34,570 --> 00:10:39,880
So it does try to be helpful, and
I think it probably will, yeah.

174
00:10:40,090 --> 00:10:45,860
Does give us some command to run to GI to
get the answer, unfortunately on its own.

175
00:10:45,930 --> 00:10:49,140
The LLM in this case, GPT-4
0.1, isn't able to help.

176
00:10:49,980 --> 00:10:53,120
The same goes with the access
to local local machine.

177
00:10:53,960 --> 00:10:57,230
This case in that it doesn't
have access to my local computer.

178
00:10:57,890 --> 00:11:01,380
Again, it does try to help
me with providing some batch

179
00:11:01,380 --> 00:11:04,630
commands to, to list the packages.

180
00:11:04,630 --> 00:11:09,090
Unfortunately even for those simple
tasks, it can't really help me.

181
00:11:09,180 --> 00:11:14,510
And, we are especially, we are going
to some more sophisticated tasks that

182
00:11:14,510 --> 00:11:17,210
require, access to local to local machine.

183
00:11:17,300 --> 00:11:18,980
For example, Iranian dock image.

184
00:11:19,030 --> 00:11:22,480
The LLM would fail here and
wouldn't be very helpful.

185
00:11:22,540 --> 00:11:25,190
And the same goes within
new and updated knowledge.

186
00:11:26,000 --> 00:11:31,060
Now, in this case the GPT-4 0.1
has a more UpToDate knowledge.

187
00:11:31,110 --> 00:11:35,880
If you try the same query with the
older model, like T four O, for example,

188
00:11:36,210 --> 00:11:39,780
it wouldn't know anything at all
about Python three 14 in this case.

189
00:11:40,780 --> 00:11:45,210
Because the knowledge cut off for
the model was, I think in June, 2024.

190
00:11:45,660 --> 00:11:48,240
It does have some knowledge
about Python three 14.

191
00:11:48,310 --> 00:11:51,160
And it does provide some
links for us as well.

192
00:11:51,550 --> 00:11:55,040
However still the knowledge
is not up to date, right?

193
00:11:55,040 --> 00:11:57,890
It is 2025, my 2025 right now.

194
00:11:58,370 --> 00:12:01,870
And basically the gap between them.

195
00:12:03,160 --> 00:12:08,120
Alumni knowledge and real life world
is essentially one year now and a

196
00:12:08,120 --> 00:12:10,120
lot has has happened since then.

197
00:12:10,810 --> 00:12:15,960
So yeah, basically, even though it does
try to be helpful by giving us command,

198
00:12:16,260 --> 00:12:21,760
by giving us answers, but based on its
knowledge, it's not really that helpful in

199
00:12:21,760 --> 00:12:23,830
real life world, in real life situations.

200
00:12:24,370 --> 00:12:28,890
Now let's see how we can improve on
that by introducing the tool use.

201
00:12:28,920 --> 00:12:30,570
To the LLM.

202
00:12:31,080 --> 00:12:36,480
So let's let me switch for that
for the basic to the basic agent.

203
00:12:36,600 --> 00:12:38,130
Agent over here.

204
00:12:39,360 --> 00:12:44,810
Alright, so I'm again using
the same model GT 4.1 for that.

205
00:12:44,940 --> 00:12:48,900
And what we will be using on top of
that is what is called react framework.

206
00:12:49,755 --> 00:12:53,715
React stands for reasonable effect
and basically we will be instructing

207
00:12:53,805 --> 00:12:58,095
LLM to go through the loop of
multiple stages, namely, thought,

208
00:12:58,215 --> 00:13:00,675
action, post observation, and answer.

209
00:13:01,145 --> 00:13:05,345
In the third step, the LLM would need
to think about what action it needs

210
00:13:05,345 --> 00:13:09,795
to perform to get the answer or to
get the information to give us answer.

211
00:13:10,515 --> 00:13:14,655
Then it needs to decide on
the action itself basically.

212
00:13:15,570 --> 00:13:19,450
As a response to our request, it
will need to send the actual action.

213
00:13:19,450 --> 00:13:22,780
It wants to perform with some,
along with some inputs potentially.

214
00:13:23,230 --> 00:13:29,250
Then there is a post step where basically
the action should run on behalf of LLM.

215
00:13:29,940 --> 00:13:33,780
Then during the observation
step, the output from the action

216
00:13:33,840 --> 00:13:36,520
will be sent to LLM and then.

217
00:13:37,540 --> 00:13:42,480
Based on this observation and the initial
input from the user the LLM hopefully

218
00:13:42,480 --> 00:13:44,250
will come up with a, with an answer.

219
00:13:44,880 --> 00:13:49,630
Or if that information is not
enough, it'll go to the second loop,

220
00:13:49,690 --> 00:13:54,590
to the third loop and so on until
it gets asked the answer or until

221
00:13:54,740 --> 00:13:56,810
it runs out of low penetrations.

222
00:13:57,500 --> 00:14:00,230
And this can pretty easily
be implemented through this.

223
00:14:01,415 --> 00:14:08,645
System prompt over here, and basically
I'm instructing a LLM to do, to follow

224
00:14:08,645 --> 00:14:13,265
the same the, to follow the loop of react
framework, which I just described, right?

225
00:14:13,265 --> 00:14:16,055
So you run in a loop of thought
action post observation.

226
00:14:16,910 --> 00:14:18,770
I use thought, I use action.

227
00:14:19,340 --> 00:14:23,210
And then we also provide a
few actions available for

228
00:14:23,255 --> 00:14:25,400
LLM to use or to choose from.

229
00:14:25,790 --> 00:14:27,290
In this case, those would be Ping.

230
00:14:27,830 --> 00:14:30,720
So basically that would
perform the ping command.

231
00:14:30,990 --> 00:14:36,880
On behalf of LLM, we have bh
which would allow LLM to use any,

232
00:14:36,940 --> 00:14:38,410
to execute any batch commands.

233
00:14:39,415 --> 00:14:42,925
And we will have web search
pretty basic web search which will

234
00:14:42,925 --> 00:14:45,835
allow LLM to well do web search.

235
00:14:47,045 --> 00:14:51,605
We also have some example session over
here for LLM to use as a reference.

236
00:14:52,125 --> 00:14:55,905
So for example here, the question
from the user could be how many

237
00:14:55,905 --> 00:14:58,255
islands make up Madera Ali Madera.

238
00:14:58,255 --> 00:15:01,145
So it's a sort of nice, nice
small Easter egg for that.

239
00:15:01,655 --> 00:15:05,615
And then the thought from LLM
should hopefully be that it needs

240
00:15:05,615 --> 00:15:07,695
to do a web search for the madada.

241
00:15:08,265 --> 00:15:14,005
Then it would need to perform to, to
reply with an action namely web search,

242
00:15:14,125 --> 00:15:16,355
and then the input for that action.

243
00:15:16,505 --> 00:15:18,425
In this case that could be just Madeira.

244
00:15:19,265 --> 00:15:22,255
Then during the post, the
actual web search will happen.

245
00:15:22,375 --> 00:15:24,085
And then based on the web search.

246
00:15:24,545 --> 00:15:28,115
Based on the observation from
that web search the LLM should

247
00:15:28,235 --> 00:15:29,675
hopefully come up with an answer.

248
00:15:30,005 --> 00:15:31,865
In this case that would be four islands.

249
00:15:33,555 --> 00:15:39,135
We are using the same code to query
the LLM, we'll just directly send

250
00:15:39,135 --> 00:15:43,605
the input from from us, from the
user, along with the pro, with the

251
00:15:43,605 --> 00:15:45,405
system prompt we've seen above.

252
00:15:47,040 --> 00:15:50,190
And then let's also define
our three actions, three

253
00:15:50,190 --> 00:15:51,720
commands to perform actions.

254
00:15:52,000 --> 00:15:54,100
Name the ping bash and web search.

255
00:15:55,000 --> 00:15:55,900
Let's test them out.

256
00:15:56,650 --> 00:15:59,240
And ping for google.com.

257
00:15:59,340 --> 00:16:01,090
Resource 200 milliseconds.

258
00:16:01,150 --> 00:16:06,910
I do indeed have Python, three point
12.6 installed locally and for the web

259
00:16:06,910 --> 00:16:13,460
search for Python three 14 it gave us
a lot of information from the website.

260
00:16:15,140 --> 00:16:20,370
So this seems to be working fine now,
let's compile this in the dictionary

261
00:16:20,430 --> 00:16:22,610
just to make it more easily accessible.

262
00:16:23,030 --> 00:16:27,310
And then the main implementation of
react framework happens basically in

263
00:16:27,310 --> 00:16:32,220
these, and these function over here
where we are going through the react loop

264
00:16:32,290 --> 00:16:36,930
we start with the sending the, is the
query of the digital query to the model.

265
00:16:37,620 --> 00:16:42,340
Then based on the output from the
model, we check if there is any action

266
00:16:42,400 --> 00:16:47,135
that model decided to perform, which
will be, signified by these actions.

267
00:16:47,135 --> 00:16:49,605
Semicolon prefix of the string.

268
00:16:50,025 --> 00:16:53,465
And if there is an action
we get the list of actions.

269
00:16:53,625 --> 00:16:58,315
We perform that action and give the
result of running that action to the

270
00:16:58,315 --> 00:17:00,485
LLM to hopefully give us the answer.

271
00:17:01,415 --> 00:17:04,945
And then of course, if it's, if
that information is not enough,

272
00:17:05,215 --> 00:17:06,505
we will go to the second loop.

273
00:17:06,625 --> 00:17:07,645
To the third loop, and so on.

274
00:17:09,715 --> 00:17:14,035
Now let's try pretty much the same,
the same prompts, the same questions

275
00:17:14,065 --> 00:17:19,865
we had before in the baseline, but
now with these basic agent behavior.

276
00:17:20,585 --> 00:17:25,235
So let's first try to get the response
time for Google, in this case it, the A

277
00:17:25,235 --> 00:17:30,825
lamp decided to perform Action Ping for
google.com which is a correct action.

278
00:17:30,855 --> 00:17:36,135
It got the answer from the action,
and then as an answer to our

279
00:17:36,195 --> 00:17:37,605
initial question, it gave us.

280
00:17:38,175 --> 00:17:44,045
The rounded number of milliseconds or
seconds for the pink the same should

281
00:17:44,045 --> 00:17:46,295
work with the Python packages, right?

282
00:17:46,295 --> 00:17:51,415
So we decided to perform the action
batch with the input of P list

283
00:17:51,465 --> 00:17:56,505
which gave the alarm a bunch of
packages I have installed locally.

284
00:17:57,375 --> 00:18:02,675
And then based on that the answer
from LLM was, I guess sort of summary

285
00:18:02,735 --> 00:18:06,545
of, of those Python packages which
have installed locally showing a

286
00:18:06,545 --> 00:18:07,865
presentative sample apparently.

287
00:18:08,645 --> 00:18:08,945
All right.

288
00:18:08,945 --> 00:18:13,305
And this, let's see what will happen
with the, our Python three 14 question.

289
00:18:14,155 --> 00:18:17,785
So the action that Ellan decided
to perform is a web search,

290
00:18:17,845 --> 00:18:19,365
which makes sense, right?

291
00:18:19,395 --> 00:18:24,535
It's pretty much the actual question
of ours was new by three 14.

292
00:18:25,015 --> 00:18:26,215
It got to the.

293
00:18:27,220 --> 00:18:33,850
Logical website from python.org with a
bunch of information and somewhere below.

294
00:18:33,940 --> 00:18:40,600
Let me scroll all the way down, somewhere
below it should give us the answer based

295
00:18:40,600 --> 00:18:42,640
on the observation from that action.

296
00:18:43,150 --> 00:18:44,170
Namely over here.

297
00:18:45,505 --> 00:18:50,895
It, it summarized some new features
changes in Python three 14, a few

298
00:18:50,895 --> 00:18:54,115
PEPs, a few new features some changes.

299
00:18:54,775 --> 00:18:59,635
So basically with just a
single system prompt like this.

300
00:19:00,810 --> 00:19:06,420
We already are able to significantly
extend the capabilities of LLM beyond

301
00:19:06,570 --> 00:19:09,420
it just being a sort of knowledge base.

302
00:19:09,420 --> 00:19:14,810
We else, it, it now has access to web,
it now has access to our local machine.

303
00:19:14,810 --> 00:19:17,810
It now has access to
batch commands, right?

304
00:19:17,810 --> 00:19:22,550
So basically it already
can be much more helpful.

305
00:19:22,925 --> 00:19:27,365
For us was in everyday life and
in our coding coding journey.

306
00:19:28,115 --> 00:19:30,775
But of course it wouldn't
be very convenient to.

307
00:19:31,990 --> 00:19:35,110
Modify this prompt every time
we need to add new action.

308
00:19:35,440 --> 00:19:38,650
And there could be a lot of different
actions depending on what tool

309
00:19:38,770 --> 00:19:40,870
you want LLM to be able to use.

310
00:19:41,260 --> 00:19:43,760
Like for example, if you
think about Git right?

311
00:19:43,790 --> 00:19:47,840
The Git itself has a bunch of
different commands like Git commit,

312
00:19:47,900 --> 00:19:50,210
Git checkout, Git branch, and so on.

313
00:19:50,240 --> 00:19:53,000
So you would potentially
need to define each.

314
00:19:53,990 --> 00:19:57,920
Single git command as a set
protection, and that probably

315
00:19:57,920 --> 00:19:59,090
would take quite a long time.

316
00:19:59,840 --> 00:20:06,550
Now, ho fortunately for us, there are ways
to abstract all these tool definitions

317
00:20:06,630 --> 00:20:13,200
from us, from the end user, and one
of those, one of these ways is MCP.

318
00:20:13,420 --> 00:20:16,510
So let me go back to the
slides real quick over here.

319
00:20:18,905 --> 00:20:20,075
Let's see.

320
00:20:20,165 --> 00:20:25,085
So MCP stands for Model Context
Protocol, and it was introduced

321
00:20:25,445 --> 00:20:30,575
pretty recently and the end of
November last year two four by Tropic.

322
00:20:31,095 --> 00:20:38,825
So essentially MCP is a protocol based on
JSON RPC, which, which aims to facilitate.

323
00:20:38,975 --> 00:20:43,565
The tool use and the development of
those tools, it consists of two main

324
00:20:43,625 --> 00:20:49,575
counterparts, MCP server and MCP host,
and MCP client, and now MCP client could

325
00:20:49,575 --> 00:20:56,095
be our LLM, it could be some id, it
could be any AI enabled tool, basically.

326
00:20:57,355 --> 00:21:01,875
And then MCP server performs
essentially two main functions.

327
00:21:02,295 --> 00:21:05,805
First, it, of course, interacts
with the, with the actual tool

328
00:21:05,865 --> 00:21:07,305
performs the actual actions, right?

329
00:21:07,305 --> 00:21:09,485
So it could access some local sources.

330
00:21:09,965 --> 00:21:13,565
It could be MCP server for the file
system, so it could manipulate files,

331
00:21:13,565 --> 00:21:18,395
for example, it could also be MCP
server that performs some a p requests.

332
00:21:18,485 --> 00:21:25,295
So it could be MCP server, which provides
tools to access Jira, for example.

333
00:21:25,325 --> 00:21:27,945
Or it could be tools to access.

334
00:21:28,965 --> 00:21:29,985
Flight radar, right?

335
00:21:29,985 --> 00:21:34,205
So basically any anything that can
be coded to be accessed through

336
00:21:34,205 --> 00:21:36,195
code can be converted to MCP server.

337
00:21:37,215 --> 00:21:41,685
And then through MCP Protocol,
the LLM can get the list of tools,

338
00:21:41,805 --> 00:21:45,315
can get any names, different
descriptions, and how to use them.

339
00:21:45,765 --> 00:21:50,835
And then again, through MCP protocol,
it would send essentially the request

340
00:21:50,955 --> 00:21:54,705
to perform the action to the MCP
server, and then it would get the

341
00:21:54,705 --> 00:21:58,935
response, from NCP server with the
result of running that ac that action

342
00:21:58,995 --> 00:22:00,550
or the result of running that tool.

343
00:22:01,930 --> 00:22:06,090
And it is pretty straightforward to
run to create your own NCP servers.

344
00:22:07,050 --> 00:22:14,980
Let me switch back to our notebook
over here, and let's go now to

345
00:22:14,980 --> 00:22:17,260
the agent with MCP directory.

346
00:22:17,740 --> 00:22:21,130
So first, let's see how we can
implement our own MCP server.

347
00:22:22,060 --> 00:22:24,130
And you can do that in multiple languages.

348
00:22:24,130 --> 00:22:29,810
I think currently there are
SDKs of Python, JavaScript, Java

349
00:22:29,870 --> 00:22:31,370
and Lin, if I'm not mistaken.

350
00:22:31,890 --> 00:22:36,620
But essentially, of course, I'm sure
that more languages will follow, but

351
00:22:36,620 --> 00:22:42,070
basically over here we have the two
MCP two or MCP server defined in Python

352
00:22:42,490 --> 00:22:49,760
and Tropic provided a nice, fast MCP
class or from the MCP framework, which

353
00:22:49,760 --> 00:22:54,330
basically requires us to essentially
just do essentially the server itself.

354
00:22:54,720 --> 00:22:59,160
And then through this, the curator, we
can convert any function into an MCP tool.

355
00:22:59,850 --> 00:23:03,440
So in this case, that would be a
bar tool which will perform any

356
00:23:03,490 --> 00:23:05,980
we will execute any batch command.

357
00:23:06,905 --> 00:23:09,155
For us, and of course you,
ideally, you don't want to

358
00:23:09,155 --> 00:23:11,735
execute blindly any b command.

359
00:23:11,835 --> 00:23:16,695
But for the sake of the, for the
presentation we we will allow that.

360
00:23:18,195 --> 00:23:21,965
But basically those three lines is the
only thing, things that you would need

361
00:23:22,355 --> 00:23:24,885
this in Python to create a bar Oh, sorry.

362
00:23:24,975 --> 00:23:27,335
To create an MCP server for yourself.

363
00:23:28,370 --> 00:23:31,680
And as I said, anything that
you can code can essentially

364
00:23:31,680 --> 00:23:33,660
be converted to MCP server.

365
00:23:35,160 --> 00:23:41,460
Now, along with that, we also would
require a sort of description of how

366
00:23:41,460 --> 00:23:44,040
to call that server, that MCP server.

367
00:23:44,340 --> 00:23:49,805
And over here I have a. Small JSON
file, which defines the MCP servers.

368
00:23:50,225 --> 00:23:55,175
In this case, the only MCP server
is called B and it is run as

369
00:23:55,325 --> 00:23:59,615
python command, right with the
arcs of just name of the file.

370
00:23:59,975 --> 00:24:01,755
'cause it's essentially by Python script.

371
00:24:02,155 --> 00:24:06,685
So that's the only two things that
needs that it needs to be executed.

372
00:24:07,285 --> 00:24:09,205
But we'll see later different ways.

373
00:24:09,325 --> 00:24:13,585
Beyond just Python script that
you can execute MCP servers as.

374
00:24:14,665 --> 00:24:21,125
So let's now see how we can use
those MCP servers along with LLM.

375
00:24:21,965 --> 00:24:25,045
So for that first of all,
we will switch to tropic.

376
00:24:25,045 --> 00:24:28,295
In this case it would be
cloud D 3.7, I believe.

377
00:24:28,535 --> 00:24:30,665
Yep, it's cloud D 3.7.

378
00:24:31,245 --> 00:24:33,065
The reason for this switch.

379
00:24:33,920 --> 00:24:39,810
Is initially tropic tropics Cloud
was more was better at using tools.

380
00:24:39,860 --> 00:24:44,630
However, now you might have heard
that even OpenAI adopted the MCP

381
00:24:44,630 --> 00:24:46,790
protocol from the arrivals, basically.

382
00:24:47,250 --> 00:24:52,000
So the recent models are also
pretty good with following, with

383
00:24:52,000 --> 00:24:54,150
using tools defined as MCP servers.

384
00:24:54,550 --> 00:24:58,220
But still here we'll be
using, tropics called 3.7.

385
00:24:58,970 --> 00:25:05,720
Now, what we essentially need to use the
CP tools is we will need an MCB client.

386
00:25:06,170 --> 00:25:11,410
And in this case the main functions
or methods of this class is, first

387
00:25:11,410 --> 00:25:16,020
of all, we need of course to connect
to servers to get the list of tools

388
00:25:16,020 --> 00:25:19,170
available for us to use no for LLM to use.

389
00:25:19,860 --> 00:25:22,520
These function is essentially
responsible for that.

390
00:25:23,030 --> 00:25:28,810
So we just connect to each server in
the loop, in the server config, and then

391
00:25:29,260 --> 00:25:32,090
get a list of tools from that server.

392
00:25:32,960 --> 00:25:39,670
And then we also need to of course,
send the request to LLM and then act

393
00:25:39,730 --> 00:25:41,890
accordingly to the response from LLM.

394
00:25:42,460 --> 00:25:45,880
So basically we attach the list of tools.

395
00:25:47,125 --> 00:25:51,335
I got from MCP servers in the format
of tool name, tool description, and

396
00:25:51,395 --> 00:25:57,105
tool input schema, along with our, user
input message, and those things are

397
00:25:57,105 --> 00:26:00,525
sent directly to CLA 3.7 in this case.

398
00:26:01,035 --> 00:26:05,995
And then the clo, the LLM, decides
if it wants to just respond as

399
00:26:05,995 --> 00:26:10,175
a plain text or if it wants to
perform an action or a tool use.

400
00:26:10,715 --> 00:26:13,165
And this is how we basically
differentiate between.

401
00:26:14,650 --> 00:26:18,430
Between those as part of the response
that would be a content type.

402
00:26:18,520 --> 00:26:23,080
It could be either text or a tool use
in, and in the case of tool use, we will

403
00:26:23,080 --> 00:26:25,310
see what kind of tool it wants to use.

404
00:26:25,380 --> 00:26:30,190
So that will basically tool name and then
what kind of input arguments, it needs to

405
00:26:30,190 --> 00:26:32,440
be we need to pass to that to that tool.

406
00:26:33,190 --> 00:26:36,850
Then we will perform that
actual tool call over here.

407
00:26:37,300 --> 00:26:44,240
And then we'll send the result of that
tool call back to LLM, and then hopefully

408
00:26:44,300 --> 00:26:46,480
we will get an answer to our question.

409
00:26:47,860 --> 00:26:51,770
And then here I have a small,
a nice small chat loop.

410
00:26:52,700 --> 00:26:55,970
Where basically we will send the we
will send the query into the into

411
00:26:55,970 --> 00:27:00,960
the text field, and then proceed with
this chat until we type the qui word.

412
00:27:01,920 --> 00:27:05,910
So let's start with our, just
with our bar tool over here.

413
00:27:07,020 --> 00:27:10,810
We got connected to the, to
our server which was run as

414
00:27:10,810 --> 00:27:13,240
Python Bar tool, fast speed pi.

415
00:27:13,810 --> 00:27:16,420
We have one single tool called Barge.

416
00:27:17,020 --> 00:27:19,700
And let's ask LLM to do something.

417
00:27:19,700 --> 00:27:24,890
Let's say list all files and
let's see what will come up with.

418
00:27:27,290 --> 00:27:31,990
So in this case, he decided to call
the B command, the Bash two with

419
00:27:31,990 --> 00:27:36,210
a comment with a. With the comment
LS dash la, which makes sense.

420
00:27:36,720 --> 00:27:42,210
It got the list of files and
basically summarized them all.

421
00:27:42,210 --> 00:27:42,420
Good.

422
00:27:43,560 --> 00:27:48,010
Now let's see how we can extend these
two multiple servers to multiple tools.

423
00:27:48,400 --> 00:27:51,805
And for that we will use
the full J confi over here.

424
00:27:53,110 --> 00:27:56,140
Which basically defines four MCP servers.

425
00:27:56,590 --> 00:28:00,910
First of all, we have a file system,
MCP server, which is essentially

426
00:28:00,910 --> 00:28:05,750
an NPM package which runs with
few inputs, see few arguments.

427
00:28:05,900 --> 00:28:10,040
We also have a web search realized
through Brave web search, and

428
00:28:10,040 --> 00:28:11,540
that is run as docker image.

429
00:28:12,725 --> 00:28:15,325
So here we have some
end file for the tokens.

430
00:28:15,895 --> 00:28:21,245
We also have a fe, a web server, which
would allow LLM to fetch any URL from the

431
00:28:21,245 --> 00:28:24,165
web, is implemented as Python package.

432
00:28:24,585 --> 00:28:28,025
And then of course we have our
Bash MCP server, which we just

433
00:28:28,025 --> 00:28:29,765
defined couple seconds ago.

434
00:28:30,935 --> 00:28:34,395
So you can see, cP servers
can come in all flavors and

435
00:28:34,395 --> 00:28:36,585
languages and ways to run them.

436
00:28:37,665 --> 00:28:45,145
Now, let's see let's not give those
servers to our LLM and let's ask

437
00:28:45,145 --> 00:28:47,115
to perform some actions, right?

438
00:28:47,115 --> 00:28:50,085
First of all, let's see
what's new in Python.

439
00:28:50,635 --> 00:28:51,415
Three 14.

440
00:28:52,415 --> 00:28:56,735
So let's see if it'll need to perform
a web search to give us the answer.

441
00:28:57,735 --> 00:29:01,695
All right, so it decided to call
the web search tool with the

442
00:29:01,695 --> 00:29:04,485
following query, Python three 14
new features through release notes.

443
00:29:05,520 --> 00:29:12,040
The unlike OpenAI GT 4.1, it didn't just
copy the questions from us and then based

444
00:29:12,040 --> 00:29:17,150
on the response from the web search tool,
it gave us the summary of new features.

445
00:29:17,900 --> 00:29:28,160
Let's also try to ask cla to create a file
called Hello the text with the content.

446
00:29:29,240 --> 00:29:30,020
Hello world.

447
00:29:31,040 --> 00:29:31,370
Alright.

448
00:29:33,560 --> 00:29:34,100
Let's see.

449
00:29:34,310 --> 00:29:38,290
So hopefully it'll be able to
access our local file system.

450
00:29:38,620 --> 00:29:41,710
So in this case, we decided
to use the tool right file

451
00:29:42,040 --> 00:29:43,210
with the following arguments.

452
00:29:43,630 --> 00:29:47,550
And let's actually see, yeah,
we just got the new file.

453
00:29:47,670 --> 00:29:53,940
We on our local file system called as
Requested, hello to 60 with the content.

454
00:29:53,970 --> 00:29:54,750
Hello World.

455
00:29:55,785 --> 00:29:56,115
Great.

456
00:29:56,475 --> 00:30:02,795
So essentially with just a few lines
of code of basically the JSON config

457
00:30:02,855 --> 00:30:08,435
of MCP servers, we, again extended
the capabilities of LLM beyond just

458
00:30:08,515 --> 00:30:13,055
being able to answer questions based
on its on what is seen in the tearing

459
00:30:13,055 --> 00:30:16,265
data, it is now also able to perform.

460
00:30:16,375 --> 00:30:22,215
A lot of different actions and those MCP
server can come in different flavors.

461
00:30:22,275 --> 00:30:26,625
And there are actually a lot
of different sources where you

462
00:30:26,625 --> 00:30:28,575
can find M CCP servers online.

463
00:30:28,755 --> 00:30:32,985
There are MCP registries, which
contains hundreds of different M

464
00:30:32,985 --> 00:30:36,375
CCP servers for tools like, for
example, Grafana JIRA and so on.

465
00:30:36,555 --> 00:30:42,195
So basically you can, give a lamb
access to any tools you use in your

466
00:30:42,195 --> 00:30:44,755
everyday every everyday working life.

467
00:30:45,235 --> 00:30:50,995
And basically, as we will see later, ask
it to, for example, solve the ticket.

468
00:30:52,795 --> 00:30:59,975
Now let's let me quickly jump back
to the slides for a few more seconds.

469
00:31:01,685 --> 00:31:03,425
All right, so we've seen MCP.

470
00:31:03,665 --> 00:31:10,105
Now let's see how we can make agents
work with each other because of course,

471
00:31:10,105 --> 00:31:15,115
before, before that, we, all the tools
we had, oh, LLM had at this disposal

472
00:31:15,115 --> 00:31:17,675
were essentially just a software, right?

473
00:31:17,675 --> 00:31:21,445
There was just API calls, it was just
file system manipulations and so on.

474
00:31:21,925 --> 00:31:25,845
However, you can imagine those
tools being agents on their own.

475
00:31:26,655 --> 00:31:31,675
And then one agent could potentially
call another agent to delegate a task

476
00:31:31,735 --> 00:31:37,025
to ask it, to ask a subordinate agent
to perform some small subtask and so on.

477
00:31:37,115 --> 00:31:42,175
And in our case, we will be building
a system which contains four

478
00:31:42,175 --> 00:31:45,415
agents and it will be hierarchical.

479
00:31:45,525 --> 00:31:48,675
Hierarchical system where, we'll,
where we will have supervisor,

480
00:31:48,675 --> 00:31:51,895
agent which you can think about
as product manager, for example.

481
00:31:52,475 --> 00:31:57,915
And this agent will be able to call
three other agents subordinate agents.

482
00:31:58,035 --> 00:32:01,665
And those would be frontend
developer virtual frontend developer.

483
00:32:02,174 --> 00:32:04,784
Virtual backend developer
and virtual DevOps engineer.

484
00:32:05,114 --> 00:32:09,414
And they also would be able to
interact with us with the client to

485
00:32:09,414 --> 00:32:11,034
ask for any clarification if needed.

486
00:32:12,124 --> 00:32:15,904
But generally all of the
manipulation of the all of the.

487
00:32:16,865 --> 00:32:19,904
Interactions between those
subordinate agents should happen

488
00:32:19,904 --> 00:32:20,984
through a supervisor agent.

489
00:32:21,444 --> 00:32:25,574
There is no direct connection from
one subordinate agent to another.

490
00:32:25,935 --> 00:32:30,604
However, of course, you can also implement
this where where in the system potentially

491
00:32:30,714 --> 00:32:34,854
all agents would be able to talk with
each other directly, not through the

492
00:32:34,854 --> 00:32:40,014
supervisor agent, it would really depend
on what you want the system to work to do.

493
00:32:41,484 --> 00:32:46,264
Now let me switch back again
to our Jupyter Notebook.

494
00:32:47,314 --> 00:32:47,734
Alright,

495
00:32:49,924 --> 00:32:55,654
and let's go to the final notebook
of the day, which is multi-agent.

496
00:32:55,924 --> 00:32:56,404
Notebook.

497
00:32:56,704 --> 00:33:01,264
Now here I will be adding one more
level of abstraction and memory,

498
00:33:01,264 --> 00:33:02,554
link chain and glowing graph.

499
00:33:03,004 --> 00:33:06,704
And the reason for that is of
course you can implement all of

500
00:33:06,704 --> 00:33:11,834
the agent, all of the cross agent
collaborate interactions on your own.

501
00:33:11,934 --> 00:33:13,074
It is essentially.

502
00:33:14,409 --> 00:33:18,309
Just the structured inputs and
outputs and then some state

503
00:33:18,489 --> 00:33:20,029
manipulations on top of that.

504
00:33:20,439 --> 00:33:24,839
Why spend time on that when you
can use the frameworks which

505
00:33:24,839 --> 00:33:26,529
do that for you basically.

506
00:33:26,939 --> 00:33:31,439
So again, we will use the
same quality 3.7 here and.

507
00:33:32,414 --> 00:33:35,734
Give it three, or, sorry, four four tools.

508
00:33:36,664 --> 00:33:38,704
Pretty much the same tools
which we've seen before.

509
00:33:38,974 --> 00:33:42,054
Shell tool for the batch
commands, we will, it'll also

510
00:33:42,144 --> 00:33:43,374
have access to brave search.

511
00:33:43,524 --> 00:33:44,934
Again, as we've seen before.

512
00:33:45,504 --> 00:33:48,704
It'll also have access to
file file system manipulation.

513
00:33:49,064 --> 00:33:54,304
And there is also one more new
tool which I called Human, which

514
00:33:54,304 --> 00:33:58,694
basically would allow LLM to
ask back questions to the human.

515
00:34:00,674 --> 00:34:03,464
And then we at the are
discussed on the site.

516
00:34:03,464 --> 00:34:06,254
We will, we'll create four agents.

517
00:34:06,374 --> 00:34:12,884
First, we'll create agent supervisor,
which will have access to three team

518
00:34:12,884 --> 00:34:17,384
members, namely frontend developer,
backend developer and ops engineer, and

519
00:34:17,384 --> 00:34:18,974
the system run the split straightforward.

520
00:34:19,944 --> 00:34:24,024
We are telling the agent that it is
a supervisor overseeing the following

521
00:34:24,024 --> 00:34:29,514
three workers, and it basically
needs to decide who's who is the

522
00:34:29,514 --> 00:34:35,154
next agent responsible to, for, to
perform the task or to act next.

523
00:34:36,144 --> 00:34:40,134
And then once the supervisor agent
is happy with the result, it should

524
00:34:40,134 --> 00:34:42,354
respond with a keyword finish.

525
00:34:42,414 --> 00:34:47,604
Basically, we will give access to
all the tools, all the available

526
00:34:47,604 --> 00:34:49,254
tools to these agents as well.

527
00:34:49,374 --> 00:34:55,254
However in real life potentially you
probably would want agents to have access

528
00:34:55,254 --> 00:34:56,544
to different lists of tools, right?

529
00:34:56,544 --> 00:35:00,194
For example, you might have DevOps
engineer, virtual DevOps engineer.

530
00:35:00,494 --> 00:35:07,484
Being able to access tools like Ana or
Promeus or Datadog or whatever, right?

531
00:35:07,514 --> 00:35:10,984
But at the same time, you don't want,
probably, you probably don't need front,

532
00:35:10,984 --> 00:35:14,104
end agent to be able to access that.

533
00:35:14,584 --> 00:35:17,104
But on the other hand, it
needs to have access to other

534
00:35:17,104 --> 00:35:18,574
tools like Figma, for example.

535
00:35:19,984 --> 00:35:25,844
So the only things we basically need
to create our supervisor agent is

536
00:35:26,354 --> 00:35:31,384
this piece of code over here where we
define what what sort of nodes or what

537
00:35:31,384 --> 00:35:35,734
sort of hand off notes are available
for these supervisor nodes to call.

538
00:35:37,054 --> 00:35:38,944
And those are again, our team members.

539
00:35:39,274 --> 00:35:41,564
And then of course, end
node to finish the tasks.

540
00:35:42,829 --> 00:35:48,129
With that, let's also define our
three agents, namely front end agent

541
00:35:48,209 --> 00:35:50,379
backend agent, and DevOps agent.

542
00:35:51,019 --> 00:35:54,439
As you can see here, we are using
pretty much the same React framework.

543
00:35:55,384 --> 00:35:59,674
As we've seen before, and again, we
are passing all the tools, all of

544
00:35:59,674 --> 00:36:03,724
the available tools to those agents,
and the prompts are pretty simple.

545
00:36:03,774 --> 00:36:06,054
Although in real life world, of
course, you probably would want

546
00:36:06,054 --> 00:36:10,244
to be more creative or be more
specific with those prompts.

547
00:36:10,604 --> 00:36:16,844
But in our case, we are just defining the
frontend agent as a frontend developer.

548
00:36:17,314 --> 00:36:19,894
And this agent can also ask.

549
00:36:20,274 --> 00:36:23,814
Help ask for help from backend
developer or DevOps engineer.

550
00:36:24,144 --> 00:36:26,784
And it can also ask for
clarifications from the human client.

551
00:36:27,574 --> 00:36:30,534
The same goes with a
backend backend agent.

552
00:36:30,744 --> 00:36:34,554
It can help, can ask for
help from front end or DevOps

553
00:36:34,554 --> 00:36:38,334
engineer, and it can also ask for
clarifications from the human client.

554
00:36:39,444 --> 00:36:41,564
And the same goes with a DevOps agent.

555
00:36:41,894 --> 00:36:42,439
It can also.

556
00:36:43,454 --> 00:36:47,684
Call, ask help for front end
or backend developers and ask

557
00:36:47,684 --> 00:36:49,064
for clarifications from human.

558
00:36:50,244 --> 00:36:55,554
All of those agents or nodes in
the terms of land graph are defined

559
00:36:55,924 --> 00:37:00,724
in a pretty three forward manner
through these comment over here.

560
00:37:01,234 --> 00:37:04,789
And that's pretty much all we need to do.

561
00:37:05,599 --> 00:37:06,859
To define those agents.

562
00:37:07,309 --> 00:37:11,959
Now, with that, let's also build a graph
and let's also visualize that graph.

563
00:37:12,589 --> 00:37:17,659
So indeed, as we've seen before, we
have the supervisor note or supervisor

564
00:37:17,659 --> 00:37:23,369
agent which can talk directly with our
front end backend and DevOps engineers.

565
00:37:23,609 --> 00:37:25,899
But subordinate agents
can talk to each other.

566
00:37:25,899 --> 00:37:27,909
They only can talk through supervisor.

567
00:37:29,439 --> 00:37:34,009
Over here I have just a small
help helper, now helper function

568
00:37:34,039 --> 00:37:36,459
to color the output as we see.

569
00:37:36,459 --> 00:37:40,819
That's what we'll see in a few seconds,
so I won't go over that piece of code.

570
00:37:42,139 --> 00:37:47,339
And then the task for the, for
our multi-agent system would be to

571
00:37:47,339 --> 00:37:48,869
create a website for the conference.

572
00:37:49,049 --> 00:37:51,359
It needs to have three pages.

573
00:37:51,929 --> 00:37:55,169
Namely intro intro page page
for people to submit it.

574
00:37:55,169 --> 00:37:57,929
There, the docs and page
with the submitted docs.

575
00:37:58,619 --> 00:38:00,589
I want the front end in React.

576
00:38:00,709 --> 00:38:04,759
I want a backend test, API
and the submissions should be

577
00:38:04,759 --> 00:38:06,519
stored in Postgres database.

578
00:38:07,239 --> 00:38:10,039
And also, it's always as have
Docker and Docker compose.

579
00:38:10,039 --> 00:38:11,239
So I also ask for that.

580
00:38:11,779 --> 00:38:16,519
And then we also mention that they can ask
the human client for any clarifications.

581
00:38:17,569 --> 00:38:23,049
This part over here is basically
all what is needed to initiate the

582
00:38:23,529 --> 00:38:25,359
execution of our multi-agent system.

583
00:38:25,899 --> 00:38:30,639
So I actually started and see
what will come up with first.

584
00:38:30,699 --> 00:38:34,089
Indeed we went into supervisor,
which decided to call the front

585
00:38:34,089 --> 00:38:39,869
frontend developer the frontend
developer itself decided to check

586
00:38:39,939 --> 00:38:42,069
what kind of tools it has installed.

587
00:38:42,559 --> 00:38:43,399
On the system.

588
00:38:43,789 --> 00:38:50,719
I got the answer and then it went ahead
to check the versions the version.

589
00:38:51,529 --> 00:38:54,709
Alright, it decided to create
a conference website directory.

590
00:38:54,709 --> 00:38:55,279
So here.

591
00:38:55,699 --> 00:39:00,089
So we already should be able to
see some changes reflected locally.

592
00:39:00,449 --> 00:39:00,839
Indeed.

593
00:39:00,839 --> 00:39:02,909
We have a few directors already.

594
00:39:03,959 --> 00:39:08,309
We have the package on, so
probably it is, yeah, it is doing.

595
00:39:08,419 --> 00:39:14,739
N-P-N-P-X command, which will potentially
take some time because, the n payment

596
00:39:14,739 --> 00:39:17,079
style usually takes a few minutes.

597
00:39:17,139 --> 00:39:22,689
We, yeah, we can see the non models
appearing for us with a bunch of packages.

598
00:39:23,289 --> 00:39:27,999
All right, let's okay, let's go back
and we already starting to see some of

599
00:39:27,999 --> 00:39:30,379
the code popping up over here, right?

600
00:39:30,379 --> 00:39:32,239
Some CSS, some TypeScript code.

601
00:39:32,849 --> 00:39:33,449
Let me.

602
00:39:33,989 --> 00:39:36,869
Scroll scroll down here.

603
00:39:37,539 --> 00:39:42,969
So it did install some packages and it
started to implement the code over here.

604
00:39:43,569 --> 00:39:44,949
So it started with the Python.

605
00:39:46,269 --> 00:39:46,749
Alright.

606
00:39:47,379 --> 00:39:47,589
Yeah.

607
00:39:47,619 --> 00:39:52,219
Basically it'll proceed to implement
the website for us on our behalf.

608
00:39:53,029 --> 00:39:57,999
Now let me switch back
again to the slides.

609
00:39:59,529 --> 00:40:00,129
All right.

610
00:40:02,859 --> 00:40:03,219
All right.

611
00:40:03,219 --> 00:40:07,229
But it is always nice to, fiddle
around with the code with the

612
00:40:07,229 --> 00:40:11,399
agents, with the L lms and see
what you can build on your own.

613
00:40:11,499 --> 00:40:17,099
Of course you don't always have time and
still you probably would want to be able

614
00:40:17,099 --> 00:40:22,474
to use, those agents be able to have those
agents help you with your everyday tasks.

615
00:40:22,924 --> 00:40:28,154
And of course there is a way for you
to have them help you with your coding.

616
00:40:28,264 --> 00:40:29,434
Coding tasks, basically.

617
00:40:30,044 --> 00:40:33,914
With that, let me briefly introduce
briefly talk about what we do at Z Coder.

618
00:40:34,894 --> 00:40:39,244
Z Coder basically is just a plugin
for V Code of Brains, and this

619
00:40:39,244 --> 00:40:44,324
plugin brings you brings the
agents to you, to your id natively.

620
00:40:44,354 --> 00:40:48,724
You don't need to switch to any other id
outside of what you are already using.

621
00:40:49,294 --> 00:40:52,274
And let me briefly show showcase.

622
00:40:52,374 --> 00:40:55,024
Our agent basically solving the Jira task.

623
00:40:55,714 --> 00:40:58,694
Let me switch to this code over here.

624
00:41:00,134 --> 00:41:00,614
Alright,

625
00:41:03,374 --> 00:41:10,929
so our agent, our z coder is already
natively integrated in the J So we

626
00:41:10,929 --> 00:41:12,579
have this encoder test over here.

627
00:41:13,149 --> 00:41:16,639
So basically we can tag
any ticket from the j.

628
00:41:19,079 --> 00:41:21,724
I think that's the
wrong the wrong account.

629
00:41:21,844 --> 00:41:22,234
Alright,

630
00:41:24,904 --> 00:41:25,474
base.

631
00:41:25,564 --> 00:41:26,104
Let's see.

632
00:41:26,164 --> 00:41:29,434
Alright, so let's ask our
agent to solve this ticket.

633
00:41:30,074 --> 00:41:34,854
Solve it create a branch called 42.

634
00:41:36,354 --> 00:41:39,684
Check out and commit changes.

635
00:41:41,829 --> 00:41:42,249
All right.

636
00:41:42,339 --> 00:41:46,369
So the ticket itself basically
requires the agent to implement

637
00:41:46,439 --> 00:41:49,829
changes across multiple languages
across the whole repository.

638
00:41:50,409 --> 00:41:55,089
So what the, what our agent will
do first that we'll try to analyze.

639
00:41:56,214 --> 00:41:58,644
The code base, it'll try
to understand the project.

640
00:41:59,174 --> 00:42:01,154
So it will check some Python files.

641
00:42:01,244 --> 00:42:04,814
It decided to also check
across different languages.

642
00:42:04,844 --> 00:42:10,334
So this repository specifically contains
three languages Python, go in TypeScript.

643
00:42:10,814 --> 00:42:14,874
So it went ahead to check some go
implementation of the repository.

644
00:42:16,704 --> 00:42:19,044
Yeah, so it will, it can take
some time depending on the

645
00:42:19,044 --> 00:42:20,584
task which we have at hand.

646
00:42:20,944 --> 00:42:23,464
So it also create already a branch for us.

647
00:42:23,534 --> 00:42:28,874
Thanks to MCP support, of course, you
can attach any MCP servers in this case.

648
00:42:29,294 --> 00:42:35,644
I have Git, MCP, which basically allows
the agent to, to perform any git commands

649
00:42:35,714 --> 00:42:40,894
locally on your machine, and we already
see some changes being implemented

650
00:42:40,994 --> 00:42:43,874
in our repository, first and Python.

651
00:42:45,764 --> 00:42:46,244
Okay?

652
00:42:49,214 --> 00:42:49,424
Okay.

653
00:42:49,424 --> 00:42:53,834
We already have modified, I
believe, two files over here.

654
00:42:54,834 --> 00:42:58,704
Then agent decided to switch, to go
implementation of the repository.

655
00:42:59,694 --> 00:43:04,474
All right, so yeah, we also need
to introduce this name space

656
00:43:05,674 --> 00:43:10,144
thingy in the go go implementation
server as well as in Python.

657
00:43:10,804 --> 00:43:11,284
Alright.

658
00:43:12,334 --> 00:43:18,864
Then we also, of course as instructed the
GI a and Git and this small the sort of

659
00:43:18,864 --> 00:43:26,154
nice feature I have here is I instructed
the agent through instructions to always

660
00:43:26,154 --> 00:43:29,044
slack me when it is done with the task.

661
00:43:30,094 --> 00:43:31,914
So let's go back to our chat.

662
00:43:33,909 --> 00:43:39,119
And yeah, basically after the combination
of agen patterns and MCB servers, it

663
00:43:39,119 --> 00:43:45,499
was able to basically pull the JIRA
JIRA ticket and then essentially do all

664
00:43:45,499 --> 00:43:51,819
the all the tasks surrounding the, the
typical software development steps, right?

665
00:43:51,819 --> 00:43:54,879
So it creates, the branch created
a commit for us and so on.

666
00:43:55,764 --> 00:44:00,904
So basically in a matter of minute, it
was able to fix fix the ticket for us.

667
00:44:02,224 --> 00:44:02,524
Alright.

668
00:44:02,524 --> 00:44:07,734
Let's switch back to the
slides one more time.

669
00:44:08,124 --> 00:44:08,544
Okay.

670
00:44:08,664 --> 00:44:13,464
So yeah, and if you are wondering this
is how those messages from sun Coder

671
00:44:13,464 --> 00:44:15,054
would look like in Slack, for example.

672
00:44:15,444 --> 00:44:22,284
And, every time I get those messages,
it feels this meme and of course, I can

673
00:44:22,284 --> 00:44:27,954
instruct Theod to not message you, but
your PM or whoever you wanted to message

674
00:44:28,344 --> 00:44:31,569
and not necessarily in Slack or, you
can, through MCP, you can connect to

675
00:44:31,569 --> 00:44:33,909
pretty much any messaging app whatsoever.

676
00:44:35,259 --> 00:44:41,729
And well, of course, these sort of
improvements or what you've seen now.

677
00:44:41,839 --> 00:44:47,699
Probably made you think if it's time
to switch switch the profession, right?

678
00:44:47,759 --> 00:44:50,399
Is still a good time to
be a software developer?

679
00:44:50,759 --> 00:44:55,619
And of course there are essentially
two main sides to that question to,

680
00:44:55,719 --> 00:44:57,249
what's coming for the developers.

681
00:44:57,729 --> 00:45:02,669
Of course, you can think
about, ai replication and.

682
00:45:03,329 --> 00:45:08,529
There is also some, variability as to if
you see it as a negative or a positive

683
00:45:08,529 --> 00:45:12,429
thing because for example, maybe you
always wanted to be a goose farmer.

684
00:45:12,769 --> 00:45:17,209
And then once you are replaced by
ai, you finally would be able to

685
00:45:17,209 --> 00:45:22,259
chase that long lasting dream of
whatever you whatever your heart

686
00:45:22,259 --> 00:45:24,929
wants you, what wants you to be.

687
00:45:25,879 --> 00:45:26,929
Now of course.

688
00:45:27,499 --> 00:45:32,109
At least for now, AI is not able
to train itself without the data.

689
00:45:32,409 --> 00:45:35,929
So there is at least one
job that is safe for now.

690
00:45:35,989 --> 00:45:41,489
Namely writing the code for AI to
train on because, still it requires a

691
00:45:41,489 --> 00:45:47,109
bunch of data for training, for model
improvements, however jokes site even

692
00:45:47,109 --> 00:45:51,379
with those, all of those improvements
from, on the AI side, on the gen side

693
00:45:51,819 --> 00:45:56,969
with things like white coding, you still
hopefully need to they still need to

694
00:45:56,969 --> 00:45:59,309
have a good knowledge of what's going on.

695
00:45:59,859 --> 00:46:03,549
Especially we're talking about some
mission critical systems especially

696
00:46:03,649 --> 00:46:06,169
about putting things into production.

697
00:46:06,949 --> 00:46:10,879
You still want to be able to un to be
able to understand what's going on.

698
00:46:10,929 --> 00:46:12,519
You need to still need to be able to.

699
00:46:13,329 --> 00:46:16,149
Read the code or know, debug the code.

700
00:46:16,269 --> 00:46:23,529
So what we at Zone Coder and me personally
see as a sort of upcoming future for

701
00:46:23,529 --> 00:46:29,499
the software development is that we as
developers would become more as a managers

702
00:46:29,589 --> 00:46:34,809
of virtual virtual agents, virtual
junior developers, if you will, and.

703
00:46:36,174 --> 00:46:40,524
We as humans would be more for
reviewers, more managers as that

704
00:46:40,924 --> 00:46:42,924
rather than writing the code ourselves.

705
00:46:43,014 --> 00:46:46,314
So basically we would be able
to offload any mundane tasks.

706
00:46:47,544 --> 00:46:52,014
For example writing documentation,
writing new in tests, and so on to our

707
00:46:52,284 --> 00:46:54,554
army of virtual virtual developers.

708
00:46:54,804 --> 00:46:58,644
We as as people would be able to
focus on more creative or more high

709
00:46:58,644 --> 00:47:02,994
level tasks, more architecturals
architectural tasks and so on.

710
00:47:04,554 --> 00:47:11,864
So yeah, hopefully the future, no longer
doesn't look as as dark as it did before.

711
00:47:12,504 --> 00:47:14,374
But of course, AI moves fast.

712
00:47:14,434 --> 00:47:17,854
So we'll see what will
happen a few years with that.

713
00:47:18,859 --> 00:47:20,899
A couple cure codes for you to use.

714
00:47:20,959 --> 00:47:23,599
On the right is my contact details.

715
00:47:23,729 --> 00:47:28,439
If you want to connect on LinkedIn,
if you want to follow up with any

716
00:47:28,439 --> 00:47:30,659
questions, feel free to message me.

717
00:47:30,719 --> 00:47:32,219
Feel free to send the connect request.

718
00:47:32,849 --> 00:47:37,809
And on the left you can see the cure
code for our website for encoder ai,

719
00:47:38,019 --> 00:47:43,674
where you can basically sign up for free
and try as, try the agents in your id.

720
00:47:44,174 --> 00:47:46,874
Already they end with that.

721
00:47:47,334 --> 00:47:49,044
Thank you for your attention.

