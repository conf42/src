1
00:00:00,500 --> 00:00:01,280
Good morning everyone.

2
00:00:01,370 --> 00:00:05,120
My name is Yash Ri, and today I'll
be discussing AI driven testing

3
00:00:05,120 --> 00:00:07,100
for conversational AI systems.

4
00:00:07,850 --> 00:00:12,739
I've spent the last decade working on
voice assistance like Alexa and Siri, and

5
00:00:12,739 --> 00:00:17,720
one challenge remains constant testing
conversational AI systems tone scale.

6
00:00:18,220 --> 00:00:23,140
In this talk, I'll show how we can
leverage L LMS themselves as judges, test

7
00:00:23,140 --> 00:00:25,240
case generators and automation drivers.

8
00:00:25,660 --> 00:00:28,720
To redefine quality assurance
for enterprise grade ai,

9
00:00:29,220 --> 00:00:30,119
what's the challenge?

10
00:00:30,390 --> 00:00:32,400
Conversational AI is unpredictable.

11
00:00:32,970 --> 00:00:34,710
There's no finite set of inputs.

12
00:00:35,160 --> 00:00:39,360
Every user, every phrasing, every
language variant can shift in dent.

13
00:00:40,320 --> 00:00:45,930
For instance, users might say, set an
alarm for seven, or Wake me up at seven

14
00:00:45,930 --> 00:00:48,780
sharp, or Get me up before sunrise.

15
00:00:49,280 --> 00:00:52,310
Traditional QA assumes you
can enumerate test cases.

16
00:00:52,970 --> 00:00:54,470
That model collapses here.

17
00:00:54,970 --> 00:00:59,470
Manual review is expensive,
inconsistent, and cannot keep up

18
00:00:59,470 --> 00:01:01,150
with the pace of model updates.

19
00:01:01,750 --> 00:01:03,940
So the testing gap keeps widening.

20
00:01:04,780 --> 00:01:08,440
We build smarter bots, but the
but test them with legacy methods.

21
00:01:09,100 --> 00:01:10,840
That's the problem we
are trying to solve here.

22
00:01:11,340 --> 00:01:14,790
So our solution is an intelligent
end-to-end QA framework.

23
00:01:15,290 --> 00:01:17,930
Our approach builds an AI powered QA loop.

24
00:01:18,430 --> 00:01:21,160
It's built on three
pillars, LLM as a judge.

25
00:01:21,970 --> 00:01:26,590
Automated evaluation that replaces
manual review, generative test data,

26
00:01:27,040 --> 00:01:32,980
AI generated diverse test cases,
and CICD integration automation

27
00:01:32,980 --> 00:01:34,660
embedded into every build cycle.

28
00:01:35,380 --> 00:01:37,540
Together they create
an end-to-end pipeline.

29
00:01:38,140 --> 00:01:41,500
Where conversational AI can
test, evaluate, and validate

30
00:01:41,500 --> 00:01:43,509
itself continuously at scale.

31
00:01:44,009 --> 00:01:45,570
Now, what is LLM as a judge?

32
00:01:46,110 --> 00:01:52,619
Think of LLM as a judge, like an automated
senior QA engineer, one that never sleeps,

33
00:01:52,679 --> 00:01:55,020
never biases and scales infinitely.

34
00:01:55,920 --> 00:02:00,135
For example, given a chat bots response,
your package will arrive next week.

35
00:02:00,944 --> 00:02:04,124
The LLM as judge can
analyze if that's accurate.

36
00:02:04,124 --> 00:02:07,754
Based on the context, was it
actually supposed to arrive tomorrow?

37
00:02:08,685 --> 00:02:12,914
It evaluates semantic accuracy,
relevance, safety, and tone in

38
00:02:12,914 --> 00:02:14,954
seconds across thousands of dialogues.

39
00:02:15,464 --> 00:02:20,654
That's how we move QA from being manual
and reactive to automated and continuous

40
00:02:21,154 --> 00:02:22,369
core components of ala.

41
00:02:22,385 --> 00:02:25,984
As a judge, there are four
pillars, standardized prompts.

42
00:02:26,375 --> 00:02:31,385
Structured evaluation templates like rate
this response for accuracy, tone, and

43
00:02:31,385 --> 00:02:38,154
user satisfaction, calibration data sets,
allowing aligning the judge models, scores

44
00:02:38,184 --> 00:02:43,604
with human expert ratings, statistical
validation, verifying correlation with

45
00:02:43,604 --> 00:02:46,969
human reviewers and multi judge consensus.

46
00:02:47,909 --> 00:02:51,390
Multiple models vote
independently to minimize bias.

47
00:02:51,869 --> 00:02:56,219
For example, you might have GT four,
Claude, and Gemini, all judged the same

48
00:02:56,219 --> 00:02:59,219
dialogue and only consensus counts.

49
00:02:59,429 --> 00:03:01,439
That's quality control through diversity.

50
00:03:01,939 --> 00:03:05,839
What LLM as a judge evaluates
our evaluation spans across

51
00:03:05,989 --> 00:03:08,719
four axis semantic accuracy.

52
00:03:09,230 --> 00:03:11,304
Did the AI actually answer what was asked?

53
00:03:11,804 --> 00:03:13,094
Contextual relevance.

54
00:03:13,274 --> 00:03:17,774
Does it remember and respond in
context, safety and compliance.

55
00:03:18,374 --> 00:03:20,594
No toxicity, no hallucinations.

56
00:03:21,094 --> 00:03:24,604
User experience, tone,
helpfulness, and naturalness.

57
00:03:25,104 --> 00:03:28,194
These become quantifiable metrics
you can monitor over time.

58
00:03:28,734 --> 00:03:32,954
Transforming conversation quality
into measurable data, ensuring

59
00:03:32,954 --> 00:03:34,709
reliable bias of our evaluation.

60
00:03:35,655 --> 00:03:38,054
Of course automation
doesn't mean abdication.

61
00:03:38,505 --> 00:03:43,244
We test across demographics and
scenarios to keep surface hidden biases.

62
00:03:43,744 --> 00:03:47,794
We keep transparent scoring rubrics
for auditability, and we use human

63
00:03:47,794 --> 00:03:51,994
in the loop calibration periodically,
ensuring our models stay aligned

64
00:03:51,994 --> 00:03:53,855
with real world expectations.

65
00:03:54,355 --> 00:03:58,350
Bias aware validation isn't just
ethics, it's reliability insurance.

66
00:03:58,850 --> 00:04:01,100
Generative AI for test data creation.

67
00:04:01,999 --> 00:04:04,579
The other half of this
framework is generative qa.

68
00:04:05,569 --> 00:04:09,679
Manually authoring test cases is
slow, and by definition, limited.

69
00:04:10,609 --> 00:04:13,819
Generative AI can produce
millions of realistic, diverse

70
00:04:13,819 --> 00:04:19,159
utterances, paraphrases, adversarial
phrasing, multilingual variables.

71
00:04:19,659 --> 00:04:21,114
It can instantly create.

72
00:04:21,594 --> 00:04:26,844
How much money do I have or show me my
account total, or tell me if I'm broke.

73
00:04:27,344 --> 00:04:28,784
This changes the QA paradigm.

74
00:04:29,504 --> 00:04:34,155
Instead of discovering edge cases after
deployment, we generate them proactively.

75
00:04:34,784 --> 00:04:39,194
This results in faster discovery of
weaknesses before they reach production.

76
00:04:39,694 --> 00:04:42,334
What are the intelligent test
data generation techniques?

77
00:04:43,024 --> 00:04:45,154
We employ several generation strategies.

78
00:04:45,654 --> 00:04:50,534
Multilingual data for global consistency,
semantic paraphrasing, for example,

79
00:04:50,714 --> 00:04:55,844
what's the weather in Paris becomes,
do I need a JAK in Paris today or do

80
00:04:55,844 --> 00:04:57,674
I need an umbrella in Paris today?

81
00:04:58,214 --> 00:05:02,944
Same meaning, but different paraphrasing
or different phrasing, adversarial inputs.

82
00:05:03,604 --> 00:05:07,564
They can be edge cases like book
me the cheapest, non cheap flight.

83
00:05:08,524 --> 00:05:10,704
It's advers adversarial, right?

84
00:05:11,469 --> 00:05:14,699
Or sarcasm sure, because
airlines never delay.

85
00:05:15,269 --> 00:05:16,859
Now this is designed to break logic.

86
00:05:17,789 --> 00:05:21,259
So an intelligent test data
generation technique can

87
00:05:21,259 --> 00:05:23,179
generate such edge cases as well.

88
00:05:23,679 --> 00:05:28,259
Next is noisy utterances, real world
typos and speech errors like, can

89
00:05:28,259 --> 00:05:33,909
you book a flight for tomorrow we can
generate phrases and entrances like this.

90
00:05:34,509 --> 00:05:36,969
Test resilience to imperfect inputs.

91
00:05:37,469 --> 00:05:40,639
The point isn't to trick the
system, it's to make sure it can

92
00:05:40,639 --> 00:05:42,589
handle how humans really speak.

93
00:05:43,089 --> 00:05:46,359
Schema driven prompting
for controlled generation.

94
00:05:46,859 --> 00:05:51,124
To avoid chaos, we use schema driven
prompting, formal definitions for

95
00:05:51,124 --> 00:05:52,619
what kind of test cases to generate.

96
00:05:53,119 --> 00:05:58,459
Each schema specifies intense entities,
languages, tone, and difficulty.

97
00:05:58,959 --> 00:06:01,839
This gives us automation with
precision, the ability to

98
00:06:02,109 --> 00:06:07,209
regenerate consistent test sets for
regression testing across releases.

99
00:06:07,719 --> 00:06:10,509
It's structured creativity, not random

100
00:06:11,009 --> 00:06:12,749
automated annotation and labeling.

101
00:06:13,589 --> 00:06:16,199
Once the data is
generated, it needs labels.

102
00:06:16,874 --> 00:06:20,534
We use the same generative models
to produce expected, intense, and

103
00:06:20,534 --> 00:06:25,114
entities with multimodal consensus
for reliability, low confidence

104
00:06:25,114 --> 00:06:27,064
cases get flagged for human review.

105
00:06:27,124 --> 00:06:32,544
Creating a closed loop system, this means
we can fully automate from data generation

106
00:06:32,544 --> 00:06:37,824
to evaluation dramatically accelerating
QA throughput without losing quality

107
00:06:38,324 --> 00:06:40,634
CI ICD integration for continuous qa.

108
00:06:41,134 --> 00:06:44,104
We plug all of this directly
into the CICD pipeline.

109
00:06:45,064 --> 00:06:48,034
A code commit triggers
generation of fresh test cases.

110
00:06:48,400 --> 00:06:53,374
LLM as a judge evaluates responses,
regression detection, flags, any quality

111
00:06:53,374 --> 00:06:58,384
drop and deployment gating ensures
only validated bills reach production.

112
00:06:58,884 --> 00:07:01,074
This gives us continuous
quality assurance.

113
00:07:01,284 --> 00:07:05,034
It's like a QA that runs 24
7, not just before a release.

114
00:07:05,534 --> 00:07:06,524
What are the benefits?

115
00:07:07,034 --> 00:07:10,064
The payoff is massive, less manual effort.

116
00:07:10,634 --> 00:07:15,164
The models handle the grind
faster release cycles, QA runs

117
00:07:15,164 --> 00:07:17,374
automatically wider coverage.

118
00:07:18,034 --> 00:07:21,834
Generative data explores the long
tail and continuous monitoring.

119
00:07:22,434 --> 00:07:24,384
Every interaction
becomes a quality signal.

120
00:07:25,049 --> 00:07:28,939
It's QA that scales with your
development velocity, not against it.

121
00:07:29,439 --> 00:07:31,309
Tactical implementation insights.

122
00:07:31,809 --> 00:07:33,999
A few lessons from real world deployments.

123
00:07:34,839 --> 00:07:36,939
Start with high impact user journeys.

124
00:07:37,089 --> 00:07:38,919
That's where ROI is highest.

125
00:07:39,419 --> 00:07:43,499
Define quantitative KPIs like
accuracy and safety scores.

126
00:07:44,309 --> 00:07:47,489
Keep humans in the loop,
especially for emerging topics.

127
00:07:47,989 --> 00:07:48,409
Version.

128
00:07:48,409 --> 00:07:50,239
Control your prompts and schemas.

129
00:07:50,839 --> 00:07:55,009
Treat them like production code and
regularly update your judge models to

130
00:07:55,009 --> 00:07:56,959
stay aligned with LLM advancements.

131
00:07:57,459 --> 00:08:01,734
This discipline is what turns research
ideas into production pipelines.

132
00:08:02,234 --> 00:08:04,124
Building Future Ready Testing pipeline.

133
00:08:04,624 --> 00:08:09,964
We are entering an era where AI tests
ai, a self-sustaining QA ecosystem.

134
00:08:10,924 --> 00:08:15,184
By combining automated evaluation
with generative test creation, we

135
00:08:15,184 --> 00:08:17,284
gain both scale and consistency.

136
00:08:17,784 --> 00:08:21,804
It's not just about speed, it's
about trust at scale, ensuring every

137
00:08:21,804 --> 00:08:25,554
conversational AI deployment is
safe, accurate, and user-centric.

138
00:08:26,054 --> 00:08:29,204
This is how we build the next
generation of reliable enterprise

139
00:08:29,204 --> 00:08:30,914
grade conversational systems.

140
00:08:31,414 --> 00:08:35,734
Thank you all, and if your teams are
building or testing conversational ai,

141
00:08:36,034 --> 00:08:38,614
now's the time to let AI help validate ai.

142
00:08:39,544 --> 00:08:44,014
I would like to thank con 40 two.com
for giving me this opportunity to

143
00:08:44,014 --> 00:08:46,174
speak here and have a good day.

144
00:08:46,234 --> 00:08:47,014
Thank you so much.

