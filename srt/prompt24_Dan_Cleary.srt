1
00:00:00,100 --> 00:00:00,600
Hey everyone.

2
00:00:00,600 --> 00:00:01,160
How's it going?

3
00:00:01,510 --> 00:00:03,200
My name is Dan Cleary.

4
00:00:03,200 --> 00:00:05,939
I'm the co founder of PromptHub
and today we will be talking

5
00:00:06,000 --> 00:00:07,470
all about prompt engineering.

6
00:00:07,970 --> 00:00:10,739
We'll talk about why prompt
engineering, is it dead?

7
00:00:11,005 --> 00:00:15,525
system message versus prompt or
user message, how different models

8
00:00:15,525 --> 00:00:18,974
require different types of prompt
and prompting methods, a variety of

9
00:00:18,975 --> 00:00:21,964
different ways that you can try to
get better outputs through prompt

10
00:00:21,964 --> 00:00:24,685
engineering methods, best practices.

11
00:00:25,095 --> 00:00:26,645
Does persona prompting even work?

12
00:00:26,834 --> 00:00:29,855
Meta prompting and a whole bunch of
templates and takeaways throughout.

13
00:00:30,355 --> 00:00:33,595
So I like to start with this question
of like, why prompt engineering?

14
00:00:34,035 --> 00:00:35,355
this was a pretty popular opinion.

15
00:00:35,355 --> 00:00:39,500
I'd say early on that prompt engineering
wasn't really a thing, but I think Over

16
00:00:39,510 --> 00:00:43,300
the months and years since ChatGPT came
out, I think people have found that

17
00:00:43,300 --> 00:00:46,350
it actually can be quite hard to get
the type of output that you're looking

18
00:00:46,350 --> 00:00:48,100
to get from a model consistently.

19
00:00:48,210 --> 00:00:50,790
and that's where kind of prompt
engineering comes into play.

20
00:00:51,290 --> 00:00:54,669
And small changes just end up making
a big difference here, because

21
00:00:54,669 --> 00:00:56,349
of how models latent space works.

22
00:00:56,359 --> 00:00:58,504
So if you say, write a
code to render this image.

23
00:00:59,454 --> 00:01:01,484
write secure code as if you
were John Carmack, which is

24
00:01:01,504 --> 00:01:03,344
like a famous software engineer.

25
00:01:04,024 --> 00:01:07,464
You'll get drastically different
outputs just by those small tweaks.

26
00:01:07,494 --> 00:01:11,184
And I think that will always
be there in some capacity.

27
00:01:11,784 --> 00:01:16,544
you maybe have to do less of the
engineering and method type work

28
00:01:16,544 --> 00:01:18,874
in the future, potentially, but I
think there's always going to be

29
00:01:19,084 --> 00:01:20,504
a small place for this, at least.

30
00:01:21,004 --> 00:01:23,684
Another reason why it's important
is that it's one of the three major

31
00:01:23,684 --> 00:01:26,254
ways to get Better outputs from LLMs.

32
00:01:26,344 --> 00:01:27,484
and it's the starting point.

33
00:01:27,974 --> 00:01:31,034
So you do a bunch of prompt engineering,
you see where you're at, what problems

34
00:01:31,034 --> 00:01:34,404
you're running into and whether
you need to turn to other methods

35
00:01:34,404 --> 00:01:36,344
to solve those remaining problems.

36
00:01:36,844 --> 00:01:39,634
It's just a starting point for a lot
of teams and it's very accessible.

37
00:01:40,279 --> 00:01:42,579
You can be technical, you can
be non technical, and you can

38
00:01:42,579 --> 00:01:44,729
get your, up and running very
quickly with prompt engineering.

39
00:01:45,199 --> 00:01:47,749
And so lastly, you really can't avoid it.

40
00:01:47,749 --> 00:01:51,239
And so for all those reasons, that's
why I believe it's important, at

41
00:01:51,239 --> 00:01:54,469
least for the time being, and I
think into the near future here.

42
00:01:54,969 --> 00:01:59,949
And lastly, in the same way that
having good UI UX product experience

43
00:01:59,979 --> 00:02:01,029
is a competitive advantage.

44
00:02:01,339 --> 00:02:04,589
Having prompts that work
well is a similarly important

45
00:02:04,599 --> 00:02:06,359
competitive advantage for AI teams.

46
00:02:06,859 --> 00:02:11,004
So now we'll talk about the different
types of messages that models can

47
00:02:11,014 --> 00:02:13,514
support, namely system versus user.

48
00:02:14,024 --> 00:02:18,554
So system message, as you can see
here, you are helpful assistant.

49
00:02:18,554 --> 00:02:21,154
Then we have a user message, which
is like the prompt where you're

50
00:02:21,164 --> 00:02:22,504
sending to the model to get an output.

51
00:02:23,014 --> 00:02:23,864
So on and so forth.

52
00:02:24,364 --> 00:02:25,874
System message is optional.

53
00:02:25,914 --> 00:02:27,704
Like when you're doing
these things via the API.

54
00:02:27,974 --> 00:02:33,014
so this is the stuff that you are, is
behind chat GPT's interface in terms

55
00:02:33,014 --> 00:02:35,394
of what open AI has programmed, the.

56
00:02:35,784 --> 00:02:38,614
Chatbot to sound like and
think and so it's optional when

57
00:02:38,614 --> 00:02:39,364
you're sending it via the API.

58
00:02:39,364 --> 00:02:43,034
It's used to set context and rules,
so just the higher level things

59
00:02:43,274 --> 00:02:44,754
versus low level instructions.

60
00:02:45,254 --> 00:02:49,024
So setting the role, context, guiding
the model behavior, controlling

61
00:02:49,024 --> 00:02:51,974
format, things like that, versus
the prompt is where you get more

62
00:02:51,974 --> 00:02:53,844
specific, more of the contextual info.

63
00:02:54,429 --> 00:02:55,869
The focus, so on and so forth.

64
00:02:56,369 --> 00:03:01,259
And we have a couple of examples in the
wild here from companies like OpenAI.

65
00:03:01,689 --> 00:03:04,929
Anthropic also published
theirs, on their documentation.

66
00:03:04,929 --> 00:03:08,029
So you could see the system messages
that power their Claude, chatbots.

67
00:03:08,529 --> 00:03:11,759
And so now we'll talk about how different
models require different prompts.

68
00:03:11,769 --> 00:03:16,299
So if you're interchanging between
providers and even models within the

69
00:03:16,299 --> 00:03:18,889
same provider, you've probably run
into this experience where each of

70
00:03:18,889 --> 00:03:22,049
them has their own differences in
the way they handle tasks and the

71
00:03:22,049 --> 00:03:23,249
way that they sound and respond.

72
00:03:24,064 --> 00:03:26,244
so for example, we'll
take a chain of thought.

73
00:03:26,544 --> 00:03:30,124
so this is thinking step by step,
prompting the model to do some

74
00:03:30,124 --> 00:03:32,654
reasoning before giving an output.

75
00:03:33,094 --> 00:03:37,484
There's an experiment ran where they found
that chain of thought actually reduced

76
00:03:37,674 --> 00:03:42,744
the performance of Palm two, which is, an
older Google model at this point, but just

77
00:03:42,744 --> 00:03:47,864
goes to show that doing what is considered
a best practice didn't help performance.

78
00:03:47,864 --> 00:03:49,724
In this case, it actually
made things worse.

79
00:03:50,224 --> 00:03:53,784
And That just goes to show that one size
is really not going to fit all, which is

80
00:03:53,784 --> 00:03:58,044
the second paper we'll talk about, which
is from VMware, where they basically

81
00:03:58,044 --> 00:04:02,564
tested a wide variety of different prompt
openers, descriptions, and closers.

82
00:04:03,514 --> 00:04:07,344
They put all these prompts together
using all of these different parts here.

83
00:04:07,384 --> 00:04:10,694
Here are a couple examples
of a math dataset with the

84
00:04:10,694 --> 00:04:12,794
various system messages here.

85
00:04:13,294 --> 00:04:15,914
Some have a role, some
don't, so on and so forth.

86
00:04:16,734 --> 00:04:22,234
And what they did was they had the
model generate the best prompt.

87
00:04:22,614 --> 00:04:23,794
for that specific task.

88
00:04:24,294 --> 00:04:27,524
And so they, they let the model decide
and do its own metaprompting based

89
00:04:27,524 --> 00:04:31,204
on the task and the outputs that it
was receiving and so on and so forth.

90
00:04:31,474 --> 00:04:35,944
This was what Llama 2 created and
you could see, it's including kind

91
00:04:35,944 --> 00:04:37,924
of some Star Trek language here.

92
00:04:38,104 --> 00:04:40,914
So this is after running hundreds of
prompts, doing hundreds of metaprompting

93
00:04:40,934 --> 00:04:42,294
in like an experimental way.

94
00:04:42,639 --> 00:04:47,699
setting where there is, a high
degree of statistical significance.

95
00:04:48,199 --> 00:04:52,419
Versus Llama 2, 13b, so same
family, same provider, doesn't know

96
00:04:52,419 --> 00:04:55,749
mention of any Star Trek things,
like it's all very cut and dry.

97
00:04:56,249 --> 00:04:59,099
And then this was pretty popular last
year, this kind of take a deep breath

98
00:04:59,099 --> 00:05:00,529
and work on this problem step by step.

99
00:05:00,529 --> 00:05:05,279
This was a similar experiment where they
had the model figure out a top instruction

100
00:05:05,539 --> 00:05:09,059
for itself, and they ran a bunch of tests
to see which one goes to the top here.

101
00:05:09,059 --> 00:05:11,539
And so they were, this is the
top instruction for the A variety

102
00:05:11,539 --> 00:05:15,559
of different models here, and we
can see GPT's fours is You know,

103
00:05:16,219 --> 00:05:18,439
five times larger than palm twos.

104
00:05:18,439 --> 00:05:22,179
And so it just goes to show that
everything is going to be a little

105
00:05:22,179 --> 00:05:23,519
bit different depending on the model.

106
00:05:23,529 --> 00:05:25,189
And that's why it's important
to test these things.

107
00:05:25,689 --> 00:05:29,909
And if you're looking for more
information on models like max tokens,

108
00:05:29,929 --> 00:05:33,709
context, windows, costs, features, and
functionalities, we have a, directory

109
00:05:33,709 --> 00:05:36,299
that we just launched that has all the
information for basically all the model

110
00:05:36,299 --> 00:05:37,549
providers that are the most popular.

111
00:05:38,049 --> 00:05:42,309
All right So moving on to My two favorite
prompt engineering practices and the

112
00:05:42,309 --> 00:05:46,509
one that we tell the teams that we work
with to focus on is you know giving the

113
00:05:46,509 --> 00:05:51,239
model room to think this is a popular
one and kind of relays into Chain of

114
00:05:51,239 --> 00:05:54,739
thought to a degree you want to let the
model think you don't want to force it

115
00:05:54,759 --> 00:05:57,499
to give an answer Or overly constrain it.

116
00:05:57,819 --> 00:06:00,779
You want it to go through some
sort of reasoning process and

117
00:06:00,779 --> 00:06:01,729
come to an answer on its own.

118
00:06:02,229 --> 00:06:05,399
And then using delimiters or some
way to better structure your prompt.

119
00:06:05,419 --> 00:06:08,029
I can't tell you how many times
I've had a team say, Hey, we're

120
00:06:08,029 --> 00:06:08,819
struggling with this prompt.

121
00:06:08,819 --> 00:06:09,399
Can you look at it?

122
00:06:09,429 --> 00:06:10,569
I look at it and I can't even.

123
00:06:10,919 --> 00:06:11,679
See what's going on.

124
00:06:12,179 --> 00:06:14,529
And so that's a good litmus test
is have someone else look at your

125
00:06:14,529 --> 00:06:17,339
prompts, see if they can organize
it or understand your organization.

126
00:06:18,219 --> 00:06:22,969
And if not start to provide some
of that via, delimiters, backticks,

127
00:06:23,219 --> 00:06:26,529
quotes, whatever is going to
help structure the prompt better.

128
00:06:27,029 --> 00:06:28,629
Now we'll look at a few.

129
00:06:29,129 --> 00:06:33,399
So just to set the stage, a zero
shot prompt is just a normal prompt.

130
00:06:33,409 --> 00:06:36,769
So if you hear that ever referenced, it's
basically just a typical prompt like this.

131
00:06:37,699 --> 00:06:41,309
A few shot prompt is when you include
examples inside of your prompt.

132
00:06:41,669 --> 00:06:44,819
So this would be all one prompt
sent, but we're going to say,

133
00:06:44,869 --> 00:06:46,964
show It's examples in line.

134
00:06:47,034 --> 00:06:49,754
So we're classifying the
sentiment of this feedback.

135
00:06:49,754 --> 00:06:52,384
So this person's positive,
then negative, then positive.

136
00:06:52,384 --> 00:06:55,304
And then we're going to let the model
kind of fill in the, the blank here.

137
00:06:55,804 --> 00:06:59,204
And you could do this
via multiple messages.

138
00:06:59,204 --> 00:07:01,384
So like sending an array
of messages from the API.

139
00:07:01,384 --> 00:07:05,124
And that's typically, I think, technically
what few shop really is rather than

140
00:07:05,124 --> 00:07:06,504
having it all be in one message.

141
00:07:07,474 --> 00:07:10,174
Because the model will handle it
different if it has it in its history

142
00:07:10,184 --> 00:07:11,674
versus reading it all in a prompt.

143
00:07:11,874 --> 00:07:12,894
Both ways are effective.

144
00:07:13,074 --> 00:07:14,164
Both ways are worth testing.

145
00:07:14,664 --> 00:07:18,084
SureShot Prompting is really
helpful in a variety of domains.

146
00:07:18,084 --> 00:07:20,034
It can help with structure.

147
00:07:20,619 --> 00:07:25,939
format, content, style, and tone,
and those are really the really big

148
00:07:26,199 --> 00:07:27,579
areas that I've seen it be helpful.

149
00:07:28,079 --> 00:07:28,949
How many examples?

150
00:07:29,079 --> 00:07:32,929
The great benefit here is that
you get a lot of the gains from

151
00:07:32,929 --> 00:07:35,039
just having one or two examples.

152
00:07:36,019 --> 00:07:38,719
And then it plateaus and can even
degrade in a lot of situations.

153
00:07:38,779 --> 00:07:42,424
we say, hey, start with, Anywhere from
two to five examples, if you're still

154
00:07:42,424 --> 00:07:44,614
not getting the performance you're
looking for, you might need to look

155
00:07:44,624 --> 00:07:48,244
elsewhere because you have the chance of
it starting to degrade, the performance.

156
00:07:49,154 --> 00:07:51,564
A couple of other important,
best practices here.

157
00:07:51,664 --> 00:07:53,314
Use diverse examples.

158
00:07:53,324 --> 00:07:56,184
So if you're doing a sentiment
analysis, don't use only positive ones.

159
00:07:56,684 --> 00:07:57,664
Use a combination.

160
00:07:57,744 --> 00:08:00,414
Have them cover a wide range
of what you are going to be

161
00:08:00,434 --> 00:08:02,024
expecting in your application.

162
00:08:02,304 --> 00:08:03,574
So cover those edge cases.

163
00:08:04,074 --> 00:08:07,064
Random, randomly order them so you
wouldn't have all the positives in one

164
00:08:07,064 --> 00:08:08,104
section and then all the negatives.

165
00:08:08,604 --> 00:08:11,424
And then make sure they follow
a common format so the model can

166
00:08:11,424 --> 00:08:13,594
better learn, in context there.

167
00:08:14,094 --> 00:08:16,954
And we have a whole guide on this as
well, with lots of examples and templates.

168
00:08:17,454 --> 00:08:19,914
Alright, next up is according
to prompting, which is basically

169
00:08:19,914 --> 00:08:24,544
just trying to ground the model
in a specific set of information.

170
00:08:25,184 --> 00:08:28,814
so you can see in this original prompt,
it's asking a question, and then it just

171
00:08:28,814 --> 00:08:30,974
has, adds in according to Wikipedia.

172
00:08:31,894 --> 00:08:35,894
So it's trying to guide the model to the
type of answer that you are looking for.

173
00:08:36,254 --> 00:08:36,784
are looking to.

174
00:08:36,784 --> 00:08:39,654
And this can be helpful, especially
if you've done like some fine tuning.

175
00:08:40,154 --> 00:08:41,254
And here's an example of that.

176
00:08:41,254 --> 00:08:44,394
Again, all the templates are
available in PromptTab under

177
00:08:44,394 --> 00:08:45,894
the templates tab for free too.

178
00:08:46,394 --> 00:08:48,724
And then last one I believe
is called step back prompting.

179
00:08:48,724 --> 00:08:52,964
So this is a very similar kind of, I say,
variant of chain of thought prompting,

180
00:08:53,324 --> 00:08:56,664
where you send a question, you have
the model kind of think step by step

181
00:08:56,774 --> 00:09:03,474
in first kind of abstract concepts, and
then Use those abstractions to reason

182
00:09:03,474 --> 00:09:05,044
through the question or the task.

183
00:09:05,044 --> 00:09:08,294
And so you prompted to do this thinking
first, and this is what you see with a

184
00:09:08,294 --> 00:09:12,734
one preview and a one mini where it thinks
about the step that reasons about them.

185
00:09:12,734 --> 00:09:14,304
And then it solves the problem.

186
00:09:14,804 --> 00:09:17,824
So again, yeah, these are
all linked in prompt up.

187
00:09:17,824 --> 00:09:21,244
So app dot prompt dot U S slash templates.

188
00:09:21,744 --> 00:09:22,204
Last up.

189
00:09:22,224 --> 00:09:25,234
And my favorite one is persona prompting.

190
00:09:25,234 --> 00:09:28,024
So this is like very
popular for a long time now.

191
00:09:28,454 --> 00:09:30,464
so this is like giving the.

192
00:09:30,759 --> 00:09:33,039
the model, a persona to
solve a certain task.

193
00:09:33,539 --> 00:09:37,839
And there are a lot of papers
on both sides of this in

194
00:09:37,839 --> 00:09:39,189
terms of how effective it is.

195
00:09:39,639 --> 00:09:42,669
I have come out to the other side
to thinking it's actually not that

196
00:09:42,669 --> 00:09:44,059
effective in certain use cases.

197
00:09:44,059 --> 00:09:48,089
And the main reason comes
from a learn prompting.

198
00:09:48,239 --> 00:09:50,149
org paper, which is linked here.

199
00:09:50,549 --> 00:09:55,969
I had this intuition that it wasn't
great for doing accuracy based tasks,

200
00:09:55,969 --> 00:09:57,094
and this really reinforced that.

201
00:09:57,994 --> 00:10:00,124
So basically they set up an experiment.

202
00:10:00,134 --> 00:10:08,014
They ran 2000 prompts, and it was a MMLU
case, so like a knowledge based, task, and

203
00:10:08,014 --> 00:10:10,304
they gave a bunch of different roles here.

204
00:10:10,434 --> 00:10:12,464
And really the kind of long
and short of it is that.

205
00:10:12,759 --> 00:10:14,919
The genius when they were told
the model, it was a genius.

206
00:10:15,589 --> 00:10:17,829
It got a lower percentage than
when it told it, it was like an

207
00:10:17,829 --> 00:10:18,909
idiot or something like that.

208
00:10:18,969 --> 00:10:19,239
Yeah.

209
00:10:19,609 --> 00:10:21,489
The genius was actually the
worst performing one here.

210
00:10:21,489 --> 00:10:26,529
And so how can you reconcile that and
still think that role prompting works?

211
00:10:26,579 --> 00:10:27,069
I don't know.

212
00:10:27,329 --> 00:10:30,569
we have to look at other data, but this
seems just pretty strong to rule out

213
00:10:30,569 --> 00:10:31,959
that conclusion and everything else.

214
00:10:31,959 --> 00:10:35,949
I would say it may just be anecdotal,
but it is helpful in terms of,

215
00:10:35,979 --> 00:10:38,029
I would say, Tone and style.

216
00:10:38,049 --> 00:10:42,219
So if you're doing content generation,
things like that, but not for increasing

217
00:10:42,229 --> 00:10:45,619
accuracy, last up, we'll talk a
little bit about meta prompting.

218
00:10:45,639 --> 00:10:47,299
So what's meta prompting.

219
00:10:47,299 --> 00:10:50,719
It's a prompt engineering method that uses
the LLM to help you write your prompt.

220
00:10:50,729 --> 00:10:52,779
So using chat GPT to
help write your prompt.

221
00:10:53,329 --> 00:10:55,659
And we are big proponents of this.

222
00:10:55,959 --> 00:10:59,959
We think this is how prompt engineering
should really be done alongside

223
00:10:59,979 --> 00:11:01,099
the model that you're working with.

224
00:11:01,599 --> 00:11:05,949
And the same way they use, AI and LLMs
for writing and coding, you should

225
00:11:05,949 --> 00:11:07,169
do it for prompt engineering as well.

226
00:11:07,549 --> 00:11:11,149
work together to form a good prompt
for your use case, and then go and test

227
00:11:11,149 --> 00:11:12,799
that, and continue that iterative loop.

228
00:11:13,699 --> 00:11:15,089
And there's a bunch of
tools out there to do this.

229
00:11:15,089 --> 00:11:19,749
We have one that we launched, and
specifically, we will run a different,

230
00:11:19,979 --> 00:11:21,249
Prompt to generate your prompt.

231
00:11:21,269 --> 00:11:24,429
So that meta prompt based on whatever
provider you're using, because as we

232
00:11:24,429 --> 00:11:26,519
saw before, every provider is different.

233
00:11:26,519 --> 00:11:28,569
So we've baked in those
differences into the meta prompt

234
00:11:28,579 --> 00:11:29,669
for each one of the providers.

235
00:11:30,489 --> 00:11:31,569
Leverages best practices.

236
00:11:31,569 --> 00:11:32,089
It's free.

237
00:11:32,129 --> 00:11:33,779
You can use it in our
app without any account.

238
00:11:33,989 --> 00:11:35,049
so that's good to go.

239
00:11:35,239 --> 00:11:39,009
Anthropic was one of the first ones to do
this, and I think they have a really great

240
00:11:39,129 --> 00:11:40,849
grasp on prompt engineering in general.

241
00:11:41,229 --> 00:11:42,919
So you can use this in
the Anthropic console.

242
00:11:42,934 --> 00:11:44,394
A bunch of best practices built in.

243
00:11:44,394 --> 00:11:45,274
It's open source.

244
00:11:45,324 --> 00:11:46,104
it does charge.

245
00:11:46,604 --> 00:11:47,544
that's nominal.

246
00:11:48,314 --> 00:11:51,104
And then OPI actually just
released one, past month or so.

247
00:11:51,604 --> 00:11:54,344
You can use it in the playground and
it generates system messages only.

248
00:11:54,754 --> 00:11:56,144
but it's still usable and fun.

249
00:11:56,144 --> 00:12:00,404
And we did a little bit of prompt
injections to get the prompt behind

250
00:12:00,404 --> 00:12:01,394
that because it wasn't open source.

251
00:12:01,394 --> 00:12:02,844
And so that was really cool to see.

252
00:12:02,844 --> 00:12:07,014
It's always interesting to see how The
model providers are writing prompts.

253
00:12:07,024 --> 00:12:08,414
So that's available in prompt as well.

254
00:12:08,914 --> 00:12:11,714
Wrapping up four things you can do today,
structuring your prompts with headers,

255
00:12:11,714 --> 00:12:13,744
delimiters, that's going to be a big help.

256
00:12:14,734 --> 00:12:16,724
The more specific you are
in your instructions, the

257
00:12:16,724 --> 00:12:17,664
better your prompt will be.

258
00:12:18,044 --> 00:12:19,454
You can throw out all the other methods.

259
00:12:19,504 --> 00:12:22,204
if you can just nail
that part, that's great.

260
00:12:22,214 --> 00:12:25,184
And if you don't nail it, all the other
stuff really isn't going to help you.

261
00:12:25,684 --> 00:12:27,664
Examples of VFU shop
prompting is a great way.

262
00:12:28,229 --> 00:12:31,879
I think metaprompting plus a few shot
plus chain of thought is like really going

263
00:12:31,879 --> 00:12:33,169
to be the winning formula going forward.

264
00:12:33,559 --> 00:12:35,299
and then don't overly constrain the model.

265
00:12:35,799 --> 00:12:36,339
And thank you.

266
00:12:36,339 --> 00:12:37,349
I hope you enjoy this.

267
00:12:37,349 --> 00:12:39,749
If you want to talk about
this, feel free to reach out.

268
00:12:40,009 --> 00:12:42,779
we're active on LinkedIn, and yeah,
have a great rest of your day.

