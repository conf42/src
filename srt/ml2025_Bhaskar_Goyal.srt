1
00:00:00,810 --> 00:00:02,250
Hello everyone, and welcome.

2
00:00:02,610 --> 00:00:05,730
My name is Pascal Goyle and I'm
thrilled to be speaking at contu.

3
00:00:05,730 --> 00:00:10,260
Today we are going to deep dive
into a topic that's crucial for any

4
00:00:10,260 --> 00:00:13,890
organization looking to leverage
artificial intelligence effectively.

5
00:00:14,310 --> 00:00:18,090
That is cloud native AI at
scale architectural patterns

6
00:00:18,270 --> 00:00:19,680
for enterprise success.

7
00:00:19,920 --> 00:00:24,750
In the next 20 minutes, we will explore
how adopting cloud native principles is

8
00:00:24,750 --> 00:00:29,400
t just a trend, but a fundamental shift
that's revolutionizing AI deployment.

9
00:00:29,790 --> 00:00:33,600
As a slide says, these architectures
deliver measurable performance

10
00:00:33,600 --> 00:00:39,269
improvements, faster development cycles,
optimize resource use, and ultimately

11
00:00:39,330 --> 00:00:41,640
a strong return on your AI investments.

12
00:00:41,940 --> 00:00:46,350
We'll walk through the challenges,
the core native concepts, specific

13
00:00:46,350 --> 00:00:51,180
architectural patterns, and the tangible
benefits you can expect, often backed by

14
00:00:51,239 --> 00:00:53,970
industry observations and project results.

15
00:00:55,905 --> 00:00:58,739
Let's start by contrasting
the old way with the new.

16
00:00:59,130 --> 00:01:02,370
Many of us have experienced
traditional AI deployment.

17
00:01:02,760 --> 00:01:07,920
It often involved manual steps, complex
handoffs between data science and

18
00:01:07,920 --> 00:01:13,350
operation teams, and infrastructure that
wasn't purpose built for ML workloads.

19
00:01:13,830 --> 00:01:17,700
This frequently led to the
deployment cycles measured in weeks,

20
00:01:17,820 --> 00:01:22,470
sometimes even in months, plagued
by manual error prone processes.

21
00:01:23,640 --> 00:01:26,370
Now compare that to the
cloud native approach.

22
00:01:26,460 --> 00:01:31,200
By leveraging automation,
containerization, and infrastructure as

23
00:01:31,200 --> 00:01:37,410
a code concepts will detailed shortly,
will dramatically shift deployment times

24
00:01:37,650 --> 00:01:40,680
down to days, hours, or even minutes.

25
00:01:41,220 --> 00:01:44,910
Rollouts become automated
and consistent reducing.

26
00:01:45,570 --> 00:01:47,850
The IT worked on my machine syndrome.

27
00:01:48,390 --> 00:01:53,130
The measurable results often cited in
industry reports and confirmed through

28
00:01:53,130 --> 00:01:55,710
project experience speak for themselves.

29
00:01:56,339 --> 00:02:01,500
Organizations adopting these patterns
typically see around 70% faster

30
00:02:01,500 --> 00:02:04,229
time reproduction for the AI models.

31
00:02:04,800 --> 00:02:08,729
Think about the competitive
advantage that speeds provide.

32
00:02:09,825 --> 00:02:13,635
Furthermore, the automation and
consistency lead to what case

33
00:02:13,635 --> 00:02:16,035
studies show can be staggering.

34
00:02:16,065 --> 00:02:19,305
85% reduction in deployment failure.

35
00:02:20,505 --> 00:02:25,095
This isn't just about speed,
it's about relay reliability and

36
00:02:25,095 --> 00:02:27,225
trust in the deployment process.

37
00:02:29,055 --> 00:02:32,865
A corner store of cloud native
approach is containerization

38
00:02:33,885 --> 00:02:35,535
using technologies like daca.

39
00:02:36,285 --> 00:02:38,175
Why is this so helpful for ai?

40
00:02:38,790 --> 00:02:44,880
First, environment, consistency containers
build the code, bundle the code,

41
00:02:45,420 --> 00:02:47,520
libraries and dependencies together.

42
00:02:47,730 --> 00:02:52,710
This eliminates those frustrating
works on my machine issues and ensures

43
00:02:53,070 --> 00:02:57,930
the environment is identical for a
deployment through two production.

44
00:02:58,530 --> 00:03:03,000
This consistency alone based
on operational data can reduce

45
00:03:03,000 --> 00:03:08,130
deployment failures significantly,
often by as much as 78%.

46
00:03:08,895 --> 00:03:12,255
Second reduced serving latency.

47
00:03:12,375 --> 00:03:16,305
We can build highly optimized
minimal container images

48
00:03:16,605 --> 00:03:18,255
specifically for inference.

49
00:03:18,705 --> 00:03:24,525
This focus cuts down on bloat and
performance benchmarks often show this can

50
00:03:24,525 --> 00:03:31,425
decrease modern inference time by around
35%, leading to a much better and faster

51
00:03:31,425 --> 00:03:33,555
user experience for your AI applications.

52
00:03:33,885 --> 00:03:36,550
Third resource, your isolation.

53
00:03:37,380 --> 00:03:41,580
Containers allow components to run
in isolation, preventing resource

54
00:03:41,580 --> 00:03:45,870
contention when one process hogs
CPU, or memory needed by another.

55
00:03:46,410 --> 00:03:50,790
This isolation also enables
precise independent scaling.

56
00:03:51,090 --> 00:03:54,570
You can scale your inference
service without necessarily scaling

57
00:03:54,600 --> 00:03:56,250
other parts of your application.

58
00:03:56,730 --> 00:04:00,330
Finally, enhance security containers.

59
00:04:00,330 --> 00:04:02,430
Provide isolated runtime environments.

60
00:04:02,775 --> 00:04:08,144
By using minimal base images,
which significantly reduce the

61
00:04:08,144 --> 00:04:12,795
potential attack surface, a widely
recognized security benefit, making

62
00:04:12,795 --> 00:04:14,924
our AI deployments more secure.

63
00:04:17,445 --> 00:04:21,224
Another foundational element is
infrastructure as code, which

64
00:04:21,224 --> 00:04:23,295
is sometimes called as IAZ.

65
00:04:24,344 --> 00:04:28,815
Instead of manually clicking buttons
in a cloud console, we define our

66
00:04:28,815 --> 00:04:30,855
infrastructure servers, networks.

67
00:04:31,605 --> 00:04:35,565
Databases and kuban
Kubernetes clusters in code.

68
00:04:36,405 --> 00:04:39,255
The key is declarative configuration.

69
00:04:39,585 --> 00:04:45,905
We use tools like Terraform or Lummi
to define the desired state of our

70
00:04:45,905 --> 00:04:51,185
infrastructure and the tool configures
out how to achieve that result.

71
00:04:51,455 --> 00:04:56,555
This is much more reliable and repeatable
than writing procedural skills.

72
00:04:56,855 --> 00:04:58,355
Do this and do then that.

73
00:04:59,585 --> 00:05:04,385
These configuration files are version
control, like application code, giving us

74
00:05:04,385 --> 00:05:10,325
transparent change tracking, and ability
to easily roll back if issues arise.

75
00:05:10,835 --> 00:05:14,675
Tools like Terraform also offer
seamless multi-cloud deployments

76
00:05:14,675 --> 00:05:16,805
using a consist syntax.

77
00:05:17,255 --> 00:05:21,635
The business outcome of IAC is
profound for AI infrastructure as

78
00:05:21,635 --> 00:05:23,285
seen across many implementations.

79
00:05:23,600 --> 00:05:28,880
A potential 90% reduction in configuration
drift across environments, ensuring dev,

80
00:05:28,880 --> 00:05:31,130
staging and production look the same.

81
00:05:31,940 --> 00:05:33,215
Often 65%.

82
00:05:33,875 --> 00:05:38,825
Faster disaster recovery because we
can automatically reprovision the

83
00:05:38,825 --> 00:05:41,825
entire infrastructure stack from code.

84
00:05:42,335 --> 00:05:48,815
Experience often shows 42% lower
infrastructure costs through optimization,

85
00:05:49,145 --> 00:05:54,995
eliminating manual provision, zombie
resources, and leveraging automation and

86
00:05:54,995 --> 00:05:58,420
significantly reducing operational toil.

87
00:05:58,925 --> 00:06:03,965
Sometimes 75% fewer manual
interventions needed for routine task.

88
00:06:06,575 --> 00:06:09,755
So the question is, how do
these concepts come together?

89
00:06:09,755 --> 00:06:13,895
In an architecture, a common
effective approach is a layered

90
00:06:13,895 --> 00:06:18,305
architectural pattern, which promotes
decoupling and specialization.

91
00:06:18,305 --> 00:06:23,255
At the top, we have application
layer, which promotes

92
00:06:23,285 --> 00:06:25,295
decoupling and specialization.

93
00:06:26,705 --> 00:06:32,455
At the top below that we, that
sits the ML framework layer.

94
00:06:33,115 --> 00:06:40,375
This is where optimized framework
like TensorFlow or PyTorch, often with

95
00:06:40,405 --> 00:06:45,085
custom accelerated runtimes designed for
high performance or specific hardware.

96
00:06:45,594 --> 00:06:48,775
Then comes container orchestration.

97
00:06:49,135 --> 00:06:52,765
This is typically Kubernetes
managing the lifecycle of our

98
00:06:52,765 --> 00:06:54,354
contained rise application.

99
00:06:54,670 --> 00:06:55,360
And the model.

100
00:06:55,900 --> 00:07:01,540
It handles auto scaling based on load,
ensure high availability, and can

101
00:07:01,540 --> 00:07:06,930
use specialized ML operators like Q
Flow operators, TF job for managing

102
00:07:06,930 --> 00:07:08,760
training and inference workloads.

103
00:07:09,150 --> 00:07:14,370
Finally, the last is the infrastructure
layers, which provides the raw

104
00:07:14,370 --> 00:07:17,850
compute power like machine virtual
machines, bare metal servers.

105
00:07:18,945 --> 00:07:23,445
Which are crucial for ai
sometimes like GPUs, TPU clusters

106
00:07:23,475 --> 00:07:25,035
for accelerated computation.

107
00:07:25,875 --> 00:07:29,655
The beauty of this decoupled
architecture is that each layer can

108
00:07:29,655 --> 00:07:32,175
be scaled and optimized independently.

109
00:07:32,565 --> 00:07:37,965
Project outcomes often demonstrate
benefits like 45%, lower maintenance

110
00:07:37,965 --> 00:07:44,655
cost, 60% improved resource utilization
as each layer is right sized and

111
00:07:44,655 --> 00:07:47,445
greatly enhance operational flexibility.

112
00:07:49,890 --> 00:07:55,860
Within our cloud native AI architecture,
it's critical to recognize that model

113
00:07:55,950 --> 00:08:00,780
training and model inference serving
have very different requirements.

114
00:08:01,320 --> 00:08:04,020
We should design separate
environments for them.

115
00:08:04,530 --> 00:08:08,820
The training environment needs
massive computation power, often

116
00:08:08,820 --> 00:08:11,190
leveraging high powered GPU clusters.

117
00:08:11,460 --> 00:08:14,640
It benefits from the batch
processing optimization.

118
00:08:15,750 --> 00:08:20,610
Admin can use cost saving
strategies like spot instances,

119
00:08:21,060 --> 00:08:23,310
which are interruptible vs.

120
00:08:23,460 --> 00:08:24,330
At lower cost.

121
00:08:24,780 --> 00:08:30,120
Since training jobs can often tolerate
restart, the infrastructure here

122
00:08:30,120 --> 00:08:35,905
can be ephemeral, spun off for a
training run or to down afterwards.

123
00:08:38,865 --> 00:08:42,465
The inference environment, on the
other hand, must be optimized for low

124
00:08:42,465 --> 00:08:45,015
latency to serve predictions quickly.

125
00:08:45,435 --> 00:08:49,395
It requires robust auto-scaling
capabilities to handle

126
00:08:49,395 --> 00:08:51,675
fluctuating request volumes.

127
00:08:52,185 --> 00:08:57,255
Users right size, compute resources
for efficiency, and absolutely needs

128
00:08:57,915 --> 00:09:02,235
a high availability design to ensure
the service is always responsive.

129
00:09:03,495 --> 00:09:06,165
This separation has a
direct business impact.

130
00:09:06,645 --> 00:09:11,025
Frequently observed and optimized
cloud deployments, we often see

131
00:09:11,025 --> 00:09:16,665
35% reduction cloud costs by using
the right resources for each job.

132
00:09:16,995 --> 00:09:21,645
Example, spot for training model
deployment can be 50% faster.

133
00:09:21,735 --> 00:09:25,215
As the inference environment
is streamlined and ready, we

134
00:09:25,215 --> 00:09:28,545
can achieve 99.9% or higher.

135
00:09:28,545 --> 00:09:32,595
Inference service uptime a common
SLA target enabled by HA design

136
00:09:33,465 --> 00:09:35,985
and the system exhibits elasticity.

137
00:09:36,645 --> 00:09:39,944
Scaling automatically
during demand spikes.

138
00:09:40,944 --> 00:09:48,115
As AI models become more complex, numerous
managing the d complex and numerous,

139
00:09:48,385 --> 00:09:53,965
managing the data features they rely
on becoming, becomes a major challenge.

140
00:09:54,325 --> 00:09:56,095
This is where a feature store comes in.

141
00:09:56,695 --> 00:10:01,615
A feature store is a centralized
repository for curated, documented, and

142
00:10:01,615 --> 00:10:04,915
versioned features used in ML models.

143
00:10:05,185 --> 00:10:10,915
It typically involves several components,
feature engineering, standardizing how

144
00:10:10,915 --> 00:10:16,285
features are defined, validated and
transformed through shared pipelines.

145
00:10:16,705 --> 00:10:20,875
Feature storage, maintaining
time, consistent version feature.

146
00:10:21,175 --> 00:10:25,315
Data often with comprehensive
metadata tracking so you can know

147
00:10:25,315 --> 00:10:27,595
exactly what data was used for.

148
00:10:27,595 --> 00:10:28,495
Track training.

149
00:10:29,455 --> 00:10:35,395
Training access, enable, enabling
reproducible model training by allowing

150
00:10:35,725 --> 00:10:42,025
Retriable retrieval of features as
they were at specific points in time.

151
00:10:42,565 --> 00:10:44,035
Point in time, correct.

152
00:10:45,505 --> 00:10:50,365
Inference serving, delivering optimized
low latency feature vectors needed

153
00:10:50,545 --> 00:10:53,275
by models for real-time protections.

154
00:10:53,455 --> 00:10:57,085
Feature stores significantly
accelerate air development.

155
00:10:57,205 --> 00:11:02,665
A benefit highlighted in many M lops case
studies by enabling feature reuse across

156
00:11:02,665 --> 00:11:05,420
team, they eliminate duplicated effort.

157
00:11:05,690 --> 00:11:10,675
They solve the notorious training
service skew problem, which features

158
00:11:11,125 --> 00:11:13,100
used in training differ from production.

159
00:11:14,120 --> 00:11:17,540
And reduce overall
deployment time by about 40%.

160
00:11:18,500 --> 00:11:24,260
Organizations implementing feature
store are often report results like 35%

161
00:11:24,260 --> 00:11:28,910
faster time to market for new models,
and a 60% improvement around operational

162
00:11:28,910 --> 00:11:32,000
efficiency related to feature management.

163
00:11:34,130 --> 00:11:35,330
We mentioned Kubernetes earlier.

164
00:11:36,050 --> 00:11:39,380
Let's look at some specific
Kubernetes organization patterns

165
00:11:39,410 --> 00:11:41,180
that are particularly valuable.

166
00:11:41,435 --> 00:11:46,685
For AI ML workloads, the first one
is custom resource definitions,

167
00:11:46,685 --> 00:11:48,245
sometimes called as CRDs.

168
00:11:49,325 --> 00:11:54,935
Kubernetes allows us to define our
own custom types for ml. This means

169
00:11:54,995 --> 00:12:00,245
resources like TF Job or Python job
that understand the specifics of running

170
00:12:00,245 --> 00:12:04,985
distributed training jobs or custom
resources for managing model deployments.

171
00:12:05,975 --> 00:12:10,055
This enables a declarative approach
to managing the ML lifecycle itself.

172
00:12:11,390 --> 00:12:18,800
Operators, these automate complex
stateful operations, ML operators

173
00:12:18,980 --> 00:12:23,510
can manage the entire lifecycle of
the ml machine learning, workflow,

174
00:12:23,780 --> 00:12:28,100
provisioning resources, running
training, deploying models, monitoring,

175
00:12:28,375 --> 00:12:30,105
codifying operational knowledge.

176
00:12:31,115 --> 00:12:33,800
Third is the horizontal pod auto scaling.

177
00:12:34,670 --> 00:12:38,960
This automatically scales the number
of pods, containers based on metrics

178
00:12:38,960 --> 00:12:45,170
like CP utilization, request volume,
or even metrics like GPA utilization.

179
00:12:46,190 --> 00:12:49,910
This ensures inference services
have the right amount of

180
00:12:49,910 --> 00:12:51,680
resources in the real time.

181
00:12:53,120 --> 00:12:55,130
Fourth is a service mesh integration.

182
00:12:55,730 --> 00:13:00,860
Example is issue a service mesh
provides advanced capabilities

183
00:13:00,860 --> 00:13:02,840
like fine-grain traffic routing.

184
00:13:03,230 --> 00:13:09,350
Essential for carrying deployment,
candry deployments or AB testing models.

185
00:13:09,800 --> 00:13:15,050
Mutual DLS for security and detailed
observability metrics, latency

186
00:13:15,050 --> 00:13:17,000
error rates across services.

187
00:13:17,870 --> 00:13:22,790
These patterns turn Kubernetes
into a powerful ML aware platform,

188
00:13:22,790 --> 00:13:24,800
enhancing automation and control

189
00:13:27,290 --> 00:13:28,640
AI particularly.

190
00:13:29,480 --> 00:13:32,630
Particularly deep learning
heavily relies on specialized

191
00:13:32,630 --> 00:13:34,340
hardware like GPUs and TPUs.

192
00:13:34,850 --> 00:13:38,720
Effectively orchestrating these
expensive resources is critical

193
00:13:39,140 --> 00:13:40,670
in a cloud native environment.

194
00:13:41,810 --> 00:13:47,000
So the first is the GPU and TPU
management Kubernetes device plugin

195
00:13:47,090 --> 00:13:49,970
allow fine-grained hardware allocation.

196
00:13:50,630 --> 00:13:54,230
Advanced schedulers can enable
multi-tenant GPU sharing

197
00:13:54,710 --> 00:13:56,180
with some implementation.

198
00:13:56,825 --> 00:14:00,755
Showing utilization increase to
three X compared to the dedicated,

199
00:14:01,265 --> 00:14:04,835
dedicating a whole GP to one
task performance optimizations.

200
00:14:05,495 --> 00:14:09,965
Techniques like numa aware scheduling
according to performance tuning

201
00:14:09,965 --> 00:14:12,845
guides can improve throughput by 40%.

202
00:14:12,905 --> 00:14:18,125
Similarly, using mixed precision
inference often reduces latency by

203
00:14:18,125 --> 00:14:23,680
60% with minimal accuracy loss as
documented in frameworks, best practices.

204
00:14:25,955 --> 00:14:27,185
Cost optimization.

205
00:14:27,245 --> 00:14:31,655
In integrating spot instances
for training workloads.

206
00:14:31,745 --> 00:14:37,085
A common cloud saving strategy can
slash training costs by up to 70%.

207
00:14:37,565 --> 00:14:43,175
Furthermore, automatic hardware
hibernation spinning down expensive

208
00:14:43,175 --> 00:14:48,935
GPUs TPUs when idle project experience
shows that it can be saved around 45%

209
00:14:48,935 --> 00:14:52,865
on idle costs, which is crucial given
how expensive these accelerators are.

210
00:14:53,780 --> 00:14:58,070
Intelligent orchestration ensures
we get the maximum performance and

211
00:14:58,070 --> 00:14:59,990
value from our hardware investments.

212
00:15:02,540 --> 00:15:07,220
Bringing all of this together requires
robust automation, which leads us

213
00:15:07,220 --> 00:15:10,610
to ML lops and CI ICD pipeline,
tailored for machine learning.

214
00:15:11,000 --> 00:15:14,630
ML OPS applies DevOps
principles to the ML lifecycle.

215
00:15:15,470 --> 00:15:19,910
CICD pipelines are the backbone
of ML ops continuous integration.

216
00:15:20,315 --> 00:15:22,535
This isn't just about code anymore.

217
00:15:22,565 --> 00:15:28,685
For ml, it involves automated model
testing, unit testing, integration tests,

218
00:15:28,925 --> 00:15:33,965
data validation, model validation against
predefined metrics and quality gates.

219
00:15:34,535 --> 00:15:38,525
It often integrates with code
model repositories via web hooks.

220
00:15:39,035 --> 00:15:43,955
We need automated checks for unit
tests, model quality metrics, and even

221
00:15:43,955 --> 00:15:46,025
security scanning for dependencies.

222
00:15:47,750 --> 00:15:52,910
Continuous delivery focuses on automating
the preparation for deployment.

223
00:15:53,330 --> 00:15:59,810
It includes packaging the model and core
code o often in two containers, generating

224
00:15:59,810 --> 00:16:05,060
environment specific configurations like
Kubernetes, helm charts and versioning.

225
00:16:05,160 --> 00:16:11,010
All artifacts produce continuous
deployment, automates the actual

226
00:16:11,040 --> 00:16:12,780
rollout of the model to production.

227
00:16:13,260 --> 00:16:16,500
We use progressive deployment
strategies like blue-green deployment,

228
00:16:16,500 --> 00:16:21,000
switching traffic to a new version
or caning releases routing a

229
00:16:21,000 --> 00:16:23,310
small percentage of traffic first.

230
00:16:23,940 --> 00:16:29,730
Automated analysis for of performance
metrics and roll back capabilities are

231
00:16:29,730 --> 00:16:32,520
crucial here for ensure to ensure safety.

232
00:16:32,940 --> 00:16:37,050
These pipelines central to
ML lops maturity models.

233
00:16:37,530 --> 00:16:37,980
Ensure.

234
00:16:38,805 --> 00:16:40,185
Moving from code.

235
00:16:40,185 --> 00:16:45,315
Commit to a validated deployed model
is fast, reliable, and repeatable.

236
00:16:46,315 --> 00:16:48,025
Deployment is in the end of the story.

237
00:16:48,325 --> 00:16:52,405
Models degrade over time due to changes
in their data patterns sometimes.

238
00:16:52,405 --> 00:16:53,095
What has drift?

239
00:16:53,815 --> 00:16:54,475
Automating?

240
00:16:54,475 --> 00:16:58,105
Monitoring solutions are essential for
maintaining performance and production.

241
00:16:58,795 --> 00:17:02,455
Cloud native monitoring tools
integrated with ML platform

242
00:17:02,455 --> 00:17:03,900
provide critical capabilities.

243
00:17:05,410 --> 00:17:07,720
First is the faster drift detection.

244
00:17:08,050 --> 00:17:12,130
Advanced algorithms continuously
monitor input data and model

245
00:17:12,130 --> 00:17:16,750
protections, detecting data drift
and model drift in near real time.

246
00:17:17,230 --> 00:17:20,890
This allows for immediate corrective
action like retraining before

247
00:17:20,890 --> 00:17:22,300
performance degrades significantly.

248
00:17:23,165 --> 00:17:27,700
Reports suggests improvements of up
to 85% in detection speed compared

249
00:17:27,700 --> 00:17:30,250
to manual checks system of time.

250
00:17:30,910 --> 00:17:35,650
A fault tolerant monitoring architecture
potentially with predictive maintenance

251
00:17:35,650 --> 00:17:41,200
alerts helps ensure continuous operation
even during infrastructure clips

252
00:17:41,410 --> 00:17:47,885
contributing to a 99.95% or higher
system uptime that many platforms aim for

253
00:17:49,960 --> 00:17:51,100
resource optimization.

254
00:17:51,760 --> 00:17:57,790
Intelligent monitoring feeds back
into the resource allocation by

255
00:17:57,880 --> 00:18:00,010
observing actual workload patterns.

256
00:18:00,325 --> 00:18:05,215
Dynamic adjustment can significantly
reduce cloud expenditure.

257
00:18:05,965 --> 00:18:09,415
Practical results often
show reduction around 40%.

258
00:18:10,765 --> 00:18:16,015
ROI multiplier crucially, end-to-end
monitoring connects ML performance

259
00:18:16,015 --> 00:18:19,735
metrics directly with business
key performance indicators.

260
00:18:20,215 --> 00:18:25,480
This allows organizations to clearly
see the value of AI is delivering and

261
00:18:25,510 --> 00:18:27,560
optimized models based on business impact.

262
00:18:28,285 --> 00:18:31,045
Effectively acting as an ROI multiplier.

263
00:18:31,495 --> 00:18:36,415
Some case studies indicate this can
potentially triple the return on

264
00:18:36,415 --> 00:18:39,805
AI investments by ensuring models
stay relevant and performant.

265
00:18:40,805 --> 00:18:45,605
So to wrap up, adopting cloud
native architectural patterns is

266
00:18:45,605 --> 00:18:50,435
fundamental for achieving AI success
at scale with the enterprise.

267
00:18:51,575 --> 00:18:53,315
We have seen how containerization.

268
00:18:54,200 --> 00:18:58,550
Infrastructure as code layered
architecture, separating training

269
00:18:58,550 --> 00:19:03,230
and inference feature stores,
Kubernetes orchestration, hardware

270
00:19:03,230 --> 00:19:08,150
management, ML ops, pipelines, and
automated monitoring work together.

271
00:19:08,630 --> 00:19:14,780
The key to takeaways are the tangible
benefits widely reported across

272
00:19:14,780 --> 00:19:20,480
industry, dramatically accelerated
deployment cycles, improved resource

273
00:19:20,480 --> 00:19:22,310
utilization and cost savings.

274
00:19:23,465 --> 00:19:29,315
Enhance reliability and security and
ultimately a much stronger and more

275
00:19:29,315 --> 00:19:31,445
measurable return on your AI investment.

276
00:19:32,405 --> 00:19:34,805
Thank you very much for your
time and attention today.

277
00:19:35,285 --> 00:19:39,455
I hope this overview of cloud
native AI patterns was valuable.

278
00:19:40,025 --> 00:19:42,950
Please feel free to
correct me on LinkedIn.

279
00:19:43,035 --> 00:19:46,275
If you have any questions, my
contacts are on the screen.

280
00:19:46,725 --> 00:19:47,775
Thank you so much.

