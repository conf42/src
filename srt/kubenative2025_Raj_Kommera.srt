1
00:00:00,500 --> 00:00:05,330
Hello everyone, and thank you for
tuning into Con 42 Cube, native 2 0 2 5.

2
00:00:06,020 --> 00:00:09,640
My name is Raku and I'm a principal
Salesforce engineer and platform

3
00:00:09,640 --> 00:00:14,410
architect, where I lead the design of
large scale AI powered enterprise systems.

4
00:00:14,770 --> 00:00:19,240
Over the last decade, I've worked
across organizations like Intel Trucks

5
00:00:19,244 --> 00:00:24,130
and Zenefit Building, event driven and
modular and highly scalable architecture.

6
00:00:25,029 --> 00:00:28,090
What brings me here today is a
growing concern I've witnessed across

7
00:00:28,090 --> 00:00:32,260
industries, AI systems that are
powerful, but fundamentally untrusted.

8
00:00:32,800 --> 00:00:36,250
In this session, we are going to
explore practical framework I call

9
00:00:36,760 --> 00:00:41,710
cube Native Trust, an approach that
blends architectural design, ative,

10
00:00:41,799 --> 00:00:43,749
native tooling, and transparency.

11
00:00:43,749 --> 00:00:48,400
First thinking to make AI systems
not only powerful, but respectable,

12
00:00:49,150 --> 00:00:51,189
explainable, and ultimately reliable.

13
00:00:51,639 --> 00:00:52,180
Let's dive in.

14
00:00:52,680 --> 00:00:54,120
Here's what we'll cover in this session.

15
00:00:54,449 --> 00:00:58,529
We'll start by excluding the
trust challenge, why even accurate

16
00:00:58,529 --> 00:01:01,470
air recommendations of will
fail in enterprise settings.

17
00:01:01,859 --> 00:01:05,039
Then we'll introduce five
architectural pillars that will

18
00:01:05,039 --> 00:01:06,930
make AI systems more transparent.

19
00:01:07,560 --> 00:01:11,910
Trustworthy, everything from
confidence scoring to audit tools.

20
00:01:12,449 --> 00:01:16,380
Next, I'll walk through a practical
implementation blueprint using

21
00:01:16,380 --> 00:01:20,940
Kubernetes native tools like
SAO, GitHub and Open Telemetry

22
00:01:21,330 --> 00:01:23,220
to operationalize this framework.

23
00:01:24,060 --> 00:01:26,100
We'll also look at
realtime world use cases.

24
00:01:26,190 --> 00:01:30,090
And finally, I'll leave you with
actionable takeaways you can use to start

25
00:01:30,090 --> 00:01:33,120
building trust into your own AI workflows.

26
00:01:33,620 --> 00:01:34,520
Trust challenge.

27
00:01:34,525 --> 00:01:38,265
AI has incredible potential,
but in enterprise environments,

28
00:01:38,265 --> 00:01:42,195
we often see a pattern users
ignore those recommendations.

29
00:01:42,435 --> 00:01:42,825
Why?

30
00:01:43,185 --> 00:01:45,164
Because they can't see how it works.

31
00:01:45,615 --> 00:01:49,039
They can scrutinize the logic, trace
the data, or evaluate certainty.

32
00:01:49,620 --> 00:01:50,480
So despite.

33
00:01:51,149 --> 00:01:52,110
Millions invested.

34
00:01:52,259 --> 00:01:53,669
These tools end up sidelined.

35
00:01:54,509 --> 00:01:57,179
The real challenge isn't in prediction.

36
00:01:57,210 --> 00:01:58,410
It's transparency.

37
00:01:58,949 --> 00:02:03,000
If stakeholders can't validate what
they are seeing, trust breaks down.

38
00:02:03,269 --> 00:02:06,150
And without trust, even the
most advanced models become

39
00:02:06,650 --> 00:02:08,780
why enterprise AI is sidelined.

40
00:02:09,280 --> 00:02:12,850
Let's break down exactly why AI fails
to gain traction in the enterprise.

41
00:02:13,329 --> 00:02:14,470
Lack of transparency.

42
00:02:15,040 --> 00:02:16,780
Most models act like black boxes.

43
00:02:16,840 --> 00:02:18,559
No insight into how
their decisions are made.

44
00:02:19,059 --> 00:02:20,079
Missing context.

45
00:02:20,409 --> 00:02:23,859
AI doesn't often adapt to business
realities like regulatory limits or

46
00:02:23,859 --> 00:02:26,529
budgets, thresholds or workflow quirks.

47
00:02:27,429 --> 00:02:28,569
Insufficient observability.

48
00:02:29,069 --> 00:02:31,049
We can trace inputs back to predictions.

49
00:02:31,109 --> 00:02:33,869
What means you can't
add audit or debug you?

50
00:02:34,785 --> 00:02:37,665
And finally, the big one,
trust gap between teams.

51
00:02:38,054 --> 00:02:41,594
Engineers build the model, data
scientists optimize it, but

52
00:02:41,594 --> 00:02:45,855
businesses use user business users
don't understand or trust it.

53
00:02:46,394 --> 00:02:48,644
Fixing the gaps starts
with the architecture.

54
00:02:49,144 --> 00:02:51,124
Trust is a first class
architectural concern.

55
00:02:51,874 --> 00:02:54,814
Five foundational design
pillars for transparent ai.

56
00:02:55,314 --> 00:02:58,554
Pillar one, contextualized
confidence scoring.

57
00:02:59,054 --> 00:03:02,114
Not every prediction is equally
reliable and users know that.

58
00:03:02,264 --> 00:03:07,184
So instead of flat confidence score,
give them monthly dimensional insights.

59
00:03:07,664 --> 00:03:10,244
How confident is the model
for this specific context?

60
00:03:10,664 --> 00:03:14,594
And how does this prediction
compare to similar past scenarios?

61
00:03:15,074 --> 00:03:17,204
And how should the user
interpret the score?

62
00:03:18,014 --> 00:03:22,994
By mapping the confidence to their
mental model and you make the AI action

63
00:03:23,084 --> 00:03:24,734
output actionable and trustworthy.

64
00:03:25,234 --> 00:03:26,344
Digital pillar two.

65
00:03:27,094 --> 00:03:28,354
Source traceability.

66
00:03:29,224 --> 00:03:32,794
Imagine you handled a recommendation
and you want to know where it came from.

67
00:03:33,304 --> 00:03:38,104
With traceability, you can answer what
data is used, how it's processed, what

68
00:03:38,104 --> 00:03:42,779
features did the model rely on, and where
were there any business rules applied?

69
00:03:43,139 --> 00:03:48,209
This is like turning on the version
history for every decision your AI makes.

70
00:03:48,719 --> 00:03:52,709
It's essential for auditability,
for governance and user confidence.

71
00:03:53,209 --> 00:03:54,319
Adaptive thresholds.

72
00:03:55,129 --> 00:03:57,679
Most AI systems use static thresholds.

73
00:03:57,799 --> 00:04:02,989
The only active conference is greater
than 70%, but that's rigid and naive.

74
00:04:03,529 --> 00:04:07,519
What you really want is adaptive
thresholds that respond to use

75
00:04:07,519 --> 00:04:11,359
case criticality, operational
constraints, risk tolerance.

76
00:04:12,049 --> 00:04:15,409
A 60% confident prediction might
be acceptable for marketing,

77
00:04:15,979 --> 00:04:17,059
but not for healthcare.

78
00:04:17,749 --> 00:04:18,709
Adaptability is the key.

79
00:04:19,209 --> 00:04:20,920
Progressive UI disclosure.

80
00:04:21,420 --> 00:04:25,140
Not every user needs the full
more internals, but some do.

81
00:04:25,920 --> 00:04:30,120
That's why Progressive
disclosure works level one.

82
00:04:30,810 --> 00:04:35,940
Simple summary plus confidence score
level two, key drivers and alternatives.

83
00:04:36,240 --> 00:04:39,659
Level three, full
lineage model parameters.

84
00:04:40,110 --> 00:04:41,070
Future importance.

85
00:04:41,415 --> 00:04:44,085
It's like an expandable explanation panel.

86
00:04:44,625 --> 00:04:47,745
Let the user choose how deep they
want to go without overwhelming them.

87
00:04:48,245 --> 00:04:50,765
Pillar five, end-to-end audit trails.

88
00:04:51,275 --> 00:04:57,474
Finally, the unit verifiable logs
for what was predicted, why and when.

89
00:04:58,044 --> 00:05:02,604
This means immutable logs, open
telemetry integration, human

90
00:05:02,604 --> 00:05:05,125
feedback capture outcome validation.

91
00:05:05,784 --> 00:05:08,674
Most importantly,
compliance ready reports.

92
00:05:09,214 --> 00:05:12,124
This isn't just a nice to
have for many industries.

93
00:05:12,124 --> 00:05:12,904
It's a requirement.

94
00:05:13,404 --> 00:05:15,744
Now let's talk about
implementation blueprint.

95
00:05:16,244 --> 00:05:18,135
Let's move from theory to practice.

96
00:05:18,674 --> 00:05:21,044
How do we build these trust features?

97
00:05:21,830 --> 00:05:23,594
Kubernetes gives us the right foundation.

98
00:05:24,315 --> 00:05:27,854
It is scalable, it is observable,
and it integrates with the

99
00:05:27,854 --> 00:05:30,825
most modern CI CD pipelines.

100
00:05:31,325 --> 00:05:32,645
We'll use that to our base

101
00:05:33,145 --> 00:05:34,914
kuber implementation.

102
00:05:35,905 --> 00:05:42,684
Here's how each pillar maps to kuber
tools service mesh, like ECO or linker

103
00:05:43,465 --> 00:05:48,744
to capture model traffic latency and
trace requests, GI tops like agro or

104
00:05:48,744 --> 00:05:54,015
flux version control for models, trace,
which version did what opened Elementary.

105
00:05:54,480 --> 00:05:58,370
Unified tracing from infrastructure
to business outcomes will be

106
00:05:58,370 --> 00:06:03,640
or to enforce governance, adapt
threshold and secure the pipelines.

107
00:06:04,150 --> 00:06:07,630
Together, these tools,
operations operationalize trust.

108
00:06:08,130 --> 00:06:12,770
Now reference architecture it brings
all together in it's a modular

109
00:06:12,770 --> 00:06:15,930
system where confidence scoring
is computed in microservices.

110
00:06:16,430 --> 00:06:20,490
Traceability is insured via
version pipelines, and the

111
00:06:20,490 --> 00:06:21,780
thresholds are policy driven.

112
00:06:21,930 --> 00:06:26,220
The UI exposes layered explanations
and auditors log everything

113
00:06:26,310 --> 00:06:27,450
from prediction to outcome.

114
00:06:27,990 --> 00:06:29,640
This is trust by design.

115
00:06:30,140 --> 00:06:32,480
Let's move on to real
world application examples.

116
00:06:32,580 --> 00:06:35,320
Let's make this tangible
customer segmentation.

117
00:06:35,755 --> 00:06:40,345
Explanations include why a user fails into
that, falls into that segment with visual

118
00:06:40,345 --> 00:06:43,585
metrics, leads, routing, sales steps.

119
00:06:43,585 --> 00:06:47,425
Can you know, trace why the lead
was prioritized so that improves

120
00:06:47,425 --> 00:06:51,645
adoption, patient risk scoring,
clinical UIs, expose risk factors,

121
00:06:51,945 --> 00:06:53,745
thresholds and scoring logic.

122
00:06:54,735 --> 00:06:59,055
Infrastructure optimization resource
scaling decisions come with the

123
00:06:59,055 --> 00:07:01,725
cost, context and past patterns.

124
00:07:02,295 --> 00:07:04,905
These systems aren't just
smart, they can be trusted.

125
00:07:05,405 --> 00:07:07,685
So the key trust was here.

126
00:07:07,925 --> 00:07:10,055
If you remember one thing
from this session, it's this.

127
00:07:10,355 --> 00:07:12,455
Trust is architecture.

128
00:07:12,695 --> 00:07:14,405
Build it in, don't bolt onto it.

129
00:07:14,495 --> 00:07:15,785
Trust requires design.

130
00:07:16,280 --> 00:07:21,110
Confidence traceability, auditability
Use Kubernetes tools to implement it.

131
00:07:21,610 --> 00:07:26,830
Progressive disclosure empowers users
trails, ensure accountability feedback

132
00:07:26,830 --> 00:07:28,330
loops enable continuous improvement.

133
00:07:28,830 --> 00:07:31,710
Let's get started with
the trust blueprint.

134
00:07:32,210 --> 00:07:35,210
If you're ready to bring this to
your team, here's how to start.

135
00:07:35,990 --> 00:07:37,610
Audit your transparency gaps.

136
00:07:37,940 --> 00:07:40,700
Map mental models to explanation needs.

137
00:07:41,480 --> 00:07:43,160
Add confidence according to one model.

138
00:07:44,000 --> 00:07:45,770
Start tracing with open telemetry.

139
00:07:46,040 --> 00:07:47,600
Add feedback loops into ui.

140
00:07:47,900 --> 00:07:48,680
Start small.

141
00:07:48,890 --> 00:07:50,060
Build trust, scale.

142
00:07:50,060 --> 00:07:50,330
Smart.

143
00:07:50,830 --> 00:07:51,310
Thank you.

