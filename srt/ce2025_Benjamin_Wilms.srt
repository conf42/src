1
00:00:00,390 --> 00:00:01,290
Welcome everyone.

2
00:00:01,470 --> 00:00:05,470
I'm excited to be here today to talk
about how to build reliable systems

3
00:00:05,520 --> 00:00:07,330
under unpredictable conditions.

4
00:00:07,880 --> 00:00:10,680
A challenge that every
engineering team faces.

5
00:00:11,559 --> 00:00:15,549
We will explore smart approaches in
chaos engineering, observability and

6
00:00:15,570 --> 00:00:20,719
incident management and how they can
work together to create resilient systems

7
00:00:20,929 --> 00:00:23,630
that can withstand real world failures.

8
00:00:24,520 --> 00:00:26,540
Throughout this session, we will discuss.

9
00:00:27,190 --> 00:00:31,550
Practical strategies and tools,
including SteadyBit that help teams

10
00:00:31,570 --> 00:00:35,630
proactively uncover weaknesses,
strengthens reliability, and ensure

11
00:00:35,639 --> 00:00:40,600
both systems and organizations are
prepared for unexpected disruptions.

12
00:00:41,280 --> 00:00:42,009
Let's dive in.

13
00:00:42,509 --> 00:00:43,509
My name is Benjamin.

14
00:00:43,569 --> 00:00:47,009
I'm one of the founder of SteadyBit,
a chaos engineering platform.

15
00:00:47,429 --> 00:00:50,369
I started with chaos engineering
around nine years ago.

16
00:00:50,789 --> 00:00:54,919
And with SteadyBit, we are in, in,
in that space since five years.

17
00:00:55,419 --> 00:00:57,959
Setting the scene, let's dive in.

18
00:00:58,459 --> 00:01:00,569
Let's start with an important question.

19
00:01:01,089 --> 00:01:02,179
What do we strive for?

20
00:01:02,549 --> 00:01:06,699
What goal does each of us
pursue every day in our work?

21
00:01:07,499 --> 00:01:10,579
In other words, what is the
mission of software development?

22
00:01:11,079 --> 00:01:15,829
When we write code, deploy applications,
or optimize systems, we are all

23
00:01:15,839 --> 00:01:17,369
working towards something bigger.

24
00:01:18,234 --> 00:01:20,964
But what is that overarching, purpose?

25
00:01:21,344 --> 00:01:25,214
Is it about delivering features
or is there something deeper?

26
00:01:25,714 --> 00:01:31,014
The mission of software development at
its core is to continuously improving

27
00:01:31,024 --> 00:01:36,294
and delivering a software solution
that provides real value to its users.

28
00:01:36,794 --> 00:01:41,204
Software isn't just about writing
code or deploying applications.

29
00:01:41,544 --> 00:01:43,464
It's a living, evolving entity.

30
00:01:43,964 --> 00:01:45,784
The best software is never done.

31
00:01:46,334 --> 00:01:50,634
It adapts, improves, and
meets users needs over time.

32
00:01:51,134 --> 00:01:53,684
But achieving this mission isn't simple.

33
00:01:54,184 --> 00:01:58,904
There are challenges, complexity,
changing changing requirements,

34
00:01:59,214 --> 00:02:04,424
reliability concerns, and that's why we
need to focus on not just on building

35
00:02:04,454 --> 00:02:10,174
a software, but on building resilient,
maintainable, and user centric software.

36
00:02:10,674 --> 00:02:14,164
Now, why does this continuous
improvement matter?

37
00:02:14,664 --> 00:02:19,564
Because customer, customers trust a
system when it's consistently good

38
00:02:19,584 --> 00:02:22,074
in both quality and performance.

39
00:02:22,574 --> 00:02:25,844
It's not enough for software
to work well from time to time.

40
00:02:26,664 --> 00:02:32,124
Users expect reliability, Stability,
every single time they interact with it.

41
00:02:32,914 --> 00:02:39,684
If a system is fast today, but slow
tomorrow, or if it works well in some

42
00:02:39,684 --> 00:02:43,314
cases, but fault in others, trust erodes.

43
00:02:43,814 --> 00:02:48,314
And once the trust is lost,
it's incredibly hard to regain.

44
00:02:49,064 --> 00:02:53,084
So as engineers, our job
isn't just to build features.

45
00:02:53,704 --> 00:02:57,264
it's to ensure that those
features work predictably.

46
00:02:57,784 --> 00:03:00,514
Reliably, under real world conditions.

47
00:03:01,014 --> 00:03:02,264
Why is it so hard?

48
00:03:02,764 --> 00:03:07,184
Now, let's talk about one
of the biggest challenges we

49
00:03:07,184 --> 00:03:09,234
face in achieving reliability.

50
00:03:10,004 --> 00:03:10,824
Complexity.

51
00:03:11,154 --> 00:03:14,864
The complexity of today's
systems is massive.

52
00:03:15,444 --> 00:03:16,964
And it's only growing.

53
00:03:16,965 --> 00:03:17,625
think about.

54
00:03:18,175 --> 00:03:20,085
How modern applications are built.

55
00:03:20,385 --> 00:03:24,275
We are no longer dealing with
monolithic, self contained systems.

56
00:03:24,935 --> 00:03:30,155
Instead, we have distributed
architectures, microservices, cloud

57
00:03:30,155 --> 00:03:36,585
platforms, third party dependencies,
and constantly evolving infrastructures.

58
00:03:37,085 --> 00:03:40,075
This complexity makes our job even harder.

59
00:03:40,645 --> 00:03:43,835
It's no longer just about writing code.

60
00:03:44,330 --> 00:03:49,560
It's about understanding how all
the moving parts interact, fail, and

61
00:03:49,570 --> 00:03:51,720
fingers crossed, hopefully recover.

62
00:03:52,220 --> 00:03:56,610
But wait, when we talk about a
system, are we all talking about

63
00:03:56,610 --> 00:03:58,530
the same definition of a system?

64
00:03:59,030 --> 00:04:01,880
Let's have a look at the, at
the definition of a system

65
00:04:02,380 --> 00:04:03,360
from my point of view.

66
00:04:03,860 --> 00:04:05,480
Of course, There is software.

67
00:04:05,730 --> 00:04:10,360
There is something we have created,
but it needs to deploy it on

68
00:04:10,360 --> 00:04:11,840
some infrastructure hardware.

69
00:04:12,340 --> 00:04:17,440
People are needed to build, maintain, and
operate such software and infrastructure.

70
00:04:17,940 --> 00:04:20,840
There is a pipeline, there is a
build process, there is something

71
00:04:20,960 --> 00:04:25,690
how we can really create and deliver
the applications and software.

72
00:04:26,190 --> 00:04:28,120
All that is done inside
of an organization.

73
00:04:28,620 --> 00:04:32,800
Which means also there are
processes and many more components.

74
00:04:33,270 --> 00:04:39,990
So it's quite complex and a lot of
stuff is going on in such a system.

75
00:04:40,100 --> 00:04:46,140
And now we also must continuously improve
our systems, not just to add new features,

76
00:04:46,500 --> 00:04:52,690
but to make them more fail safe and
capable of handling failures gracefully.

77
00:04:53,190 --> 00:04:55,285
And to be honest, That's freaking hard.

78
00:04:55,955 --> 00:04:57,365
And one thing must be clear.

79
00:04:58,275 --> 00:05:02,835
We will never have a 100
percent error free system.

80
00:05:03,335 --> 00:05:09,635
No matter how much testing we do,
no matter how many best practices

81
00:05:09,635 --> 00:05:12,345
we follow, failures will happen.

82
00:05:13,165 --> 00:05:14,125
Servers will crash.

83
00:05:14,955 --> 00:05:15,935
Networks will lag.

84
00:05:16,285 --> 00:05:17,559
Dependencies will break.

85
00:05:18,500 --> 00:05:24,360
So instead of chasing this impossible
dream of a failure proof system, we

86
00:05:24,500 --> 00:05:26,950
should focus on building resilience

87
00:05:27,450 --> 00:05:31,080
by using chaos engineering and
the power of chaos engineering.

88
00:05:31,580 --> 00:05:35,040
You all know the definition of chaos
engineering, so nothing new in here.

89
00:05:35,540 --> 00:05:36,200
Let's continue.

90
00:05:36,700 --> 00:05:40,960
But as mentioned earlier, the
definition of a system is much

91
00:05:40,980 --> 00:05:42,430
more than just technology.

92
00:05:42,930 --> 00:05:47,690
The term socio technical
system expresses it very well.

93
00:05:48,080 --> 00:05:49,540
It's not just technology.

94
00:05:49,750 --> 00:05:54,670
It's a combination of people,
processes, and tools working together

95
00:05:54,700 --> 00:05:56,550
to produce a specific outcome.

96
00:05:57,050 --> 00:06:00,330
This means failures
aren't just software bugs.

97
00:06:01,250 --> 00:06:06,140
They can come from misconfigurations,
human errors, unexpected

98
00:06:06,140 --> 00:06:11,490
interactions between services or
even misaligned team processes.

99
00:06:11,990 --> 00:06:17,180
Chaos Engineering helps us
proactively test, learn, and improve.

100
00:06:17,570 --> 00:06:22,810
we are not just reacting to failures
when they happen, but anticipating

101
00:06:22,810 --> 00:06:28,400
when, then anticipating them and
strengthening our systems in advance.

102
00:06:29,130 --> 00:06:31,420
We are getting into
something more proactive.

103
00:06:31,920 --> 00:06:35,920
Let's now take a look at such
a socio technical system and

104
00:06:35,920 --> 00:06:37,170
how it evolves over time.

105
00:06:37,670 --> 00:06:41,650
This simple website shows the result
of a collaboration between many

106
00:06:41,650 --> 00:06:43,790
different people and technologies.

107
00:06:44,710 --> 00:06:48,930
I would like to address the question
of what and who is needed to build

108
00:06:48,930 --> 00:06:50,490
and operate this online shop.

109
00:06:50,990 --> 00:06:54,930
Starting on the right hand side,
we now see the individual services

110
00:06:55,670 --> 00:06:59,000
that are needed to operate the
shop on the left hand side.

111
00:06:59,500 --> 00:07:03,450
Let's group the elements by
the, yeah, let's say subject

112
00:07:03,490 --> 00:07:05,990
area to get a better overview.

113
00:07:06,490 --> 00:07:10,360
It's not getting better or it's still
quite complex and many moving parts.

114
00:07:10,860 --> 00:07:14,940
These components are provided by
more than one team or one person.

115
00:07:15,700 --> 00:07:21,040
And they require coordinated interaction
between the individual teams for the

116
00:07:21,080 --> 00:07:26,920
overarching common goal to provide
the customer with a functioning

117
00:07:27,290 --> 00:07:32,810
system at all times with consistency,
good in quality and performance.

118
00:07:33,310 --> 00:07:35,310
But it gets even more complex.

119
00:07:35,780 --> 00:07:40,070
Within the teams, people work together
to build and operate this online shop.

120
00:07:40,900 --> 00:07:44,840
There's a lot of interaction between
the teams and each individual

121
00:07:44,880 --> 00:07:47,090
person is interacting as well.

122
00:07:48,000 --> 00:07:52,380
So it is difficult to keep everyone
in the loop and to keep this

123
00:07:52,410 --> 00:07:54,770
constantly changing system stable.

124
00:07:55,270 --> 00:08:00,210
Now that we are all clear on the
preconditions and now the whole system,

125
00:08:00,320 --> 00:08:02,120
let's get into the subject in detail.

126
00:08:02,620 --> 00:08:05,580
So I want to increase
the systemic resilience.

127
00:08:05,940 --> 00:08:10,650
And there are three phases needed
and we have to go through to ensure

128
00:08:10,650 --> 00:08:15,020
that our system constantly delivers
good quality and performance.

129
00:08:15,850 --> 00:08:19,870
Let's go through the phases one by one
and discuss how we proceed in them.

130
00:08:20,370 --> 00:08:21,180
Uncover risk.

131
00:08:21,240 --> 00:08:21,780
First one.

132
00:08:22,140 --> 00:08:25,439
Let's talk about how we identify
and address system vulnerabilities.

133
00:08:26,340 --> 00:08:27,130
Vulnerabilities.

134
00:08:28,070 --> 00:08:31,510
One of the key challenges in modern
distributed systems, especially

135
00:08:31,510 --> 00:08:36,080
in Kubernetes environments, is
understanding where the risk is.

136
00:08:36,750 --> 00:08:41,120
Dependencies, misconfigurations,
or weak points in redundancy

137
00:08:41,360 --> 00:08:42,860
can all lead to failures.

138
00:08:43,360 --> 00:08:45,840
This is where SteadyBits
approach comes in.

139
00:08:46,230 --> 00:08:50,290
By analyzing system configuration,
we can uncover hidden risk and

140
00:08:50,290 --> 00:08:54,060
provide precise recommendations
to enhance system robustness.

141
00:08:54,560 --> 00:08:58,660
What you see here is a risk analyze,
highlighting potential weak spots.

142
00:08:59,000 --> 00:09:04,300
Red areas indicate a critical issue
that could impact availability, while

143
00:09:04,310 --> 00:09:06,770
green areas show resilient components.

144
00:09:07,200 --> 00:09:09,085
with this analysis, kind of insight.

145
00:09:09,265 --> 00:09:13,055
We are not just reacting to failures,
we are getting ahead of them, we are

146
00:09:13,695 --> 00:09:15,735
turning it into a proactive approach.

147
00:09:16,235 --> 00:09:18,365
Phase number two, understand impact.

148
00:09:18,865 --> 00:09:22,545
Once we have identified hidden
risks, the next step is to verify

149
00:09:22,575 --> 00:09:27,015
our resilience strategy to ensure our
system can truly withstand disruptions.

150
00:09:27,515 --> 00:09:31,284
This is where chaos engineering
experiments can We don't just assume

151
00:09:31,284 --> 00:09:33,534
that our redundancy measures work.

152
00:09:33,944 --> 00:09:38,484
We test them under real world
conditions before failures happen.

153
00:09:38,984 --> 00:09:42,404
Here on the picture, you can
see an experiment focused

154
00:09:42,424 --> 00:09:46,654
on validating Kubernetes pot
redundancy across AWS zones.

155
00:09:47,624 --> 00:09:50,644
The system, or SteadyBit,
flags a potential risk.

156
00:09:51,144 --> 00:09:55,714
Pots are distributed across zones,
but we still need to verify if

157
00:09:55,714 --> 00:09:57,369
an outage in one zone is valid.

158
00:09:57,829 --> 00:10:00,229
Impacts our performance and quality.

159
00:10:00,729 --> 00:10:04,919
The best part about, these
experiments don't disrupt production.

160
00:10:05,189 --> 00:10:10,119
They are controlled, observable, and
measurable early in the development cycle.

161
00:10:10,209 --> 00:10:14,509
Helping teams build confidence
in their infrastructure before

162
00:10:14,599 --> 00:10:16,019
they deploy into production.

163
00:10:16,020 --> 00:10:18,867
Want to get a real demo?

164
00:10:18,867 --> 00:10:19,816
Real example?

165
00:10:19,816 --> 00:10:21,714
Let's jump into SteadyBit.

166
00:10:22,214 --> 00:10:25,774
Now, on the right side, again, you
can see like this bubble with all

167
00:10:25,774 --> 00:10:27,094
the moving parts from the system.

168
00:10:28,054 --> 00:10:30,914
I would like to do again, a grouping.

169
00:10:30,944 --> 00:10:36,684
So I would like to group the elements by
the deployment name of Kubernetes, just

170
00:10:36,694 --> 00:10:38,904
to get a better picture about the system.

171
00:10:39,404 --> 00:10:42,674
And now I want to identify a
potential risk in my system.

172
00:10:42,894 --> 00:10:45,434
So I can do that with some colors.

173
00:10:46,264 --> 00:10:49,554
I can ask SteadyBit, please color
all the elements on the right side

174
00:10:50,054 --> 00:10:51,474
by the zone they are running in.

175
00:10:51,974 --> 00:10:55,904
In total, SteadyBit now tells me,
okay, you're running in two zones.

176
00:10:56,404 --> 00:11:01,754
And with just one look, I can identify
Toy's Best Seller is distributed across

177
00:11:01,784 --> 00:11:04,374
two zones, checkout service as well.

178
00:11:05,154 --> 00:11:10,104
But here in the center, orders or our
hot deal service isn't distributed

179
00:11:10,104 --> 00:11:11,644
across all the zones you are running in.

180
00:11:12,434 --> 00:11:19,594
This is already a risk, and I was able to
identify this without any need of running

181
00:11:19,594 --> 00:11:21,724
experiments or so, just based on the data.

182
00:11:22,224 --> 00:11:26,104
doing one step back, grouped
by all the deployments.

183
00:11:26,804 --> 00:11:30,504
Now, I'm using SteadyBuild
and the Advice feature.

184
00:11:31,004 --> 00:11:35,314
help me to filter in my, yeah, in
my moving targets on the right side.

185
00:11:35,744 --> 00:11:40,254
And SteadyBit is now able to tell me
where a potential risk is already.

186
00:11:40,644 --> 00:11:45,584
So getting in again in the checkout
service, SteadyBit tells me,

187
00:11:45,654 --> 00:11:47,254
okay, here are some orange ones.

188
00:11:47,284 --> 00:11:48,184
So what's going on?

189
00:11:49,064 --> 00:11:54,134
Let's get into this
example, the pod deployment.

190
00:11:54,804 --> 00:12:00,484
So an advice by Steadybit was, Hey,
you should run this in, in, in, with

191
00:12:00,484 --> 00:12:02,944
more instances and how to fix this.

192
00:12:03,004 --> 00:12:07,974
Hey, here takes a snippet and
reconfigure your elements.

193
00:12:08,474 --> 00:12:12,084
This is already something
where, yeah, Steadybit can help

194
00:12:12,084 --> 00:12:16,084
me to identify something, can
help me to improve my system.

195
00:12:16,574 --> 00:12:19,834
And last element to verify.

196
00:12:19,874 --> 00:12:21,094
Now, if this.

197
00:12:21,844 --> 00:12:24,424
is something which already
fixed the situation.

198
00:12:24,764 --> 00:12:29,604
So there is an experiment created based
on the data SteadyBit has discovered.

199
00:12:30,094 --> 00:12:31,784
And that's just one example.

200
00:12:32,064 --> 00:12:33,694
So let's zoom in.

201
00:12:34,354 --> 00:12:38,834
What SteadyBit is doing here right now
is, first of all, there's a pre check.

202
00:12:38,854 --> 00:12:41,164
SteadyBit will check if
all the pods are ready.

203
00:12:41,324 --> 00:12:44,294
If not, don't execute this
experiment because the system

204
00:12:44,334 --> 00:12:45,344
isn't in a healthy state.

205
00:12:46,264 --> 00:12:50,684
Next, we will simulate a pod
failure of the checkout service.

206
00:12:51,074 --> 00:12:53,014
So we will delete a specific pod.

207
00:12:53,594 --> 00:12:57,884
And then our expectation is, first
of all, we want to see that this

208
00:12:57,944 --> 00:13:03,374
pod is failing, but also that it's
returning in a couple of seconds.

209
00:13:03,374 --> 00:13:04,474
So just a minute.

210
00:13:05,064 --> 00:13:08,794
So our expectation is, even if there's
one pod, the system under test is

211
00:13:08,804 --> 00:13:10,604
still working and is recovering.

212
00:13:11,104 --> 00:13:14,844
Getting back to the slides, because
now we can execute this experiment.

213
00:13:15,344 --> 00:13:16,364
same experiment.

214
00:13:16,864 --> 00:13:19,984
But this time it's, just
with the fashion bestseller.

215
00:13:20,324 --> 00:13:21,734
So pre check was done.

216
00:13:21,854 --> 00:13:22,824
Everything is fine.

217
00:13:22,844 --> 00:13:27,524
Now we are injecting the delete pot
attack, and then we want to see the pot

218
00:13:27,534 --> 00:13:31,294
is coming back after, within 60 seconds.

219
00:13:31,474 --> 00:13:35,884
If not, the experiment will fail and we
already identified the risk in the system.

220
00:13:36,804 --> 00:13:40,634
It's now just been executing on
fast forward to save some time.

221
00:13:41,134 --> 00:13:44,264
Steadybit is also collecting
some internals about Kubernetes.

222
00:13:44,294 --> 00:13:45,894
So Kubernetes events are coming in.

223
00:13:46,274 --> 00:13:50,134
I'm getting some information about the
deployment readiness and everything

224
00:13:50,134 --> 00:13:51,904
is getting in one central report.

225
00:13:52,404 --> 00:13:53,944
Four, three seconds left.

226
00:13:53,954 --> 00:13:54,644
Here we go.

227
00:13:54,824 --> 00:13:57,594
Experiment was successful in the end.

228
00:13:57,595 --> 00:14:02,954
So first job done.

229
00:14:03,794 --> 00:14:04,604
We are quite okay.

230
00:14:05,274 --> 00:14:07,844
Now let's get into the second part.

231
00:14:08,344 --> 00:14:12,404
We have established the preconditions,
understanding systems complexity,

232
00:14:12,724 --> 00:14:18,524
uncovering vulnerabilities or risks, and
verify, the resilience more proactively.

233
00:14:19,024 --> 00:14:22,964
It's time to deep, dive deeper
into this subject, subject, sorry.

234
00:14:23,494 --> 00:14:29,824
So let's shift our focus now from Why we
should do it into more how we can do it.

235
00:14:30,054 --> 00:14:33,334
So how we can apply these principles
in practice, run meaningful

236
00:14:33,334 --> 00:14:38,304
experiments, and truly enhance the
system resilience in our organization.

237
00:14:38,484 --> 00:14:39,924
And that's on another level.

238
00:14:40,124 --> 00:14:42,554
It's not only on the
technical side of things.

239
00:14:43,054 --> 00:14:47,684
Now we are, yeah, we want to increase
the systemic resilience of our

240
00:14:47,684 --> 00:14:51,504
organization, which is like the last
element, the last building block.

241
00:14:52,004 --> 00:14:55,754
We have already done the hard work
of improving our system's resilience,

242
00:14:55,804 --> 00:15:00,374
identifying weaknesses, validating
redundancies, and running experiments

243
00:15:00,374 --> 00:15:02,314
to strengthen our technical setup.

244
00:15:03,094 --> 00:15:06,434
But there is still one
crucial question left.

245
00:15:07,264 --> 00:15:10,764
How will our teams respond
when things go wrong?

246
00:15:11,264 --> 00:15:16,454
Even the most robust systems
can, can't prevent all failures.

247
00:15:17,084 --> 00:15:22,914
What really determines success is how
well the organization, our people and

248
00:15:22,914 --> 00:15:25,074
processes can react under pressure.

249
00:15:25,574 --> 00:15:28,594
This is where socio technical
resilience comes in.

250
00:15:29,414 --> 00:15:33,604
It's not just about the technology,
it's about how different teams

251
00:15:33,654 --> 00:15:38,074
interact, coordinate and make
decisions when things break.

252
00:15:38,574 --> 00:15:44,004
The unpleasant feeling of
uncertainty, of knowing how well we

253
00:15:44,004 --> 00:15:46,124
will handle an incident, is real.

254
00:15:47,094 --> 00:15:49,944
And the best way to
eliminate that uncertainty?

255
00:15:50,574 --> 00:15:51,214
We test it.

256
00:15:51,984 --> 00:15:57,394
We simulate incidents, we practice
responses, and we ensure that

257
00:15:57,414 --> 00:16:01,374
our organization is just as
resilient as our technology.

258
00:16:02,154 --> 00:16:04,714
Now you can see how both
worlds are coming together.

259
00:16:05,214 --> 00:16:09,034
What you see here are two
complex systems on the left

260
00:16:09,044 --> 00:16:11,524
hand and one on the right hand.

261
00:16:11,864 --> 00:16:15,964
But what's important to understand is
that both are essential to running and

262
00:16:16,174 --> 00:16:18,444
operating a truly resilient system.

263
00:16:18,944 --> 00:16:23,094
On left we have the technical system,
the architecture, infrastructure and

264
00:16:23,094 --> 00:16:25,634
software that, that power our application.

265
00:16:26,134 --> 00:16:28,904
On the right, we have the
organizational system.

266
00:16:29,804 --> 00:16:35,564
It's a team's communication channels,
processes that ensure smooth operations

267
00:16:35,674 --> 00:16:41,644
when incidents occur and that are helping
us to keep our systems up and running.

268
00:16:42,144 --> 00:16:43,244
So now.

269
00:16:43,744 --> 00:16:49,374
Let's jump into another demo and see
how a tool like Steadybit can help you

270
00:16:49,524 --> 00:16:54,254
harness the power of chaos engineering
to measure and improve the reliability

271
00:16:54,274 --> 00:16:58,834
of both systems and organizations,
of both systems and organizations.

272
00:16:59,334 --> 00:17:04,094
There was, let's assume there was an
incident a while ago, and with all

273
00:17:04,094 --> 00:17:08,754
the data from the incident, we were
able to identify a specific scenario.

274
00:17:08,754 --> 00:17:12,484
Let's The scenario I'm talking
about is a latency spike in one

275
00:17:12,494 --> 00:17:17,864
of the backend services called Hot
Deals, followed by a total outage

276
00:17:17,884 --> 00:17:19,884
of the central gateway component.

277
00:17:20,264 --> 00:17:23,424
So this was really like a cascading
error, something went wrong in the

278
00:17:23,434 --> 00:17:28,994
backend, but still it also went wrong
in the, in, in the, earlier stages

279
00:17:28,994 --> 00:17:32,974
of the system, earlier, elements of
the system in the gateway component.

280
00:17:33,674 --> 00:17:38,594
My expectation, or in other words, my
hypothesis is I want to see that our

281
00:17:38,594 --> 00:17:46,044
monitoring recognizes the scenario within
90 seconds and reports it to the relevant

282
00:17:46,144 --> 00:17:51,194
team on call, we are using PagerDuty,
and that the incident has been opened

283
00:17:51,354 --> 00:17:53,774
and acknowledged within three minutes.

284
00:17:54,274 --> 00:17:55,594
That's the first element.

285
00:17:55,604 --> 00:17:59,904
That is something I need to see from my
system, but also for my organization.

286
00:18:00,134 --> 00:18:00,584
But then.

287
00:18:01,504 --> 00:18:06,274
Getting more on the technical side
of things, the technical system, the

288
00:18:06,284 --> 00:18:11,634
system normalized within three minutes
and the incident and our on call team,

289
00:18:12,174 --> 00:18:16,464
determined that the resilience system
has recovered and is working normally.

290
00:18:16,804 --> 00:18:19,074
So the incident is resolved
within four minutes.

291
00:18:19,234 --> 00:18:21,654
So you can now really
see both, both worlds.

292
00:18:21,654 --> 00:18:27,164
It's a technical system where we have
implemented, yeah, resilience patterns.

293
00:18:28,159 --> 00:18:33,749
So that our system can recover from
failures, but also on the other side,

294
00:18:33,809 --> 00:18:38,439
our organization, our teams, our
people that are able to understand

295
00:18:38,439 --> 00:18:41,509
what's going on and how they should
react under those conditions.

296
00:18:42,009 --> 00:18:46,309
And to truly strengthen our organization's
resilience, we need to focus on the

297
00:18:46,309 --> 00:18:51,759
interaction, not just within teams, but
also between the tools and platforms

298
00:18:51,759 --> 00:18:53,889
that keep everything running smoothly.

299
00:18:54,389 --> 00:19:00,479
Here, we see three key players,
PagerDuty, Datadog, and SteadyBit.

300
00:19:01,109 --> 00:19:05,749
PagerDuty helps us orchestrate
incident response, ensuring the right

301
00:19:05,809 --> 00:19:08,209
people are alerted at the right time.

302
00:19:09,089 --> 00:19:11,739
Datadog provides observability.

303
00:19:12,259 --> 00:19:16,379
giving us real time insights into
system performance and failure patterns.

304
00:19:16,849 --> 00:19:21,849
And finally, SteadyBit brings in
chaos engineering, allowing us to

305
00:19:21,869 --> 00:19:27,029
proactively test, validate, and
strengthen both our technical and

306
00:19:27,279 --> 00:19:29,499
organizational response strategies.

307
00:19:29,999 --> 00:19:35,369
And by integrating these tools, We
create a holistic approach to resilience

308
00:19:35,769 --> 00:19:41,679
where we don't just detect failures,
but also understand, react, and

309
00:19:41,759 --> 00:19:45,429
ultimately prevent from impacting users.

310
00:19:46,369 --> 00:19:49,779
And yeah, resilience isn't
about a single tool or strategy.

311
00:19:50,139 --> 00:19:55,939
It's about making sure everything and
everyone works together seamlessly

312
00:19:56,489 --> 00:19:59,129
to handle whatever comes our way.

313
00:19:59,489 --> 00:19:59,939
All right.

314
00:20:00,439 --> 00:20:02,189
Getting into the details and the timeline.

315
00:20:03,144 --> 00:20:09,094
everything will start with a latency
spike in our Hot Deals service, followed

316
00:20:09,114 --> 00:20:11,604
by an outage of our gateway component.

317
00:20:12,104 --> 00:20:16,784
We want to see this event or the,
yeah, the failures in our monitoring

318
00:20:16,804 --> 00:20:19,444
tool, Datadog, within 90 seconds.

319
00:20:19,944 --> 00:20:25,414
Datadog will call PagerDuty, that there
is something wrong, and will trigger the

320
00:20:25,864 --> 00:20:32,124
An incident, PagerDuty knows who's on
call and will, yeah, notify those people.

321
00:20:32,624 --> 00:20:39,494
We want to see that those people on call
are jumping in, getting first insights and

322
00:20:39,684 --> 00:20:42,454
doing an acknowledgement of the incident.

323
00:20:42,954 --> 00:20:46,354
Then getting back on the technical
side of things and our resilience

324
00:20:46,384 --> 00:20:48,284
and reliability patterns.

325
00:20:48,574 --> 00:20:50,634
The system is able to recover.

326
00:20:51,134 --> 00:20:56,344
It's turning into an okay status back,
which has been recognized by Datadog.

327
00:20:56,854 --> 00:21:02,694
And this will also, this also means that
our team is able to see this improvement.

328
00:21:02,694 --> 00:21:04,404
So the system is back to normal.

329
00:21:04,724 --> 00:21:07,264
So the incident needs
to be resolved as well.

330
00:21:07,764 --> 00:21:09,114
A lot of stuff is going on.

331
00:21:09,954 --> 00:21:13,774
Let's get in, in, in something
before we start into the experiment.

332
00:21:14,434 --> 00:21:15,584
Something very important.

333
00:21:16,254 --> 00:21:18,464
It's, I don't like finger pointing.

334
00:21:18,554 --> 00:21:19,634
And it's about.

335
00:21:20,074 --> 00:21:23,934
Testing how fast it's not about
testing how fast an individual

336
00:21:23,984 --> 00:21:25,334
person fixes an outage.

337
00:21:26,214 --> 00:21:31,904
It's really about how good the
organization is at detecting and fixing

338
00:21:31,904 --> 00:21:36,934
faults and how to processes and all
the and how processes are coordinated.

339
00:21:37,434 --> 00:21:43,014
So now it's time to zoom in and see, take
a look at the experiment we will run.

340
00:21:43,514 --> 00:21:43,884
Okay.

341
00:21:44,384 --> 00:21:44,624
First.

342
00:21:45,124 --> 00:21:49,734
SteadyBit is integrated with Datadog
and we will check as a pre check if

343
00:21:49,794 --> 00:21:51,444
the system is in a healthy state.

344
00:21:51,664 --> 00:21:53,754
If not, don't execute this experiment.

345
00:21:54,664 --> 00:22:00,994
Next, SteadyBit will inject latency in
all hot deal services, followed by a

346
00:22:01,004 --> 00:22:03,154
total outage of the gateway component.

347
00:22:03,944 --> 00:22:09,079
And then, our expectation in the
hypothesis is After 90 seconds,

348
00:22:09,129 --> 00:22:12,189
there needs to be an alert in
our monitoring tool data talk.

349
00:22:12,239 --> 00:22:14,319
So we want to see this alert coming in.

350
00:22:14,819 --> 00:22:17,009
This alert needs to trigger an incident.

351
00:22:17,269 --> 00:22:22,519
We will, we are integrated with
PagerDuty from SteadyBits point of view.

352
00:22:23,039 --> 00:22:25,899
And we can check if there
is an incident triggered.

353
00:22:26,759 --> 00:22:29,569
If so, everything okay,
everything as designed.

354
00:22:30,409 --> 00:22:32,999
Now, our system is able to recover.

355
00:22:33,499 --> 00:22:35,619
It's getting back into an okay status.

356
00:22:36,459 --> 00:22:37,439
So far, so good.

357
00:22:37,689 --> 00:22:42,309
But also, we are checking again
in PagerDuty if someone on call

358
00:22:42,379 --> 00:22:45,929
is jumping into that incident
and is doing some search about

359
00:22:45,949 --> 00:22:47,519
what's going on to get insights.

360
00:22:48,019 --> 00:22:52,339
If the system is stable back
in an okay status, the incident

361
00:22:52,339 --> 00:22:53,429
should have been resolved.

362
00:22:53,829 --> 00:22:58,429
And that is something again, we will
check inside automatically in PagerDuty.

363
00:22:59,349 --> 00:23:01,509
And that's this experiment
we will execute now.

364
00:23:01,769 --> 00:23:05,799
You can really see how many interactions
are needed to really see if this process

365
00:23:05,809 --> 00:23:08,009
is designed right and working as needed.

366
00:23:08,509 --> 00:23:10,069
So here we go.

367
00:23:10,569 --> 00:23:13,699
Let's take a look at the recording
of this experiment, because normally

368
00:23:13,709 --> 00:23:15,049
it takes about five minutes.

369
00:23:15,549 --> 00:23:17,519
So prechecks are executed.

370
00:23:17,989 --> 00:23:20,789
Data doc has been, yeah,
integrated inside of Steadybit.

371
00:23:21,159 --> 00:23:24,059
So we can ask the system
if everything is fine.

372
00:23:24,879 --> 00:23:30,109
At the bottom of that screen, you can see
like a little green bar, it's coming up.

373
00:23:30,339 --> 00:23:33,489
This tells us that the status is okay.

374
00:23:33,989 --> 00:23:35,749
And we are checking it
for a couple of seconds.

375
00:23:35,759 --> 00:23:37,159
So it's not just a one shot.

376
00:23:37,209 --> 00:23:40,269
It's really like for a specific time
we want to see everything is okay.

377
00:23:40,269 --> 00:23:46,989
Now Steadybit is injecting the
latency followed by a total

378
00:23:47,049 --> 00:23:48,949
outage of the gateway component.

379
00:23:49,449 --> 00:23:53,089
The expectation now is after 90 seconds,
we are in the fast forward mode.

380
00:23:53,549 --> 00:23:56,379
We want to see an alert inside of Datadog.

381
00:23:56,549 --> 00:23:58,299
So we are calling again Datadog.

382
00:23:58,379 --> 00:24:01,139
Hey, the status needs to be alert.

383
00:24:01,639 --> 00:24:04,109
And you can see a red bar
is coming up at the bottom.

384
00:24:05,029 --> 00:24:08,529
And also we are now checking PagerDuty
if there is an incident triggered.

385
00:24:09,489 --> 00:24:12,499
And we found an incident
related to that outage.

386
00:24:12,999 --> 00:24:15,069
Now, again, the outage is gone.

387
00:24:15,069 --> 00:24:16,249
System should recover.

388
00:24:16,289 --> 00:24:21,949
And we want to see after some
seconds that first of all, someone

389
00:24:21,989 --> 00:24:24,019
is jumping in the incident.

390
00:24:24,029 --> 00:24:25,949
So the incident needs to be acknowledged.

391
00:24:26,539 --> 00:24:31,389
And we want also to see that Datadog is
able to see that the system is able to

392
00:24:31,389 --> 00:24:35,919
recover and that the status of the system
is turning back into an okay status.

393
00:24:36,419 --> 00:24:37,419
Monitoring is okay.

394
00:24:37,419 --> 00:24:39,299
Now you're scrolling down.

395
00:24:39,299 --> 00:24:39,839
You can see the bar.

396
00:24:40,339 --> 00:24:44,209
And now, last element, now
the system is back to normal.

397
00:24:45,049 --> 00:24:50,839
The incident needs to be resolved,
maybe by data doc automatically inside

398
00:24:50,839 --> 00:24:52,869
of PagerDuty or by someone on call.

399
00:24:53,669 --> 00:24:58,329
And now our scenario is successful because
our system was able to handle it and

400
00:24:58,449 --> 00:25:03,009
the people on call were able to react
as needed, so they are well trained.

401
00:25:03,059 --> 00:25:06,009
Let's quickly recap what
we have covered today.

402
00:25:06,839 --> 00:25:09,889
We started by defining the
mission of software development.

403
00:25:10,389 --> 00:25:13,689
Delivering continuous value
while ensuring reliability.

404
00:25:14,169 --> 00:25:14,439
It's hard.

405
00:25:14,439 --> 00:25:16,379
It's not about just features.

406
00:25:16,879 --> 00:25:20,089
We saw that complexity is massive.

407
00:25:20,699 --> 00:25:25,969
Failures are inventable and
trust is built on consistent

408
00:25:25,979 --> 00:25:27,939
good quality and performance.

409
00:25:28,649 --> 00:25:31,399
And to, yeah.

410
00:25:32,299 --> 00:25:36,379
recover from a bad outage is
quite hard to get the trust from

411
00:25:36,389 --> 00:25:37,859
the customers back is very hard.

412
00:25:38,619 --> 00:25:43,169
So to tackle this, we explored chaos
engineering as a way to uncover

413
00:25:43,169 --> 00:25:47,659
weaknesses in both technical and
organizational systems called socio

414
00:25:47,659 --> 00:25:52,319
technical systems, helping us verify
resilience before failures happen.

415
00:25:52,369 --> 00:25:57,139
And we are all, we did this every
time in a, not in production,

416
00:25:57,169 --> 00:25:58,919
in a early stage environment.

417
00:25:59,419 --> 00:26:04,839
And finally, we saw how a tool like
SteadyBit empowers team to test,

418
00:26:05,059 --> 00:26:10,099
validate, and strengthens both the
infrastructure and their response

419
00:26:10,129 --> 00:26:11,719
strategy on the organization level.

420
00:26:12,189 --> 00:26:17,059
So because in the end, resilience is
not just about preventing failures.

421
00:26:17,279 --> 00:26:21,349
It's about also preparing for
them because they will happen.

422
00:26:21,849 --> 00:26:23,719
So thank you again for listening.

423
00:26:24,129 --> 00:26:25,579
I hope you enjoyed the session.

424
00:26:25,879 --> 00:26:27,269
If you have any questions.

425
00:26:27,979 --> 00:26:28,899
Please reach out to me.

426
00:26:28,909 --> 00:26:31,869
You can find me online
at LinkedIn at SteadyBit.

427
00:26:32,329 --> 00:26:35,289
And yeah, again, thank you
very much for your time.

428
00:26:36,279 --> 00:26:36,539
Bye.

