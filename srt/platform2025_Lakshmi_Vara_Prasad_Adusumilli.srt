1
00:00:00,500 --> 00:00:00,860
Hello.

2
00:00:00,889 --> 00:00:02,389
Good morning or good afternoon everyone.

3
00:00:02,930 --> 00:00:04,670
My name is LaMi.

4
00:00:05,015 --> 00:00:07,010
I'm a senior E at DevOps,
lead of cloud lead.

5
00:00:07,510 --> 00:00:10,959
I have experience that spans both
traditional middleware administration and

6
00:00:10,959 --> 00:00:14,884
modern cloud native technologies making
me versatile technology who consistently

7
00:00:15,384 --> 00:00:17,665
cloud scalable infrastructure solutions.

8
00:00:18,279 --> 00:00:19,449
Let me begin with the scenario.

9
00:00:19,689 --> 00:00:24,729
Imagine a hurricane making a landfall
nine one call volume search dispatch

10
00:00:24,729 --> 00:00:28,720
systems are under stress and every
second of downtime could cost lives.

11
00:00:29,220 --> 00:00:32,130
When we think about emergency
response, whether it's dispatching

12
00:00:32,130 --> 00:00:35,490
ambulances, coordinating firefighters,
or managing disaster relief,

13
00:00:35,490 --> 00:00:36,960
downtime is simply not an option.

14
00:00:37,350 --> 00:00:37,590
Today.

15
00:00:37,590 --> 00:00:41,370
In this talk, I'll share how platform
engineering a practice often associated

16
00:00:41,730 --> 00:00:46,110
with enterprise ID can fundamentally
transform emergency response terms into

17
00:00:46,110 --> 00:00:48,090
cloud native platforms that save lives.

18
00:00:48,590 --> 00:00:49,610
In this agenda.

19
00:00:50,000 --> 00:00:52,970
First we'll begin with foundations
of platform engineering and why

20
00:00:52,970 --> 00:00:54,530
they matter for emergency systems.

21
00:00:54,920 --> 00:00:59,360
Then drive into self-service
infrastructure and developer experience.

22
00:00:59,839 --> 00:01:04,129
Third, operational ex excellence patterns
from orchestration to observability, and

23
00:01:04,129 --> 00:01:07,789
finally, organizational studies that make
this platform sustainable and adoptable.

24
00:01:08,289 --> 00:01:09,009
The challenge.

25
00:01:09,429 --> 00:01:12,669
Unlike traditional enterprise
applications, emergency systems can't

26
00:01:12,669 --> 00:01:14,169
afford even seconds of downtime.

27
00:01:14,679 --> 00:01:17,679
They must scale instantly during
crisis, integrate with legacy

28
00:01:17,679 --> 00:01:20,529
and government systems, and still
comply with strict regulations.

29
00:01:21,029 --> 00:01:24,179
Think of what happens when a
hurricane hits call volumes spike.

30
00:01:24,179 --> 00:01:27,089
Dispatch systems much as much
spawn in milli milliseconds

31
00:01:27,104 --> 00:01:28,524
and for you could cost lives.

32
00:01:29,024 --> 00:01:33,434
Traditional deployment model models
will with long cycles and manual

33
00:01:33,434 --> 00:01:34,844
process simply can't keep up.

34
00:01:35,624 --> 00:01:36,764
We need a new paradigm.

35
00:01:37,064 --> 00:01:40,924
The paradigm shift before platform
engineering deployment took two weeks.

36
00:01:41,014 --> 00:01:43,204
Errors of frequent and
redundancy was limited.

37
00:01:43,534 --> 00:01:46,354
Operation teams are isolated,
infrastructure is inconsistent,

38
00:01:46,354 --> 00:01:49,469
and geographic CIE and
special knowledge is required.

39
00:01:49,809 --> 00:01:50,674
And platform.

40
00:01:50,674 --> 00:01:53,524
After platform engineering,
we achieved three minutes.

41
00:01:53,674 --> 00:01:55,189
Selfer, self-service provisioning.

42
00:01:55,999 --> 00:01:59,749
Golden paths with built-in per
practices had 99% reduction.

43
00:01:59,749 --> 00:02:02,689
The configurators consistent
patterns across 200 plus

44
00:02:02,689 --> 00:02:06,769
microservices, multi-region
deployment by default and hide out

45
00:02:06,769 --> 00:02:08,539
complexity from application teams.

46
00:02:09,049 --> 00:02:10,849
The shift creates multiplier effect.

47
00:02:11,450 --> 00:02:15,229
Emergency teams can focus on their
mission on saving lives, struck

48
00:02:15,229 --> 00:02:16,549
firefighting infrastructure,

49
00:02:17,049 --> 00:02:17,949
coming to develop a portal.

50
00:02:18,449 --> 00:02:20,579
Portal is heart of our
self-service platform.

51
00:02:20,579 --> 00:02:24,599
It acts as a primary interface for
emergency response teams, a place

52
00:02:24,779 --> 00:02:28,529
where they request infrastructure,
deploy services, monitor their systems.

53
00:02:29,459 --> 00:02:33,239
Instead of waiting weeks from manual
approvals or writing low level scripts

54
00:02:34,109 --> 00:02:38,099
now have a simple gateway that abstracts
complexity and towards consistency.

55
00:02:38,599 --> 00:02:42,609
Here we discuss about Golden
Park templates, self service

56
00:02:42,609 --> 00:02:44,749
catalog, and service scorecards.

57
00:02:45,039 --> 00:02:50,080
We'll dive in deep into these, all these
three points, golden part templates.

58
00:02:50,290 --> 00:02:51,730
Golden paths are pre-approved.

59
00:02:52,230 --> 00:02:55,500
Template that developers follow to
provision applications and services.

60
00:02:55,530 --> 00:02:58,530
They're embedded with security
observability and compliance best

61
00:02:58,530 --> 00:03:02,460
practices By default, why import
for emergency response during a

62
00:03:02,460 --> 00:03:05,850
disaster, developers don't have time
to figure out how to configure network

63
00:03:05,850 --> 00:03:06,990
trucking, encryption and logging.

64
00:03:07,490 --> 00:03:11,090
Golden Path ensure all services meet
baseline requirements automatically.

65
00:03:11,590 --> 00:03:12,490
Let's take an example.

66
00:03:12,580 --> 00:03:15,765
A new emergency microservice can
be deployed in under three minutes

67
00:03:16,035 --> 00:03:17,475
using a Golden Path template.

68
00:03:18,075 --> 00:03:22,125
It comes pre-wire with centralized logging
TLS, security and modern dashboards.

69
00:03:22,515 --> 00:03:23,775
No manual work is needed.

70
00:03:24,765 --> 00:03:28,065
One of such example is Backstage,
which is Spotify's open source

71
00:03:28,065 --> 00:03:31,515
developer portal, often used
for Golden Park implementations.

72
00:03:32,295 --> 00:03:32,925
Golden Pass.

73
00:03:32,975 --> 00:03:36,290
Might also include hand check templates,
Terraform modules or Kubernetes AML

74
00:03:36,605 --> 00:03:39,425
blueprints and pre prebuilt guardrails.

75
00:03:40,265 --> 00:03:44,285
Coming to service catalog, the service
catalog is like a minimum where teams

76
00:03:44,285 --> 00:03:48,335
can pick the infrastructure and services
they need without open tickets are

77
00:03:48,335 --> 00:03:53,015
relying on ops teams, self-service,
provisioning of databases, messages,

78
00:03:53,015 --> 00:03:57,065
queues, and caches, object storage,
and other cloud native components.

79
00:03:57,565 --> 00:03:59,035
These are all what it offers.

80
00:03:59,535 --> 00:04:03,135
Each entry in the catalog comes
with built in process like hipaa

81
00:04:03,615 --> 00:04:07,725
NIST, and local regulations coming
to emergency response scenario.

82
00:04:07,845 --> 00:04:11,055
One of the example is suppose
an incident occurs that requires

83
00:04:11,055 --> 00:04:12,735
scaling up realtime event.

84
00:04:13,155 --> 00:04:16,935
Few of Q4 incoming calls instead days
of provisioning an engineer Kafka

85
00:04:16,935 --> 00:04:21,795
cluster from the service catalog and
has means pre-configured for resilience.

86
00:04:22,215 --> 00:04:23,715
Some of the tools and examples are.

87
00:04:24,215 --> 00:04:28,545
HashiCorp Terraform Cloud Cross or a
W Service catalog often powered the

88
00:04:28,545 --> 00:04:31,025
backend coming to service scorecards.

89
00:04:31,835 --> 00:04:35,090
Scorecards are provide realtime
metrics on health, reliability,

90
00:04:35,090 --> 00:04:36,740
and compliance of each service.

91
00:04:37,440 --> 00:04:40,480
Think of it as a report card for
every microservice, what they measure.

92
00:04:40,480 --> 00:04:44,410
Reliability, uptime error
rates mean time to recover.

93
00:04:44,910 --> 00:04:46,710
They also offer security and compliance.

94
00:04:47,190 --> 00:04:50,550
They also measure performance latency,
throughput and resource utilization.

95
00:04:51,050 --> 00:04:53,960
Some of the examples of pros and
Grafana metrics visualization,

96
00:04:54,020 --> 00:04:55,460
open telemetry for traces.

97
00:04:55,960 --> 00:04:59,200
The conclusion is the developers
portal is not just a dashboard,

98
00:04:59,260 --> 00:05:00,460
it's productivity engine.

99
00:05:00,460 --> 00:05:01,300
Golden paths.

100
00:05:01,570 --> 00:05:03,460
Where Golden Paths provide saves.

101
00:05:03,475 --> 00:05:06,940
Foster deployments service catalog
gives instant access to critical

102
00:05:06,940 --> 00:05:07,900
infrastructure and service.

103
00:05:07,900 --> 00:05:09,640
Scorecards realtime visibility.

104
00:05:10,140 --> 00:05:13,320
The result is what took two
weeks now takes three minutes,

105
00:05:13,820 --> 00:05:19,120
coming to IAC and GI tops,
which are core for the, for this

106
00:05:19,120 --> 00:05:22,925
infrastructure, everything is defined
as code and managed to GitHubs.

107
00:05:23,425 --> 00:05:25,825
We have full version control drift
detection with hundred percent

108
00:05:25,825 --> 00:05:29,965
coverage and 73% of deviations auto
remediated immutable infrastructure

109
00:05:29,965 --> 00:05:31,705
patterns mean no ad hoc changes.

110
00:05:32,205 --> 00:05:35,745
Let's dive deep into the infrastructures
code and DevOps infrastructures

111
00:05:35,745 --> 00:05:38,805
in code and DevOps, a backbone of
reliable cloud native platforms.

112
00:05:39,015 --> 00:05:42,705
The transform how they, how we
build, deploy, and manage emergency

113
00:05:42,705 --> 00:05:45,315
response systems with consistency
and trust are on negotiable.

114
00:05:45,795 --> 00:05:48,020
Let's break down in these practices
and why they are critical.

115
00:05:48,520 --> 00:05:53,080
What is infrastructure as a code ISC means
we infrastructure in code now through

116
00:05:53,080 --> 00:05:57,310
manual, not through manual flick or ad
hoc scripts, everything from Kubernetes

117
00:05:57,310 --> 00:06:01,330
cluster load balance to IM rules is
written as declarative configuration

118
00:06:01,330 --> 00:06:02,680
file stored in version control.

119
00:06:03,400 --> 00:06:07,030
This enables consistency,
automation, and version control.

120
00:06:07,105 --> 00:06:10,380
Every infrastructure change is
tracked like code without history

121
00:06:10,410 --> 00:06:12,180
or differences and rollback ability.

122
00:06:13,095 --> 00:06:17,175
Coming to consistency, same ation of
is across different a like dev and

123
00:06:17,175 --> 00:06:19,355
production automation development.

124
00:06:19,535 --> 00:06:22,265
Deployments happen via CA CD,
pipelines without human error.

125
00:06:22,765 --> 00:06:28,315
Some example tools are cloud agno
agnostic, ISC tool project resources

126
00:06:28,315 --> 00:06:31,105
like AWS Azure, Google Cloud platform.

127
00:06:31,345 --> 00:06:36,100
And also some other example is
Ansible often use it for conservation

128
00:06:36,100 --> 00:06:37,475
management and small scale provisioning.

129
00:06:37,975 --> 00:06:39,910
A Terraform module, take an example.

130
00:06:39,910 --> 00:06:43,525
A Terraform module provisions five
Kubernetes testers across different

131
00:06:43,525 --> 00:06:46,765
regions with identical settings,
ensuring complaints and resilience.

132
00:06:47,265 --> 00:06:50,235
When a new node pool is added to the
hand of the disaster load is done

133
00:06:50,235 --> 00:06:52,485
by updating coding gi, not manually.

134
00:06:52,985 --> 00:06:53,645
What is GitHubs?

135
00:06:54,145 --> 00:06:57,355
GitHub's Accents a infrastructure
is a code by using GitHubs as single

136
00:06:57,355 --> 00:06:59,785
source of truth for both infrastructure
and application deployment.

137
00:07:00,325 --> 00:07:02,995
Any change to infrastructure
or application manifest must

138
00:07:02,995 --> 00:07:06,505
be committed to git a GitHub
controller like August City Flex.

139
00:07:06,505 --> 00:07:09,865
Continuously reconcile live cluster
state with clash state in Git.

140
00:07:10,365 --> 00:07:14,685
This provides auditability, automatic
detection and safer deployments.

141
00:07:14,715 --> 00:07:15,285
What is auditability?

142
00:07:16,155 --> 00:07:18,825
Every change has an other committee
history and approval workflow.

143
00:07:19,325 --> 00:07:22,385
Coming to automated D detection, if
someone changes the resource directly

144
00:07:22,385 --> 00:07:24,275
in the cluster, GIS reverse is back.

145
00:07:24,775 --> 00:07:30,235
And these deployments are also safer
where changes are tested, be reviewed

146
00:07:30,235 --> 00:07:31,555
and rolled out inconsistently.

147
00:07:32,055 --> 00:07:34,815
So my example tools
are Argo CD and Flux CD

148
00:07:35,315 --> 00:07:35,795
coming to.

149
00:07:36,295 --> 00:07:39,445
Key benefits of these emergency
response systems are reliability,

150
00:07:39,445 --> 00:07:41,485
speed, resilience, and compliance.

151
00:07:42,295 --> 00:07:44,815
In short, IAC ensures
that our infrastructure is

152
00:07:45,055 --> 00:07:46,975
reproducible and predictable.

153
00:07:47,815 --> 00:07:51,835
While GitHubs ensures that our operations
are automated and audible together, they

154
00:07:51,835 --> 00:07:55,705
make sure emergency systems stay online,
secure, and ready to handle demand

155
00:07:55,705 --> 00:07:58,615
spikes when every second truly matters.

156
00:07:59,115 --> 00:08:01,245
Coming to multi cluster orchestration.

157
00:08:01,745 --> 00:08:04,205
Imagine a flood knocking
out an anti-D data center.

158
00:08:04,265 --> 00:08:06,965
The system must continue
running without missing a beat.

159
00:08:07,465 --> 00:08:08,665
Resilience is critical.

160
00:08:09,115 --> 00:08:13,465
Multi, multi cluster orchestration issues
that from one, if one region goes down

161
00:08:13,465 --> 00:08:17,150
due to a flood power outage, or cyber
attacks, as services continues seamlessly,

162
00:08:17,650 --> 00:08:19,710
we receive workloads across fire regions.

163
00:08:20,150 --> 00:08:23,470
Maintain active clusters and pro travel
to near the nearest healthy endpoint.

164
00:08:23,970 --> 00:08:26,810
Multi coming to multi cluster
orchestration architecture,

165
00:08:27,310 --> 00:08:29,110
we have failover cluster.

166
00:08:29,410 --> 00:08:31,310
We operate multiple Kubernetes
clusters per region.

167
00:08:31,450 --> 00:08:35,620
The this design ensures that if one
cluster goes down to hardware failure,

168
00:08:35,620 --> 00:08:40,030
software, bug, or even a there disaster,
another cluster seamlessly takes over.

169
00:08:40,420 --> 00:08:43,780
Automated failure mechanisms
synchronize straight, straightforward

170
00:08:43,780 --> 00:08:45,250
workloads across clusters.

171
00:08:45,280 --> 00:08:49,180
This means data is not lost and operations
can assume within minimum disruption.

172
00:08:49,650 --> 00:08:51,870
By Thereal isolation, we
prevent cascading failure.

173
00:08:52,410 --> 00:08:56,400
For example, an issue in one region
does not spill and impact others,

174
00:08:56,610 --> 00:08:58,380
which is crucial in emergencies.

175
00:08:58,880 --> 00:09:00,350
Multiple clusters per region.

176
00:09:00,530 --> 00:09:02,810
Within each region, we
maintain more than one cluster.

177
00:09:02,810 --> 00:09:07,220
It supports active two configurations
where both clusters are live share

178
00:09:07,220 --> 00:09:11,960
load, and improve availability and fault
tolerance During peak load, for example,

179
00:09:11,960 --> 00:09:16,670
a certain 8800% spike in emergency
calls during the disaster resources are

180
00:09:16,670 --> 00:09:18,320
automatically distributed across clusters.

181
00:09:18,320 --> 00:09:21,740
These balances, performance and
ensures fosters possible response

182
00:09:21,740 --> 00:09:23,770
time for first responders.

183
00:09:24,270 --> 00:09:27,450
Regional balances coming to
regional balances with redundancy.

184
00:09:27,570 --> 00:09:32,300
Each region is frontend by regional
role balances, which is distributed

185
00:09:32,420 --> 00:09:34,010
incoming traffic among clusters.

186
00:09:34,640 --> 00:09:36,590
These load balances
themselves are redundant.

187
00:09:36,860 --> 00:09:39,560
If one fails another, instantly
takes over, ensuring there's

188
00:09:39,560 --> 00:09:40,730
no single point of failure.

189
00:09:41,330 --> 00:09:44,755
They also support intelligent
routing, sending request to region.

190
00:09:45,255 --> 00:09:46,530
Emergency services with failover.

191
00:09:47,030 --> 00:09:51,380
Each individual emergency service such as
dispatching, geolocation, or medical trial

192
00:09:51,560 --> 00:09:53,510
systems is designed, built at failover.

193
00:09:53,510 --> 00:09:56,270
For example, the primary
instance of a dispatch service

194
00:09:56,300 --> 00:09:57,980
in cluster becomes unavailable.

195
00:09:58,250 --> 00:10:01,790
The system automatically roads to a
secondary instance in cluster B without

196
00:10:01,790 --> 00:10:05,570
manual intervention coming to Global
Traffic Management and failover.

197
00:10:06,260 --> 00:10:09,270
In this one of the key
component of the architecture.

198
00:10:09,900 --> 00:10:13,320
The reason level we use global
traffic managers like DNS Road, a

199
00:10:13,320 --> 00:10:17,940
cloud native global load balancing
the systems direct user request

200
00:10:17,940 --> 00:10:19,200
to the nearest healthy region.

201
00:10:19,200 --> 00:10:25,290
Ensuring edge optimized routing with
sub mil 50 millisecond latency for

202
00:10:25,290 --> 00:10:26,610
entire region becomes unavailable.

203
00:10:26,880 --> 00:10:29,910
For instance, due to disaster,
natural disaster, global routing,

204
00:10:29,910 --> 00:10:31,650
automatic failures to another region.

205
00:10:32,150 --> 00:10:36,110
To summarize, this architecture
combines failover at every level,

206
00:10:36,370 --> 00:10:40,240
service cluster, regional and global
intelligent traffic management.

207
00:10:40,690 --> 00:10:44,370
This result is a platform that is
a resilient complaint and ready

208
00:10:45,120 --> 00:10:46,635
to further unexpected failures.

209
00:10:46,935 --> 00:10:50,475
This architecture ensures that
sub 50 millisecond dispatch

210
00:10:50,475 --> 00:10:51,645
response times globally.

211
00:10:52,145 --> 00:10:55,465
Coming to service mesh
integration, a service mesh adds

212
00:10:55,525 --> 00:10:57,175
another layers of resilience.

213
00:10:57,235 --> 00:11:01,285
It automatically traffic to healthy
services using breaking to stop

214
00:11:01,285 --> 00:11:05,395
cascading failures and enforce
mutual TL security for zero trust.

215
00:11:05,395 --> 00:11:09,000
Security, even partial failures
does not have system availability.

216
00:11:09,330 --> 00:11:11,310
A must for life critical operations.

217
00:11:11,810 --> 00:11:15,890
Coming to observability, of
course, you can't operate at

218
00:11:15,890 --> 00:11:17,180
the scale without visibility.

219
00:11:17,720 --> 00:11:22,415
You can't fix what you can't see,
or observability platform ES 2.3

220
00:11:22,415 --> 00:11:27,700
million metrics per minute, ands 90%
of alert accuracy through machine

221
00:11:27,700 --> 00:11:29,350
learning and animal detection.

222
00:11:29,850 --> 00:11:31,635
This enables less than 30 seconds.

223
00:11:32,135 --> 00:11:35,885
Coming to policy as cloud security
and governance are non-negotiable.

224
00:11:36,305 --> 00:11:39,685
Governance should not slow teams down.

225
00:11:39,745 --> 00:11:41,605
By adding, by admitting policy.

226
00:11:41,605 --> 00:11:46,185
As code security and compliance are
enforced automatically, we enforce

227
00:11:46,875 --> 00:11:48,525
runtime policies automatically.

228
00:11:48,525 --> 00:11:52,115
Con, continuously validate against
frameworks like HIPA and secure the

229
00:11:52,115 --> 00:11:54,680
supply chain with and pro checks.

230
00:11:55,070 --> 00:11:57,320
Example, take an example.

231
00:11:57,820 --> 00:12:00,940
A deployment violates, sometimes
security is blocked without

232
00:12:01,030 --> 00:12:02,290
requir manual intervention.

233
00:12:02,790 --> 00:12:06,270
This approach, governance without
slowing teams down, security and

234
00:12:06,270 --> 00:12:07,650
complaints are built in default.

235
00:12:08,150 --> 00:12:10,190
Coming to platform team, organization.

236
00:12:10,690 --> 00:12:14,050
Enabled by 12 platform team
supporting more than 80 developers.

237
00:12:14,980 --> 00:12:19,510
Platform gathering feedback,
engineer with application teams.

238
00:12:20,140 --> 00:12:21,840
Four, not doing things.

239
00:12:22,410 --> 00:12:25,290
It's about enabling others to move safely.

240
00:12:25,790 --> 00:12:27,485
Measuring platform success.

241
00:12:27,985 --> 00:12:29,875
Is how do we measure success?

242
00:12:30,145 --> 00:12:35,425
Developer experience is improved 67%
faster time to production, 70% fewer

243
00:12:35,425 --> 00:12:40,675
stock support operational metrics,
19% availability, and 78% decrease.

244
00:12:40,675 --> 00:12:43,645
In meantime to response repay.

245
00:12:44,145 --> 00:12:46,415
There 30% reduction in
emergency response time.

246
00:12:46,915 --> 00:12:51,295
Increase in future delivery
velocity and 65% decrease in.

247
00:12:52,165 --> 00:12:54,295
Ultimately, these are not just numbers.

248
00:12:54,535 --> 00:12:57,865
They represent faster resources,
better outcomes, and save lives.

249
00:12:58,365 --> 00:13:00,505
The key takeaways to close.

250
00:13:01,005 --> 00:13:01,515
Service.

251
00:13:02,205 --> 00:13:06,855
Key takeaways are self-service
infrastructure unlocks, agility, platform

252
00:13:06,855 --> 00:13:11,265
obstructions, reduce cognitive load and
golden path, enforce best practices.

253
00:13:11,765 --> 00:13:14,105
The journey does not start
with boiling the ocean.

254
00:13:14,345 --> 00:13:15,035
Begin with what?

255
00:13:15,035 --> 00:13:17,250
Golden path, measure
rigorously and expand.

256
00:13:18,090 --> 00:13:21,425
When platform engineering meets
emergency response, technology

257
00:13:21,425 --> 00:13:23,195
directly translates to human impact.

258
00:13:23,795 --> 00:13:25,295
That's why this work matters.

259
00:13:25,795 --> 00:13:26,365
Thank you.

