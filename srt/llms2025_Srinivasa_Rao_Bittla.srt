1
00:00:00,150 --> 00:00:05,970
Welcome everyone to my talk on
agent ai architecting, scalable and

2
00:00:05,970 --> 00:00:08,160
reliable AI agents for the future.

3
00:00:09,120 --> 00:00:13,340
This is Bitler working as a senior
software development engineer at Adobe.

4
00:00:13,840 --> 00:00:17,440
Before I get on, get onto my talk,
I want to make a quick disclaimer.

5
00:00:18,220 --> 00:00:23,200
All views expressed here are my own
and do not reflect the opinions of

6
00:00:23,200 --> 00:00:25,800
any affiliated organization today.

7
00:00:26,279 --> 00:00:26,400
We.

8
00:00:26,900 --> 00:00:31,640
Tools to become active participants
in solving complex problems.

9
00:00:32,299 --> 00:00:36,710
By the end, you'll understand
the key architectural principles

10
00:00:37,190 --> 00:00:41,930
for building AI agents that
are both scalable and reliable.

11
00:00:42,530 --> 00:00:43,610
Let's deep dive into it.

12
00:00:44,110 --> 00:00:47,890
If you really look at
historically, AI has fundamentally

13
00:00:47,890 --> 00:00:50,080
transformed over the past decade.

14
00:00:50,580 --> 00:00:57,180
If you look at it, we started with systems
that simply responded to queries, think

15
00:00:57,689 --> 00:00:59,730
early, search engine or basic chatbots.

16
00:01:00,230 --> 00:01:03,529
Then we moved to more
sophisticated interactions.

17
00:01:04,030 --> 00:01:09,220
That the systems that could generate
content or solve specific problems

18
00:01:09,220 --> 00:01:16,350
when prompted right, and now we're
entering the era of agentic AI systems

19
00:01:16,350 --> 00:01:22,440
that can take initiatives, make
decisions, and execute multi-step plans.

20
00:01:22,940 --> 00:01:27,524
This represents a fundamental shift
in human computer interaction.

21
00:01:28,369 --> 00:01:31,940
From tools we used to
partners we collaborate with.

22
00:01:32,720 --> 00:01:37,550
So that is the power of evolution that is
happening, and that is the transformation

23
00:01:37,550 --> 00:01:43,105
that we are going through To understand
agent ai, first of all, we need to

24
00:01:43,105 --> 00:01:47,825
define what makes system a truly agent.

25
00:01:48,325 --> 00:01:52,490
If we look at it, there are four
qualities that I categorized here.

26
00:01:52,990 --> 00:01:55,450
A systems to act as an agent.

27
00:01:56,230 --> 00:01:59,850
Ai, the first goal is directed behavior.

28
00:02:00,350 --> 00:02:06,140
The system should have the ability to
pursue specific objectives rather than

29
00:02:06,620 --> 00:02:08,900
just responding to immediate inputs.

30
00:02:09,400 --> 00:02:10,210
That is the first goal.

31
00:02:10,210 --> 00:02:11,080
And the second is.

32
00:02:11,580 --> 00:02:15,030
Operating with minimal human intervention.

33
00:02:15,480 --> 00:02:19,530
Once your goal is established,
they should automatically perform

34
00:02:19,530 --> 00:02:21,840
all the tasks that are given.

35
00:02:22,740 --> 00:02:25,890
And the third one is
environment awareness.

36
00:02:26,390 --> 00:02:32,270
The ability to perceive and interpret
the context in which the agent

37
00:02:32,270 --> 00:02:34,890
operates and the adaptability.

38
00:02:35,760 --> 00:02:40,290
Learning from outcomes and
adjusting strategies accordingly.

39
00:02:40,980 --> 00:02:45,810
So if these four capabilities are there
in any system that we can say it as a

40
00:02:45,810 --> 00:02:53,170
agent system that can actually plug and
play with any other bigger system, right?

41
00:02:53,470 --> 00:02:55,710
Let's look where already making an impact.

42
00:02:56,210 --> 00:03:02,690
There personal assistance, like advanced
versions of tools that can proactively

43
00:03:02,690 --> 00:03:09,590
manage schedules for any individual
filter information and coordinate their

44
00:03:09,590 --> 00:03:12,050
tasks with other agents are humans.

45
00:03:12,550 --> 00:03:17,320
In software development, we are seeing
agents that can not just generate

46
00:03:17,320 --> 00:03:23,530
code, but plan implementations,
debug issues, and performance.

47
00:03:24,235 --> 00:03:30,435
So in software development, we see in day
to day, like you have, Microsoft Copilot,

48
00:03:30,935 --> 00:03:33,875
GitHub copilot, and also uc, cursor ai.

49
00:03:34,775 --> 00:03:39,035
These are amazing tools where you can
actually leverage for code generation

50
00:03:39,035 --> 00:03:41,855
and couple more tools to perform.

51
00:03:42,105 --> 00:03:45,785
all of these tasks I mentioned,
and if you look at the research.

52
00:03:46,285 --> 00:03:49,195
Design experiments and
analyze the results.

53
00:03:50,125 --> 00:03:55,045
So for research agents, you have so
many other types of things to take care.

54
00:03:55,045 --> 00:04:00,625
So now agents are there to solve all of
these problems and in physical domains,

55
00:04:01,125 --> 00:04:06,635
robots, which are going to help you in
industrial systems that can adapt to

56
00:04:06,905 --> 00:04:08,410
changing conditions and requirements.

57
00:04:08,910 --> 00:04:12,790
So that's where you can see the
robotic agents in the manufacturing

58
00:04:12,970 --> 00:04:15,249
and in other support areas.

59
00:04:15,749 --> 00:04:22,559
So here, what's notable is the increasing
scope of agency from narrow specific

60
00:04:22,559 --> 00:04:25,950
tasks to broader domains of action, right?

61
00:04:26,369 --> 00:04:27,989
So adaptability.

62
00:04:28,489 --> 00:04:32,590
willing to collaborate with the agent
AI to perform their multitasking

63
00:04:32,590 --> 00:04:36,180
things without any stress, right?

64
00:04:36,540 --> 00:04:40,020
So now let's break down the
essential components that

65
00:04:40,020 --> 00:04:42,650
enable the agent systems, right?

66
00:04:43,099 --> 00:04:48,119
So if you really look at the system
here at the core, in the foundation.

67
00:04:48,619 --> 00:04:52,150
Typically large language models,
which are going to provide a

68
00:04:52,150 --> 00:04:56,469
cognitive engine to break down the
prompts and give the instructions.

69
00:04:57,400 --> 00:05:01,059
Then the planning frameworks comes
into the picture for strategic

70
00:05:01,059 --> 00:05:06,849
decision making where the ability to
map out the steps towards a goal to

71
00:05:06,849 --> 00:05:11,879
achieve the goal that is defined for
the agents to integration systems.

72
00:05:12,405 --> 00:05:17,145
That can extend the agent's capabilities
through APIs and external services.

73
00:05:18,014 --> 00:05:20,384
So that's where the integration
comes into the picture.

74
00:05:21,134 --> 00:05:25,094
Then the memory systems for
maintaining the context and history

75
00:05:25,094 --> 00:05:26,775
beyond immediate interaction.

76
00:05:26,775 --> 00:05:31,574
So see the storage related information
comes where it can, where the agents can

77
00:05:31,604 --> 00:05:34,060
retrieve the information based on the.

78
00:05:34,560 --> 00:05:39,390
The system is able to learn from
the success or failure and then

79
00:05:39,510 --> 00:05:45,260
try to, take the corresponding
actions and the feedback mechanism.

80
00:05:45,260 --> 00:05:49,910
Also make the system so get corrected,
process dynamically and stores the,

81
00:05:50,220 --> 00:05:51,870
information for the future usage.

82
00:05:52,620 --> 00:05:55,830
These are the typical key
components of an agent system.

83
00:05:56,330 --> 00:05:56,840
So now.

84
00:05:57,340 --> 00:06:02,170
If you really look at this whole diagram
in the centralized area where you have

85
00:06:02,650 --> 00:06:06,780
the total, the processing capability,
like how the processing is going to

86
00:06:06,780 --> 00:06:11,990
be taking place, and there you have
the lms, the large language models,

87
00:06:12,050 --> 00:06:13,730
which is the core of the system.

88
00:06:14,390 --> 00:06:17,240
And then these, there
are multiple components.

89
00:06:17,740 --> 00:06:22,240
You see the bidirectional mapping
between all of these tasks, right?

90
00:06:22,600 --> 00:06:29,224
That includes the planning and reasoning
module where you see, how LLM need to,

91
00:06:29,275 --> 00:06:35,295
communicate within a different kind of,
sub components and tool connectors, right?

92
00:06:35,565 --> 00:06:38,685
The a p connectors are the
tools that can actually interact

93
00:06:38,685 --> 00:06:40,874
with between these, components.

94
00:06:41,400 --> 00:06:43,799
And the memory storage, right?

95
00:06:44,159 --> 00:06:49,790
So where you can store the outputs
of your agent based on the kind of,

96
00:06:49,970 --> 00:06:52,340
information that is processed, right?

97
00:06:52,340 --> 00:06:56,720
And based on the historical data that it
can actually keep it in, respond back.

98
00:06:57,380 --> 00:07:02,600
And then you also have monitoring
and feedback where you have the

99
00:07:02,600 --> 00:07:07,290
feedback loops to see whether
the system is, giving you the.

100
00:07:07,790 --> 00:07:11,810
And then the safety guardrails
where you see like how the systems

101
00:07:11,810 --> 00:07:14,429
are actually, safe to use or not.

102
00:07:14,520 --> 00:07:16,619
So all of this information
you can see through this

103
00:07:17,009 --> 00:07:18,599
technical architectural diagram.

104
00:07:19,099 --> 00:07:22,179
And then the challenges in
scaling agentic ai, right?

105
00:07:22,539 --> 00:07:27,639
So as we move from prototype to
production, there are several challenges.

106
00:07:28,139 --> 00:07:33,859
Increase dramatically with both
model size and task complexity, then

107
00:07:33,859 --> 00:07:35,749
the latency becomes very critical.

108
00:07:36,529 --> 00:07:41,419
Users expect rapid responses
even for complex tasks.

109
00:07:42,049 --> 00:07:46,849
So if you really look at the users the way
they are coming up to the system, right?

110
00:07:47,119 --> 00:07:51,869
So you need to understand
like how the agent is actually

111
00:07:51,869 --> 00:07:53,519
supporting what kind of complex.

112
00:07:54,019 --> 00:07:55,519
And then you see the reliability.

113
00:07:55,524 --> 00:07:59,149
Reliability, it must be
maintained across an expanding

114
00:07:59,149 --> 00:08:01,759
set of use cases and age cases.

115
00:08:02,259 --> 00:08:06,579
And the multi-agent systems
introduce new complexities in

116
00:08:06,579 --> 00:08:08,529
coordination and communication.

117
00:08:09,039 --> 00:08:13,094
And of course cost
scales with huge, usage.

118
00:08:13,779 --> 00:08:13,999
And

119
00:08:14,499 --> 00:08:15,204
so these are.

120
00:08:15,704 --> 00:08:20,954
Are possible, but they require through
the architectural approaches of agent

121
00:08:20,954 --> 00:08:26,844
AI and reliability concerns, reliability
deserves a special attention as it's

122
00:08:27,354 --> 00:08:30,489
often the make or big factor for adoption.

123
00:08:30,989 --> 00:08:34,839
Because if without reliable systems,
it's very difficult to, use it.

124
00:08:35,709 --> 00:08:36,709
So Hall.

125
00:08:37,209 --> 00:08:42,009
When agents generate convincing,
but incorrect information remain

126
00:08:42,009 --> 00:08:43,979
a significant challenge, right?

127
00:08:44,309 --> 00:08:49,149
So if every information is coming
as hallucination, it is very hard

128
00:08:49,149 --> 00:08:53,559
to soak that information and you
can't really use it in the real time.

129
00:08:54,059 --> 00:08:58,429
Rule misuse occurs when agents
apply available capabilities

130
00:08:58,489 --> 00:09:00,829
inappropriately or inefficiency.

131
00:09:01,789 --> 00:09:04,909
So that's where, to see where
the tool is getting misused.

132
00:09:05,409 --> 00:09:09,729
Planning failures happen when
agents create ineffective or

133
00:09:09,729 --> 00:09:11,829
nonsensical action sequences.

134
00:09:12,549 --> 00:09:15,339
So this is, planning is
one of the crucial point.

135
00:09:16,299 --> 00:09:17,799
Context limitations.

136
00:09:18,299 --> 00:09:22,349
Context limitations lead to
agents losing track of relevant

137
00:09:22,349 --> 00:09:24,899
information during extended tasks.

138
00:09:25,399 --> 00:09:29,419
So these are the major concerns, and apart
from that, the last and final one is the

139
00:09:29,419 --> 00:09:34,909
feedback loops, which can trap agents
in unpredictable patterns of behavior.

140
00:09:35,409 --> 00:09:39,879
So if the feedback loops are not giving
you the proper feedback, if there is

141
00:09:40,029 --> 00:09:44,854
a chances of 20% errors information,
and the feedback is actually going as

142
00:09:44,854 --> 00:09:50,524
a storage, eventually the system can
give very information to the end user.

143
00:09:51,019 --> 00:09:54,919
So that's where you need to be very
careful on what kind of feedback

144
00:09:54,919 --> 00:09:57,439
mechanism is there and what
kind of corrections are getting.

145
00:09:57,939 --> 00:10:04,109
So here we, we have three solutions, so
I want to go through one after the other.

146
00:10:04,439 --> 00:10:10,639
The fastest solution here is modular
architecture, so by decomposing complex.

147
00:10:11,139 --> 00:10:15,479
We reduce the cognitive load
on any single system, right?

148
00:10:15,479 --> 00:10:19,949
You're breaking down into multiple
components and that's where you are,

149
00:10:20,319 --> 00:10:24,790
trying to give a task for each of
the component in an isolation phase.

150
00:10:25,290 --> 00:10:30,690
This enables specialized agents
for specific domains, leveraging

151
00:10:30,750 --> 00:10:33,000
expertise where it matters the most.

152
00:10:33,500 --> 00:10:37,640
Modularity facilitates easier
updating of individual components

153
00:10:38,360 --> 00:10:43,360
without disrupting the entire
system, and it supports distributed

154
00:10:43,360 --> 00:10:46,945
processing, spreading computational,
and load across the resources.

155
00:10:47,445 --> 00:10:51,535
Perhaps most importantly, it
allows for graceful degradation.

156
00:10:52,395 --> 00:10:56,385
If one component fails, other
can continue functioning it.

157
00:10:56,885 --> 00:11:00,665
This approach has prevent successful
in other complex software domains.

158
00:11:01,165 --> 00:11:05,705
So here, if you look at any kind of,
banking system, how you can break

159
00:11:05,705 --> 00:11:10,725
down into multiple, agents and each
agent can take care of its task.

160
00:11:11,205 --> 00:11:14,475
And ultimately they align
with the centralized system

161
00:11:14,895 --> 00:11:16,035
to give the end results.

162
00:11:16,535 --> 00:11:20,225
And second solution is robust
planning and framework.

163
00:11:20,725 --> 00:11:25,965
In this case, there is a hierarchical
planning, which where the structure

164
00:11:25,965 --> 00:11:30,945
is break down into complex goals
and into know manageable sub goals.

165
00:11:31,695 --> 00:11:37,525
So the ultimate goal is to, provide the
solution to an end user with so many,

166
00:11:37,525 --> 00:11:42,835
interactive kind of processing that
are needed for agents to work on it.

167
00:11:43,335 --> 00:11:47,865
So in this case, you may need to have
verifications at multiple stages.

168
00:11:48,600 --> 00:11:53,490
Ensure that plans are logical and
aligned with the common goal or

169
00:11:53,490 --> 00:11:54,930
the objective that is defined.

170
00:11:55,430 --> 00:11:59,900
In this case, you may see some
uncertainty, estimation, uncertainty,

171
00:12:00,610 --> 00:12:04,720
which can help the agents to
recognize when they may be operating

172
00:12:04,720 --> 00:12:06,340
with incomplete information.

173
00:12:06,840 --> 00:12:10,710
So this is where you may need
to see like what is going wrong

174
00:12:10,920 --> 00:12:12,300
and which kind of scenario.

175
00:12:13,199 --> 00:12:16,110
So that's where the
fallback mechanism provides.

176
00:12:17,010 --> 00:12:20,730
What are the alternate you have
when the primary approach fails?

177
00:12:21,720 --> 00:12:25,740
So that's where you see here, this
may be the common goal, but these

178
00:12:25,740 --> 00:12:29,520
agents are connected and everywhere
you have a fallback mechanism

179
00:12:29,939 --> 00:12:34,170
where there can been corrective
action, can be taken care, right?

180
00:12:34,510 --> 00:12:38,230
So again, when something goes wrong,
there will be a dynamic planning.

181
00:12:38,230 --> 00:12:43,540
So the adaptable planning, Together, these
approaches create more resilient planning

182
00:12:43,900 --> 00:12:45,610
for handling real world complexity.

183
00:12:46,110 --> 00:12:49,770
The third key solution in
comprehensive, in comprehensive

184
00:12:49,770 --> 00:12:55,470
evaluation is it is like how you
wanna test the quality of your agent.

185
00:12:55,970 --> 00:12:58,280
So in this case, you
may have several test.

186
00:12:58,780 --> 00:13:04,680
However, not just common cases, but cases
where failures are more likely, right?

187
00:13:05,160 --> 00:13:09,630
So continuous monitoring, which will
allow us to detect the performance

188
00:13:09,630 --> 00:13:12,709
degradation before it becomes critical.

189
00:13:13,550 --> 00:13:19,370
So you may need to monitor, like whether
is there any kind of underlying system

190
00:13:19,370 --> 00:13:23,945
is, going through any, performance
bottlenecks or degradations.

191
00:13:24,445 --> 00:13:28,315
Real time failure detection
enables immediate intervention when

192
00:13:28,315 --> 00:13:33,705
necessary, and also human feedback
in cooperation ensures that technical

193
00:13:33,705 --> 00:13:35,775
metrics align with actual user needs.

194
00:13:36,275 --> 00:13:41,645
So human feedback is very essential
because you can't really rely on a

195
00:13:41,645 --> 00:13:43,265
hundred percentage of the systems

196
00:13:43,765 --> 00:13:43,985
be.

197
00:13:44,485 --> 00:13:49,485
So this is what in the third solution,
which you may need to, see like how

198
00:13:49,485 --> 00:13:52,515
it actually helps the, real user.

199
00:13:52,515 --> 00:13:58,035
So combining these three solutions,
definitely you may get a better agent to

200
00:13:58,035 --> 00:14:00,075
use it as part of your implementation.

201
00:14:00,400 --> 00:14:02,350
So let's start with a case study.

202
00:14:02,850 --> 00:14:05,630
So here an example of a bank manager.

203
00:14:06,130 --> 00:14:10,870
So if you really look at an enterprise
knowledge agent, how this works on

204
00:14:10,870 --> 00:14:16,090
the left hand side of this image,
you can see in the current scenario

205
00:14:16,090 --> 00:14:22,030
how the bank manager is actually,
working with the, in the real world

206
00:14:22,030 --> 00:14:28,240
scenario and on the right hand side,
a knowledge agent that is enabling or

207
00:14:28,240 --> 00:14:30,520
using it for processing their tasks.

208
00:14:31,020 --> 00:14:31,530
Excuse me.

209
00:14:32,010 --> 00:14:39,500
So here, yeah, he's dealing with a lot of,
started documents, databases, and systems.

210
00:14:39,980 --> 00:14:43,910
So he doesn't have any kind of
a proper mechanism to handle

211
00:14:43,910 --> 00:14:45,420
the, current scenario here.

212
00:14:46,380 --> 00:14:47,100
This.

213
00:14:47,895 --> 00:14:52,765
This solution definitely a kind of
a complex thing to really, handle,

214
00:14:52,985 --> 00:14:58,185
and he'll be stressful to, at the end
of the day to handle, so many tasks.

215
00:14:58,815 --> 00:15:01,575
So that's where he got the
knowledge agent in place.

216
00:15:02,415 --> 00:15:02,715
Okay.

217
00:15:03,165 --> 00:15:05,625
So this knowledge agent,
what does it do for him?

218
00:15:06,125 --> 00:15:11,015
the solution implemented is a
modular approach, where you got

219
00:15:11,015 --> 00:15:13,005
the, dis from different systems.

220
00:15:13,505 --> 00:15:14,225
And generation.

221
00:15:14,795 --> 00:15:20,465
So this way he is gonna get a scalable
agent system with specialized components,

222
00:15:21,305 --> 00:15:23,525
which can be, implemented for documents.

223
00:15:24,075 --> 00:15:28,185
documents in a sense for reading,
for writing, for any such kind

224
00:15:28,185 --> 00:15:32,380
of matters, any interpretation,
like what kind of information is

225
00:15:32,380 --> 00:15:34,095
coming and how we need to process.

226
00:15:34,545 --> 00:15:34,635
And.

227
00:15:35,135 --> 00:15:41,975
Agent so that way a bank manager can relax
and let the agents do the task for him

228
00:15:42,155 --> 00:15:43,985
and he can take the decisions as needed.

229
00:15:44,975 --> 00:15:48,365
The results, if you really look at
both of these systems, these are,

230
00:15:48,635 --> 00:15:50,375
these results were remarkable.

231
00:15:51,065 --> 00:15:54,095
You can see 40% reduction
information, re time.

232
00:15:54,595 --> 00:15:58,375
He doesn't need to really go personally,
check the systems for report generation

233
00:15:58,375 --> 00:16:01,825
and all, and 65% improvement in accuracy.

234
00:16:02,740 --> 00:16:07,630
So there are no human errors and there
is no kind of rush kind of a thing.

235
00:16:07,930 --> 00:16:12,350
So that way you can see, the systems
are giving, like the improvement

236
00:16:12,350 --> 00:16:16,660
in accuracy and the reduction
in information retrieval, right?

237
00:16:16,900 --> 00:16:21,910
This way people can relax and
another case study is autonomous.

238
00:16:22,410 --> 00:16:23,070
The challenge.

239
00:16:23,570 --> 00:16:27,530
Where you can have, like with
very minimal human oversight

240
00:16:27,710 --> 00:16:29,060
while maintaining their quality.

241
00:16:29,150 --> 00:16:30,350
So that is the objective.

242
00:16:31,010 --> 00:16:35,890
So if you wanna implement a solution
to cater this need here, you can see

243
00:16:35,890 --> 00:16:42,070
like you can implement a agent system,
which can perform a different roles.

244
00:16:42,820 --> 00:16:47,890
One agent could be for coding, another
agent could be for testing, right?

245
00:16:48,130 --> 00:16:50,260
And another agent could
be for integrating.

246
00:16:50,760 --> 00:16:51,960
Of course, integration testing.

247
00:16:52,500 --> 00:16:57,330
So if you use these agents, the
results demonstrated out of this

248
00:16:57,330 --> 00:17:03,120
system would be a three x developer
productivity and 50% reduction in bug.

249
00:17:03,810 --> 00:17:08,940
So developer can actually give quality,
outcome, but using these agents and

250
00:17:08,940 --> 00:17:11,850
you can also be more efficient, right?

251
00:17:12,090 --> 00:17:17,410
So this is the outcome of agent, usage,
especially in the autonomous software.

252
00:17:17,910 --> 00:17:19,260
General purpose agents.

253
00:17:19,890 --> 00:17:23,790
So these are like general purpose
agents need a lot more information,

254
00:17:23,790 --> 00:17:28,030
lot more storage, lot more,
processing capabilities, right?

255
00:17:28,420 --> 00:17:33,070
So here these move beyond narrow,
specialized to handle diverse

256
00:17:33,070 --> 00:17:34,630
tasks across different domains.

257
00:17:35,130 --> 00:17:39,725
They maintain long memory and
accumulate experience over extended.

258
00:17:40,225 --> 00:17:43,165
So they should have all the
sophisticated information to

259
00:17:43,165 --> 00:17:45,295
maintain and to serve the clients.

260
00:17:45,925 --> 00:17:50,335
They transfer learning across
domains and applying insights

261
00:17:50,335 --> 00:17:51,685
from one area to another.

262
00:17:52,185 --> 00:17:56,990
The domain includes, it could be banking,
to insurance, and banking to, The

263
00:17:56,990 --> 00:18:00,470
trading systems, it can be of anything.

264
00:18:01,040 --> 00:18:05,630
They engage in meta reasoning about
their own capabilities and limitations,

265
00:18:06,590 --> 00:18:11,390
and they also develop sophisticated
understanding of human intent and

266
00:18:11,390 --> 00:18:13,340
beyond the explicit instructions.

267
00:18:13,840 --> 00:18:19,120
So these agents in the real world
can solve a lot of problems where

268
00:18:19,480 --> 00:18:21,250
a common human can, struggle with.

269
00:18:21,750 --> 00:18:26,670
While we're not there yet, especially for
the general purpose agents, architectural

270
00:18:26,670 --> 00:18:31,500
editions today will determine how quickly
and safely we approach this horizon.

271
00:18:32,010 --> 00:18:34,080
Let's wait and see how
soon that we can get there.

272
00:18:34,080 --> 00:18:39,410
But, and if you really look at, the
agent AI or any a system for that

273
00:18:39,410 --> 00:18:42,330
matter, ethical considerations are very

274
00:18:42,830 --> 00:18:43,310
values.

275
00:18:43,810 --> 00:18:45,160
And ethical considerations.

276
00:18:45,670 --> 00:18:48,160
So how we can actually balance right?

277
00:18:48,220 --> 00:18:49,660
What is more important?

278
00:18:50,160 --> 00:18:54,180
So especially when it comes to the
age and decision making, it's the

279
00:18:54,180 --> 00:18:58,650
transparency which is very essential
for an appropriate oversight.

280
00:18:59,150 --> 00:19:02,750
And then the accountability
mechanism we should ensure.

281
00:19:03,250 --> 00:19:08,760
Which should be built into a data
usage and memory systems, right?

282
00:19:08,760 --> 00:19:10,860
You can't really use data for any reason.

283
00:19:10,950 --> 00:19:15,840
So the user data should be protected,
and we need robust safeguard to

284
00:19:15,840 --> 00:19:18,210
prevent harmful emergent behaviors.

285
00:19:19,140 --> 00:19:21,930
So these are the things you may
need to consider when you're.

286
00:19:22,430 --> 00:19:25,700
in successful systems, you
need to see what can be

287
00:19:25,700 --> 00:19:27,380
incorporated, what shouldn't be.

288
00:19:28,220 --> 00:19:32,060
So separation of reasoning and
action allows for specialized

289
00:19:32,060 --> 00:19:33,830
optimization of each function.

290
00:19:34,330 --> 00:19:37,510
And you should also have explicit
verification steps, which

291
00:19:37,510 --> 00:19:39,340
should prevent cascading errors.

292
00:19:40,270 --> 00:19:42,930
And you should also
have strategic human in

293
00:19:43,430 --> 00:19:43,910
bottleneck.

294
00:19:44,410 --> 00:19:49,750
If you use agents for everything,
if agents stops doing mistakes, so

295
00:19:49,750 --> 00:19:54,070
if every time, if they're making
20% mistakes with five repetitions,

296
00:19:54,070 --> 00:19:55,810
you may see only the faulty system.

297
00:19:55,810 --> 00:20:00,070
So that's where human in the
loop checkpoints always needed

298
00:20:00,570 --> 00:20:04,105
and graceful handling of
uncertainty, which will avoid the.

299
00:20:04,605 --> 00:20:06,855
So anything that comes uncertainty, right?

300
00:20:07,005 --> 00:20:09,945
You should have always have the,
modes to correct the system.

301
00:20:10,845 --> 00:20:13,965
And continuous learning from
operational data, right?

302
00:20:14,465 --> 00:20:16,385
Which will be an ongoing improvement.

303
00:20:16,385 --> 00:20:19,385
So you should always
incorporate that, right?

304
00:20:19,775 --> 00:20:24,355
So these are the imaging patterns
you can use and directions.

305
00:20:24,855 --> 00:20:29,805
So if you really look at it as tasks
become more complex, specialization

306
00:20:29,805 --> 00:20:31,365
becomes increasingly valuable.

307
00:20:32,205 --> 00:20:37,015
This requires a sophisticated
communication, sorry, sophisticated

308
00:20:37,015 --> 00:20:40,465
communication protocols between
the heterogeneous agents.

309
00:20:41,155 --> 00:20:43,735
so how these agents can communicate.

310
00:20:44,235 --> 00:20:48,885
a bank manager to process, currents
and current account details and savings

311
00:20:48,885 --> 00:20:50,685
and loan account related information.

312
00:20:51,165 --> 00:20:55,005
So you may have the agents to
process all of these information from

313
00:20:55,005 --> 00:20:59,965
different, distributed agents and
giving that information to the, the

314
00:20:59,965 --> 00:21:04,825
bank manager to ensure that how the
specific tasks are being performed.

315
00:21:05,395 --> 00:21:08,275
So you have the centralized
information processing.

316
00:21:08,995 --> 00:21:09,745
Capability.

317
00:21:09,925 --> 00:21:13,165
And at the same time, agents are
actually interacting with the

318
00:21:13,165 --> 00:21:17,525
central system and they're actually
informing the bank manager to, use

319
00:21:17,525 --> 00:21:19,115
that information in an effective way.

320
00:21:19,775 --> 00:21:23,695
So this is the distributed,
multi-agent, system that you can build.

321
00:21:23,695 --> 00:21:26,815
And ultimately one information
will float outside.

322
00:21:27,745 --> 00:21:32,275
So in this case, the resource
sharing and allocation mechanism

323
00:21:32,275 --> 00:21:34,225
becomes for efficiency.

324
00:21:34,725 --> 00:21:37,635
So they need to, like what kind
of resources they need to share,

325
00:21:37,635 --> 00:21:41,955
like GPUs and memory or whatever
it's, and conflict resolution.

326
00:21:42,455 --> 00:21:47,345
That is very important for any kind
of agentic system to ensure that they

327
00:21:47,345 --> 00:21:51,445
are, prevented from deadlocks and
any kind of contradictory actions.

328
00:21:51,445 --> 00:21:55,065
So they have to do, they
should actually generate.

329
00:21:55,565 --> 00:22:00,575
Here, the ultimate goal is to emergent
collective intelligence systems that

330
00:22:00,575 --> 00:22:06,335
can solve problems no single agent
could solve with these kind of issues.

331
00:22:06,875 --> 00:22:09,245
So that's where you need to
have the, collective agents to,

332
00:22:09,675 --> 00:22:14,150
process the information, future
directions and adaptive systems.

333
00:22:14,650 --> 00:22:17,860
So these can dynamically
adjust the capabilities based

334
00:22:17,860 --> 00:22:19,210
on the task requirements.

335
00:22:19,710 --> 00:22:23,480
And they improve themselves
through operational excellence and

336
00:22:23,480 --> 00:22:26,990
not just leaving from data, but
learning from their own mistakes.

337
00:22:27,500 --> 00:22:30,110
So this is the beauty
of the adaptive systems.

338
00:22:30,860 --> 00:22:36,530
They automatically detect and mitigate
weakness without human intervention.

339
00:22:37,030 --> 00:22:40,120
They may manage resources
based on environmental

340
00:22:40,120 --> 00:22:41,950
constraints and opportunities.

341
00:22:42,450 --> 00:22:46,530
They implement context sensitive
safety mechanisms that, that

342
00:22:46,530 --> 00:22:48,210
adapt to changing risk profiles.

343
00:22:48,710 --> 00:22:53,180
The result is system that become
more capable and renewable over

344
00:22:53,180 --> 00:22:55,220
time through their own experience.

345
00:22:56,150 --> 00:23:00,900
So these are the systems you may want
to see in the futuristic way, right?

346
00:23:00,900 --> 00:23:02,370
the self-learning systems are.

347
00:23:03,330 --> 00:23:03,960
Better.

348
00:23:04,230 --> 00:23:08,670
But at the same time, there should
be checkpoints to ensure that, as

349
00:23:08,670 --> 00:23:13,410
I discussed in my previous slides,
the human feedback loop mechanism

350
00:23:13,410 --> 00:23:14,970
we should definitely incorporate.

351
00:23:15,510 --> 00:23:19,200
But the self adaptable systems,
you don't need to sit there and

352
00:23:19,200 --> 00:23:22,920
then train and they can learn by
themselves and become more efficient.

353
00:23:22,980 --> 00:23:26,460
But at the same time, human
feedback loops also, we should.

354
00:23:26,960 --> 00:23:31,370
Building for the future and the
key principles for agent ai.

355
00:23:31,870 --> 00:23:37,540
To summarize the architectural approach,
I advocate first, embrace modular design.

356
00:23:38,040 --> 00:23:42,450
So how do you wanna break down the
whole systems into sub components?

357
00:23:43,050 --> 00:23:45,420
Second is prioritize the observability.

358
00:23:45,920 --> 00:23:49,130
So you should ensure that the systems are.

359
00:23:49,630 --> 00:23:52,460
Debug, if there is any kind
of a system comes, system

360
00:23:52,460 --> 00:23:53,810
failure comes into the picture.

361
00:23:54,800 --> 00:24:01,370
Third is implement the controlled autonomy
with clear boundaries for agent decision.

362
00:24:01,870 --> 00:24:05,425
And the fourth one is develop
the scalable evaluation, the test

363
00:24:05,435 --> 00:24:08,135
system under diverse conditions.

364
00:24:08,715 --> 00:24:13,610
because you don't want system to, so it
should be tested in diverse conditions.

365
00:24:14,110 --> 00:24:18,290
Pass engineering and see if the system
is still reliable enough to, answer

366
00:24:18,290 --> 00:24:20,790
the, the questions asked by the user.

367
00:24:21,690 --> 00:24:27,400
Finally, integrate feedback continuously
from deployment to, to develop

368
00:24:27,400 --> 00:24:28,810
and, improvement related things.

369
00:24:29,380 --> 00:24:32,770
So you should have the, con
consistent feedback mechanism on the.

370
00:24:33,270 --> 00:24:38,340
Agent A represents a fundamental shift
in how we interact with technology.

371
00:24:38,840 --> 00:24:42,050
So this is essential, like
how you want to interact.

372
00:24:42,770 --> 00:24:49,040
these are the, whatever we discussed so
far, these things really makes, agents

373
00:24:49,040 --> 00:24:53,560
are like more, when you maintain all
of these things in a systematic way.

374
00:24:54,060 --> 00:24:59,300
So if you really look at now we are
moving from tools we operate to partner

375
00:24:59,870 --> 00:25:04,170
with, and to partner with the agents,
and also we also collaborate with them

376
00:25:04,170 --> 00:25:08,830
to ensure that, we get the, productivity
improvement and accuracy improvement.

377
00:25:09,550 --> 00:25:13,330
This transition request, thoughtful
architecture that balances

378
00:25:13,330 --> 00:25:14,920
capacity with reliability.

379
00:25:15,790 --> 00:25:18,460
So this is very essential
transitioning, like when.

380
00:25:18,960 --> 00:25:19,620
Human based.

381
00:25:20,120 --> 00:25:21,930
So you have to, maintain it.

382
00:25:22,710 --> 00:25:26,130
And success purely depends on
finding the right equilibrium

383
00:25:26,370 --> 00:25:28,350
between autonomy and oversight.

384
00:25:28,850 --> 00:25:33,260
And finally, the future belongs to
composable, adaptable agent systems

385
00:25:33,345 --> 00:25:35,155
that can evolve with our needs.

386
00:25:35,655 --> 00:25:36,085
Thank you.

387
00:25:36,585 --> 00:25:37,365
Reach on.

