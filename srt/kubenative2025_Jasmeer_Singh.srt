1
00:00:00,500 --> 00:00:01,339
Hello everyone.

2
00:00:01,880 --> 00:00:03,290
Thank you for joining me today.

3
00:00:03,320 --> 00:00:04,850
My name is Jmir Sink.

4
00:00:05,450 --> 00:00:09,530
Today I'll be sharing how predictive
manufacturing analytics can be scaled

5
00:00:09,530 --> 00:00:12,800
using Kubernetes powered CRM systems.

6
00:00:13,300 --> 00:00:18,515
The big idea is this, when companies
move from reactive service models to

7
00:00:18,520 --> 00:00:23,920
predictive proactive ones, they can
unlock massive value, including the.

8
00:00:24,670 --> 00:00:27,160
The potential for dramatic revenue growth.

9
00:00:27,970 --> 00:00:29,920
Now let's dive right into it.

10
00:00:30,160 --> 00:00:31,840
I'm gonna start sharing my screen.

11
00:00:32,340 --> 00:00:36,420
Manufacturers face a big
challenge after market services.

12
00:00:36,570 --> 00:00:41,670
Things like maintenance and spare
parts represent a huge revenue

13
00:00:41,670 --> 00:00:45,840
opportunity, but most companies
don't capture it effectively.

14
00:00:46,455 --> 00:00:46,964
Why?

15
00:00:47,535 --> 00:00:48,825
Because they're reactive.

16
00:00:49,605 --> 00:00:52,035
Equipment breaks, then they respond.

17
00:00:52,545 --> 00:00:58,305
Even with digital initiatives, many can't
scale predictive service models, but if

18
00:00:58,305 --> 00:01:05,085
organizations shift towards predictive
analytics driven operations, they can

19
00:01:05,085 --> 00:01:09,795
move from firefighting to creating
real time enterprise scale value.

20
00:01:10,295 --> 00:01:12,634
Traditional CRMs weren't built for this.

21
00:01:13,505 --> 00:01:18,725
They were designed for tracking customer
interactions, not billions of iot signals.

22
00:01:19,175 --> 00:01:21,875
They're monolithic, so scaling is hard.

23
00:01:22,414 --> 00:01:23,914
They struggle with velocity.

24
00:01:24,365 --> 00:01:29,164
The speed of realtime streams and
volume of customer data explodes, and

25
00:01:29,164 --> 00:01:31,445
it all leads to a lot of problems.

26
00:01:31,895 --> 00:01:36,274
So if manufacturers want predictive
insights, they can't just

27
00:01:36,274 --> 00:01:38,315
rely on old CRM architectures.

28
00:01:38,735 --> 00:01:41,195
They need systems that scale natively.

29
00:01:41,695 --> 00:01:45,295
This is where Kubernetes
really changes things.

30
00:01:45,415 --> 00:01:49,495
By moving to Kubernetes native
architectures, we can break

31
00:01:49,495 --> 00:01:55,255
analytics into containerized,
microservices, small modular pieces

32
00:01:55,884 --> 00:01:57,805
that are easy to reuse and scale.

33
00:01:58,405 --> 00:02:02,455
When demand spikes, Kubernetes
automatically scales resources

34
00:02:02,455 --> 00:02:04,405
up when demand falls.

35
00:02:04,780 --> 00:02:06,190
It dials them back down.

36
00:02:06,729 --> 00:02:08,949
That means performance when you need it.

37
00:02:09,070 --> 00:02:11,019
Cost saving when you don't.

38
00:02:11,519 --> 00:02:14,549
So what does a realtime
pipeline actually look like?

39
00:02:14,969 --> 00:02:20,939
It starts with iot ingestion,
sensor streaming, nonstop capturing,

40
00:02:21,119 --> 00:02:24,059
captured by containerized collectors.

41
00:02:24,559 --> 00:02:24,890
Then comes.

42
00:02:25,390 --> 00:02:31,840
Service history, all the maintenance
logs and repair records analyzed in

43
00:02:31,840 --> 00:02:34,600
distributed fashion to surface patterns.

44
00:02:35,049 --> 00:02:40,450
On top of that machine learning
models, inside Kubernetes pods model,

45
00:02:40,450 --> 00:02:42,445
customer behavior and usage trends.

46
00:02:42,945 --> 00:02:45,795
Finally, predictive insights
are delivered in real time

47
00:02:46,124 --> 00:02:47,804
through auto-scaling services.

48
00:02:48,494 --> 00:02:53,465
So you're taking raw sensor noise,
combining it with history and behavior,

49
00:02:53,735 --> 00:02:55,984
and turning it into actionable insight.

50
00:02:56,484 --> 00:03:01,105
If we go a little deeper into the
architecture, we've got containerized

51
00:03:01,105 --> 00:03:06,204
pipelines with helm managed machine
learning deployments, auto-scaling

52
00:03:06,535 --> 00:03:08,304
services, keep things responsive.

53
00:03:09,010 --> 00:03:12,909
While even driven architectures
react instantly as data comes in

54
00:03:13,689 --> 00:03:19,109
on Kubernetes itself, jobs handle
batch analytics, CR jobs schedule

55
00:03:19,109 --> 00:03:25,369
recurring tasks, custom operators
streamline machine line workflows and

56
00:03:25,369 --> 00:03:27,979
state full sets manage persistence.

57
00:03:28,479 --> 00:03:32,139
Each piece has a role, and
together they form a flexible

58
00:03:32,139 --> 00:03:34,029
backbone for predictive analytics.

59
00:03:34,529 --> 00:03:38,640
When companies design systems
like this, the impact is clear.

60
00:03:39,059 --> 00:03:43,019
Customers stick around longer
because service is proactive.

61
00:03:43,619 --> 00:03:47,729
Downtime drops sharply thanks to
predictive maintenance, and most

62
00:03:47,729 --> 00:03:52,499
importantly, service revenue grows
because resources are allocated at

63
00:03:52,499 --> 00:03:54,390
the right time in the right way.

64
00:03:54,890 --> 00:03:58,010
There are a few orchestration
strategies worth highlighting.

65
00:03:58,510 --> 00:04:03,430
Use persistent volumes for stateful
data, so context isn't lost.

66
00:04:03,930 --> 00:04:10,349
Distribute model training across multiple
pods so it scales efficiently and use

67
00:04:10,380 --> 00:04:13,140
event driven triggers inside Kubernetes.

68
00:04:13,640 --> 00:04:17,900
So predictions handle happen
the instant data arise.

69
00:04:18,400 --> 00:04:22,720
Resource allocation is where
performance really lives or dies.

70
00:04:23,080 --> 00:04:25,630
CPU allocation should be dynamic.

71
00:04:26,170 --> 00:04:29,110
Workloads get compute
power when they need it.

72
00:04:29,680 --> 00:04:35,380
Memory should be managed with limits
and affinity rules, so no single pod

73
00:04:35,440 --> 00:04:38,470
hogs, the cluster and for storage.

74
00:04:39,310 --> 00:04:43,840
Persistent volumes handle model
artifacts you need to keep.

75
00:04:44,080 --> 00:04:48,160
While a femoral storage takes
care of temporary workloads,

76
00:04:48,660 --> 00:04:51,510
A typical orchestration
flow looks like this.

77
00:04:51,900 --> 00:04:56,190
Data comes in from manufacturing
systems, goes through EDL for

78
00:04:56,190 --> 00:05:01,050
cleaning, then analytics for
feature engineering and inference.

79
00:05:01,980 --> 00:05:08,040
Finally, predictions get pushed out
through APIs, into CRMs and dashboards.

80
00:05:08,850 --> 00:05:14,160
Simple flow data comes in, gets
cleaned and enriched, and delivered.

81
00:05:14,660 --> 00:05:17,000
Of course, monitoring is critical.

82
00:05:17,030 --> 00:05:23,180
On the application side, you should track
accuracy, drift latency, and data quality.

83
00:05:23,600 --> 00:05:26,540
On the infrastructure side,
it's about monitoring.

84
00:05:27,040 --> 00:05:32,350
Monitoring PO resource use, scaling
events and storage performance.

85
00:05:32,800 --> 00:05:38,140
Without good monitoring, you won't
catch issues before they spiral.

86
00:05:38,640 --> 00:05:42,960
There are pitfalls to watch for
if you don't set proper resources.

87
00:05:43,020 --> 00:05:47,850
Resource requests and limits workloads
will compete and slow each other.

88
00:05:48,350 --> 00:05:51,740
Each other down if you
don't design data access.

89
00:05:51,790 --> 00:05:57,130
IO bottlenecks creep in fast, and
if state isn't managed properly,

90
00:05:57,160 --> 00:06:01,360
models and intermediate data
can disappear during scaling.

91
00:06:01,930 --> 00:06:05,055
These are avoidable, but
only if planned for upfront.

92
00:06:05,555 --> 00:06:09,505
Finally, resilience production
systems should be able to

93
00:06:09,505 --> 00:06:11,100
handle failure without breaking.

94
00:06:11,600 --> 00:06:16,430
That means multi-zone deployments,
circuit breakers for fall tolerance

95
00:06:16,430 --> 00:06:20,150
and horizontal scaling policies to
balance workloads automatically.

96
00:06:20,870 --> 00:06:23,450
And of course, persistent
volumes and backups.

97
00:06:23,450 --> 00:06:24,410
Keep data safe.

98
00:06:25,070 --> 00:06:29,960
Resilience is what turns and experiment
into something the business can rely on.

99
00:06:30,460 --> 00:06:34,885
So to wrap up scaling predictive
manufacturing analytics isn't just about

100
00:06:34,885 --> 00:06:36,775
analytics, it's about architecture.

101
00:06:37,720 --> 00:06:43,210
Kubernetes native arch native systems
give us the scalability, efficiency,

102
00:06:43,300 --> 00:06:47,010
and resilience needed to move from
reactive service to predictive

103
00:06:47,010 --> 00:06:50,820
operations, and that's where the
real business impact comes from.

104
00:06:51,510 --> 00:06:53,250
Thank you so much for joining me today.

105
00:06:53,310 --> 00:06:56,040
I'd be glad to continue this
discussion and answer your

106
00:06:56,040 --> 00:06:57,630
questions after this session.

107
00:06:58,410 --> 00:06:58,860
Thank you.

