1
00:00:00,049 --> 00:00:00,679
hello everyone.

2
00:00:01,250 --> 00:00:02,689
I'm Kumar Madla.

3
00:00:03,229 --> 00:00:07,009
Today I'm going to present what
are the advantages of auto ML

4
00:00:07,339 --> 00:00:09,200
and how auto ML is transforming.

5
00:00:09,739 --> 00:00:14,869
Predictive analytics with 60
to 80% of foster development.

6
00:00:15,829 --> 00:00:20,459
I'm currently working as a senior data
scientist at PepsiCo, and I had ma I did

7
00:00:20,459 --> 00:00:25,769
my masters in artificial intelligence
from University of EBA back in 20 at 13.

8
00:00:25,859 --> 00:00:30,149
I had a total of 11 plus years
of experience working in data

9
00:00:30,149 --> 00:00:32,310
science, machine learning,
and artificial intelligence.

10
00:00:32,340 --> 00:00:36,140
And I have implemented projects in
multiple industries ranging from

11
00:00:36,680 --> 00:00:40,430
retail, healthcare, manufacturing,
banking, and finance sectors.

12
00:00:40,700 --> 00:00:44,520
So based on all my experience
and my expertise, I'm going

13
00:00:44,520 --> 00:00:45,650
to present this today.

14
00:00:46,730 --> 00:00:51,950
So my topic title is Democratizing
Enterprise ai, how Auto ML is Transforming

15
00:00:51,950 --> 00:00:57,170
Predictive Analytics with 60 to
80% faster deployment Development.

16
00:00:59,415 --> 00:01:04,335
Before understanding this Auto ml in
olden days we were using different

17
00:01:04,335 --> 00:01:08,415
machine learning models and different
hyper parameter configurations, and it

18
00:01:08,415 --> 00:01:12,945
is taking more time whenever you take any
problem and we have to, if you have to

19
00:01:12,945 --> 00:01:16,945
develop a predictive analytics solution
being it classification, recreation

20
00:01:16,945 --> 00:01:21,615
or clustering we have multiple machine
learning models and each algorithm has.

21
00:01:22,045 --> 00:01:23,725
And number of hyper parameters.

22
00:01:24,055 --> 00:01:27,645
And each hyper parameter
takes many different values.

23
00:01:27,975 --> 00:01:32,695
Building multiple models and tuning
those hyper parameters, multiple hyper

24
00:01:32,695 --> 00:01:36,595
parameters in the, coming up with
the best model takes a lot of time.

25
00:01:37,105 --> 00:01:38,815
But with the advent of these.

26
00:01:39,105 --> 00:01:42,745
Auto ML techniques there is a
paradigm shift in the way that

27
00:01:42,805 --> 00:01:46,345
machine learning engineers or data
scientists are developing these

28
00:01:47,005 --> 00:01:50,125
machine learning models for different
problems that they're working on.

29
00:01:50,605 --> 00:01:54,905
So these are the advantages, main
advantages of auto ML techniques.

30
00:01:55,295 --> 00:01:59,975
So this automobile techniques encompasses
and the tools that automate traditionally.

31
00:02:00,580 --> 00:02:05,830
Manual expertise dependent processes
from data preprocessing and feature

32
00:02:05,830 --> 00:02:10,060
engineering tool algorithm selection
and hyper parameter optimization.

33
00:02:10,840 --> 00:02:16,379
And another advantage of using these
autos the bridge, the talent gap if you

34
00:02:16,379 --> 00:02:21,539
how to build a different machine learning
models, if without having these auto

35
00:02:21,539 --> 00:02:25,829
ml, you need to hire a machine learning
engineer or a data scientist to build.

36
00:02:26,214 --> 00:02:28,974
These different models and
to come up with a solution.

37
00:02:29,394 --> 00:02:33,514
But by using these auto techniques,
you can effectively bridge the

38
00:02:33,514 --> 00:02:38,554
talent gap that has constrained many
organizations, analytical capabilities,

39
00:02:38,944 --> 00:02:44,214
enabling business analyst and domain
experts to develop predictive models

40
00:02:44,484 --> 00:02:47,734
without extensive program expertise.

41
00:02:48,604 --> 00:02:50,704
So these are the evolving capabilities.

42
00:02:51,349 --> 00:02:56,109
As I said early systems focused primarily
on AMIC selection and hyper parameter.

43
00:02:56,739 --> 00:03:04,779
And the recent developments in the
ml focuses not only on algorithmic

44
00:03:04,779 --> 00:03:08,589
selection and the hyper parameter
tuning, they also address the

45
00:03:08,589 --> 00:03:12,969
entire machine learning pipeline,
including deployment and monitoring.

46
00:03:14,740 --> 00:03:20,020
So these are the theoretical foundations
of, as we initially discussed in the

47
00:03:20,020 --> 00:03:23,750
previous slide, these are the common.

48
00:03:24,275 --> 00:03:26,435
Or basic foundations of auto.

49
00:03:26,975 --> 00:03:31,295
So one is the, so this optimization
theory employs various strategies

50
00:03:31,295 --> 00:03:34,975
to navigate where as they discussed
in the beginning of the session.

51
00:03:35,365 --> 00:03:39,115
So these machine learning models have
different hyper parameter configurations

52
00:03:39,115 --> 00:03:42,385
and each configuration, each hyper
parameter has multiple values.

53
00:03:43,105 --> 00:03:46,015
So this is related to this
optimization in theory.

54
00:03:46,375 --> 00:03:49,675
So what algorithm to use and
what hyper parameter tool.

55
00:03:50,450 --> 00:03:54,230
Tune and what are the best values
for those hyper parameters comes

56
00:03:54,230 --> 00:03:58,999
under this optimization theory
and the second foundation for

57
00:03:58,999 --> 00:04:01,100
auto ML is the meta learning.

58
00:04:01,400 --> 00:04:02,909
So this meta learning includes, I.

59
00:04:04,634 --> 00:04:09,984
How to learn across data sets and modeling
tasks modeling tasks here, it can be

60
00:04:09,984 --> 00:04:11,904
regression classification or clustering.

61
00:04:12,204 --> 00:04:16,494
And how do we train multiple models
to come up with the best model to

62
00:04:16,494 --> 00:04:18,834
use it in the real time and the comp.

63
00:04:19,015 --> 00:04:22,945
The next third foundation for
this art M is the computational

64
00:04:22,974 --> 00:04:28,284
efficiency, balancing exploration and
exploitation during the model training.

65
00:04:28,630 --> 00:04:33,520
Comes under this computational a, c, and
C. So we should not focus only on the

66
00:04:33,520 --> 00:04:36,340
exploration or only on the exploitation.

67
00:04:36,700 --> 00:04:41,930
So we have to do a balance between
the exploration and exploitation while

68
00:04:42,440 --> 00:04:44,230
training these machine learning models.

69
00:04:44,830 --> 00:04:51,190
So these automal systems leverage these
foundations to efficiently identify

70
00:04:51,940 --> 00:04:56,410
promising solutions while transferring
knowledge between the problems.

71
00:04:57,520 --> 00:05:02,560
The employee techniques such as base
optimization, genetic algorithms, and

72
00:05:02,560 --> 00:05:09,370
gradient based approaches to navigate
the complex space of possible model

73
00:05:09,370 --> 00:05:13,990
configurations significantly, and also
the significantly improve the efficiency

74
00:05:13,990 --> 00:05:17,350
and performance of traditional systems.

75
00:05:18,385 --> 00:05:22,375
So this is how the auto ML
frameworks have been about.

76
00:05:22,825 --> 00:05:27,425
So it initially started with auto
which was introduced in 2013.

77
00:05:27,815 --> 00:05:28,595
So this auto.

78
00:05:29,555 --> 00:05:34,445
Pioneered combined algorithmic selection
and hyper parameter optimization,

79
00:05:35,165 --> 00:05:39,025
and it established the foundation
of subsequent auto ml frameworks.

80
00:05:39,325 --> 00:05:43,165
This is the first in the auto ml
frameworks or auto ML techniques

81
00:05:43,575 --> 00:05:47,745
which was introduced by automaker
and then it followed by autos, KN.

82
00:05:47,865 --> 00:05:52,395
So this autos, KN not only involves
hyper parameter optimization

83
00:05:52,545 --> 00:05:53,805
and algorithmic selection.

84
00:05:54,420 --> 00:05:57,190
It also introduced the
transfer learning concept.

85
00:05:57,400 --> 00:05:59,050
So what does it mean by transfer?

86
00:05:59,050 --> 00:06:06,310
Learning is so the, any model or
algorithm that was trained on one task

87
00:06:06,790 --> 00:06:10,640
can be used to retrain on another task.

88
00:06:10,730 --> 00:06:14,000
Maybe we can take an example
of any deep planning models

89
00:06:14,000 --> 00:06:15,650
or image recognition models.

90
00:06:16,130 --> 00:06:18,080
So the models that were trained to.

91
00:06:19,805 --> 00:06:27,695
Identify cats and dogs can be used to
retrain from last couple of layers to

92
00:06:27,695 --> 00:06:34,065
identify other things other animals
like horses of, or any other animals.

93
00:06:34,065 --> 00:06:40,745
So this comes under transfer learning and
nowadays there are more advanced auto ml.

94
00:06:41,630 --> 00:06:44,060
Frameworks are coming up into the market.

95
00:06:44,360 --> 00:06:49,280
They not only focus on hyper
parameter optimization and algorithmic

96
00:06:49,280 --> 00:06:54,785
selection, they also focus on
data preprocessing and other data

97
00:06:54,785 --> 00:06:56,285
preparation and other techniques.

98
00:06:56,535 --> 00:07:00,425
Some of the notable players in this
end-to-end platforms are Google

99
00:07:00,425 --> 00:07:05,974
Cloud, R ml, and H2O is driverless
a and they extend automation

100
00:07:05,974 --> 00:07:08,284
across the entire ML lifecycle.

101
00:07:09,390 --> 00:07:11,480
This is an extension
to the previous slide.

102
00:07:11,540 --> 00:07:13,880
These are the prominent
auto ML framework analysis.

103
00:07:14,450 --> 00:07:21,800
Now I'm comparing the differences between
Autor, IBM's Auto, aa, and Microsoft.

104
00:07:22,090 --> 00:07:28,400
And I, as we discussed it in the
previous slide auto was introduced in

105
00:07:28,760 --> 00:07:34,580
2013, and it focuses more mostly on
the algorithmic selection and hyper.

106
00:07:35,399 --> 00:07:35,939
Tuning.

107
00:07:36,199 --> 00:07:40,499
And the technique is called sequential
model based algorithmic configuration,

108
00:07:40,859 --> 00:07:45,119
and it uses patient optimization to
navigate these complex set spaces.

109
00:07:45,869 --> 00:07:49,929
And in 2023 KDD has awarded auto.

110
00:07:51,499 --> 00:07:54,169
As a test time award in 2013.

111
00:07:54,229 --> 00:07:54,829
20, sorry.

112
00:07:54,834 --> 00:08:02,400
2023. IBM's next one is IBM's Auto A.
It extends traditional capabilities by

113
00:08:02,459 --> 00:08:07,919
addressing the entire machine learning
lifecycle within enterprise context.

114
00:08:08,849 --> 00:08:12,599
It also includes automated
data preparation, feature

115
00:08:12,599 --> 00:08:17,369
engineering, model selection,
and high parameter optimization.

116
00:08:18,855 --> 00:08:25,214
The main difference with respect to IBM's
Auto AAEs, it has a strong integration

117
00:08:25,214 --> 00:08:31,155
with IBM's Watson Ecosystem and it
enterprise focused features like built in

118
00:08:31,155 --> 00:08:34,424
fairness checks and explainability tools.

119
00:08:35,444 --> 00:08:35,865
The third one.

120
00:08:37,125 --> 00:08:40,155
In this comparison is a Microsoft's NNI.

121
00:08:40,814 --> 00:08:45,555
It takes a specialized approach
focusing on neural network optimization

122
00:08:45,555 --> 00:08:48,255
and automated deep learning.

123
00:08:49,185 --> 00:08:52,845
It provides infrastructure and a
neural architecture search, hyper

124
00:08:52,845 --> 00:08:57,255
parameter tuning and model compression
through a highly modular framework.

125
00:08:58,155 --> 00:09:03,585
It also supports deep learning
frameworks such as tensor flow by, sorry.

126
00:09:03,805 --> 00:09:05,455
It's such as the tensor flow.

127
00:09:06,580 --> 00:09:09,490
By touch, et cetera.

128
00:09:10,390 --> 00:09:15,770
It offers flexible deployment options
across diverse computing environments.

129
00:09:16,770 --> 00:09:19,650
This is the framework comparison,
strengths and limitations.

130
00:09:20,080 --> 00:09:24,100
These are the different strengths
and limitations of the three

131
00:09:24,160 --> 00:09:25,720
frameworks that we have discussed.

132
00:09:25,720 --> 00:09:29,260
Auto, IBM's Auto, a I, and Microsoft.

133
00:09:29,310 --> 00:09:32,785
And I let us first start with the auto.

134
00:09:34,375 --> 00:09:38,515
So the primary strength
of Otca is in pioneering.

135
00:09:39,265 --> 00:09:40,525
Cash solution.

136
00:09:41,485 --> 00:09:45,025
And it also integrates with
established ML toolkit and it

137
00:09:45,025 --> 00:09:46,855
has a strong academic foundation.

138
00:09:47,665 --> 00:09:53,095
And the key limitations with AKA is it
has a limited end-to-end automation.

139
00:09:53,365 --> 00:09:58,715
It has less support for deep learning,
minimal enterprise integration features.

140
00:10:00,935 --> 00:10:05,925
And the best enterprise use cases
for using auto is academic research.

141
00:10:06,400 --> 00:10:11,910
For developing proof of concept projects,
and it'll be suitable for organizations

142
00:10:11,910 --> 00:10:13,650
with existing WCA investments.

143
00:10:14,580 --> 00:10:17,890
The next one is auto EI which is from IBM.

144
00:10:19,000 --> 00:10:23,920
The primary sense of auto from
IBM is its end to end ML lifecycle

145
00:10:23,920 --> 00:10:28,510
Automation, built in fairness and
explainability tools strong, and it

146
00:10:28,510 --> 00:10:30,130
has a strong enterprise integration.

147
00:10:31,780 --> 00:10:36,570
The key limitations, it can be
limitation for some of the users.

148
00:10:36,940 --> 00:10:40,910
We will have a vendor lock in with
IBM, and it's a proprietary ecosystem.

149
00:10:40,910 --> 00:10:45,400
It may be expensive for some clients, and
it is higher implementation complexity.

150
00:10:45,790 --> 00:10:51,680
The complexity of implementing IBM's auto,
difficult and the best enterprise use case

151
00:10:51,680 --> 00:10:57,080
for IBM's Auto AEs regulated industries
like finance and healthcare organizations

152
00:10:57,080 --> 00:11:01,400
since existing IBM infrastructure
application requiring explainability.

153
00:11:02,840 --> 00:11:07,110
The third one in this comparison
is and I from Microsoft.

154
00:11:07,635 --> 00:11:11,685
The primary strength of NI is it's
deep learning specialization, multi

155
00:11:11,685 --> 00:11:15,435
framework support, flexible deployment
options, and the key limitations.

156
00:11:15,825 --> 00:11:20,805
It has a steep learning curve, less
focus on classical ML algorithms and

157
00:11:20,805 --> 00:11:22,595
requires more technical expertise.

158
00:11:23,855 --> 00:11:29,255
Best enterprise use cases are day planning
applications, optimizations with teams

159
00:11:29,255 --> 00:11:31,480
with strong technical capabilities.

160
00:11:32,480 --> 00:11:35,210
These are the enterprise
integration considerations.

161
00:11:36,530 --> 00:11:42,470
So IT infrastructure integration
organizations must evaluate compatibility

162
00:11:42,470 --> 00:11:48,230
with current data, current storage
solutions, processing frameworks, and

163
00:11:48,230 --> 00:11:52,640
more and model deployment infrastructure.

164
00:11:53,365 --> 00:11:57,440
A PA based integration approaches
have emerge as preferred.

165
00:11:58,865 --> 00:12:02,345
Allowing auto ML systems to interact
with existing data pipelines

166
00:12:02,465 --> 00:12:03,815
while minimizing disruption.

167
00:12:05,255 --> 00:12:06,935
And these are the deployment options.

168
00:12:08,135 --> 00:12:13,205
Cloud-based deployments offer
scalability, but may introduce

169
00:12:13,295 --> 00:12:15,005
data movement challenges.

170
00:12:15,305 --> 00:12:19,085
So when you have to implement a solution
in the cloud-based infrastructure,

171
00:12:19,505 --> 00:12:24,155
you may have to move your data from
in-house systems to cloud-based systems,

172
00:12:24,155 --> 00:12:25,790
which comes with some cost and time.

173
00:12:27,095 --> 00:12:32,915
On-premises implementations provide
greater control, but require significant

174
00:12:32,915 --> 00:12:37,715
computational resources and the
middle ground like hybrid approach.

175
00:12:37,775 --> 00:12:40,805
Leveraging containerization
and orchestration technologies

176
00:12:41,165 --> 00:12:44,615
present a promising middle ground
data governance requirements.

177
00:12:44,915 --> 00:12:48,575
Robust mechanisms for data quality
assessment, version control.

178
00:12:48,845 --> 00:12:52,235
Linear tracking and access
control are essential.

179
00:12:52,685 --> 00:12:56,050
Auto assistance typically require
substantial volumes of training data.

180
00:12:57,050 --> 00:13:00,740
Amplifying the importance of
governance frameworks that ensure

181
00:13:00,740 --> 00:13:03,380
data accuracy and appropriate use.

182
00:13:06,230 --> 00:13:10,430
Organizational adoption for
auto MR. Traditional boundaries

183
00:13:10,430 --> 00:13:15,680
between engineering, data science
and ation analysis roles often

184
00:13:15,680 --> 00:13:18,500
blur as auto ML democratizes.

185
00:13:19,145 --> 00:13:23,825
Model development capabilities
and these auto ML establishes

186
00:13:23,825 --> 00:13:25,175
cross-functional governance.

187
00:13:25,385 --> 00:13:29,585
Successful implementations typically
establish cross-functional teams

188
00:13:30,095 --> 00:13:37,145
responsible for model governance with
clearly defined hands of between automated

189
00:13:37,385 --> 00:13:43,025
and human LED processes, implement
change management address potential.

190
00:13:43,640 --> 00:13:48,410
Resistance from technical specialists
while encouraging responsible

191
00:13:48,500 --> 00:13:54,320
adoption by business users through
targeted training and communication.

192
00:13:55,640 --> 00:13:57,020
Create tiered approaches.

193
00:13:57,590 --> 00:14:01,280
Many organizations implement tiered
approaches where straightforward

194
00:14:01,280 --> 00:14:07,370
predictive tasks leverage auto ml, while
complex mission critical applications

195
00:14:07,370 --> 00:14:09,110
maintain greater human oversight.

196
00:14:10,400 --> 00:14:12,380
These are the enterprise benefits.

197
00:14:13,445 --> 00:14:18,635
Of using auto, 60 to 80% of the
development time will be reduced by

198
00:14:18,635 --> 00:14:23,405
using these auto ML techniques or
strategies, and there will be a return

199
00:14:23,405 --> 00:14:28,505
on investment within 12 to 18 months
of adopting these auto ML strategies.

200
00:14:29,585 --> 00:14:34,055
And there will be 30% reduction
in downtime when using these

201
00:14:34,055 --> 00:14:36,005
optimal strategies or techniques.

202
00:14:37,085 --> 00:14:39,365
Democratization of predict two analytics.

203
00:14:39,365 --> 00:14:40,985
The first one is expanded access.

204
00:14:41,600 --> 00:14:45,890
Auto ML enables business analysts,
domain experts, and non-specialists to

205
00:14:45,890 --> 00:14:51,080
develop sophisticated predictive models
with less machine learning knowledge.

206
00:14:52,070 --> 00:14:57,290
Breaking down silos allows those
closest to business problems to direct

207
00:14:57,290 --> 00:14:58,880
end engine and solution development.

208
00:14:59,480 --> 00:15:00,680
Citizen data science.

209
00:15:01,130 --> 00:15:05,480
Many enterprises establish citizen
data scientist programs with auto

210
00:15:05,480 --> 00:15:07,790
ML as the technological foundation.

211
00:15:09,200 --> 00:15:13,130
Multiply the capabilities
effectively multiplies analytical

212
00:15:13,130 --> 00:15:17,420
capabilities without proportional
increases in specialized hiring.

213
00:15:19,190 --> 00:15:23,030
These are the implementation
challenges, interpretability concerns.

214
00:15:24,050 --> 00:15:27,650
Automated approaches often generate
complex models resistant to

215
00:15:27,650 --> 00:15:29,150
straightforward human understanding.

216
00:15:29,720 --> 00:15:34,520
Data quality dependencies systems
remain foundationally, fundamentally

217
00:15:34,520 --> 00:15:38,210
dependent on data quality, potentially
amplifying underlying issues,

218
00:15:38,630 --> 00:15:40,130
domain specific requirements.

219
00:15:40,940 --> 00:15:45,440
Generic solutions often struggle with
highly specialized domain problems

220
00:15:45,800 --> 00:15:48,200
requiring industry specific approaches.

221
00:15:48,290 --> 00:15:54,500
Technical debt, cremation, unmanaged
adoption can accelerate technical debt.

222
00:15:55,340 --> 00:15:59,300
Through model proliferation
without adequate governance.

223
00:16:00,320 --> 00:16:03,980
These are some of the strategies
to overcome those challenges.

224
00:16:04,650 --> 00:16:10,320
Implement explainable a address data
quality, enable domain customization.

225
00:16:11,340 --> 00:16:13,440
So the first one is
implement explainable ai.

226
00:16:14,365 --> 00:16:18,345
So integrated explainable AI
techniques alongside auto ml establish

227
00:16:18,690 --> 00:16:23,640
interpretability thresholds for
different application categories and.

228
00:16:24,630 --> 00:16:28,440
Maintain simpler model adoption
for high transparency requirements.

229
00:16:29,700 --> 00:16:35,430
Address data quality, implement
systematic data quality assessment

230
00:16:35,460 --> 00:16:37,470
prior to auto ML deployment.

231
00:16:39,120 --> 00:16:43,890
Automated data quality monitoring clear
processes for handling quality exceptions

232
00:16:44,520 --> 00:16:46,830
and realistic expectation setting.

233
00:16:47,640 --> 00:16:50,940
Establish data quality
thresholds that must be satisfied

234
00:16:50,940 --> 00:16:52,680
before automated modeling.

235
00:16:53,415 --> 00:16:56,625
Proceeds enable domain customization.

236
00:16:57,195 --> 00:17:01,575
Develop customized autoAML frameworks
that incorporate domain knowledge via

237
00:17:01,935 --> 00:17:07,060
specialized pre-processing pipelines,
custom algorithm implementations, domain

238
00:17:07,060 --> 00:17:13,635
specific object, two functions and expert
guided constraints on model exploration.

239
00:17:14,635 --> 00:17:16,105
These are the future directions.

240
00:17:17,410 --> 00:17:23,740
For using auto explainable a integration,
next generation auto ML frameworks

241
00:17:23,740 --> 00:17:28,450
are incorporating explainability by
design rather than as in afterthought.

242
00:17:29,380 --> 00:17:32,830
This includes optimization objectives
that balance predictable performance

243
00:17:32,830 --> 00:17:37,120
with interpretability metrics and
automatic generation of explanation

244
00:17:37,780 --> 00:17:43,150
artifacts, edge computing applications,
auto resistance, specifically designed

245
00:17:43,150 --> 00:17:45,550
to optimize models for edge development.

246
00:17:47,845 --> 00:17:52,615
Considering resource constraints, power
limitations, and specialized hardware

247
00:17:52,615 --> 00:17:57,835
accelerators, these systems automatically
balance model complexity against

248
00:17:57,895 --> 00:17:59,695
inference speed and memory footprint.

249
00:18:01,075 --> 00:18:07,375
Federated approaches converging with
auto ml to address data privacy and

250
00:18:07,375 --> 00:18:10,645
sovereignty challenges, enabling
prediction model development

251
00:18:11,365 --> 00:18:14,605
across decentralized data sources.

252
00:18:14,965 --> 00:18:21,115
Without requiring data centralization,
regulatory aware, evolving regulatory

253
00:18:21,115 --> 00:18:25,945
frameworks are driving innovation
in automated compliance verification

254
00:18:25,945 --> 00:18:31,015
and documentation generation with
systems incorporating regulatory

255
00:18:31,015 --> 00:18:33,895
awareness directly into optimization.

256
00:18:33,895 --> 00:18:34,465
Objectives.

257
00:18:35,370 --> 00:18:37,080
Enterprise implementation roadmap.

258
00:18:37,885 --> 00:18:39,205
Assessment and planning.

259
00:18:39,745 --> 00:18:44,425
Identify high value use cases, evaluate
data readiness, select appropriate

260
00:18:44,425 --> 00:18:46,735
framework and define governance structure.

261
00:18:48,445 --> 00:18:51,580
Success metrics include prioritize,
use case portfolio, and.

262
00:18:52,420 --> 00:18:53,890
Established success criteria.

263
00:18:53,920 --> 00:18:57,520
Common challenges include
unrealistic expectations and

264
00:18:57,520 --> 00:18:58,690
insufficient data quality.

265
00:18:58,690 --> 00:19:03,610
Assessment, initial implementation,
deploy optimal for targeted use cases,

266
00:19:03,700 --> 00:19:07,120
established and monitoring and evaluation.

267
00:19:07,360 --> 00:19:10,780
Train initial user cohort,
and document early learnings.

268
00:19:11,320 --> 00:19:16,120
Success metrics include model performance
metrics and development time reduction.

269
00:19:16,270 --> 00:19:17,260
Challenges include.

270
00:19:17,680 --> 00:19:21,520
Technical integration issues and
resistance from data scientists, scaling

271
00:19:21,520 --> 00:19:28,600
and optimization, expand use case
governance, enhance governance frameworks,

272
00:19:28,660 --> 00:19:32,020
establish model arts practices, and
integrate with business processes.

273
00:19:32,020 --> 00:19:36,400
Success metrics include enterprise
web model inventory, and the

274
00:19:36,400 --> 00:19:37,750
business impact measurements.

275
00:19:37,750 --> 00:19:41,290
Challenges include model
proliferation and technical data

276
00:19:41,290 --> 00:19:43,660
accumulation and advance integration.

277
00:19:44,230 --> 00:19:46,420
Incorporate emerging auto ML capabilities.

278
00:19:46,420 --> 00:19:47,170
Integrate with.

279
00:19:47,590 --> 00:19:53,200
Complementary AI systems develop
custom domain adoptions and establish

280
00:19:53,200 --> 00:19:54,790
continuous improvement cycles.

281
00:19:54,850 --> 00:19:59,410
Success metrics include hybrid,
a, system effectiveness and

282
00:19:59,410 --> 00:20:01,030
competitive differentiation metrics.

283
00:20:02,020 --> 00:20:07,600
Strategic recommendations For
enterprise adoption, we have to first

284
00:20:07,600 --> 00:20:11,080
start with phased implementation
and then proceed balance to

285
00:20:11,080 --> 00:20:16,990
governance model, strategic workforce
integration with use case boundaries.

286
00:20:19,315 --> 00:20:21,625
Organizations should adopt
phased implementation.

287
00:20:21,625 --> 00:20:26,785
Approaches that balance ambition with
paradigm initial deployment should

288
00:20:26,785 --> 00:20:33,355
target well-defined use cases with clear
success criteria and model complexity.

289
00:20:33,565 --> 00:20:34,465
Moderate complexity.

290
00:20:35,215 --> 00:20:39,835
Effective governance structures typically
combine centralized oversight with

291
00:20:40,105 --> 00:20:41,845
distributed execution capabilities.

292
00:20:44,665 --> 00:20:45,085
Thank you.

