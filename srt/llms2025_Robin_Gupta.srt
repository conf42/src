1
00:00:00,120 --> 00:00:03,860
Hello, my name is Robin, and
today we'll look at the topic

2
00:00:03,860 --> 00:00:05,900
of how to test AI using ai.

3
00:00:06,650 --> 00:00:07,939
First, a little bit of introduction.

4
00:00:08,809 --> 00:00:12,200
I'm Robin Gupta, co-founder
and CEO at Te Zeus.

5
00:00:12,700 --> 00:00:15,610
I have three plus years of
leading product engineering pride,

6
00:00:15,610 --> 00:00:18,100
AI teams of up to 45 members.

7
00:00:18,880 --> 00:00:23,110
I'm a published author on the topic of
software testing and automation, and

8
00:00:23,110 --> 00:00:24,490
I'm also an open source contributor.

9
00:00:24,990 --> 00:00:26,669
Here are a few logo where have in.

10
00:00:27,169 --> 00:00:30,499
And on the large QR code, you
can find more details about us.

11
00:00:30,999 --> 00:00:37,209
First and foremost, let's look at the rise
of the IA or intelligent applications.

12
00:00:37,989 --> 00:00:41,289
So for example, large
damage models themselves.

13
00:00:41,440 --> 00:00:47,430
Examples like open ai, GP 4.5,
deep C carbon, and other Ls tend

14
00:00:47,430 --> 00:00:49,320
to in an intelligent fashion.

15
00:00:49,820 --> 00:00:51,080
The second bucket is.

16
00:00:51,580 --> 00:00:56,800
Rag applications, retrieval, augmented
generation, or even chat bots, which

17
00:00:56,800 --> 00:00:58,870
are wrappers on top of these models.

18
00:00:59,410 --> 00:01:01,150
And the third is agents.

19
00:01:01,510 --> 00:01:08,050
Agents like TE New or hardware ai,
which have agency inside them or

20
00:01:08,050 --> 00:01:13,360
which can perform tasks autonomously
using planning, memory and tools.

21
00:01:13,780 --> 00:01:17,530
So these are just a few example
of intelligent applications which

22
00:01:17,530 --> 00:01:19,419
need to be tested in novel ways.

23
00:01:19,919 --> 00:01:23,339
That being said, let's look at these
changing needs for software testing.

24
00:01:24,330 --> 00:01:28,289
As you can see on the table over here,
I divided this into three columns.

25
00:01:28,499 --> 00:01:29,009
The first six.

26
00:01:29,999 --> 00:01:33,059
Second is the comparison between
traditional software and the

27
00:01:33,059 --> 00:01:35,009
third one, element based apps.

28
00:01:35,399 --> 00:01:37,050
The first example is behavior.

29
00:01:37,559 --> 00:01:41,940
For example, the traditional software
behaves in a very predefined way

30
00:01:42,479 --> 00:01:44,130
based on the rules that it has.

31
00:01:44,729 --> 00:01:48,054
Think of it as a program
having if else, if.

32
00:01:48,554 --> 00:01:53,294
However, on the other hand, airline
based apps give the behavior

33
00:01:53,294 --> 00:01:55,214
of probability and prediction.

34
00:01:55,714 --> 00:01:57,695
The second criterion is output.

35
00:01:58,354 --> 00:02:02,945
For example, if you log into an
application like Salesforce, it'll

36
00:02:02,945 --> 00:02:06,125
determine stickly log you in,
and they will always be that one

37
00:02:06,125 --> 00:02:07,294
output for that funding input.

38
00:02:07,660 --> 00:02:11,734
But in the case of real based apps, these
could provide non-deterministic outputs.

39
00:02:11,795 --> 00:02:15,095
You can get different outcomes
for the same question.

40
00:02:15,595 --> 00:02:16,795
Last, but not the least.

41
00:02:17,035 --> 00:02:21,325
The testing strategy for traditional
software was only about the

42
00:02:21,325 --> 00:02:23,334
evaluations of it being right or wrong.

43
00:02:23,695 --> 00:02:27,984
On the other hand, for airline based
apps, they need to be evaluated on

44
00:02:27,984 --> 00:02:33,655
accuracy, quality, bias, consistency,
and last, but not the least, toxicity.

45
00:02:34,155 --> 00:02:36,600
That brings us to the automated evals.

46
00:02:36,660 --> 00:02:39,269
Now that we know what our
evals, let's understand the what

47
00:02:39,269 --> 00:02:40,980
and when of automated evals.

48
00:02:41,610 --> 00:02:42,300
So what should you.

49
00:02:43,200 --> 00:02:48,929
You must focus on context adherence,
context relevance, correctness bias and

50
00:02:48,929 --> 00:02:53,789
toxicity in all intelligent applications,
and when should you evaluate it?

51
00:02:54,119 --> 00:02:57,089
Now that can be taken as cues
from traditional software.

52
00:02:57,659 --> 00:03:00,899
For example, you can check
after every change, bug fix,

53
00:03:00,959 --> 00:03:02,640
feature update, or data changes.

54
00:03:03,344 --> 00:03:08,565
You can have the pipeline steps and
evaluations as part of predeployment in

55
00:03:08,565 --> 00:03:12,644
your SIT or UT environment wherein you
check after mergers to broad branch, end

56
00:03:12,644 --> 00:03:15,284
of sprint or prior to shipping hot fixes.

57
00:03:16,064 --> 00:03:19,575
And last but not the least, it
wouldn't hurt if we do a little bit

58
00:03:19,575 --> 00:03:23,054
of smoke testing post deployment,
for example, based on the demand

59
00:03:23,144 --> 00:03:25,394
from business or internal team needs.

60
00:03:25,894 --> 00:03:27,724
That brings us to today's.

61
00:03:28,085 --> 00:03:32,195
Demo application Under test, what
we'll do is we'll build a small

62
00:03:32,585 --> 00:03:35,825
rack based application, which
will act as a quiz generator.

63
00:03:36,484 --> 00:03:41,075
We'll provide it with a sample data
set around topics like physics and

64
00:03:41,075 --> 00:03:46,174
science, and then we'll ask the LLM
to generate quiz questions for it,

65
00:03:46,325 --> 00:03:47,465
which can be provided to the user.

66
00:03:48,155 --> 00:03:49,114
So here is an example.

67
00:03:49,715 --> 00:03:51,995
Let's say we ask it to
write a quiz about science.

68
00:03:52,355 --> 00:03:55,835
It'll respond back with some
science questions for us

69
00:03:55,895 --> 00:03:57,035
with right and wrong answers.

70
00:03:57,535 --> 00:04:01,820
And for this application we'll use
AI to perform the automated evals.

71
00:04:02,320 --> 00:04:04,120
So let's look at the pipeline.

72
00:04:05,050 --> 00:04:07,930
So from the starting point,
we have the Quizit app.

73
00:04:08,109 --> 00:04:13,269
We'll supplement it with the small
quiz bank, and we'll also give it the

74
00:04:13,269 --> 00:04:14,800
user input and the prompt template.

75
00:04:15,279 --> 00:04:18,519
The prompt template defines
what kind of outputs it should.

76
00:04:19,019 --> 00:04:23,219
The output of a skills generator
will go through the first ring of

77
00:04:23,219 --> 00:04:29,130
fire for rule-based evals wherein
we'll check if it generates answers,

78
00:04:29,130 --> 00:04:30,749
which contains specific words or not.

79
00:04:31,260 --> 00:04:33,749
If yes, good, if no fail the test case.

80
00:04:34,260 --> 00:04:37,200
The second gate is around formatting.

81
00:04:37,619 --> 00:04:41,159
Does it generate the quiz in the
right format as specified or not?

82
00:04:41,940 --> 00:04:46,260
And then last but not the least, we'll
look for things like hallucination.

83
00:04:46,760 --> 00:04:51,770
Wherein we'll check it against
negative prompts and see the

84
00:04:51,770 --> 00:04:53,210
kind of output that it generates.

85
00:04:53,480 --> 00:04:58,850
We'll also ask an AI based automated
eval system to reason about the

86
00:04:58,850 --> 00:05:03,770
answer and tell us whether the quiz
generator app is working fine or not.

87
00:05:04,270 --> 00:05:08,949
That being said, it's time to roll
up your sleeves and let's go onto

88
00:05:09,369 --> 00:05:11,199
some hands-on coding examples.

89
00:05:11,699 --> 00:05:16,429
So first and foremost, as you can see on
my screen, we are using Google collab.

90
00:05:16,939 --> 00:05:21,799
So these notebooks are I Python
notebooks wherein you can write snippets

91
00:05:21,829 --> 00:05:23,539
of Python code and run them online.

92
00:05:23,899 --> 00:05:28,399
This is free and even you can use
it for these experimental purposes.

93
00:05:28,899 --> 00:05:33,549
First and foremost, as we can see, we
can run each of these cells individually.

94
00:05:34,049 --> 00:05:37,649
And in the second cell, we
are highlighting my OpenAI,

95
00:05:37,649 --> 00:05:38,849
API key being imported.

96
00:05:38,849 --> 00:05:44,879
Over here you can use OpenAI or any
other lys that you're comfortable with.

97
00:05:45,089 --> 00:05:47,039
For the same I Python Notebooks.

98
00:05:47,339 --> 00:05:50,789
These resources will provided
right after the session for your

99
00:05:50,789 --> 00:05:52,199
reference, so don't worry about that.

100
00:05:52,699 --> 00:05:55,639
First and foremost, we are
highlighting the human template as

101
00:05:55,639 --> 00:06:01,184
the question, and as mentioned, the
app that we're testing today is a.

102
00:06:01,684 --> 00:06:06,814
Which uses the quiz bank or the data set
and large language models to generate

103
00:06:06,874 --> 00:06:09,544
quiz questions for Lexi students.

104
00:06:10,234 --> 00:06:16,984
So here the quiz bank is being run and
it has, subjects around DaVinci, Paris

105
00:06:17,254 --> 00:06:19,269
telescopes, study nights, and physics.

106
00:06:20,059 --> 00:06:22,804
Each of them have a
category and a few facts.

107
00:06:23,044 --> 00:06:27,069
So I, when we ask this
Ative app, it should use an.

108
00:06:27,694 --> 00:06:31,734
Two, look at the data set of this
question bank and generate a quiz

109
00:06:31,734 --> 00:06:33,894
for us, and that is how it performs.

110
00:06:34,134 --> 00:06:38,004
Retrieval augmented generation based
on the data that we have provided it.

111
00:06:38,504 --> 00:06:41,084
Now what we'll do is we'll
build a small prompt template

112
00:06:41,774 --> 00:06:43,604
as part of this demonstration.

113
00:06:43,604 --> 00:06:48,944
Today we'll be using Lang Chain as the
core framework, and in the construc chain

114
00:06:49,244 --> 00:06:50,714
we have to highlight the prompt template.

115
00:06:51,554 --> 00:06:54,434
So the prompt template that we're
following for the quiz generator

116
00:06:54,434 --> 00:06:59,504
app is very simple learning To
complicate it, we are asking the LLM

117
00:07:00,014 --> 00:07:03,554
to follow the below steps and generate
a customized quiz for the user.

118
00:07:04,304 --> 00:07:07,604
It must identify the category which
the user is asking, determine the

119
00:07:07,604 --> 00:07:11,984
subject, and then generate a quiz
for the user based on the format.

120
00:07:12,584 --> 00:07:16,184
With a few question, what
we'll chain is an open source.

121
00:07:16,684 --> 00:07:21,334
Which acts as a wrapper on
top of large language bottles.

122
00:07:21,604 --> 00:07:24,454
So we have provided the input as
a human and the prompt template,

123
00:07:24,634 --> 00:07:26,104
and from there we'll move forward.

124
00:07:26,604 --> 00:07:29,724
So for example, if we just
print the chat prompt, this is

125
00:07:29,724 --> 00:07:31,554
what goes through blank chain.

126
00:07:32,054 --> 00:07:35,564
So as we can see, this is the same
quiz bank and the prompt template

127
00:07:35,564 --> 00:07:37,454
that we had highlighted earlier.

128
00:07:38,084 --> 00:07:40,609
Now we'll use GPD four oh
with the temperature as zero.

129
00:07:41,109 --> 00:07:44,079
And choose that as the large
language model for us today.

130
00:07:44,579 --> 00:07:46,739
As highlighted, you can use
other large language models

131
00:07:46,799 --> 00:07:48,179
as well for the demonstration.

132
00:07:48,679 --> 00:07:55,349
Now, from LAN chain, we use the
schema par so that we get appropriate

133
00:07:55,889 --> 00:07:59,249
parts outputs from the open language.

134
00:07:59,749 --> 00:08:02,299
Now we'll take all these components and.

135
00:08:02,359 --> 00:08:05,209
We'll make them reusable as one piece.

136
00:08:05,299 --> 00:08:07,609
Okay, so nothing too complicated.

137
00:08:07,609 --> 00:08:11,089
Over here we're creating an assistant
chain, the system message, the

138
00:08:11,089 --> 00:08:15,029
human template, and the LLM with
the prompt template that we have

139
00:08:15,029 --> 00:08:17,129
provided and the name of the model.

140
00:08:17,629 --> 00:08:21,259
So let's experiment with that
quiz generator application.

141
00:08:21,759 --> 00:08:25,719
So we are asking it to a quiz about
science, and then we'll print the answer

142
00:08:26,259 --> 00:08:27,849
what we are getting back from this.

143
00:08:27,939 --> 00:08:29,589
So what it has done is.

144
00:08:29,979 --> 00:08:34,450
It has understood that the user is asking
about the category signs, and then based

145
00:08:34,510 --> 00:08:38,049
on the tags and labels that we have
provided in the data set, it has generated

146
00:08:38,349 --> 00:08:40,539
quiz about telescopes and physics.

147
00:08:40,899 --> 00:08:41,619
All good so far?

148
00:08:42,119 --> 00:08:47,039
So now we create an eval for
expected words as a first example.

149
00:08:47,519 --> 00:08:52,109
So what we are doing over here is we
are creating a small quiz from the quiz

150
00:08:52,109 --> 00:08:53,624
digital application that we have created.

151
00:08:54,124 --> 00:08:58,534
And the output must be evaluated
to contain certain expected words.

152
00:08:59,034 --> 00:09:01,224
So it is a very rule-based eval system.

153
00:09:01,584 --> 00:09:03,984
There is nothing magical,
there is nothing AI inside it.

154
00:09:04,374 --> 00:09:08,664
We'll come to the AI once in the
second example, so just keep up.

155
00:09:09,624 --> 00:09:14,114
Now what we are doing over here is
that in the expected words, we have

156
00:09:14,114 --> 00:09:16,724
asked it to have a few expected words.

157
00:09:17,224 --> 00:09:21,004
And it's as simple as generating
a quiz and then checking that the

158
00:09:21,004 --> 00:09:22,714
output should have the expected words.

159
00:09:23,464 --> 00:09:28,664
Okay, so when we run this with the
eval, and then as expected, we should

160
00:09:28,664 --> 00:09:33,884
see that it creates a quiz about
science, which picked up the scope

161
00:09:34,004 --> 00:09:38,804
and physics generated quiz, and then
it had the right words inside it.

162
00:09:39,584 --> 00:09:39,974
However.

163
00:09:40,634 --> 00:09:43,934
Let's create an accurate test
case or evals for refusal.

164
00:09:44,434 --> 00:09:49,534
So in that, what we are doing is
that we are just asking our system to

165
00:09:49,534 --> 00:09:54,274
create a quiz and then invoking it on
the question that we have asked for.

166
00:09:54,774 --> 00:09:59,664
And if we ask it to generate
a quiz about bread making the

167
00:09:59,664 --> 00:10:01,404
decline responses, I'm sorry.

168
00:10:01,904 --> 00:10:06,014
So for example, if we run
this, we'll start seeing the

169
00:10:06,014 --> 00:10:08,084
failures in that eval test.

170
00:10:08,584 --> 00:10:12,634
So we expected the assistant questions
to include this, but it did not.

171
00:10:12,994 --> 00:10:15,064
Is the idea very simple?

172
00:10:15,274 --> 00:10:19,144
You ask the quiz app to generic
a quiz based on a topic.

173
00:10:19,654 --> 00:10:21,724
Look for specific words inside the answer.

174
00:10:22,294 --> 00:10:24,844
Nothing fancy, all simple python overhead.

175
00:10:25,344 --> 00:10:28,794
But a key problem with limb
based applications as we saw

176
00:10:28,794 --> 00:10:30,234
earlier, is hallucinations.

177
00:10:30,734 --> 00:10:34,424
So now what we are doing is we
are asking the quiz janitor app

178
00:10:34,664 --> 00:10:36,914
to write a poem about conferences.

179
00:10:37,334 --> 00:10:38,924
Let's see what it does.

180
00:10:39,794 --> 00:10:43,604
So when we invoke the assistant
application, it actually

181
00:10:43,844 --> 00:10:45,314
wrote a poem about conference.

182
00:10:45,884 --> 00:10:52,064
Now, a key failure point for this
is that we had created a app, not

183
00:10:52,154 --> 00:10:56,464
a. But when we asked it to create a
poem about conferences, it broke all

184
00:10:56,464 --> 00:11:00,604
the rules about format and its system
prompt and went ahead and wrote a

185
00:11:00,604 --> 00:11:02,944
small poem about conferences not cool.

186
00:11:03,444 --> 00:11:07,374
That is where we come to our
second example wherein we use

187
00:11:07,374 --> 00:11:10,644
an AI system to test that first
AI system that we have built.

188
00:11:11,214 --> 00:11:14,154
So the first AI system which we
had built was this question app,

189
00:11:14,544 --> 00:11:18,414
and we'll use another AI system
with a system prompt to check out

190
00:11:18,414 --> 00:11:20,034
the responses from the first one.

191
00:11:20,274 --> 00:11:20,784
Very simple.

192
00:11:21,284 --> 00:11:25,274
So let's start running the
same example from the top.

193
00:11:26,174 --> 00:11:29,291
As I earlier, we are
setting up the open IPI key.

194
00:11:29,791 --> 00:11:30,751
In the second block.

195
00:11:31,291 --> 00:11:35,611
We are also setting up the quiz
bank, so nothing changed over here.

196
00:11:35,731 --> 00:11:38,341
It's the same quiz bank
as from the previous ones.

197
00:11:38,806 --> 00:11:42,106
Which has topics covered about
telescopes, starry nights,

198
00:11:42,166 --> 00:11:44,356
physics, science, so on, so forth.

199
00:11:44,856 --> 00:11:47,796
Now what we are doing is that we
are creating the assistant chain as

200
00:11:47,796 --> 00:11:49,626
our sample application data test.

201
00:11:49,686 --> 00:11:52,596
Basically, we are building the
quiz generator app overhead.

202
00:11:53,096 --> 00:11:55,976
So we are asking you to follow the
steps, need a customized quiz for

203
00:11:55,976 --> 00:12:00,461
the user, just as we saw earlier,
it should follow a certain format.

204
00:12:00,961 --> 00:12:04,711
Now what we've also done is we've tried
to harden the system prompt a little bit.

205
00:12:04,891 --> 00:12:07,891
We are asking it to own, include questions
from information in the quiz bank.

206
00:12:08,671 --> 00:12:11,101
Only use explicit string
matches for the category name.

207
00:12:11,281 --> 00:12:13,771
And if the user asks a question
about the subject, you do not have

208
00:12:13,921 --> 00:12:17,881
information about the quiz bank, just
say that you do not own the answer.

209
00:12:18,211 --> 00:12:20,731
So we can also sort see
that on the right side.

210
00:12:20,911 --> 00:12:24,566
And it says it should say, I'm
sorry, I do not have information.

211
00:12:25,066 --> 00:12:26,026
Ask you to write a poem.

212
00:12:26,026 --> 00:12:27,586
It should not do that, is the idea.

213
00:12:28,516 --> 00:12:33,586
So we've run that small cell, it has
done the setup for us, and then we'll

214
00:12:33,586 --> 00:12:36,676
build a prompt that has the LM to
evaluate the output of the quizzes.

215
00:12:36,886 --> 00:12:40,546
Now, this is the second
evaluator AI system.

216
00:12:41,386 --> 00:12:45,016
So it has this very simple system
prompt, which says you are an

217
00:12:45,016 --> 00:12:48,436
assistant that evaluates whether
or not an assistant is producing.

218
00:12:48,936 --> 00:12:50,196
And then it should give the answer.

219
00:12:50,696 --> 00:12:54,206
So the idea as highlighted earlier,
was that you have the quiz app,

220
00:12:54,446 --> 00:12:59,156
which is an LLM or an AI based app,
acts as a rag application retrieval.

221
00:12:59,156 --> 00:13:02,696
Augmented donation takes the
quiz bank based on the system

222
00:13:02,696 --> 00:13:04,556
prompt provided it should.

223
00:13:04,616 --> 00:13:09,856
Id create the quizzes as the
output, the second evaluator, ai.

224
00:13:10,846 --> 00:13:14,536
Is, as we can see over here,
has a system prompt acting as

225
00:13:14,596 --> 00:13:17,746
an assistant that evaluates the
responses from the first one.

226
00:13:18,316 --> 00:13:22,366
So that is how we are using
AI to test another AI system.

227
00:13:22,726 --> 00:13:23,296
Very simple.

228
00:13:23,796 --> 00:13:28,866
So moving forward, we similarly
little response to make a first

229
00:13:28,866 --> 00:13:34,266
small test and we set the prompt for
testing agent as you are evaluating

230
00:13:34,266 --> 00:13:36,636
a based on the context assistant.

231
00:13:37,136 --> 00:13:39,026
And an interim response.

232
00:13:39,086 --> 00:13:42,416
Read the response carefully determine
if it looks like a quiz or not.

233
00:13:43,316 --> 00:13:47,066
Output y if the response to a
quiz output, n if the response

234
00:13:47,066 --> 00:13:48,536
does not look like a quiz.

235
00:13:48,806 --> 00:13:52,526
So that is where we are
doing that assertion of the

236
00:13:52,526 --> 00:13:53,936
response from the first ai.

237
00:13:54,056 --> 00:13:54,986
Using the second AI.

238
00:13:55,046 --> 00:13:59,571
As an evaluator, we use blank chain to
build the prompt template for evaluation.

239
00:14:00,301 --> 00:14:00,931
We'll choose.

240
00:14:01,431 --> 00:14:04,791
And we'll import the parser
to have readable response.

241
00:14:04,911 --> 00:14:08,541
We connect all these pieces
together in the variable chain, and

242
00:14:08,541 --> 00:14:12,531
we'll test the positive response
by invoking the email chain.

243
00:14:12,981 --> 00:14:17,091
So basically, as we had highlighted, if
the answers are correct, it should respond

244
00:14:17,091 --> 00:14:21,531
with a Y. If we don't get the proper quiz
back it, it'll respond back with a no.

245
00:14:22,221 --> 00:14:26,181
So combining all these pieces
create an chain, using chain,

246
00:14:27,051 --> 00:14:29,211
and then what we also do is.

247
00:14:29,241 --> 00:14:31,881
We'll check for a negative response.

248
00:14:32,631 --> 00:14:36,261
Now, the known bad result highlighted
over here, or the negative test case, is

249
00:14:36,261 --> 00:14:38,421
that there are a lot of interesting facts.

250
00:14:38,421 --> 00:14:39,921
Tell me more about what
you'd like to know.

251
00:14:40,461 --> 00:14:44,961
Now, this will not donate a quiz,
and that is what the second AI

252
00:14:44,961 --> 00:14:46,821
should catch and fill the test case.

253
00:14:47,781 --> 00:14:49,821
So let's run that and
see what's happening.

254
00:14:50,091 --> 00:14:51,861
So it also generated a small end.

255
00:14:52,671 --> 00:14:57,741
What we'll do is we'll compress the
pieces of these systems into a test.

256
00:14:58,241 --> 00:15:03,401
So that we can run by test
or test fixtures around it.

257
00:15:04,301 --> 00:15:07,421
So we are running the code for
the test assistant, setting

258
00:15:07,421 --> 00:15:10,241
up for all these scenarios.

259
00:15:10,361 --> 00:15:13,841
And then there is a specific
method which will look for sub

260
00:15:13,841 --> 00:15:17,471
stringing of the message, and
it'll also decline the response

261
00:15:17,471 --> 00:15:19,481
if it is not the correct response.

262
00:15:20,201 --> 00:15:25,261
So when we run that, we'll ask it
around some facts which we had provided.

263
00:15:25,906 --> 00:15:28,756
And then if it is outside
the knowledge base, as we can

264
00:15:28,756 --> 00:15:30,256
see, the is also responding.

265
00:15:30,256 --> 00:15:32,416
I'm sorry, I do not have
the information about that.

266
00:15:32,916 --> 00:15:39,201
We'll create the test release valves and
when we run that, as we can see for the

267
00:15:39,261 --> 00:15:45,141
assertion, we've got an N where it should
have got a why, because we have input

268
00:15:45,201 --> 00:15:47,541
the known bad result as we saw earlier.

269
00:15:47,991 --> 00:15:53,211
So that is how you can use the second
AI system to check the first AI system.

270
00:15:53,711 --> 00:15:58,676
It is as simple as the secondary
system has prompt, which checks

271
00:15:59,006 --> 00:16:03,116
that the quiz generator is
generating the right outputs or not.

272
00:16:03,956 --> 00:16:08,816
Now, the same could be applicable
for your customer support scenarios

273
00:16:09,176 --> 00:16:11,276
or outbound sales scenarios.

274
00:16:11,636 --> 00:16:16,346
For example, in the case of a customer
support scenario, let's, your AI system is

275
00:16:16,346 --> 00:16:18,656
supposed to act as a customer service bot.

276
00:16:19,631 --> 00:16:24,131
It should ideally not reveal
any secret information or should

277
00:16:24,131 --> 00:16:25,661
not go into hallucinations.

278
00:16:26,261 --> 00:16:30,821
So when you're building that bot or that
AI application, you can have another

279
00:16:30,881 --> 00:16:36,161
AI evaluator with known bad results
and then check for the behavior of

280
00:16:36,161 --> 00:16:38,501
that first customer support AI part.

281
00:16:39,491 --> 00:16:43,181
That is how you can test AI
systems using secondary AI systems.

282
00:16:43,871 --> 00:16:45,251
But let's not stop there.

283
00:16:45,311 --> 00:16:46,511
Let's make it more fun.

284
00:16:47,021 --> 00:16:52,271
What if not only could we find
the deviations on the format, we

285
00:16:52,271 --> 00:16:56,471
could also find the deviations
from the context adherence.

286
00:16:56,921 --> 00:17:00,731
And what if we could reason
about the bad responses?

287
00:17:01,511 --> 00:17:04,841
So last but not the least,
let's perform some automated

288
00:17:04,871 --> 00:17:06,881
evals with advanced examples.

289
00:17:07,481 --> 00:17:11,231
First and foremost, we
have the OpenAI key set up.

290
00:17:11,696 --> 00:17:17,206
The quiz bank is the same as earlier,
and we'll create the assistant

291
00:17:17,206 --> 00:17:21,827
chain wherein it can act as a quiz
generator for us using GPT-4 oh.

292
00:17:22,637 --> 00:17:26,861
What we'll do is we'll create the
second AI system with a system prompt

293
00:17:27,041 --> 00:17:30,032
and give it a very specific direction.

294
00:17:30,677 --> 00:17:35,062
Asking it to act as an assistant
that evaluates how well the quiz

295
00:17:35,117 --> 00:17:38,956
assistant creates quizzes for
a user by looking at the set of

296
00:17:38,956 --> 00:17:40,337
facts available to the assistant.

297
00:17:40,907 --> 00:17:44,837
So we are asking the second AI system
to look at the same question bank

298
00:17:44,837 --> 00:17:48,287
given to the first one and see that
the quiz generated by the first

299
00:17:48,287 --> 00:17:50,267
one adhere to that context or not.

300
00:17:50,767 --> 00:17:54,246
So we are asking it that your primary
concern is making sure that only facts

301
00:17:54,246 --> 00:17:56,167
available are used if you focus here.

302
00:17:56,667 --> 00:17:58,106
Only is accurate in bold.

303
00:17:58,616 --> 00:18:04,677
So what we found is that text written
in bold, in system prompt is acted

304
00:18:04,677 --> 00:18:06,927
upon strictly by large language models.

305
00:18:07,427 --> 00:18:12,767
So we'll highlight that we learn that
small cell, and we'll also ask it to

306
00:18:12,767 --> 00:18:14,507
compare the content with the question.

307
00:18:15,297 --> 00:18:19,017
And if a fact is in the quiz, but not in
the question bank, then the quiz is bad.

308
00:18:19,557 --> 00:18:23,877
So we are specifically asking it
to check for context relevance

309
00:18:23,937 --> 00:18:25,107
as part of the system problem.

310
00:18:25,607 --> 00:18:30,317
So we are asking you to output why if
the quiz contains facts on the question

311
00:18:30,317 --> 00:18:34,067
bank and output N if it contains
facts that are not in the question.

312
00:18:34,567 --> 00:18:36,907
So we'll create a function
which will check for the

313
00:18:36,907 --> 00:18:38,767
evaluation and hallucinations.

314
00:18:39,267 --> 00:18:41,307
So in this case, when we run it.

315
00:18:41,807 --> 00:18:48,072
We will find that while the glass
chat opener is deprecated, when we

316
00:18:48,072 --> 00:18:51,847
ask it for a bad one, it says, I'm
sorry, but books is not a part of the

317
00:18:51,847 --> 00:18:53,467
categories I can generate a quiz for.

318
00:18:53,887 --> 00:18:57,907
So as you can see in the question bank, we
actually don't have anything around books.

319
00:18:58,057 --> 00:19:02,557
It has topics about telescope science,
study night physics, and DaVinci.

320
00:19:03,057 --> 00:19:07,677
So that is how, in very simple words,
it can check the context relevance.

321
00:19:08,177 --> 00:19:11,087
But let's improve the
system prompt a little bit.

322
00:19:11,587 --> 00:19:14,822
So we are asking it to act an
assistant that evaluates how well

323
00:19:14,822 --> 00:19:16,507
the quiz assistant creates quizzes.

324
00:19:17,497 --> 00:19:21,487
Your primary concern is making sure that
only facts available are used and helpful.

325
00:19:21,487 --> 00:19:23,587
Quizzes only contain
facts in the test set.

326
00:19:24,337 --> 00:19:28,397
We'll rebuild the evaluator to not
only provide the decision of the

327
00:19:28,397 --> 00:19:30,167
result, but also the explanation.

328
00:19:30,526 --> 00:19:32,086
So that is the fun part over here.

329
00:19:32,626 --> 00:19:33,466
So for example.

330
00:19:34,336 --> 00:19:36,766
We are not only asking it to
compare the information in the

331
00:19:36,766 --> 00:19:40,996
quiz, the question bank, we are also
giving it a few additional rules.

332
00:19:41,177 --> 00:19:46,336
Over here in line numbers 28 to 32,
we're asking it to output an explanation

333
00:19:46,397 --> 00:19:49,907
of whether the quiz only references
information in the context, make

334
00:19:49,907 --> 00:19:53,266
explanation brief and only include the
summary of a reasoning for the decision.

335
00:19:53,806 --> 00:19:57,407
Include a clear yes or no, and
then reference facts bank if the

336
00:19:57,407 --> 00:20:00,156
answer is yes and explanation.

337
00:20:00,561 --> 00:20:02,481
For example, if there will
be decision, and then there

338
00:20:02,481 --> 00:20:03,651
could be a small explanation.

339
00:20:04,151 --> 00:20:07,091
So we'll rebuild that whole
check prompt with the new prompt.

340
00:20:07,591 --> 00:20:14,141
And what we'll do is we'll also run
it with a few small test data set.

341
00:20:14,381 --> 00:20:18,941
So for example, there are topics
about science, about geography

342
00:20:19,361 --> 00:20:20,741
and bread making or cooking.

343
00:20:21,641 --> 00:20:23,941
So ideally it should pass.

344
00:20:24,316 --> 00:20:27,886
The topics that we have in the quiz
bank, and it should fail the ones around

345
00:20:27,886 --> 00:20:29,506
bread making because we did not cover it.

346
00:20:30,006 --> 00:20:33,246
So what we'll do is we'll
create this function data set

347
00:20:34,026 --> 00:20:35,976
and invoke the quiz generation.

348
00:20:36,476 --> 00:20:43,346
We'll use a library from Python called as
Pandas to help us display the results in

349
00:20:43,346 --> 00:20:47,776
a more format once we run this end piece.

350
00:20:48,276 --> 00:20:53,886
The data set and the evaluator ai, what
we'll see is for the positive test cases,

351
00:20:54,126 --> 00:20:58,956
not only will it pass the test case or
evaluation for the negative funds, it'll

352
00:20:58,956 --> 00:21:04,116
not just fail them as highlighted in the
system prong for the evaluator ai, it'll

353
00:21:04,176 --> 00:21:10,536
also try to look at the data set and
then reason or explain its results to us.

354
00:21:11,016 --> 00:21:14,876
So for example, in the
first row, we are asking it.

355
00:21:15,376 --> 00:21:19,006
To generate a quiz about science and can
you gimme a quiz to test my knowledge?

356
00:21:19,006 --> 00:21:20,176
So I generated that.

357
00:21:20,676 --> 00:21:26,766
So the quiz generator app created a small
quiz for the user, but then the evaluator

358
00:21:26,826 --> 00:21:31,836
AI checked the quiz based on the data set
and highlighted that yes, the decision

359
00:21:31,836 --> 00:21:36,716
is right, the quiz is good, and give an
explanation of why it believes that the

360
00:21:36,716 --> 00:21:39,236
quiz was generated is accurate or not.

361
00:21:39,736 --> 00:21:41,926
Similarly, we ask it about geography.

362
00:21:42,616 --> 00:21:47,326
And last but not the least, when we ask
it about bread making, not only did the

363
00:21:47,326 --> 00:21:52,396
quiz generator app replied, I'm sorry, I
cannot give you a quiz of bread making the

364
00:21:52,396 --> 00:21:54,946
evaluator, AI also had a decision as No.

365
00:21:55,756 --> 00:21:58,846
And then explain that the quiz does
not reference any facts from the

366
00:21:58,846 --> 00:22:03,166
question bank, and it has nothing to do
with DaVinci Paris telescopes, so on.

367
00:22:03,166 --> 00:22:04,516
so in very simple ways.

368
00:22:05,446 --> 00:22:06,351
What we have done is.

369
00:22:06,616 --> 00:22:12,106
We created a small quiz generator
app, which takes a question back,

370
00:22:12,676 --> 00:22:14,746
talks to the LLM generates quizzes.

371
00:22:15,246 --> 00:22:21,696
What we then did was part one, look
for certain rule-based evals that the

372
00:22:21,696 --> 00:22:26,196
generated quiz from this first AI based
application contains a few words or not.

373
00:22:26,916 --> 00:22:33,216
Second, we checked for the format, and
last, but not we created this evaluator.

374
00:22:34,191 --> 00:22:39,981
Which not only checked for the context
adherence and relevance based on the same

375
00:22:39,981 --> 00:22:46,941
data set provided to us for the quiz,
it also gave us the app explanation of

376
00:22:47,661 --> 00:22:50,121
why it passed or failed the test case.

377
00:22:50,621 --> 00:22:55,091
So that is how you can build AI
systems to check other AI systems.

378
00:22:55,451 --> 00:22:56,921
Let's get back to our presentation.

379
00:22:57,826 --> 00:23:01,076
I'll put this in slide mode and time to.

380
00:23:01,576 --> 00:23:01,936
Okay.

381
00:23:02,296 --> 00:23:08,266
Jokes aside, moving forward, let's
zoom out a little bit and compress

382
00:23:08,266 --> 00:23:10,486
these concepts into a CI CT pipeline.

383
00:23:11,176 --> 00:23:15,016
Continuous integration, continuous
testing pipeline for AI applications.

384
00:23:15,646 --> 00:23:21,191
Let's say you are doing some changes
you must do per commit evals on the dev

385
00:23:21,191 --> 00:23:23,981
feature branch from there merged to me.

386
00:23:24,821 --> 00:23:29,621
After that, you can do pre-release evals,
like the second test around formatting.

387
00:23:30,026 --> 00:23:35,116
That we did move it to deploy, and
then last but not the least after that.

388
00:23:35,116 --> 00:23:39,496
You can also check it for a few smoke
scenarios with the evaluator AI that we

389
00:23:39,496 --> 00:23:44,476
had created and look at not just the pass
fail responses, but also the explanations.

390
00:23:45,316 --> 00:23:50,026
It is very important to highlight
that, not just the pre-release

391
00:23:50,141 --> 00:23:51,382
eval, but the post release eval.

392
00:23:51,771 --> 00:23:53,831
Must go through conferences.

393
00:23:54,331 --> 00:23:58,951
When I highlighted that you can use AI
systems to check the other AI systems,

394
00:23:59,701 --> 00:24:04,771
someone very smart in the audience
asked me then, who checks both of these

395
00:24:04,771 --> 00:24:06,181
AI systems are working fine or not.

396
00:24:06,751 --> 00:24:10,741
The answer, as you can imagine,
is today and forever Humans.

397
00:24:11,241 --> 00:24:13,941
That being said, let's
look at a few differences.

398
00:24:14,811 --> 00:24:17,961
Infosys recently released a
responsible AI toolkit, so I.

399
00:24:18,461 --> 00:24:21,551
This can help you do red
teaming for AI applications.

400
00:24:22,051 --> 00:24:27,211
GitHub publishes their opens and then last
but not least, is very nice research paper

401
00:24:27,541 --> 00:24:29,581
on evaluation of large language models.

402
00:24:30,081 --> 00:24:32,961
That brings us to the
closure of our session today.

403
00:24:33,381 --> 00:24:36,621
Feel free to show us questions, and
you can also check out the world's

404
00:24:36,621 --> 00:24:40,731
first open source testing agent at
the GitHub report highlighted below.

405
00:24:41,231 --> 00:24:42,251
Thank you so much.

406
00:24:42,371 --> 00:24:43,181
Have a nice day.

407
00:24:43,511 --> 00:24:44,531
Or a nice evening.

408
00:24:44,801 --> 00:24:45,941
Stay curious.

409
00:24:46,091 --> 00:24:46,901
Stay smart.

410
00:24:47,021 --> 00:24:48,246
Take care, and byebye.

