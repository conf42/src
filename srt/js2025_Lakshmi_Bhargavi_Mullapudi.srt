1
00:00:00,990 --> 00:00:01,680
Hello everyone.

2
00:00:01,680 --> 00:00:06,750
This is LaMi Avi and my topic here today
is Real time data Systems engineering

3
00:00:06,750 --> 00:00:08,850
for speed, scale and resilience.

4
00:00:09,350 --> 00:00:11,510
So let's talk about the realtime in two.

5
00:00:11,660 --> 00:00:17,330
Let's talk like 180 terabytes of data
where the realtime demand is 30% and the

6
00:00:17,330 --> 00:00:19,549
latency target is less than one seconds.

7
00:00:19,910 --> 00:00:23,180
The expected global data volume by 2025.

8
00:00:23,780 --> 00:00:28,280
Modern applications demand instant
responsiveness from fraud detection

9
00:00:28,280 --> 00:00:30,140
to personalized recommendations.

10
00:00:30,650 --> 00:00:34,070
Realtime data processing has
become the bone of mission

11
00:00:34,070 --> 00:00:36,620
critical JavaScript experiences.

12
00:00:37,120 --> 00:00:39,130
Where does realtime matters most?

13
00:00:39,590 --> 00:00:40,100
FinTech fraud, detect.

14
00:00:40,600 --> 00:00:45,820
Within millisecond level transaction
analysis, analytics, protecting

15
00:00:45,820 --> 00:00:51,340
billions in assets, web personalization,
instant content adaptation based

16
00:00:51,340 --> 00:00:53,740
on user behavior and preferences.

17
00:00:54,280 --> 00:00:59,345
Iot sensor on networks, subsequent
response to critical environmental or

18
00:00:59,345 --> 00:01:02,334
equipment changes like architecture.

19
00:01:02,534 --> 00:01:06,734
Overview, the real time pipeline
ingesting the data into even streams.

20
00:01:07,134 --> 00:01:07,775
Captured data, a source.

21
00:01:08,500 --> 00:01:13,900
Processing the data and transform
and enrich data in flight storage.

22
00:01:13,900 --> 00:01:19,750
Fast query engines for instant access
delivery to the applications and end

23
00:01:19,750 --> 00:01:26,380
users, even stream ingestion, getting
data in fast like Apache Kafka distributed

24
00:01:26,380 --> 00:01:28,870
log for high throughput scenarios.

25
00:01:29,259 --> 00:01:33,130
Strong ordering guarantees per
partition, rich ecosystems of

26
00:01:33,130 --> 00:01:35,470
connectors, and a w Genesis assist.

27
00:01:36,264 --> 00:01:38,634
Manage service with auto scaling.

28
00:01:38,634 --> 00:01:44,394
Seamless AWS integration, lower
operational overhead, and built

29
00:01:44,394 --> 00:01:46,225
in data retention and replay.

30
00:01:46,674 --> 00:01:51,114
Choosing the right ingestion layer
depends on cput requirements, operational

31
00:01:51,114 --> 00:01:53,845
complexity, and existing infrastructure.

32
00:01:54,445 --> 00:01:59,459
Both solutions handy millions of events
per second when configured correctly.

33
00:01:59,959 --> 00:02:05,659
Stream processing like transformation
and motion like Apache Flink true stream

34
00:02:05,659 --> 00:02:11,449
engine with exactly one semantics,
stateful operations and event time

35
00:02:11,449 --> 00:02:14,059
processing for complex event patterns.

36
00:02:14,629 --> 00:02:19,639
Sparks structured streaming micro
batch processing with unified badge of

37
00:02:19,639 --> 00:02:25,479
streaming API strong SQL support and
excellent for existing spark ecosystems.

38
00:02:25,979 --> 00:02:30,719
Fraud detection in milliseconds
is a case study like number

39
00:02:30,719 --> 00:02:32,339
one is even capture rate.

40
00:02:32,339 --> 00:02:37,769
Transaction data ingested via Kafka
topics with subsecond 10 milliseconds.

41
00:02:37,769 --> 00:02:43,049
Latency two is realtime enrichment
where joined with a user profile,

42
00:02:43,049 --> 00:02:45,509
historical patterns and risk code.

43
00:02:45,509 --> 00:02:48,839
And flight three is ML model scoring.

44
00:02:49,184 --> 00:02:53,174
Where lightweight models evaluate
risk within 50 milliseconds

45
00:02:53,174 --> 00:02:54,704
using feature vectors.

46
00:02:55,184 --> 00:03:00,404
Four is action and alert where high
risk transactions blocked instantly.

47
00:03:00,974 --> 00:03:04,394
Alerts sent to security teams here.

48
00:03:04,394 --> 00:03:09,374
End-to-end latency, like 80 to one 20
milliseconds from transaction to decision.

49
00:03:09,874 --> 00:03:12,515
Fast query engines the final mile.

50
00:03:13,144 --> 00:03:18,415
Apache drilled, optimized for time
series and even data with storage.

51
00:03:18,775 --> 00:03:24,625
Subsequent aggregations across billions
of events, perfect for realtime analytical

52
00:03:24,805 --> 00:03:30,805
dashboards like realtime ingestion with
historical data, approximate algorithms

53
00:03:30,805 --> 00:03:33,530
for speed, horizontal scalability built.

54
00:03:34,030 --> 00:03:36,250
And click House All lab database.

55
00:03:36,250 --> 00:03:41,020
Designed for analytical query at
scale, exceptional compression

56
00:03:41,020 --> 00:03:43,120
ratios and query performance.

57
00:03:43,540 --> 00:03:48,880
Ideal for high cardinality data,
vectorized query execution,

58
00:03:48,880 --> 00:03:51,790
native replication and shading.

59
00:03:52,030 --> 00:03:53,745
SQL interface for developers.

60
00:03:54,245 --> 00:03:56,045
Engineering for low latency.

61
00:03:56,315 --> 00:04:02,344
Minimize network hops, optimize
serialization, bad, smart, not big.

62
00:04:02,404 --> 00:04:07,325
And catch chase strategically, like
when you say minimize network, hops,

63
00:04:07,685 --> 00:04:09,274
collocate processing, and storage.

64
00:04:09,274 --> 00:04:12,695
When possible, each network
round trip adds like one to five

65
00:04:12,695 --> 00:04:14,045
milliseconds designed for data.

66
00:04:14,664 --> 00:04:17,185
Locality and reduced
cross center data calls.

67
00:04:17,875 --> 00:04:22,015
Optimize serialization, choose
efficiency formats like Avro or

68
00:04:22,075 --> 00:04:27,565
Proto Booth over js ON serialization
can consume 20 to 30% of processing

69
00:04:27,565 --> 00:04:29,455
time in high throughput systems.

70
00:04:29,965 --> 00:04:34,645
Bad, smart, not big, small micro batches,
balanced throughput, and latency.

71
00:04:35,215 --> 00:04:39,294
Sweet spot is often a hundred thousand
events or 10 to 50 milliseconds

72
00:04:39,294 --> 00:04:41,060
window depending on use case.

73
00:04:41,810 --> 00:04:46,550
Catches strategically using
memory caches for hard data and

74
00:04:46,550 --> 00:04:49,340
lookup tables ready or cast.

75
00:04:49,340 --> 00:04:53,150
Conserve reads in
microseconds, not milliseconds.

76
00:04:53,650 --> 00:04:54,640
Horizon beyond machines.

77
00:04:55,140 --> 00:05:00,020
Partition your data distribute load
across multiple nodes using consistent

78
00:05:00,020 --> 00:05:01,940
hashing or range partitioning.

79
00:05:02,540 --> 00:05:04,040
Stateless when possible.

80
00:05:04,130 --> 00:05:08,030
Like stateless services, scale
effortlessly when state is required

81
00:05:08,030 --> 00:05:12,050
to use external stores like reds
or distributed state management

82
00:05:12,050 --> 00:05:12,975
and your system processes.

83
00:05:13,475 --> 00:05:17,495
Autoscaling strategies monitor
qip, then processing lag.

84
00:05:17,645 --> 00:05:19,775
Scale out when lag increases.

85
00:05:20,225 --> 00:05:25,625
Scale in during quiet periods to optimize
costs without sacrificing performance.

86
00:05:26,125 --> 00:05:28,315
Consistency versus availability.

87
00:05:28,315 --> 00:05:29,395
The trade off.

88
00:05:29,575 --> 00:05:30,895
Strong consistency.

89
00:05:30,985 --> 00:05:33,445
All readers see the same data immediately.

90
00:05:33,805 --> 00:05:36,265
Higher latency and reduced availability.

91
00:05:36,775 --> 00:05:39,805
Use for financial transactions
and critical operations.

92
00:05:40,780 --> 00:05:46,240
Eventual consistency data propagates
over time, lower latency and

93
00:05:46,240 --> 00:05:51,370
higher availability, acceptable
for analytics, recommendations,

94
00:05:51,430 --> 00:05:53,290
and non-critical features.

95
00:05:53,680 --> 00:05:59,590
Tuneable consistency, just preparation
using Quorum reads rights balance

96
00:05:59,590 --> 00:06:03,760
requirements dynamically based on
the importance of each request,

97
00:06:04,150 --> 00:06:06,640
there is no one size fits all answer.

98
00:06:07,030 --> 00:06:09,635
Choose based on the business
requirements, not technically.

99
00:06:10,375 --> 00:06:11,125
Preference.

100
00:06:11,155 --> 00:06:15,385
Many systems use different consistency
levels for different data types.

101
00:06:15,885 --> 00:06:21,225
Fall tolerance building for failures
like we have checkpointing replication,

102
00:06:21,255 --> 00:06:26,805
retrial logics, circuit breakers where we
can prevent cascading failures by failing

103
00:06:26,805 --> 00:06:31,935
fast monitor downstream services and
hard requests when systems are degraded.

104
00:06:32,435 --> 00:06:35,315
Let's talk about like
frontend integration bringing.

105
00:06:35,795 --> 00:06:40,735
Realtime, the ui, web sockets
and server sent events enabled

106
00:06:41,245 --> 00:06:44,935
bidirectional or unidirectional
streaming from server to browser.

107
00:06:45,475 --> 00:06:49,945
Perfect for live dashboards,
notifications and collaborative features.

108
00:06:50,545 --> 00:06:56,695
Graph QL subscriptions, declarative
realtime data into your existing GraphQL.

109
00:06:56,695 --> 00:07:02,395
API client subscribe to specific data
changes and receive updates automatically.

110
00:07:03,310 --> 00:07:09,220
State management, use redx, noex,
or just turn to handle streaming

111
00:07:09,220 --> 00:07:11,710
updates in React applications.

112
00:07:12,370 --> 00:07:16,270
Normalize data to prevent
rear-ends and maintain performance.

113
00:07:16,770 --> 00:07:20,310
Take away building real time systems,
like start with the requirements.

114
00:07:20,340 --> 00:07:23,040
Define latency, targets
and consistency needs.

115
00:07:23,040 --> 00:07:26,250
Before choosing technology,
not everything needs subsecond.

116
00:07:26,250 --> 00:07:30,840
Processing design for failure,
assume components will fail and

117
00:07:30,840 --> 00:07:32,610
build resilience from day one.

118
00:07:33,060 --> 00:07:35,700
Monitoring and alerting are not optional.

119
00:07:36,405 --> 00:07:37,695
Measure everything.

120
00:07:37,815 --> 00:07:41,895
Instrument your pipeline
with metrics at every stage.

121
00:07:42,375 --> 00:07:44,685
You can't optimize what you don't measure.

122
00:07:45,405 --> 00:07:46,845
Scale incrementally.

123
00:07:47,385 --> 00:07:50,775
Start simple and add
complexity only when needed.

124
00:07:50,865 --> 00:07:53,775
Or engineering early
creates technical depth.

125
00:07:54,585 --> 00:07:55,660
Think end to end.

126
00:07:56,235 --> 00:07:59,775
Latency in one component
affects the entire system.

127
00:07:59,865 --> 00:08:02,660
Optimize the full pipeline,
not individual pieces.

128
00:08:03,160 --> 00:08:03,670
Thank you.

