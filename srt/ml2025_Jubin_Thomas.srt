1
00:00:01,350 --> 00:00:02,040
Hello everyone.

2
00:00:02,070 --> 00:00:03,060
I'm Juin Thomas.

3
00:00:03,270 --> 00:00:05,670
I work as a technical
architect at Signe Jewelers.

4
00:00:06,060 --> 00:00:10,110
I have 15 plus years of experience
in supply chain and retail, and

5
00:00:10,110 --> 00:00:12,240
I'm also a senior member of IEE.

6
00:00:13,530 --> 00:00:16,590
Having said that, I want to thank
Mark for inviting me as a speaker

7
00:00:16,590 --> 00:00:18,840
for machine learning conference 2025.

8
00:00:19,650 --> 00:00:22,950
Today, I would like to present on
forecasting using machine learning.

9
00:00:23,369 --> 00:00:26,369
We will deep dive into models
and basically understand.

10
00:00:26,880 --> 00:00:29,940
Different type of models in
doing the forecasting and why?

11
00:00:30,330 --> 00:00:33,650
XT Boost, in other words called as xtb.

12
00:00:33,650 --> 00:00:36,740
Regressor is superior to the
other models, which we have used.

13
00:00:37,740 --> 00:00:41,930
So now there are two kind of
forecasting what we have in the

14
00:00:41,930 --> 00:00:43,940
world of retail and supply chain.

15
00:00:43,940 --> 00:00:45,710
One is called the demand forecasting.

16
00:00:45,710 --> 00:00:49,600
It is the forecasting of a
store and item combination.

17
00:00:49,840 --> 00:00:51,460
So it basically helps.

18
00:00:51,880 --> 00:00:56,050
It's a process of using historical data to
estimate the future customer demand, and

19
00:00:56,050 --> 00:00:58,510
it helps in the planning of the inventory.

20
00:00:58,870 --> 00:01:02,620
It reduces stockouts and it helps
in optimizing the supply chain,

21
00:01:03,070 --> 00:01:04,720
enhancing the customer satisfaction.

22
00:01:06,255 --> 00:01:09,920
I. Moving forward to understand
what is sales forecasting.

23
00:01:09,950 --> 00:01:14,580
Sales forecasting is a technique which
is used to estimate the future sales

24
00:01:14,880 --> 00:01:19,710
based on the historical data market
trends, seasonality and external factors.

25
00:01:20,820 --> 00:01:24,440
It helps the retail business
in understanding the informed

26
00:01:24,440 --> 00:01:26,390
inventory and staffing decisions.

27
00:01:26,780 --> 00:01:29,630
It helps in planning the
budgets and marketing efforts.

28
00:01:30,260 --> 00:01:34,820
Optimizing the supply chain and operations
and anticipating the demand fluctuations.

29
00:01:36,395 --> 00:01:40,125
So in this presentation I have
four different objectives.

30
00:01:40,435 --> 00:01:44,165
First one is we will evaluate
the data, what we have.

31
00:01:44,195 --> 00:01:46,145
It's also called as the training data.

32
00:01:46,535 --> 00:01:50,325
So in that data is basically we
are gonna predict the weekly sales

33
00:01:50,325 --> 00:01:51,735
using the machine learning models.

34
00:01:52,215 --> 00:01:53,385
Second one is explore.

35
00:01:53,385 --> 00:01:56,055
We are going to explore the
data, trends and relationship.

36
00:01:56,505 --> 00:02:00,485
And thirdly, we will evaluate and
compare the different models what

37
00:02:00,485 --> 00:02:01,775
we will see in this presentation.

38
00:02:01,805 --> 00:02:02,525
And finally.

39
00:02:03,070 --> 00:02:08,320
Identifying why XE Boosto perform
better than the other models.

40
00:02:09,715 --> 00:02:11,365
Moving on to the data set.

41
00:02:11,395 --> 00:02:16,540
We have a Walmart data set, which
basically has certain features

42
00:02:16,780 --> 00:02:20,260
like store data, weekly sales,
holiday flag, and temperature.

43
00:02:20,620 --> 00:02:24,840
And now it has 45 stores
Walmart stores with the data.

44
00:02:24,840 --> 00:02:26,490
And this data is online available.

45
00:02:26,910 --> 00:02:29,215
And in this we will see that how.

46
00:02:29,620 --> 00:02:35,110
We have the additional economic indicators
like the fuel price and CPI unemployment,

47
00:02:35,110 --> 00:02:41,820
which plays an important role to analyze
a specific model to to basically figure

48
00:02:41,820 --> 00:02:45,649
out the forecasting of this dataset.

49
00:02:46,159 --> 00:02:49,514
And now finally, we will have the target
variable, which is the weekly sales.

50
00:02:51,094 --> 00:02:54,934
So this is the Walmart data set, what
we have, and as we see that these are

51
00:02:54,934 --> 00:02:59,284
the stores, we have 45 stores in this
data set, and then we have the date

52
00:02:59,404 --> 00:03:01,524
and the weekly sales for that week.

53
00:03:01,794 --> 00:03:06,474
And then the holiday flag zero stands for,
it was not a holiday, and one is basically

54
00:03:06,474 --> 00:03:07,884
that it was a holiday on that day.

55
00:03:08,334 --> 00:03:12,374
And then we have, temperature that
week or the weather that week.

56
00:03:12,614 --> 00:03:16,254
Then we have a fuel price and
CPI customer pricing index.

57
00:03:16,384 --> 00:03:18,844
And then we have the employ
an unemployment ratio.

58
00:03:21,369 --> 00:03:25,999
The models, which we have evaluated
as part of this test or presentation

59
00:03:25,999 --> 00:03:30,109
is basically linear regression, rich
regression, polynomial regression,

60
00:03:30,559 --> 00:03:34,099
10 years neighbor decision tree,
random forest, and XG boost.

61
00:03:34,459 --> 00:03:39,219
So these are all out of the box model
provided in the Python framework itself,

62
00:03:39,519 --> 00:03:41,469
which does the work of forecasting.

63
00:03:41,589 --> 00:03:42,379
And we will evaluate.

64
00:03:42,609 --> 00:03:47,449
How to work on these models and what are
the results which these models produced.

65
00:03:47,939 --> 00:03:50,699
Moving on to understand the
linear regression model.

66
00:03:50,699 --> 00:03:55,139
So this is also known as a regression
model, and here we basically

67
00:03:55,139 --> 00:03:59,519
see that the polynomial feature
degree is three, which was given.

68
00:03:59,899 --> 00:04:00,799
To build this model.

69
00:04:01,189 --> 00:04:05,299
And this model gave an accuracy
rate of 97.7 for this test.

70
00:04:05,329 --> 00:04:10,489
This data set, what we had, and the
test accuracy is 95.8 percentage.

71
00:04:12,109 --> 00:04:14,449
The second model is the
rich regression model.

72
00:04:14,499 --> 00:04:16,449
And this is also a regression model.

73
00:04:16,449 --> 00:04:17,139
And we see here.

74
00:04:17,859 --> 00:04:21,669
That the paranormal feature degree
was given as three, and the accuracy

75
00:04:21,669 --> 00:04:27,999
rate given by the model is 97.7 with
the test accuracy as 95.8 percentage.

76
00:04:29,874 --> 00:04:31,674
The next model is the KNN model.

77
00:04:31,709 --> 00:04:33,894
KNN is also known as K nearest neighbor.

78
00:04:33,924 --> 00:04:38,484
The way how it works is it tries to
fetch the three ne nearest neighbor

79
00:04:38,784 --> 00:04:42,264
for the given combination or the given
input, which is provided to the model.

80
00:04:42,594 --> 00:04:46,014
So here, in this case, the N
neighbors is basically three.

81
00:04:46,354 --> 00:04:49,384
That means it basically searches
for the three nearest neighbor

82
00:04:49,384 --> 00:04:50,674
for the given combination.

83
00:04:51,034 --> 00:04:54,764
KN gave the accuracy rate
of a hundred percent and the

84
00:04:54,764 --> 00:04:57,674
test accuracy rate of 91.9%.

85
00:04:59,804 --> 00:05:03,614
The next model we evaluated
is a decision tree model, and

86
00:05:03,794 --> 00:05:06,374
it is again, a decision tree.

87
00:05:06,374 --> 00:05:10,044
So it basically decides based
on the max depth what we have.

88
00:05:10,374 --> 00:05:16,374
So it gave a training set accuracy of
97.3 and the test accuracy of 93.3.

89
00:05:18,744 --> 00:05:22,494
The next model, which I evaluated
is the random forest model.

90
00:05:22,554 --> 00:05:24,924
And as the name says,
it is a forest model.

91
00:05:25,284 --> 00:05:30,904
It basically creates a set of decision
tree or also known as a forest.

92
00:05:30,904 --> 00:05:34,084
So here, in this case, n
estimator is one of the parameter

93
00:05:34,084 --> 00:05:35,894
what we passed to the forest.

94
00:05:36,414 --> 00:05:40,744
Model and we see that the, an
estimator given as 75 basically

95
00:05:40,744 --> 00:05:43,194
creates a seven 75 decision trees.

96
00:05:43,314 --> 00:05:46,494
And based on that, we see
that the training set accuracy

97
00:05:46,494 --> 00:05:48,234
is 99.1, which is good.

98
00:05:48,234 --> 00:05:51,834
And then test set accuracy
is 95.6 percentage.

99
00:05:52,989 --> 00:05:57,429
Moving on to the final model, which I
evaluated is the XGB REGRESSOR model.

100
00:05:57,459 --> 00:06:03,039
Out of all the models we have evaluated
xg XGB stands the best for the test

101
00:06:03,039 --> 00:06:08,409
data, what we have we see here so in
the XGB, the training set accuracy is

102
00:06:08,409 --> 00:06:15,189
99.9, and the test accuracy has given
us 97.2%, which is the best out of all

103
00:06:15,189 --> 00:06:16,599
the models, which we have compared.

104
00:06:18,819 --> 00:06:20,829
Trying to understand
the correlation metrics.

105
00:06:20,859 --> 00:06:25,689
Now correlation metrics is one of the
most important metrics which we analyze

106
00:06:25,719 --> 00:06:27,899
as part of understanding the data.

107
00:06:28,199 --> 00:06:32,759
And as we see that there are some
of the columns, which has a very

108
00:06:32,759 --> 00:06:36,119
close relationship to each other,
like the weekly sales and holiday

109
00:06:36,119 --> 00:06:39,859
flag, they have a close relationship
with either with each other.

110
00:06:40,259 --> 00:06:41,699
Similarly temperature and fuel.

111
00:06:41,699 --> 00:06:44,729
Price has a close
relationship with each other.

112
00:06:45,234 --> 00:06:47,994
So once we determine
the correlation metrics.

113
00:06:48,509 --> 00:06:50,969
The second thing is
the feature importance.

114
00:06:50,969 --> 00:06:55,019
So each model produces its
own feature importance.

115
00:06:55,259 --> 00:07:01,209
So this is, I think the feature
importance given by the XGB regressor

116
00:07:01,239 --> 00:07:03,339
or the XG B'S XG boost model.

117
00:07:03,609 --> 00:07:08,289
And we see here that the store and
CPI, the customer pricing indexes

118
00:07:08,629 --> 00:07:12,889
featured as the most important feature
compared to the other features like

119
00:07:12,889 --> 00:07:14,149
the temperature and holiday flag.

120
00:07:16,919 --> 00:07:22,109
Now I would like to talk about why
XC Boost or xg B Regressor model

121
00:07:22,169 --> 00:07:23,669
outperformed the other models.

122
00:07:24,059 --> 00:07:25,349
So there are a few reasons.

123
00:07:25,699 --> 00:07:29,869
It uses the gradient boosting with
regularization to reduce or fitting,

124
00:07:30,349 --> 00:07:34,099
it handles the missing values and
skew distributions effectively.

125
00:07:34,954 --> 00:07:35,914
Or efficiently.

126
00:07:36,154 --> 00:07:40,484
And then finally it is highly at
Tuneable with strong cross validation

127
00:07:40,484 --> 00:07:44,594
support, and that is why we have
achieved that 97.2 percentage accuracy,

128
00:07:44,984 --> 00:07:46,334
the highest in the experiment,

129
00:07:48,524 --> 00:07:54,014
conclusion, and recommendations, visual
analysis and AIDS featuring understanding.

130
00:07:54,569 --> 00:07:57,209
Simple models offer
speed, but less accuracy.

131
00:07:57,689 --> 00:08:01,769
XG Boost is recommended for
accurate and scalable forecasting.

132
00:08:02,189 --> 00:08:06,119
Consider assembling or hyper parameter
tuning for even better results.

133
00:08:06,419 --> 00:08:10,419
So for this experiment or the
test, what we have done with the

134
00:08:10,419 --> 00:08:14,919
Walmart data set, we have used the
basic parameters for the models.

135
00:08:14,919 --> 00:08:19,719
But if we have a complicated data
set, then for sure we can hyper tune

136
00:08:19,959 --> 00:08:21,909
our model to get better results.

137
00:08:23,959 --> 00:08:25,399
Thank you so much for having me.

138
00:08:25,459 --> 00:08:27,709
I hope you have a good day
and a great conference.

139
00:08:27,739 --> 00:08:28,159
Thank you.

