1
00:00:00,330 --> 00:00:01,020
Hey everyone.

2
00:00:01,350 --> 00:00:05,040
Welcome to com 42 on
large language models.

3
00:00:05,970 --> 00:00:09,570
My name is Peter Deten, technical
trainer at Microsoft Live,

4
00:00:09,570 --> 00:00:11,340
presenting from Redmond, Washington.

5
00:00:11,730 --> 00:00:16,560
My session today covers using
Azure AI Foundry to manage all

6
00:00:16,560 --> 00:00:18,150
your large language models.

7
00:00:18,870 --> 00:00:21,240
With that, I would say
welcome and let's go.

8
00:00:21,740 --> 00:00:26,630
Over the next 45 minutes to an hour, I
will cover the following topics, starting

9
00:00:26,630 --> 00:00:32,030
with a quick overview of the future
of work with ai, followed by domain

10
00:00:32,030 --> 00:00:38,300
section, how Azure AI Foundry is used by
Microsoft itself to run AI solutions and

11
00:00:38,300 --> 00:00:40,580
obviously how you can leverage the same.

12
00:00:41,480 --> 00:00:46,849
And then last, how to bring in a rag
architecture, meaning using all the beauty

13
00:00:46,849 --> 00:00:49,610
from Azure AI together with AI Foundry.

14
00:00:50,060 --> 00:00:55,340
Generative AI using large language models,
but then also integrating your own data.

15
00:00:56,000 --> 00:00:59,510
And then for each of these topics,
you can expect quite some live

16
00:00:59,510 --> 00:01:02,390
demos during the session as well.

17
00:01:02,890 --> 00:01:05,950
So again, my name is
Peter d Tander originally.

18
00:01:06,450 --> 00:01:10,619
Originally from Belgium, but ated to
Redmond, Washington to continue my

19
00:01:10,619 --> 00:01:12,480
job as a Microsoft technical trainer.

20
00:01:13,200 --> 00:01:15,929
I've been a Microsoft trainer
for about six years now.

21
00:01:16,150 --> 00:01:20,860
before I joined Microsoft in a full-time
employee position, I was already working

22
00:01:20,860 --> 00:01:25,090
for them as a partner and vendor out of
my own company for about seven years.

23
00:01:25,590 --> 00:01:30,360
My Azure background has always been on
the infra and in architecture side, but

24
00:01:30,360 --> 00:01:35,190
gradually I shifted more into DevOps
developing Azure solutions, and nowadays,

25
00:01:35,220 --> 00:01:37,890
obviously a lot about AI and copilot.

26
00:01:38,820 --> 00:01:42,420
Feel free to reach out if you
should have any questions using

27
00:01:42,420 --> 00:01:44,600
any of the listed methods.

28
00:01:45,100 --> 00:01:45,350
Good.

29
00:01:45,350 --> 00:01:47,960
So with that all out of
the way, let's jump in.

30
00:01:48,530 --> 00:01:48,680
Now.

31
00:01:48,680 --> 00:01:53,150
When I talk about AI in any of
the Azure and AI workshops I'm

32
00:01:53,150 --> 00:01:57,230
teaching, I always like to start
with a quote from our CEO Satya.

33
00:01:58,130 --> 00:01:59,510
He explained it as follows.

34
00:02:00,110 --> 00:02:06,230
Organizations are asking not only how,
but also how fast they can actually

35
00:02:06,230 --> 00:02:11,120
apply this next generation of AI to
address the biggest opportunities

36
00:02:11,120 --> 00:02:12,769
and challenges they are facing.

37
00:02:13,269 --> 00:02:16,605
Good with that all out of
the way, let's jump in.

38
00:02:17,105 --> 00:02:20,855
Now when I talk about AI in our
workshops here at Microsoft, I always

39
00:02:20,855 --> 00:02:22,924
like to start with a quote from our CEO.

40
00:02:22,924 --> 00:02:23,494
Satya.

41
00:02:24,454 --> 00:02:29,734
Organizations are asking not only how,
but also how fast they can apply this

42
00:02:29,734 --> 00:02:34,744
next generation of AI to address the
biggest challenges, but also opportunities

43
00:02:35,015 --> 00:02:37,954
they face safely and responsibly.

44
00:02:38,454 --> 00:02:41,815
Now the core of the quote will
become more clear by the end of my

45
00:02:41,815 --> 00:02:46,225
session, so that, let's start with
the foundation, understanding what

46
00:02:46,225 --> 00:02:48,475
the future of work with AI looks like.

47
00:02:48,975 --> 00:02:53,265
For the last two years, give or take,
organizations have primarily been

48
00:02:53,265 --> 00:02:55,635
experimenting with different models.

49
00:02:56,115 --> 00:03:01,185
I think it is safe to say that OpenAI
with Jet GPD revolutionized the world

50
00:03:01,275 --> 00:03:04,275
with Jet GPD again, end of 2023.

51
00:03:05,115 --> 00:03:09,455
But from there, several other players
came into the market like Gemini,

52
00:03:09,455 --> 00:03:11,705
from Google, and Tropic with Claude.

53
00:03:12,285 --> 00:03:17,125
deep seek from China, Microsoft
having the five, models, menstrual,

54
00:03:17,125 --> 00:03:18,895
hugging, face, and so many other.

55
00:03:19,435 --> 00:03:23,605
Now what this slide represents is how
many different models are actually

56
00:03:23,605 --> 00:03:25,345
being used by an organization.

57
00:03:26,095 --> 00:03:30,335
The average, you could say here
is, 3, 2, 5, so probably four as

58
00:03:30,335 --> 00:03:34,295
the average where no one on the
interviewed organizations was just

59
00:03:34,295 --> 00:03:38,645
relying on a single large language
model for any of their AI solutions.

60
00:03:39,145 --> 00:03:44,005
Now also important to highlight is
that about 80% of early AI projects

61
00:03:44,065 --> 00:03:48,295
actually fail because not meeting
expectations and not meeting them

62
00:03:48,295 --> 00:03:50,395
because they're too complex now.

63
00:03:50,395 --> 00:03:54,055
Complexity and the fact that
especially generative AI is

64
00:03:54,055 --> 00:03:55,705
still rather new technology.

65
00:03:55,755 --> 00:03:58,965
And also providing a breadth
of large language models to

66
00:03:58,965 --> 00:04:01,275
choose from, but then also.

67
00:04:02,175 --> 00:04:07,215
The fact that applications are
changing, moving from single models

68
00:04:07,245 --> 00:04:12,075
into orchestrated systems, allowing
to learn and adapt continuously.

69
00:04:12,825 --> 00:04:16,845
Customers and users are expecting
AI influenced, or you could

70
00:04:16,845 --> 00:04:19,065
say AI inspired capabilities.

71
00:04:19,455 --> 00:04:23,775
In almost any kind of application
today across different industries

72
00:04:23,835 --> 00:04:25,485
and across different use cases.

73
00:04:25,985 --> 00:04:30,455
Now, even amidst these challenges, it's
clear that generative AI is what makes

74
00:04:30,455 --> 00:04:34,865
applications through the intelligent,
but that's also a paradigm shift.

75
00:04:35,365 --> 00:04:39,490
AI is moving from this, I don't
know, autopilot phase, which was all

76
00:04:39,490 --> 00:04:43,570
about narrowing purpose-built tools
that use machine learning models.

77
00:04:43,875 --> 00:04:46,875
To now come up with
predictions recommendations.

78
00:04:46,935 --> 00:04:53,235
also just automating to now having this
co-pilot era where there's tremendous

79
00:04:53,235 --> 00:04:58,245
opportunity to really revolutionize
how just about everything can start

80
00:04:58,745 --> 00:05:00,815
using those intelligent applications.

81
00:05:00,875 --> 00:05:05,375
You can now enable natural language
interaction, constantly improving user

82
00:05:05,375 --> 00:05:10,175
experience and quickly delivering new
features and capabilities to the market.

83
00:05:10,675 --> 00:05:13,735
So with that, let's shift gears
a little bit and talk about

84
00:05:13,735 --> 00:05:15,655
Azure AI Foundry specifically.

85
00:05:16,525 --> 00:05:20,995
By the way, one of the reasons Microsoft
has moved such fast pace over the last

86
00:05:20,995 --> 00:05:25,945
few months is because our Microsoft
AI solutions within Microsoft are

87
00:05:25,945 --> 00:05:28,255
all running using Azure AI Foundry.

88
00:05:28,755 --> 00:05:32,925
Now we've built our Microsoft
copilot reaching in meantime,

89
00:05:32,925 --> 00:05:35,055
millions of users across the globe.

90
00:05:35,775 --> 00:05:40,245
Informing them across different platforms
using, for example, just copilot on

91
00:05:40,245 --> 00:05:44,565
the mobile device in the browser,
using copilot web, using copilot

92
00:05:44,595 --> 00:05:49,905
within Microsoft 3 6 5 applications,
security copilot dynamics copilot,

93
00:05:50,145 --> 00:05:52,845
Azure co-pilot, and GitHub copilot.

94
00:05:53,175 --> 00:05:58,035
All of these co-pilot are a hundred
percent begged by Azure AI Foundry.

95
00:05:58,535 --> 00:06:01,295
Which now also becomes available to you.

96
00:06:02,045 --> 00:06:06,455
So you might have heard about Azure AI
Studio before, where it's still the same

97
00:06:06,455 --> 00:06:11,345
foundation, I would say being the one-stop
shop, like a management portal for

98
00:06:11,345 --> 00:06:14,105
developers IT sales admins, cloud admins.

99
00:06:14,105 --> 00:06:20,705
If you want to create your own custom
copilots leveraging ai, Azure AI services.

100
00:06:21,665 --> 00:06:26,975
So insured Azure AI Foundry is a
trusted, integrated platform designed for

101
00:06:26,975 --> 00:06:32,645
developers, IT admins, cloud architects,
allowing them to design, customize, and

102
00:06:32,645 --> 00:06:35,675
manage AI applications as well as agents.

103
00:06:35,675 --> 00:06:40,675
Nowadays, it offers a rich set of AI
capabilities and tools, and yes, I'll

104
00:06:40,675 --> 00:06:45,835
walk you through a few of these in a demo
using an easy to use, easy to navigate.

105
00:06:46,165 --> 00:06:52,225
Portal, but there's also a unified SDK
providing you APIs to really accelerate

106
00:06:52,225 --> 00:06:54,415
the path from developing to production.

107
00:06:54,915 --> 00:06:59,595
Now, what sets Azure AI Foundry apart
is the accessibility through the world's

108
00:06:59,595 --> 00:07:05,025
most loved developer tools, meaning
GitHub Visual Studio and co-pilot studio.

109
00:07:05,770 --> 00:07:08,890
This really integrates with
a lot of other scenarios.

110
00:07:09,640 --> 00:07:15,010
So what we see here is continuously
building up on Azure AI Foundry being this

111
00:07:15,010 --> 00:07:20,760
open, flexible, modular platform, sorry,
with a lot of the tools a developer needs

112
00:07:20,760 --> 00:07:26,130
in a single platform to build multi-agent
solutions, integrating third party tools.

113
00:07:26,465 --> 00:07:28,385
Just like we've done with our own models.

114
00:07:28,885 --> 00:07:33,085
This also means that developers now get
access to Quick Start AI application

115
00:07:33,085 --> 00:07:37,525
templates to support their development
cycle and really shortening that

116
00:07:37,525 --> 00:07:39,895
complexity that I talked about before.

117
00:07:40,395 --> 00:07:45,345
Any of these templates can be customized
using a wide area of already existing

118
00:07:45,345 --> 00:07:50,925
models and tools, making your applications
future-proof development investments.

119
00:07:51,425 --> 00:07:53,974
Another part I wanna talk
about is it governance.

120
00:07:54,425 --> 00:07:57,905
So IT governance at scale, like
what we call here, enterprise

121
00:07:57,905 --> 00:08:00,395
setup is baked in AI foundry.

122
00:08:01,295 --> 00:08:05,375
It allows you to provide a comprehensive
approach providing self-service

123
00:08:05,375 --> 00:08:11,555
experiences, customizable configurations,
and overall enhancing agility, security,

124
00:08:11,795 --> 00:08:13,685
but also keeping compliance in mind.

125
00:08:14,495 --> 00:08:17,825
So to give you an idea, there's
obviously prebuilt baked in.

126
00:08:18,670 --> 00:08:23,890
Azure and Azure AI Foundry, role-based
access control, including like owner

127
00:08:23,890 --> 00:08:28,320
having you, giving you all permissions,
including changing security permissions.

128
00:08:28,955 --> 00:08:32,135
They're a little bit lower
permission contributor, but there's

129
00:08:32,135 --> 00:08:37,985
also reader ai, developer and AI
inference deployment operator roles.

130
00:08:38,015 --> 00:08:39,125
Little bit complex there.

131
00:08:39,505 --> 00:08:43,465
but what it means is like for
any kind of responsibility as

132
00:08:43,465 --> 00:08:45,055
part of your development cycle.

133
00:08:45,390 --> 00:08:48,840
You can have, a corresponding
role-based access control.

134
00:08:49,680 --> 00:08:53,460
Next to that, all these roles, are
accessible from within the same AI

135
00:08:53,460 --> 00:08:59,100
foundry where we now use a topology called
the hub and projects out of the hub.

136
00:08:59,100 --> 00:09:01,740
It's like the highest
level in the topology.

137
00:09:01,920 --> 00:09:04,980
You're gonna allocate one or
more projects, and within a

138
00:09:04,980 --> 00:09:06,450
project you're gonna define.

139
00:09:06,680 --> 00:09:11,440
The different, permissions On top
of that, you can think about other

140
00:09:11,440 --> 00:09:13,890
features, mentioned here on the diagram.

141
00:09:14,315 --> 00:09:18,425
Identity, access management,
network security, data protection,

142
00:09:18,525 --> 00:09:22,605
encryption, compute, storage,
quota, access to the models.

143
00:09:22,935 --> 00:09:27,885
All that is now becoming available
within a project and within a hub.

144
00:09:28,725 --> 00:09:32,265
Mainly avoiding that each and every
developer when they're working

145
00:09:32,265 --> 00:09:36,035
on an AI inspired application
that they have to deploy, like

146
00:09:36,035 --> 00:09:37,685
the full architecture themselves.

147
00:09:38,165 --> 00:09:43,025
So you would almost say that your cloud
team is now building the hub and project.

148
00:09:43,355 --> 00:09:47,645
And developers are consuming the
services, the building blocks within

149
00:09:47,705 --> 00:09:50,095
a project, and then on the outside.

150
00:09:50,595 --> 00:09:52,905
And then on the outside
we have our business it.

151
00:09:53,535 --> 00:09:58,605
And from there we could also expand
with IT security because in the

152
00:09:58,605 --> 00:10:01,755
end, it's still part of the broader
Azure world, which means that

153
00:10:01,755 --> 00:10:03,375
everything you might already know.

154
00:10:03,840 --> 00:10:07,770
From Azure Tenants, Azure subscriptions
management groups, like the whole

155
00:10:07,770 --> 00:10:11,970
governance layer around it is now
also still valid once you start

156
00:10:11,970 --> 00:10:16,050
deploying your AI foundry and
corresponding Azure Resources.

157
00:10:16,550 --> 00:10:20,480
Apart from the core AI services
dependencies extended with other

158
00:10:20,480 --> 00:10:23,900
Azure resources like E Vault,
private networking, and the like.

159
00:10:24,350 --> 00:10:28,340
You can now also easily, I would
say, provide access to those external

160
00:10:28,340 --> 00:10:33,380
resources from within AI Foundry
using a feature called Connections.

161
00:10:34,040 --> 00:10:38,240
So again, it means that instead of needing
to provide access to your development

162
00:10:38,240 --> 00:10:43,790
team, your IT Cloud admins to all those
resources, it's now becoming just another

163
00:10:43,790 --> 00:10:46,280
aspect of your AI Foundry landscape.

164
00:10:46,880 --> 00:10:49,550
And these connections are
typically already linked to

165
00:10:49,550 --> 00:10:51,320
multiple projects within a hub.

166
00:10:51,820 --> 00:10:55,540
And with that, let's shift to a first
demo here where I'll walk you through the

167
00:10:55,540 --> 00:11:01,360
base deployment of Azure AI services, as
well as a first look at Azure AI Foundry,

168
00:11:01,840 --> 00:11:06,460
showing you the hope and project, as well
as how to add and manage your connections.

169
00:11:06,960 --> 00:11:13,410
So my starting point here is my Azure
subscription, and I got everything inside

170
00:11:13,680 --> 00:11:17,350
my, sample com 42 Foundry resource group.

171
00:11:18,160 --> 00:11:23,090
I already deployed most of the
resources that I need, but my

172
00:11:23,090 --> 00:11:27,230
assumption is that you already know
how to deploy some resource in Azure.

173
00:11:27,710 --> 00:11:29,210
So not all that important.

174
00:11:29,280 --> 00:11:29,660
for now.

175
00:11:29,990 --> 00:11:34,070
One of the building blocks
I have is an Azure AI hub.

176
00:11:34,100 --> 00:11:36,440
I'll talk about that a
little bit again later on.

177
00:11:37,070 --> 00:11:42,650
Within, we got a project, the core that
I'm using here is Azure AI Services,

178
00:11:43,010 --> 00:11:48,380
and I got a few site services over here,
like a container registry and Azure Key

179
00:11:48,380 --> 00:11:50,480
Vault log analytics for my monitoring.

180
00:11:51,170 --> 00:11:57,020
So the starting point will most probably
be your AI service, which means that

181
00:11:57,050 --> 00:11:59,090
you would go into the Azure portal.

182
00:11:59,470 --> 00:12:02,920
From there, you would deploy
a new service called Azure AI

183
00:12:02,920 --> 00:12:05,050
Service, and that's pretty much it.

184
00:12:05,830 --> 00:12:09,940
Now, from a development perspective, there
are a few things that you need to keep in

185
00:12:09,940 --> 00:12:13,530
mind for connecting to your AI service.

186
00:12:14,280 --> 00:12:17,640
Primarily, I would say here,
endpoints and your keys.

187
00:12:18,060 --> 00:12:22,230
So when we move to endpoints, what
we have is obviously depending

188
00:12:22,230 --> 00:12:24,420
on the different AI use cases.

189
00:12:24,660 --> 00:12:29,490
In my example here, I'm using OpenAI
to really have that generative AI

190
00:12:29,490 --> 00:12:35,340
capability available as an endpoint
allowing me to integrate later on

191
00:12:35,790 --> 00:12:40,200
my large language models and so much
more out of my foundry interface.

192
00:12:40,200 --> 00:12:44,090
I. If I wanna interact with
other AI services like the

193
00:12:44,090 --> 00:12:45,530
more traditional ones, right?

194
00:12:45,650 --> 00:12:49,730
Compute, vision, content, safety,
language, translator, I can again

195
00:12:49,730 --> 00:12:51,950
find all that information up here.

196
00:12:52,450 --> 00:12:57,500
Now, the reason why, we have our AI
Foundry as a portal is because in

197
00:12:57,500 --> 00:13:02,390
the end from here, what I'm doing is
just managing the Azure resources.

198
00:13:02,780 --> 00:13:05,450
So you could almost say
that this should be a part.

199
00:13:05,535 --> 00:13:08,565
That maybe your developer is
not really seeing anymore.

200
00:13:09,105 --> 00:13:09,555
Why not?

201
00:13:09,555 --> 00:13:13,395
Because for them, everything
that is related to management

202
00:13:13,575 --> 00:13:15,855
is now moved into AI Foundry.

203
00:13:16,695 --> 00:13:21,065
By the way, if you navigate back
to the starting point AI service,

204
00:13:21,125 --> 00:13:25,505
you can see down here there is
the Azure AI Foundry portal link.

205
00:13:26,465 --> 00:13:29,785
So let me move over to that one,
and that's where we are now,

206
00:13:29,785 --> 00:13:32,005
landing in our Foundry portal.

207
00:13:32,515 --> 00:13:34,285
Now, there's a few different ways you can.

208
00:13:34,285 --> 00:13:35,215
You'd end up here.

209
00:13:35,305 --> 00:13:38,905
So I talked about the
hub and project, right?

210
00:13:39,175 --> 00:13:43,425
But when within my setup here,
you won't really see that.

211
00:13:43,875 --> 00:13:46,725
So depending a bit how you get
there, you're gonna see that.

212
00:13:46,935 --> 00:13:51,375
Right now here I'm in my Azure
open AI service because for

213
00:13:51,375 --> 00:13:56,905
this scenario, I started from
deploying an open ai Azure service.

214
00:13:57,455 --> 00:14:04,545
now if I navigate to my other scenario,
I'm now in my Azure AI foundry, homepage

215
00:14:04,575 --> 00:14:10,385
you could say, which by the way, you
can navigate to from ai.azure.com.

216
00:14:10,855 --> 00:14:11,545
And within.

217
00:14:12,385 --> 00:14:15,745
As you can see here, I do
have my hub and my project.

218
00:14:16,525 --> 00:14:20,545
When I navigate to my hub,
you're gonna see some highlights

219
00:14:20,545 --> 00:14:22,315
from my Azure subscription.

220
00:14:22,735 --> 00:14:26,035
So down here I can still
see my Azure subscription.

221
00:14:26,065 --> 00:14:30,805
I could switch back to manage it in
my Azure portal, but now I can also,

222
00:14:30,805 --> 00:14:35,535
as a developer, picking up the AI
endpoints and keys that I need from here.

223
00:14:36,225 --> 00:14:40,095
So instead of now just having
my open AI service, it's not.

224
00:14:40,095 --> 00:14:46,425
Now switched, you could say, to
Azure AI Foundry Management Center.

225
00:14:46,925 --> 00:14:50,645
Within the management center,
we have obviously the overview

226
00:14:50,825 --> 00:14:52,475
of our hubs and projects.

227
00:14:52,535 --> 00:14:56,525
And again, the logic is that you
would create one or more hubs as

228
00:14:56,525 --> 00:15:00,395
the higher level in the topology
and underneath you would create

229
00:15:00,395 --> 00:15:03,275
one or more projects within a hub.

230
00:15:03,335 --> 00:15:06,665
So that's the relationship
you can see from here.

231
00:15:07,145 --> 00:15:09,575
I got my AI project as part of my.

232
00:15:09,875 --> 00:15:10,535
AI hub.

233
00:15:10,595 --> 00:15:12,215
That's the logic behind it.

234
00:15:12,715 --> 00:15:16,525
Staying within the hub level for a minute.

235
00:15:17,365 --> 00:15:21,595
I talked about RAC, role-based access
control, where now you can see I got

236
00:15:21,595 --> 00:15:25,105
my AI admin and a little bit lower.

237
00:15:25,255 --> 00:15:29,845
I got my Azure ML data scientists
replicating that you have someone

238
00:15:29,845 --> 00:15:34,555
managing the AI service and you might
have some data scientist on the other side

239
00:15:34,975 --> 00:15:39,425
interacting with the storage, providing,
the data endpoints most probably.

240
00:15:39,845 --> 00:15:43,505
And then from there, allowing my
developers to start interacting.

241
00:15:44,005 --> 00:15:46,345
You can manage your quota.

242
00:15:46,495 --> 00:15:50,855
So if I switch back up here,
one of the, I would say.

243
00:15:51,395 --> 00:15:53,855
Configuration options
you have within Azure.

244
00:15:53,885 --> 00:15:58,115
Later on when we start deploying
our models is that you need to

245
00:15:58,115 --> 00:15:59,645
know a bit about the models.

246
00:15:59,645 --> 00:16:05,165
First of all, you need to know how much
tokens, like the virtual AI currency,

247
00:16:05,165 --> 00:16:09,965
I would call it, your application
would need, but also knowing that each

248
00:16:09,965 --> 00:16:14,445
and every Azure region together with
the models, also provide you a quota.

249
00:16:14,655 --> 00:16:19,205
So in my setup here, I already
have a few scenarios like models

250
00:16:19,205 --> 00:16:20,555
deployed and I'll show you in there.

251
00:16:20,555 --> 00:16:22,595
Next demo how to actually do this.

252
00:16:23,135 --> 00:16:27,395
But what you can see here
is that I deployed GPT-4 oh.

253
00:16:28,235 --> 00:16:32,555
This is the version I'm using most,
probably the latest one, and I'm

254
00:16:32,555 --> 00:16:35,525
allocating 8,000 tokens per minute.

255
00:16:36,125 --> 00:16:42,660
We're now, for the total of my Azure
region, there's 450,000 available.

256
00:16:43,160 --> 00:16:46,175
So depending on the needs of
your application, you're gonna

257
00:16:46,175 --> 00:16:50,265
allow less or more numbers of
tokens or thousands of tokens.

258
00:16:51,195 --> 00:16:55,385
Because they heavily influence, the
richness, I would say, of the prompts

259
00:16:55,385 --> 00:17:01,745
your users can run, but also, how complete
the actual, prompt response can be.

260
00:17:02,345 --> 00:17:06,305
Where at some point you might actually
run out of tokens, and that's where

261
00:17:06,305 --> 00:17:10,935
now in the quota you need to validate
what your Azure region, provides.

262
00:17:11,565 --> 00:17:15,545
So that's the first, I would say
high level scenario on how to

263
00:17:15,545 --> 00:17:18,245
actually navigate across your.

264
00:17:18,695 --> 00:17:24,035
AI foundry starting from the Azure
portal, deploying an Azure AI service,

265
00:17:24,245 --> 00:17:26,495
and within navigating to Foundry.

266
00:17:26,855 --> 00:17:33,975
Where next you have the option to use the
hub and, project topology allocating REC.

267
00:17:34,245 --> 00:17:39,365
And then in the next step, we're gonna
allocate our actual, language models.

268
00:17:39,845 --> 00:17:41,855
But for now, back to the presentation.

269
00:17:42,355 --> 00:17:46,735
While most of my demos will happen from
the AI Foundry portal, I understand

270
00:17:46,735 --> 00:17:51,505
that most developers will probably
like to interact from a, I don't know,

271
00:17:51,535 --> 00:17:55,645
development interface, and that's
where an SDK comes into the picture.

272
00:17:56,335 --> 00:18:00,835
So the good news is that there is an
Azure ai, SDK specifically available.

273
00:18:01,215 --> 00:18:06,135
To equip developers streamlining
AI integration and really enriching

274
00:18:06,135 --> 00:18:10,785
that user experience and building in
functionalities into their applications.

275
00:18:11,535 --> 00:18:16,065
This toolkit supports multiple programming
languages, Python, c sharp.net,

276
00:18:16,065 --> 00:18:20,325
Java, you think of it, you name it,
and it is supported, really enabling

277
00:18:20,325 --> 00:18:24,675
developers to select the language of
choice and making them more productive.

278
00:18:25,115 --> 00:18:28,635
While developing, generative
AI inspired applications.

279
00:18:29,385 --> 00:18:32,805
So from there, developers can
efficiently build, evaluate,

280
00:18:32,805 --> 00:18:34,965
deploy those AI components.

281
00:18:35,475 --> 00:18:39,435
The SEK integration is obviously
part of the already trusted

282
00:18:39,435 --> 00:18:43,105
development environments, mentioned
before, GitHub Visual Studio vs.

283
00:18:43,105 --> 00:18:47,785
Code, and you're gonna interact
with your AI Foundry not from

284
00:18:47,785 --> 00:18:51,325
within the portal, like I'll show
you in the demo, but obviously from

285
00:18:51,415 --> 00:18:53,815
within the SDK integration directly.

286
00:18:54,315 --> 00:18:58,155
With the base Azure Services
and AI Foundry up and running.

287
00:18:58,365 --> 00:19:02,385
Let's talk a bit about the large language
models, which by the way is the topic

288
00:19:02,445 --> 00:19:03,945
of the conference overall, right?

289
00:19:04,665 --> 00:19:07,935
With Azure AI Foundry, you
get access to an extensive

290
00:19:07,935 --> 00:19:09,705
list of large language models.

291
00:19:10,065 --> 00:19:13,755
Really allowing you as the developer
or obviously your customers,

292
00:19:14,025 --> 00:19:17,595
to choose the models that make
most sense for your solution.

293
00:19:18,405 --> 00:19:21,705
Now, while this list here on
screen might not feel extensive.

294
00:19:22,230 --> 00:19:24,750
Know that there are more than
a thousand different models.

295
00:19:24,900 --> 00:19:30,300
Yes, more than a thousand to choose
from available today, which can all

296
00:19:30,300 --> 00:19:32,430
be deployed within your AI foundry.

297
00:19:32,730 --> 00:19:34,170
Even I would say deep seek.

298
00:19:34,230 --> 00:19:37,850
One of the more recent, large
language models integrated

299
00:19:37,850 --> 00:19:39,320
only a couple of weeks ago.

300
00:19:39,380 --> 00:19:43,880
It's already available, and we got more
on the list coming out in the near future.

301
00:19:44,380 --> 00:19:48,580
So for that, let me jump back to my
demo environment and show you how

302
00:19:48,580 --> 00:19:52,930
easy it can be to search for models,
deploy the models, and also covering

303
00:19:52,930 --> 00:19:57,490
a few other, I would say, baseline
tasks once you start using models

304
00:19:57,550 --> 00:19:59,530
and all from within AI Foundry.

305
00:20:00,030 --> 00:20:00,420
All right.

306
00:20:00,420 --> 00:20:04,710
So with that, let's have a look at,
the actual large language models can be

307
00:20:04,710 --> 00:20:07,800
deployed again from within our AI foundry.

308
00:20:08,490 --> 00:20:12,060
So I'm still at the screen where,
I finished my previous demo.

309
00:20:12,120 --> 00:20:14,730
There was actually one
part I forgot to show you.

310
00:20:14,730 --> 00:20:17,910
And that's, the connectors
or connected resources.

311
00:20:18,540 --> 00:20:21,780
Now, if you think about how
a developer interacts with.

312
00:20:22,455 --> 00:20:26,925
The AI service, as I showed you, there's
the endpoint, but there's also the keys.

313
00:20:27,405 --> 00:20:30,735
And later on we'll talk about rag
architecture, which means you're

314
00:20:30,735 --> 00:20:33,325
probably gonna integrate, like AI search.

315
00:20:33,775 --> 00:20:37,195
And then in the last part there's a
little bit, I'll talk about content

316
00:20:37,195 --> 00:20:41,815
safety, making sure that your
application is following our Microsoft

317
00:20:41,815 --> 00:20:44,695
responsible AI framework guidelines.

318
00:20:45,175 --> 00:20:49,195
So all of these are standalone
services, standalone resources

319
00:20:49,225 --> 00:20:50,485
in the Azure platform.

320
00:20:50,975 --> 00:20:54,635
We're now again, in that mindset
that your developer will probably

321
00:20:54,635 --> 00:20:56,735
need access to all those resources.

322
00:20:57,155 --> 00:21:01,535
Instead of giving them access from
an Azure perspective, you could now

323
00:21:01,535 --> 00:21:07,625
allocate them as an available resource
for the hub or an individual project.

324
00:21:07,840 --> 00:21:10,060
And that's mainly what you
could manage from here.

325
00:21:10,390 --> 00:21:14,570
So just to clarify the interface, if
you've never really seen, AI Foundry

326
00:21:14,570 --> 00:21:22,040
in action, the highest level AI foundry
is available from ai.azure.com and

327
00:21:22,040 --> 00:21:24,050
underneath you're gonna create a hub.

328
00:21:24,920 --> 00:21:25,760
Within the hub.

329
00:21:26,090 --> 00:21:29,390
You later on gonna create a project
that we already talked about,

330
00:21:29,810 --> 00:21:33,770
and then from there we interact
with our connected resources.

331
00:21:34,250 --> 00:21:37,160
So from here I could interact with new.

332
00:21:37,610 --> 00:21:38,930
I talked about Key Vault.

333
00:21:39,350 --> 00:21:43,960
I didn't really, deploy it yet, but you
could interact with OpenAI, with your

334
00:21:43,960 --> 00:21:46,350
speech and other, some other services.

335
00:21:46,770 --> 00:21:50,520
And if you want, you could actually
directly connect to other service

336
00:21:50,520 --> 00:21:53,970
building blocks in Azure or
even outside of Azure as well.

337
00:21:54,470 --> 00:21:57,260
Now, from here, we can
shift to our models.

338
00:21:57,380 --> 00:22:01,100
Now, there's a few different ways, I
would say within the portal to do this,

339
00:22:01,100 --> 00:22:06,830
depending if you are active on a project,
active on a. Are active in the open AI

340
00:22:06,950 --> 00:22:08,930
services that I showed you at the start.

341
00:22:09,430 --> 00:22:15,510
From here, I navigated inside the hub
and I'm now inside this specific project

342
00:22:16,320 --> 00:22:19,710
where you can see, as you already
know from my previous demo, I already

343
00:22:19,710 --> 00:22:22,200
have some of my connections available.

344
00:22:22,680 --> 00:22:27,540
So what this means is that, for example,
my cloud admin pre deploy the connections

345
00:22:27,570 --> 00:22:29,220
and they're now becoming available.

346
00:22:29,670 --> 00:22:32,850
But imagine that I also
wanna deploy my own specific.

347
00:22:33,330 --> 00:22:36,390
That I only want to use
within this specific project.

348
00:22:36,960 --> 00:22:41,400
So I could do this again from here
since I'm already in the project, right?

349
00:22:41,460 --> 00:22:44,700
I could manage it all
from here, or why not?

350
00:22:44,730 --> 00:22:48,500
I could open up my project
in a separate blade.

351
00:22:48,860 --> 00:22:52,610
And then from here I get
again, my models and endpoints.

352
00:22:53,000 --> 00:22:54,110
So it looks about the same.

353
00:22:54,110 --> 00:22:56,900
It just depends on how
you're gonna navigate to it.

354
00:22:57,455 --> 00:23:02,135
So let's show you how we can
add a new model, and this is now

355
00:23:02,135 --> 00:23:06,755
giving me access to all possible
models within our environment.

356
00:23:07,115 --> 00:23:11,495
So you can see I talked about, a bit
more than a thousand, and we actually

357
00:23:11,495 --> 00:23:14,045
have almost 2000 available in there.

358
00:23:14,675 --> 00:23:17,435
So you can start with
pre-built collections.

359
00:23:17,435 --> 00:23:21,395
So if you want, you could filter
based on only the ones from OpenAI.

360
00:23:22,110 --> 00:23:26,910
Like an easy example and then the list
will only obviously present those ones.

361
00:23:27,330 --> 00:23:32,850
Or if you wanna filter based on what
I can do with them and then maybe

362
00:23:32,850 --> 00:23:37,620
some specific features, like I only
wanna have the ones supporting chat

363
00:23:37,710 --> 00:23:40,620
completions and overall completions.

364
00:23:40,650 --> 00:23:43,720
Then you can see that
there are, open AI ones.

365
00:23:43,720 --> 00:23:48,700
The Microsoft five one, there's minus
one, there's Lama from Meta, and again,

366
00:23:48,700 --> 00:23:50,350
all the other ones showing up here.

367
00:23:50,850 --> 00:23:55,020
So the next step now is
selecting your model.

368
00:23:55,200 --> 00:23:59,700
It always provides you a pretty detailed
description, what that model actually

369
00:23:59,850 --> 00:24:05,230
represents, and then you could also
define some of its, capabilities.

370
00:24:05,710 --> 00:24:09,670
From there, you would confirm, now, since
I already deployed this, it's not gonna

371
00:24:09,670 --> 00:24:12,400
allow me to deploy this anymore, so let's.

372
00:24:12,890 --> 00:24:16,250
Try and select another one here, GPT-4 oh.

373
00:24:16,370 --> 00:24:18,350
Still one of the more recent ones.

374
00:24:18,770 --> 00:24:23,370
Again, explanation, sharing information
about the latest, version you could

375
00:24:23,370 --> 00:24:26,910
say, and then some description
what it actually allows you to do.

376
00:24:27,180 --> 00:24:32,090
So I'm gonna confirm, and the next
step is now defining the specifics

377
00:24:32,090 --> 00:24:36,830
for my project so I can choose the
deployment type global standard.

378
00:24:36,830 --> 00:24:39,560
It means that you're
gonna pay per API call.

379
00:24:40,475 --> 00:24:44,285
And if you want, if the model supports
it, there's a few other ones as well.

380
00:24:44,735 --> 00:24:48,065
I would say if you wanna know more
details, then please consult our,

381
00:24:48,135 --> 00:24:51,075
Microsoft documentation, because
I don't have the time in this

382
00:24:51,075 --> 00:24:53,145
demo to expand on all of these.

383
00:24:53,145 --> 00:24:54,945
But it has a lot to do with.

384
00:24:55,410 --> 00:24:59,370
The high variability aspects of the
Azure architecture in the backend.

385
00:25:00,330 --> 00:25:05,430
Next, in our deployment details, we can
fine tune, customize this a little bit, so

386
00:25:05,430 --> 00:25:07,200
you've got the different model versions.

387
00:25:07,250 --> 00:25:08,570
some versions up and down.

388
00:25:08,570 --> 00:25:13,640
You could say typically, my guidance
is to use the most up-to-date version,

389
00:25:13,790 --> 00:25:17,120
but there might be specific use
cases where maybe you don't have

390
00:25:17,120 --> 00:25:18,650
to or you don't want to do that.

391
00:25:19,495 --> 00:25:22,555
If you wanna integrate it with
one of your previously discussed

392
00:25:22,555 --> 00:25:24,565
connections, you could do that as well.

393
00:25:24,595 --> 00:25:27,685
And then defining the tokens
per minute rate limit.

394
00:25:27,775 --> 00:25:32,785
And again, this influences the use
cases of your application if you

395
00:25:32,785 --> 00:25:34,465
wanna integrate content filtering.

396
00:25:34,465 --> 00:25:36,500
So again, the content safety, right?

397
00:25:36,770 --> 00:25:40,930
That's where, you could at least for now,
pick the default, because I'll talk about

398
00:25:40,930 --> 00:25:42,890
this, a little bit more towards the end.

399
00:25:43,790 --> 00:25:47,420
So you pick your model, use,
confirm some of the settings,

400
00:25:47,480 --> 00:25:48,710
and from there you're gonna.

401
00:25:48,740 --> 00:25:49,790
To run the deployment.

402
00:25:50,090 --> 00:25:51,260
So pretty easy.

403
00:25:51,260 --> 00:25:52,910
I would say pretty straightforward.

404
00:25:53,410 --> 00:25:57,750
Once we have a model deployed,
like in this case, we typically

405
00:25:57,750 --> 00:25:59,550
provide you some starting points.

406
00:25:59,580 --> 00:26:01,620
And again, we're targeting
developers, right?

407
00:26:02,100 --> 00:26:03,870
So what do you need here is.

408
00:26:04,745 --> 00:26:05,855
Azure credentials.

409
00:26:05,915 --> 00:26:09,905
Installing like Python example
in this case, and how to actually

410
00:26:09,905 --> 00:26:14,765
start testing, validating, and
it's almost literally copy pasting.

411
00:26:14,855 --> 00:26:17,755
If Python is your, language of choice.

412
00:26:17,905 --> 00:26:21,825
If you go oh, actually I want to use
another language, I'm gonna do C sharp,

413
00:26:21,855 --> 00:26:25,935
bam, within just a split second, it's
gonna give you the different steps,

414
00:26:25,965 --> 00:26:31,215
how to import the necessary packages.

415
00:26:31,255 --> 00:26:37,255
To install Azure AI and then obviously the
identity, and then from there, creating

416
00:26:38,095 --> 00:26:40,615
a point to your AI service endpoint.

417
00:26:40,975 --> 00:26:45,955
What's important here is the name of your
endpoint together with the deployment

418
00:26:46,045 --> 00:26:47,815
and the name of your deployment.

419
00:26:48,455 --> 00:26:50,885
And then you're gonna tune
your chat conversations.

420
00:26:50,915 --> 00:26:52,865
I'll talk about this
a little bit later on.

421
00:26:53,345 --> 00:26:58,115
And then if you want some additional
samples, how to interact with,

422
00:26:58,165 --> 00:27:01,505
conversational context, how
to keep the history and so on.

423
00:27:02,005 --> 00:27:07,585
Another angle to validate some
model information is now I

424
00:27:07,585 --> 00:27:09,655
moved from project into the hub.

425
00:27:10,345 --> 00:27:13,175
The way to deploy is obviously,
a hundred percent the same.

426
00:27:13,625 --> 00:27:18,325
So if I wanna search for LAMA
instead of using any of the

427
00:27:18,325 --> 00:27:19,940
pre-built categories and filters.

428
00:27:20,620 --> 00:27:23,330
You could now interact
with, any of these models.

429
00:27:23,780 --> 00:27:27,440
So the baseline is the same on the
hub level, on the project level,

430
00:27:27,500 --> 00:27:29,060
so nothing really different.

431
00:27:29,560 --> 00:27:34,810
Another scenario that I would like to
highlight here, this is the playground,

432
00:27:34,990 --> 00:27:39,380
but I'll talk about the playground,
a little bit later on, is inside.

433
00:27:39,575 --> 00:27:40,865
Our model catalog.

434
00:27:40,865 --> 00:27:44,525
From here, it's basically
giving you the exact same view.

435
00:27:44,885 --> 00:27:49,745
Now, where it is slightly different
is that again, here I'm inside the

436
00:27:49,745 --> 00:27:52,385
open AI service specific option.

437
00:27:52,895 --> 00:27:56,705
And again, I like to highlight that
it's all based on AI Foundry, but

438
00:27:56,705 --> 00:28:00,335
every now and then, depending on
the model you deploy, it might show

439
00:28:00,335 --> 00:28:02,595
you more or less, integrations.

440
00:28:03,435 --> 00:28:07,395
If I now move to another open model here.

441
00:28:07,895 --> 00:28:11,165
You can see that it also
allows me to deploy it.

442
00:28:11,195 --> 00:28:15,515
It still provides all those details,
but now I could also look into why

443
00:28:15,515 --> 00:28:20,765
should I maybe deploy this if one of my
colleagues already deployed this scenario?

444
00:28:21,305 --> 00:28:24,335
So giving you, again,
quite some, some options.

445
00:28:24,835 --> 00:28:27,895
Another question that we
sometimes get about the model

446
00:28:28,015 --> 00:28:31,105
is getting access to metrics.

447
00:28:31,135 --> 00:28:35,225
Now this is not showing you, like
specific details I would say about

448
00:28:35,225 --> 00:28:40,025
the model, but more about how your
applications, how your developers

449
00:28:40,265 --> 00:28:42,395
are using, targeting this model.

450
00:28:42,995 --> 00:28:46,955
I just deployed this without actually
having a sample app in the front

451
00:28:46,955 --> 00:28:50,615
of it, so that's why my metrics
are not really impressive, right?

452
00:28:50,885 --> 00:28:51,605
But it should give.

453
00:28:51,605 --> 00:28:55,625
You some idea that auditing
monitoring is also baked in.

454
00:28:56,345 --> 00:29:02,470
And then a bit on our Microsoft security
framework or the responsible AI framework.

455
00:29:02,470 --> 00:29:08,020
We have, since I deployed my model
using a default filter, it's already

456
00:29:08,020 --> 00:29:14,230
having, some content safety as
part of my language model baked in.

457
00:29:14,740 --> 00:29:18,040
And obviously for now, because I
didn't use it, there's no violations,

458
00:29:18,040 --> 00:29:19,780
there's no abusive use and so on.

459
00:29:20,280 --> 00:29:24,760
But again, giving you a pretty nice
idea about, what you could use it for.

460
00:29:25,260 --> 00:29:29,430
Another example I can show you
is using the model catalog.

461
00:29:29,490 --> 00:29:33,720
And again, this is the same catalog,
what I showed you before, it just giving

462
00:29:33,720 --> 00:29:35,430
you the full list and a different view.

463
00:29:36,180 --> 00:29:38,670
Why did I switch yet to another view?

464
00:29:38,820 --> 00:29:42,120
Because there's another question
that we can answer from here

465
00:29:42,270 --> 00:29:44,450
and that's what is, the model?

466
00:29:44,450 --> 00:29:48,200
Supposed to help me with, or
also answering the question,

467
00:29:48,530 --> 00:29:52,280
what model is better for a
specific purpose than another?

468
00:29:52,850 --> 00:29:56,240
Since I got deep seek up here,
I'm gonna check out that model.

469
00:29:56,570 --> 00:30:01,190
And same as before, providing
a description, but now it also

470
00:30:01,280 --> 00:30:03,770
gives me a link to benchmarks.

471
00:30:04,190 --> 00:30:07,730
So by design, what it's gonna do
is looking at, I would say its

472
00:30:07,730 --> 00:30:09,970
own, core competition, right?

473
00:30:10,540 --> 00:30:11,950
'cause as a developer.

474
00:30:12,580 --> 00:30:15,520
You need to think about all these
different language models, and I'm

475
00:30:15,520 --> 00:30:19,180
pretty sure that the conference sessions
will help you with a lot of this.

476
00:30:19,600 --> 00:30:22,990
But then within our AI Foundry,
knowing that you get access to

477
00:30:22,990 --> 00:30:28,580
more than, 1800, now, how do you
decide across those language models?

478
00:30:28,970 --> 00:30:32,270
So that's where now you can easily
select any of the models and

479
00:30:32,270 --> 00:30:33,950
there will always be benchmarking.

480
00:30:34,910 --> 00:30:39,530
In this case, it's comparing the deep
seek feed three that I selected with

481
00:30:39,530 --> 00:30:41,870
some of the other popular counterparts.

482
00:30:41,870 --> 00:30:46,850
Parts, but nothing blocks you
from also integrating a comparison

483
00:30:46,850 --> 00:30:50,810
that you can manage, that you
can tune with some other models.

484
00:30:51,310 --> 00:30:54,870
I think with that, you should have
a pretty good idea about, using

485
00:30:54,870 --> 00:30:59,490
different parts of the AI Foundry
portal, how to deploy the different

486
00:30:59,490 --> 00:31:05,700
models using open AI service, using
other services within the hub and

487
00:31:05,700 --> 00:31:07,710
project, and then also talked about.

488
00:31:08,085 --> 00:31:13,425
The higher level model, catalog,
and the benchmarking, so that, let's

489
00:31:13,425 --> 00:31:14,715
switch back to the presentation.

490
00:31:15,215 --> 00:31:15,755
Nice.

491
00:31:15,875 --> 00:31:20,045
So we're now at the point where we have
our large language models deployed.

492
00:31:20,105 --> 00:31:23,675
We did some benchmark testing
and I briefly talked about some

493
00:31:23,675 --> 00:31:26,985
other capabilities, like the
fine tuning I briefly touched on.

494
00:31:27,675 --> 00:31:30,075
So I can hear your next question already.

495
00:31:30,445 --> 00:31:30,925
coming up.

496
00:31:31,425 --> 00:31:31,965
okay.

497
00:31:32,055 --> 00:31:37,545
AI Foundry is the go-to portal I use for
generative AI with large language models.

498
00:31:37,695 --> 00:31:41,865
But what about all the other more
traditional AI services that we had

499
00:31:41,865 --> 00:31:43,575
in the Azure portal in the past?

500
00:31:44,145 --> 00:31:46,095
I would say that's
actually a great question.

501
00:31:46,545 --> 00:31:50,595
Now remember in the introduction
section we talked about the paradigm

502
00:31:50,595 --> 00:31:55,125
shift in application development
where customers and users somewhat

503
00:31:55,125 --> 00:31:57,315
expect to have AI capabilities.

504
00:31:57,570 --> 00:32:01,560
In basically any kind of application
they're building or using.

505
00:32:02,130 --> 00:32:06,840
While generative f AI seems to provide
a lot of those capabilities, all other

506
00:32:06,840 --> 00:32:12,180
AI services you might know from the
past existing in Azure already are now

507
00:32:12,180 --> 00:32:18,250
also gradually moving into AI Foundry
as that management, AI services portal.

508
00:32:18,750 --> 00:32:23,040
For example, AI search for architecture,
although I'll talk about that later on,

509
00:32:23,370 --> 00:32:28,790
but also talking about AI speech, AI
Vision, document intelligence, language

510
00:32:28,820 --> 00:32:33,890
translator, all those services have been
around in Azure for close to 10 years

511
00:32:34,100 --> 00:32:39,350
and can now gradually be integrated and
managed from within AI Foundry as well.

512
00:32:39,850 --> 00:32:45,240
Now the magic behind the scenes to
manage all this is Foundry playground.

513
00:32:45,780 --> 00:32:50,820
I already showed you a little bit
of this from within our AI Foundry

514
00:32:50,820 --> 00:32:55,110
portal, especially around a large
language model deployment, but there's

515
00:32:55,110 --> 00:32:57,030
actually a lot more you can do with it.

516
00:32:57,540 --> 00:32:59,295
I would say let's have another look.

517
00:32:59,795 --> 00:33:03,695
In this next demo, I'm gonna walk you
through AI Foundry, showing you some

518
00:33:03,695 --> 00:33:08,135
of the capabilities around playground,
allowing you to test and validate

519
00:33:08,135 --> 00:33:12,875
your models, and also switching to
some more traditional AI capabilities.

520
00:33:13,375 --> 00:33:13,645
Good.

521
00:33:13,825 --> 00:33:18,115
So we have our models deployed in the
previous part of the presentation,

522
00:33:18,595 --> 00:33:22,165
which now means that we're ready
to actually test and validate.

523
00:33:22,435 --> 00:33:26,455
So the way to do this is from
within once more AI Foundry,

524
00:33:26,955 --> 00:33:29,085
we're now selecting playgrounds.

525
00:33:29,115 --> 00:33:35,895
You could do this directly navigating
to ai.azure.com/playgrounds, and

526
00:33:35,895 --> 00:33:37,965
then it's gonna pull up your project.

527
00:33:37,995 --> 00:33:41,355
And allowing you to actually
build out your playgrounds.

528
00:33:41,895 --> 00:33:46,965
Remember, we're primarily focusing
on generative AI using chat co

529
00:33:47,325 --> 00:33:52,755
conversations, but remember that we
do have other AI services as well.

530
00:33:53,415 --> 00:33:58,195
So if you wanna integrate with like speech
or the newer agents based, like auto gen

531
00:33:58,195 --> 00:34:03,955
alike syns, or you wanna integrate with
like images using, for example, Dali or

532
00:34:03,955 --> 00:34:06,985
some other large language model using.

533
00:34:07,015 --> 00:34:08,065
Language playground.

534
00:34:08,095 --> 00:34:11,845
And again, there's so many different
ways to start testing interacting.

535
00:34:12,535 --> 00:34:15,955
The most obvious one is
using the chat playground.

536
00:34:16,615 --> 00:34:20,545
So in the previous part of the
demo, we deployed our GPT model

537
00:34:21,475 --> 00:34:23,275
as part of our hub and project.

538
00:34:23,275 --> 00:34:26,365
I got two of them linked
to different connectors.

539
00:34:26,425 --> 00:34:29,155
So again, emphasizing that all
those building blocks from the

540
00:34:29,155 --> 00:34:34,035
start are still nicely coming
back here, I could start easy.

541
00:34:34,155 --> 00:34:36,015
I got an AI assistant pretty.

542
00:34:36,165 --> 00:34:40,215
Generic message here, and I'm gonna
ask something like, what is the

543
00:34:40,215 --> 00:34:45,125
typical weather in Seattle mid-March?

544
00:34:45,625 --> 00:34:48,565
now it's nicely responding
in mid-March and so on.

545
00:34:48,565 --> 00:34:52,505
Obviously it's not about, the details,
although in a real life scenario, I

546
00:34:52,505 --> 00:34:57,665
would obviously encourage you to really
validate and verify the actual response.

547
00:34:58,235 --> 00:35:01,775
Now, again, based on your model, what
do we get as a confirmation here?

548
00:35:02,105 --> 00:35:05,885
Is that the model is working,
it is responding well.

549
00:35:05,885 --> 00:35:07,685
Now, if I would ask something like,

550
00:35:08,185 --> 00:35:11,095
can you provide Belgian food recipe?

551
00:35:11,095 --> 00:35:16,735
Remember my Belgian roots, it's gonna
come up with some ingredients, and again,

552
00:35:16,735 --> 00:35:18,805
it's still doing a pretty good job.

553
00:35:19,135 --> 00:35:19,765
Let's see.

554
00:35:19,795 --> 00:35:22,585
It came up with a, so mussels and fries.

555
00:35:22,585 --> 00:35:23,095
Perfect.

556
00:35:23,095 --> 00:35:24,595
Like a typical Belgian dish.

557
00:35:25,285 --> 00:35:28,585
It provides me the ingredients,
and next to that, it also provides.

558
00:35:28,795 --> 00:35:32,485
The instructions and I'm actually
getting a little bit hungry now out

559
00:35:32,485 --> 00:35:36,685
of that, but not there yet because I
need to show you a few other things.

560
00:35:37,405 --> 00:35:39,655
Now, back to our starting point.

561
00:35:40,645 --> 00:35:44,965
I got another project here, so
quickly switching where this time I

562
00:35:44,965 --> 00:35:47,005
got two different language models.

563
00:35:47,455 --> 00:35:52,435
Now remember, the language
model is trained on public data

564
00:35:52,525 --> 00:35:54,265
up to a certain point in time.

565
00:35:54,925 --> 00:35:55,525
Easy set.

566
00:35:55,615 --> 00:35:57,445
GPT-3 five is.

567
00:35:57,885 --> 00:36:00,435
Less up to date than GPT-4.

568
00:36:00,945 --> 00:36:06,705
An easy example I can use to
show you how this works is who

569
00:36:06,705 --> 00:36:10,055
is the Prime Minister of the uk?

570
00:36:10,555 --> 00:36:12,775
now it's gonna tell me based on a date.

571
00:36:12,775 --> 00:36:13,975
October 21.

572
00:36:14,275 --> 00:36:16,345
The Prime Minister is Boris Johnson.

573
00:36:16,910 --> 00:36:17,480
Pretty cool.

574
00:36:17,480 --> 00:36:18,470
I got my answer.

575
00:36:19,370 --> 00:36:25,700
Where now if I switch to my GPT-4 model
and I'm gonna run the same prompt,

576
00:36:26,510 --> 00:36:28,400
I'm just gonna copy it from here.

577
00:36:28,900 --> 00:36:32,140
You can see that now the
answer is different and not

578
00:36:32,140 --> 00:36:34,120
only different in context.

579
00:36:34,120 --> 00:36:36,295
Like the actual answer I would say is.

580
00:36:36,895 --> 00:36:41,125
More up to date, but also just
by switching the model, you can

581
00:36:41,125 --> 00:36:45,055
see that now I get access to
more tokens, a short answer, a

582
00:36:45,055 --> 00:36:47,215
pretty, little bit longer answer.

583
00:36:47,335 --> 00:36:50,965
And if you wanna tune all this a little
bit more, that's where you can go back

584
00:36:50,965 --> 00:36:53,075
to, the previous part of the demo.

585
00:36:53,125 --> 00:36:57,055
Another thing that's pretty
cool is interacting with what

586
00:36:57,055 --> 00:36:59,335
your chat actually can do.

587
00:36:59,755 --> 00:37:01,945
So right now I used an easy example.

588
00:37:02,275 --> 00:37:06,715
This could be used for I dunno, writing
an essay on UK politics or something.

589
00:37:06,955 --> 00:37:08,215
I don't know where.

590
00:37:08,215 --> 00:37:12,145
Now we could tune this a little
bit more, where I could do

591
00:37:12,145 --> 00:37:15,005
something like, you are, Microsoft.

592
00:37:15,875 --> 00:37:22,965
Technical trainer with
expertise in Azure and Azure ai.

593
00:37:23,465 --> 00:37:30,115
You can answer questions as long as
you keep it polite and professional.

594
00:37:30,115 --> 00:37:30,325
There we go.

595
00:37:30,825 --> 00:37:40,325
You cannot answer questions about
Amazon AWS or Google Cloud platform

596
00:37:40,825 --> 00:37:44,305
to apologize in those scenarios.

597
00:37:44,805 --> 00:37:50,265
Offer a Belgian beer
flavor to try out instead.

598
00:37:50,765 --> 00:37:54,245
So now what I'm doing here is
tweaking, fine tuning if you want.

599
00:37:54,755 --> 00:38:00,445
I use case where this could almost be like
a virtual Microsoft technical trainer.

600
00:38:01,045 --> 00:38:07,095
I'm gonna run a new chat conversation
and from here I could do, can you explain

601
00:38:07,095 --> 00:38:11,345
a bit about Azure Kubernetes service?

602
00:38:11,845 --> 00:38:15,775
So it comes back as expected
with a nice detailed prompt.

603
00:38:15,955 --> 00:38:20,485
I'm using GPT-4 oh latest version,
quite some tokens available in my

604
00:38:20,485 --> 00:38:30,075
subscription when Now from here I could
ask, what is the use case for AWS Beans

605
00:38:30,075 --> 00:38:33,435
stock, like an existing AWS service.

606
00:38:33,935 --> 00:38:36,005
When now it tells me like, oh, I'm sorry.

607
00:38:36,005 --> 00:38:38,585
So I asked it to be
professional and polite.

608
00:38:38,675 --> 00:38:41,235
I think that's, pretty well covered here.

609
00:38:41,735 --> 00:38:48,245
Unable to answer questions about AWS or
any other AWS service and then however.

610
00:38:48,430 --> 00:38:49,600
To make up for it.

611
00:38:49,660 --> 00:38:53,860
Again, being nice and professional,
I could recommend a Belgium beer.

612
00:38:54,580 --> 00:38:55,540
How cool is that?

613
00:38:55,660 --> 00:39:01,600
You can actually tune your environment,
your chat conversations, using by the

614
00:39:01,600 --> 00:39:04,510
way, what we call the system message.

615
00:39:04,930 --> 00:39:08,840
And then as a developer you
would integrate that, obviously

616
00:39:08,840 --> 00:39:10,400
as part of your code as well.

617
00:39:10,760 --> 00:39:14,180
And then allowing the chat
conversations, going back and forth.

618
00:39:14,960 --> 00:39:15,920
So that's pretty much it.

619
00:39:16,160 --> 00:39:17,810
Out of this demo showed you.

620
00:39:17,930 --> 00:39:22,790
How to interact with the playground,
specifically this one for chat or

621
00:39:22,790 --> 00:39:26,600
going back to the previous part of
the demo where you can choose across

622
00:39:26,600 --> 00:39:31,880
different playgrounds depending on use
cases for images, integrating audio,

623
00:39:31,880 --> 00:39:36,730
integrating other, assistant alike
scenarios back to the presentation.

624
00:39:37,230 --> 00:39:37,650
Sweet.

625
00:39:37,920 --> 00:39:42,450
This brings me to the last topic in
today's session covering rag architecture

626
00:39:42,510 --> 00:39:45,000
or retrieval augmented generation.

627
00:39:45,500 --> 00:39:48,560
Now, we heavily discussed large
language models and how they

628
00:39:48,560 --> 00:39:51,950
enrich your applications with
generative AI capabilities.

629
00:39:52,145 --> 00:39:56,225
For example, conversational
context, natural language,

630
00:39:56,285 --> 00:39:58,325
and primarily chat driven.

631
00:39:58,985 --> 00:40:03,755
One main characteristic for most LMS
is that they're trained using public

632
00:40:03,755 --> 00:40:08,405
internet data, which obviously is
totally fine, but what if your app

633
00:40:08,405 --> 00:40:13,745
needs to know about your organizational
data specifically, or your customer?

634
00:40:13,745 --> 00:40:18,455
Your user can only use internal
company specific information, not

635
00:40:18,455 --> 00:40:20,675
using the context from public models.

636
00:40:21,450 --> 00:40:26,220
That's exactly what RAG or retrieval
augmented Generation is about.

637
00:40:26,850 --> 00:40:30,930
Starting from a large language model
approach, you are now augmenting

638
00:40:30,990 --> 00:40:37,770
enriching if you want the dataset your AI
application is using within your own data.

639
00:40:38,405 --> 00:40:43,085
Which can be images, documents,
knowledge bases, and they can be

640
00:40:43,145 --> 00:40:44,945
stored within the Azure backend.

641
00:40:45,445 --> 00:40:47,245
And that's really the next step, right?

642
00:40:47,305 --> 00:40:50,485
So if you are wondering like
where does this data come from,

643
00:40:50,485 --> 00:40:52,615
like how do I integrate it?

644
00:40:52,885 --> 00:40:54,385
There's a lot of different options.

645
00:40:54,655 --> 00:40:58,405
So the easiest one I would say
is using Azure blob storage.

646
00:40:58,650 --> 00:41:01,260
But nothing blocks you from
integrating with, for example,

647
00:41:01,260 --> 00:41:03,330
Amazon S3 buckets as well.

648
00:41:03,990 --> 00:41:08,010
And yes, I can show you also how
to upload files manually in the

649
00:41:08,010 --> 00:41:10,830
Azure portal, although I don't
think it's like an enterprise

650
00:41:10,860 --> 00:41:12,450
recommended approach to do that.

651
00:41:12,950 --> 00:41:17,810
The backend interaction happens
out of Azure AI search, building up

652
00:41:17,810 --> 00:41:21,770
what we call vector information for
each and every of your data sets.

653
00:41:22,250 --> 00:41:27,650
And then once the indexing is done, your
AI application will be able to respond to

654
00:41:27,650 --> 00:41:32,420
prompts in the same way you expect from
your large language model, but now using

655
00:41:32,420 --> 00:41:34,820
knowledge coming in from your own data.

656
00:41:35,320 --> 00:41:39,550
And you can expect it also brings me
to the last demo here, showing you

657
00:41:39,580 --> 00:41:44,530
what this rag architecture looks like
and how to use it from within ai.

658
00:41:45,030 --> 00:41:49,070
So regarding the, rag architecture,
the main idea we wanna do from

659
00:41:49,070 --> 00:41:53,120
here, and again, I'm just using
the playground again, is importing

660
00:41:53,120 --> 00:41:55,790
or linking it to our custom data.

661
00:41:56,360 --> 00:42:00,370
So I'm, inside my project and I'm gonna.

662
00:42:00,520 --> 00:42:05,760
Select here a new section where I
could define other system messages, but

663
00:42:05,970 --> 00:42:08,130
that's not specifically to re anymore.

664
00:42:08,490 --> 00:42:12,630
So we're shifting down to the next
section, and that's using your own data.

665
00:42:13,130 --> 00:42:18,380
We can add new data sources and for
now, I'll make it a little bit bigger.

666
00:42:19,070 --> 00:42:23,780
You can choose from any of these using
Azure AI search a service that's been

667
00:42:23,780 --> 00:42:28,760
around in the platform for a couple of
years already and now nicely integrating.

668
00:42:29,060 --> 00:42:35,120
With, the generative AI capabilities of
what an AI solution is, offering today

669
00:42:35,870 --> 00:42:41,390
Azure blob storage, where obviously
the idea is to have your data sets

670
00:42:41,420 --> 00:42:45,850
like, PDF documents, images, word
files, any other text files, json

671
00:42:46,000 --> 00:42:48,850
alike scenarios in Azure blob storage.

672
00:42:48,970 --> 00:42:53,260
Remember, you could link this to your
hub and project, making sure that not.

673
00:42:53,800 --> 00:42:56,050
Everyone needs access to the blob storage.

674
00:42:56,500 --> 00:43:02,020
I would also recommend using, role-based
access, preferably managed identities

675
00:43:02,380 --> 00:43:04,480
to interact with those data endpoints.

676
00:43:04,980 --> 00:43:09,840
Azure Cosmos database, our non-relational
database here, which could be a

677
00:43:09,840 --> 00:43:15,070
perfect, data set or database endpoint
interacting with elastic search.

678
00:43:15,100 --> 00:43:18,670
If you want, you could straight
point to your web address

679
00:43:19,120 --> 00:43:21,530
connecting to, a knowledge base.

680
00:43:21,890 --> 00:43:27,300
Website, intranet, maybe SharePoint
alike scenario, or, why not uploading

681
00:43:27,300 --> 00:43:31,560
files and then still allowing
you to turn them into an index.

682
00:43:32,130 --> 00:43:33,420
So quite some options.

683
00:43:33,450 --> 00:43:36,660
So imagine we are gonna
go for blob storage.

684
00:43:36,720 --> 00:43:42,000
You need to identify your
subscription, the storage container,

685
00:43:42,060 --> 00:43:43,590
the BLO storage, obviously.

686
00:43:43,650 --> 00:43:50,280
And then if you wanna use a specific Azure
search, you're gonna define the index.

687
00:43:50,310 --> 00:43:51,030
And then from there.

688
00:43:51,510 --> 00:43:57,660
How frequently is my information
changing, which influences my index?

689
00:43:58,410 --> 00:44:00,360
So from here, pretty straightforward.

690
00:44:00,840 --> 00:44:04,290
You point to the data endpoints
and that's pretty much it.

691
00:44:04,950 --> 00:44:09,780
If I switch here to uploading files,
it's still gonna ask for storage.

692
00:44:09,810 --> 00:44:14,160
So you still need to have that storage
background where now it's gonna enable

693
00:44:14,160 --> 00:44:20,740
cross, origin to allow me to interact from
my AI service here, my playground into.

694
00:44:21,730 --> 00:44:26,800
My, blob storage container, I would
still need to identify the index,

695
00:44:26,800 --> 00:44:29,830
so this could be the live PDT index,

696
00:44:30,330 --> 00:44:36,030
where now I can basically from here start
uploading my files like a Word document.

697
00:44:36,530 --> 00:44:41,330
Where for some reason it didn't pick
up my REC that I specified like a

698
00:44:41,330 --> 00:44:45,530
few minutes before the recording,
so I'm gonna save this for now.

699
00:44:45,980 --> 00:44:49,760
But you probably get the idea, and again,
most probably you're not gonna do this

700
00:44:49,760 --> 00:44:54,950
from here 'cause you're gonna ask your
data team, your data admins, your data

701
00:44:54,950 --> 00:45:01,550
scientists, maybe to upload the data in
the Azure storage or in a Cosmos database.

702
00:45:02,305 --> 00:45:06,505
But then the way to interact with it
from here would be basically the same.

703
00:45:07,465 --> 00:45:10,195
That's, I would say mainly
what I wanted to show you.

704
00:45:10,645 --> 00:45:16,555
Different capabilities, different
ways to interact your GPT alike

705
00:45:16,555 --> 00:45:21,265
scenario, at least in this case,
your overall AI inspired scenarios.

706
00:45:21,765 --> 00:45:25,880
Instead of just using the large
language model, how to interact with

707
00:45:25,880 --> 00:45:30,080
your own custom data, where again,
you got a multitude of sources.

708
00:45:30,990 --> 00:45:34,950
I am close to running out of time, so
I guess I'm gonna switch back to the

709
00:45:34,950 --> 00:45:39,920
presentation for the last couple of words
before closing the session boundary.

710
00:45:40,420 --> 00:45:44,950
Now, before we wrap it up here, I wanted
to highlight one other actually crucial

711
00:45:44,950 --> 00:45:47,170
aspect in developing AI solutions.

712
00:45:47,510 --> 00:45:50,390
And that's our Microsoft
responsible AI framework.

713
00:45:51,050 --> 00:45:55,370
In short, we keep responsibility
high across all levels of our

714
00:45:55,370 --> 00:45:59,930
AI development cycle and also
in our AI and copilot solutions.

715
00:46:00,740 --> 00:46:03,470
Now, for example, we
don't train on your data.

716
00:46:04,130 --> 00:46:08,450
We also do not use your prompts to
train the models, and eventually

717
00:46:08,450 --> 00:46:10,520
your data remains your data.

718
00:46:11,020 --> 00:46:15,430
Specifically within AI Foundry, you
can manage an integration with our

719
00:46:15,430 --> 00:46:20,800
responsible framework out of Azure
AI content safety, which is, robust,

720
00:46:20,830 --> 00:46:23,230
safe content moderation platform.

721
00:46:23,590 --> 00:46:30,230
Leveraging AI to ensure that whatever
you are building keeps safety, in mind,

722
00:46:30,560 --> 00:46:32,960
and also enhances user experiences.

723
00:46:33,530 --> 00:46:36,680
It integrates with a lot
of powerful AI models.

724
00:46:36,965 --> 00:46:41,135
Allowing you to detect, but also
eliminate inappropriate content.

725
00:46:41,285 --> 00:46:46,805
For example, hateful, sexual, violent,
or self-harm inducing responses.

726
00:46:47,555 --> 00:46:53,225
Using filters and safety thresholds,
organizations can tailor content safety

727
00:46:53,225 --> 00:46:57,845
measures to, again, make sure that once
the application goes live, a lot of the

728
00:46:57,845 --> 00:47:00,215
safety measures are already in place.

729
00:47:00,715 --> 00:47:05,365
This brings me to the end of this session
where I would like to highlight several

730
00:47:05,365 --> 00:47:11,425
of our top use cases for Azure AI Foundry,
starting from deploying your Azure AI

731
00:47:11,425 --> 00:47:14,365
services and AI foundry hubs and projects.

732
00:47:14,425 --> 00:47:16,705
Starting the development
project governance.

733
00:47:17,155 --> 00:47:20,785
You would use AI Foundry to
deploy, test, validate your

734
00:47:20,785 --> 00:47:22,495
large language models of choice.

735
00:47:23,185 --> 00:47:26,595
From there, you're gonna primarily
use it, out of the playground that

736
00:47:26,595 --> 00:47:27,945
I talked about and showed you.

737
00:47:28,285 --> 00:47:33,355
To validate the models, configure system
messages, validate your prompt responses,

738
00:47:33,595 --> 00:47:37,975
and then last fine tuning the model,
and then obviously integrating your

739
00:47:37,975 --> 00:47:40,825
safety net, your responsible AI as well.

740
00:47:41,325 --> 00:47:45,285
I hope with this session I managed to walk
you through a sneak peek of what Azure

741
00:47:45,285 --> 00:47:51,615
AI services using AI Foundry can do for
your organizations, especially when you

742
00:47:51,615 --> 00:47:55,905
are thinking about developing your own
custom co-pilots, as we like to call it.

743
00:47:56,405 --> 00:47:58,835
I wanna thank you for having
joined me in this session.

744
00:47:59,105 --> 00:48:03,065
I also would like to thank the com
42 team for having invited me as a

745
00:48:03,065 --> 00:48:05,465
speaker to present at this conference.

746
00:48:06,065 --> 00:48:10,025
I hope you enjoyed the rest of com
42 large language model conference

747
00:48:10,355 --> 00:48:14,075
and hopefully we'll meet again
soon in any of the other com 42

748
00:48:14,225 --> 00:48:15,965
conferences in the near future.

749
00:48:16,595 --> 00:48:17,435
Take care for now.

750
00:48:17,435 --> 00:48:20,375
Have a great day and don't
hesitate reaching out if you

751
00:48:20,375 --> 00:48:21,755
should have any more questions.

752
00:48:22,385 --> 00:48:23,165
Take care my friends.

