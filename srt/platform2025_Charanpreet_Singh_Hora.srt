1
00:00:00,900 --> 00:00:02,170
Hello all welcome.

2
00:00:02,800 --> 00:00:04,750
This is Sharon ING Hora.

3
00:00:04,990 --> 00:00:07,149
I'm going to talk on Platform First.

4
00:00:07,149 --> 00:00:08,290
Mobile Automation.

5
00:00:08,929 --> 00:00:11,749
I have around 20 plus years of experience.

6
00:00:11,929 --> 00:00:17,180
I'm working with Cognizant Technology
Solution, and I am in two 10 plus years

7
00:00:17,299 --> 00:00:22,580
with mobile automation with on different
cloud platforms like cts, perfecto.

8
00:00:22,984 --> 00:00:25,924
And browser stack and mobile device.

9
00:00:26,494 --> 00:00:30,905
I'm available on LinkedIn for any
if we want to discuss more on this.

10
00:00:31,444 --> 00:00:35,405
So I'm working with, mobile
Cloud plus AI as well.

11
00:00:35,405 --> 00:00:37,684
So I thought of, presenting this PPT.

12
00:00:38,495 --> 00:00:40,235
So yes, let's get started.

13
00:00:40,324 --> 00:00:44,945
Platform first, mobile automation
engineering, t testing infrastructure

14
00:00:44,945 --> 00:00:46,475
across enterprise ecosystem.

15
00:00:47,044 --> 00:00:50,945
A technical exploration of how platform
engineering principle transform

16
00:00:50,945 --> 00:00:55,415
mobile automation from isolated
QA process into integrated cell

17
00:00:55,415 --> 00:00:59,404
service infrastructure that scales
across multiple cloud environments

18
00:00:59,764 --> 00:01:02,044
and diverse development teams.

19
00:01:02,495 --> 00:01:07,370
As we as per the first slide platform,
first mobile automation, we are talking

20
00:01:07,370 --> 00:01:12,680
about the t testing infrastructure across
the various, enterprise ecosystems.

21
00:01:13,180 --> 00:01:14,860
The platform engineering revolution.

22
00:01:15,340 --> 00:01:19,460
So modern enterprise face complex
mobile testing challenges nowadays.

23
00:01:19,590 --> 00:01:23,100
We are doing mobile automation, but
we are very complex infrastructure,

24
00:01:23,600 --> 00:01:27,380
multiple device ecosystems, diverse
operating systems, versions,

25
00:01:27,380 --> 00:01:30,920
varying network conditions, and
continuous delivery at a scale.

26
00:01:31,490 --> 00:01:35,410
So basically, we have various
ecosystems of, available right now.

27
00:01:35,920 --> 00:01:39,340
And we have diverse operating
systems like in iOS and Android.

28
00:01:39,340 --> 00:01:43,880
If you see every month we have new
releases, we have new devices different

29
00:01:43,880 --> 00:01:46,399
type of versions, upgrades, right?

30
00:01:46,429 --> 00:01:49,880
And there are various network
conditions also associated with it.

31
00:01:49,940 --> 00:01:54,440
A lot of complexity right now testing
with mobile devices and we have, native

32
00:01:54,440 --> 00:01:59,879
apps or reactive web based we have
to validate test in mobile devices.

33
00:02:00,029 --> 00:02:01,529
It's very complex nowadays.

34
00:02:02,174 --> 00:02:03,854
And continuous delivery at a scale.

35
00:02:03,884 --> 00:02:07,855
Traditional approaches with, siloed
QA teams manual infrastructure

36
00:02:07,855 --> 00:02:10,705
management can't keep pace
with these demands right now.

37
00:02:11,405 --> 00:02:13,085
Yes, it is very difficult.

38
00:02:13,085 --> 00:02:15,695
You cannot buy each and every device.

39
00:02:15,725 --> 00:02:17,615
You need some type of solution.

40
00:02:17,615 --> 00:02:21,965
Where devices are available on
demand as and when need is there.

41
00:02:22,394 --> 00:02:26,435
For this platform engineering reemergence,
mobile automations product, platform

42
00:02:26,435 --> 00:02:30,005
engineering, obviously, they think,
this is just not a mobile automation.

43
00:02:30,055 --> 00:02:33,775
It's a mobile, it's a product
rather than a service.

44
00:02:33,925 --> 00:02:34,345
Okay?

45
00:02:34,345 --> 00:02:38,015
It's altogether different product
because it's a big elephant nowadays

46
00:02:38,015 --> 00:02:41,614
because everybody's using smart
phones, mobile devices, iOS or Android.

47
00:02:42,114 --> 00:02:46,784
So it's creating a self-service, API
driven system that empower development

48
00:02:46,784 --> 00:02:50,774
teams while maintaining enterprise
grade reliability and governance.

49
00:02:51,284 --> 00:02:55,094
So basically, it is API driven
and it maintains enterprise

50
00:02:55,094 --> 00:02:56,864
grade reliability and governance.

51
00:02:56,864 --> 00:03:00,834
It is secured by government is
monitoring all those, policies,

52
00:03:00,834 --> 00:03:02,184
compliance, and all those things.

53
00:03:02,544 --> 00:03:05,579
Organizations implementing platform
first, mobile automation report.

54
00:03:06,214 --> 00:03:10,414
Dramatic improvement in deployment,
confidence reduced time to market, enhance

55
00:03:10,414 --> 00:03:12,994
ability to response to market changes.

56
00:03:13,534 --> 00:03:17,785
So yes, as you see it has dramatic
improvements in deployment,

57
00:03:17,785 --> 00:03:22,035
confi aggressions, reduced time
to market, and all those factors

58
00:03:22,185 --> 00:03:23,895
which are associated with this.

59
00:03:24,395 --> 00:03:26,765
Now we talk about
architectural foundations.

60
00:03:27,155 --> 00:03:29,495
So what are these
architectural foundations like?

61
00:03:29,495 --> 00:03:30,920
It is infrastructure S code.

62
00:03:31,325 --> 00:03:35,405
GI tops driven deployments
like CICD, vvc, right?

63
00:03:35,435 --> 00:03:40,385
We have GitLab, GitHubs multi-tenant
architecture as such, right?

64
00:03:40,385 --> 00:03:41,915
So what is infrastructure as code?

65
00:03:42,305 --> 00:03:46,155
It is a modern platform engineering
trade mobile testing, infrastructure

66
00:03:46,275 --> 00:03:51,060
code, eliminating environment drift, and
ensuring reproducible test conditions.

67
00:03:51,825 --> 00:03:56,265
So like we have Terraform Polo
or AWS, we have Azure also.

68
00:03:56,770 --> 00:03:58,150
Google Cloud also, right?

69
00:03:58,210 --> 00:04:01,650
This defines environment spanning
multiple cloud providers.

70
00:04:02,189 --> 00:04:06,480
We, this use YML adjacent
configuration files automatically

71
00:04:06,480 --> 00:04:08,489
provides appropriate resources.

72
00:04:09,150 --> 00:04:12,869
Kubernetes provides runtime foundation,
which isolated secure containers.

73
00:04:12,869 --> 00:04:17,749
So yes, we have Kubernetes which works
on, secure containers containerized

74
00:04:17,749 --> 00:04:18,829
approach using Kubernetes.

75
00:04:19,714 --> 00:04:22,764
So we have now we will talk
about GitHub's driven deployment.

76
00:04:22,794 --> 00:04:26,364
Like we have testing configurations,
automation scripts and infrastructure

77
00:04:26,364 --> 00:04:30,994
definitions resides in gate repositories,
enabling version control, peer review,

78
00:04:30,994 --> 00:04:32,824
and automated deployment workflows.

79
00:04:33,434 --> 00:04:37,819
This will change follow same rigorous
process as application code staging

80
00:04:37,819 --> 00:04:39,179
environments to receive updates.

81
00:04:39,189 --> 00:04:43,339
First for validation, progressive
delivery patterns, roll out new

82
00:04:43,339 --> 00:04:44,779
testing capabilities gradually.

83
00:04:45,279 --> 00:04:49,629
Then we are multi-tenant architecture,
enterprise platform support, multi

84
00:04:49,629 --> 00:04:53,219
development teams while maintaining
strict security boundaries through

85
00:04:53,219 --> 00:04:54,929
isolated testing environments.

86
00:04:55,409 --> 00:05:00,299
Network segmentation ensures sensitive
testing data remains isolated.

87
00:05:00,449 --> 00:05:05,399
Each tenant receives dedicated namespace
resource quotas and access controls.

88
00:05:05,909 --> 00:05:08,759
And also it has role-based
access controls, integrates with

89
00:05:08,819 --> 00:05:11,309
enterprise direct directories.

90
00:05:11,789 --> 00:05:14,969
So basically, we are multi-tenant
architecture where we are using,

91
00:05:14,969 --> 00:05:16,379
cloud-based infrastructure.

92
00:05:16,379 --> 00:05:20,069
Might be A-W-S-G-C-P,
Google Cloud, or Azure.

93
00:05:20,339 --> 00:05:26,804
So it is very secured and network segment
is, segmentation basically, which ensures

94
00:05:26,894 --> 00:05:28,934
your data is secured enough, right?

95
00:05:28,964 --> 00:05:32,924
And it has role-based access
controls by default, it is denied.

96
00:05:32,984 --> 00:05:36,874
So if you have a role, it will be
given the access, like that in cloud.

97
00:05:36,934 --> 00:05:37,744
This is how it works.

98
00:05:38,569 --> 00:05:41,449
Now we'll talk about AI
enhance resource orchestration.

99
00:05:42,319 --> 00:05:46,489
So we have modern platform engineering
incorporates artificial intelligence

100
00:05:46,489 --> 00:05:50,899
to optimize mobile testing, resource
allocation, machine learning algorithms,

101
00:05:50,899 --> 00:05:52,519
analyze historical testing patterns.

102
00:05:53,239 --> 00:05:57,169
Predictive models consider application
release schedules, test execution

103
00:05:57,169 --> 00:06:01,299
times seasonal traffic patterns
and team productivity cycles.

104
00:06:01,799 --> 00:06:06,479
Intelligent test selection algorithms
identify minimum test suit required

105
00:06:06,479 --> 00:06:08,519
to validate specific changes.

106
00:06:08,939 --> 00:06:13,049
So basically what we are trying to
say here is AI is basically machine

107
00:06:13,049 --> 00:06:16,799
learning algorithms are there, which
will analyze historical testing patterns.

108
00:06:17,429 --> 00:06:21,329
So we have a lot of data from the
past, which is getting analyzed by, AI

109
00:06:21,359 --> 00:06:26,669
LLMs or machine learning algorithms,
which will, which is a key for the

110
00:06:26,849 --> 00:06:29,849
pattern testing and predictive model.

111
00:06:29,909 --> 00:06:31,859
Consider application releases schedule.

112
00:06:31,859 --> 00:06:36,274
So basically all the LLMs, ai, lms,
or, predictive models are there.

113
00:06:36,769 --> 00:06:41,889
Which are based on heavy data from the
past years which will predict, which will

114
00:06:41,889 --> 00:06:46,299
release the schedules, execution times,
and team productivity cycles as well.

115
00:06:46,899 --> 00:06:50,019
Now we'll talk about intelligent
test selection algorithms.

116
00:06:50,019 --> 00:06:54,189
Identify minimum tests suit required
to validate specific changes as such.

117
00:06:54,889 --> 00:06:58,909
Because of this, machine learning, we have
intelligent test selection algorithms are.

118
00:06:59,494 --> 00:07:04,664
Built in over the years which will
help us to minimize the test suit

119
00:07:04,664 --> 00:07:06,644
required to validate specific changes.

120
00:07:06,644 --> 00:07:11,064
So all the critical flows are
tested using, these intelligent

121
00:07:11,064 --> 00:07:12,474
test selection algorithms.

122
00:07:12,894 --> 00:07:16,944
These proactive approach eliminates
resource contention while minimizing

123
00:07:16,949 --> 00:07:21,654
cloud computing costs, ensuring adequate
testing capacity during peak demand,

124
00:07:21,654 --> 00:07:23,724
while avoiding over provisioning during.

125
00:07:24,224 --> 00:07:26,354
Quite periods, yes.

126
00:07:26,354 --> 00:07:30,804
So this will very cost effective
because this is on demand cloud and

127
00:07:30,804 --> 00:07:32,424
resources we are using on demand.

128
00:07:32,424 --> 00:07:33,744
This is a proactive approach.

129
00:07:33,744 --> 00:07:39,024
So that is why, AI and Cloud helps a
lot for cost reduction for the company.

130
00:07:39,524 --> 00:07:43,274
Now we will talk about some,
cross-platform compatibility, automation.

131
00:07:43,904 --> 00:07:46,274
What is this comprehensive
device mattresses.

132
00:07:47,234 --> 00:07:50,774
And beyond functional testing
and global device forms, what is

133
00:07:50,774 --> 00:07:52,424
comprehensive device mattresses?

134
00:07:52,484 --> 00:07:56,804
It is a sophisticated platform
maintain which maintains devices,

135
00:07:56,804 --> 00:08:00,554
mattresses, spanning iOS, android,
and imaging platforms automatically

136
00:08:00,554 --> 00:08:05,474
executing test suits across
representative device combinations.

137
00:08:05,474 --> 00:08:09,834
So basically it's a mechanism which
will have the mattresses which will span

138
00:08:10,044 --> 00:08:12,684
across the platforms like iOS, Android.

139
00:08:13,374 --> 00:08:18,584
And which will execute test suits
across represented device combinations

140
00:08:19,364 --> 00:08:21,074
on various device combinations.

141
00:08:21,074 --> 00:08:24,344
It is going to, execute all
the test suits, excuse me.

142
00:08:24,344 --> 00:08:28,189
And it'll also beyond functional
testing, compatibility testing,

143
00:08:28,189 --> 00:08:30,229
access to performance accessibility.

144
00:08:30,559 --> 00:08:33,819
So basically we are talking about
not only functional testing, we are

145
00:08:33,819 --> 00:08:35,289
talking about performance accessibility.

146
00:08:35,889 --> 00:08:38,439
And user experience
consistency testing as well.

147
00:08:38,469 --> 00:08:43,939
It is automated with visual regression
which detects UI in across devices.

148
00:08:43,939 --> 00:08:46,399
Devices are of, various
sizes and shapes, right?

149
00:08:46,399 --> 00:08:50,179
We can easily, if they're UI
insistency, which we can identify

150
00:08:50,299 --> 00:08:51,499
very easily using regress.

151
00:08:52,084 --> 00:08:54,064
Across the devices, across the platforms.

152
00:08:54,764 --> 00:08:58,414
We have, global device forms
cloud platforms are available,

153
00:08:58,414 --> 00:09:02,584
like c test, which, have multiple
physical devices, perfecto.

154
00:09:02,614 --> 00:09:06,934
Or we can talk about mobile
device labs or browser stack.

155
00:09:06,984 --> 00:09:10,494
This will be having real devices
as well as emulators, which will

156
00:09:10,494 --> 00:09:15,074
enable testing across various network
condition and regional configurations.

157
00:09:15,074 --> 00:09:18,074
So based on regions, we
can select these devices.

158
00:09:18,564 --> 00:09:22,704
Suppose I'm in us, I want to select,
devices in Australia because I

159
00:09:22,704 --> 00:09:23,814
have a customer in Australia.

160
00:09:23,814 --> 00:09:26,574
I want to see the latency,
network speed and everything.

161
00:09:27,114 --> 00:09:30,444
So using these, cloud provider
providers, I can select the region

162
00:09:30,534 --> 00:09:32,214
and we can test accordingly.

163
00:09:32,574 --> 00:09:36,414
And that will let us know what is
going on with that region, devices,

164
00:09:36,414 --> 00:09:38,034
or are we facing any issues.

165
00:09:38,604 --> 00:09:41,844
So this platform orchestration,
manage device allocations, test

166
00:09:41,844 --> 00:09:43,614
scheduling result aggregation.

167
00:09:44,194 --> 00:09:48,244
Presenting unified compatibility
reports to development teams as such.

168
00:09:48,904 --> 00:09:52,804
So this is the platform orchestration
teams, which manages all these,

169
00:09:52,804 --> 00:09:55,674
devices, allocations test scheduling.

170
00:09:55,734 --> 00:09:59,064
This is on the orchestration
layer of the platform, basically.

171
00:09:59,994 --> 00:10:02,604
Now we'll talk about progressive
delivery integration.

172
00:10:02,755 --> 00:10:03,385
So what is it?

173
00:10:03,505 --> 00:10:07,314
It's a feature flag integration,
candidate deployment testing

174
00:10:07,405 --> 00:10:08,694
automated roll back triggers.

175
00:10:08,724 --> 00:10:11,484
What is feature flag integration
like to suppose, example.

176
00:10:12,040 --> 00:10:14,790
You are going to deliver
new code in production.

177
00:10:14,839 --> 00:10:15,724
And it's a very.

178
00:10:16,574 --> 00:10:17,505
New functionality.

179
00:10:17,535 --> 00:10:22,084
So now what you will do is you'll
slowly throttle that in production in

180
00:10:22,084 --> 00:10:28,204
Android or iOS platforms, like 1%, 2%
in first few days based on the feedback.

181
00:10:28,305 --> 00:10:32,795
Then you will enable that feature
flag for, 15%, 20%, and within

182
00:10:32,795 --> 00:10:35,705
couple of months you will be a
hundred percent throttling that.

183
00:10:35,705 --> 00:10:37,745
So that is called
feature flag integration.

184
00:10:38,345 --> 00:10:40,265
Then we have candid
deployment testing, right?

185
00:10:40,295 --> 00:10:40,895
What is it?

186
00:10:40,925 --> 00:10:46,355
It's automatically compares mattresses
between control and experimental groups.

187
00:10:46,415 --> 00:10:50,045
Detecting performance regression
crash rates, increase our

188
00:10:50,045 --> 00:10:52,265
user experience degradation.

189
00:10:52,265 --> 00:10:54,515
So basically what it is
doing, it just perform.

190
00:10:54,954 --> 00:10:59,854
It's, it provides the mattresses ex on
the experiments detecting performance

191
00:10:59,854 --> 00:11:05,304
regression crash rate, increase or
user experience degradations as well.

192
00:11:06,054 --> 00:11:08,904
Now we'll talk about
automated rollback triggers.

193
00:11:08,904 --> 00:11:11,694
As such, respond to testing
failures or metrics.

194
00:11:11,694 --> 00:11:16,164
Degradation instantly reverting
problematic changes to protect

195
00:11:16,435 --> 00:11:21,094
user experience while enabling
aggregative innovation cycles.

196
00:11:21,379 --> 00:11:23,239
So we are talking about
automated rollbacks.

197
00:11:23,239 --> 00:11:27,120
Say for example, if I am deploying
some new code in productions

198
00:11:27,170 --> 00:11:29,030
something happens, right?

199
00:11:29,030 --> 00:11:33,199
Something network problem, some code is
not working or something fails, right?

200
00:11:33,709 --> 00:11:37,000
So there should be automated
rollback mechanism, right?

201
00:11:37,060 --> 00:11:39,034
Which we say disaster recovery, right?

202
00:11:39,034 --> 00:11:42,629
So we can make sure, we are on the
original state, previous, original state.

203
00:11:43,444 --> 00:11:45,934
This is how this automated
rollback triggers.

204
00:11:45,934 --> 00:11:50,104
Basically, this is for the
progressive delivery integration.

205
00:11:50,194 --> 00:11:52,744
Three factors are there, as we discussed.

206
00:11:52,744 --> 00:11:55,774
So these systems basically, balance
the risk and velocity in mobile

207
00:11:55,774 --> 00:11:59,014
application development, providing
confidence data that informs

208
00:11:59,014 --> 00:12:01,084
rollout decision at each stage.

209
00:12:01,334 --> 00:12:04,874
Yes, this will, make sure every
stage we are getting the correct

210
00:12:04,874 --> 00:12:09,214
information based on these flags,
deployments, or rollback triggers.

211
00:12:09,714 --> 00:12:14,544
Now we talk about, industry applications
financial services, what is it?

212
00:12:14,604 --> 00:12:15,984
Compliance driven automation.

213
00:12:15,984 --> 00:12:20,174
So in financial sector, a data, PCI
compliance data is very important.

214
00:12:20,174 --> 00:12:21,854
You cannot share data like that.

215
00:12:22,214 --> 00:12:27,229
It should be compliant, mask, and,
otherwise company or financial

216
00:12:27,229 --> 00:12:29,209
organization might face a lot of issues.

217
00:12:29,704 --> 00:12:33,814
Or people can sue if financial data
is shared or there are some losses.

218
00:12:34,294 --> 00:12:37,924
So what we are saying is financial
service organizations face unique mobile

219
00:12:37,924 --> 00:12:41,764
testing challenges due to stick regulatory
requirements and security constraints.

220
00:12:42,484 --> 00:12:44,434
Platform engineering
addresses these through.

221
00:12:44,494 --> 00:12:49,244
So basically, financial organization
has to be PCI compliant.

222
00:12:49,274 --> 00:12:51,464
It should not share the data like that.

223
00:12:51,464 --> 00:12:54,314
It's a very secured industry, we can say.

224
00:12:54,854 --> 00:12:57,794
So how platform engineering
address these issues through

225
00:12:57,794 --> 00:12:59,234
automated compliance testing.

226
00:12:59,234 --> 00:13:04,574
So yes, P-C-I-D-S-S, SOCs and Regional
Banking regulations are there, right?

227
00:13:04,604 --> 00:13:05,954
Which is automated.

228
00:13:06,384 --> 00:13:08,275
So that, manual you might.

229
00:13:08,540 --> 00:13:13,089
Fail on something, but if processes
are automated, vetted accordingly and

230
00:13:13,140 --> 00:13:15,479
this, there's less chances of failures.

231
00:13:16,030 --> 00:13:18,190
And then policy as code framework, right?

232
00:13:18,190 --> 00:13:20,890
That defines compliance rules
in machine readable format.

233
00:13:21,640 --> 00:13:25,030
Then security testing automation
that detects vulnerable value.

234
00:13:25,405 --> 00:13:26,155
It's encryption.

235
00:13:26,155 --> 00:13:28,525
Ensure secure data handling.

236
00:13:28,525 --> 00:13:32,274
So basically security testing is
must, and if it is automated that's

237
00:13:32,274 --> 00:13:37,305
really saves a lot of time in leakages
vulnerabilities across the financial

238
00:13:37,305 --> 00:13:38,805
organization with that product.

239
00:13:39,584 --> 00:13:43,154
This approach transforms compliance
from a manual gatekeeper process into

240
00:13:43,154 --> 00:13:48,099
an automated quality gate, dramatically
reducing regulatory review cycles by

241
00:13:48,499 --> 00:13:51,044
maintaining strict security standards.

242
00:13:51,044 --> 00:13:53,864
Automated reporting generates
compliance documentation.

243
00:13:54,375 --> 00:13:58,045
Required for regulatory audits,
streaming government process without

244
00:13:58,045 --> 00:13:59,875
sacrifice, government velocity.

245
00:14:00,444 --> 00:14:04,345
So yes this is really, approach
transforms compliance from manual

246
00:14:04,345 --> 00:14:09,625
gatekeeper to automated where you can
have less chances of, leakages security

247
00:14:09,625 --> 00:14:13,405
issues because is automated and it's
a role-based process, basically.

248
00:14:13,905 --> 00:14:18,045
Now we'll talk about industry application,
e-commerce performance at scale.

249
00:14:18,675 --> 00:14:21,015
So traffic simulation engines, right?

250
00:14:21,065 --> 00:14:22,055
What is performance?

251
00:14:22,175 --> 00:14:24,215
So like we see traffic simulation engines.

252
00:14:24,695 --> 00:14:28,445
So here, what is their model complex
Using journey including browsing,

253
00:14:28,445 --> 00:14:30,005
searching, card managing, and checkout.

254
00:14:30,980 --> 00:14:33,830
Process across represented
device configurations.

255
00:14:33,830 --> 00:14:37,790
Realistic load patterns include
geographic distribution, device

256
00:14:37,790 --> 00:14:43,110
diversity, temporal, variations that
my mirror actual shopping behavior.

257
00:14:43,110 --> 00:14:46,730
So what this traffic simulation
engines is basically, let's say you

258
00:14:46,730 --> 00:14:48,500
are navigating to one website, right?

259
00:14:48,500 --> 00:14:52,730
So this will, simulate the traffic
patterns, load patterns, at what

260
00:14:52,730 --> 00:14:54,790
time, people are visiting these sites.

261
00:14:54,820 --> 00:14:54,840
What.

262
00:14:55,710 --> 00:14:59,840
It's a holidays or, weekends or
what days, basically, so this

263
00:14:59,840 --> 00:15:04,170
simulation engines will scale all
this automated performance monitoring.

264
00:15:04,170 --> 00:15:08,360
So what it'll do is detects degradation
in real time triggering scaling actions.

265
00:15:08,360 --> 00:15:11,570
So alerting operations teams to
prevent performance related incident

266
00:15:11,570 --> 00:15:13,250
during peak shopping events, right?

267
00:15:13,760 --> 00:15:17,300
Like we have Thanksgiving or holidays,
it's a peak shopping day, right?

268
00:15:17,300 --> 00:15:20,780
Integration with content delivery
networks, edge computing platforms, and

269
00:15:20,780 --> 00:15:22,160
show optimal performance well, right?

270
00:15:22,160 --> 00:15:26,520
So basically in a cloud world, we
can say edge computing platforms

271
00:15:26,520 --> 00:15:29,580
are platforms which are near to
that geographic locations like

272
00:15:29,580 --> 00:15:31,380
we have Australia, US, or Europe.

273
00:15:31,440 --> 00:15:33,535
We will be having edge
locations near to that.

274
00:15:34,320 --> 00:15:40,720
Where performance, basically is more, if
I'm accessing a website from Australia,

275
00:15:40,720 --> 00:15:43,450
it has a same website as more performance.

276
00:15:43,780 --> 00:15:47,500
If I'm pointing that website to us,
and if I'm accessing Australia, it'll

277
00:15:47,500 --> 00:15:49,780
be low latency performance, very slow.

278
00:15:49,780 --> 00:15:51,970
So that is the concept of edge computing.

279
00:15:52,900 --> 00:15:54,820
Now we'll talk about performance budgets.

280
00:15:55,150 --> 00:15:58,780
So enforce accessible response
times, preventing performance

281
00:15:58,780 --> 00:16:02,680
regressions from reaching production
and maintaining optimal user.

282
00:16:03,355 --> 00:16:06,535
Experience across diverse
device ecosystems?

283
00:16:06,535 --> 00:16:06,745
Yes.

284
00:16:07,165 --> 00:16:11,000
So basically enforcing the
acceptable response diamonds per

285
00:16:11,050 --> 00:16:12,760
preventing performance regression.

286
00:16:12,810 --> 00:16:15,570
So automatically the scale
testing environments to match

287
00:16:15,570 --> 00:16:16,530
production load patterns.

288
00:16:16,530 --> 00:16:18,000
So basically performance budgets.

289
00:16:18,050 --> 00:16:21,640
We can try to automatically
scaling testing environments.

290
00:16:21,640 --> 00:16:26,440
Basically we are putting the same budget,
whatever we are doing in production, which

291
00:16:26,440 --> 00:16:28,290
will scale the environment automatically.

292
00:16:28,290 --> 00:16:31,820
Testing environment so that, we can
match the actual production load patterns

293
00:16:31,880 --> 00:16:33,530
that is very important key feature.

294
00:16:34,030 --> 00:16:37,270
Now we'll talk about, self-service,
API and developer experience.

295
00:16:37,870 --> 00:16:41,170
So a successful mobile automation
patterns, prioritize developer

296
00:16:41,170 --> 00:16:44,800
experience through restful
APIs, enabling programmatic

297
00:16:44,800 --> 00:16:46,480
access to testing capabilities.

298
00:16:47,425 --> 00:16:50,455
Okay, restful APIs they will
enable programmer technical

299
00:16:50,455 --> 00:16:52,105
excel to testing capabilities.

300
00:16:52,155 --> 00:16:58,765
Like we have, restful APIs where we can
directly call API services and check, we

301
00:16:58,765 --> 00:17:02,874
can get the response, whether it's get or
post and accordingly validate the data.

302
00:17:03,279 --> 00:17:05,949
Then graph will interface is
providing flexible queries.

303
00:17:05,949 --> 00:17:10,810
We can have graph queries to
precise testing data, real time

304
00:17:10,810 --> 00:17:14,789
subscription, delivering test results
and infrastructure status updates.

305
00:17:14,789 --> 00:17:19,199
So real time, we can get the test results
and infrastructure status updates as well.

306
00:17:19,739 --> 00:17:23,519
So we have comprehensive as d
liabilities, as well as simplifying

307
00:17:23,519 --> 00:17:26,219
platform integration across
popular programming languages.

308
00:17:26,719 --> 00:17:31,009
So yes, we have, these SDK libraries
available which we can integrate

309
00:17:31,009 --> 00:17:36,129
to our, programming languages
across might be, Java, see whatever

310
00:17:36,129 --> 00:17:37,334
language we want to integrate it.

311
00:17:38,154 --> 00:17:42,534
Code generators are there creating a
boilerplate testing confi configurators.

312
00:17:42,684 --> 00:17:45,324
Nowadays we have, copilot
and all those things.

313
00:17:45,324 --> 00:17:48,454
We can just instruct it and
we can get the codes also.

314
00:17:48,454 --> 00:17:50,704
And there are various other
code generators as well.

315
00:17:51,214 --> 00:17:55,594
Interactive documentation with executable
example, demonstrate platform so we can

316
00:17:55,594 --> 00:17:57,764
give interactive documentation as such.

317
00:17:57,764 --> 00:18:01,914
We can have a PowerPoint interactive,
documentation, which will be show us

318
00:18:01,944 --> 00:18:07,019
exactly how codes are getting executed
and how we can have those executables.

319
00:18:07,269 --> 00:18:13,249
Now we'll talk about observ
observability and operational excellence.

320
00:18:13,919 --> 00:18:16,709
First is comprehensive
monitoring in this section.

321
00:18:17,189 --> 00:18:18,899
Then we have distributed tracing.

322
00:18:19,019 --> 00:18:21,659
Then we have service level,
objective, then error budget.

323
00:18:22,154 --> 00:18:23,894
So what is comprehensive monitoring?

324
00:18:23,924 --> 00:18:26,474
So we are talking about, this
covers the infrastructure,

325
00:18:26,474 --> 00:18:28,784
health, text execution metrics.

326
00:18:29,124 --> 00:18:32,394
Developer productivity indicates
enabling productivity should

327
00:18:32,394 --> 00:18:33,894
resolve capacity planning.

328
00:18:34,284 --> 00:18:39,475
So basically this is overall, you can
say budgeting, monitoring of execution.

329
00:18:39,524 --> 00:18:43,235
Everything comes into comprehensive
monitoring as such, right?

330
00:18:43,235 --> 00:18:46,514
All the capacity planning all
type of, indicators are there.

331
00:18:46,874 --> 00:18:50,324
Distributed tracing means provides
visibility into complex testing

332
00:18:50,324 --> 00:18:54,344
workflows, identifying bottlenecks
and optimizing execution path

333
00:18:54,344 --> 00:18:56,354
across the testing infrastructure.

334
00:18:56,745 --> 00:18:59,965
What we are saying here is it'll
provide the visibility into testing

335
00:18:59,965 --> 00:19:03,955
workflows, identifying bottlenecks,
if we have any bottlenecks, right?

336
00:19:04,254 --> 00:19:07,465
That will optimize execution
parts as well across the testing

337
00:19:07,465 --> 00:19:10,074
infrastructure, service level objectives.

338
00:19:10,574 --> 00:19:14,134
Here we are talking about, defined
platform reliability expectation,

339
00:19:14,134 --> 00:19:17,824
driving continuous improvements
efforts through objective criteria

340
00:19:17,824 --> 00:19:19,414
for infrastructure changes.

341
00:19:19,464 --> 00:19:23,374
So basically we are talking about
platform reliability, driving

342
00:19:23,374 --> 00:19:25,054
continuous improvements efforts.

343
00:19:25,054 --> 00:19:26,975
So this is ongoing process.

344
00:19:27,379 --> 00:19:29,720
In the infrastructure for changes.

345
00:19:30,139 --> 00:19:31,220
Then error budgeting.

346
00:19:31,220 --> 00:19:35,180
So we should, balance innovation,
velocity, stability requirements,

347
00:19:35,180 --> 00:19:38,420
providing objective criteria, managing
the pace of pattern evolution.

348
00:19:38,840 --> 00:19:42,139
So here we are talking about, how
patterns are getting evaluated, right?

349
00:19:42,200 --> 00:19:45,290
Accordingly, we are budgeting,
providing objective criteria.

350
00:19:45,710 --> 00:19:48,590
So it should be like some
criteria driven, right?

351
00:19:48,770 --> 00:19:51,830
It should not be like, we have to do
something for doing it, but it should

352
00:19:51,830 --> 00:19:53,160
be business driven, criteria driven.

353
00:19:53,660 --> 00:19:57,350
So now we are talking about go
governance and policy enforcement.

354
00:19:57,379 --> 00:20:01,730
So here we are talking about,
enterprise platform requires governance

355
00:20:01,730 --> 00:20:05,270
framework that balance developer
authority with organization control.

356
00:20:05,600 --> 00:20:09,800
Here we are talking policy engines and
for security requirements, resource

357
00:20:09,800 --> 00:20:11,600
limits and compliance standard.

358
00:20:12,245 --> 00:20:16,385
Automated policy validation prevent
non-compliant congregations from breaching

359
00:20:16,385 --> 00:20:21,455
production integration with admission
controls and validation web books and

360
00:20:21,455 --> 00:20:23,735
force policies at the intersection level.

361
00:20:24,475 --> 00:20:27,355
Here we are talking about cost
management policies, prevent runway

362
00:20:27,355 --> 00:20:32,944
resource consumption while enabling bus
capacity for critical testing needs.

363
00:20:32,944 --> 00:20:34,804
We are talking about resource quota.

364
00:20:35,494 --> 00:20:37,084
Establish clear boundaries.

365
00:20:37,144 --> 00:20:40,084
Budget alert, provide early
warning for potential over.

366
00:20:40,834 --> 00:20:46,804
Automatic scaling policies, balance cost,
testing of effectiveness, regular policy

367
00:20:46,804 --> 00:20:51,064
reviews, ensure governance framework
evolve with changing organizational needs.

368
00:20:51,064 --> 00:20:54,754
So basically what we are talking about
is a government policies we should

369
00:20:54,754 --> 00:20:58,415
be up to date and we have to make
sure we are reviewing our policy on

370
00:20:58,415 --> 00:21:02,084
daily basis so that we are compliant
with the GO governance framework.

371
00:21:02,810 --> 00:21:04,760
And government policies as such.

372
00:21:05,260 --> 00:21:08,770
Now we'll talk about future directions,
where we have to go from here.

373
00:21:09,159 --> 00:21:11,739
So we are talking about edge
computing and 5G integrations.

374
00:21:11,739 --> 00:21:15,459
So edge, a native testing, validation,
application performance under the

375
00:21:15,459 --> 00:21:19,780
i low latency conditions while
ensuring compatibility across

376
00:21:19,784 --> 00:21:21,909
diverse edge computing environments.

377
00:21:21,909 --> 00:21:24,404
Like we have spoken about, edge locations.

378
00:21:24,404 --> 00:21:25,424
What is edge location?

379
00:21:25,424 --> 00:21:29,834
Edge locations means, if I am in
Australia, I'm accessing some website

380
00:21:29,834 --> 00:21:32,204
or from mobile devices, right?

381
00:21:32,204 --> 00:21:35,224
So I will be hitting a
nearby edge locations where

382
00:21:35,224 --> 00:21:36,634
performance is good, right?

383
00:21:36,664 --> 00:21:41,524
Although that website is hosted in
us, but through Azure locations,

384
00:21:41,524 --> 00:21:43,084
it performance is very fast.

385
00:21:43,504 --> 00:21:47,014
Then we are talking 5G network
Simulation EN enables testing of

386
00:21:47,014 --> 00:21:51,135
advanced mobile capability, including
augmented realtime ion IOT integration.

387
00:21:51,135 --> 00:21:53,085
So we are talking about
here 5G integration.

388
00:21:53,955 --> 00:21:58,305
Sustainable testing practices, carbon
aware testing schedule, shift resource

389
00:21:58,305 --> 00:22:02,835
intense operations to periods when
renewable energy availability is

390
00:22:02,835 --> 00:22:05,054
highest reducing environmental impact.

391
00:22:05,115 --> 00:22:08,415
Green software engineering principle
guide platform development,

392
00:22:08,415 --> 00:22:12,274
ensuring environmental constitution
influence architectural decisions.

393
00:22:12,274 --> 00:22:16,415
So basically we have to be, make sure
it's environmental and, engineering

394
00:22:16,415 --> 00:22:18,995
principles are implemented accordingly.

395
00:22:19,655 --> 00:22:21,695
So we should follow good practices always.

396
00:22:22,489 --> 00:22:24,979
Now we'll talk about
implementation strategy.

397
00:22:25,429 --> 00:22:27,739
So first is build a strong foundation.

398
00:22:27,799 --> 00:22:28,129
Yes.

399
00:22:28,129 --> 00:22:32,029
We have to focus on infrastructure,
comprehensive observability, developer

400
00:22:32,029 --> 00:22:36,439
centric design for building a strong
foundation enable self services.

401
00:22:36,439 --> 00:22:39,289
So we have to make sure
every developer is self ent.

402
00:22:39,289 --> 00:22:43,310
We have proper documentation, SD,
SDKs intuitive APIs, libraries,

403
00:22:43,310 --> 00:22:46,250
so that, it should be integrated
testing into their workflows.

404
00:22:46,250 --> 00:22:47,750
Developers should integrate the same.

405
00:22:48,649 --> 00:22:49,669
Implement governance.

406
00:22:49,669 --> 00:22:53,220
So we should, balance developer
autonom organization control through

407
00:22:53,220 --> 00:22:56,879
policy engine that enforce security
compliance and resource manage

408
00:22:57,750 --> 00:22:59,820
management, which is very important here.

409
00:23:00,780 --> 00:23:02,129
It evolve continuously.

410
00:23:02,129 --> 00:23:04,379
So we have to learn and
evolve continuously.

411
00:23:04,429 --> 00:23:10,209
We have to add whatever the new data
we are reading new testing techniques

412
00:23:10,259 --> 00:23:11,704
it's evolving process basically.

413
00:23:12,009 --> 00:23:15,119
A data drive iterative
improvement, scaling platform

414
00:23:15,119 --> 00:23:18,989
capabilities as they matured and
adopting emerging technologies.

415
00:23:19,679 --> 00:23:23,069
These elements enable iterative
improvement, scaling as platform

416
00:23:23,219 --> 00:23:26,579
capabilities mature, creating
the foundation for sustainable

417
00:23:26,579 --> 00:23:29,609
growth and continuous innovation.

418
00:23:30,479 --> 00:23:33,224
Now we'll talk about the
strategic, imperative.

419
00:23:33,734 --> 00:23:37,514
So platform first, mobile automation
represents a fundamental shift in

420
00:23:37,514 --> 00:23:40,394
how enterprise approach testing
infrastructure by treating

421
00:23:40,814 --> 00:23:42,704
testing capabilities as product.

422
00:23:42,794 --> 00:23:44,774
Yes, rather than sources.

423
00:23:45,134 --> 00:23:49,364
So this mobile infrastructure
testing, all this is like a product.

424
00:23:49,424 --> 00:23:49,814
Okay.

425
00:23:49,814 --> 00:23:52,514
We should read all together
as a different product.

426
00:23:52,564 --> 00:23:53,534
Mobile testing.

427
00:23:53,594 --> 00:23:58,154
It should not be treated to the services
organization, achieve unprecedented scale

428
00:23:58,154 --> 00:23:59,714
reliability and developer productivity.

429
00:23:59,714 --> 00:24:03,884
Team, the transformation extends beyond
operational efficiency to strategic

430
00:24:03,884 --> 00:24:07,244
advantage, enabling what this will enable.

431
00:24:07,274 --> 00:24:10,814
Faster time to market, enhanced
competitive positioning,

432
00:24:10,814 --> 00:24:15,014
improved deployment confidence,
a reduced operational overhead.

433
00:24:15,849 --> 00:24:20,259
Organizations that master these
capabilities will define the future of

434
00:24:20,259 --> 00:24:24,009
mobile application development, setting
new standards for quality, velocity

435
00:24:24,009 --> 00:24:26,139
and scale in the digital economy.

436
00:24:26,619 --> 00:24:28,419
So mobile is the future, right?

437
00:24:28,539 --> 00:24:30,699
We have a smartphone and Android, iOS.

438
00:24:30,699 --> 00:24:34,299
So we have to make sure, all the
organization understand that these

439
00:24:34,299 --> 00:24:38,019
capabilities and it should be treated
as a product, not as in service.

440
00:24:38,519 --> 00:24:38,999
Oh, okay.

441
00:24:38,999 --> 00:24:40,709
So we come to the last slide.

442
00:24:40,889 --> 00:24:44,649
Thank you very much for
listening me and watching me.

443
00:24:44,919 --> 00:24:48,849
And in case of any questions,
KU as I told in beginning right,

444
00:24:48,849 --> 00:24:50,409
I am available on LinkedIn.

445
00:24:50,559 --> 00:24:53,019
You can search by chair and
preaching who, and we can connect

446
00:24:53,019 --> 00:24:54,659
there and discuss more over there.

447
00:24:54,749 --> 00:24:55,739
Thank you very much.

448
00:24:55,789 --> 00:24:56,299
Good day.

449
00:24:56,809 --> 00:24:57,139
Bye.

