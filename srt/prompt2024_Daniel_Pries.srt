1
00:00:00,150 --> 00:00:04,000
By the end of today's session, hopefully
you'll have a working understanding

2
00:00:04,000 --> 00:00:08,940
of how AI is changing the hiring
landscape, particularly in technology.

3
00:00:09,440 --> 00:00:12,940
And then we'll learn some techniques to
battle hard and people centric processes

4
00:00:12,950 --> 00:00:15,430
such as talent acquisition using AI.

5
00:00:16,140 --> 00:00:18,799
Now just understand, I chose
talent acquisition because of this

6
00:00:18,830 --> 00:00:22,659
personal mission that I was on, but
it could also be useful for other

7
00:00:22,750 --> 00:00:24,650
human centered processes as well.

8
00:00:25,150 --> 00:00:27,569
Alright, so today's agenda is going
to look a little bit like this.

9
00:00:28,039 --> 00:00:30,200
First, I'm going to start
with some anchoring bias.

10
00:00:30,429 --> 00:00:33,170
I'm going to talk about the
circumstances that kind of led

11
00:00:33,170 --> 00:00:34,610
me to take on this experiment.

12
00:00:35,460 --> 00:00:38,680
And then we're going to talk about my
personal mission a little bit here.

13
00:00:38,970 --> 00:00:41,580
Because if you're going to risk it all,
you might as well make it personal.

14
00:00:42,190 --> 00:00:44,169
We'll talk about the
process that was followed.

15
00:00:44,180 --> 00:00:48,710
Now, because of the magnitude of research
that was required for this exercise,

16
00:00:48,900 --> 00:00:52,720
we're only going to cover a couple data
points associated with this experiment.

17
00:00:53,699 --> 00:00:56,050
And then finally, we'll
talk about the outcomes.

18
00:00:56,550 --> 00:00:59,879
Alright, so first of all, I need
to anchor you guys in some bias.

19
00:00:59,879 --> 00:01:02,290
You guys need some context,
because this wasn't just

20
00:01:02,310 --> 00:01:05,110
initiated out of nowhere, right?

21
00:01:05,110 --> 00:01:07,200
There was a reason why
I started this process.

22
00:01:08,055 --> 00:01:10,535
So we're gonna start with a little
bit about me, and I know it's a

23
00:01:10,535 --> 00:01:13,575
little cliche, but it's important
to understand my context and the

24
00:01:13,575 --> 00:01:16,225
things that I want to solve for and
how it relates to this exercise.

25
00:01:16,905 --> 00:01:18,364
So my name is Daniel Preece.

26
00:01:18,415 --> 00:01:21,485
I'm an engineering manager
of digital experience teams

27
00:01:21,485 --> 00:01:22,725
for a super regional bank.

28
00:01:23,385 --> 00:01:26,774
Now, I'm an engineer first with
20 plus years of experience

29
00:01:26,774 --> 00:01:30,115
across various industries, ranging
from bare metal computer chips

30
00:01:30,175 --> 00:01:31,675
to cloud native architecture.

31
00:01:31,970 --> 00:01:33,150
And everything in between.

32
00:01:33,630 --> 00:01:36,690
I'm currently on a personal
mission to improve the developer

33
00:01:36,690 --> 00:01:41,660
experience for the teams that I
oversee, and I love growing others.

34
00:01:41,860 --> 00:01:45,740
I like to watch the light bulb turn
on as people learn new skills and help

35
00:01:45,750 --> 00:01:48,780
people through their soft skills and
as they navigate their career journey.

36
00:01:49,280 --> 00:01:53,439
So when I started this experiment,
there was a hiring climate

37
00:01:53,439 --> 00:01:54,819
that predicated all of it.

38
00:01:55,319 --> 00:01:59,069
I was hired at my current
organization in 2020, in July 2020.

39
00:01:59,109 --> 00:02:03,269
Now, prior to that, there was this
thing going on, in the 2019 into

40
00:02:03,269 --> 00:02:05,329
2020 called the great resignation.

41
00:02:05,559 --> 00:02:08,479
And this is where people decided
that they wanted to do something

42
00:02:08,479 --> 00:02:09,599
about their quality of life.

43
00:02:09,609 --> 00:02:11,569
A lot more people wanted
to work from home.

44
00:02:11,569 --> 00:02:12,809
They wanted to be with their families.

45
00:02:12,809 --> 00:02:14,799
They were tired of commuting in every day.

46
00:02:14,999 --> 00:02:17,239
Many people quit their careers.

47
00:02:17,509 --> 00:02:19,629
They were experiencing burnout
and decided, you know what?

48
00:02:19,669 --> 00:02:20,789
It's time to move on.

49
00:02:21,074 --> 00:02:23,784
To something else, and we
can see that in the data.

50
00:02:24,054 --> 00:02:27,264
when we look at February,
2019 is February 2020.

51
00:02:27,284 --> 00:02:32,074
There was a 47 percent reduction of
applications across all industries.

52
00:02:32,524 --> 00:02:36,614
Now, some of you may think, we also had
this thing called the coven 19 pandemic.

53
00:02:36,614 --> 00:02:37,554
Not sure if you heard of it.

54
00:02:37,744 --> 00:02:38,384
actually.

55
00:02:38,674 --> 00:02:42,414
When the United States shut
down that was March of 2020.

56
00:02:42,634 --> 00:02:45,714
So this is a year prior to
any of this even occurring.

57
00:02:45,884 --> 00:02:48,934
We're starting to see a significant
reduction in the number of applicants

58
00:02:49,124 --> 00:02:51,604
and people in the job market because
they're looking for something

59
00:02:51,604 --> 00:02:52,934
more in that quality of life.

60
00:02:53,754 --> 00:02:57,674
So the talent pool itself
is electively decreasing.

61
00:02:58,594 --> 00:03:00,744
Now, while that's going on, while
the talent pool is electively

62
00:03:00,744 --> 00:03:05,004
decreasing, we also have big
tech going on a hiring spree.

63
00:03:05,354 --> 00:03:06,754
And we're also seeing that in the data.

64
00:03:06,754 --> 00:03:10,814
Now, first, I want to acknowledge here
that this data covers a period from 2019

65
00:03:10,814 --> 00:03:16,294
through 2022, that 20 to 19 to 2020 period
is that period of the great resignation.

66
00:03:16,614 --> 00:03:19,654
And then beyond that is when we
get into the COVID 19 years, right?

67
00:03:19,654 --> 00:03:23,974
We're all separating, social
distancing together and big tech

68
00:03:23,984 --> 00:03:25,674
is actively hiring like crazy.

69
00:03:26,079 --> 00:03:28,809
The other piece of data I want to
acknowledge here just because of

70
00:03:28,809 --> 00:03:30,949
its bias a little bit is Amazon.

71
00:03:31,119 --> 00:03:35,969
They are part of the supply chain
and the COVID 19 pandemic, right?

72
00:03:35,969 --> 00:03:38,139
They are part of the
improvement of the supply chain.

73
00:03:38,389 --> 00:03:41,089
And so they did ramp up
significantly in that process.

74
00:03:41,349 --> 00:03:44,619
But the rest of big tech like
Microsoft, Apple, Alphabet, they

75
00:03:44,619 --> 00:03:49,659
grew by thousands, if not tens of
thousands from 2019 through 2022.

76
00:03:50,159 --> 00:03:53,529
This is very frustrating because, again,
we have this great resignation going on,

77
00:03:53,529 --> 00:03:57,709
people are electively not wanting to work
anymore, and also Big Tech is drinking

78
00:03:57,709 --> 00:04:01,189
our milkshake, because at the end of
the day, the talent pool is only so big.

79
00:04:01,689 --> 00:04:05,829
Pulling in talent from the same
talent pool around the globe and

80
00:04:05,829 --> 00:04:10,069
prior to that, there was a big push
for digitization and recruitment as

81
00:04:10,069 --> 00:04:11,889
a solution for talent acquisition.

82
00:04:11,939 --> 00:04:15,439
so as part of, the way that talent
acquisition is working, they want

83
00:04:15,439 --> 00:04:20,229
to move from very manual toil based
processes into automation so that it can.

84
00:04:20,534 --> 00:04:23,354
Focus on better set of
behaviors and better outcomes.

85
00:04:23,854 --> 00:04:24,574
So what does that mean?

86
00:04:24,574 --> 00:04:27,454
What does the digitization
of talent acquisition mean?

87
00:04:28,084 --> 00:04:32,314
we really want to automate those data
heavy tasks that are highly repetitive.

88
00:04:32,564 --> 00:04:36,274
In the SRE world, this would be analogous
to things that we would call toil, right?

89
00:04:36,274 --> 00:04:38,394
So we want to automate
those processes away.

90
00:04:38,394 --> 00:04:39,684
They're also a little error prone.

91
00:04:40,144 --> 00:04:43,934
we also want to take things like resume
screening, any of the scheduling.

92
00:04:43,944 --> 00:04:46,724
So if you've ever done any scheduling,
we select your own schedule with

93
00:04:47,074 --> 00:04:50,224
Talent acquisition, or maybe an
HR representative or a conference

94
00:04:50,224 --> 00:04:52,664
speaker or whatnot, they're
scheduling tools that are out there.

95
00:04:53,529 --> 00:04:57,159
Technology screening right to
understand as a person understand

96
00:04:57,219 --> 00:05:00,839
a particular technology set, or
does a resume actually satisfy a

97
00:05:00,839 --> 00:05:04,479
particular technology needs, chat
box, which are used for relationships.

98
00:05:04,479 --> 00:05:06,539
And this is prior to generative AI.

99
00:05:06,539 --> 00:05:09,099
When we were working more with
natural language processing,

100
00:05:09,099 --> 00:05:10,609
just a small segment of.

101
00:05:10,769 --> 00:05:14,449
What we now use as part of generative
AI and RPA is a robotic process

102
00:05:14,449 --> 00:05:16,449
automation to manage those leads.

103
00:05:17,069 --> 00:05:20,149
Now, all this automation was really
there with this promise that it

104
00:05:20,149 --> 00:05:23,869
would free up the recruiter's time
for more strategic tasks, right?

105
00:05:23,929 --> 00:05:26,699
building out your talent network,
as well as building those

106
00:05:26,699 --> 00:05:28,659
relationships with the candidates.

107
00:05:29,159 --> 00:05:31,949
All right, so let's talk a little
bit about a hiring process, right?

108
00:05:32,429 --> 00:05:34,849
Because we now understand,
we've got this great resignation

109
00:05:34,849 --> 00:05:36,229
going on, talent pool shrinking.

110
00:05:36,519 --> 00:05:38,609
We've got big tech drinking our milkshake.

111
00:05:38,839 --> 00:05:40,569
We've got a lot of
automation in the process.

112
00:05:40,569 --> 00:05:41,779
But what is the process?

113
00:05:42,389 --> 00:05:44,039
for most organizations,
it looks like this.

114
00:05:44,039 --> 00:05:47,549
We have talent acquisition and HR deciding
that they're going to have a strategy.

115
00:05:47,549 --> 00:05:50,949
They're going to do either open up
roles as needed, or there's going

116
00:05:50,949 --> 00:05:53,079
to be some sort of recruitment
effort to build a talent pool.

117
00:05:53,269 --> 00:05:55,819
They might reach out to career
fairs or job fairs, right?

118
00:05:55,819 --> 00:06:00,579
They really want to build up a network
where people can source candidates.

119
00:06:01,339 --> 00:06:05,739
It may also include external sourcers
as well, whose job is just to collect

120
00:06:05,739 --> 00:06:09,759
these networks for you, for these
organizations and set HR up for

121
00:06:09,759 --> 00:06:11,289
success in terms of their hirings.

122
00:06:11,789 --> 00:06:14,529
Then we may take a candidate through
a technical interview, right?

123
00:06:14,529 --> 00:06:15,639
Which is like a technical screen.

124
00:06:15,639 --> 00:06:17,529
if you're in technology, you've
gone through this is where you're

125
00:06:17,529 --> 00:06:18,779
going to ask them simple questions.

126
00:06:18,829 --> 00:06:20,839
They make it harder and harder
over time, but they're really

127
00:06:20,839 --> 00:06:23,559
trying to understand what your
tech technical acumen looks like.

128
00:06:24,079 --> 00:06:26,279
It's really hard to do in
a short period of time.

129
00:06:26,519 --> 00:06:29,349
So it tends to be pretty quick
though, like 30 minutes to

130
00:06:29,349 --> 00:06:32,339
an hour at most, to get, to
understand your technical literacy.

131
00:06:32,829 --> 00:06:36,559
And then to offset that a little bit, what
you can do in practice, more organizations

132
00:06:36,559 --> 00:06:38,559
are starting to use automated tests.

133
00:06:38,999 --> 00:06:40,979
Now this is a thing that I
had a personal gripe with.

134
00:06:40,989 --> 00:06:44,689
The automated testing thing is
part of my personal mission.

135
00:06:45,059 --> 00:06:48,009
Because while they're useful
in most contexts, in some

136
00:06:48,009 --> 00:06:49,499
contexts they can be used poorly.

137
00:06:49,779 --> 00:06:52,009
And so I had some concerns, so
I really wanted to address that.

138
00:06:52,509 --> 00:06:54,609
Then there's also a
manager meet and greet.

139
00:06:54,659 --> 00:06:57,469
And this might not be somebody who's
directly invested in the process.

140
00:06:57,469 --> 00:07:00,989
Maybe a senior, more senior person
or a person outside the process.

141
00:07:01,239 --> 00:07:03,259
They're really just looking
for red flags, right?

142
00:07:03,259 --> 00:07:05,479
Cause you can have a great candidate
and you're like, Hey, this person

143
00:07:05,509 --> 00:07:06,509
did great on the interview.

144
00:07:06,509 --> 00:07:09,339
They did great in the technology
screen, but, you may have missed the

145
00:07:09,339 --> 00:07:10,529
red flags and all of your excitement.

146
00:07:10,529 --> 00:07:11,869
So this person is really there to help.

147
00:07:11,929 --> 00:07:15,079
sell the organization, maybe sell
the geography where they're going

148
00:07:15,079 --> 00:07:18,329
to need to move to if they need to
relocate, sell the culture of the

149
00:07:18,329 --> 00:07:21,109
organization and really look, just
look for red flags and the candidate.

150
00:07:21,439 --> 00:07:24,449
but if everything's great, then we
move on into the next piece, which

151
00:07:24,449 --> 00:07:26,409
is the competency based interview.

152
00:07:26,529 --> 00:07:29,749
And we'll cover that shortly, but we
really just want to understand not the

153
00:07:29,749 --> 00:07:31,789
technology itself that you know, but.

154
00:07:31,844 --> 00:07:34,384
and there's a lot of great questions
and competency based interviews that

155
00:07:34,384 --> 00:07:38,594
really help you understand a person
and if they're the right team member

156
00:07:38,594 --> 00:07:41,104
for the job, not just do they have
the right skill set, but do they have

157
00:07:41,104 --> 00:07:45,024
the right behaviors within that skill
set to be able to do their job and

158
00:07:45,024 --> 00:07:47,964
execute and bring the right kind of
values and culture to the organization.

159
00:07:48,744 --> 00:07:50,444
And then lastly, we
compare the notes, right?

160
00:07:50,444 --> 00:07:53,144
We take all of these things and
we say, okay, does the person,

161
00:07:53,154 --> 00:07:54,394
is there skilled enough, right?

162
00:07:54,395 --> 00:07:54,459
Okay.

163
00:07:54,709 --> 00:07:56,549
Do they seem to solve
the problems well enough?

164
00:07:56,889 --> 00:07:58,259
Do they have no red flags?

165
00:07:58,389 --> 00:08:00,339
Do they really want to be
part of this organization?

166
00:08:00,339 --> 00:08:01,369
Do they match our values?

167
00:08:01,370 --> 00:08:05,049
Do they solve problems in a way that
is meaningful to the organization?

168
00:08:05,049 --> 00:08:09,359
If everything is great, we give that
candidate a thumbs up, we make an offer.

169
00:08:09,629 --> 00:08:11,929
And that's typically how most
organizations work, at least the

170
00:08:11,929 --> 00:08:14,549
organizations that I've worked
with, as part of the hiring process.

171
00:08:15,464 --> 00:08:19,344
So anyway, that's a background about the
hiring process we want to work through.

172
00:08:19,844 --> 00:08:22,764
So at this point, I need to tell
you a little bit of a story, right?

173
00:08:23,124 --> 00:08:27,404
So I'm getting a little frustrated with
different pieces of the hiring process.

174
00:08:27,404 --> 00:08:30,294
And at one point I was
doing a lot of interviews.

175
00:08:30,794 --> 00:08:33,474
I think over a course
of, Three or four years.

176
00:08:33,524 --> 00:08:37,964
I was doing hundreds of interviews a year,
and I wasn't just doing them for my teams.

177
00:08:37,974 --> 00:08:40,194
I was doing them for other
teams in the organization.

178
00:08:40,474 --> 00:08:43,634
I work for a large organization,
and so I got a kind of got a

179
00:08:43,634 --> 00:08:45,354
reputation for being good at them.

180
00:08:45,474 --> 00:08:46,274
I like doing them.

181
00:08:46,274 --> 00:08:47,034
I think it's fun.

182
00:08:47,064 --> 00:08:48,354
I like picking apart people's brains.

183
00:08:48,774 --> 00:08:51,004
And so I was doing an interview.

184
00:08:51,504 --> 00:08:54,304
First of all, there's this
person on your screen, right?

185
00:08:54,334 --> 00:08:56,684
Kind of looks like the
Lorax, big bushy mustache.

186
00:08:56,784 --> 00:08:59,764
you frowned upon to talk about
somebody's physical features, especially

187
00:08:59,764 --> 00:09:00,814
as it relates to an interview.

188
00:09:01,144 --> 00:09:02,164
But this is important.

189
00:09:02,484 --> 00:09:05,764
I was talking to a candidate and I
was doing a technical screen and I

190
00:09:05,764 --> 00:09:09,804
think I was asking a simple set of
questions, something like, what is SOLID?

191
00:09:09,974 --> 00:09:14,314
And SOLID is an acronym, it means
like Single Responsibility, Open

192
00:09:14,314 --> 00:09:17,204
Closed Principle, Live Scoss
Substitution Principle, Interface

193
00:09:17,214 --> 00:09:19,904
Segregation, and Dependency Inversion.

194
00:09:20,329 --> 00:09:23,869
Now, most candidates, they will
say, something like dependency

195
00:09:23,879 --> 00:09:25,879
injections, set a dependency inversion.

196
00:09:25,969 --> 00:09:27,319
and we'll navigate that a little bit.

197
00:09:27,689 --> 00:09:30,529
So I'm a few minutes into this
conversation and as the conversation is

198
00:09:30,529 --> 00:09:35,339
evolving, then the facial features aren't
really lining up with the mouth at all.

199
00:09:35,339 --> 00:09:37,139
Like the movements aren't quite there.

200
00:09:37,539 --> 00:09:41,309
Now, I wasn't sure if it was just the
auto audio buffering issues or if it was

201
00:09:41,319 --> 00:09:45,619
like, just The latency over the network
or whatnot, but it didn't seem right.

202
00:09:45,629 --> 00:09:46,389
Something was off.

203
00:09:46,389 --> 00:09:48,179
And so I get to this question, right?

204
00:09:48,229 --> 00:09:54,109
what's the difference between dependency
injection and dependency inversion, right?

205
00:09:54,189 --> 00:09:56,909
And really the answer there is
dependency injection is a way

206
00:09:56,909 --> 00:09:58,389
to perform dependency inversion.

207
00:09:58,539 --> 00:10:01,969
It's not the only way, but it is
the most common way, typically

208
00:10:02,009 --> 00:10:03,329
the way we do things today.

209
00:10:03,829 --> 00:10:06,519
So I get to this question
in the audio cuts.

210
00:10:07,019 --> 00:10:07,569
I'm like, okay.

211
00:10:07,570 --> 00:10:07,709
Okay.

212
00:10:08,499 --> 00:10:09,799
This is not abnormal, right?

213
00:10:09,849 --> 00:10:11,209
Sometimes the audio cuts, right?

214
00:10:11,209 --> 00:10:12,599
And screens cut, whatever.

215
00:10:13,009 --> 00:10:15,209
So the candidate starts
typing on the screen.

216
00:10:15,209 --> 00:10:16,319
I can't hear you.

217
00:10:16,319 --> 00:10:17,849
I have an audio issues.

218
00:10:18,009 --> 00:10:18,939
Okay, it's great.

219
00:10:19,449 --> 00:10:21,999
And but then something
registered in my head.

220
00:10:22,499 --> 00:10:25,069
You see the candidate as they were typing.

221
00:10:25,099 --> 00:10:29,339
I could hear their keyboard
clicks in the microphone.

222
00:10:29,340 --> 00:10:33,209
So that's when it registered.

223
00:10:34,034 --> 00:10:39,174
The person that I was talking
to in audio was not the person

224
00:10:39,354 --> 00:10:40,744
on the other side of the screen.

225
00:10:41,504 --> 00:10:45,394
The person on the other side of the
screen was mouthing the words because

226
00:10:45,394 --> 00:10:47,334
their microphone was working just fine.

227
00:10:48,304 --> 00:10:49,084
Oh my goodness.

228
00:10:49,394 --> 00:10:50,324
This is crazy, right?

229
00:10:50,404 --> 00:10:53,544
So they said, Hey, look, I'm going
to call back in a few minutes.

230
00:10:53,554 --> 00:10:55,244
I'm going to rejoin the line.

231
00:10:55,274 --> 00:10:56,074
okay, that's fine.

232
00:10:56,364 --> 00:11:00,014
And while that's
happening, I start texting.

233
00:11:00,474 --> 00:11:03,464
I am in the, the HR department,
our recruiter and say,

234
00:11:03,464 --> 00:11:04,694
Hey, what's going on here?

235
00:11:04,694 --> 00:11:07,914
I think our candidate might be
fraudulent and they say, stay in

236
00:11:07,914 --> 00:11:09,464
the line, start asking questions.

237
00:11:09,464 --> 00:11:12,694
And so went ahead and continued
the rest of the interview.

238
00:11:12,864 --> 00:11:17,224
Five minutes later, the person shows
up again, they're on the visual, their

239
00:11:17,224 --> 00:11:19,824
audio comes through and they asked
where we were on their questions.

240
00:11:19,824 --> 00:11:25,214
And so we regroup again and they
give me a, not a great answer, but

241
00:11:25,214 --> 00:11:26,494
we continue through the interview.

242
00:11:27,034 --> 00:11:27,944
But the voice.

243
00:11:28,369 --> 00:11:29,509
was completely different.

244
00:11:29,999 --> 00:11:32,069
The accent was completely different.

245
00:11:32,079 --> 00:11:34,389
The tone was completely different.

246
00:11:35,179 --> 00:11:37,929
And the person on the other end was
still mouthing the words and things

247
00:11:37,929 --> 00:11:40,709
weren't lining up, but they were
using their bushy mustaches to cover

248
00:11:40,949 --> 00:11:43,589
so that you really couldn't tell
that it was necessarily the mouth.

249
00:11:43,589 --> 00:11:47,249
But I'm a musician and I could pick
up on these audio cues from the

250
00:11:47,250 --> 00:11:51,429
way the lips are moving and the way
it's supposed to be interacting.

251
00:11:51,929 --> 00:11:53,329
I knew something was off here.

252
00:11:53,379 --> 00:11:56,299
So after everything said and
done, we talked to our recruiters.

253
00:11:56,529 --> 00:11:59,749
we really came back and said, hey, we
were, we think there might be an issue,

254
00:11:59,779 --> 00:12:03,549
particularly with the sourcing agency and,
we might need to do something about it.

255
00:12:03,549 --> 00:12:06,739
But it was providing some evidence
that, hey, there was some fraudulent

256
00:12:06,779 --> 00:12:08,659
activity that was going on in the system.

257
00:12:09,159 --> 00:12:11,499
Now, if you're in a hiring
role, there's some questions.

258
00:12:11,529 --> 00:12:13,229
have you ever experienced.

259
00:12:13,824 --> 00:12:17,464
fraud and hiring, whether it's,
the person's audio is different.

260
00:12:17,684 --> 00:12:19,124
They won't go on video.

261
00:12:19,364 --> 00:12:21,924
I've had situations where people
are typing in the questions.

262
00:12:21,924 --> 00:12:25,304
I can see them on video typing the
questions and they're reading it.

263
00:12:25,314 --> 00:12:26,724
it's great that they're resourceful.

264
00:12:26,724 --> 00:12:30,364
I think it's important software
engineering, but it's also important.

265
00:12:30,374 --> 00:12:32,954
You have a good foundations
and you're able to express

266
00:12:32,954 --> 00:12:34,274
the answers pretty readily.

267
00:12:34,784 --> 00:12:38,694
as a person who showed up on day one, not
been the person you even interviewed with.

268
00:12:39,089 --> 00:12:41,049
That's another thing that we commonly see.

269
00:12:41,729 --> 00:12:42,729
So it's very interesting.

270
00:12:42,729 --> 00:12:47,129
So I'm getting frustrated because while
we got, talent pools are decreasing

271
00:12:47,389 --> 00:12:49,419
because of the great resignation, right?

272
00:12:49,419 --> 00:12:53,579
We got the big tech, trying to
get everybody they possibly can.

273
00:12:53,579 --> 00:12:57,479
We've also got to deal with fraud and
this is a really challenging climate

274
00:12:57,479 --> 00:13:00,989
to work through, which the reality
is with the situation is if you're

275
00:13:00,989 --> 00:13:02,269
not cheating, you're not trying.

276
00:13:02,419 --> 00:13:04,759
And for a lot of people who are
looking for jobs at this time,

277
00:13:04,979 --> 00:13:06,889
they are cheating like crazy.

278
00:13:06,890 --> 00:13:11,719
All right, so now we got to get into
our personal mission a little bit.

279
00:13:12,119 --> 00:13:15,889
So I had some concerns about the
automated testing that we were using.

280
00:13:15,899 --> 00:13:18,709
Some of the questions seemed simple,
some of them were ridiculously hard.

281
00:13:19,019 --> 00:13:22,589
And they weren't testing whether you
knew the language or not, they were

282
00:13:22,589 --> 00:13:23,759
testing could you solve the puzzle.

283
00:13:24,604 --> 00:13:27,714
Which on some level was not great
because these were like Mensa

284
00:13:27,714 --> 00:13:31,304
level puzzles that you could solve
with any language using for loops.

285
00:13:31,324 --> 00:13:33,914
And I thought that was really not
the right way to solve the problem.

286
00:13:34,274 --> 00:13:37,144
yes, you could screen out certain things,
but I'm looking for things like code

287
00:13:37,144 --> 00:13:40,624
quality, maintainability, cyclomatic
complexity, cognitive complexity.

288
00:13:40,924 --> 00:13:45,284
All sorts of things that are important
in the maintenance of software over

289
00:13:45,284 --> 00:13:47,104
time, not just did you solve a problem.

290
00:13:47,424 --> 00:13:51,214
And so I had some concerns and I started
elevating them to the organization.

291
00:13:51,714 --> 00:13:54,664
So in spring of 2022, I started
voicing the concern about the

292
00:13:54,664 --> 00:13:55,764
automated code assessments.

293
00:13:56,174 --> 00:13:58,624
I didn't like the way that they were
being used as a blanket utility.

294
00:13:58,624 --> 00:14:01,874
I wanted to make sure that we're
using them in the right context,

295
00:14:01,874 --> 00:14:04,904
maybe with more junior engineers who
didn't have a professional background

296
00:14:05,204 --> 00:14:06,544
because it really didn't make sense.

297
00:14:06,544 --> 00:14:10,929
If you had somebody who wrote clean code,
To write it in this way, when I took this

298
00:14:10,929 --> 00:14:14,629
test, I wrote clean code, and I honestly
just needed a for loop, but that's just

299
00:14:14,629 --> 00:14:18,469
how I write, and that's just, it wasn't,
didn't seem like the right set of problems

300
00:14:18,469 --> 00:14:22,299
that we were solving for, because it
really wasn't solving for engineering,

301
00:14:22,309 --> 00:14:23,859
it was solving for the puzzle.

302
00:14:24,359 --> 00:14:27,329
So in summer 2022, I was asked to
be part of a panel that reviewed

303
00:14:27,329 --> 00:14:29,639
questions for fit and application.

304
00:14:29,639 --> 00:14:33,129
We wanted to improve our questions because
we thought that might be a problem.

305
00:14:33,489 --> 00:14:36,659
just, again, we didn't want super
hard questions, but we wanted

306
00:14:36,659 --> 00:14:38,929
them to be enough where you had
to, understand the sequencing.

307
00:14:38,929 --> 00:14:42,829
And so after that, I started
to ask if, has anybody tried

308
00:14:42,829 --> 00:14:44,449
to run these through copilot?

309
00:14:44,449 --> 00:14:48,559
Because it was in beta and chat GPT,
which I think was in an early beta.

310
00:14:49,419 --> 00:14:50,319
It was crickets.

311
00:14:51,119 --> 00:14:52,739
Everybody said that the process was fine.

312
00:14:52,749 --> 00:14:54,669
Like, why would we ever
be concerned about AI?

313
00:14:55,659 --> 00:14:58,049
It was, it was new, and I don't
think a lot of people really cared,

314
00:14:58,299 --> 00:14:59,679
and it was part of our strategy.

315
00:15:00,179 --> 00:15:03,079
So in fall of 2022, ChatGPT 3.

316
00:15:03,079 --> 00:15:04,749
5 is released to the general public.

317
00:15:04,819 --> 00:15:08,939
And this, at this point is when I
started taking these questions and

318
00:15:09,029 --> 00:15:12,839
bringing them through ChatGPT to see
which ones could be easily figured out.

319
00:15:12,849 --> 00:15:16,469
And as it turns out, a bunch of them, not
all of them, could be easily figured out.

320
00:15:16,469 --> 00:15:19,009
And that kind of signaled the ones
that we needed to start retiring.

321
00:15:19,219 --> 00:15:20,479
We need to not use them anymore.

322
00:15:20,759 --> 00:15:23,249
But the challenge is when you
retire something, you create new

323
00:15:23,249 --> 00:15:26,979
work because you now have to Create
new questions and those also that

324
00:15:26,999 --> 00:15:28,429
also have to go through the system.

325
00:15:28,749 --> 00:15:30,519
And so it's a little bit
challenging to deal with.

326
00:15:31,019 --> 00:15:33,009
Now, when I started to present
some of these findings, just

327
00:15:33,009 --> 00:15:34,799
about the questions themselves.

328
00:15:34,839 --> 00:15:38,629
Now, this is just technical questions
like solving the code puzzle.

329
00:15:38,899 --> 00:15:40,109
that's just one lens of this.

330
00:15:40,389 --> 00:15:43,339
And I was getting frustrated that I
wasn't getting enough attention around it.

331
00:15:43,649 --> 00:15:48,599
So in winter of 2022 into, January
2023, the plot starts to thicken as

332
00:15:48,599 --> 00:15:49,999
I'm spreading this knowledge around.

333
00:15:50,499 --> 00:15:50,779
All right.

334
00:15:50,989 --> 00:15:54,319
So let's break the context before we get
into the thickening of the plot, right?

335
00:15:54,319 --> 00:15:56,229
So we got like the great resignation.

336
00:15:56,519 --> 00:15:58,629
We got big tech, drinking our milkshake.

337
00:15:58,809 --> 00:16:00,189
We got these fraudulent candidates.

338
00:16:00,189 --> 00:16:03,189
We got some automated testing
that's really not so great.

339
00:16:03,239 --> 00:16:04,789
it's good, but it really could be better.

340
00:16:05,009 --> 00:16:08,219
And then we got this challenge
of also being on prem, right?

341
00:16:08,219 --> 00:16:11,239
we as an organization that one
I work for really want people

342
00:16:11,259 --> 00:16:12,669
in the locality that we're in.

343
00:16:12,889 --> 00:16:16,279
and that's important to us to build up
the community that we're operating in.

344
00:16:16,969 --> 00:16:21,229
And so these things are just filtering
out really good candidates and it's

345
00:16:21,229 --> 00:16:24,559
really becoming problematic to find
the right people for the organization.

346
00:16:25,059 --> 00:16:27,999
So now it's time for some creative
problem solving like I'm expressing the

347
00:16:27,999 --> 00:16:32,829
frustration and I happen to be speaking
at a conference in the middle of Ohio

348
00:16:32,959 --> 00:16:35,869
in the winter, middle of nowhere, right?

349
00:16:35,869 --> 00:16:38,949
Snow all around and we're at
this convention and it's a

350
00:16:38,949 --> 00:16:40,059
big technology conference.

351
00:16:40,449 --> 00:16:45,379
four day conference and on one end is
the conference hall and the other end

352
00:16:45,389 --> 00:16:49,169
is like a resort side of hotel rooms and
in between is a bunch of restaurants.

353
00:16:49,169 --> 00:16:51,789
And so I'm walking from the
conference center to my bedroom.

354
00:16:51,789 --> 00:16:52,359
It's late at night.

355
00:16:52,359 --> 00:16:54,259
It's 10 something at
night and I'm just done.

356
00:16:54,259 --> 00:16:55,519
We have an early day the next day.

357
00:16:56,304 --> 00:17:00,624
And so one of my, one of my buddies
who actually, is part of this,

358
00:17:01,004 --> 00:17:04,034
he was a speaker and he said,
Hey Dan, I want to talk to you.

359
00:17:04,034 --> 00:17:06,024
And I'm like, no buddy, like I'm tired.

360
00:17:06,044 --> 00:17:07,004
I'm ready to go to bed.

361
00:17:07,014 --> 00:17:08,834
And he's Hey, I'll buy you a drink.

362
00:17:08,854 --> 00:17:09,544
I'm like, okay, fine.

363
00:17:09,764 --> 00:17:10,994
So let's go ahead and have a talk.

364
00:17:10,994 --> 00:17:14,324
And so he was talking about my
frustrations and he said, look,

365
00:17:14,334 --> 00:17:15,894
Dan, I've got a proposition.

366
00:17:16,394 --> 00:17:21,054
I think you've done an amazing thing with
this test, and I think we need to build

367
00:17:21,054 --> 00:17:24,374
some content on this and start talking
about this more and help bring better

368
00:17:24,374 --> 00:17:30,264
awareness about fraud as a vector and
how or how generative AI can be a vector

369
00:17:30,284 --> 00:17:34,314
and fraudulent candidate hiring and
how we can improve the overall process.

370
00:17:34,864 --> 00:17:36,544
He's a man of science
and I'm a man of science.

371
00:17:36,544 --> 00:17:40,394
He said, look, let's create a process
and let's talk about this candidate.

372
00:17:40,394 --> 00:17:42,574
And so we started figuring
out names for his candidate.

373
00:17:43,209 --> 00:17:47,329
And we called him Chet Gupta,
which is a play on ChatGPT.

374
00:17:48,089 --> 00:17:49,339
And that was the name, Chet.

375
00:17:49,379 --> 00:17:51,839
It's like a Texas chat, and so
we were like, we like that name.

376
00:17:52,139 --> 00:17:55,689
And then, couldn't figure out a
whole name for GPT, so we got Gupta.

377
00:17:56,049 --> 00:18:00,569
And we, we started plotting
this out over a napkin.

378
00:18:01,309 --> 00:18:03,819
At a conference, and we figured
we chop this around and figure

379
00:18:03,819 --> 00:18:05,229
out what is this worth doing.

380
00:18:05,449 --> 00:18:07,969
And as it turns out, this turns
out to be a really good set of

381
00:18:07,969 --> 00:18:09,459
materials over the long term.

382
00:18:09,739 --> 00:18:11,259
A lot of people have had interest in this.

383
00:18:11,289 --> 00:18:14,909
I've spoken this particular talk
at multiple conferences nationally,

384
00:18:14,919 --> 00:18:18,889
and it's been a great talk to bring
awareness, but with that, we wanted

385
00:18:18,889 --> 00:18:20,649
to find a process that's repeatable.

386
00:18:20,649 --> 00:18:22,829
So you can bring it to your
organization and try it.

387
00:18:23,209 --> 00:18:26,189
for different human centered processes,
not just talent acquisition, but

388
00:18:27,019 --> 00:18:28,249
we wanted to create a persona.

389
00:18:28,629 --> 00:18:31,699
Now, when we initially started
this, we looked at using, LinkedIn

390
00:18:31,699 --> 00:18:33,059
and creating a fake profile.

391
00:18:33,319 --> 00:18:34,739
It turns out it's frowned upon.

392
00:18:34,739 --> 00:18:35,789
So we didn't do that.

393
00:18:36,199 --> 00:18:40,319
We did, generate some AI bio pictures
that we wanted to be a part of that

394
00:18:40,319 --> 00:18:43,569
persona as we were pregaming before we
made that decision to not use LinkedIn.

395
00:18:43,829 --> 00:18:45,099
So we're going to go through
that in a little bit.

396
00:18:45,859 --> 00:18:47,319
We want to run the test problem.

397
00:18:47,319 --> 00:18:49,329
So I hadn't done a lot of this research.

398
00:18:49,329 --> 00:18:52,639
I wanted to run some more problems
through, through, chat TPT, as

399
00:18:52,639 --> 00:18:55,379
well as co pilot that was the new
hotness at the time, See if it

400
00:18:55,379 --> 00:18:56,679
can solve the problems for us.

401
00:18:57,069 --> 00:18:59,809
And then I want to prompt some of
the technical screen questions.

402
00:18:59,809 --> 00:19:03,579
These are the things like your, your data
structures, your algorithms, what do how

403
00:19:03,579 --> 00:19:06,769
do you apply a particular object oriented
pattern versus a functional pattern?

404
00:19:06,809 --> 00:19:07,519
What not right.

405
00:19:07,579 --> 00:19:10,009
At this point, we're, we're, it's
getting late and we're talking through

406
00:19:10,009 --> 00:19:12,989
the process and we said, Hey, look,
maybe we want to start bringing

407
00:19:12,989 --> 00:19:14,559
talent acquisition along for the ride.

408
00:19:14,559 --> 00:19:17,989
Now, as it turns out, somebody from our
talent acquisition department was there.

409
00:19:18,279 --> 00:19:22,539
And so we're able to pull them in,
collude with them a little bit on how

410
00:19:22,539 --> 00:19:23,949
we're going to go about this process.

411
00:19:24,009 --> 00:19:27,489
And we, we wanted to have the shock
and awe with a larger group, but

412
00:19:27,719 --> 00:19:29,969
we really wanted to understand the
process a little bit more and bring

413
00:19:29,969 --> 00:19:31,219
them to our side of the table.

414
00:19:31,889 --> 00:19:34,229
Because we didn't want to
attack talent acquisition.

415
00:19:34,229 --> 00:19:37,319
We just want to make sure that
we're addressing a conflict in the

416
00:19:37,319 --> 00:19:38,739
process and how to manage that.

417
00:19:39,309 --> 00:19:42,699
And then we were we decided after
that we would perform the competency

418
00:19:42,699 --> 00:19:46,129
based interviews questions,
which is Are a little different

419
00:19:46,139 --> 00:19:47,459
than our technology questions.

420
00:19:47,479 --> 00:19:48,679
They're more situational.

421
00:19:48,679 --> 00:19:49,539
They're less technical.

422
00:19:49,539 --> 00:19:52,749
And we wanted to see how chat
TPT would respond to that.

423
00:19:53,589 --> 00:19:55,859
And then ultimately, we wanted to
do is bundle this up together as a

424
00:19:55,859 --> 00:19:59,259
nice little package and present it
to our talent acquisition department

425
00:19:59,269 --> 00:20:02,199
to see if we can make meaningful
change in the organization.

426
00:20:02,699 --> 00:20:03,019
All right.

427
00:20:03,519 --> 00:20:04,879
So these are the chats.

428
00:20:05,379 --> 00:20:08,549
So all of these were generated,
I believe, using Dolly, just

429
00:20:08,549 --> 00:20:10,139
like the Lorax picture before.

430
00:20:10,359 --> 00:20:14,139
and so the prompt here was, Create
using dramatic lighting, create a

431
00:20:14,139 --> 00:20:17,969
LinkedIn profile bio picture for a
software engineer named Chet Gupta.

432
00:20:18,579 --> 00:20:19,379
That was it.

433
00:20:19,699 --> 00:20:22,809
Now, when that happened, we
got 300 gentlemen who are

434
00:20:22,809 --> 00:20:24,009
represented on the screen.

435
00:20:24,349 --> 00:20:26,609
And I said, Hey, look, at some
point during these conferences.

436
00:20:27,374 --> 00:20:29,924
I started to realize that Gupta
introduced some bias into the

437
00:20:29,924 --> 00:20:33,594
system, and so I removed the word
Gupta, and then I got, these two

438
00:20:33,654 --> 00:20:35,424
Caucasian gentlemen here as well.

439
00:20:35,754 --> 00:20:38,304
now if you notice, again, there's
still bias in the system because

440
00:20:38,304 --> 00:20:41,764
all of the pictures that here
that are generated all have.

441
00:20:42,254 --> 00:20:46,364
Assume that software engineers have
shallow stubble and, and glasses

442
00:20:46,394 --> 00:20:50,124
and they pick white people and
Indian people based on the names,

443
00:20:50,124 --> 00:20:51,724
but, as a Hispanic man, right?

444
00:20:52,024 --> 00:20:53,814
I could be a chat too, right?

445
00:20:53,814 --> 00:20:54,954
So why not have a Hispanic chat?

446
00:20:55,014 --> 00:20:56,624
Anyway, there's bias in the system.

447
00:20:56,654 --> 00:20:57,294
It's there.

448
00:20:57,374 --> 00:20:59,634
It's something we need to
acknowledge at some point.

449
00:20:59,874 --> 00:21:01,654
But this is a system
that we're operating in.

450
00:21:01,774 --> 00:21:04,484
So we started to select the pictures here.

451
00:21:04,784 --> 00:21:07,934
And, so if we go from like
the top, like in the middle

452
00:21:07,934 --> 00:21:09,284
there, we said, Hey, this chat.

453
00:21:09,539 --> 00:21:13,980
This Chet Gupta, he looks like he's
a musician, like he plays jazz,

454
00:21:13,990 --> 00:21:17,370
music only drinks IPAs, maybe a
little pretentious, maybe he's not

455
00:21:17,370 --> 00:21:18,260
the person you want to deal with.

456
00:21:18,520 --> 00:21:20,890
so what about the guy on the far right?

457
00:21:21,140 --> 00:21:23,590
he looks like he runs, like
he's the CEO of a company.

458
00:21:23,590 --> 00:21:26,880
So we said, no, maybe we don't want to
use him because I'm inspired by him.

459
00:21:26,880 --> 00:21:28,000
He doesn't look like an employee.

460
00:21:28,500 --> 00:21:30,180
So what about the guy in the bottom left?

461
00:21:30,990 --> 00:21:34,520
as it turns out, he looks like a lot of
our other engineers as part of our group

462
00:21:34,540 --> 00:21:38,400
and it'd be too stereotypical there, but
he does, and it looks like just a guy we

463
00:21:38,400 --> 00:21:40,330
would hang out with on an everyday basis.

464
00:21:40,360 --> 00:21:42,300
Now, these were the three
candidates we had when we

465
00:21:42,300 --> 00:21:43,340
initially started this process.

466
00:21:43,350 --> 00:21:46,360
The two Caucasian gentlemen were just
an afterthought as we were given this.

467
00:21:46,360 --> 00:21:48,480
So we're really focused
on these three people.

468
00:21:49,300 --> 00:21:52,120
And so ultimately we selected
the guy in the bottom left.

469
00:21:52,420 --> 00:21:53,580
He's going to be Archette.

470
00:21:53,620 --> 00:21:55,580
And again, these pictures
are all generated.

471
00:21:55,580 --> 00:21:59,195
And When I first gave this talk,
we also had synthesized audio and

472
00:21:59,195 --> 00:22:00,335
now they're synthesized video.

473
00:22:00,335 --> 00:22:03,585
So the way that you can present this is
interesting because you don't need to

474
00:22:03,585 --> 00:22:06,845
have video that's rendered over time.

475
00:22:06,845 --> 00:22:09,515
It can be rendered in real time
and that's very interesting.

476
00:22:09,775 --> 00:22:12,815
You can have profile pictures that are
generated and send in LinkedIn profiles

477
00:22:12,815 --> 00:22:14,075
or even send in on resumes, right?

478
00:22:14,075 --> 00:22:15,855
They aren't the real candidate themselves.

479
00:22:15,965 --> 00:22:17,305
Also very interesting.

480
00:22:17,555 --> 00:22:19,615
But the bot guy in the bottom
left is the one we chose.

481
00:22:20,115 --> 00:22:21,555
Now the competency based interview.

482
00:22:21,555 --> 00:22:24,735
I want to talk about this one for a second
because we talked about the technology

483
00:22:24,735 --> 00:22:28,095
screen and technical assessments, but a
competency based interview is one where

484
00:22:28,095 --> 00:22:30,195
we're following a star shaped pattern.

485
00:22:30,825 --> 00:22:33,535
So we're looking for things
like your situation, your task,

486
00:22:33,735 --> 00:22:35,355
your action, and your result.

487
00:22:35,545 --> 00:22:38,905
We're not necessarily looking for how you,
for what technology you used, although

488
00:22:38,905 --> 00:22:41,025
it is important, but how you used it.

489
00:22:41,325 --> 00:22:45,535
Or maybe how you dealt with a difficult
situation or maybe challenging individuals

490
00:22:45,535 --> 00:22:48,895
on teams or maybe if you're late for a
project, but those kind of situations

491
00:22:48,895 --> 00:22:51,765
and how you overcame them, we want
to make sure you clearly define the

492
00:22:51,775 --> 00:22:55,235
problem set in the situation, the
task and the action and the result.

493
00:22:55,995 --> 00:22:59,465
So the framing is really important
because communication is very

494
00:22:59,465 --> 00:23:00,955
important when we're hiring people.

495
00:23:01,455 --> 00:23:01,635
All right.

496
00:23:01,635 --> 00:23:03,905
So we asked chat or chat GPT.

497
00:23:04,815 --> 00:23:08,135
when were you on a team
that face challenges?

498
00:23:08,275 --> 00:23:13,045
And so the response that we got
back was, one of the main challenges

499
00:23:13,045 --> 00:23:14,195
we faced was communication.

500
00:23:14,645 --> 00:23:17,190
We had a feature that involved
multiple components and the

501
00:23:17,190 --> 00:23:18,170
interactions between them.

502
00:23:18,170 --> 00:23:21,930
And it requires close collaboration
between the team members to ensure

503
00:23:21,930 --> 00:23:23,460
that everyone is on the same page.

504
00:23:23,980 --> 00:23:27,410
However, due to different work schedules,
time zones and communication styles,

505
00:23:27,750 --> 00:23:31,870
Some team members found it challenging to
keep up with updates and changes, leading

506
00:23:31,870 --> 00:23:34,320
to confusion and misunderstandings.

507
00:23:34,980 --> 00:23:36,750
Another challenge we faced was technical.

508
00:23:37,160 --> 00:23:40,290
The feature requires integrating
with a third party API that's poorly

509
00:23:40,290 --> 00:23:41,920
documented and difficult to use.

510
00:23:42,330 --> 00:23:45,370
And some of those team members
lacked experience with the API and

511
00:23:45,380 --> 00:23:48,800
struggled to understand its nuances,
leading to delays and errors.

512
00:23:49,190 --> 00:23:53,870
To overcome these challenges, I, Chet
Gupta, decided to take several steps.

513
00:23:54,300 --> 00:23:57,470
First, I organized daily stand up
meetings to ensure that everyone is

514
00:23:57,470 --> 00:23:59,570
aligned on the process and any blockers.

515
00:23:59,910 --> 00:24:03,210
Second, I introduced task management
tools like JIRA or Trello to track

516
00:24:03,210 --> 00:24:04,960
progress and maintain transparency.

517
00:24:05,270 --> 00:24:09,110
And third, I paired up team members
with varying levels of expertise with

518
00:24:09,110 --> 00:24:13,270
the API to ensure that everyone has a
solid understanding of how it works.

519
00:24:13,510 --> 00:24:16,420
And then by taking these steps,
we successfully overcame the

520
00:24:16,420 --> 00:24:19,790
challenges and helped the team
achieve its goal of delivering

521
00:24:19,800 --> 00:24:21,915
the new feature By the deadline.

522
00:24:22,415 --> 00:24:26,675
Now, some of you are going to have
two different answers to this, right?

523
00:24:26,685 --> 00:24:28,635
Some of you are going to
say, this is a great answer.

524
00:24:28,635 --> 00:24:28,955
Wow.

525
00:24:28,955 --> 00:24:31,065
This is well thought
through and it's amazing.

526
00:24:31,065 --> 00:24:32,095
And actually it really is.

527
00:24:32,095 --> 00:24:34,065
This is a really great situation.

528
00:24:34,105 --> 00:24:36,625
Task action result of this.

529
00:24:36,625 --> 00:24:37,755
This question is prompting.

530
00:24:38,545 --> 00:24:41,715
The other ones may say, Hey,
look, this person invented agile.

531
00:24:41,905 --> 00:24:44,225
It's already been invented,
which is also true.

532
00:24:44,225 --> 00:24:45,525
But believe it or not, we get this a lot.

533
00:24:45,535 --> 00:24:47,355
A lot of candidates come in and we'll say.

534
00:24:48,340 --> 00:24:50,650
They're not familiar with Agile, they're
working with organizations that have

535
00:24:50,650 --> 00:24:54,750
only used parts of it, or parts of
maybe a larger framework, and, so they

536
00:24:54,750 --> 00:24:58,110
don't have maybe a total experience or
a total lens on the things that we're

537
00:24:58,170 --> 00:25:00,430
necessarily looking for, and That's okay.

538
00:25:00,450 --> 00:25:03,080
And it's okay to have that
background just because Agile

539
00:25:03,080 --> 00:25:05,270
is supposed to be appropriate
for the context that you're in.

540
00:25:05,570 --> 00:25:08,750
And so it's okay to not have like
maybe a larger understanding of it

541
00:25:08,760 --> 00:25:10,040
or maybe a different set of tools.

542
00:25:10,040 --> 00:25:11,300
Not everybody uses Jira or Trello.

543
00:25:11,710 --> 00:25:12,510
So it's totally okay.

544
00:25:13,010 --> 00:25:15,660
So let's ask maybe a technical question.

545
00:25:16,380 --> 00:25:19,840
Right now, technical interviews are, what
we want to understand is the breadth of

546
00:25:19,840 --> 00:25:22,610
experience across relevant technology.

547
00:25:22,610 --> 00:25:24,490
So this is how T shaped you are.

548
00:25:24,790 --> 00:25:27,460
And so for a full stack engineer who
needs to understand like front end,

549
00:25:27,740 --> 00:25:31,760
back end, maybe networking and gateways
and whatnot, databases, this is

550
00:25:31,780 --> 00:25:33,520
important, but they're very T shaped.

551
00:25:33,520 --> 00:25:37,360
they're wide in their acumen, but
they might not be super deep, but we

552
00:25:37,360 --> 00:25:38,620
do want to understand that as well.

553
00:25:38,620 --> 00:25:42,320
So we're looking for the depth of any
experience in any one technology, because

554
00:25:42,370 --> 00:25:46,570
we want to really understand, how deep or
why they are in a particular area relevant

555
00:25:46,580 --> 00:25:48,740
to the role that we're trying to hire for.

556
00:25:49,240 --> 00:25:52,390
And then we want to make sure that they're
exposed to various patterns and practices.

557
00:25:52,390 --> 00:25:55,710
We're going to cover concepts, like object
oriented patterns or design patterns.

558
00:25:56,020 --> 00:25:59,710
And we really want to figure out, what
is their total acumen, which is very

559
00:25:59,710 --> 00:26:02,530
hard to do in 45 minutes to an hour.

560
00:26:03,030 --> 00:26:05,560
And then the way that we do that
is through adaptive testing.

561
00:26:05,560 --> 00:26:09,780
So we start in an area, like maybe, like
a language like Java or C sharp, which

562
00:26:09,830 --> 00:26:13,290
the questions will get harder and harder
or design pattern or something like,

563
00:26:13,300 --> 00:26:15,200
solid, single responsibility and whatnot.

564
00:26:15,220 --> 00:26:18,150
We'll go through those into harder
concepts, like into like domain

565
00:26:18,150 --> 00:26:21,460
driven design, general responsibility,
assignment principles and whatnot.

566
00:26:21,830 --> 00:26:24,850
But the goal of that technical interviews
to understand against the rubric, how

567
00:26:24,850 --> 00:26:28,850
this candidate sits, how deep and why
they are, because, it's very challenging

568
00:26:28,850 --> 00:26:30,140
to do, and we have to move quickly.

569
00:26:30,970 --> 00:26:32,800
So the adaptive testing
model works well for us.

570
00:26:33,300 --> 00:26:35,770
So one of the, one of the questions
we have here is an algorithm.

571
00:26:35,770 --> 00:26:39,230
This is actually a retired question,
which is, In Java, write a function that

572
00:26:39,230 --> 00:26:41,190
determines if a given string is balanced.

573
00:26:41,250 --> 00:26:45,035
Basically, you want to determine
On it, if a string has, open parens

574
00:26:45,035 --> 00:26:47,901
and closed parens that there's,
if you send eight open parens,

575
00:26:47,921 --> 00:26:49,051
do you have eight closed parens?

576
00:26:49,591 --> 00:26:53,431
And the chat GPT response or the chat
Gupta response was the one that's

577
00:26:53,441 --> 00:26:55,661
posted here, which uses a stack.

578
00:26:56,011 --> 00:26:59,311
It's an algorithm, sorry, it's
a design, data structure that

579
00:26:59,321 --> 00:27:00,961
allows an object to come in first.

580
00:27:01,251 --> 00:27:03,941
and as you add more things, the top
most thing on that stack comes out as

581
00:27:03,941 --> 00:27:05,861
opposed to the first item coming out.

582
00:27:06,191 --> 00:27:08,321
And so a queue is the opposite of a stack.

583
00:27:08,561 --> 00:27:09,751
And that's first in, first out.

584
00:27:09,761 --> 00:27:11,161
Stacks are last in, first out.

585
00:27:11,851 --> 00:27:14,851
And so this is measuring the open paren.

586
00:27:14,851 --> 00:27:18,091
So every time an open paren comes
in, it adds something to the stack.

587
00:27:18,101 --> 00:27:20,571
And every time a closed paren
comes in, it removes something.

588
00:27:20,571 --> 00:27:23,211
And if you're at the end,
then the stack is empty.

589
00:27:23,531 --> 00:27:25,231
Now, is it a perfect answer?

590
00:27:25,271 --> 00:27:26,021
Probably not.

591
00:27:26,041 --> 00:27:26,771
Is it a good answer?

592
00:27:26,771 --> 00:27:27,661
Yeah, it's not bad.

593
00:27:27,661 --> 00:27:28,481
it solved the problem.

594
00:27:28,481 --> 00:27:31,911
And I think this is pretty fantastic in
terms of the response that we're getting.

595
00:27:32,411 --> 00:27:35,621
When we look at our rubric answer,
the answer is pretty similar,

596
00:27:35,621 --> 00:27:39,701
except we're using an integer based
accumulator to do that, calculation.

597
00:27:39,701 --> 00:27:43,171
So instead of maybe a more memory
intensive object like a stack, we're

598
00:27:43,171 --> 00:27:47,071
actually just using an accumulator to
say, every time an open parent comes in,

599
00:27:47,071 --> 00:27:50,481
we add something, and every time a closed
parent comes in, we remove something.

600
00:27:50,681 --> 00:27:53,911
And if we're at zero by the time
we're done, instead of negative or

601
00:27:53,911 --> 00:27:55,531
positive, then everything's fine.

602
00:27:55,921 --> 00:27:58,151
Effectively chasing the
same results, right?

603
00:27:58,151 --> 00:28:01,381
And so these are good answers are good
enough answers, especially if you're

604
00:28:01,391 --> 00:28:02,661
dealing with more junior engineer.

605
00:28:03,001 --> 00:28:07,381
So this starting to look like chat
GPT is not a bad candidate, right?

606
00:28:07,381 --> 00:28:11,441
We got our questions that
we're asking about competency.

607
00:28:11,441 --> 00:28:13,926
We got our algorithm question
that's being asked very well.

608
00:28:13,926 --> 00:28:17,108
All right, maybe let's ask some
slightly harder questions or maybe

609
00:28:17,108 --> 00:28:19,711
some data structure questions
that are a little different.

610
00:28:20,691 --> 00:28:23,831
So one of the things that we wanted
to ask for was, could you explain

611
00:28:23,831 --> 00:28:25,261
what a concurrent hash map is?

612
00:28:26,126 --> 00:28:29,346
And this is a Java centric, data
structure, for the most part.

613
00:28:29,606 --> 00:28:31,806
And a concurrent HashMap.

614
00:28:32,416 --> 00:28:35,316
As he responds, it's a data structure
that allows multiple threads to read

615
00:28:35,316 --> 00:28:39,846
and write key value pairs simultaneously
without inconsistency or race conditions.

616
00:28:40,086 --> 00:28:43,806
In a typical hash map, when two threads
try to access and modify the same

617
00:28:43,806 --> 00:28:46,846
key value pair concurrently, a race
condition occurs, leading to data

618
00:28:46,846 --> 00:28:48,636
inconsistency or even program crashes.

619
00:28:49,136 --> 00:28:52,906
However, a concurrent hash map
uses a mechanism called locking

620
00:28:52,906 --> 00:28:56,486
or synchronization to ensure that
multiple threads can access and modify

621
00:28:56,486 --> 00:28:59,606
different parts of the hash map at
the same time without conflicts.

622
00:29:00,396 --> 00:29:03,196
And in a concurrent hash map,
The data is divided into buckets.

623
00:29:03,236 --> 00:29:04,596
Each bucket has its own lock.

624
00:29:04,816 --> 00:29:08,526
And when a thread wants to read or
write a key value pair, within that,

625
00:29:08,546 --> 00:29:11,546
it first locks the corresponding
bucket so that no other thread

626
00:29:11,576 --> 00:29:13,116
can access it at the same time.

627
00:29:13,456 --> 00:29:17,046
And then once one thread is done,
it unlocks the bucket so that

628
00:29:17,056 --> 00:29:18,266
another thread can access it.

629
00:29:18,856 --> 00:29:22,346
And this mechanism allows multiple
threads to access and modify different

630
00:29:22,346 --> 00:29:23,676
parts of the HashMap concurrently.

631
00:29:23,676 --> 00:29:25,736
So this is a great explanation so far.

632
00:29:25,736 --> 00:29:28,256
Very wordy, and I'm sorry for the
wall of text, but that's how it is.

633
00:29:28,951 --> 00:29:30,801
What's interesting is
what's happening next.

634
00:29:31,771 --> 00:29:34,771
So Now it starts negotiating trade off.

635
00:29:34,781 --> 00:29:36,561
So it also responds.

636
00:29:36,571 --> 00:29:40,401
However, it is important to note that
locking and synchronization mechanisms

637
00:29:40,411 --> 00:29:44,181
can introduce some overhead and decrease
the performance of the data structure,

638
00:29:44,621 --> 00:29:47,961
especially when the number of threads
and the size of the hash map is large.

639
00:29:48,441 --> 00:29:51,491
Now, when you're dealing with the
software engineer, like this is important

640
00:29:51,501 --> 00:29:55,576
because we want to understand, can
they look at the design, Patterns of

641
00:29:55,786 --> 00:29:58,586
the way that they're going through
the creational process and say, is

642
00:29:58,586 --> 00:30:00,226
this the right tool for the job?

643
00:30:00,496 --> 00:30:03,276
And so the ability to evaluate a data
structure and say, it's the right

644
00:30:03,276 --> 00:30:04,626
tool for the job is super important.

645
00:30:04,626 --> 00:30:08,576
And it's growing more and more important
as we look at the kinds of algorithms

646
00:30:08,576 --> 00:30:12,766
and structures that we would use for
AI and maybe a B tree for one kind

647
00:30:12,766 --> 00:30:16,826
of problem or a KNN, algorithm for
another and how we want to manage

648
00:30:16,826 --> 00:30:18,226
our grouping and our correlation.

649
00:30:18,226 --> 00:30:22,086
So there's a lot of different, just
because you know an algorithm doesn't mean

650
00:30:22,326 --> 00:30:23,476
that it's the right algorithm for the job.

651
00:30:23,476 --> 00:30:25,746
There's a lot of different ways to
apply them, so it's important to

652
00:30:25,746 --> 00:30:27,416
understand how they sit in context.

653
00:30:27,466 --> 00:30:32,896
ChatGPT is providing a contextual based
evaluation of a particular data structure.

654
00:30:33,226 --> 00:30:35,886
This is valuable as an engineer.

655
00:30:35,886 --> 00:30:37,926
It's valuable for a
candidate to understand.

656
00:30:38,426 --> 00:30:40,546
as I got into this, there were
some things that started to

657
00:30:40,546 --> 00:30:42,696
get pretty stinkin interesting.

658
00:30:43,676 --> 00:30:47,866
So if we look at the results that
we're getting, so the one on the

659
00:30:47,866 --> 00:30:51,957
right is the organization's kind of
rubric response that we're looking for

660
00:30:51,957 --> 00:30:55,637
something along this lines and the one
on the left is the one that chat GPT

661
00:30:55,637 --> 00:30:59,427
gave us and as I'm starting to evaluate
this, I'm looking for common themes.

662
00:30:59,427 --> 00:31:02,427
So I've color coded them, like for
to say, these are the common themes

663
00:31:02,427 --> 00:31:04,247
where we have something going on.

664
00:31:04,247 --> 00:31:07,417
So in our answer, we segment or
internal data structure for locking

665
00:31:07,707 --> 00:31:09,217
where they use the word buckets.

666
00:31:09,217 --> 00:31:10,567
And I think it's analogous, right?

667
00:31:10,827 --> 00:31:14,117
but what gets interesting
is how, what happens next.

668
00:31:14,157 --> 00:31:20,367
So as I started to dive into this, We can
see the last piece that we were looking

669
00:31:20,367 --> 00:31:23,457
for is that their answer says it locks
a corresponding bucket and in ours it

670
00:31:23,457 --> 00:31:25,177
says it does it without locking at all.

671
00:31:25,707 --> 00:31:27,667
So I decided to go ahead
and do some research.

672
00:31:28,247 --> 00:31:29,127
Which answer is right?

673
00:31:29,667 --> 00:31:30,327
I need to know, right?

674
00:31:30,327 --> 00:31:32,337
I'm not necessarily a Java guy.

675
00:31:32,487 --> 00:31:34,077
I really focus on different languages.

676
00:31:34,167 --> 00:31:36,427
So I needed to go do a little
research to figure this out.

677
00:31:36,747 --> 00:31:41,807
And as it turns out, chat GPT, check
Gupta was more right than we were.

678
00:31:42,067 --> 00:31:44,077
This was starting to turn out
to be a very interesting thing.

679
00:31:44,077 --> 00:31:48,316
Our candidates were better at
development and being a better

680
00:31:48,316 --> 00:31:50,046
gatekeeper than we were for engineers.

681
00:31:50,446 --> 00:31:53,716
So some concerns and we started to
make some changes as a result of that.

682
00:31:54,216 --> 00:31:54,701
So cool.

683
00:31:55,191 --> 00:31:58,241
We've got this candidate now who's
answering questions very well.

684
00:31:58,411 --> 00:32:02,881
He's answering situational based
questions for teams very well.

685
00:32:03,131 --> 00:32:04,541
there was a lot of research about this.

686
00:32:04,851 --> 00:32:08,292
some of a lot of the questions when
they were being asked, they were It

687
00:32:08,292 --> 00:32:11,672
took longer to write the question than
it did for ChatGPT to respond to them.

688
00:32:11,672 --> 00:32:15,392
And that's crazy because now it creates
these opportunities where a person can

689
00:32:15,752 --> 00:32:20,072
read over it, gloss over it, provide
some human interjections, maybe some

690
00:32:20,072 --> 00:32:26,202
ums, or let me think for a second and
just natural inflection so it doesn't

691
00:32:26,202 --> 00:32:27,492
sound like a robot's reading it.

692
00:32:27,492 --> 00:32:28,952
And that's interesting.

693
00:32:29,452 --> 00:32:32,512
Now, when we think about prompting,
right at the time of this writing, it

694
00:32:32,512 --> 00:32:36,022
was a lot of it was based on just text
input, but you can also take audio

695
00:32:36,022 --> 00:32:39,642
input, do some transcription, live
transcription, which drops it into an

696
00:32:39,642 --> 00:32:42,002
API and does the same thing as well.

697
00:32:42,242 --> 00:32:46,442
So you don't need to have somebody
actually handwriting these promptings

698
00:32:46,702 --> 00:32:49,262
to give you the results of the
feedback that you're looking for.

699
00:32:49,932 --> 00:32:51,332
So let's talk through
some of these outcomes.

700
00:32:51,832 --> 00:32:52,022
All right.

701
00:32:52,022 --> 00:32:54,592
So first of all, we just,
this we're presented and

702
00:32:54,592 --> 00:32:55,752
bundled all this information.

703
00:32:56,022 --> 00:33:00,852
We decided that, we really need to have
a better awareness about, cheating that's

704
00:33:00,942 --> 00:33:03,742
occurring during our technical screens
and our competency based interviews.

705
00:33:03,812 --> 00:33:07,202
And we wanted to provide some education
and uplift to the organization to

706
00:33:07,202 --> 00:33:10,532
make sure that they were equipped with
the tools necessary to be able to do

707
00:33:10,582 --> 00:33:13,842
constructive interviews and root out
maybe toxic candidates who weren't

708
00:33:13,852 --> 00:33:15,242
be valuable for the organization.

709
00:33:15,742 --> 00:33:18,922
We also started looking at Ongro
and scrutiny of the vendors

710
00:33:18,922 --> 00:33:20,112
and how things were used.

711
00:33:20,907 --> 00:33:24,587
We had a sourcing vendor as a part of
this like conversations, particularly

712
00:33:24,587 --> 00:33:29,097
the one with the Lorax picture where
that candidate, that or that the sourcing

713
00:33:29,097 --> 00:33:32,827
agency, was actually we had suspicions
that they were providing candidates that

714
00:33:32,827 --> 00:33:34,177
weren't the right candidates for the job.

715
00:33:34,467 --> 00:33:38,287
ultimately, we ended up changing
our relationship with them because

716
00:33:38,307 --> 00:33:40,467
we realized that they were sending
us candidates that were fraudulent.

717
00:33:40,467 --> 00:33:41,717
And so it closed the gap there.

718
00:33:41,717 --> 00:33:42,887
That was a significant vector.

719
00:33:43,277 --> 00:33:44,776
And then we also looked at our candidates.

720
00:33:44,927 --> 00:33:46,737
Our testing tool to say,
is this the right tool?

721
00:33:46,747 --> 00:33:50,497
And so one of the interesting parts
about the testing tool was that we

722
00:33:50,597 --> 00:33:52,657
started asking questions about the test.

723
00:33:52,657 --> 00:33:54,897
I said, Hey, look, I don't think
these answers are the right answers.

724
00:33:55,637 --> 00:33:57,767
And and they said, I
said, everything's fine.

725
00:33:58,282 --> 00:33:59,952
The people who write the
test say everything's fine.

726
00:34:00,072 --> 00:34:00,932
It's not going to be an issue.

727
00:34:00,982 --> 00:34:02,452
So I said, okay, that's great.

728
00:34:02,522 --> 00:34:04,102
I'm not really sure it's
a good enough answer.

729
00:34:04,212 --> 00:34:05,352
Who writes the test?

730
00:34:05,672 --> 00:34:06,632
They said the vendor does.

731
00:34:07,132 --> 00:34:09,782
So I was screaming in font
ligatures at this point, right?

732
00:34:10,032 --> 00:34:13,562
And I said, okay, so the people
we pay to do their job are telling

733
00:34:13,562 --> 00:34:14,732
us there's nothing to see here.

734
00:34:14,982 --> 00:34:16,082
There's nothing to worry about.

735
00:34:16,282 --> 00:34:16,972
oh!

736
00:34:17,352 --> 00:34:18,832
Snap, we need to do something about this.

737
00:34:19,112 --> 00:34:22,132
So we met with the vendor, we
started talking through the tool,

738
00:34:22,192 --> 00:34:24,851
and we said, hey, look, what do
you guys think about generative AI?

739
00:34:24,852 --> 00:34:26,022
How are you guys navigating?

740
00:34:26,972 --> 00:34:30,532
And they were letting us know that they
love it, and they think it's great, and

741
00:34:30,532 --> 00:34:34,582
it's a powerful tool, and, it's hard to
test for, because it's non deterministic,

742
00:34:34,702 --> 00:34:38,042
which basically means that it's not going
to give you the same answer every time,

743
00:34:38,042 --> 00:34:41,772
and the facts play into the facts, so it
can give you new answers based on previous

744
00:34:41,772 --> 00:34:43,762
facts, and that's all very interesting.

745
00:34:44,507 --> 00:34:48,847
Except we pay for a tool that can
now be broken with generative AI.

746
00:34:48,847 --> 00:34:49,687
And this is a problem.

747
00:34:49,687 --> 00:34:51,507
So are we going to continue
to pay for this tool?

748
00:34:51,507 --> 00:34:54,957
So I said, what do you guys think
we should do with your tool if it's

749
00:34:54,957 --> 00:34:57,477
not satisfying the problems for
these cases that we have today?

750
00:34:57,477 --> 00:35:00,687
And they said, look, don't
use it as a complete stopgap.

751
00:35:01,517 --> 00:35:03,737
Why don't you go ahead
and proctor your tests?

752
00:35:03,967 --> 00:35:05,887
Now I told you we're interviewing
a lot of people, right?

753
00:35:05,917 --> 00:35:08,957
So I can't take my best engineers all day.

754
00:35:09,377 --> 00:35:10,757
Take them away from valuable work.

755
00:35:10,797 --> 00:35:13,467
They're contributing to the organization
to sit down and make sure if somebody

756
00:35:13,467 --> 00:35:18,517
is actually taking a test correctly,
so it becomes a big problem in terms

757
00:35:18,517 --> 00:35:23,207
of how we use our best people to
solve problems for the organization.

758
00:35:23,207 --> 00:35:26,937
So really take an extra scrutiny to
say this is the right tool for the job.

759
00:35:27,017 --> 00:35:28,411
And how are we going
to approach this tool?

760
00:35:29,142 --> 00:35:33,192
And so we had to look at changes to our
technical testing and we're still in

761
00:35:33,192 --> 00:35:37,212
evaluation for using things like public
facing repositories and we're leaving

762
00:35:37,212 --> 00:35:40,942
certain things up to the hiring managers
to say hey, if this test isn't appropriate

763
00:35:40,942 --> 00:35:42,162
for you, we might not introduce.

764
00:35:42,697 --> 00:35:46,597
This tested result as a way to bias
against a particular candidate.

765
00:35:46,837 --> 00:35:50,507
Maybe you want to use a different
mechanic or vehicle to make that happen.

766
00:35:51,007 --> 00:35:53,797
And the reality is our tools,
they're just not good enough, right?

767
00:35:53,797 --> 00:35:57,707
So tools in isolation, such as
our automated co testing tool,

768
00:35:58,047 --> 00:35:59,497
it's an ineffective stopgap.

769
00:36:00,337 --> 00:36:02,716
But that aside, there's also
other challenges, right?

770
00:36:02,717 --> 00:36:06,687
Our adaptive testing is no longer
an effective litmus because you're

771
00:36:06,687 --> 00:36:10,197
just one prompt away from being
able to get a well reasoned answer.

772
00:36:11,022 --> 00:36:14,112
And this is going to start to
require more social interaction

773
00:36:14,112 --> 00:36:15,562
to improve the feedback loop.

774
00:36:15,562 --> 00:36:19,642
So we can start getting better cues
about whether a person is, a bot or

775
00:36:19,642 --> 00:36:23,672
whether they're actually, a different
person in the audio or, there's somebody

776
00:36:23,672 --> 00:36:25,992
who's manipulating in some way, right?

777
00:36:25,992 --> 00:36:29,032
To get hired for whatever reason, right?

778
00:36:29,777 --> 00:36:32,737
So some things like, after giving
this conference a few times, I've

779
00:36:32,737 --> 00:36:35,367
heard certain different talent
acquisition folks say, I've seen this.

780
00:36:35,397 --> 00:36:36,117
This is crazy.

781
00:36:36,337 --> 00:36:38,947
And so what I've started doing
is using instructions on a post

782
00:36:38,947 --> 00:36:40,447
it note and having the candidate.

783
00:36:41,137 --> 00:36:44,457
Read the instruction on the Post it note
and provide the same response or just

784
00:36:44,547 --> 00:36:49,117
give a response to the note or provide a
visual cue on the Post it note or maybe

785
00:36:49,117 --> 00:36:52,687
some sort of like a notepad to say,
I want you to do this and then maybe

786
00:36:52,687 --> 00:36:55,817
look to the left or to the right, just
to see if they were the person who was

787
00:36:55,817 --> 00:36:58,277
actually seeing the content on the screen.

788
00:36:58,977 --> 00:37:01,372
And so that was very valuable feedback.

789
00:37:01,372 --> 00:37:04,387
And I think, we've started to
consider what it means to have.

790
00:37:04,742 --> 00:37:09,092
Better social interaction is cameras
on visual cues and whatnot in our

791
00:37:09,092 --> 00:37:12,852
feedback loop, but the tools themselves
in isolation are not good enough And so

792
00:37:12,852 --> 00:37:16,492
we're gonna have to get more creative
about the way we you know, we validate

793
00:37:16,502 --> 00:37:20,112
the legitimacy of a candidate We
have to consider that competency bit

794
00:37:20,122 --> 00:37:21,712
interviews at this point to as well.

795
00:37:21,982 --> 00:37:26,622
They can be framed with some light
prompting It doesn't take much For

796
00:37:26,632 --> 00:37:30,572
a candidate to drive contacts or
create some context behind the scenes.

797
00:37:30,572 --> 00:37:34,552
And as we were creating these competency
based questions, I think we went through

798
00:37:34,582 --> 00:37:37,592
for the CBI, probably 7 to 10 questions.

799
00:37:37,822 --> 00:37:43,002
and each one was pretty stinking good, to
be honest with you and, very long winded

800
00:37:43,002 --> 00:37:46,832
responses, which is, CBI typically only
has, It's an hour long conversation,

801
00:37:46,852 --> 00:37:48,552
typically has three to four questions.

802
00:37:48,562 --> 00:37:52,072
You want them to be long essay
kind of questions, and so you're

803
00:37:52,072 --> 00:37:54,122
getting a lot of rich, deep context.

804
00:37:54,622 --> 00:38:00,152
With light prompting, and that's really
challenging to navigate and quite frankly,

805
00:38:00,152 --> 00:38:03,752
we have seen the automated code test
can be easily solved with plenty of lead

806
00:38:03,752 --> 00:38:05,852
time to introduce those human elements.

807
00:38:05,902 --> 00:38:08,452
making mistakes or doing things
that kind of look close enough.

808
00:38:08,502 --> 00:38:11,692
these code tests typically will run and
they'll run with a bunch of unit tests

809
00:38:11,932 --> 00:38:15,952
and you'll find that some of these tests,
maybe 99 percent test coverage because

810
00:38:15,952 --> 00:38:18,522
they introduce a human element by design.

811
00:38:18,882 --> 00:38:21,892
Because they add the time to that
would allow them to be able to.

812
00:38:22,562 --> 00:38:23,412
To look human.

813
00:38:23,412 --> 00:38:25,642
They're not perfect solutions
or close enough solutions,

814
00:38:25,912 --> 00:38:26,922
and that's very interesting.

815
00:38:27,422 --> 00:38:29,382
And the text screens again
are just a prompt away from

816
00:38:29,382 --> 00:38:32,202
providing well reasoned examples.

817
00:38:32,702 --> 00:38:35,042
So what it would look like
if you wanted to try this.

818
00:38:35,092 --> 00:38:38,862
I think the first thing you need
to do is assume positive intent.

819
00:38:39,152 --> 00:38:41,072
hiring talent is not a
frictionless process.

820
00:38:41,112 --> 00:38:43,922
There's plenty of opportunities
to reduce the friction, but some

821
00:38:43,922 --> 00:38:45,172
of that friction is important.

822
00:38:45,562 --> 00:38:48,622
But just because it can be automated
doesn't mean it should be automated.

823
00:38:48,632 --> 00:38:51,682
And that's something we need to figure
out as we navigate a gen AI world.

824
00:38:51,742 --> 00:38:55,362
I once heard that AI in general
should be the best thing that

825
00:38:55,362 --> 00:38:58,322
happens for humans, not the worst
thing that happens to humans.

826
00:38:58,642 --> 00:39:02,262
And so I think it's important to just
be, pragmatic and appropriate when

827
00:39:02,262 --> 00:39:05,762
we apply automation and artificial
intelligence to our process.

828
00:39:06,572 --> 00:39:08,612
The next thing to do is
to lead with empathy.

829
00:39:08,792 --> 00:39:12,582
it can take months or years to
bring in tools that will help reduce

830
00:39:12,882 --> 00:39:14,442
this friction or things like toil.

831
00:39:14,912 --> 00:39:18,852
And in our case, it took a very long
time to bring this automated testing

832
00:39:18,852 --> 00:39:22,812
tool, which at the crest of its
mature implementation became highly

833
00:39:22,812 --> 00:39:24,757
exploitable using generative AI.

834
00:39:25,247 --> 00:39:27,227
And lastly, you are a second.

835
00:39:27,267 --> 00:39:30,267
Thirdly, you want to be able to
bring talent acquisition with you.

836
00:39:30,287 --> 00:39:33,347
It's better to work together to
address concerns than to attack a

837
00:39:33,347 --> 00:39:37,557
process or people group who created
that process such as a department.

838
00:39:37,927 --> 00:39:40,527
You really want to bring them along
for the ride and say, Hey, look, I

839
00:39:40,527 --> 00:39:42,897
think we might have an exploit vector.

840
00:39:43,167 --> 00:39:45,267
I want to suss this out with you.

841
00:39:45,507 --> 00:39:48,127
Can you help me understand
where your context is?

842
00:39:48,127 --> 00:39:50,917
And I'm going to show you where my
research is and we're going to work

843
00:39:50,917 --> 00:39:52,727
together to create a better process.

844
00:39:53,227 --> 00:39:55,047
And lastly, seek win outcomes.

845
00:39:55,047 --> 00:39:58,287
ultimately, you're looking
for an effective process.

846
00:39:58,627 --> 00:40:01,117
The person that you're going to hire,
especially if you're dealing with the

847
00:40:01,117 --> 00:40:03,827
talent acquisition process, the person
you're going to hire is going to spend

848
00:40:03,827 --> 00:40:06,497
about 1, 800 hours a year with you.

849
00:40:06,497 --> 00:40:08,067
That's the average amount of time a U.

850
00:40:08,067 --> 00:40:08,187
S.

851
00:40:08,207 --> 00:40:12,337
candidate will spend in office
or working with somebody, hybrid,

852
00:40:12,337 --> 00:40:14,407
remote, whatever, with your peers.

853
00:40:14,407 --> 00:40:16,487
And so if you're building a team, you
want to make sure you protect your team.

854
00:40:16,487 --> 00:40:18,997
That's a lot of time that
they're going to spend with them.

855
00:40:19,187 --> 00:40:22,157
You want to make sure that they're
the right candidate for the job.

856
00:40:22,657 --> 00:40:25,257
So if you do have any questions,
you're want to look at some of

857
00:40:25,257 --> 00:40:26,487
the research that we've done.

858
00:40:26,677 --> 00:40:28,197
I would, feel free to reach out to me.

859
00:40:28,207 --> 00:40:31,637
You can reach out to me by
email at DanielMprese at gmail.

860
00:40:31,637 --> 00:40:36,437
com or you can reach out to me on
LinkedIn at in slash Daniel Mprese.

861
00:40:36,697 --> 00:40:40,427
Thank you for taking the time today to sit
through this conversation and learn some

862
00:40:40,427 --> 00:40:42,437
more and hopefully you had a great time.

863
00:40:42,747 --> 00:40:44,247
Thank you again and have a great day.

