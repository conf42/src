1
00:00:01,500 --> 00:00:02,040
Hello all.

2
00:00:02,100 --> 00:00:03,240
I'm Nata Kala.

3
00:00:03,900 --> 00:00:08,130
As the presentation title states
Building Resilient Machine Learning Cloud

4
00:00:08,130 --> 00:00:13,110
integrations, a practical guide to secure,
scalable and cross platform architectures.

5
00:00:13,500 --> 00:00:17,320
Today we'll be seeing the robust,
practical guide for machine learning

6
00:00:17,320 --> 00:00:19,570
infrastructures that we have in place.

7
00:00:20,380 --> 00:00:23,740
Very first slide is talking
about multi-cloud reality.

8
00:00:23,980 --> 00:00:25,570
What exactly is multi-cloud?

9
00:00:26,075 --> 00:00:30,275
Machine learning is very much evolving
in today's world, as we all know.

10
00:00:30,625 --> 00:00:33,745
And to deploy machine learning solutions.

11
00:00:33,775 --> 00:00:37,765
All the companies are widely
using three plus cloud services.

12
00:00:38,435 --> 00:00:41,675
So it could be two plus, it
could be one plus but it is a

13
00:00:41,735 --> 00:00:43,145
multi-cloud, I would say overall.

14
00:00:44,225 --> 00:00:48,895
So using this multi-cloud cloud
solutions or cloud deployment

15
00:00:48,895 --> 00:00:51,385
models definitely has advantage.

16
00:00:51,684 --> 00:00:57,144
The very first advantage is that we
were able to get get over vendor lockin.

17
00:00:57,834 --> 00:01:00,175
So vendor lockin is no longer happening.

18
00:01:00,175 --> 00:01:01,134
That's great.

19
00:01:01,265 --> 00:01:06,205
But what is the con of this multiple cloud
services that we are incorporating into?

20
00:01:07,149 --> 00:01:09,940
Very firstly, operational efficiency.

21
00:01:10,389 --> 00:01:15,309
How about we going to operate the
instances of all these clouds and also

22
00:01:15,309 --> 00:01:21,160
we will be running into issues around
compliance and data security and privacy.

23
00:01:22,929 --> 00:01:29,450
The overall spendings into the cloud
by 2028 is going to cross 1 trillion.

24
00:01:30,080 --> 00:01:34,550
Just imagine that 10,000 companies
are today are trying to invest.

25
00:01:35,840 --> 00:01:40,040
Into multiple clouds, like 10,000
into three is already 30,000.

26
00:01:40,040 --> 00:01:44,080
And each of them pays their amount
depending on the scale of the solutions

27
00:01:44,080 --> 00:01:47,180
that they have in place that is like.

28
00:01:47,750 --> 00:01:49,280
A lot to be honest.

29
00:01:49,490 --> 00:01:53,760
And when we are trying to spend a
lot I think we have to make sure that

30
00:01:53,810 --> 00:01:57,500
whatever we try to spend is worthy.

31
00:01:57,980 --> 00:02:01,610
It's deployed in the right way and
the architecture is all array in

32
00:02:01,610 --> 00:02:03,350
the laid in the correct manner.

33
00:02:03,980 --> 00:02:08,330
And overall, today's
percentage is crossing 75%.

34
00:02:08,900 --> 00:02:11,840
So exactly to be more precise, it's 78%.

35
00:02:12,110 --> 00:02:16,700
So we have many ML deployments that
are taking place across multiple

36
00:02:16,700 --> 00:02:18,500
clouds and not through a single cloud.

37
00:02:20,670 --> 00:02:21,540
Let's move on.

38
00:02:22,320 --> 00:02:24,780
Let's take a look at
cloud deployment models.

39
00:02:24,840 --> 00:02:26,700
What all models do we have in place?

40
00:02:26,700 --> 00:02:32,160
We have infrastructure, we have platform,
and we have software as a service.

41
00:02:32,430 --> 00:02:35,370
So all these cloud models are widely used.

42
00:02:35,370 --> 00:02:39,075
For different purposes and
mostly infrastructure means that

43
00:02:39,105 --> 00:02:43,065
they have virtual machines and
networks for complete control over

44
00:02:43,115 --> 00:02:44,585
machine learning environments.

45
00:02:44,735 --> 00:02:48,515
So this is best for custom
frameworks and specialized workloads.

46
00:02:48,815 --> 00:02:54,775
And one of the major example in this area
is AWS EC2 have, they're going to, give

47
00:02:54,835 --> 00:02:56,635
all the machine learning solutions, right?

48
00:02:57,205 --> 00:03:00,835
And platform as a service
for platform as a service.

49
00:03:00,835 --> 00:03:04,985
We have AWS SageMaker in
place which is a good example.

50
00:03:04,985 --> 00:03:10,145
And also IBM Watson Studio, along
with Azure ML and Google Vertex ai.

51
00:03:10,655 --> 00:03:13,475
So this is very much useful
for development teams to

52
00:03:13,475 --> 00:03:14,975
focus on model creation.

53
00:03:15,545 --> 00:03:19,625
Mostly we'll be having all
the ML frameworks as managed.

54
00:03:19,860 --> 00:03:24,820
So we don't have to really worry about
building something from scratch because

55
00:03:24,820 --> 00:03:28,900
we already have all the building
built-in scaling that is enabled for us.

56
00:03:29,470 --> 00:03:31,060
Software as a service.

57
00:03:31,270 --> 00:03:36,720
Software as a service is something, so it
is using minimal minimal configuration.

58
00:03:36,870 --> 00:03:39,990
So it is definitely perfect
for specific use cases.

59
00:03:39,990 --> 00:03:45,290
For example, AWS recognition
and Azure Cognitive Services and

60
00:03:45,290 --> 00:03:48,930
global Vision AI are providing
very good service in this area.

61
00:03:49,290 --> 00:03:53,220
So all this minimal configuration
means that you can just drag and

62
00:03:53,220 --> 00:03:57,120
drop most of the components which
are out of boxing nature, all and out

63
00:03:57,120 --> 00:03:58,650
of boxing nature, and already built.

64
00:04:00,465 --> 00:04:03,195
Nextly ML API Integration procedures.

65
00:04:03,645 --> 00:04:07,875
Today we have a lot of
procedures that we are following.

66
00:04:08,235 --> 00:04:11,735
One is rest API, so rest
API is a very robust.

67
00:04:12,275 --> 00:04:17,805
API, it can be very much used by
mobiles and it's super lightweight.

68
00:04:17,805 --> 00:04:22,355
It is stateless architecture and all
the endpoints or all the callouts

69
00:04:22,385 --> 00:04:24,995
are made on HT TP based endpoints.

70
00:04:24,995 --> 00:04:27,095
So it is definitely secure.

71
00:04:27,485 --> 00:04:31,515
And also json and XML
responses are all accepted.

72
00:04:32,230 --> 00:04:37,520
That means that it can work with
wide architectures and it can work

73
00:04:37,590 --> 00:04:40,020
very easily with third party APIs.

74
00:04:40,050 --> 00:04:42,450
APIs and third party
coding frameworks as well.

75
00:04:43,710 --> 00:04:44,371
Nextly, GraphQL.

76
00:04:44,610 --> 00:04:47,570
So GraphQL is definitely growing.

77
00:04:48,695 --> 00:04:54,085
It also has a principles which are
similar to rest API and the flexible data

78
00:04:54,085 --> 00:04:56,745
queries option is available in GraphQL.

79
00:04:56,985 --> 00:05:02,265
So data retrieval will be very much very
much precise and also it is stateless

80
00:05:02,265 --> 00:05:05,145
and we'll still have a single endpoint.

81
00:05:05,205 --> 00:05:11,015
And the very much advantage of
GraphQL is that it is it has.

82
00:05:11,915 --> 00:05:14,965
Reduced the over fetching limit, right?

83
00:05:14,995 --> 00:05:17,365
So you don't have to over fetch the data.

84
00:05:17,695 --> 00:05:21,385
It is taking care of all the data
and giving us the right data we need.

85
00:05:21,385 --> 00:05:24,025
And also it is processing machine
learning in the right way.

86
00:05:24,515 --> 00:05:28,065
So this GraphQL has been recently
integrated with Salesforce.

87
00:05:28,065 --> 00:05:30,525
Salesforce is one of the
software as a service.

88
00:05:31,245 --> 00:05:31,905
Platform.

89
00:05:32,265 --> 00:05:37,655
And it is mostly used on the JavaScript
side of things, and it is very much

90
00:05:37,775 --> 00:05:40,805
robust in connecting to the server
and getting all the data that we need.

91
00:05:42,320 --> 00:05:42,830
Next slide.

92
00:05:42,830 --> 00:05:43,760
GRPC.

93
00:05:44,030 --> 00:05:47,210
It is a high performance, binary
communication communication

94
00:05:47,210 --> 00:05:50,810
integration approach that we take,
and mostly it'll help us with the

95
00:05:50,810 --> 00:05:52,190
streaming support that we need.

96
00:05:52,190 --> 00:05:55,170
And also the latency is very
low making, is very marrying,

97
00:05:55,290 --> 00:05:56,640
making it very advantaged.

98
00:05:56,860 --> 00:05:58,540
For handling large volumes of data.

99
00:05:59,140 --> 00:06:01,690
And last but not least, is event driven.

100
00:06:02,020 --> 00:06:07,020
This is very much required to make
sure that all the asynchronous

101
00:06:07,155 --> 00:06:11,045
machine learning are processing
at scale because it handles.

102
00:06:11,360 --> 00:06:15,040
Super large data volumes,
millions and billions of data.

103
00:06:15,430 --> 00:06:19,235
And also one of the main one of the
major example in this area is publish

104
00:06:19,235 --> 00:06:23,785
subscribe, pattern Q based processing,
which is a synchronous in nature.

105
00:06:23,785 --> 00:06:27,655
And also we do have serverless
triggers, which is more advantages.

106
00:06:27,895 --> 00:06:32,605
So by using the right API procedures,
we can definitely improve the

107
00:06:32,605 --> 00:06:35,250
efficiency of overall overall model.

108
00:06:36,820 --> 00:06:40,210
And Nextly Identity and access management.

109
00:06:40,510 --> 00:06:46,570
We were talking about security breaches
and potential issues around identity.

110
00:06:46,840 --> 00:06:55,050
So this is this model has a pyramid shown
here in the image and from bottom to top.

111
00:06:55,875 --> 00:07:00,255
If you can look at it, the top
is having least privilege access.

112
00:07:00,255 --> 00:07:03,735
That means you are minimizing
all the permissions to

113
00:07:03,735 --> 00:07:06,135
what's absolutely necessary.

114
00:07:06,135 --> 00:07:13,425
Only so least privilege Access is mostly
preferred and multi-factor authentication

115
00:07:13,425 --> 00:07:16,785
and role-based and centralized identity.

116
00:07:17,115 --> 00:07:21,135
All of these factors should be
considered when we are designing a model.

117
00:07:21,555 --> 00:07:24,375
The implementation implementations.

118
00:07:25,155 --> 00:07:30,265
With organizations, with implementations
of IAM definitely we'll be

119
00:07:30,265 --> 00:07:33,325
reporting less than 50% breach cost.

120
00:07:33,595 --> 00:07:36,135
So we just need to
implement it in a right way.

121
00:07:36,495 --> 00:07:41,355
And I think that role-based
multifactor and centralized identity,

122
00:07:41,625 --> 00:07:46,785
so for example, your resellers can
definitely get a centralized identity

123
00:07:46,785 --> 00:07:50,595
and multifactor authentication,
but have a guest user is trying to.

124
00:07:50,640 --> 00:07:51,840
Access the application.

125
00:07:51,840 --> 00:07:55,650
Our overall model is where the
where the issue comes from.

126
00:07:55,650 --> 00:07:58,810
We have to manage it depending
on the type of the user who is

127
00:07:58,810 --> 00:08:00,370
trying to access the application.

128
00:08:00,910 --> 00:08:03,400
And nextly zero trust, security model.

129
00:08:04,240 --> 00:08:08,990
That means do not trust, just keep
validating and validating every time

130
00:08:08,990 --> 00:08:14,725
you try to, or you try to make a.
Trust to, it could be to a person or

131
00:08:14,725 --> 00:08:17,015
it could be to an, to other device.

132
00:08:17,885 --> 00:08:19,445
So firstly, yes.

133
00:08:19,485 --> 00:08:26,025
Verify identity, authenticate every
user, and service accessing ML resources.

134
00:08:26,025 --> 00:08:28,165
That's very much necessary.

135
00:08:28,465 --> 00:08:31,495
And nextly, you have to validate
the device as we discussed.

136
00:08:31,555 --> 00:08:33,145
So keep checking the device.

137
00:08:33,145 --> 00:08:36,925
It could be via any kind of authentication
practices that we discussed in the

138
00:08:36,925 --> 00:08:39,565
past slide, and a limit access just.

139
00:08:40,055 --> 00:08:44,515
Provide just in time, just enough
permissions, usually for limiting access.

140
00:08:44,515 --> 00:08:47,535
We also have many handlers
in place that we can use.

141
00:08:47,775 --> 00:08:52,245
In the models we can incorporate
them and nextly monitor activity.

142
00:08:52,425 --> 00:08:58,205
So continuously do event monitoring to
analyze the behavior for anomaly, analyze

143
00:08:58,205 --> 00:09:02,365
the behavior for fraud detection, and
also anom, analyze anom, analyze it for

144
00:09:02,365 --> 00:09:06,345
most of the issues related to duplicates.

145
00:09:07,455 --> 00:09:11,365
So all these anomalies need to be
identified in the right manner and at

146
00:09:11,365 --> 00:09:15,445
every step I would strongly recommend
us to have monitoring activity.

147
00:09:15,625 --> 00:09:20,005
It could be via interactive dashboard,
it could be via report, but this is

148
00:09:20,005 --> 00:09:24,075
very much necessary and most of the
platforms are also providing this

149
00:09:24,075 --> 00:09:25,725
out of box which we can leverage.

150
00:09:27,240 --> 00:09:32,320
I think zero trust definitely
eliminates the implicit trust from

151
00:09:32,320 --> 00:09:33,970
machine learning architectures.

152
00:09:34,270 --> 00:09:36,760
Every request must be
verified regardless of source.

153
00:09:37,975 --> 00:09:42,655
And training data production this
is very much vital for us to get

154
00:09:42,655 --> 00:09:46,875
rid of all the privacy concerns
that especially we have in place.

155
00:09:47,325 --> 00:09:50,115
So end-to-end encryption
is very much needed.

156
00:09:50,325 --> 00:09:54,645
So we have to make sure all the
ML data in transit addressed.

157
00:09:55,035 --> 00:09:57,945
And in use is encrypted correctly.

158
00:09:58,125 --> 00:10:00,345
So we have to include
all the key rotation.

159
00:10:00,345 --> 00:10:04,285
We have to include all the
shark keys, SHA keys all the

160
00:10:04,285 --> 00:10:06,055
encryption practices in place.

161
00:10:06,055 --> 00:10:09,874
And very much as, as much as we can try
to serialize and also keep it keep it

162
00:10:10,024 --> 00:10:15,844
secure via key authentic authenticated
key and data sovereignty controls.

163
00:10:15,874 --> 00:10:20,474
So mostly if we have to respect
the geographical data restrictions,

164
00:10:20,554 --> 00:10:24,424
through regional storage, we have
to implement cross border transfer

165
00:10:24,424 --> 00:10:26,104
mechanisms whenever necessary.

166
00:10:26,614 --> 00:10:28,534
And dataset access monitoring.

167
00:10:28,744 --> 00:10:32,434
We have to track all the interactions
with training data, implement.

168
00:10:33,004 --> 00:10:38,284
Alerting for unusual access patterns
that might indicate data leakage.

169
00:10:38,534 --> 00:10:42,554
Data leakage can happen at any
point of time if we do not have

170
00:10:42,774 --> 00:10:46,124
proper dataset access monitoring
techniques laid in place.

171
00:10:46,604 --> 00:10:49,829
Differential privacy we
have to add a statistical.

172
00:10:50,114 --> 00:10:55,764
Noise to predict individual records,
balance privacy with accuracy needs

173
00:10:55,764 --> 00:10:57,774
for sensitive ML applications.

174
00:10:58,074 --> 00:11:04,014
This will also be indicating that we
need to have the proper IAM mechanisms

175
00:11:04,044 --> 00:11:07,764
in place and nextly compliance.

176
00:11:07,764 --> 00:11:11,394
We spoke about compliance issues
that today's world is facing.

177
00:11:11,394 --> 00:11:12,804
And why is this happening?

178
00:11:13,114 --> 00:11:16,714
Because with the cross with the
cross cloud, architecture we have in

179
00:11:16,714 --> 00:11:20,224
place, we are facing HIPAA concerns.

180
00:11:20,224 --> 00:11:26,484
We are facing GDPR compliance
effect EU, PCI and CCP.

181
00:11:26,904 --> 00:11:32,154
So all these laws are all these laws
are legal and ethical, and all the ML

182
00:11:32,154 --> 00:11:37,194
architectures that we are developing
should comply with each of these laws.

183
00:11:37,849 --> 00:11:43,309
So GDPR is mostly data subject rights
and AI transparency requirements

184
00:11:43,439 --> 00:11:45,329
that affect the model design.

185
00:11:45,659 --> 00:11:46,349
And hipaa.

186
00:11:46,349 --> 00:11:48,149
HIPAA is mostly healthcare.

187
00:11:48,429 --> 00:11:52,229
You'll be, each of us will be signing
a HIPAA consent when we go to a doctor.

188
00:11:52,589 --> 00:11:55,589
So all the hipaa, HIPAA
consent practices should be.

189
00:11:56,129 --> 00:11:59,639
Laid in our infrastructure and
platform should be encrypted.

190
00:11:59,639 --> 00:12:03,089
We have to use SHIELD platform
encryption, and we have to use

191
00:12:03,089 --> 00:12:06,599
other encryption techniques that
are available for us to encrypt all

192
00:12:06,599 --> 00:12:10,379
the data and make sure that what is
available and what is not available

193
00:12:11,039 --> 00:12:12,869
depending on the type of the users.

194
00:12:13,409 --> 00:12:19,019
EU AI Act is a risk-based approach to
regulating ML systems by application

195
00:12:19,349 --> 00:12:23,609
and the payment secure handling of
financial data used in fraud detection

196
00:12:23,609 --> 00:12:25,249
models that we need that model.

197
00:12:26,104 --> 00:12:31,954
And also the C CCPA, right
Consumer rights to data access and

198
00:12:31,954 --> 00:12:33,934
deletion impact training process.

199
00:12:34,354 --> 00:12:39,064
So all these considerations have
to be considered and nextly cost

200
00:12:39,064 --> 00:12:43,504
optimization strategies, because we
are spending a lot, what are we really

201
00:12:43,694 --> 00:12:46,034
trying to, in terms of optimizations?

202
00:12:46,304 --> 00:12:49,394
So leverage all these spot instances.

203
00:12:50,594 --> 00:12:54,684
So that means we have to make
sure all the non-critical training

204
00:12:54,684 --> 00:12:57,414
job on discounted compute.

205
00:12:57,744 --> 00:13:01,554
You just have to defer all the
computations of non-critical training

206
00:13:01,554 --> 00:13:07,194
jobs to make sure that we will be
using spot instances and nextly.

207
00:13:07,194 --> 00:13:10,164
We have to optimize the storage tiers.

208
00:13:10,314 --> 00:13:14,664
Meaning if your training data is not
accessing any data frequently, then

209
00:13:14,664 --> 00:13:16,464
you have to move it to a cold storage.

210
00:13:17,544 --> 00:13:19,104
And also auto-scaling.

211
00:13:19,154 --> 00:13:20,594
Meaning scaling.

212
00:13:20,644 --> 00:13:23,374
We have to scale the resources
based on prediction demand.

213
00:13:23,374 --> 00:13:28,224
That's very much vital and right
size, compute resources, match

214
00:13:28,284 --> 00:13:32,424
instance types to ML workload needs.

215
00:13:33,144 --> 00:13:34,549
You just don't need it.

216
00:13:34,604 --> 00:13:35,444
Oversized.

217
00:13:35,774 --> 00:13:40,874
But you wanted to have it in a right
size so that you'll be saving on all

218
00:13:40,874 --> 00:13:45,754
the space complexities that we'll
be having and properly configured.

219
00:13:45,784 --> 00:13:50,994
ML environments can reduce the cloud
spending by 30 to 40%, which is a lot.

220
00:13:51,564 --> 00:13:56,724
And also regular cost or the audits
should be taken place so that we

221
00:13:56,724 --> 00:14:00,234
will discuss all the optimizations
with them and we can always.

222
00:14:01,064 --> 00:14:04,364
Try to optimize as much as we can
if you are missing on anything.

223
00:14:04,944 --> 00:14:09,264
Cross-platform model
service containerization.

224
00:14:09,684 --> 00:14:14,514
So package ML models and dependencies
for consistent deployment anywhere.

225
00:14:14,514 --> 00:14:17,974
One of the example is Docker
and Kubernetes because they

226
00:14:18,004 --> 00:14:21,789
are already providing platform
agnostic or orchestration.

227
00:14:22,279 --> 00:14:23,799
Next list serverless in.

228
00:14:24,969 --> 00:14:29,889
Inference, deploy models and functions
that automatically scale with demand.

229
00:14:30,699 --> 00:14:35,439
And also we only pay for actual prediction
time with minimal management overhead.

230
00:14:36,744 --> 00:14:41,654
La Lastly, we'll be discussing about model
versioning and performance monitoring.

231
00:14:41,894 --> 00:14:44,834
Performance monitoring is, again,
we have to track all the model

232
00:14:44,834 --> 00:14:49,184
metrics consistently consistently
across multiple crowd providers.

233
00:14:49,664 --> 00:14:55,544
And related to versioning, we have to
implement all the releases for safe

234
00:14:55,544 --> 00:14:59,544
model updates across platform platforms.

235
00:15:00,544 --> 00:15:03,814
And real time machine
learning integration patterns.

236
00:15:04,294 --> 00:15:08,024
So what are the integration
patterns that we have in place?

237
00:15:08,214 --> 00:15:13,684
Synchronous API synchronous processing
and stream processing synchronous.

238
00:15:13,684 --> 00:15:16,254
API example is again a rest.

239
00:15:16,254 --> 00:15:19,134
We could think of it as just
using a rest, API in place.

240
00:15:19,629 --> 00:15:23,039
So direct request response
pattern for immediate prediction.

241
00:15:23,039 --> 00:15:28,599
That means you will fe you'll
fetch wait and get the response

242
00:15:28,599 --> 00:15:29,859
and show it back to the user.

243
00:15:30,159 --> 00:15:35,349
So the latency is very less under a
hundred MS. And a synchronous processing.

244
00:15:35,629 --> 00:15:40,159
This could be even driven architecture
mostly where we'll be using Q based

245
00:15:40,579 --> 00:15:42,679
inference for high throughput workloads.

246
00:15:43,099 --> 00:15:45,789
Ideal for batch predictions
and background trust.

247
00:15:46,394 --> 00:15:50,564
Scales easily during peak demands
and nextly stream processing.

248
00:15:50,614 --> 00:15:54,064
That is a con continuous
inference on data streams.

249
00:15:54,364 --> 00:15:58,444
So you keep streaming the data
and you keep receiving and the

250
00:15:58,444 --> 00:16:02,034
people can subscribe and they can
hear the real time data from us.

251
00:16:03,799 --> 00:16:05,029
Disaster recovery.

252
00:16:05,059 --> 00:16:06,199
This is very much needed.

253
00:16:06,199 --> 00:16:08,119
What exactly is a disaster recovery?

254
00:16:08,359 --> 00:16:12,669
Let's say we have a natural calamity
or, immediate power interruption.

255
00:16:12,879 --> 00:16:13,959
What are we going to do?

256
00:16:14,259 --> 00:16:17,409
So disasters are something
even more bigger than power

257
00:16:17,409 --> 00:16:18,669
interruption, like I mentioned.

258
00:16:18,669 --> 00:16:23,139
It could be a calamity or it could be even
more a system failure altogether, right?

259
00:16:23,569 --> 00:16:28,594
What we have to make sure all the models
have these, strategies incorporated.

260
00:16:28,924 --> 00:16:33,904
So model registry replication, that
is where you automate all re registry

261
00:16:33,904 --> 00:16:38,574
synchronization, implement cross region
validation, which is more required.

262
00:16:38,574 --> 00:16:41,334
What if other region fails
and one region is up?

263
00:16:41,634 --> 00:16:45,234
And also version control
all model artifacts.

264
00:16:45,264 --> 00:16:50,014
You can use any GitHub, you can
use Bitbucket and also others.

265
00:16:50,064 --> 00:16:53,334
Source controls and version controls
that we have today in place.

266
00:16:54,054 --> 00:16:58,554
Multi-region deployment using
global load balances, which is very

267
00:16:58,554 --> 00:17:02,934
much vital for a right model and
implementing health checks as required.

268
00:17:03,204 --> 00:17:05,754
And test regional is isolations regularly.

269
00:17:06,144 --> 00:17:11,394
Health checks are mostly part of
many of the software as a service.

270
00:17:11,394 --> 00:17:14,934
Software as a service platforms,
they have out of box health

271
00:17:14,934 --> 00:17:16,194
checks that we can leverage.

272
00:17:16,344 --> 00:17:19,314
But if we do not have one, we
have to make sure we'll build one

273
00:17:19,314 --> 00:17:21,114
depending on the org requirement.

274
00:17:21,479 --> 00:17:25,289
And degrade degraded operation
model operation modes, right?

275
00:17:25,589 --> 00:17:29,069
So we have to develop
simplified fallback models.

276
00:17:29,259 --> 00:17:34,389
Meaning you can build a dead letter
queue, you can build a retry mechanism,

277
00:17:34,389 --> 00:17:38,699
but that is more important and
also cashier recent predictions and

278
00:17:38,699 --> 00:17:41,639
creating rules based alternatives.

279
00:17:41,669 --> 00:17:44,359
You just need to make
sure how you redirect.

280
00:17:44,744 --> 00:17:48,534
Your Q2 or how you are going to
redirect your model to, that's

281
00:17:48,534 --> 00:17:52,754
more vital for the machine learning
system to work in the right way.

282
00:17:52,844 --> 00:17:54,944
And that represents the cleaner design.

283
00:17:55,754 --> 00:18:01,184
And also the key takeaways are we have
discussed about training databases.

284
00:18:01,214 --> 00:18:03,694
We have discussed about
how engineer resilient.

285
00:18:04,574 --> 00:18:09,554
Cloud integrations through a PA
architectures and also through IAM

286
00:18:09,554 --> 00:18:13,904
protocols implement comprehensive
safeguard for training data while

287
00:18:13,904 --> 00:18:19,134
navigating complex compliance
requirements across multiple regions.

288
00:18:19,554 --> 00:18:23,194
And also we have to architect our
systems to build built in with.

289
00:18:23,229 --> 00:18:29,229
Scalability, and we have to make sure that
cost optimization strategies are in place.

290
00:18:29,439 --> 00:18:34,029
And also there is the disaster
recovery mechanisms, which includes

291
00:18:34,179 --> 00:18:38,889
deadline queues and more to
ensure op operational continuity.

292
00:18:40,259 --> 00:18:42,889
That's mostly about my presentation.

293
00:18:42,919 --> 00:18:46,529
And thank you all for your patience today.

294
00:18:46,709 --> 00:18:48,989
I really enjoyed talking
in the conference.

295
00:18:49,559 --> 00:18:49,949
Thank you all.

