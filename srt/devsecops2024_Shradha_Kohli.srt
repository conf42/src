1
00:00:00,290 --> 00:00:00,970
Hello, everybody.

2
00:00:01,530 --> 00:00:05,890
My name is Shraddha Kohli, and today
I will be talking about building user

3
00:00:05,890 --> 00:00:12,120
trust in conversational AI, the role of
explainable AI in chatbot transparency.

4
00:00:12,620 --> 00:00:17,950
The agenda for today's talk is, I will
be introducing what is explainable AI,

5
00:00:18,600 --> 00:00:24,130
the evolution of chatbots, what are
the key technologies in the explainable

6
00:00:24,170 --> 00:00:29,930
AI domain, what is the methodology
that I used in my research, What was

7
00:00:29,930 --> 00:00:35,040
the result of my research, the user
impact, some of the challenges, and

8
00:00:35,040 --> 00:00:38,850
lastly, what is the future research
directions that can be taken in this area?

9
00:00:39,350 --> 00:00:42,560
Starting with introduction
to explainable AI.

10
00:00:43,390 --> 00:00:49,280
Explainable AI tackles the black box
challenge in complex AI systems by

11
00:00:49,300 --> 00:00:51,430
making decision processes understandable.

12
00:00:52,190 --> 00:00:56,300
It helps, it's essentially for
systems that interact directly

13
00:00:56,330 --> 00:00:58,260
with users, such as chatbots.

14
00:00:58,910 --> 00:01:00,284
Without transparency, it's impossible.

15
00:01:00,525 --> 00:01:06,845
Users often feel unsure about how
chatbots arrive at responses, especially

16
00:01:06,845 --> 00:01:09,275
in areas such as healthcare or finance.

17
00:01:09,850 --> 00:01:13,480
This leads to a lot of mistrust
and hesitation for users

18
00:01:13,690 --> 00:01:15,040
to use these technologies.

19
00:01:15,540 --> 00:01:21,630
There are many explainable AI methods
like LIME, SHAP, and Counterfactuals

20
00:01:21,900 --> 00:01:26,340
that can actually help chatbots
provide insights into their reasoning,

21
00:01:26,690 --> 00:01:30,640
fostering user trust, and enabling
developers to fine tune their tools.

22
00:01:30,640 --> 00:01:34,049
How do chatbots actually evolve?

23
00:01:35,039 --> 00:01:40,539
Chatbots have been here for a long
time, since the 1960s, and previously

24
00:01:40,599 --> 00:01:44,129
they were rule based on pattern
matching and scripted responses.

25
00:01:44,399 --> 00:01:49,571
But now with the advancement in the
field of AI, a lot of them use very

26
00:01:49,571 --> 00:01:54,499
deep neural networks as well as very
advanced AI and machine learning

27
00:01:54,499 --> 00:01:58,779
technology to allow for more natural
and conversational interactions.

28
00:01:59,389 --> 00:02:03,754
But today's modern chatbots Though
they are very powerful, they do not

29
00:02:03,854 --> 00:02:09,564
provide us the transparency in their
decision making, which tends to create

30
00:02:09,934 --> 00:02:12,344
a sense of doubt in the user's mind.

31
00:02:13,239 --> 00:02:16,699
In order to solve this, there
are a few key techniques

32
00:02:16,929 --> 00:02:18,529
that we can use for chatbots.

33
00:02:18,929 --> 00:02:23,669
The first one is called LIME,
which is Local Interpretable

34
00:02:23,749 --> 00:02:25,879
Model Agnostic Explanations.

35
00:02:26,569 --> 00:02:30,939
This tool necessarily generates
explanations by creating a simplified

36
00:02:30,969 --> 00:02:35,449
interpretable model of chatbot
behavior for a single response.

37
00:02:35,879 --> 00:02:41,174
Users can see which input features
example words most influenced

38
00:02:41,184 --> 00:02:42,634
the chatbot's responses.

39
00:02:43,234 --> 00:02:48,264
The second one stands for SHAMP, which
is Shapely Additive Explanations.

40
00:02:49,064 --> 00:02:55,144
This uses values from game theory to
assign importance to input features, such

41
00:02:55,144 --> 00:02:57,339
as adding weights to the different words.

42
00:02:57,679 --> 00:03:03,779
Which helps to offer a clearer picture of
how each input or how each word has been

43
00:03:03,829 --> 00:03:09,329
contributing to the chatbot's response at
both the local as well as global levels.

44
00:03:10,079 --> 00:03:16,189
Lastly, the counterfactual explanations
provide how slight changes in the user's

45
00:03:16,209 --> 00:03:21,409
input can actually lead to different
outputs, helping users understand the

46
00:03:21,409 --> 00:03:26,089
decision boundary and the sensitivity of
the chatbot to different input variations.

47
00:03:26,589 --> 00:03:32,119
For our study, we actually interviewed
around 150 users in different

48
00:03:32,119 --> 00:03:37,509
demographics, and we selected three
different types of chatbot models,

49
00:03:37,649 --> 00:03:42,409
ranging from retrieval based,
generative, as well as hybrid models.

50
00:03:42,939 --> 00:03:47,869
These represent the diversity of different
modern chatbots that we have, ranging from

51
00:03:47,879 --> 00:03:53,029
simple FAQ based to highly conversational
systems that we see nowadays.

52
00:03:53,924 --> 00:03:59,664
The explainable AI application process,
we basically use the three models that are

53
00:03:59,664 --> 00:04:03,124
described above to, to use, on our users.

54
00:04:03,544 --> 00:04:08,214
Starting with the LIME one, this one
helped us analyze specific chatbot

55
00:04:08,224 --> 00:04:12,774
responses by approximating them
with simple interpretable models.

56
00:04:13,269 --> 00:04:18,749
The SHAP1 helped us to calculate feature
importance scores to understand which

57
00:04:18,749 --> 00:04:21,159
parts of the input influence responses.

58
00:04:21,649 --> 00:04:27,419
And lastly, the counterfactuals identified
minor changes in input that would actually

59
00:04:27,429 --> 00:04:31,369
yield a different output, showcasing
the sensitivity of the response.

60
00:04:32,119 --> 00:04:35,519
In order to evaluate this, we
had three different metrics.

61
00:04:35,909 --> 00:04:37,369
The first one was faithfulness.

62
00:04:37,659 --> 00:04:39,559
What was the accuracy of the response?

63
00:04:39,849 --> 00:04:41,389
The second one was stability.

64
00:04:41,779 --> 00:04:45,199
What is the consistency of the
explanations across the different users?

65
00:04:45,549 --> 00:04:47,379
And lastly, the comprehensibility.

66
00:04:47,629 --> 00:04:53,659
How easy was it for non technical users
as well to understand the responses?

67
00:04:54,159 --> 00:04:55,519
The results were pretty good.

68
00:04:55,639 --> 00:05:01,169
What we found was that LIME worked
well for individual, for explaining

69
00:05:01,179 --> 00:05:05,979
individual responses, but it struggled
at global level, meaning that the

70
00:05:05,979 --> 00:05:08,669
explanations may vary for similar inputs.

71
00:05:09,199 --> 00:05:12,929
The SHAP provided detailed
insights into feature importance

72
00:05:13,009 --> 00:05:14,659
across multiple interactions.

73
00:05:15,039 --> 00:05:17,879
However, due to high processing
and computational need, LIME did

74
00:05:17,879 --> 00:05:21,544
not meet the initial need This is
not, this was not feasible and also

75
00:05:21,544 --> 00:05:23,474
confusing for non technical users.

76
00:05:24,034 --> 00:05:28,184
The counterfactual explanations were
very intuitive for users, but this

77
00:05:28,184 --> 00:05:32,414
was also challenging due to real
time demands that the users have.

78
00:05:33,354 --> 00:05:37,934
The main insight is that each technique
brings its own pros and cons to

79
00:05:37,934 --> 00:05:41,754
the chatbot transparency, though
real time interaction and latency

80
00:05:41,944 --> 00:05:45,934
and ease of comprehension are still
some areas that need to be explored.

81
00:05:46,434 --> 00:05:51,434
Some of the key data points and the
user impact was after trying this

82
00:05:51,434 --> 00:05:55,154
with, trying these techniques with
some of the users, we found that their

83
00:05:55,214 --> 00:06:00,464
trust in their users trust in the
chatbot technology improved by 35%.

84
00:06:01,144 --> 00:06:06,364
They also understood that 48% What
of users understood what is the, what

85
00:06:06,364 --> 00:06:10,754
is the reasoning behind the chatbot
behavior complex task engagement.

86
00:06:10,984 --> 00:06:13,724
This was the willingness to
engage with complex chatbot

87
00:06:13,774 --> 00:06:15,934
tasks was also increased by 27%.

88
00:06:15,934 --> 00:06:18,944
The error tolerance for users.

89
00:06:19,254 --> 00:06:23,844
Basically, in forgiving the chatbot
for the responses or the errors was

90
00:06:23,864 --> 00:06:26,084
also increased to a stunning 40%.

91
00:06:26,694 --> 00:06:33,054
And the overall engagement and the removal
of hesitation increased by 30, 31%.

92
00:06:33,704 --> 00:06:35,074
So pretty promising results.

93
00:06:36,069 --> 00:06:39,289
Some of the challenges that we
experienced in implementing the

94
00:06:39,289 --> 00:06:43,639
explainable AI for chatbots is number
one, as I said, real time constraints.

95
00:06:44,219 --> 00:06:48,329
There is a, the generate, generating
explanations in real time without

96
00:06:48,349 --> 00:06:52,479
actually providing a noticeable
delay and latency is still difficult.

97
00:06:53,099 --> 00:06:57,244
How do we balance detail with
comprehension to make sure that the

98
00:06:57,324 --> 00:07:02,544
explanations have the correct amount
of detail, but they are also easy to

99
00:07:02,544 --> 00:07:04,374
be understood by non technical users.

100
00:07:05,064 --> 00:07:09,594
Then each of the model, as I said,
has its own limitation and not

101
00:07:09,614 --> 00:07:12,764
everything will be suitable for
complex architectures in state of the

102
00:07:12,764 --> 00:07:14,664
art chatbots that we have nowadays.

103
00:07:15,494 --> 00:07:17,184
Lastly, ethical concerns.

104
00:07:17,564 --> 00:07:21,484
When our chatbots are providing us with
this information, there is also a chance

105
00:07:21,534 --> 00:07:26,124
that some sensitive information could
be exposed or there could be some bias.

106
00:07:26,494 --> 00:07:30,104
This requires careful ethical
handling of explanation techniques.

107
00:07:30,604 --> 00:07:34,374
There are a lot of future research
directions that are, that we can take

108
00:07:34,374 --> 00:07:39,734
in this area, starting with advancing
the explainable AI for complex models.

109
00:07:40,154 --> 00:07:44,084
How do we develop new explainable
AI methods suited to complex

110
00:07:44,084 --> 00:07:47,004
architectures like transformers,
which are common in chatbots?

111
00:07:47,604 --> 00:07:50,494
Lastly, real time adaptive explanations.

112
00:07:50,624 --> 00:07:55,184
How do we make sure that the research
adaptive systems that adjust with the

113
00:07:55,184 --> 00:07:57,404
right level of detail that is needed?

114
00:07:58,154 --> 00:08:01,259
And that's Third, self
explaining chatbots.

115
00:08:01,409 --> 00:08:05,799
Investigate how chatbots can learn
to explain themselves as they evolve,

116
00:08:06,109 --> 00:08:11,049
leading to a truly self explanatory
AI that users understand intuitively.

117
00:08:11,549 --> 00:08:15,219
Lastly, I would like to conclude,
as chatbots became an integral

118
00:08:15,219 --> 00:08:19,009
part of customer service and user
interaction across sectors, building

119
00:08:19,039 --> 00:08:20,579
trust in these sectors is critical.

120
00:08:21,559 --> 00:08:26,569
Explainable AI offers a pathway to
address the black box nature of AI

121
00:08:26,799 --> 00:08:30,939
by making chatbot decision making
processes transparent and interpretable.

122
00:08:31,659 --> 00:08:37,009
By leveraging methods like LIME, SHAP,
and counterfactual explanations, we enable

123
00:08:37,039 --> 00:08:43,109
chatbots to provide insights into their
responses, which helps to foster a more

124
00:08:43,109 --> 00:08:45,329
reliable and user centered experience.

125
00:08:45,849 --> 00:08:50,309
This transparency not only enhances user
trust and confidence in the chatbot, but

126
00:08:50,309 --> 00:08:55,059
also equips developers with powerful tools
for refining and improving these systems.

127
00:08:55,669 --> 00:09:00,529
Our research demonstrated that
integrating XAI with chatbot technology

128
00:09:00,579 --> 00:09:04,009
yields significant benefits in user
trust, comprehension, and engagement.

129
00:09:04,549 --> 00:09:08,349
However, this journey is still a long
one and there is a lot of research that

130
00:09:08,349 --> 00:09:10,029
still needs to be done in this area.

131
00:09:10,819 --> 00:09:15,199
The advancements in XAI techniques
have provided a promising foundation

132
00:09:15,429 --> 00:09:20,189
for more accountable, transparent,
and trustworthy AI applications.

133
00:09:20,689 --> 00:09:21,159
Thank you.

