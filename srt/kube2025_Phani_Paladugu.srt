1
00:00:00,500 --> 00:00:01,190
Hello everyone.

2
00:00:01,549 --> 00:00:05,990
I'm Fanish Product Management
Professional from Synopsis.

3
00:00:06,830 --> 00:00:10,490
Welcome to the presentation
on re-imagining service for

4
00:00:10,490 --> 00:00:14,420
scalable AI architectures
bottleneck and breakthroughs.

5
00:00:14,920 --> 00:00:18,185
In today's presentation,
I'll be using a service.

6
00:00:19,120 --> 00:00:19,840
More often.

7
00:00:20,530 --> 00:00:24,130
It is a short form for
serializer de serializer.

8
00:00:24,490 --> 00:00:28,750
It's a high speed interface
that is used for data transfers.

9
00:00:29,250 --> 00:00:33,690
Today's agenda covers ai, workload
impact on interconnect designs,

10
00:00:33,870 --> 00:00:38,285
signal integrity, challenges at multi
gigabit data rates, architectural

11
00:00:38,285 --> 00:00:40,680
tradeoffs, and future directions for.

12
00:00:41,180 --> 00:00:45,910
The generative AI leads to
exponential growth in compute demands.

13
00:00:46,600 --> 00:00:50,380
The model sizes are doubling
every three to four months.

14
00:00:50,880 --> 00:00:56,214
Despite the parallelism, the training
times are increased to weeks and months.

15
00:00:56,714 --> 00:01:00,905
Due to increased compute demands,
the memory and interconnect

16
00:01:00,905 --> 00:01:05,905
bandwidths are falling behind
to support the compute demands.

17
00:01:06,715 --> 00:01:12,584
With this, it puts a lot of pressure on
the interconnect and memory technologies

18
00:01:12,614 --> 00:01:17,469
to deliver higher bandwidths with
the lower power and lower latency.

19
00:01:17,969 --> 00:01:20,429
The conflicting demands
for service in the I era.

20
00:01:21,359 --> 00:01:25,759
So as I mentioned earlier, in
order to support the increased

21
00:01:25,789 --> 00:01:29,959
compute demands, the interconnect
bandwidths needs to be increased.

22
00:01:30,350 --> 00:01:34,339
That means the data rates for the
the service are going high and high.

23
00:01:34,839 --> 00:01:36,789
If you see the current transition.

24
00:01:37,210 --> 00:01:43,929
The Ethernet's service are moving from
112 gig data rates to 224 gig data rate,

25
00:01:44,429 --> 00:01:50,459
and the PCIE is moving from 64 gig
data rate to 128 gig data rate,

26
00:01:50,959 --> 00:01:52,639
even with increased data rates.

27
00:01:52,969 --> 00:01:55,369
The power efficiency is also very key.

28
00:01:55,819 --> 00:02:00,439
So in order to meet the system
requirements, we have to ensure.

29
00:02:00,814 --> 00:02:04,264
The power efficiency targets
are well within the limit.

30
00:02:04,764 --> 00:02:09,174
The current side is the power efficiencies
are around like four to five Pico Joel per

31
00:02:09,174 --> 00:02:16,774
be that needs to support the long range
channels of other, of 45 to 50 db EV.

32
00:02:17,274 --> 00:02:20,154
In addition to this we need to
deal with the signal integrated

33
00:02:20,154 --> 00:02:23,599
challenges as well at a higher data
rate, so with increased data rate.

34
00:02:24,369 --> 00:02:27,504
The signal integrity challenges
are becoming more and more

35
00:02:28,004 --> 00:02:29,114
at a higher data rates.

36
00:02:29,114 --> 00:02:34,734
The channel loss is very high and it
leads to more reflections as well due to

37
00:02:34,734 --> 00:02:36,774
the con discontinuities in the channel.

38
00:02:37,224 --> 00:02:39,594
And the crosstalk impact
is also very high.

39
00:02:40,224 --> 00:02:45,904
So in addition to that, we need to
understand the workloads where this

40
00:02:45,904 --> 00:02:48,184
particular service is being utilized.

41
00:02:48,664 --> 00:02:51,129
So understanding the
workloads will help us.

42
00:02:51,514 --> 00:02:57,064
To better get the use case and
so we can optimize the service

43
00:02:57,304 --> 00:02:58,804
to meet all the requirements.

44
00:02:59,344 --> 00:03:05,324
The conflicting demands are
creating a design paradox that

45
00:03:05,324 --> 00:03:10,364
demands innovative approaches to
meet all the service requirements.

46
00:03:10,864 --> 00:03:14,549
Let's try to understand the AI workload
impact on interconnect designs.

47
00:03:14,549 --> 00:03:18,889
Sir. So as we know, like there are two
different workloads, like a training

48
00:03:18,889 --> 00:03:20,809
workload and inference workloads.

49
00:03:20,859 --> 00:03:22,809
Let's start with the inference workloads.

50
00:03:23,049 --> 00:03:27,879
Inference workloads are more of a
topic with the variable loads that

51
00:03:27,879 --> 00:03:30,609
needs asymetic bandwidth requirements.

52
00:03:30,879 --> 00:03:32,109
And inference.

53
00:03:32,109 --> 00:03:38,669
Workloads are more of a memory bond than a
compute bond, and the latency is very key.

54
00:03:39,194 --> 00:03:39,434
Here.

55
00:03:39,934 --> 00:03:44,734
If you look at the training workloads,
training workloads are more of a compute

56
00:03:44,734 --> 00:03:50,724
bound, and it needs like a very high
bandwidth to move the higher data.

57
00:03:51,294 --> 00:03:53,304
And the latency is also very key here.

58
00:03:53,904 --> 00:03:58,314
So for the distinct workload
characteristics requires a specialized

59
00:03:58,314 --> 00:03:59,664
research design techniques.

60
00:03:59,664 --> 00:03:59,874
So.

61
00:04:00,374 --> 00:04:05,114
For ai, before we start designing
the the service, we need to better

62
00:04:05,114 --> 00:04:09,224
understand the exact use case and
the workload requirements that will

63
00:04:09,224 --> 00:04:13,304
help us to optimize the performance
power area and the latency.

64
00:04:13,804 --> 00:04:18,019
Let's touch base on the signal
integrity at multi gigabit day trade.

65
00:04:18,519 --> 00:04:21,879
The channel characteristics
varies with the frequency.

66
00:04:22,599 --> 00:04:26,049
The channel loss is very
high at higher data rates.

67
00:04:26,549 --> 00:04:33,489
If you look at the ethernet service at 224
gigabytes per second data rate, it has to

68
00:04:33,489 --> 00:04:40,389
support channel loss of order of 45 to 50
DB to meet the system level constraints.

69
00:04:40,809 --> 00:04:41,649
Similarly.

70
00:04:42,149 --> 00:04:47,009
The PCIE Gen seven server is at
128 gigabits per second needs

71
00:04:47,009 --> 00:04:52,450
to meet a channel loss of 35 to
40 DB with increased data rates.

72
00:04:52,950 --> 00:04:57,570
We have a design constraints on the
jitter as well as like increased

73
00:04:57,570 --> 00:05:02,640
inter symbol interference, increased
reflections due to discontinuities in the

74
00:05:02,640 --> 00:05:05,250
channels, and increased crosstalk effect.

75
00:05:05,325 --> 00:05:13,365
S. So as we move forward 2 24 and
beyond, we need to implement novel

76
00:05:13,604 --> 00:05:18,015
equalization techniques to address
all the signal integrity challenges.

77
00:05:18,515 --> 00:05:21,124
Let's touch on innovations
in service design.

78
00:05:21,624 --> 00:05:27,594
The traditional n RZ based CER
implements a feed forward equalizer.

79
00:05:28,119 --> 00:05:33,099
On the transmit side and continuous
time linear equalizer, followed by a

80
00:05:33,099 --> 00:05:37,179
dis feedback equalizer on the received
side in order to support the long reach

81
00:05:37,179 --> 00:05:43,289
channel requirements as the data rates
are increasing, the signals scheme for ER

82
00:05:43,829 --> 00:05:46,439
has moved to like a PAM four from Nazi.

83
00:05:47,099 --> 00:05:52,349
All the PAM four service are
DSP based, these service.

84
00:05:52,849 --> 00:05:59,829
Leverages multi-tap feed forward equalizer
and multi-tap distill feedback equalizer

85
00:05:59,919 --> 00:06:05,084
and optimize the continuous time linear
equalizers, along with the the high

86
00:06:05,084 --> 00:06:10,094
performance data converters to meet the
stringent signal integrated constraints.

87
00:06:10,594 --> 00:06:13,244
If you look at adopted equalization.

88
00:06:13,744 --> 00:06:17,829
Real time adaptation techniques
are implemented to fine tune the

89
00:06:17,829 --> 00:06:22,119
service parameters to meet to
meet the channel characteristics.

90
00:06:22,929 --> 00:06:25,419
Machine learning for service.

91
00:06:25,869 --> 00:06:29,339
So there are machine learning
algorithms are implemented for

92
00:06:29,339 --> 00:06:31,019
calibration and adaptation.

93
00:06:31,519 --> 00:06:34,999
Advanced CDR and forward
error correction techniques.

94
00:06:35,499 --> 00:06:40,059
The clock and data recovery is a key
function that is being implemented

95
00:06:40,539 --> 00:06:44,889
on receiver side to recover the
clock from the received data.

96
00:06:45,369 --> 00:06:49,559
So advanced clock on data
recovery circuits uses a digital

97
00:06:49,559 --> 00:06:50,849
bang bang phase detector.

98
00:06:51,299 --> 00:06:55,529
And a multi-phase sampling to
improve the accuracy of the

99
00:06:55,529 --> 00:06:58,049
sampling and the spec spectrum.

100
00:06:58,049 --> 00:07:03,929
Clocking is implemented to minimize
the electro migration and IR drop.

101
00:07:04,429 --> 00:07:09,049
In addition to that, hybrid
architectures are selected to

102
00:07:09,079 --> 00:07:14,594
balance the performance versus power
forward error correction circuitry.

103
00:07:15,369 --> 00:07:21,719
Our error correction circuitry
helps to optimize the bid rate by

104
00:07:21,929 --> 00:07:24,149
minimizing the bids within the service.

105
00:07:24,569 --> 00:07:29,029
There are various standard fact circuits
are available out in the market like

106
00:07:29,089 --> 00:07:31,424
re, Solomon Fact, and L-D-P-C-F.

107
00:07:31,804 --> 00:07:36,064
A specific effect can be selected
based on the channel performance

108
00:07:36,364 --> 00:07:38,954
and power and latency constraints.

109
00:07:39,454 --> 00:07:43,314
Let's look into the architectural
tradeoffs for the SER design for er.

110
00:07:43,495 --> 00:07:49,630
As I mentioned earlier, performance power
area, and latency are the key parameters.

111
00:07:50,130 --> 00:07:53,909
This leads to a multi-dimensional system.

112
00:07:53,909 --> 00:07:54,695
Design challenges.

113
00:07:55,530 --> 00:07:59,940
So we need to address and optimize
all these four parameters to make

114
00:07:59,940 --> 00:08:02,070
sure it meets the system requirements.

115
00:08:02,940 --> 00:08:07,080
So the next one is looking
at different architectural

116
00:08:07,080 --> 00:08:11,000
options, analog architectures
versus digital architectures.

117
00:08:11,090 --> 00:08:15,819
So the legacy service are more of analog
architectures with the higher data

118
00:08:15,819 --> 00:08:21,210
rates and the signaling scheme moved
to PAMM four, the latest PAMM four.

119
00:08:21,825 --> 00:08:27,045
ER are more of a DSP based and moving
towards the digital architectures

120
00:08:27,405 --> 00:08:34,044
to enable all the, the process
scalability advantages as well as

121
00:08:34,044 --> 00:08:37,314
to implement the voltage scaling
to further minimize the power.

122
00:08:37,814 --> 00:08:38,034
For.

123
00:08:38,150 --> 00:08:42,770
Third is the configurability and
scalability are very key parameters.

124
00:08:43,020 --> 00:08:48,020
As I mentioned earlier, in order to
support a wide variety of bandwidth

125
00:08:48,020 --> 00:08:52,749
requirement service can be configured
from one lane to 16 lane for ethernet.

126
00:08:52,749 --> 00:08:55,579
And similarly like the PCI use case.

127
00:08:55,999 --> 00:09:01,784
So configurability is one key,
important parameter for the service

128
00:09:02,234 --> 00:09:05,634
as well as reconfigurability
is also equally important.

129
00:09:06,309 --> 00:09:10,649
So if we look at multi-protocol
service, the same service can be

130
00:09:10,649 --> 00:09:15,659
configured for ethernet as well as
the PCIE based on the, the use case.

131
00:09:16,159 --> 00:09:17,329
The Power Challenge.

132
00:09:17,829 --> 00:09:23,094
AI workload demands a few hundred
sub servers to be used in order

133
00:09:23,094 --> 00:09:25,164
to meet the compute demands.

134
00:09:25,664 --> 00:09:26,084
So.

135
00:09:26,594 --> 00:09:29,834
The power efficiency is
very key for the service.

136
00:09:30,764 --> 00:09:34,454
There are various techniques can be
implemented starting from circuit to

137
00:09:34,454 --> 00:09:36,914
the system level to optimize the power.

138
00:09:37,414 --> 00:09:42,069
If you look at the, the circuit techniques
available to optimize the power that

139
00:09:42,069 --> 00:09:46,534
includes supply voltage, scaling,
adaptive biasing, and cloud getting.

140
00:09:47,034 --> 00:09:50,379
If you look at the architectural
optimizations, we can implement

141
00:09:50,409 --> 00:09:51,369
the power eye landing.

142
00:09:51,834 --> 00:09:56,594
And the workload aware power states that
can optimize the architectural level.

143
00:09:57,094 --> 00:10:01,124
If you look at the system approaches,
there are a few ways of optimizing the

144
00:10:01,124 --> 00:10:08,264
power by implementing the dynamic voltage
and frequency scaling, as well as thermal

145
00:10:08,264 --> 00:10:12,599
aware floor plan and placement techniques
also will help us to optimize the power.

146
00:10:13,099 --> 00:10:16,009
The holistic solution strategies
for the service design.

147
00:10:16,639 --> 00:10:21,649
So before we start designing the
er, we need to analyze few things

148
00:10:21,769 --> 00:10:23,389
and understand the use case.

149
00:10:23,749 --> 00:10:27,799
Then we can optimize the
the service solution for a

150
00:10:27,799 --> 00:10:29,479
specific application use case.

151
00:10:30,019 --> 00:10:33,044
So in this case, we need to
start with the workload analysis.

152
00:10:33,709 --> 00:10:39,439
We have to understand the exact
workload patterns and the traffic use

153
00:10:39,439 --> 00:10:44,699
case, so that will help us to better
understand the service use case.

154
00:10:44,699 --> 00:10:49,429
And it'll help us to optimize the
performance, the signal integrity

155
00:10:49,429 --> 00:10:51,019
and power integrity challenges.

156
00:10:51,799 --> 00:10:57,289
We need to build a end-to-end model
that includes the transmitter receiver

157
00:10:57,289 --> 00:11:00,079
and the channel, including the package.

158
00:11:00,379 --> 00:11:07,099
And PCB traces and analyze the system
level performance and fine tune the

159
00:11:07,099 --> 00:11:10,279
characteristics of the individual
modules within the transmitter and

160
00:11:10,279 --> 00:11:15,659
receiver based on the, the channel
characteristics that will help us to

161
00:11:15,659 --> 00:11:19,859
optimize the performance power area
and the latency of the individual

162
00:11:19,889 --> 00:11:22,219
modules, the architecture selection.

163
00:11:22,834 --> 00:11:26,734
So architecture selection means
we need to better understand

164
00:11:27,304 --> 00:11:28,744
the application use case.

165
00:11:29,314 --> 00:11:34,114
For example, the Ultra Accelerator
link can be used for scale up

166
00:11:34,204 --> 00:11:36,124
architecture within the data centers.

167
00:11:36,484 --> 00:11:41,464
Similarly, ultra ethernet can be
used for scale out architectures

168
00:11:41,464 --> 00:11:44,174
for data center architectures.

169
00:11:44,414 --> 00:11:48,794
So these particular configurations
are optimized for latency

170
00:11:49,124 --> 00:11:50,534
and power and performance.

171
00:11:51,034 --> 00:11:54,754
In addition to all these three, we need
to look at the physical design as well.

172
00:11:55,254 --> 00:11:58,949
We need to optimize the service
for north South as well as the

173
00:11:58,949 --> 00:12:02,189
east west placement in the chip.

174
00:12:02,999 --> 00:12:08,069
So most of these AI applications
needs hundreds of service lanes.

175
00:12:08,069 --> 00:12:12,509
So, so we will be able to
place all these service in.

176
00:12:13,094 --> 00:12:19,714
On north side, south side, east and west
side, and find optimal package escape

177
00:12:19,714 --> 00:12:22,864
routes to not to impact the performance.

178
00:12:23,364 --> 00:12:24,774
Let's touch on the future.

179
00:12:24,774 --> 00:12:31,724
Directions insert is for ai, so as we
discussed earlier, we are at a data rate

180
00:12:31,724 --> 00:12:35,434
of 224 gig for current ethernet service.

181
00:12:35,869 --> 00:12:40,699
And we'll be moving to 448
gigabytes per second data rate

182
00:12:40,699 --> 00:12:42,349
in next to two to three years.

183
00:12:42,399 --> 00:12:47,309
Similarly we'll be transitioning to
PCIE generate at 258 gigabits per

184
00:12:47,309 --> 00:12:52,189
second from PCI Gen seven, which
is at 128 gigabits per second.

185
00:12:52,189 --> 00:12:59,469
And link also will be transitioned to
220 4K to 448 in a couple of years.

186
00:13:00,054 --> 00:13:05,314
In addition to these NextGen technologies
on the standards, the co-pack optics

187
00:13:05,314 --> 00:13:07,114
is becoming more and more popular.

188
00:13:07,614 --> 00:13:12,774
This will help move the optics closer
to the switches and AI accelerators

189
00:13:13,274 --> 00:13:17,314
that minimizes the channel loss
requirements and eliminates the need

190
00:13:17,314 --> 00:13:21,984
for the long service, which in turn
optimizes the, the power and performance.

191
00:13:22,484 --> 00:13:26,734
In addition to the co package optics
service for advanced packaging, also

192
00:13:26,734 --> 00:13:32,264
becoming more and more popular with the
multi D solutions chip plates and the

193
00:13:32,264 --> 00:13:38,114
3D packaging applications needs fine
tuning the lot of service requirements

194
00:13:38,114 --> 00:13:41,144
to meet all these latest technologies.

195
00:13:41,504 --> 00:13:41,564
So.

196
00:13:42,064 --> 00:13:46,899
These technologies promises five to eight
x improvement in the bandwidth with the

197
00:13:47,099 --> 00:13:49,644
reduction in power by two to three x.

198
00:13:50,214 --> 00:13:54,614
So this will help us to further
improve the, the performance

199
00:13:54,919 --> 00:13:56,554
and minimize the power.

200
00:13:57,054 --> 00:14:00,624
The key takeaways from the
presentation are AI workloads

201
00:14:01,074 --> 00:14:02,574
are fundamentally reshaping the.

202
00:14:03,159 --> 00:14:08,969
Service requirements, power efficiency
and latency are key Design constraints

203
00:14:08,969 --> 00:14:15,059
for the service signal integrity requires
increasingly sophisticated approaches.

204
00:14:15,559 --> 00:14:18,379
Heterogene service
architectures are the feature.

205
00:14:18,879 --> 00:14:21,099
This concludes my presentation for today.

206
00:14:21,489 --> 00:14:22,179
Thanks everyone.

207
00:14:22,679 --> 00:14:22,799
I.

