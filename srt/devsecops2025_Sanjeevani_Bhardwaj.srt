1
00:00:02,640 --> 00:00:05,100
Hi everyone, and thank you for joining me.

2
00:00:05,640 --> 00:00:10,320
My name is Sanny and I work at Salesforce
as a director of product management,

3
00:00:11,310 --> 00:00:16,440
and today I am thrilled to share a
transformative framework for understanding

4
00:00:16,440 --> 00:00:21,780
DevSecOps Health, the one that moves
beyond individual tools or isolated

5
00:00:21,780 --> 00:00:28,020
metrics into a more holistic, actionable
engineering first way of driving.

6
00:00:28,365 --> 00:00:30,884
Security and operational excellence.

7
00:00:31,604 --> 00:00:36,585
This framework responds to a challenge
nearly every organization faces.

8
00:00:37,545 --> 00:00:42,225
You are investing heavily in DevSecOps,
automation, scanners, compliant

9
00:00:42,225 --> 00:00:43,845
workflows and whatnot, right?

10
00:00:45,254 --> 00:00:47,535
And yet, leadership still struggles.

11
00:00:47,535 --> 00:00:52,665
To answer this simple question, is
our pipeline actually healthy today?

12
00:00:52,905 --> 00:00:56,745
I'll show you how to answer
that question with clarity.

13
00:00:57,089 --> 00:00:59,040
Precision and confidence.

14
00:01:01,230 --> 00:01:04,650
Let's talk a little bit about
the DevSecOps Health Paradox

15
00:01:04,950 --> 00:01:06,300
that we currently face.

16
00:01:07,380 --> 00:01:11,850
This is at the heart of the
modern, uh, organizations today.

17
00:01:11,850 --> 00:01:15,509
Organizations never had more
tools than we have today.

18
00:01:15,750 --> 00:01:22,560
Um, more scans than ever, more dashboards
than ever, but somehow the actual security

19
00:01:22,560 --> 00:01:24,955
posture is less clearer than ever.

20
00:01:26,100 --> 00:01:26,910
Strange, right?

21
00:01:27,869 --> 00:01:30,570
Security teams are checking boxes.

22
00:01:30,570 --> 00:01:35,250
They are, their development teams are
pushing code and operations team are

23
00:01:35,250 --> 00:01:39,720
maintaining uptime, but they're not
speaking a shared language of health.

24
00:01:40,619 --> 00:01:45,630
When everything gets measured
independently, nothing gets understood

25
00:01:45,630 --> 00:01:51,330
collectively and the result, you might
have pipelines that technically pass every

26
00:01:51,330 --> 00:01:53,125
scan, but they're fundamentally brittle.

27
00:01:54,539 --> 00:01:56,970
You might have deployments
happening rapidly.

28
00:01:57,330 --> 00:02:01,619
Yet the observability debt is
masking early signs of incidents,

29
00:02:02,309 --> 00:02:06,000
and the more tools we add, the
more artifacts we generate, like

30
00:02:06,000 --> 00:02:11,905
logs, alerts, reports without
necessarily improving decision making.

31
00:02:13,415 --> 00:02:15,385
This is called the DevSecOps Health Para.

32
00:02:16,560 --> 00:02:22,170
So basically the bottom, the bottom line
is more tooling does not really equal

33
00:02:22,170 --> 00:02:25,440
more clarity in many cases, less is more.

34
00:02:31,020 --> 00:02:35,640
So what are some of these, um, gaps
in our current practices today?

35
00:02:35,970 --> 00:02:39,450
So we studied organizations across
various industries, and there are

36
00:02:39,450 --> 00:02:43,710
these three systemic gaps that surface
again and again across all of them.

37
00:02:44,370 --> 00:02:45,300
The first one being.

38
00:02:45,825 --> 00:02:47,385
Lack of standardization.

39
00:02:49,365 --> 00:02:53,475
Everyone collects data, but nobody
translates it in the same way.

40
00:02:54,255 --> 00:02:59,025
What I mean by that is there is
no consistent methodology for

41
00:02:59,025 --> 00:03:04,755
turning raw scan output into
health signals, which means no two

42
00:03:04,755 --> 00:03:07,695
teams measure things the same way.

43
00:03:09,945 --> 00:03:12,435
The second one is inconsistent threshold.

44
00:03:13,155 --> 00:03:17,355
Teams are defining their own
acceptable limits, their own threshold.

45
00:03:17,355 --> 00:03:20,625
So one group might consider
a 32nd bill delay acceptable

46
00:03:20,625 --> 00:03:22,545
versus while other would not.

47
00:03:23,235 --> 00:03:27,465
Security exceptions may be strict in
one unit, but relax in another unit.

48
00:03:27,705 --> 00:03:31,335
This inconsistency, undermines
benchmarking and meaningful

49
00:03:31,335 --> 00:03:33,075
improvement systemically.

50
00:03:34,845 --> 00:03:37,875
The third one is missing
remediation guidance.

51
00:03:38,579 --> 00:03:42,420
Even when a problem is identified,
teams don't know what to do next.

52
00:03:42,720 --> 00:03:44,459
What is the next best action to take?

53
00:03:45,149 --> 00:03:46,709
Is this a configuration fix?

54
00:03:46,709 --> 00:03:47,970
Is this a redesign?

55
00:03:47,970 --> 00:03:49,440
Is this a backlog item?

56
00:03:49,440 --> 00:03:51,059
How do I actually move forward?

57
00:03:52,350 --> 00:03:56,850
So our framework addresses all of these
three gaps by grounding these thresholds,

58
00:03:56,850 --> 00:04:02,200
maturity levels, and remediation
pathways across the research that we did.

59
00:04:05,670 --> 00:04:09,540
So let's talk about this framework and
the four dimensions associated with it.

60
00:04:09,960 --> 00:04:14,490
So instead of drowning in dozens
of disconnected metrics, these are

61
00:04:14,490 --> 00:04:18,150
the four dimensions that we have
distilled DevSecOps health into

62
00:04:19,680 --> 00:04:24,360
these act as pillars of a secure,
sustainable, and scalable ecosystem.

63
00:04:25,140 --> 00:04:29,700
The first one being platform
efficiency, meaning how effective and

64
00:04:29,700 --> 00:04:31,350
stable your underlying platforms are.

65
00:04:32,130 --> 00:04:34,380
The second one, customization.

66
00:04:34,380 --> 00:04:40,230
Resilience, meaning how safely you
diverge from vendor or community defaults.

67
00:04:40,770 --> 00:04:44,640
The third one, observability meaning
how deeply you understand your

68
00:04:44,640 --> 00:04:46,320
application and system behavior.

69
00:04:46,860 --> 00:04:51,870
And the fourth one, security guardrail
adherence, meaning how consistently

70
00:04:51,870 --> 00:04:57,900
teams follow automated, preventative
detective and corrective controls when

71
00:04:57,900 --> 00:05:00,390
assessed together these dimensions.

72
00:05:00,854 --> 00:05:04,184
Give you a 360 view of your
security posture, not only

73
00:05:04,184 --> 00:05:05,955
in theory, but in reality.

74
00:05:07,724 --> 00:05:12,974
Now, let's deep dive into each one
of these dimensions and understand a

75
00:05:12,974 --> 00:05:14,565
little bit more about what they mean.

76
00:05:15,494 --> 00:05:17,534
So the first one is platform efficiency.

77
00:05:17,684 --> 00:05:20,835
We start with platform efficiency
because nothing else matters if the

78
00:05:20,835 --> 00:05:22,695
foundation itself is shaky, right?

79
00:05:23,205 --> 00:05:25,125
Security cannot just be bolted on.

80
00:05:25,364 --> 00:05:28,484
It cannot be something you add
once everything else is finished.

81
00:05:28,950 --> 00:05:32,460
It must be embedded inside
a performant and scalable,

82
00:05:32,730 --> 00:05:34,650
stable and resilient platform.

83
00:05:35,220 --> 00:05:36,330
Here's why, right?

84
00:05:36,930 --> 00:05:40,770
If builds are slow, developers
are gonna bypass the gates.

85
00:05:41,010 --> 00:05:44,730
If infrastructure provisioning is
sluggish, incident response slows.

86
00:05:45,210 --> 00:05:48,865
If reliability is low, teams
constantly are in that firefight

87
00:05:48,865 --> 00:05:52,590
mode, and when you're firefighting,
you're not proactively securing.

88
00:05:54,750 --> 00:05:57,900
So what are some of these key
indicators of platform efficiency?

89
00:06:00,075 --> 00:06:02,505
The top four are pipeline performance.

90
00:06:03,284 --> 00:06:07,875
We all no long builds in white shortcuts,
so pipeline performance is key.

91
00:06:08,265 --> 00:06:11,985
Second one is provisioning speed,
'cause that impacts your blast

92
00:06:11,985 --> 00:06:13,485
radius and response window.

93
00:06:14,235 --> 00:06:17,085
The third one is resource utilization.

94
00:06:17,414 --> 00:06:22,215
Shows whether systems are tuned correctly
or accumulating silent technical debt

95
00:06:24,435 --> 00:06:25,305
and reliability.

96
00:06:25,995 --> 00:06:29,925
Frequent outages, degrade
trust in security processes.

97
00:06:30,225 --> 00:06:34,485
So a secure organization is first
and foremost an efficient one.

98
00:06:35,115 --> 00:06:38,775
Hence platform efficiency is
one of the key dimensions here.

99
00:06:40,785 --> 00:06:43,845
Alright, let's talk about
the second dimension.

100
00:06:43,965 --> 00:06:45,645
Customization, resilience.

101
00:06:46,335 --> 00:06:50,470
This is one of the most underestimated
sources of incidents, customization.

102
00:06:52,230 --> 00:06:56,250
They involve, they evolve, they
drift, they become outdated.

103
00:06:56,520 --> 00:06:58,290
Customizations get orphaned.

104
00:06:58,680 --> 00:07:01,020
Uh, and that accumulates tech debt, right?

105
00:07:01,500 --> 00:07:04,950
And many of them inadvertently
introduce vulnerabilities.

106
00:07:05,520 --> 00:07:07,830
We classify maturity
in these three levels.

107
00:07:07,950 --> 00:07:11,850
Low maturity, meaning everything
is customized, nothing is tracked.

108
00:07:12,420 --> 00:07:16,415
The security implications in this
case are wild and unknown, right?

109
00:07:17,070 --> 00:07:20,340
And teams inherit this fragmented,
inconsistent ecosystem,

110
00:07:20,340 --> 00:07:21,870
which is not sustainable.

111
00:07:23,130 --> 00:07:26,520
The next level is the developing
maturity where teams maintain

112
00:07:26,640 --> 00:07:28,380
a customization registry.

113
00:07:28,470 --> 00:07:32,970
At least basic reviews are happening,
but still like the long-term governance

114
00:07:33,030 --> 00:07:36,960
is missing from the picture, which
is where the high maturity comes in.

115
00:07:37,350 --> 00:07:38,820
This is where the magic happens, right?

116
00:07:38,820 --> 00:07:43,290
Customizations have clear owners,
lifecycle management exists.

117
00:07:43,350 --> 00:07:44,970
Deprecation is intentional.

118
00:07:45,120 --> 00:07:45,705
It is regular.

119
00:07:46,665 --> 00:07:52,305
Testing coverage is deep and wide, and the
security reviews aren't just ceremonial.

120
00:07:52,305 --> 00:07:53,265
They are meaningful.

121
00:07:53,835 --> 00:07:59,085
This dimension, as you can
see, helps organization balance

122
00:07:59,985 --> 00:08:04,185
between what they must customize
and with what they cannot break.

123
00:08:04,185 --> 00:08:05,805
Security hardening by over customizing.

124
00:08:10,245 --> 00:08:13,710
Alright, the third dimension
talks about observability.

125
00:08:14,040 --> 00:08:14,130
Right.

126
00:08:14,490 --> 00:08:18,720
Observability is one of the most powerful
predictors of incident reduction, right?

127
00:08:18,990 --> 00:08:21,360
It tells you what happened,
why it happened, where it

128
00:08:21,360 --> 00:08:22,770
happened, and what it touched.

129
00:08:24,360 --> 00:08:27,990
So observability spans
across these four layers.

130
00:08:28,440 --> 00:08:34,470
Application instrumentation, which is
all about, you know, code level behavior

131
00:08:34,470 --> 00:08:38,909
and application logic, execution,
infrastructure, telemetry that talks

132
00:08:38,909 --> 00:08:43,200
about system level patterns, revealing
source usage and performance indicator.

133
00:08:44,115 --> 00:08:49,455
Security event aggregation, that all
these logs that come from scanners

134
00:08:50,115 --> 00:08:54,015
identity system and the correlation
across these distributed systems.

135
00:08:54,585 --> 00:08:59,805
And the last one is trace propagation,
which is all about understanding attack

136
00:08:59,805 --> 00:09:02,085
paths across these microservices.

137
00:09:03,585 --> 00:09:07,635
But what are the security benefits
behind, you know, implementing

138
00:09:07,635 --> 00:09:09,645
a robust observability platform?

139
00:09:10,975 --> 00:09:12,750
Well, it gives you earlier detection.

140
00:09:12,930 --> 00:09:17,310
You can catch these anomalies
before they become breaches, and

141
00:09:17,310 --> 00:09:18,719
everyone wants to do that, right?

142
00:09:20,310 --> 00:09:22,350
The second one is faster investigation.

143
00:09:22,890 --> 00:09:26,760
It's all about, you know, reducing
your mean time to detect your mean time

144
00:09:26,760 --> 00:09:31,110
to remediate, and these containment
time so that you are investigating as

145
00:09:31,110 --> 00:09:35,370
fast as possible and you're reducing
your SLA or you do reducing your

146
00:09:35,370 --> 00:09:38,425
turnaround time because that all.

147
00:09:39,135 --> 00:09:40,365
Has a business impact.

148
00:09:41,175 --> 00:09:43,245
The third one is control validation.

149
00:09:43,545 --> 00:09:47,535
You empirically see what guardrails
are walking, validating those

150
00:09:47,535 --> 00:09:51,375
security control effectiveness through
empirical measure measurements.

151
00:09:51,945 --> 00:09:53,625
And the last one is continuous learning.

152
00:09:53,925 --> 00:09:58,485
Learning from the past incidents
through post mortem analysis.

153
00:10:01,725 --> 00:10:05,475
'cause every incident becomes a source
of this pattern based improvement.

154
00:10:06,105 --> 00:10:08,475
So strong observability isn't optional.

155
00:10:08,969 --> 00:10:09,959
It's foundational.

156
00:10:12,839 --> 00:10:15,930
So the first dimension that I
talked about in the previous slide

157
00:10:15,959 --> 00:10:19,109
is security guardrail, adherence.

158
00:10:22,500 --> 00:10:26,939
Guardrails generally fall into
these three categories, preventative

159
00:10:27,089 --> 00:10:28,765
detective and corrective.

160
00:10:30,545 --> 00:10:33,420
But the real differentiator
here is the maturity.

161
00:10:33,839 --> 00:10:36,724
High performing organizations
don't just create cartridge.

162
00:10:37,770 --> 00:10:44,610
They are operationalizing it so that
leadership enforces them consistently.

163
00:10:45,480 --> 00:10:49,170
These the exceptions are
clear and controlled.

164
00:10:49,470 --> 00:10:53,730
The signals are continuously
refined and the feedback loops are

165
00:10:53,730 --> 00:10:56,760
integrated into development workflows.

166
00:10:57,060 --> 00:11:02,699
When guardrail adherence is high, security
becomes the fastest path, not the slowest.

167
00:11:05,610 --> 00:11:10,440
So now that we have talked about all
these four dimensions of the framework,

168
00:11:10,620 --> 00:11:15,150
let's talk about the methodology and
you know, measuring what matters.

169
00:11:18,630 --> 00:11:22,200
So our measurement approach uses a
layered data collection architecture.

170
00:11:22,800 --> 00:11:23,730
Why layers?

171
00:11:24,095 --> 00:11:27,300
Because each dimension needs
a different data source.

172
00:11:27,810 --> 00:11:30,570
Monitoring tools, repost,
storing configuration.

173
00:11:31,335 --> 00:11:36,015
Logging and tracing platforms, scanning
engines, and policy frameworks.

174
00:11:36,015 --> 00:11:41,685
All these have different data sources,
so automation is non-negotiable.

175
00:11:41,895 --> 00:11:45,495
Manual processes create
inconsistency and they don't scale.

176
00:11:47,355 --> 00:11:51,645
So we also incorporate data quality
validation because missing or incomplete

177
00:11:51,645 --> 00:11:54,699
data often reveals infrastructure
issues that we didn't know we had.

178
00:11:55,485 --> 00:11:55,815
Right.

179
00:11:56,205 --> 00:12:00,555
So automated collection priority and
data quality validation are the two

180
00:12:00,975 --> 00:12:03,885
main concepts to prioritize here.

181
00:12:08,805 --> 00:12:13,245
Now, when we talk about establishing
thresholds, what we want to avoid is

182
00:12:13,245 --> 00:12:16,155
one site, one size fits all number.

183
00:12:17,595 --> 00:12:21,285
Instead, we created three
performance tiers, baseline

184
00:12:21,285 --> 00:12:23,445
meaning foundational health target.

185
00:12:24,270 --> 00:12:27,900
Meaning competitive performance
and excellence, meaning industry

186
00:12:27,900 --> 00:12:32,520
leading outcomes, which is where
industry leader performance achieved

187
00:12:32,520 --> 00:12:34,350
by top performing organizations.

188
00:12:36,360 --> 00:12:38,580
So the key principle here is

189
00:12:41,280 --> 00:12:43,680
thresholds must remain stable over time.

190
00:12:44,850 --> 00:12:49,175
Only then can an organization truly
understand improvement versus fluctuation.

191
00:12:55,380 --> 00:12:59,340
Let's talk about some of the different
industries that adapted these, this

192
00:12:59,340 --> 00:13:01,800
framework to their unique constraints.

193
00:13:04,530 --> 00:13:09,000
Healthcare where security intersects
with patient safety, custom

194
00:13:09,000 --> 00:13:13,740
guardrails for medical device and
data needed, and there's a significant

195
00:13:13,740 --> 00:13:16,380
compliance lift as well in retail.

196
00:13:17,055 --> 00:13:21,224
There's elastic infrastructure that
is needed with high seasonal velocity.

197
00:13:21,795 --> 00:13:25,604
Payment systems are required
with restricted thresholds.

198
00:13:26,834 --> 00:13:30,854
Now, when you, when it comes to financial
services, that's where like the most

199
00:13:30,854 --> 00:13:35,474
advanced customization governance
lives, and there's a heavy emphasis on

200
00:13:35,834 --> 00:13:37,935
resilience and regulatory stability.

201
00:13:39,285 --> 00:13:42,290
Last but not the least, we also looked
at manufacturing industry where.

202
00:13:42,675 --> 00:13:47,805
IT Convergence creates special
safety critical requirements and

203
00:13:47,805 --> 00:13:51,854
guardrails had to account for legacy
systems and long deployment cycles.

204
00:13:52,875 --> 00:13:56,204
This cross-industry validation
demonstrates the framework's

205
00:13:56,204 --> 00:13:58,334
flexibility and robustness.

206
00:14:06,479 --> 00:14:08,834
So what were some of
these measurable results?

207
00:14:09,135 --> 00:14:11,594
Uh, when we wanted to quantify our impact?

208
00:14:11,610 --> 00:14:11,700
Right.

209
00:14:12,540 --> 00:14:16,140
The organizations that implemented
all four dimensions saw very

210
00:14:16,140 --> 00:14:17,730
powerful and tangible outcomes.

211
00:14:17,730 --> 00:14:21,870
Actually, there was a major
reduction in successful attacks.

212
00:14:22,290 --> 00:14:26,730
There's a stronger operational resilience
across the board, faster and cleaner

213
00:14:26,730 --> 00:14:32,430
incident responses with shorter release
cycles, and there's fewer production

214
00:14:32,430 --> 00:14:38,430
defects that coupled with optimized
resource optimization utilization.

215
00:14:39,780 --> 00:14:41,790
And increased developer trust, right?

216
00:14:41,790 --> 00:14:46,950
These were not just theoretical results,
they were real measurable improvements

217
00:14:48,180 --> 00:14:50,700
based on using this framework.

218
00:14:55,890 --> 00:15:01,680
Now, how do you get started on this, uh,
on, you know, implementing this framework?

219
00:15:01,680 --> 00:15:01,920
Right?

220
00:15:01,980 --> 00:15:05,670
The first thing to do here is
doing a baseline assessment.

221
00:15:06,285 --> 00:15:07,964
Understand your starting point, right?

222
00:15:07,964 --> 00:15:12,074
Conduct a comprehensive assessment of all
these four dimensions and establishing

223
00:15:12,074 --> 00:15:14,265
starting points in each of these areas.

224
00:15:14,984 --> 00:15:16,905
The second one is stakeholder engagement.

225
00:15:17,324 --> 00:15:24,015
Align your stakeholders from various,
um, cross-functional teams, including

226
00:15:24,015 --> 00:15:29,025
security development, operations, product,
and establishing those regular health

227
00:15:29,025 --> 00:15:32,234
review forums for cross-functional
collaboration and strategic planning.

228
00:15:33,660 --> 00:15:39,870
Capacity development, build that
statistical literacy, those RCA, the

229
00:15:39,870 --> 00:15:41,700
root cause analysis skills, right?

230
00:15:42,030 --> 00:15:44,730
And develop these specialized
DevSecOps health roles and

231
00:15:44,730 --> 00:15:46,320
champions across the company.

232
00:15:47,580 --> 00:15:50,700
Then you get into the phased
implementation aspect of it.

233
00:15:50,850 --> 00:15:54,840
Begin with platform efficiency and
security guardrails for quick wins.

234
00:15:55,260 --> 00:15:57,930
Those are essential and you
need to build upon them.

235
00:15:58,200 --> 00:16:01,980
Then progress to customization,
resilience, and observability,

236
00:16:01,980 --> 00:16:04,680
which require a little bit
more of instrumentation.

237
00:16:06,960 --> 00:16:09,780
In terms of tool
integration, keep it simple.

238
00:16:10,350 --> 00:16:12,810
Leverage existing tools
that you currently have.

239
00:16:13,200 --> 00:16:17,190
Start by what you already
have, and less is more.

240
00:16:17,190 --> 00:16:20,100
In this case, continuous improvement.

241
00:16:20,100 --> 00:16:22,680
That's all about establishing
your regular review cycles.

242
00:16:22,740 --> 00:16:26,010
Uh, to assess the
framework's effectiveness.

243
00:16:26,010 --> 00:16:30,600
If you need to tweak something, maintain
that governance process, ensuring

244
00:16:31,590 --> 00:16:33,600
regular evolution of version control.

245
00:16:37,470 --> 00:16:42,240
Ultimately, the DevSecOps Health
Framework represents a paradigm shift,

246
00:16:43,145 --> 00:16:45,690
the shift conversion, the, the shift con.

247
00:16:46,230 --> 00:16:49,845
This shifts conversations
from opinions to data.

248
00:16:50,820 --> 00:16:55,320
From reactive firefighting to
proactive prevention and from

249
00:16:55,320 --> 00:16:57,690
siloed metrics to holistic health.

250
00:16:59,190 --> 00:17:02,610
Looking ahead, this framework will
also start to incorporate AI driven

251
00:17:02,610 --> 00:17:06,750
operations, confidential computing,
third party risks, supply chain

252
00:17:06,750 --> 00:17:08,430
security, and other things like that.

253
00:17:10,175 --> 00:17:15,480
So this journey towards DevSecOps
Health Excellence begins with honesty,

254
00:17:15,900 --> 00:17:19,890
gains momentum through discipline,
and sustains itself through evolution.

255
00:17:21,734 --> 00:17:23,954
The question is in whether
to pursue this or not.

256
00:17:24,285 --> 00:17:26,954
It's how fast your organizations
can start with this.

257
00:17:28,815 --> 00:17:29,535
So thank you.

258
00:17:29,895 --> 00:17:31,425
Thank you for your time and attention.

259
00:17:31,514 --> 00:17:34,910
I hope this session empowers
you to rethink DevSecOps Health

260
00:17:35,230 --> 00:17:36,430
holistically and strategically.

261
00:17:37,030 --> 00:17:37,149
I.

