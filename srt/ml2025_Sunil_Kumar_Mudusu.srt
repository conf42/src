1
00:00:00,300 --> 00:00:01,020
Hello everyone.

2
00:00:01,050 --> 00:00:02,490
My name is Neil Kumar Muso.

3
00:00:02,520 --> 00:00:04,200
I work in AI data engineering.

4
00:00:04,410 --> 00:00:07,920
Today I want to talk about something
really important in mission learning,

5
00:00:08,340 --> 00:00:11,640
making sure our data is clean and correct.

6
00:00:12,090 --> 00:00:19,045
We will look at these three useful tools
that help with this great expectations,

7
00:00:19,050 --> 00:00:22,260
DQ and TensorFlow data valuation.

8
00:00:23,260 --> 00:00:27,310
This slides talk about why data
quality matters in ml. Machine

9
00:00:27,310 --> 00:00:30,160
learning needs good data to work well.

10
00:00:30,490 --> 00:00:35,560
If the data is messy or wrong,
the model can make bad decisions.

11
00:00:36,040 --> 00:00:41,050
Even small mistakes in data can
cause big problems, so we cannot

12
00:00:41,050 --> 00:00:43,270
just focus on building the models.

13
00:00:43,480 --> 00:00:46,030
We can also need to check our data.

14
00:00:47,030 --> 00:00:48,800
The common data problems.

15
00:00:49,010 --> 00:00:53,330
Here are some problems we often
see in data missing values.

16
00:00:53,420 --> 00:00:58,580
Number saved as text and data
format changing over time.

17
00:00:58,820 --> 00:01:03,050
High, very high or strange
values, duplicate rules.

18
00:01:03,110 --> 00:01:04,310
This all can hurt.

19
00:01:04,340 --> 00:01:05,360
Model's performance.

20
00:01:06,360 --> 00:01:09,690
The data validation means checking
if the data is clean and correct.

21
00:01:09,750 --> 00:01:11,040
Before we train a model.

22
00:01:12,030 --> 00:01:14,820
It helps us finding a problem early.

23
00:01:14,970 --> 00:01:18,630
We can also set up to do
these checks automatically.

24
00:01:20,430 --> 00:01:24,780
Let's look at these free tools
that can help to check our data.

25
00:01:25,170 --> 00:01:28,470
Great expectations, dq
TensorFlow, data validation.

26
00:01:29,730 --> 00:01:33,570
Each tool is good for
different situations and teams.

27
00:01:35,580 --> 00:01:38,070
Great expectation is a tool in Python.

28
00:01:38,250 --> 00:01:42,870
You can write a sample rules for what
you, your data should looks like.

29
00:01:43,350 --> 00:01:47,070
It works with Pandas, SQL, and Spark.

30
00:01:47,130 --> 00:01:50,250
It also gives a clear
and nice look reports.

31
00:01:51,240 --> 00:01:56,790
It works better for Python users, handling
small to medium size of data sets, but it.

32
00:01:57,180 --> 00:02:01,440
It is not ideal for very
large or real time data.

33
00:02:02,440 --> 00:02:07,329
DQ is built by Amazon
and runs on Apache Spark.

34
00:02:07,600 --> 00:02:13,179
It's good for checking big data
and data that change a lot.

35
00:02:13,450 --> 00:02:16,630
It can also track your
data quality over time.

36
00:02:17,019 --> 00:02:22,510
It works best for AWS users,
big data or teams using Spark.

37
00:02:22,900 --> 00:02:26,950
But it is not ideal for
small projects or beginners.

38
00:02:28,989 --> 00:02:32,859
This is my favorite tool, which
is TensorFlow data validation.

39
00:02:33,340 --> 00:02:37,090
TensorFlow data validation
is part of a TensorFlow.

40
00:02:37,540 --> 00:02:43,540
It checks your data before training
a model, and it is good for dataset

41
00:02:43,869 --> 00:02:46,900
and can find a problem automatically.

42
00:02:47,470 --> 00:02:52,390
It works better for TensorFlow users,
but not for people using other ML tools.

43
00:02:53,390 --> 00:02:55,040
This slides compare the tools.

44
00:02:55,340 --> 00:02:57,530
Great expectation, easy to use.

45
00:02:57,530 --> 00:02:59,030
Work well with Python.

46
00:02:59,270 --> 00:03:09,620
DQ is best for big data or AWS Spark
setups, but TensorFlow validation is best

47
00:03:09,620 --> 00:03:12,530
for TensorFlow or production pipelines.

48
00:03:13,530 --> 00:03:19,800
So choosing the right tools, using a
great expectation for flexible rules that,

49
00:03:19,860 --> 00:03:23,730
and also clear the reports using a D dq.

50
00:03:23,940 --> 00:03:29,910
If your data is big or always changing,
this is the best tool to use, and

51
00:03:29,910 --> 00:03:33,990
if you are using a tensor flow, then
you definitely have to definitely

52
00:03:33,990 --> 00:03:36,660
use TensorFlow data validation.

53
00:03:36,840 --> 00:03:39,360
This is perfectly fit when
you're using a TensorFlow.

54
00:03:40,360 --> 00:03:41,860
Here are the key takeaways.

55
00:03:42,040 --> 00:03:42,970
Let's remember.

56
00:03:43,000 --> 00:03:45,250
The good data is just important.

57
00:03:45,250 --> 00:03:50,200
As good model, bad data can
silently hurt your results.

58
00:03:50,560 --> 00:03:55,480
We should use tools to
check data automatically.

59
00:03:56,230 --> 00:04:03,010
Great expectations, DQ or TensorFlow, data
validation all helps in a different ways.

60
00:04:05,650 --> 00:04:06,820
Here is a conclusion.

61
00:04:07,150 --> 00:04:09,190
Good data equal to a better model.

62
00:04:09,610 --> 00:04:13,870
Pick the tool that works better
for your team and your setup.

63
00:04:13,960 --> 00:04:17,500
Make sure to check your
data early and often.

64
00:04:19,870 --> 00:04:21,700
Thank you for this wonderful opportunity.

65
00:04:21,730 --> 00:04:25,420
If you have any questions or
would you like to discuss these

66
00:04:25,420 --> 00:04:28,840
tools more in detail, feel
free to connect me on LinkedIn.

67
00:04:29,020 --> 00:04:29,800
Thank you again.

68
00:04:29,860 --> 00:04:30,790
Have a nice day.

