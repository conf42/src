1
00:00:00,500 --> 00:00:01,369
Speaker 17: Hello everyone.

2
00:00:01,700 --> 00:00:05,600
My name is Kika Gupta and I'm
a software engineer at Amazon.

3
00:00:06,170 --> 00:00:11,270
Today we are going to deep dive
into a critical intersection of

4
00:00:11,270 --> 00:00:15,890
modern engineering where high
scale machine learning meets the

5
00:00:15,950 --> 00:00:19,970
operational rigor of CICD and DevOps.

6
00:00:20,210 --> 00:00:25,040
CICD stands for continuous integration
and continuous delivery pipeline.

7
00:00:25,865 --> 00:00:30,995
We will discuss how we build a system
for ML driven intellectual property

8
00:00:30,995 --> 00:00:36,995
detection that operates at massive scale,
focusing not just on model accuracy,

9
00:00:37,385 --> 00:00:43,055
but also on the cloud native enforcement
mechanisms that make these models

10
00:00:43,055 --> 00:00:45,035
viable in a production environment.

11
00:00:45,535 --> 00:00:46,525
So let's dive right in.

12
00:00:47,025 --> 00:00:51,795
The challenge IP violations At
Unprecedented Scale, the scale

13
00:00:51,855 --> 00:00:53,535
we are dealing with is immense.

14
00:00:53,955 --> 00:00:58,964
Digital marketplaces are seeing
explosive growth in IP violations.

15
00:00:59,355 --> 00:01:01,665
We aren't just processing a few items.

16
00:01:01,904 --> 00:01:06,525
We are handling millions of
new listings every single day.

17
00:01:07,514 --> 00:01:12,585
Every one of these require a
decision in near real time.

18
00:01:13,215 --> 00:01:14,055
These decisions.

19
00:01:14,789 --> 00:01:20,009
Our high stakes, they directly impact
our seller's livelihoods, our brand

20
00:01:20,009 --> 00:01:24,060
partner's rights, and the trust
our customers have placed in us.

21
00:01:24,854 --> 00:01:26,535
Let's deep dive into this a bit.

22
00:01:26,775 --> 00:01:29,445
We face a fourfold challenge.

23
00:01:29,595 --> 00:01:32,685
First volume, millions of daily listings.

24
00:01:32,984 --> 00:01:37,245
Second, high stake decisions and
enforcement action is not just a

25
00:01:37,245 --> 00:01:39,585
data point, it's a business action.

26
00:01:40,365 --> 00:01:41,984
Third, precision imperative.

27
00:01:42,315 --> 00:01:47,865
A false positive harms a
legitimate seller, whereas a false

28
00:01:47,924 --> 00:01:50,535
negative enables a bad actor.

29
00:01:51,035 --> 00:01:53,315
Finally, trust and compliance.

30
00:01:53,465 --> 00:01:58,445
We operate within a complex web of
legal and regulatory requirements

31
00:01:58,685 --> 00:02:01,115
that demand extreme accuracy.

32
00:02:01,615 --> 00:02:04,134
Why traditional approaches can't keep up.

33
00:02:04,645 --> 00:02:09,055
Traditional systems are breaking
because their limitations are

34
00:02:09,205 --> 00:02:11,305
architectural, not just technical.

35
00:02:11,805 --> 00:02:14,715
Let's look at five specific failure modes.

36
00:02:15,105 --> 00:02:16,695
First, manual review.

37
00:02:17,235 --> 00:02:22,695
Human oversight is essential for
quality, but it's impossible for volume.

38
00:02:23,085 --> 00:02:27,555
You cannot hire enough people
to review millions of listings

39
00:02:27,555 --> 00:02:31,095
per day with consistent speed
and accuracy at the same time.

40
00:02:31,675 --> 00:02:33,955
Second rule-based systems.

41
00:02:34,135 --> 00:02:37,195
These are brittle adversaries are smart.

42
00:02:37,435 --> 00:02:42,325
They see a static rule and immediately
pivot their tactics to evade it.

43
00:02:42,925 --> 00:02:49,135
Every day, we are seeing multiple mos
being popped up by the bad actors.

44
00:02:49,635 --> 00:02:51,375
Third ML only focus.

45
00:02:51,765 --> 00:02:53,145
This is a common pitfall.

46
00:02:53,505 --> 00:02:58,365
If your team only cares about F1 scores
and ignores deployment, monitoring,

47
00:02:58,365 --> 00:03:04,450
and incident response, the system will
fail in the wild static models, dec.

48
00:03:04,950 --> 00:03:10,350
Adversarial behavior evolves and
without a continuous retraining loop,

49
00:03:10,560 --> 00:03:13,050
your model becomes a legal liability.

50
00:03:13,140 --> 00:03:19,490
Within weeks five siloed teams, when
the ML researchers are separated

51
00:03:19,490 --> 00:03:25,310
from the infrastructure engineers,
you get massive blind spots and

52
00:03:25,760 --> 00:03:27,770
this low incident escalation.

53
00:03:28,270 --> 00:03:30,070
Core Insight production.

54
00:03:30,070 --> 00:03:32,290
ML is a systems problem.

55
00:03:32,830 --> 00:03:35,830
This brings us to our core
philosophy production.

56
00:03:35,830 --> 00:03:39,550
ML is a systems problem,
not a modeling problem.

57
00:03:39,970 --> 00:03:44,680
Detection accuracy is necessary,
but it is insufficient.

58
00:03:45,130 --> 00:03:50,860
Even a 99.9% accurate model is a
failure if you cannot roll it back

59
00:03:50,860 --> 00:03:53,530
instantly when it hits a new med case.

60
00:03:54,355 --> 00:03:55,765
So here are the key pillars.

61
00:03:56,485 --> 00:03:59,455
Real world enforcement
requires operational rigor.

62
00:04:00,175 --> 00:04:05,125
We must maintain visibility, handle
rollbacks gracefully, and earn

63
00:04:05,125 --> 00:04:07,225
business trust through reliability.

64
00:04:07,945 --> 00:04:12,745
This is a full stack engineering
challenge that requires us to prioritize

65
00:04:13,015 --> 00:04:18,655
reliability over raw accuracy and
use observability to detect drift

66
00:04:18,835 --> 00:04:20,905
before it becomes an incident.

67
00:04:21,405 --> 00:04:22,815
High level system architecture.

68
00:04:23,260 --> 00:04:28,515
Our architecture treats the entire
pipeline as a unified observable system.

69
00:04:28,905 --> 00:04:33,945
It is designed to separate concerns while
maintaining end-to-end traceability.

70
00:04:34,515 --> 00:04:36,675
Here are the components
within our pipeline.

71
00:04:37,485 --> 00:04:38,415
Real time ingestion.

72
00:04:38,775 --> 00:04:40,000
We use a streaming pipeline.

73
00:04:40,345 --> 00:04:42,415
To ingest millions of events.

74
00:04:42,865 --> 00:04:44,965
Number two, multimodal detection.

75
00:04:45,355 --> 00:04:47,155
We do not rely on one signal.

76
00:04:47,455 --> 00:04:51,985
We analyze images, text and
seller behavior in conjunction to

77
00:04:51,985 --> 00:04:53,635
make the best possible decision.

78
00:04:54,295 --> 00:04:59,455
Number three, event driven orchestration,
intelligent routing based on.

79
00:04:59,945 --> 00:05:07,085
Humans based on models confidence, human
plus LLM verification, A hybrid approach

80
00:05:07,265 --> 00:05:13,135
for edge cases that we take observability
and feedback a loop where monitoring

81
00:05:13,165 --> 00:05:15,505
directly drives model improvement.

82
00:05:16,345 --> 00:05:18,055
Online and offline separation.

83
00:05:18,415 --> 00:05:22,795
This allows us to run inference in
real time while retraining models

84
00:05:22,855 --> 00:05:24,655
independently in the background.

85
00:05:25,155 --> 00:05:26,775
Multimodal detection engine.

86
00:05:27,435 --> 00:05:30,885
So different signals capture
different evasion tactics.

87
00:05:31,065 --> 00:05:36,255
Bad actors might obfuscate text or
manipulate images, but it's much harder

88
00:05:36,255 --> 00:05:39,075
to hide when you combine the modalities.

89
00:05:39,495 --> 00:05:41,235
So here's our technical stack.

90
00:05:41,535 --> 00:05:45,585
We use a weighted ensemble
approach for images.

91
00:05:45,705 --> 00:05:48,165
We use a fine tuned YOLO V seven model.

92
00:05:48,665 --> 00:05:51,995
Or Roberta for object detection for text.

93
00:05:52,145 --> 00:05:56,885
We utilize domain adapted bird
models to understand semantic context

94
00:05:57,065 --> 00:05:58,595
rather than just keyword matching.

95
00:05:59,195 --> 00:06:04,565
We also integrate behavior signals
like seller history, seller enforcement

96
00:06:04,565 --> 00:06:08,990
actions other platforms on which
the seller is selling, et cetera.

97
00:06:09,490 --> 00:06:16,780
The key advantage is that this modality
independence is crucial for CICD.

98
00:06:17,410 --> 00:06:21,700
We can upgrade the image detection
model without touching the text model.

99
00:06:22,210 --> 00:06:28,060
This reduces regression risk and allows
for a much faster deployment cycle.

100
00:06:28,560 --> 00:06:31,020
Vector similarity, surge at scale.

101
00:06:31,650 --> 00:06:36,120
So the engine behind our detection
is embedding based similarity.

102
00:06:36,570 --> 00:06:38,340
Let me explain the workflow here a bit.

103
00:06:38,760 --> 00:06:44,460
We convert both images and text
into dense vector representations.

104
00:06:45,210 --> 00:06:49,950
After that, we pre-compute a
reference index of known violations

105
00:06:50,460 --> 00:06:51,785
when a new listing comes in.

106
00:06:52,370 --> 00:06:57,350
We perform A KNN, which stands for
KN nearest neighbor search, using

107
00:06:57,350 --> 00:07:02,620
cosign similarity to handle the scale
we use approximate nearest neighbor,

108
00:07:02,825 --> 00:07:05,080
a NN search via AWS open search.

109
00:07:05,530 --> 00:07:10,975
This allows us to trade a. Tiny fraction
of recall for massive gains in latency,

110
00:07:11,305 --> 00:07:14,005
specifically subsecond P 99 latency.

111
00:07:14,245 --> 00:07:18,955
Even at millions of queries per
second, we use index versioning.

112
00:07:19,235 --> 00:07:21,035
Every index is immutable.

113
00:07:21,275 --> 00:07:25,715
If a new deployment degrades
quality, we can perform an instant

114
00:07:25,715 --> 00:07:27,520
rollback to the previous version.

115
00:07:28,020 --> 00:07:29,820
Event driven orchestration.

116
00:07:30,540 --> 00:07:33,870
Our backbone is an event
driven orchestration.

117
00:07:34,410 --> 00:07:38,100
Our architecture designed for failure.

118
00:07:38,580 --> 00:07:43,140
We use Amazon Kinesis for real-time
ingestion, and here's how we

119
00:07:43,140 --> 00:07:45,420
handle all these ingestion events.

120
00:07:45,870 --> 00:07:51,450
Listings are routed via S-N-S-S-Q-S based
on the confidence score of the ML model.

121
00:07:51,950 --> 00:07:56,480
Complex workflows are handled by AWS
step functions, which provide built-in

122
00:07:56,480 --> 00:07:58,490
retrial, logic and error handling.

123
00:07:59,090 --> 00:08:01,550
We focus heavily on reliability.

124
00:08:02,030 --> 00:08:05,690
Every component is designed with
circuit breakers and back pressure.

125
00:08:06,140 --> 00:08:08,030
If a downstream service is struggling.

126
00:08:08,675 --> 00:08:11,465
We rate limited to prevent
cascading failures.

127
00:08:11,765 --> 00:08:15,545
Perhaps most importantly, we
use immutable event streams.

128
00:08:15,875 --> 00:08:21,185
This allows us to replay a sequence
of events to debug exactly where a

129
00:08:21,185 --> 00:08:26,105
specific decision to debug exactly
why a specific decision was made.

130
00:08:26,605 --> 00:08:28,705
Confidence based enforcement strategy.

131
00:08:29,095 --> 00:08:31,345
Not all enforcement actions are equal.

132
00:08:31,705 --> 00:08:36,775
Our system maps ML confidence scores
directly to business policies.

133
00:08:37,555 --> 00:08:39,865
These are the different
tiers that we operate in.

134
00:08:40,165 --> 00:08:44,575
High confidence triggers
immediate listing removal, or in

135
00:08:44,575 --> 00:08:46,465
some cases, account suspension.

136
00:08:46,855 --> 00:08:49,440
These require more than 99% position.

137
00:08:50,440 --> 00:08:55,060
Medium confidence triggers a seller
warning or educational intervention,

138
00:08:55,270 --> 00:08:59,860
or in some cases listing removal as
well, depending on the seller history.

139
00:09:00,490 --> 00:09:06,780
Low to medium confidence listings are sent
to a manual review queue, the governance.

140
00:09:06,780 --> 00:09:09,540
Finally, this makes the system auditable.

141
00:09:09,870 --> 00:09:13,980
Legal, and trust teams can
modify these thresholds in.

142
00:09:14,625 --> 00:09:19,005
In an app config without
needing a developer to retrain

143
00:09:19,005 --> 00:09:20,800
or redeploy the ML models.

144
00:09:21,300 --> 00:09:23,305
LLM assisted verification.

145
00:09:23,845 --> 00:09:28,525
For those medium confidence cases,
we use large language models,

146
00:09:28,675 --> 00:09:31,105
LLMs to augment human judgment.

147
00:09:31,555 --> 00:09:34,015
The LLM acts as a reasoning engine.

148
00:09:34,585 --> 00:09:39,865
It aggregates similarity scores, seller
history, sellers enforcement actions,

149
00:09:39,925 --> 00:09:45,745
and metadata to generate a structured
decision with a supporting rationale.

150
00:09:46,510 --> 00:09:47,710
What has been the impact?

151
00:09:47,710 --> 00:09:49,120
It has been transformative.

152
00:09:49,450 --> 00:09:55,930
We have seen a 78% auto verification
rate for medium confidence cases and a

153
00:09:55,930 --> 00:09:59,500
68% reduction in manual review workload.

154
00:10:00,100 --> 00:10:04,060
Because the LLM provides an
explanation, the appeal win rate

155
00:10:04,060 --> 00:10:08,770
has improved significantly as we
can provide sellers with clear

156
00:10:08,800 --> 00:10:11,110
defensible reasons for enforcement.

157
00:10:11,610 --> 00:10:13,890
CICD and model governance.

158
00:10:14,340 --> 00:10:18,750
We treat models as first class
software artifact artifacts.

159
00:10:19,140 --> 00:10:23,400
This means strict versioning
in a model registry with full

160
00:10:23,400 --> 00:10:25,770
lineage and approval workflows.

161
00:10:26,510 --> 00:10:28,550
So the model pipeline is as follows.

162
00:10:28,850 --> 00:10:33,260
Every model candidate undergoes
automated evaluation against

163
00:10:33,260 --> 00:10:36,110
holdout sets before it goes live.

164
00:10:36,320 --> 00:10:37,700
It runs in shadow mode.

165
00:10:38,160 --> 00:10:41,790
It produces production traffic
and generates decisions, but

166
00:10:41,790 --> 00:10:43,590
those decisions are not enforced.

167
00:10:43,890 --> 00:10:47,220
We compare these results to
the current production model.

168
00:10:47,720 --> 00:10:50,300
And decide the next steps accordingly.

169
00:10:50,690 --> 00:10:54,980
We use gradual rollouts with
automated quality gates.

170
00:10:55,370 --> 00:10:59,480
If the system detects any degradation,
it triggers an auto rollback.

171
00:10:59,990 --> 00:11:05,750
This cultural shift, knowing that the
system will protect itself, has allowed

172
00:11:05,750 --> 00:11:07,910
us to double our release velocity.

173
00:11:08,410 --> 00:11:10,510
Observability and monitoring.

174
00:11:11,080 --> 00:11:13,810
We monitor three distinct layers.

175
00:11:14,320 --> 00:11:18,880
Business metrics like false
positive rates, true positive rates,

176
00:11:18,880 --> 00:11:20,800
false negative rates, et cetera.

177
00:11:21,250 --> 00:11:26,350
System metrics like API latency,
API, throughputs error rates

178
00:11:26,630 --> 00:11:31,070
failure rates, et cetera, and
model metrics like feature drift.

179
00:11:31,550 --> 00:11:33,825
We have early warning systems in place.

180
00:11:34,560 --> 00:11:37,650
We do not just wait for accuracy to drop.

181
00:11:38,220 --> 00:11:42,600
We monitor the distribution
of confidence scores.

182
00:11:43,080 --> 00:11:47,100
If we see a shift in that
distribution, it's an early warning

183
00:11:47,100 --> 00:11:52,530
of model decay or an adversarial
pivot often detected within hours.

184
00:11:52,980 --> 00:11:59,580
This unified view ensures the ML engineers
and support engineers that all of them

185
00:11:59,580 --> 00:12:01,710
are looking at the same source of truth.

186
00:12:02,210 --> 00:12:04,520
Incident response and debugging.

187
00:12:05,120 --> 00:12:11,210
Production insights are inevitable at our
scale, so we have architected our system

188
00:12:11,420 --> 00:12:16,940
to make them manageable through rigorous
engineering rather than guesswork.

189
00:12:17,630 --> 00:12:23,390
Our goal was to turn debugging from
an art into a repeatable science.

190
00:12:24,050 --> 00:12:25,805
So what is in our arsenal?

191
00:12:26,495 --> 00:12:32,735
Trace IDs we use end-to-end trace IDs to
follow a listings journey across every

192
00:12:32,735 --> 00:12:35,345
service, hop to the final destination.

193
00:12:35,915 --> 00:12:41,465
Event replay immutable streams allow
us to determine ally reproduce and

194
00:12:41,465 --> 00:12:48,155
investigate incidents by replaying the
exact event sequences, structured logs.

195
00:12:48,605 --> 00:12:54,755
We query logs by listing seller or model
version to isolate root causes instantly.

196
00:12:55,255 --> 00:13:02,095
We have couple of response scenarios, like
latency spikes, if the downstream service

197
00:13:02,185 --> 00:13:06,925
degrades, the circuit breakers, activate
and shift traffic to backup regions.

198
00:13:07,615 --> 00:13:08,845
False positive waves.

199
00:13:09,205 --> 00:13:15,355
If feature drift causes a wave of
errors, auto rollback triggers and

200
00:13:15,835 --> 00:13:17,935
affected decisions are reversed.

201
00:13:18,505 --> 00:13:22,765
Data corruption, schema changes or
passing errors are caught at the

202
00:13:22,765 --> 00:13:26,910
ingestion and routed to dead letter
queues to prevent pipeline poison.

203
00:13:27,695 --> 00:13:28,835
What has been the result?

204
00:13:29,255 --> 00:13:34,295
By using all the run books and error
budgets, we have dropped our meantime

205
00:13:34,295 --> 00:13:37,085
to resolution from hours to minutes.

206
00:13:37,585 --> 00:13:40,915
The results and operational
impact, the results have been

207
00:13:40,915 --> 00:13:44,305
incredible and impact is clear.

208
00:13:44,665 --> 00:13:49,225
We have doubled our throughput
and we have halved RP 99 latency.

209
00:13:49,705 --> 00:13:55,135
We have reduced manual review by 68%
while doubling our release velocity.

210
00:13:55,780 --> 00:13:56,470
But why?

211
00:13:56,860 --> 00:13:57,850
Here's the answer.

212
00:13:58,240 --> 00:14:03,460
These metrics are great, but the
real win is trust by making the

213
00:14:03,460 --> 00:14:05,920
system reliable and observable.

214
00:14:06,370 --> 00:14:11,350
We have moved from a world where ML
was a black box to a world where it

215
00:14:11,350 --> 00:14:15,805
is a trustworthy, fundamental part
of our enforcement infrastructure.

216
00:14:16,305 --> 00:14:21,105
To conclude production ML is
about the convergence of ML

217
00:14:21,105 --> 00:14:23,595
expertise and DevOps discipline.

218
00:14:24,105 --> 00:14:27,915
The systems that win aren't
just the most accurate.

219
00:14:28,245 --> 00:14:32,835
They are the most observable
and the most resilient systems.

220
00:14:33,225 --> 00:14:39,075
Remember, engineer for failure,
prioritize deployment over

221
00:14:39,135 --> 00:14:44,380
training and use automation to
create velocity through safety.

222
00:14:44,880 --> 00:14:45,390
Thank you.

