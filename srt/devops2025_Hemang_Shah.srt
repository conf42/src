1
00:00:00,220 --> 00:00:03,830
Hi, I'm Hemang and I'm a
software developer at amazon.

2
00:00:04,030 --> 00:00:04,320
com.

3
00:00:05,110 --> 00:00:09,040
I have a lot of experience in working
with machine learning models, which are

4
00:00:09,040 --> 00:00:11,300
tasked to identify intellectual property.

5
00:00:11,595 --> 00:00:14,665
such as logos, copyrights, or trademarks.

6
00:00:15,465 --> 00:00:21,045
I worked on how to fine tune ML models,
how to recompile them, how to deploy

7
00:00:21,045 --> 00:00:25,754
them in cloud environments at scale,
you know, to the likes of 20, 000,

8
00:00:25,755 --> 00:00:28,784
transactions per second and setting up.

9
00:00:29,485 --> 00:00:35,905
Human assisted AI frameworks, to enable
iterative development of ML models

10
00:00:36,125 --> 00:00:41,124
and also improvement in precision
and recall of IP monitoring systems.

11
00:00:41,844 --> 00:00:48,265
So today I'm excited to give a talk on how
human assisted AI is revolutionizing the

12
00:00:48,760 --> 00:00:50,880
intellectual property monitoring space.

13
00:00:51,290 --> 00:00:55,990
we'll talk about how human expertise,
along with machine learning models,

14
00:00:56,100 --> 00:01:00,669
basically cutting edge AI, can help
improve the precision, recall, and

15
00:01:00,669 --> 00:01:05,439
scalability of IP monitoring systems,
thereby allowing, organizations

16
00:01:05,509 --> 00:01:08,289
to stay ahead of the curve and
protect their intellectual property.

17
00:01:08,789 --> 00:01:13,099
Protecting intellectual property is one
of the key challenges and one of the

18
00:01:13,099 --> 00:01:15,539
most important challenges for companies.

19
00:01:16,179 --> 00:01:20,419
Estimates show that globally
companies take a one trillion dollar

20
00:01:20,589 --> 00:01:25,239
loss due to use of counterfeit
goods and copyright infringement.

21
00:01:25,884 --> 00:01:29,144
what we've seen is that in the
last few years, this number has

22
00:01:29,174 --> 00:01:30,844
been exponentially increasing.

23
00:01:31,174 --> 00:01:36,624
And that's majorly because of newer and
innovative techniques or technologies

24
00:01:36,644 --> 00:01:38,234
that are available to bad actors.

25
00:01:38,654 --> 00:01:39,834
one of which is Gen AI.

26
00:01:40,494 --> 00:01:45,564
we've seen bad actors use generative AI
to quickly, you know, generate content

27
00:01:45,854 --> 00:01:50,214
that's, infringing on intellectual
property of organizations and put it

28
00:01:50,214 --> 00:01:54,424
out there on the web and, you know,
other channels, other media, and,

29
00:01:54,464 --> 00:01:57,434
and thereby, you know, these, the
losses have just been increasing.

30
00:01:58,094 --> 00:01:59,164
So because of these.

31
00:01:59,704 --> 00:02:05,534
Companies need advanced systems which
actively monitor for, you know, illegal

32
00:02:05,554 --> 00:02:07,744
use of their IPs and, take action.

33
00:02:08,244 --> 00:02:10,174
This is where AI comes into the picture.

34
00:02:10,434 --> 00:02:13,804
There are numerous models available
out there for different use

35
00:02:13,804 --> 00:02:15,514
cases that companies can use.

36
00:02:15,784 --> 00:02:19,334
in the IP detection space,
let's go over some of them.

37
00:02:20,214 --> 00:02:23,984
One of the, one of the techniques is
to perform embedding based searches.

38
00:02:24,884 --> 00:02:28,304
as opposed to keyword based searches,
embedding based searches are far

39
00:02:28,304 --> 00:02:33,404
superior because, they're inherently
performing semantic searches, whereas

40
00:02:33,404 --> 00:02:38,154
key keyword based searches are naive and
basically just string searches, right?

41
00:02:38,704 --> 00:02:39,134
so.

42
00:02:39,609 --> 00:02:44,479
There are models, such as the CLIP
model or, OpenAI's Dolly, which

43
00:02:44,479 --> 00:02:46,449
helps generate embeddings for images.

44
00:02:46,749 --> 00:02:52,439
These models can be used to convert
any entity, you know, such as text,

45
00:02:52,509 --> 00:02:57,479
or an image into vector representation
or something that we call embeddings.

46
00:02:57,919 --> 00:03:01,929
And these embeddings would have all the
contextual understanding of the entity.

47
00:03:02,469 --> 00:03:06,089
Similarly, you generate embeddings
of your query, your search query,

48
00:03:06,219 --> 00:03:07,879
and perform a similarity search.

49
00:03:08,099 --> 00:03:13,159
So this can be used for, you know, use
cases such as identifying similar images

50
00:03:13,279 --> 00:03:17,209
and similar content to detect potential
infringements of your copyrights.

51
00:03:17,919 --> 00:03:20,779
another method is using
natural language processing.

52
00:03:21,649 --> 00:03:25,709
There are state of the art models
such as BERT and Roberta, which

53
00:03:25,769 --> 00:03:27,959
are amazing in analyzing text.

54
00:03:28,179 --> 00:03:33,219
So these models can be used to, you know,
if I were to give an example, identify if

55
00:03:33,319 --> 00:03:35,879
the usage of the term apple in a sentence.

56
00:03:36,289 --> 00:03:40,869
is in context to the fruit
apple or the company apple.

57
00:03:41,459 --> 00:03:45,569
such use cases can help analyze
text for copyright violations

58
00:03:45,599 --> 00:03:47,149
or trademark infringements.

59
00:03:47,719 --> 00:03:49,709
then we have the vision suite of models.

60
00:03:50,079 --> 00:03:53,149
there are models such as
the YOLO family of models.

61
00:03:53,579 --> 00:03:55,719
YOLO stands for you only look once.

62
00:03:56,149 --> 00:04:02,289
so the YOLO V5 or YOLO V7 models and
the newer models such as the VIT models,

63
00:04:02,509 --> 00:04:04,899
also, short for vision transformers.

64
00:04:05,500 --> 00:04:10,330
These models are really good in
analyzing an image holistically.

65
00:04:10,640 --> 00:04:14,290
so these can analyze image
and detect unauthorized use of

66
00:04:14,350 --> 00:04:16,160
logos, trademarks, and so on.

67
00:04:16,660 --> 00:04:18,980
Then comes the large,
large language models.

68
00:04:19,310 --> 00:04:20,880
In the last two to three years.

69
00:04:21,300 --> 00:04:23,650
Large language models
have picked up immensely.

70
00:04:23,800 --> 00:04:28,400
There's been a boom going on and these are
basically models which have been trained

71
00:04:28,400 --> 00:04:33,179
on humongous amount of data, almost to
the likes of the entire internet, right?

72
00:04:34,009 --> 00:04:38,179
so these models have, these models
have enough context already.

73
00:04:38,709 --> 00:04:41,479
They can be used to solve
really complex problems.

74
00:04:41,539 --> 00:04:45,779
You can just give it a research paper
and ask it to do a plagiarism check.

75
00:04:46,109 --> 00:04:50,989
Or you could give them, give these
models an image and ask the model to

76
00:04:50,989 --> 00:04:56,079
identify, you know, if the image has
illegal use of a brand's logo and so on.

77
00:04:56,579 --> 00:04:58,479
But AI has its own limitations as well.

78
00:04:59,294 --> 00:05:03,454
AI cannot use, cannot be used
in standalone because there's

79
00:05:03,494 --> 00:05:04,824
only so much it can do.

80
00:05:05,664 --> 00:05:09,764
Artificial intelligence is excellent
at detecting known patterns and

81
00:05:09,764 --> 00:05:14,584
statistical anomalies, but it does
not do really well in the unknown.

82
00:05:15,024 --> 00:05:18,034
if I were to give you an example,
for example, let's take LLMs,

83
00:05:18,764 --> 00:05:23,014
LLM being trained on, you know,
almost The entire internet's data.

84
00:05:23,364 --> 00:05:28,374
It would be really good in identifying,
you know, the use of Nike's logo or

85
00:05:28,374 --> 00:05:32,754
adidas's logo, but if tomorrow I were
to launch my own company and create

86
00:05:32,754 --> 00:05:39,044
a create my own logo LLM would not be
able to identify the use of my company's

87
00:05:39,104 --> 00:05:43,654
logo in you know, images all over the
internet because It would not have

88
00:05:43,654 --> 00:05:50,614
been trained on On on the data which
includes my logo, right so ML models

89
00:05:50,614 --> 00:05:55,734
can only perform in cases where, they
have context or they have, the, the,

90
00:05:55,774 --> 00:05:57,664
the knowledge on taking decisions.

91
00:05:58,164 --> 00:06:00,555
the other problem that, you know, LLMs is.

92
00:06:01,265 --> 00:06:06,365
The problem of hallucination, for the same
query, for the same request, it can give

93
00:06:06,365 --> 00:06:08,355
you different answers in different times.

94
00:06:08,545 --> 00:06:14,655
Then, you know, that's when these are
cases where, the LLMs or models are not

95
00:06:14,775 --> 00:06:16,625
confident enough to take a decision.

96
00:06:17,385 --> 00:06:18,649
So human expertise.

97
00:06:18,650 --> 00:06:24,480
A human is far, has far more
superior contextual understanding

98
00:06:24,790 --> 00:06:29,410
and can take judgment in complex
situations whereas the AI cannot.

99
00:06:29,850 --> 00:06:35,080
So what we propose is a amalgamation
of human expertise along with

100
00:06:35,300 --> 00:06:41,830
AI's capabilities to create IP
monitoring systems that are superior

101
00:06:41,860 --> 00:06:43,800
in terms of precision and recall.

102
00:06:44,300 --> 00:06:48,350
A very basic, approach to this
would be, you know, a human machine

103
00:06:48,350 --> 00:06:54,880
collaboration where you let the machine
take potential decisions, you let

104
00:06:54,920 --> 00:06:57,905
the machine take, make inferences,
but you do not take, decisions.

105
00:06:58,215 --> 00:07:01,495
automated actions based on,
you know, just the ML model.

106
00:07:01,765 --> 00:07:04,945
Let the machine learning
model give you an output.

107
00:07:05,305 --> 00:07:08,905
And then a human reviews the output
of this machine learning model.

108
00:07:09,395 --> 00:07:13,745
So when I say human, it would be
an expert in that domain who is,

109
00:07:13,845 --> 00:07:18,435
flagging and, Re verifying the
output of the machine learning model.

110
00:07:18,605 --> 00:07:22,975
So based on the human output, you
can take actions, for the certain

111
00:07:22,975 --> 00:07:24,985
situation, for the situations.

112
00:07:25,385 --> 00:07:29,865
And also now you have a golden
set of data that can be used

113
00:07:29,965 --> 00:07:31,565
to fine tune your ML model.

114
00:07:31,875 --> 00:07:34,345
And create the next
version of your ML model.

115
00:07:34,845 --> 00:07:39,770
So this is what we call active learning
where the machine or the model is

116
00:07:39,840 --> 00:07:41,840
actively learning from the human.

117
00:07:42,580 --> 00:07:45,190
There are two main advantages
of active learning.

118
00:07:45,490 --> 00:07:49,150
One is improvement in precision and
the other is improvement in recall.

119
00:07:49,650 --> 00:07:55,120
By improvement in precision, what
I mean is the model is now better.

120
00:07:55,300 --> 00:07:57,940
at tasks which it was previously good at.

121
00:07:58,020 --> 00:08:02,400
So say there are situations which the
model was able to identify, but there was

122
00:08:02,460 --> 00:08:07,180
some false positives, in the output of
the model, which was audited by the human.

123
00:08:07,690 --> 00:08:11,700
The next version of the model will
no longer have these false positives.

124
00:08:11,870 --> 00:08:15,380
So the model has now become
better in situations which

125
00:08:15,380 --> 00:08:17,060
it was doing okay at before.

126
00:08:17,540 --> 00:08:19,590
This is what we call
improvement in precision.

127
00:08:20,090 --> 00:08:24,720
Improvement in recall is basically
the model is now able to identify

128
00:08:24,720 --> 00:08:28,130
new patterns, which it was
previously not even able to detect.

129
00:08:28,360 --> 00:08:31,990
So these are better edge case
handling that the model is able

130
00:08:31,990 --> 00:08:33,810
to do in the newer versions.

131
00:08:34,300 --> 00:08:38,220
If I were to give an example, say
we have a logo detection model.

132
00:08:38,720 --> 00:08:43,170
the model was previously able
to accurately identify logos

133
00:08:43,210 --> 00:08:46,000
of brand X, but not of brand Y.

134
00:08:46,820 --> 00:08:51,450
The human audits the data and
annotates the images with, which

135
00:08:51,450 --> 00:08:53,460
have the logos of brand Y as well.

136
00:08:54,445 --> 00:08:58,315
This data is fed back into the model and
the next version of the model is trained.

137
00:08:58,725 --> 00:09:02,165
The new version of the model will
now be able to identify logos

138
00:09:02,215 --> 00:09:04,195
of both brand X and brand Y.

139
00:09:04,525 --> 00:09:09,825
So these are newer situations that
the model is now able to identify.

140
00:09:09,970 --> 00:09:13,820
So this is what we call
improvement in recall.

141
00:09:14,330 --> 00:09:18,700
what we generally see is when we
compare, you know, just a ML model,

142
00:09:19,480 --> 00:09:24,350
in contrast to a framework where
we have a human AI, human AI setup.

143
00:09:24,870 --> 00:09:29,110
in the human AI setup, we generally
see that there's a 20 percent increase

144
00:09:29,130 --> 00:09:33,390
in precision and almost a 25 percent
improvement in recall over time.

145
00:09:33,890 --> 00:09:35,185
And these numbers just keep increasing.

146
00:09:35,335 --> 00:09:38,605
Increasing with more the
number of iterations there are.

147
00:09:39,105 --> 00:09:43,105
So how do we make this human
AI framework more scalable?

148
00:09:43,745 --> 00:09:45,155
There are two components to it, right?

149
00:09:45,415 --> 00:09:47,735
the human component and the AI component.

150
00:09:48,195 --> 00:09:52,485
To make the AI component scalable, the
best strategy would be to deploy your

151
00:09:52,515 --> 00:09:54,175
machine learning workloads on the cloud.

152
00:09:55,140 --> 00:09:59,920
There are multiple cloud service providers
out there, such as Microsoft Azure, Amazon

153
00:09:59,920 --> 00:10:06,120
Web Services, Google Cloud Platform, and
these have numerous services, which are

154
00:10:06,270 --> 00:10:10,530
at your disposal, available out of the
box for, different parts of this pipeline.

155
00:10:11,050 --> 00:10:15,080
for example, they offer compute
services where you can containerize

156
00:10:15,210 --> 00:10:17,130
your machine learning workloads.

157
00:10:17,145 --> 00:10:21,915
Or, ML code and deploy it on
instances which can be auto

158
00:10:21,915 --> 00:10:23,535
scaled based on your traffic.

159
00:10:23,955 --> 00:10:27,915
At times of peak, the number of ML
instances increase, and then there's

160
00:10:27,915 --> 00:10:29,835
no peak or there's hardly any traffic.

161
00:10:30,135 --> 00:10:35,895
Your ML instances threat use, this is not
really possible in on premise solutions.

162
00:10:36,685 --> 00:10:40,285
they offer a lot of data
integration services as well.

163
00:10:40,610 --> 00:10:46,540
So you could host all your human
audit data on, NoSQL databases in the

164
00:10:46,550 --> 00:10:51,960
cloud and this, these databases can
automatically be ingested or linked

165
00:10:52,070 --> 00:10:56,870
to your machine learning, instances
or machine, machine learning pipelines

166
00:10:56,920 --> 00:11:01,630
on the cloud, which act, and this data
could act as the training data for

167
00:11:01,670 --> 00:11:03,580
every, every new version of the model.

168
00:11:04,080 --> 00:11:05,550
Now, how can we make the system scalable?

169
00:11:06,410 --> 00:11:07,510
from the human angle.

170
00:11:08,010 --> 00:11:13,290
The goal over here is to reduce dependency
on the human as much as possible.

171
00:11:13,490 --> 00:11:17,630
And the human should have the least
number of human touch points as possible.

172
00:11:18,180 --> 00:11:23,430
so what happens is that over time with
few, few iterations of the system and

173
00:11:23,430 --> 00:11:28,530
few model versions, you would see that
the model is performing really well

174
00:11:28,950 --> 00:11:30,570
with high precision and high recall.

175
00:11:31,050 --> 00:11:33,210
in certain use cases.

176
00:11:33,650 --> 00:11:39,700
for example, if I had a logo detection
model, the My model would start performing

177
00:11:39,780 --> 00:11:45,185
really well in identifying logos on
shoes But it might not be very well on

178
00:11:45,225 --> 00:11:51,675
identifying logos on bags so now A human
no longer needs to see the output of the

179
00:11:51,685 --> 00:11:57,045
model For where all the images are that
of shoes because you have a high accuracy

180
00:11:57,085 --> 00:12:02,470
in that Product category, and you're going
to let the model take automatic decisions

181
00:12:02,770 --> 00:12:04,760
and actions for those categories.

182
00:12:05,450 --> 00:12:11,900
So what you then do is you let the AI flag
what is important for a human to review.

183
00:12:12,340 --> 00:12:16,945
So in the shoes category, you would
let AI to take automated actions.

184
00:12:17,245 --> 00:12:21,725
But in the backs category, you would
park all the decisions for human audit.

185
00:12:22,545 --> 00:12:25,735
You would, accumulate all the human
audits across all the different

186
00:12:25,765 --> 00:12:29,795
product categories, which the model
is not able to accurately determine.

187
00:12:30,615 --> 00:12:34,595
And then you would have an algorithm
that prioritizes the human audit.

188
00:12:34,625 --> 00:12:38,435
You would pick, you know, categories
that are important for your use case,

189
00:12:38,865 --> 00:12:42,995
and then let the human only review
those use cases or those, audits.

190
00:12:42,995 --> 00:12:43,455
Okay.

191
00:12:43,955 --> 00:12:48,575
And so now you have technically reduced
the number of audits that a human

192
00:12:48,575 --> 00:12:53,335
has to do, and you feed that into the
next version of the model training.

193
00:12:53,765 --> 00:12:57,835
So thereby you have now reduced
the dependency on the human as well

194
00:12:57,955 --> 00:12:59,405
and made the system more scalable.

195
00:12:59,905 --> 00:13:03,435
by doing this, by offloading, you know,
What we generally see is by offloading

196
00:13:03,435 --> 00:13:08,735
40 percent of the workload from the
human, you're still able to maintain

197
00:13:08,745 --> 00:13:11,325
95 percent of precision in most cases.

198
00:13:11,825 --> 00:13:16,675
So, yeah, in a nutshell, the
human assisted AI, combination.

199
00:13:17,060 --> 00:13:21,710
Has a lot of benefits, especially for
brand protection and IP monitoring.

200
00:13:22,140 --> 00:13:28,610
we see improved precision, high amount of,
recall and very less false positive rates

201
00:13:28,800 --> 00:13:31,450
than, you know, a human assists an AI.

202
00:13:31,950 --> 00:13:35,800
So what should be the mental model
of someone who is implementing

203
00:13:35,920 --> 00:13:40,380
a human assisted AI framework
for IP detection use cases.

204
00:13:40,950 --> 00:13:42,210
So step one is to.

205
00:13:43,160 --> 00:13:48,520
Assess the entire IP, IP evaluation
framework as it stands today.

206
00:13:48,930 --> 00:13:53,970
Identify which parts of your system
are good at taking automated decisions,

207
00:13:54,120 --> 00:13:58,390
and which parts are not that good
and need some input from the human.

208
00:13:58,940 --> 00:14:02,710
because only the parts which have
high false positive rates, would

209
00:14:02,710 --> 00:14:06,530
be the parts where, Step 3 would be
to develop an integration strategy,

210
00:14:06,960 --> 00:14:11,620
which basically means that, like,
where would a human audit the data?

211
00:14:11,980 --> 00:14:16,270
You would need some sort of a user
interface which outputs, which

212
00:14:16,270 --> 00:14:20,000
displays the output of the model
and where, where human auditors

213
00:14:20,040 --> 00:14:21,700
can come and audit the data.

214
00:14:22,200 --> 00:14:27,610
All you then need to figure out what the
output data of this audit would look like.

215
00:14:27,680 --> 00:14:31,890
And it should be seamlessly
integrated with the ML model.

216
00:14:31,990 --> 00:14:36,920
What the, the form of input that the
training of the ML model can take so

217
00:14:36,920 --> 00:14:41,480
that all of this output is readily
fed into the system, for training

218
00:14:41,480 --> 00:14:42,670
of the next version of the model.

219
00:14:43,550 --> 00:14:46,720
You would then have to train the
teams on how to audit this data

220
00:14:46,850 --> 00:14:48,460
and finally train your ML models.

221
00:14:49,130 --> 00:14:54,280
The audit and, retraining of the model
should be monitored and repeatedly

222
00:14:54,290 --> 00:14:59,320
iterated over to see like which
parts of the system you have achieved

223
00:14:59,350 --> 00:15:03,170
the accuracy that you want so that
human test points can now be removed

224
00:15:03,190 --> 00:15:04,490
from those parts of the pipeline.

225
00:15:04,990 --> 00:15:06,910
So yeah, that was the end of my talk.

226
00:15:07,130 --> 00:15:11,940
thank you so much for attending my talk
and feel free to, reach me on LinkedIn if

227
00:15:11,940 --> 00:15:13,700
you have any further questions about this.

228
00:15:13,920 --> 00:15:14,210
Thank you.

