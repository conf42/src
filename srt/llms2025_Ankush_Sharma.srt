1
00:00:00,000 --> 00:00:00,780
Hello everyone.

2
00:00:01,020 --> 00:00:04,080
Welcome to Con 42 LLM 2025.

3
00:00:05,070 --> 00:00:09,720
My name is, I'm a tech engineering leader
specializing in cloud infrastructure,

4
00:00:10,080 --> 00:00:12,390
SRE, and AI driven innovations.

5
00:00:12,930 --> 00:00:16,290
My career spans from Microsoft
and fast pace startups.

6
00:00:16,790 --> 00:00:20,599
For this talk, we will focus
on observability, SRE, and

7
00:00:20,599 --> 00:00:22,520
how this is implemented in s.

8
00:00:23,020 --> 00:00:28,044
Agenda will be introduction to AI
LLM Trends, understanding LLM, SI

9
00:00:28,044 --> 00:00:35,769
fundamentals, observability in AI systems,
SRE, roles in managing LMS case studies.

10
00:00:36,269 --> 00:00:39,135
And we'll conclude with
some open discussions.

11
00:00:39,635 --> 00:00:40,714
AI is your needs.

12
00:00:40,714 --> 00:00:44,405
So we are right now experiencing
an exponential arc in ai.

13
00:00:44,705 --> 00:00:51,184
We started in 2012 with AlexNet and
slowly we trending towards GPT GPT-4.

14
00:00:51,665 --> 00:00:57,214
We are planning to gain a GI, which
is artificial journal intelligence

15
00:00:57,275 --> 00:00:58,415
within the next five years.

16
00:00:58,475 --> 00:00:58,505
Okay.

17
00:00:59,014 --> 00:01:04,135
And hopefully with this, progress in
next more than 10 years, maybe we can

18
00:01:04,135 --> 00:01:06,655
have artificial super intelligence, also

19
00:01:07,155 --> 00:01:08,955
current LLM market trend.

20
00:01:09,615 --> 00:01:16,310
So we are expecting 37.2% growth
rate by 2030, and this will

21
00:01:16,310 --> 00:01:18,320
focus mostly on LLM side of it.

22
00:01:18,820 --> 00:01:21,070
Introduction to LLM models.

23
00:01:21,340 --> 00:01:27,700
So what is L-L-M-L-L-M are advanced AI
systems trained on vast data sets to

24
00:01:27,700 --> 00:01:30,070
understand and generate human like text.

25
00:01:30,940 --> 00:01:35,200
Their applications are content
generations, customer support, research,

26
00:01:35,205 --> 00:01:41,260
coding assistance, and a couple
of examples of LM GPT-4 and palm.

27
00:01:41,760 --> 00:01:46,050
L and M have transport so many
industries, including healthcare,

28
00:01:46,050 --> 00:01:48,120
education, software developments,

29
00:01:48,620 --> 00:01:55,510
overview of SRE, so introduction of SREs,
SRE ensures reliability, scalability,

30
00:01:55,540 --> 00:01:57,610
efficiency in software systems.

31
00:01:58,060 --> 00:02:01,655
Key practices include proactive
monitoring, automation

32
00:02:01,870 --> 00:02:03,100
and incident response.

33
00:02:03,600 --> 00:02:08,009
So SRE has some core principles,
S-L-I-S-L-O, service level, objective,

34
00:02:08,009 --> 00:02:10,199
service level, indicators, error, budget.

35
00:02:10,680 --> 00:02:15,109
All these are guiding principles
of SRE, but the high level focus

36
00:02:15,140 --> 00:02:19,459
is how we can balance reliability
with innovation and speed.

37
00:02:19,959 --> 00:02:21,339
Next part is observability.

38
00:02:21,339 --> 00:02:24,759
So how observability can ensure.

39
00:02:24,804 --> 00:02:30,684
In AI system, so basically observability
is more like a system behavior, which

40
00:02:30,684 --> 00:02:32,394
is measurable and understandable.

41
00:02:33,204 --> 00:02:38,665
We have three key pillars of
possibility, metrics, logs, and traces.

42
00:02:39,444 --> 00:02:45,084
Metrics are continuity values, which is
like CPU usage, memory utilization, API

43
00:02:45,084 --> 00:02:47,575
response times and logs are detailed.

44
00:02:48,174 --> 00:02:50,994
Timestamped records of system events.

45
00:02:51,494 --> 00:02:56,274
Traces are, visualizing the flow of
requests through your various services

46
00:02:56,274 --> 00:03:01,464
of to identify bottleneck traces
are very helpful in for developers.

47
00:03:01,464 --> 00:03:07,325
Basically challenges in observing
lms, so LLM operates own enormous

48
00:03:07,325 --> 00:03:10,415
data sets, creating challenges
in performance monitoring.

49
00:03:11,269 --> 00:03:13,999
And, LLM has a dynamic behavior.

50
00:03:14,084 --> 00:03:18,949
LLM adapts based on the inputs, make
their response non-deterministic

51
00:03:18,949 --> 00:03:21,619
in case transparency.

52
00:03:21,619 --> 00:03:25,279
black box nature of LLM complicates
understanding their internal

53
00:03:25,279 --> 00:03:28,309
decision process and scalability.

54
00:03:28,809 --> 00:03:32,350
Monitoring and managing LM require
robust and scalable infrastructure.

55
00:03:32,850 --> 00:03:35,820
So how we can implement
observability in LLM.

56
00:03:36,480 --> 00:03:38,010
So it's a step by step process.

57
00:03:38,010 --> 00:03:42,959
Step one is we need to define our
key metrics, monitor prediction,

58
00:03:43,019 --> 00:03:45,390
latency, throughputs error rates.

59
00:03:46,050 --> 00:03:52,589
Step two is integrate advanced
logging, so collect logs for input,

60
00:03:52,649 --> 00:03:54,300
output, and model resilience.

61
00:03:55,170 --> 00:03:57,870
Once that is done, we
use distributed tracing.

62
00:03:57,930 --> 00:04:01,950
So map end-to-end interactions
for pinpointing your failures.

63
00:04:02,054 --> 00:04:04,625
Okay, and deploy real time dashboards.

64
00:04:04,954 --> 00:04:09,065
Dashboard can be Grafana or any
other visualization tools we can use.

65
00:04:09,565 --> 00:04:11,965
Now, what's the role
of SRE in managing lms?

66
00:04:12,465 --> 00:04:18,220
So SRE responsibility and LLM include
ensuring 24 by seven availability through

67
00:04:18,555 --> 00:04:23,580
automated failover systems, developing
runbooks for common incident scenarios.

68
00:04:24,120 --> 00:04:26,220
Automation is definitely a key.

69
00:04:26,220 --> 00:04:30,720
So automate scaling up resources
during high demand period.

70
00:04:31,590 --> 00:04:35,670
And this also involves tackling the
use case of toils and other things.

71
00:04:36,170 --> 00:04:40,640
Collaboration with AI team is very
important, so providing feedbacks on model

72
00:04:40,640 --> 00:04:42,710
performance for iterative improvements.

73
00:04:43,210 --> 00:04:46,482
we have multiple case
studies which will focus on.

74
00:04:46,982 --> 00:04:52,322
One of the case study is AI chat
bot monitoring response latency.

75
00:04:52,832 --> 00:04:57,962
To ensure the user experience
healthcare AI is there, you can ensure

76
00:04:57,962 --> 00:05:03,902
compliance of medical guidelines and
reduce false positive fraud detection.

77
00:05:03,992 --> 00:05:06,872
This can be in a security
or banking system.

78
00:05:07,352 --> 00:05:10,982
Continuous monitoring of
prediction accuracy is identified

79
00:05:10,982 --> 00:05:12,512
fraudulent transactions.

80
00:05:13,012 --> 00:05:18,412
So conclusion of my talk is basically
focused on observability and SRE and

81
00:05:18,412 --> 00:05:23,992
these two concepts observability, SRE,
are vital to ensure we have reliability

82
00:05:23,997 --> 00:05:29,177
and scalability of l and m. As AI
system involve adopting innovative

83
00:05:29,657 --> 00:05:34,942
practices and prioritization, reliability
practices will be the key to build

84
00:05:35,032 --> 00:05:37,522
resilient and trustworthy AI system.

85
00:05:38,152 --> 00:05:40,432
This drives value across industries.

86
00:05:40,932 --> 00:05:44,352
And finally, I have a
recommendation on the books.

87
00:05:44,352 --> 00:05:51,482
So for SRE, definitely SRE Handbook,
which was written by Nile Murphy.

88
00:05:51,992 --> 00:05:56,522
It, this is a on SRE dot, Google
Books, and it's, free over there.

89
00:05:56,972 --> 00:05:57,962
That is very helpful.

90
00:05:58,532 --> 00:06:02,902
And another book, which I recently
completed is about engineering.

91
00:06:03,622 --> 00:06:08,692
This book will definitely go beyond
and help in implementing all the

92
00:06:08,692 --> 00:06:10,282
concepts that we just learned.

93
00:06:10,782 --> 00:06:11,827
Thank you for listening my talk.

94
00:06:11,827 --> 00:06:12,107
Yeah.

95
00:06:12,567 --> 00:06:12,907
See ya.

