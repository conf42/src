1
00:00:00,070 --> 00:00:01,560
Hi, I'm Rinoshun.

2
00:00:02,009 --> 00:00:05,939
I'm a software engineer
in the AI team of WSO2.

3
00:00:06,820 --> 00:00:10,709
Today I'll be talking about building
trust in generated AI through

4
00:00:10,710 --> 00:00:12,690
accuracy evaluation and automation.

5
00:00:12,800 --> 00:00:20,239
So these days there are many organizations
that are leveraging generated AI to infuse

6
00:00:20,250 --> 00:00:25,269
some AI features into their products
to enhance the developer experience.

7
00:00:25,769 --> 00:00:30,279
But when it comes to an AEI feature,
key factor would be the accuracy.

8
00:00:30,779 --> 00:00:33,999
How accurate are the
responses of this AEI feature?

9
00:00:34,499 --> 00:00:39,719
So from a, from an organization
perspective, when a developer pushes

10
00:00:39,719 --> 00:00:45,429
some changes to an AEI feature,
what trust or the guarantee do they

11
00:00:45,439 --> 00:00:51,259
have in these changes that is going
into the existing AEI feature?

12
00:00:51,759 --> 00:00:58,554
So, In addition to code reviews and unit
testing for AI features, they will also

13
00:00:58,554 --> 00:01:00,654
have to do some accuracy evaluation.

14
00:01:01,154 --> 00:01:03,744
And this accuracy evaluation
should be automated.

15
00:01:04,344 --> 00:01:09,734
So each and every changes that goes
into production needs to be checked

16
00:01:09,774 --> 00:01:14,674
if a particular accuracy level
is maintained for that feature.

17
00:01:15,174 --> 00:01:19,654
This process has to be automated such
that with each and every ER changes

18
00:01:20,104 --> 00:01:26,214
that goes into production, We have
verified that the accuracy of the

19
00:01:26,214 --> 00:01:29,374
feature is maintained at a certain level.

20
00:01:29,874 --> 00:01:33,095
So let's dive deep into this.

21
00:01:33,095 --> 00:01:38,564
So that is generative AI
with and without context.

22
00:01:38,564 --> 00:01:44,334
So generative AI is being leveraged
for its creative responses you

23
00:01:44,334 --> 00:01:49,654
can get from the LLMs, which
is the large language models.

24
00:01:49,989 --> 00:01:52,389
But then there's, there
are some limitations to it.

25
00:01:52,390 --> 00:01:58,394
It has been pre trained on multiple
different, areas and data set.

26
00:01:58,894 --> 00:02:03,364
So the answer it gives might not
be tailored for your use case.

27
00:02:04,234 --> 00:02:09,734
It might not be, it might be more
generic and it might lack some precision

28
00:02:10,394 --> 00:02:14,504
since it does not have the relevant
context for your particular use case.

29
00:02:14,664 --> 00:02:21,144
So then we have this Generate AI with
Context, which will have some context.

30
00:02:21,764 --> 00:02:25,424
Fed into the prompt and this prompt
will be sent to, sent it to L.

31
00:02:25,724 --> 00:02:30,914
So can look at the context and based
on that context it can give much

32
00:02:30,914 --> 00:02:33,614
more relevant and tailored responses.

33
00:02:34,114 --> 00:02:38,854
So this generating AI with context,
this is where we are going to

34
00:02:38,854 --> 00:02:45,464
try in this presentation, will be
evaluating the accuracy and the, and

35
00:02:45,464 --> 00:02:47,294
automate the accuracy evaluation.

36
00:02:47,794 --> 00:02:52,634
So one common pattern of,
generative ai that, generative

37
00:02:52,724 --> 00:02:53,924
ai, which context is that?

38
00:02:54,634 --> 00:02:57,234
Retrieval, augment generation rack.

39
00:02:57,534 --> 00:03:02,154
so this rack enhances generating
AI by integrating some external

40
00:03:02,924 --> 00:03:08,444
knowledge sources, external knowledge
sources that which will improve

41
00:03:08,444 --> 00:03:10,784
the accuracy of the generator.

42
00:03:11,024 --> 00:03:12,824
So this has two components.

43
00:03:12,824 --> 00:03:15,404
One is the retrieval component
and the generator component.

44
00:03:15,844 --> 00:03:16,379
So there will be.

45
00:03:16,789 --> 00:03:23,889
Knowledge base created which will contain
all the external knowledge users And

46
00:03:23,889 --> 00:03:29,719
document and documented so the retriever
will use this knowledge base to whenever

47
00:03:30,159 --> 00:03:34,919
it gets a question from the user It will
use the knowledge base to search for

48
00:03:34,919 --> 00:03:39,578
relevant context And get the results
from the knowledge base and edit into

49
00:03:39,579 --> 00:03:44,019
the prompt And this prompt with the
context will be sent to the next component

50
00:03:44,029 --> 00:03:49,290
Which is the generator component and the
generator Will generate a response that

51
00:03:49,290 --> 00:03:52,329
is more relevant to the user's query.

52
00:03:52,489 --> 00:03:58,359
So that is the rack pattern and Let's
see how we can evaluate this rack

53
00:03:58,729 --> 00:04:05,029
applications So there is this Ragas
library so it's a research that has

54
00:04:05,059 --> 00:04:10,029
been done and it has defined multiple
metrics but in this presentation, we

55
00:04:10,029 --> 00:04:15,599
will look at certain metrics that we
will be using for accuracy evaluation.

56
00:04:15,599 --> 00:04:19,044
So each of these metrics
You serve different purpose.

57
00:04:19,124 --> 00:04:23,744
So you need to figure out
which metric will, will be

58
00:04:23,764 --> 00:04:25,494
best for your RAG application.

59
00:04:25,994 --> 00:04:31,784
So the retriever can be evaluated using
the metrics like context recall and the

60
00:04:32,064 --> 00:04:36,844
context precision and the generator can be
evaluated with the metrics, faithfulness

61
00:04:36,904 --> 00:04:38,184
and the answer semantic similarity.

62
00:04:38,684 --> 00:04:41,534
So both the components will
be individually, evaluated

63
00:04:41,944 --> 00:04:44,124
in on different aspects.

64
00:04:44,624 --> 00:04:48,654
So before we go into this accuracy
evaluation, we'll just be familiarized

65
00:04:48,714 --> 00:04:54,114
with some keywords that we'll be using
so one is the question that is the user's

66
00:04:54,114 --> 00:04:59,824
query that is being input into the rack
and then you have the context these are

67
00:04:59,824 --> 00:05:04,794
the documents that are being retrieved
from a knowledge base by the retriever

68
00:05:05,294 --> 00:05:10,734
and then the answer so the This is the
generated answer from the generator

69
00:05:10,764 --> 00:05:15,874
that for a specific user's question
And the ground truth So these, these

70
00:05:15,924 --> 00:05:21,944
are the labels or the human annotated
answers for a particular question.

71
00:05:21,944 --> 00:05:25,743
So we'll first, we'll first look
at the context recall metric

72
00:05:25,743 --> 00:05:27,323
that evaluates the retriever.

73
00:05:27,993 --> 00:05:34,303
so what, this metric will measure
is the extent to which the retrieved

74
00:05:34,353 --> 00:05:36,313
context aligns with the ground truth.

75
00:05:36,813 --> 00:05:40,573
So we want to, so we have a ground truth
predefined for a particular question.

76
00:05:40,583 --> 00:05:44,133
We want to see that each and every
claim, we did that ground truth.

77
00:05:44,908 --> 00:05:49,378
will be available in the contract
context that we are retrieving

78
00:05:50,098 --> 00:05:51,778
from the knowledge base.

79
00:05:52,278 --> 00:05:56,918
So to achieve high context, recall
all the sentences or claims in

80
00:05:56,918 --> 00:06:02,208
the ground truth answer should be
available in the retrieved context.

81
00:06:02,708 --> 00:06:07,148
So the context recall is formulated
like, ground number of ground truth

82
00:06:07,148 --> 00:06:12,518
sentences that can be attributed
to the context divided by the

83
00:06:12,518 --> 00:06:14,108
number of sentences in the ground.

84
00:06:14,108 --> 00:06:14,258
Truth.

85
00:06:14,758 --> 00:06:19,278
And then we have the context . So this
will check, so the context recall,

86
00:06:19,278 --> 00:06:23,508
we checked if the most, if all the
relevant context have been retrieved.

87
00:06:24,278 --> 00:06:27,818
But now in context, , we want
to see the order of these

88
00:06:28,468 --> 00:06:30,398
context, that has been retrieved.

89
00:06:31,348 --> 00:06:35,678
So we want in context pressure,
we want the, we, we want the most

90
00:06:35,678 --> 00:06:38,528
relevant item to be, rank higher.

91
00:06:39,343 --> 00:06:43,933
Because when we if even if there are 100
documents and if we give all these 100

92
00:06:43,933 --> 00:06:49,153
documents into LLM feed all those 100
documents into LLM If the most relevant

93
00:06:49,203 --> 00:06:55,623
item is in the bottom or in the middle
then LLM might not pick that context to

94
00:06:55,683 --> 00:07:01,293
answer the questions it might hallucinate
Or it might hallucinate or give the

95
00:07:01,363 --> 00:07:04,153
answer based on a different context.

96
00:07:04,653 --> 00:07:09,503
So we want to see if The most
relevant context is on the top.

97
00:07:09,583 --> 00:07:13,933
It's ranked higher So that's what we
want to achieve by context precision.

98
00:07:13,933 --> 00:07:18,463
So together the context recall and
the context precision we'll check how

99
00:07:18,513 --> 00:07:23,983
accurate the retrieval is so based on
these, you can make so many decisions

100
00:07:24,003 --> 00:07:27,743
like For the retriever like how many
documents do you want to retrieve?

101
00:07:28,513 --> 00:07:33,158
So if you retrieve large number of files
Documents then the context record will

102
00:07:33,188 --> 00:07:36,968
be higher because you might there are
high chances of getting the relevant

103
00:07:36,978 --> 00:07:43,828
documents into the Prompt, but then the
precision might be low if the rank is

104
00:07:43,848 --> 00:07:49,498
not higher So you might want to find you
might want to re rank those documents.

105
00:07:49,998 --> 00:07:56,978
So there so based on these, metrics
you can like fine tune the indexing

106
00:07:56,978 --> 00:08:01,988
strategy Like based on if the pressure
is lower you can go and change the

107
00:08:01,988 --> 00:08:06,678
indexing strategy of the knowledge base
and then also you can change the search

108
00:08:06,678 --> 00:08:12,388
strategy like you can instead of using
the Distance metric or cosine similarity.

109
00:08:12,588 --> 00:08:14,598
You can even use euclidean distance.

110
00:08:14,598 --> 00:08:21,358
So, and also you can Use re rag
to re rag these Documents retreat.

111
00:08:21,858 --> 00:08:24,978
So there are multiple decisions
you can take based on these metrics

112
00:08:25,478 --> 00:08:29,898
And then to evaluate the generator we
have this faithfulness So this measures

113
00:08:29,898 --> 00:08:36,998
the factual consistency Of the generated
answer against the given context So if

114
00:08:37,058 --> 00:08:41,608
there are any sentences that has been
hallucinated then this faithfulness

115
00:08:41,638 --> 00:08:46,178
metric will give us will will show us
that the answer has been hallucinated.

116
00:08:46,678 --> 00:08:53,350
So what it compares is the Generated
answer with the context if it's easy all

117
00:08:53,350 --> 00:08:58,173
the sentences in the generated answer
is available in the given context So

118
00:08:58,933 --> 00:09:02,793
the faithfulness code is defined like
the number of claims in the generated

119
00:09:02,963 --> 00:09:07,983
answer that can be inferred from the
given context Divided by the total number

120
00:09:07,983 --> 00:09:13,483
of claims in the generated answer and
then also semantic similarity So we

121
00:09:13,483 --> 00:09:15,613
will check in this through this method.

122
00:09:15,613 --> 00:09:20,883
We will be checking the Semantic meaning
if the semantic meaning of the answer

123
00:09:20,883 --> 00:09:22,623
matches with the ground truth we have.

124
00:09:23,123 --> 00:09:28,993
So what we will be doing here is giving
the, getting the, vectors for the

125
00:09:29,603 --> 00:09:33,428
generated answer and the ground truth, and
we will compare this to cosine similarity.

126
00:09:33,428 --> 00:09:36,063
So this will be the answer
semantic similarity.

127
00:09:36,563 --> 00:09:40,793
So based on answer semantics, so based on
these metrics, that measure the accuracy

128
00:09:40,793 --> 00:09:45,403
of generator, we can take some decisions
like which model to use and which,

129
00:09:45,423 --> 00:09:47,043
what should be the model temperature.

130
00:09:47,043 --> 00:09:47,123
Okay.

131
00:09:48,113 --> 00:09:52,543
So those kind of decisions you
can you can take through these two

132
00:09:52,563 --> 00:09:57,383
metrics So the key stages of accuracy
evaluation will dig deeper into this.

133
00:09:57,383 --> 00:10:02,813
So the data set preparation so that you
need to first prepare a Comprehensive

134
00:10:02,863 --> 00:10:07,948
data set and then also you need to do
the calculation and get the matrix We

135
00:10:07,948 --> 00:10:12,103
need to compute the matrix and based
on and this matrix computation needs to

136
00:10:12,113 --> 00:10:18,658
be integrated into ciscd pipeline such
that Whenever you send some pr This

137
00:10:18,708 --> 00:10:23,498
will automatically run and compute the
metrics, and then you need to report

138
00:10:23,498 --> 00:10:28,848
the accuracy, such that you can make any
decisions based on this accuracy report.

139
00:10:29,348 --> 00:10:32,608
So the dataset preparation, this
is a very key, this is the key

140
00:10:32,608 --> 00:10:34,728
step of accuracy evaluation.

141
00:10:35,228 --> 00:10:39,758
So the questions, so this, the
questions you choose are very important.

142
00:10:39,758 --> 00:10:44,925
So the questions should be able
to, this dataset should cover

143
00:10:44,925 --> 00:10:47,598
wide variety of complexities.

144
00:10:48,098 --> 00:10:50,938
So there should be hard questions,
easy questions, medium level

145
00:10:50,938 --> 00:10:53,648
questions, and then complex
questions, combined questions.

146
00:10:54,168 --> 00:10:58,168
Different types of questions should be
there such that it can cover all the

147
00:10:58,168 --> 00:11:00,828
scenarios that can occur in productions.

148
00:11:01,328 --> 00:11:04,598
And also you need to carefully
write the ground truth.

149
00:11:05,098 --> 00:11:09,668
So this ground truth, if, if the,
all these, like, some, most of these

150
00:11:09,668 --> 00:11:11,948
metrics are based on this ground truth.

151
00:11:12,008 --> 00:11:15,478
So if you don't have a proper
ground truth, then the accuracy.

152
00:11:16,113 --> 00:11:23,243
evaluated will be meaningless and also if
you don't have the proper questions, then

153
00:11:23,353 --> 00:11:29,873
you are not evaluating the right accuracy
So if you suggest give some easy questions

154
00:11:29,893 --> 00:11:35,373
Then they are you might be confident with
that given accuracy that the model might

155
00:11:35,423 --> 00:11:41,383
work and the feature might work on these
equations, but We would not have an idea

156
00:11:41,383 --> 00:11:45,993
of how it will work when it goes to our
questions So the dataset preparation is

157
00:11:45,993 --> 00:11:51,603
a key step in evaluating the accuracy
and then the matrix computation.

158
00:11:52,543 --> 00:11:57,873
So here I have attached a code Snipper,
for, to evaluate, some service.

159
00:11:58,383 --> 00:12:04,783
so here we use the RGAs library
to, we get the rga, the metrics.

160
00:12:04,923 --> 00:12:07,583
So these, we will import
the metrics which we want.

161
00:12:07,583 --> 00:12:12,373
So here have import context, call context,
special holders, and the art similarity.

162
00:12:13,103 --> 00:12:17,553
So first we, get the data set
and this data set, we prepare the

163
00:12:17,553 --> 00:12:23,483
extended data set by running these
questions on the AI feature and you

164
00:12:23,513 --> 00:12:25,623
get the answers and the context.

165
00:12:25,623 --> 00:12:31,483
So, you combine, you concatenate the
questions, answers and the context and

166
00:12:31,503 --> 00:12:34,253
the ground truth and create a data set.

167
00:12:34,923 --> 00:12:37,583
And that data set will be
used in the Raghav's library.

168
00:12:38,083 --> 00:12:42,103
So this will evaluate the context,
here So we mentioned that we want to

169
00:12:42,103 --> 00:12:46,523
evaluate based on these metrics And
then this the results will be saved

170
00:12:46,523 --> 00:12:48,373
to some accuracy results dot csv.

171
00:12:48,873 --> 00:12:53,673
And also we will For all the questions,
we'll get the weighted mean or mean and

172
00:12:53,673 --> 00:13:00,513
then we we will see if We will define some
thresholds for each and every metric So

173
00:13:00,513 --> 00:13:04,883
we have to define different thresholds
for each metric because each metric

174
00:13:05,383 --> 00:13:11,116
serves different purpose So we see if the
threshold passes or not in the Threshold

175
00:13:11,116 --> 00:13:19,473
passes or not to check if you can pass the
total accuracy test or not So that will

176
00:13:19,483 --> 00:13:24,743
be the matrix computation code snippet
and then integrating this into the CIC

177
00:13:24,743 --> 00:13:30,303
pipeline So now when you have if you had a
code in the github, you can use the github

178
00:13:30,353 --> 00:13:34,950
workflows So you can for the workflow
you can you add a workflow yaml file

179
00:13:34,950 --> 00:13:39,971
You where you can set up the environment
install the dependencies and you can

180
00:13:39,971 --> 00:13:44,323
set up the github environment variables
You can set it to the variables github

181
00:13:44,513 --> 00:13:50,663
variables and the secrets and then you
can give the script Which you want to run.

182
00:13:50,763 --> 00:14:00,053
So here i am giving them to run the test
accuracy And then you can publish the csv

183
00:14:00,473 --> 00:14:05,273
Publishing this is also important because
If you fail the accuracy test, then you

184
00:14:05,273 --> 00:14:07,743
can go and inspect why it has failed.

185
00:14:08,243 --> 00:14:10,383
So the report accuracy,
so the accuracyresults.

186
00:14:10,863 --> 00:14:12,903
csv.

187
00:14:12,903 --> 00:14:18,023
This, this is a snippet, this
is a, one example of, the, of

188
00:14:18,023 --> 00:14:18,563
a row in the accuracyresults.

189
00:14:19,103 --> 00:14:19,933
csv.

190
00:14:20,043 --> 00:14:24,330
So this will contain the whole data
set and the, context, the appreciation,

191
00:14:24,330 --> 00:14:28,073
context recall, faithfulness, and
all similarity scores you get.

192
00:14:28,573 --> 00:14:31,883
So this, so based on this, like you
can take important decision, you

193
00:14:31,883 --> 00:14:34,993
can decide on what to do next to it.

194
00:14:35,413 --> 00:14:40,433
If this passes, then you can directly
merge this into the, into the production.

195
00:14:40,963 --> 00:14:46,133
But if the accuracy test fails, you can
come in and look at the CSV file and

196
00:14:46,133 --> 00:14:50,923
check which question has failed and why,
which metric has gone down and why it has.

197
00:14:50,933 --> 00:14:54,623
You can look at the answer and
the context and the ground truth

198
00:14:55,203 --> 00:14:56,843
and get an idea why it has failed.

199
00:14:57,698 --> 00:15:01,368
So say for instance, for a particular
question, there are, you have

200
00:15:01,518 --> 00:15:05,918
read five documents and the most
relevant document is not on the top.

201
00:15:06,088 --> 00:15:08,338
So the current text, the
position has gone down.

202
00:15:09,318 --> 00:15:14,668
And for such cases, what you can do
is you can come in, you can introduce

203
00:15:14,668 --> 00:15:17,528
a re ranker into the architecture.

204
00:15:18,158 --> 00:15:22,918
so then you can, this re ranker
will re rank these documents and put

205
00:15:22,918 --> 00:15:24,468
the most relevant one on the top.

206
00:15:24,818 --> 00:15:26,498
So then the cortex pressure will go.

207
00:15:27,453 --> 00:15:27,783
Higher.

208
00:15:28,283 --> 00:15:32,963
So that's the accuracy parting, and then
the bit about the automation pipeline.

209
00:15:33,533 --> 00:15:35,213
So how the automation happens.

210
00:15:35,693 --> 00:15:42,353
So first, the developer will send a pr and
this PR will trigger the GitHub workflows.

211
00:15:43,093 --> 00:15:48,853
And in the workflow you will have the
accuracy script, which will be one to

212
00:15:48,853 --> 00:15:54,543
evaluate the accuracy of the changes
of the, of the app after the changes.

213
00:15:55,473 --> 00:15:57,998
And then based on the accuracy results.

214
00:15:58,728 --> 00:16:05,118
You make the decision you verify if the
PR Merges, if you can merge this PR or

215
00:16:05,158 --> 00:16:10,968
not So that's the automation pipeline
and some challenges, in this approach

216
00:16:11,328 --> 00:16:15,918
would be like, So you so these evaluation
results some of those metrics use

217
00:16:15,918 --> 00:16:23,348
the LLMs, for example, Context record
you want to check if all the All the

218
00:16:23,628 --> 00:16:27,458
ground truth claims are available in
the context which you have retrieved.

219
00:16:27,958 --> 00:16:30,458
So you use NLM behind the scenario.

220
00:16:31,368 --> 00:16:34,178
So the evaluation results
are dependent on the NLM.

221
00:16:34,198 --> 00:16:38,548
So each time you run it, the
results might vary, I mean,

222
00:16:39,288 --> 00:16:41,788
by a small amount, of course.

223
00:16:42,288 --> 00:16:44,578
Still, this LLM, is important.

224
00:16:44,588 --> 00:16:51,348
So you might want to use a very, accurate
LLM, very, high, high, high accurate LLM.

225
00:16:52,028 --> 00:16:55,118
And also like, the dataset, as I
mentioned earlier, the data should,

226
00:16:55,148 --> 00:16:58,138
should cover all the possible scenarios
that might occur in production.

227
00:16:58,638 --> 00:17:02,148
So it should not be questions
of just one complexity.

228
00:17:02,158 --> 00:17:03,868
It should be of different
complexity levels.

229
00:17:04,368 --> 00:17:09,378
So then, then only you can get a
very good, accuracy evaluated and

230
00:17:09,378 --> 00:17:13,258
then, and then need to create a
high quality ground truth data sets.

231
00:17:13,268 --> 00:17:18,268
So this creating such ground truth
data, ground truth, ground truth is

232
00:17:18,268 --> 00:17:20,958
very time consuming and also expensive.

233
00:17:21,218 --> 00:17:25,498
So you need to spend some time
and write the proper, ground

234
00:17:25,558 --> 00:17:27,078
truth for a particular question.

235
00:17:27,578 --> 00:17:29,838
And also the LLM API cost.

236
00:17:29,838 --> 00:17:35,168
So since you are using the LLM behind
the scenario So you for a large scale

237
00:17:35,348 --> 00:17:40,058
evaluations the LLM API cost might be
higher and also there might be performance

238
00:17:40,058 --> 00:17:47,078
bottlenecks It might take some time to
compute the accuracy Also cost is another

239
00:17:47,088 --> 00:17:52,548
factor that needs that you need to include
in your project for accuracy evaluation

240
00:17:52,918 --> 00:18:02,553
So that's about the evaluating Accuracy of
your rag applications and automating this

241
00:18:02,583 --> 00:18:08,193
and making sure that all the changes You
go that all the changes that go into the

242
00:18:08,193 --> 00:18:13,713
productions maintain a particular accuracy
that your organization won't persist

243
00:18:13,713 --> 00:18:16,213
for the Persist for user experience.

244
00:18:16,713 --> 00:18:17,053
Thank you.

245
00:18:17,053 --> 00:18:18,083
Thank you very much.

246
00:18:18,093 --> 00:18:19,053
It's nice talking to you

