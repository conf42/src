1
00:00:04,740 --> 00:00:06,000
Hey, good morning everyone.

2
00:00:06,000 --> 00:00:08,850
Welcome to Platform
Engineering Conference.

3
00:00:09,180 --> 00:00:09,900
My name is,

4
00:00:12,450 --> 00:00:16,650
I have over 14 years of experience as a
platform architect in the IT industry.

5
00:00:17,400 --> 00:00:24,180
I'm here to give a presentation on the
building production ready rag systems,

6
00:00:24,690 --> 00:00:28,140
platform engineer strategies for
enterprise knowledge infrastructure.

7
00:00:29,354 --> 00:00:33,405
So before going to that, I
would like to know, I would

8
00:00:33,405 --> 00:00:34,964
like to discuss about the rag.

9
00:00:35,625 --> 00:00:36,585
what is rag?

10
00:00:37,305 --> 00:00:42,585
RAG is stands rag in AI stands for
the re travel argument generation.

11
00:00:43,065 --> 00:00:48,375
A technique where a generative model,
such as a large language model, first

12
00:00:48,675 --> 00:00:55,065
drives relevant information from external
sources before generating responses.

13
00:00:55,905 --> 00:00:58,995
Improving factual accuracy and relevance.

14
00:00:59,535 --> 00:01:03,855
The code concept behind the RAG
is it combines the traditional

15
00:01:03,855 --> 00:01:06,975
information retrieval systems.

16
00:01:07,905 --> 00:01:12,375
It'll search the databases with
the generat, with the generated

17
00:01:12,375 --> 00:01:18,795
capabilities of lms instead of relying
ly on static PRETRAINED data sets.

18
00:01:19,275 --> 00:01:21,615
RAG allows in AI to dynamically.

19
00:01:22,335 --> 00:01:27,074
Access up to date information
are domain specific content and

20
00:01:27,074 --> 00:01:28,875
incorporated into its output.

21
00:01:30,285 --> 00:01:32,625
How is rags going to work?

22
00:01:32,744 --> 00:01:37,215
So a user submit a prompter query
the system such as our retro

23
00:01:37,515 --> 00:01:42,610
relevant information snips from
the designated large base or data

24
00:01:42,645 --> 00:01:48,645
sets, which might include internal
documents, PDFs, emails, our web data.

25
00:01:49,620 --> 00:01:55,289
These retrial snip nets are passed as
context alongside the prompt to the LLM.

26
00:01:56,190 --> 00:02:01,500
The LLM generates its response,
grounded in both its modern knowledge

27
00:02:01,860 --> 00:02:04,680
and the most relevant retried facts.

28
00:02:05,580 --> 00:02:10,500
So as enterprise scales, their
use of LLMs, they encounter two

29
00:02:10,500 --> 00:02:13,650
critical challenges, hallucinations.

30
00:02:13,710 --> 00:02:16,470
The first one, which is.

31
00:02:17,280 --> 00:02:23,370
Rate as high as 27% and
outdated training data.

32
00:02:24,630 --> 00:02:30,180
So the re travel argument generation
has emerged as a powerful architectural

33
00:02:30,180 --> 00:02:35,310
solution, bridging the gap between
static model origin and realtime

34
00:02:35,310 --> 00:02:41,340
information by coupling generated AI
with enterprise scale large repositories.

35
00:02:41,850 --> 00:02:47,910
Rack Systems enable reliable, accurate,
and context responses at scale.

36
00:02:49,860 --> 00:02:53,970
The Enterprise Rack Challenge
over deploying production ready

37
00:02:54,000 --> 00:02:57,665
rack systems in enterprise
environment is far from trivial.

38
00:02:58,605 --> 00:03:03,525
Because platform engineers must
design architectures that can handle

39
00:03:03,975 --> 00:03:07,965
terabytes up to 10 or plus repositories.

40
00:03:08,235 --> 00:03:15,645
You subsecond query response times and
maintain 95% uptime while supporting

41
00:03:15,645 --> 00:03:17,685
10,000 plus concurrent users.

42
00:03:18,285 --> 00:03:21,885
This article explores the platform
engineering strategies needed to

43
00:03:21,885 --> 00:03:27,285
operationalize rag pipelines at
scale, focusing on infrastructure.

44
00:03:27,675 --> 00:03:32,775
Performance, reliability,
security, and cost optimization.

45
00:03:34,035 --> 00:03:38,535
when we come to the infrastructure
architecture, scaling a rag for

46
00:03:38,535 --> 00:03:40,395
the enterprise is a big challenge.

47
00:03:40,875 --> 00:03:45,765
The backbone of any rag system is
its vector database, which stores

48
00:03:45,945 --> 00:03:50,680
embedding self enterprise knowledge
for the travel to achieve enterprise

49
00:03:50,769 --> 00:03:53,240
scale, reliability and throughput.

50
00:03:55,155 --> 00:03:55,560
Platform engineer must design.

51
00:03:56,790 --> 00:04:02,910
Based on these four concepts, first
distributor, vector databases, and

52
00:04:03,030 --> 00:04:05,310
next is load balancing strategies.

53
00:04:05,549 --> 00:04:10,799
Part of one is hybrid storage models,
and fourth is the elastic scaling.

54
00:04:10,799 --> 00:04:13,859
These are the four pillars
when we are building a rack

55
00:04:13,859 --> 00:04:15,269
system for the enterprises.

56
00:04:16,020 --> 00:04:20,910
When we come to the distributed vector
databases, shedding embeddings across

57
00:04:20,910 --> 00:04:28,290
nodes, ensure horizontal scalability
systems like Vate, pine, cone, and Fan

58
00:04:29,220 --> 00:04:33,600
provide different tradeoffs between
scalability, query latency, and cost.

59
00:04:35,655 --> 00:04:39,495
So these are the various vector data
databases, which we can use when we

60
00:04:39,495 --> 00:04:42,075
are building a rag for the enterprise.

61
00:04:42,645 --> 00:04:48,045
Now, when it comes to the load balancing,
is very important to handle the

62
00:04:48,345 --> 00:04:52,365
upscale or vertical scale, requests.

63
00:04:52,845 --> 00:04:57,375
So the balances must intelligently
route queries across database

64
00:04:57,375 --> 00:05:03,465
clusters, pipelines, and LLM
instances to minimize bottlenecks.

65
00:05:04,364 --> 00:05:09,405
So load balances must play an important
role to retrieve your results.

66
00:05:09,945 --> 00:05:11,655
Then the second is storage.

67
00:05:11,715 --> 00:05:12,674
Third one is, sorry.

68
00:05:12,825 --> 00:05:14,414
Third one is hybrid storage.

69
00:05:15,015 --> 00:05:20,804
So when the storage comes into picture,
we were combining the SSDs based

70
00:05:20,804 --> 00:05:26,445
hard storage for frequently accessed
embeddings with coal data and is

71
00:05:26,445 --> 00:05:28,935
both performance and cost efficiency.

72
00:05:29,640 --> 00:05:32,400
And the last one is Elastic scaling.

73
00:05:32,909 --> 00:05:37,500
Kubernetes deployments allow rack
components, vector stores and

74
00:05:37,500 --> 00:05:42,360
traverse, rankers and LMS to scale
independently based on demand.

75
00:05:43,440 --> 00:05:50,039
Now the second part is performance
optimization, so we need to get, we need

76
00:05:50,039 --> 00:05:53,940
to optimize our query set so that we will
get the results in a subsequent second.

77
00:05:54,854 --> 00:05:58,395
So the query latency, should
we need to get it below two

78
00:05:58,395 --> 00:06:01,185
seconds to retry your results.

79
00:06:01,784 --> 00:06:06,525
So the near, because we, in
enterprise, we used to get the real

80
00:06:06,525 --> 00:06:09,585
time responses from rack systems.

81
00:06:10,185 --> 00:06:14,445
So reducing query times from eight to
12 seconds to under second subsecond

82
00:06:14,505 --> 00:06:19,094
under two seconds, it requires a
multi-layer optimization strategy.

83
00:06:20,205 --> 00:06:27,525
So to our, to give these sub two second
response time for any rank systems, we

84
00:06:27,525 --> 00:06:30,135
have to focus on these four pillars.

85
00:06:30,195 --> 00:06:37,395
One is catching strategies, so your
que much must be catched in and, catch

86
00:06:37,395 --> 00:06:44,835
with the hash ash, hash value and query
level, catching for repeated requests and

87
00:06:44,835 --> 00:06:49,125
embedding level catching for frequently,
documents significantly reduced.

88
00:06:49,785 --> 00:06:51,015
Redundant competition.

89
00:06:52,455 --> 00:06:57,135
And the next one is hierarchical re
travel using a two-step travel process

90
00:06:57,615 --> 00:07:03,975
filtering, followed by fine range ranking,
minimize unnecessary vector comparisons.

91
00:07:05,325 --> 00:07:07,275
The third one is resource allocation.

92
00:07:07,305 --> 00:07:13,275
This which is a. Which is also a
place, a vital role, GPV accelerated

93
00:07:13,275 --> 00:07:15,735
with travel and dynamic model routing.

94
00:07:16,425 --> 00:07:20,205
For example, small L LMS for
lightweight queries, large LMS for

95
00:07:20,205 --> 00:07:26,085
complex queries, balance, speed with
cost, and the hybrid cloud deployment.

96
00:07:26,085 --> 00:07:30,015
So the deployment we can choose
is a hybrid cloud, so locating the

97
00:07:30,045 --> 00:07:34,155
travel and interference pipelines
closer to data sources via edge

98
00:07:34,155 --> 00:07:36,615
deployments or regional clusters.

99
00:07:37,125 --> 00:07:38,355
Reduces the latency.

100
00:07:40,155 --> 00:07:47,715
And when we go to the next slide, reliable
engineering, which is 99% availability,

101
00:07:47,805 --> 00:07:50,115
which is a must for the rag systems.

102
00:07:50,590 --> 00:07:56,445
The resell features of resilient
two failures across multiple

103
00:07:56,445 --> 00:08:01,095
layers, databases, inference,
pipelines, and orchestration.

104
00:08:01,695 --> 00:08:08,625
The key practices include monitoring and
observability fault tolerance, Charles

105
00:08:08,625 --> 00:08:11,265
engineering, ci, and CD automation.

106
00:08:12,044 --> 00:08:15,465
When it comes to the monitoring and
observability, we need to collect the

107
00:08:15,465 --> 00:08:20,534
metrics across embedding throughput
vector, such latency LLM, inference,

108
00:08:20,534 --> 00:08:23,445
time and system resource utilization.

109
00:08:23,610 --> 00:08:30,150
Tools we should use as ERs,
Grafana, et cetera, and telemetry

110
00:08:30,150 --> 00:08:31,530
is an essential tool too.

111
00:08:32,640 --> 00:08:33,845
For monitoring and observability.

112
00:08:35,460 --> 00:08:39,840
Next, when it comes to the fault
tolerance, so implement the replica of the

113
00:08:39,840 --> 00:08:45,930
clusters so that at any time any automated
failure happens, it'll automatically

114
00:08:45,930 --> 00:08:50,910
go back to the other region or other
failure in point to give you results.

115
00:08:51,510 --> 00:08:56,400
So check pointing of embeds to recover
from outages with minimal downtime.

116
00:08:56,400 --> 00:08:59,010
This is the main, motto
for the fall tolerance.

117
00:08:59,160 --> 00:09:03,930
When it comes to the Charles
Engineering regularly stress test

118
00:09:04,110 --> 00:09:08,520
trial pipelines under simulated
note values, our network partition

119
00:09:08,760 --> 00:09:10,770
to validate reliability exemptions.

120
00:09:11,189 --> 00:09:17,219
So always we need to focus when we
do, deploy the rag models, we can also

121
00:09:17,219 --> 00:09:20,699
check the stress systems test as well.

122
00:09:22,800 --> 00:09:28,170
So all these pipelines should be automated
and deployed through CICD process.

123
00:09:28,830 --> 00:09:34,470
We need to keep your was control
mechanisms for all your rack pipelines.

124
00:09:36,690 --> 00:09:42,060
It comes to next security and
compliance, which is a trustworthy

125
00:09:42,060 --> 00:09:44,910
for the enterprises security.

126
00:09:45,270 --> 00:09:49,680
So given the current days,
we need to secure our data.

127
00:09:49,740 --> 00:09:55,770
Enterprise data because of the sensitivity
and ence issues are non-negotiable.

128
00:09:56,610 --> 00:10:01,800
Production Ready Rack Systems must
integrate zero trust architecture

129
00:10:02,250 --> 00:10:07,470
encryption from end to end, and
must focus on trials and the

130
00:10:07,470 --> 00:10:09,150
data governance Integration too.

131
00:10:09,810 --> 00:10:15,569
Zero trust architectures means in
encrypt least privilege access across

132
00:10:15,569 --> 00:10:23,819
all rack components and ensure no
implicit trust between services.

133
00:10:24,780 --> 00:10:30,960
The encryption to end so encrypt
embeds at rest and in transit.

134
00:10:30,960 --> 00:10:33,210
To safeguard your S two data.

135
00:10:34,290 --> 00:10:38,580
Audit trials must be happens,
and it needs to be compliance

136
00:10:38,580 --> 00:10:42,660
with SOX two and IS 4 27 0 0 1.

137
00:10:42,660 --> 00:10:47,280
The data governance integration,
ensure rack pipelines, respect

138
00:10:47,550 --> 00:10:51,780
existing enterprise data governance
frameworks, including retention

139
00:10:51,780 --> 00:10:53,580
policies and access controls.

140
00:10:54,780 --> 00:10:55,860
Cost management.

141
00:10:56,160 --> 00:11:02,790
So after security and compliance comes
to the cost management for optimizing

142
00:11:02,790 --> 00:11:09,750
your resources at scale, enterprises
often face skying costs as rack systems

143
00:11:09,750 --> 00:11:12,360
scale, achieving up to 60% cost.

144
00:11:12,360 --> 00:11:17,550
DUCTION requires intelligence,
resource optimization, auto scaling,

145
00:11:17,550 --> 00:11:21,745
LLM, inference endpoints under
travel services and sourcers.

146
00:11:22,305 --> 00:11:28,005
Resources match demand without pro
or provisioning, the more tiring

147
00:11:28,305 --> 00:11:33,435
using smaller open social lamps for
routine queries and reserving premium.

148
00:11:33,435 --> 00:11:37,605
API calls for high value
use cases, cut cost.

149
00:11:37,610 --> 00:11:38,260
Brushed ling.

150
00:11:40,215 --> 00:11:45,825
Vendor negotiations, which will also play
a crucial role when we want, to reduce

151
00:11:45,825 --> 00:11:48,945
the cost for the rag systems enterprise.

152
00:11:48,945 --> 00:11:54,405
Managing 10 terabytes or terabyte
pository should leverage scale to

153
00:11:54,405 --> 00:11:58,785
secure volume discounts with vector
database and cloud service vendors.

154
00:12:00,195 --> 00:12:04,605
Workload placement, balancing
between on-premises, GPUs, part cloud

155
00:12:04,605 --> 00:12:10,275
incentives and manage vector services,
minimizes compute and storage expenses.

156
00:12:11,685 --> 00:12:15,615
The real world case studies,
proven patterns at scale.

157
00:12:16,515 --> 00:12:21,465
So over the last few years, more
than 50% Prise implementations

158
00:12:22,065 --> 00:12:23,325
success patterns have emerged.

159
00:12:24,765 --> 00:12:31,185
85% user adoption rates using this
rag model achieved by integrating

160
00:12:31,185 --> 00:12:36,135
seamlessly into existing enterprise
workflows like Slack Bot CRM plugins,

161
00:12:36,465 --> 00:12:39,201
knowledge portals, 200 to 400%.

162
00:12:41,280 --> 00:12:47,430
ROI in 18 months, driven by practic
gains, reduce support costs, and faster

163
00:12:47,790 --> 00:12:53,130
data missing making These implementations
also demonstrate proven architecture

164
00:12:53,130 --> 00:12:58,500
blueprints, modular pipelines that
combine vector databases, orchestrators

165
00:12:58,530 --> 00:13:03,210
and inference layers, allowing gradual
scaling with that wholesale system.

166
00:13:04,035 --> 00:13:09,105
Rewrites when it comes to the external
frameworks for the platform engineers.

167
00:13:09,225 --> 00:13:14,085
We need to succeed the rag model
and the production deployments.

168
00:13:14,355 --> 00:13:17,895
Platform engineers should
adapt section frameworks.

169
00:13:18,375 --> 00:13:21,045
The first one is vector picture design.

170
00:13:21,495 --> 00:13:26,870
Your right picture should involve any
vector database for your vector, such as

171
00:13:27,380 --> 00:13:32,295
this is your first component when you are
designing your rag company rag systems.

172
00:13:33,105 --> 00:13:39,584
In the enterprise level, so this
is, vector search will establish

173
00:13:39,675 --> 00:13:43,964
embedding, update, IES trading
logic and ranking algorithms

174
00:13:43,964 --> 00:13:45,495
aligned with the business needs.

175
00:13:46,214 --> 00:13:48,975
Next, your deployment should be automated.

176
00:13:49,605 --> 00:13:54,704
Use infrastructure as a code like
Terraform or health to standardize

177
00:13:54,765 --> 00:13:57,074
rack deployments across environments.

178
00:13:57,735 --> 00:14:01,275
Your deployment should be
seamless and automated.

179
00:14:02,355 --> 00:14:03,735
Using your Terraform call

180
00:14:06,015 --> 00:14:09,795
performance benchmarking, create
benchmarks, measuring end-to-end

181
00:14:09,795 --> 00:14:13,695
latency with travel accuracy
and throughput under peak load.

182
00:14:14,295 --> 00:14:19,065
So you need to do your performance
testing before deploying your rag models

183
00:14:19,545 --> 00:14:24,150
so that you will be aware of how your
rag is, re your response is coming.

184
00:14:24,885 --> 00:14:31,035
On a huge terabytes of data
request, so operational excellence.

185
00:14:31,334 --> 00:14:32,715
Define SLAs.

186
00:14:32,805 --> 00:14:34,454
What is your availability?

187
00:14:34,545 --> 00:14:38,385
99.9% and less than two.

188
00:14:38,385 --> 00:14:39,855
Second response time.

189
00:14:40,770 --> 00:14:45,030
And minimizing your whatever
rates and latency that align

190
00:14:45,030 --> 00:14:46,410
with the enterprise expectation.

191
00:14:46,410 --> 00:14:48,300
This will comes under
operational excellence.

192
00:14:49,080 --> 00:14:54,150
So the four, as I discussed, these
are the main core architecture

193
00:14:54,150 --> 00:14:56,550
components in any rag model.

194
00:14:57,540 --> 00:14:58,080
First is ingest.

195
00:14:59,865 --> 00:15:01,725
How you'll ingesting your data.

196
00:15:01,785 --> 00:15:05,925
Next is Vector database,
how you are retrieving or

197
00:15:05,925 --> 00:15:08,175
searching your query request.

198
00:15:08,715 --> 00:15:13,695
And now the third one is retrieval
how you want to retrieve your output.

199
00:15:14,595 --> 00:15:17,835
Next is you getting the
ranking of the output.

200
00:15:17,955 --> 00:15:20,625
And finally, LLM in France.

201
00:15:21,930 --> 00:15:27,900
Event and architecture integrates these
components while maintaining separation of

202
00:15:27,900 --> 00:15:33,420
concerns, allowing each element to scale
independently based on demand patterns.

203
00:15:34,020 --> 00:15:38,610
This module approach enables enterprise
to upgrade individual components

204
00:15:38,790 --> 00:15:44,250
without disrupting the entire system
performance benchmarking framework,

205
00:15:45,060 --> 00:15:47,135
rack system performance benchmarking.

206
00:15:48,405 --> 00:15:51,885
So platform English should
focus on these key five metrics.

207
00:15:52,005 --> 00:15:58,875
First is end-to-end query latency
under various load conditions, accuracy

208
00:15:58,935 --> 00:16:03,495
compared to ground truth system
throughput at peak, concurrent user

209
00:16:03,495 --> 00:16:09,285
levels, resource utilization across
compute, memory and storage, cost

210
00:16:09,285 --> 00:16:11,505
per query at different scale points.

211
00:16:11,895 --> 00:16:14,625
These benchmarks provide the
foundation for continuous

212
00:16:14,625 --> 00:16:17,175
automation and capacity planning.

213
00:16:18,314 --> 00:16:20,324
Security implementation checklist.

214
00:16:20,324 --> 00:16:26,775
So when we go into the security of
data, you need to implement this

215
00:16:26,865 --> 00:16:28,604
authentication and authorization.

216
00:16:28,995 --> 00:16:33,045
You need to protect your data,
and you have you, you need to

217
00:16:33,135 --> 00:16:35,025
compile your data with all these.

218
00:16:35,834 --> 00:16:42,735
and is O 27 0 0 1, certified
authentication authorization, implement

219
00:16:42,735 --> 00:16:46,635
WATH 2.4 or OIDC for user authentication.

220
00:16:47,400 --> 00:16:52,290
Enforce role-based access control
for all rag components integrated

221
00:16:52,290 --> 00:16:54,239
with the enterprise solutions.

222
00:16:55,079 --> 00:16:59,130
These are the three best practices we
need to follow when we are deploying

223
00:16:59,130 --> 00:17:01,229
your rag models and enterprise level.

224
00:17:01,560 --> 00:17:06,359
And make sure you those RA
models are securely deployed.

225
00:17:08,369 --> 00:17:14,234
the data protection at rest and
transient must be encrypted.

226
00:17:15,704 --> 00:17:22,814
Using a 2 56 algorithm, implement
TLS 1.34 protocol for all service,

227
00:17:22,814 --> 00:17:24,704
authentication or communications.

228
00:17:25,395 --> 00:17:29,355
Apply data masking for sensitive
information in logs so that you can

229
00:17:29,355 --> 00:17:31,725
use your, role based access control.

230
00:17:33,435 --> 00:17:34,395
Compliance.

231
00:17:34,425 --> 00:17:37,725
Maintain detailed audit logs
for all system interactions.

232
00:17:37,754 --> 00:17:42,014
Implement retention policies
aligned with regulated requirements,

233
00:17:42,375 --> 00:17:45,465
conduct regular security
assessment and penetration testing.

234
00:17:46,094 --> 00:17:50,715
Implementing these security measures,
ensure that rack systems meet and price

235
00:17:50,895 --> 00:17:56,475
compliance requirements while protecting
data through the generation process.

236
00:17:58,274 --> 00:18:00,129
And the last slide when
we come to the conclusion.

237
00:18:01,110 --> 00:18:04,320
The rag represents a paradigm
shift in endocrin knowledge

238
00:18:04,320 --> 00:18:09,179
infrastructure, transforming static
K models into dynamic context.

239
00:18:09,360 --> 00:18:14,129
Our systems for platform engineers
challenge lies not only in implementing

240
00:18:14,639 --> 00:18:19,050
pipelines, but also in scaling how you
are going to scale your rag models.

241
00:18:19,409 --> 00:18:23,700
You have to design your
architecture both to be scaled

242
00:18:23,700 --> 00:18:25,439
in vertically and horizontally.

243
00:18:26,100 --> 00:18:31,230
And implementing best security practices
like we discussed, we need to mu we

244
00:18:31,230 --> 00:18:33,060
need to follow the proper protocols.

245
00:18:33,735 --> 00:18:35,535
And optimizing them for production.

246
00:18:36,045 --> 00:18:40,005
By mastering infrastructure design,
performance optimization, reliable

247
00:18:40,005 --> 00:18:46,095
engineering, security and cost management,
platform engineers can build production

248
00:18:46,095 --> 00:18:51,705
ready rack systems that deliver business
value adaption and generate to and

249
00:18:51,705 --> 00:18:56,145
generate miserable ROI and raise that.

250
00:18:56,145 --> 00:18:56,475
Adapt.

251
00:18:56,475 --> 00:18:59,775
These strategies will not only overcome
the limitations of traditional.

252
00:19:00,615 --> 00:19:05,385
But also unlock a new era of AI
driven knowledge, access, reliable,

253
00:19:05,385 --> 00:19:06,945
scalable, and future proof.

254
00:19:08,264 --> 00:19:08,685
That's all.

255
00:19:08,685 --> 00:19:09,524
Any questions.

256
00:19:09,554 --> 00:19:10,185
Thank you.

257
00:19:13,004 --> 00:19:14,570
Thank you for providing this opportunity.

