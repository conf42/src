1
00:00:00,360 --> 00:00:00,810
Hello everyone.

2
00:00:01,110 --> 00:00:02,340
My name is Gobin Kaman.

3
00:00:02,550 --> 00:00:06,270
I'm a data architect enable digital
transformations through data strategy

4
00:00:06,270 --> 00:00:11,340
and ea. I focus on ERNI, industry,
sector and specialist and oil and guests.

5
00:00:11,880 --> 00:00:15,420
Today I'll be presenting on how
AA is reshaping the master data

6
00:00:15,420 --> 00:00:17,190
governance in an SAP environment.

7
00:00:17,280 --> 00:00:20,310
And I'll also take you through with the
small use cases, which is an incident

8
00:00:20,310 --> 00:00:23,630
management application as we talk
about data such as customer master.

9
00:00:23,974 --> 00:00:28,174
Suppliers, materials, enterprises,
asset management or HR data such.

10
00:00:28,174 --> 00:00:30,904
For any example, employee
data are considered.

11
00:00:30,904 --> 00:00:35,375
These data are considered a blood line of
any enterprise applications when this data

12
00:00:35,375 --> 00:00:38,135
is inaccurate, inconsistent, or outdated.

13
00:00:38,614 --> 00:00:42,394
This affects the operational SAP
processes such as supply chain, order

14
00:00:42,394 --> 00:00:44,435
to cash, or even infect the finance.

15
00:00:44,935 --> 00:00:46,225
It also doesn't stop there.

16
00:00:46,345 --> 00:00:49,555
It also impacts their downstream
applications, which consumes

17
00:00:49,555 --> 00:00:51,085
this data and use this data.

18
00:00:51,585 --> 00:00:55,780
Any change to the data will, not
just going and updating data,

19
00:00:55,840 --> 00:00:58,960
it needs an incident management
application where you had to submit

20
00:00:59,005 --> 00:01:00,045
an incident to correct the data.

21
00:01:00,955 --> 00:01:05,425
And the data stewards who are responsible
for that have to come and put their

22
00:01:05,425 --> 00:01:08,965
effort to correct the data and replicate
the data to the respective applications.

23
00:01:09,465 --> 00:01:14,085
Today I'll be taking through the journey
from a traditionally MDM to an A driven

24
00:01:14,085 --> 00:01:19,185
cognitive MDM and practical SAP use
cases, implementing that approach.

25
00:01:20,145 --> 00:01:23,295
We will discuss about how AI
brings an A actionable results.

26
00:01:23,795 --> 00:01:27,935
Measurable results, actionable
insights, and forward looking, how

27
00:01:27,935 --> 00:01:29,495
implementing those set solutions.

28
00:01:29,705 --> 00:01:35,065
Let's start with the governance approach
and see how this can be mitigated, but

29
00:01:35,065 --> 00:01:36,865
then instant management applications.

30
00:01:37,765 --> 00:01:42,025
As we all know, data is the backbone
of A-E-S-A-P applications, rather

31
00:01:42,085 --> 00:01:43,615
any ERP applications, right?

32
00:01:43,855 --> 00:01:47,210
It connects to the various business
processes or operations such as

33
00:01:47,210 --> 00:01:49,010
procurement, finance, or supply chain.

34
00:01:49,900 --> 00:01:50,860
Of data.

35
00:01:50,860 --> 00:01:53,820
So data is the DNA for ions.

36
00:01:54,000 --> 00:01:57,270
If the DNA is corrupted, you're
right, everything will go back

37
00:01:57,660 --> 00:01:58,680
and then it'll fall apart.

38
00:01:59,250 --> 00:02:00,720
You cannot uncompromised on this data.

39
00:02:00,870 --> 00:02:02,220
Incorrect data, right?

40
00:02:03,210 --> 00:02:05,670
How these, this has
been done traditionally.

41
00:02:06,150 --> 00:02:09,780
Traditionally, our systems are
built and relied on manual rules.

42
00:02:10,280 --> 00:02:13,554
That means that can be manageable
when the volume is limited.

43
00:02:13,929 --> 00:02:18,180
Or the proactive measures can be taken
through a manual processes, right?

44
00:02:19,019 --> 00:02:24,660
Ghana, the days now things are changing
by a globalization with the imp, with the

45
00:02:24,660 --> 00:02:29,190
inclusion of multi-system environment,
a rule-based approach are fragile,

46
00:02:29,400 --> 00:02:34,100
slow, and prone To understand this
challenge better, let's get to a few

47
00:02:34,130 --> 00:02:36,140
master data maintenance limitations.

48
00:02:36,170 --> 00:02:39,770
How cognitive MDM can address
this challenge, right?

49
00:02:40,270 --> 00:02:44,350
Let's shift into that traditional MDM
limitation so that you'll all understand

50
00:02:44,680 --> 00:02:49,030
how, what is the key challenges
using a traditional md, as we all

51
00:02:49,030 --> 00:02:53,350
know, we talked about that rule-based
validations and a manual fencing impact.

52
00:02:53,850 --> 00:02:58,850
Traditional MDM to be slow as this cannot
cap up, this cannot keep up with the PA

53
00:02:58,910 --> 00:03:03,410
pace when there is a velocity increases
or the variety of data changes, right?

54
00:03:03,890 --> 00:03:08,420
Key challenges includes such static
data that do not adapt to a business

55
00:03:08,420 --> 00:03:13,700
scenario such as consolidations or
harmonization, and also do not support

56
00:03:13,725 --> 00:03:15,455
an extension to a new product line.

57
00:03:15,955 --> 00:03:19,935
Majority of the traditional MDM
were batch managed batch process,

58
00:03:19,935 --> 00:03:24,135
managed that delayed detection
until the, until it is too late.

59
00:03:24,635 --> 00:03:26,015
It has a huge challenge.

60
00:03:26,225 --> 00:03:27,755
It's more of a reactive approach.

61
00:03:28,024 --> 00:03:30,785
The struggle is in the distributed
environment where the correction

62
00:03:30,785 --> 00:03:33,725
need to be started from the MDM
applications and then replicate

63
00:03:33,725 --> 00:03:34,715
to the consumer application.

64
00:03:35,215 --> 00:03:37,640
Research shows that poor data maintenance.

65
00:03:38,290 --> 00:03:44,299
In an enterprise application on an average
impacts $13 million annually, right?

66
00:03:44,929 --> 00:03:45,589
That's not it.

67
00:03:45,890 --> 00:03:47,470
It does not stop with the cost.

68
00:03:47,560 --> 00:03:51,690
It also includes 41% of data,
professional work data, professional

69
00:03:51,690 --> 00:03:53,160
car time is getting wasted.

70
00:03:53,550 --> 00:03:56,220
It can be, which it can be
used for innovating purposes.

71
00:03:56,720 --> 00:04:00,865
Now it's a time to sift how
through an AI transformation.

72
00:04:01,365 --> 00:04:05,445
A transforms MDM to a deterministic
to a cognitive though, right?

73
00:04:05,715 --> 00:04:09,735
How a brings up machine
learning that enables a pattern

74
00:04:09,765 --> 00:04:11,535
recognition and anomaly detection.

75
00:04:12,035 --> 00:04:14,765
Natural language processing
unlocks the unstructured data

76
00:04:14,855 --> 00:04:15,875
and improves the useability.

77
00:04:16,805 --> 00:04:19,695
A sentimental reviews can be read
through that unstructured data

78
00:04:19,800 --> 00:04:21,825
and text can be read through that.

79
00:04:21,915 --> 00:04:22,545
And based on that.

80
00:04:23,045 --> 00:04:25,955
Incident can be created
automatically where incident

81
00:04:25,955 --> 00:04:27,664
management can help with this.

82
00:04:28,145 --> 00:04:32,485
With the preventive predictive analytics
in place, the set of governance

83
00:04:32,485 --> 00:04:38,140
from a reactive to a proactive
can happen when AI arguments MDM

84
00:04:38,575 --> 00:04:42,505
organization move from a firefighting
mode to a preventing them right?

85
00:04:43,105 --> 00:04:47,875
I can give a few real time examples
instead of waiting for a duplicate vendor

86
00:04:47,875 --> 00:04:49,375
need to be corrected in the first place.

87
00:04:49,990 --> 00:04:53,230
Right now what is happening is it's
waiting for them payments to be

88
00:04:53,230 --> 00:04:57,640
failed, and the system flags if the
duration that duration can happen.

89
00:04:58,150 --> 00:04:58,660
Instead.

90
00:04:58,900 --> 00:05:03,340
If we were able to do that well
in advance, this detection can

91
00:05:03,340 --> 00:05:06,355
happen well in advance so that the
correction can be early in advance.

92
00:05:06,700 --> 00:05:10,495
How the evolution happened from a
traditional versus a cognitive brain.

93
00:05:11,380 --> 00:05:14,830
Since we got a good handle of
traditional MDM, as we all talked

94
00:05:14,830 --> 00:05:18,970
about a rule-based workflow, our
rule-based definition has been made.

95
00:05:19,810 --> 00:05:21,370
MDM has a limitations.

96
00:05:21,370 --> 00:05:23,380
Now, traditional MDM has a limitation.

97
00:05:23,380 --> 00:05:28,930
Now let's do a quick compare how
a traditional MDM can be a can

98
00:05:28,930 --> 00:05:31,645
be an issue with the cognitive
MDM against the cognitive M dm.

99
00:05:32,320 --> 00:05:36,520
In traditional MDM, as we talked about
majority death cases, it's all rule-based.

100
00:05:37,255 --> 00:05:40,284
Majority of them are generally
central managed, right?

101
00:05:40,315 --> 00:05:43,315
Which means that somebody has
to come and correct the data

102
00:05:43,465 --> 00:05:45,474
and manually intent process.

103
00:05:45,974 --> 00:05:48,465
It's all reactive and a
batch processes, right?

104
00:05:48,794 --> 00:05:52,934
Which means that you had to wait for the
failure to happen and somebody manually

105
00:05:52,934 --> 00:05:54,284
have to go and correct this data.

106
00:05:54,974 --> 00:05:57,014
This is an which, an impact, right?

107
00:05:57,374 --> 00:06:02,224
In contrast, when we do the cognitive
M DM machine learning algorithms.

108
00:06:02,629 --> 00:06:03,649
Natural language process.

109
00:06:03,949 --> 00:06:07,759
Our predictive analytics can ha
help improving this processes,

110
00:06:08,259 --> 00:06:09,609
you take the proactive measures.

111
00:06:10,209 --> 00:06:13,779
Adapt that and address the realtime
issues on and off on directly.

112
00:06:14,499 --> 00:06:17,619
It's capable of also, it is
also capable of handling a large

113
00:06:17,619 --> 00:06:19,149
volume of data in a sub-second.

114
00:06:19,649 --> 00:06:23,729
This approach from a traditional
MDM to a cognitive M immune is not

115
00:06:23,729 --> 00:06:26,669
just an incremental, you are not
sifting from one system to another.

116
00:06:26,849 --> 00:06:28,319
It's whole paradigm shift.

117
00:06:28,859 --> 00:06:32,459
The data governance evolved
from a static guardrail to an

118
00:06:32,459 --> 00:06:34,679
intelligent self-improving systems.

119
00:06:35,489 --> 00:06:36,929
So the challenge shows that.

120
00:06:37,739 --> 00:06:40,859
There is a need for a smarter
way at adaptive governance

121
00:06:40,859 --> 00:06:41,909
through a cognitive MDM.

122
00:06:42,409 --> 00:06:47,164
This sits from the fundamental MDM
to a powered MDM solution, right?

123
00:06:47,674 --> 00:06:50,854
How organization approach data
governance within the SAP ecosystem.

124
00:06:51,514 --> 00:06:54,754
Now let's understand the impact
of when master data goes wrong.

125
00:06:55,234 --> 00:06:59,224
Data, how, when there is an instant
need to be created and then instant

126
00:06:59,674 --> 00:07:01,444
ripple through the SAP landscape.

127
00:07:01,944 --> 00:07:06,534
There are four areas that need to focus
when incident need to be treated right.

128
00:07:07,104 --> 00:07:12,054
How there are majority of the areas
such as data quality issues, which is

129
00:07:12,054 --> 00:07:18,354
a inconsistency of data which spreads
across the module, impacted areas like

130
00:07:18,414 --> 00:07:23,574
data analytics, where the direct impacts
to identify the right details or reporting

131
00:07:23,574 --> 00:07:24,714
to the leadership of our customer.

132
00:07:25,374 --> 00:07:27,804
Personally, I have seen
many such challenges.

133
00:07:27,864 --> 00:07:31,404
Where involves heavy human
interventions to carry the data.

134
00:07:32,214 --> 00:07:36,804
Obviously this will cost time and
money for any of the human projects.

135
00:07:37,194 --> 00:07:41,694
Majority of the data projects invo
involves in the data quality corrections.

136
00:07:42,194 --> 00:07:46,614
It also doesn't stop there just as the
data, it cascades the are, it propagates

137
00:07:46,614 --> 00:07:51,494
the data into a integration points
such as the data which are created

138
00:07:51,494 --> 00:07:53,499
or updated in the traditionally MDM.

139
00:07:54,479 --> 00:07:57,869
Sends operational, send the data
to integration plans such as

140
00:07:57,869 --> 00:08:01,709
operational SAP systems, or in fact,
to the downstream applications.

141
00:08:02,219 --> 00:08:06,359
For example, if a EA Enterprise Asset
management data replaces the data to

142
00:08:06,359 --> 00:08:10,979
a performance management system, the
rules that in the performance management

143
00:08:10,979 --> 00:08:14,939
need to be corrected are calculated
based on the data, what it receives.

144
00:08:15,509 --> 00:08:19,409
If the data goes bad, obviously the
rules will not match, and then the

145
00:08:19,409 --> 00:08:20,909
performance calculation will go over.

146
00:08:21,749 --> 00:08:25,809
This would impact, hit the preventive
or proactive maintenance or a

147
00:08:25,809 --> 00:08:27,339
reactive maintenance process.

148
00:08:27,439 --> 00:08:32,139
Wherein the wherein the process can go
bad and then it'll create a lot of issues

149
00:08:32,139 --> 00:08:34,929
in the preventive maintenance process,
especially in the oil and gas sector.

150
00:08:35,429 --> 00:08:37,529
It also has a valid velocity changes.

151
00:08:37,529 --> 00:08:39,719
When there is a velocity
that volume changes.

152
00:08:40,454 --> 00:08:45,684
In the global instance, such as the
global Master declaration, the issue

153
00:08:45,739 --> 00:08:49,939
doesn't stop in one location, it
spreads to the other areas as well.

154
00:08:50,439 --> 00:08:52,719
These are the very concerning
for the centrally managed

155
00:08:52,719 --> 00:08:54,069
objects, such as customer master.

156
00:08:54,489 --> 00:08:57,309
It replicates the data to the
all the subsequent applications,

157
00:08:57,369 --> 00:08:58,569
which impacts this data.

158
00:08:59,069 --> 00:09:02,159
It also impacts the operational
resilience, depends on

159
00:09:02,159 --> 00:09:03,449
preventing that failure early.

160
00:09:03,854 --> 00:09:09,404
A single corrupted supplier
data today, no longer, it'll

161
00:09:09,404 --> 00:09:11,144
not just stop the supply chain.

162
00:09:11,244 --> 00:09:11,844
Impact.

163
00:09:12,024 --> 00:09:15,684
It also impacts the foundational
data that cannot be compromised.

164
00:09:16,674 --> 00:09:19,404
The effects can propagate to the
multiple layers of the enterprise

165
00:09:19,404 --> 00:09:23,034
architecture, as you all know, from
the data ingestion to the operational

166
00:09:23,034 --> 00:09:25,284
systems, to the data consumption systems.

167
00:09:26,274 --> 00:09:29,934
Speaking to all these challenges
with the new tools and technologies,

168
00:09:29,964 --> 00:09:32,034
the challenge can be addressed via.

169
00:09:32,534 --> 00:09:37,264
A solution which has an which
enhances resilience by making a data

170
00:09:37,864 --> 00:09:39,334
ance as a proactive ance, right?

171
00:09:39,724 --> 00:09:41,794
Instead of your reactive
or a firefighting mode.

172
00:09:42,294 --> 00:09:45,334
Three pillars of the there are
three pillars which can drive this

173
00:09:45,334 --> 00:09:49,469
transformations, machine learning,
natural language processing,

174
00:09:49,834 --> 00:09:51,304
and then predictor analytics.

175
00:09:51,604 --> 00:09:56,194
These are the three key pillars
which A, can be driven and help this

176
00:09:56,344 --> 00:09:57,964
cognitive implementing cognitive.

177
00:09:58,464 --> 00:10:01,714
Machine learning, for example
it can detect and correlate the

178
00:10:01,954 --> 00:10:04,744
SubT related data predictor.

179
00:10:04,744 --> 00:10:09,364
Lyze anomalies automate the
classifications and it gives

180
00:10:09,364 --> 00:10:10,814
a it gives a good results.

181
00:10:11,084 --> 00:10:16,124
For instance, anomaly detection capability
that far exceeds from the human analytics.

182
00:10:16,514 --> 00:10:20,204
In today's world, what data stewards
are doing it is they're taking a

183
00:10:20,204 --> 00:10:22,394
report out of a Power BI or an Excel.

184
00:10:22,424 --> 00:10:23,984
They scan through the data.

185
00:10:24,014 --> 00:10:27,044
They're finding an anomaly of
this data is very cumbersome.

186
00:10:27,644 --> 00:10:31,754
It's not easy to do a manual
interpretation and try to find that data,

187
00:10:32,234 --> 00:10:34,424
which cost a lot of time and energy.

188
00:10:34,424 --> 00:10:39,664
Further, this can be overridden by
writing in ML languages, whether all

189
00:10:39,664 --> 00:10:43,024
those challenges can be addressed and
anomaly detection can be done within

190
00:10:43,024 --> 00:10:44,564
the Sub-Zero seconds, as you all know.

191
00:10:45,064 --> 00:10:46,864
NLP natural language pricing, right?

192
00:10:47,554 --> 00:10:50,554
There are unstructured data
which relies on customer.

193
00:10:50,684 --> 00:10:55,754
Data can be relayed on the desktop
applications from the users, or it

194
00:10:55,754 --> 00:11:00,415
can be relay on the data management
applications such as DMS or D two systems.

195
00:11:00,915 --> 00:11:04,485
Any of these unstructured data
enables a conversational governance

196
00:11:04,485 --> 00:11:06,020
by leveraging the value through her.

197
00:11:06,675 --> 00:11:12,555
Text extraction wherein NLP will go read
that data and then find that text out.

198
00:11:13,515 --> 00:11:17,685
You can do the sentimental analysis
based on the user's response saying

199
00:11:17,685 --> 00:11:19,485
that, okay, this is a good data.

200
00:11:19,740 --> 00:11:22,190
I helped to remediate by this processes.

201
00:11:22,190 --> 00:11:26,270
All those things, based on their
interactions with the systems, these

202
00:11:26,330 --> 00:11:30,020
sentiments can be read and then future
forward looking it can correct its

203
00:11:30,020 --> 00:11:31,989
own predictive analytics, right?

204
00:11:32,139 --> 00:11:34,599
Helps to identify the
risk very well in advance.

205
00:11:35,469 --> 00:11:39,540
And materialize and focus that issues
in a potential on the potential

206
00:11:40,110 --> 00:11:43,949
these data can, these issues can
happen and potentially instant can

207
00:11:43,980 --> 00:11:46,140
be triggered well in advance, right?

208
00:11:46,560 --> 00:11:49,770
Based on the time series
analysis, it has its own, and then

209
00:11:49,770 --> 00:11:52,260
historical data analysis together.

210
00:11:52,260 --> 00:11:55,801
These create a cognitive layer
over the A PM, dm, S-A-P-M-D-G,

211
00:11:55,806 --> 00:11:57,574
haa and data outs and on.

212
00:11:58,574 --> 00:12:04,094
From 2025 SAP roadmap, adding SAPM,
dg, MDG on B two P applications, which

213
00:12:04,094 --> 00:12:07,364
supports a and ML capability, right?

214
00:12:07,864 --> 00:12:12,514
Analytics, a driven analytics is part
of the SAPM, DG MDG solution with the

215
00:12:12,514 --> 00:12:16,055
data quality controls as they make
it to their a core as a solution.

216
00:12:16,055 --> 00:12:19,584
Looking forward with all the
foundational layout laid out.

217
00:12:19,944 --> 00:12:25,619
Now let's jump into understand how
operational AA is supporting this in M

218
00:12:25,619 --> 00:12:27,659
dm. How this can be implemented, right?

219
00:12:28,079 --> 00:12:32,519
Cognitive MDM for an instant readiness
classified into four different stages.

220
00:12:33,329 --> 00:12:37,619
First, as we all know, we start with the
assessment and find the readiness of it.

221
00:12:38,119 --> 00:12:41,404
The assessment on any data project
starts with the filing of data, right?

222
00:12:41,904 --> 00:12:42,224
Evaluate the.

223
00:12:43,114 --> 00:12:46,714
Current process maturity,
data, infrastructure readiness,

224
00:12:47,494 --> 00:12:48,744
and other parameters.

225
00:12:49,224 --> 00:12:55,674
This can be done through a building a LLM,
small LLM based on the AA to drive the

226
00:12:55,674 --> 00:13:00,684
data profiling work where users can build
profiling dashboards from a live data and

227
00:13:00,684 --> 00:13:06,994
perform appropriate, actionable cleansing
effort, okay, at the source and advise the

228
00:13:06,994 --> 00:13:08,764
transformations logic to be implemented.

229
00:13:09,264 --> 00:13:14,184
I personally have implemented a small
solution, which is a LLM that reads

230
00:13:14,184 --> 00:13:18,414
the data from the live data, from
the systems or the legacy systems,

231
00:13:18,744 --> 00:13:22,254
and generate the profiling dashboard
for the users that this have the

232
00:13:22,254 --> 00:13:24,834
users to go and figure it out.

233
00:13:24,894 --> 00:13:28,674
If there is a data cleansing data is
required when there is a transformation

234
00:13:28,674 --> 00:13:32,064
project in place for them, and
then this will be help for them in

235
00:13:32,064 --> 00:13:33,534
the transformation project across.

236
00:13:34,034 --> 00:13:35,144
How do we approach, right?

237
00:13:35,744 --> 00:13:38,174
We cannot just go and
do the whole deployment.

238
00:13:38,234 --> 00:13:42,374
Instead, we had to go as a modular
architecture, deploy a domain

239
00:13:42,374 --> 00:13:44,594
specific or use case driven modules.

240
00:13:44,744 --> 00:13:45,044
Okay?

241
00:13:45,104 --> 00:13:48,074
Integrating in C framework,
we don't want to just go and

242
00:13:48,134 --> 00:13:49,424
boil the integration, right?

243
00:13:50,024 --> 00:13:54,024
Our focus should be on a priority, our
severity, key use cases on the high

244
00:13:54,024 --> 00:13:57,819
priority and the severity use cases, and
approach those as the priority one items.

245
00:13:58,319 --> 00:14:00,719
Obviously there will
be a human interaction.

246
00:14:00,719 --> 00:14:05,309
AI collaboration is must have, as you
all know, the data need to be the a LM

247
00:14:05,309 --> 00:14:11,039
model need to be trained based on the
use case given by the data stewards and

248
00:14:11,039 --> 00:14:12,389
with the SAP infrastructure framework.

249
00:14:12,889 --> 00:14:17,089
Focus on the objects which are
high, complex logics to be trained,

250
00:14:17,589 --> 00:14:21,489
complex objects so that the A model
can be trained and then enrich their

251
00:14:21,489 --> 00:14:23,019
capabilities on the going forward.

252
00:14:23,519 --> 00:14:26,039
Change management is one of the
key area which you need to focus

253
00:14:26,039 --> 00:14:27,329
on the whole process, right?

254
00:14:27,659 --> 00:14:32,099
It's not just a tool which derives
that or which determines the solution.

255
00:14:32,594 --> 00:14:35,234
It's a mindset of people
also need to be changed.

256
00:14:35,324 --> 00:14:39,594
They have to upskill their upskill,
redesign the process where necessary,

257
00:14:39,744 --> 00:14:43,264
such as implementing a SIP two
implementing smaller solutions.

258
00:14:43,324 --> 00:14:47,794
For example, a SIP two customer,
which today it has been manual

259
00:14:47,794 --> 00:14:51,974
process of, integrating this and
then creating a workflow process

260
00:14:51,974 --> 00:14:53,564
and all those things tomorrow.

261
00:14:53,819 --> 00:14:56,789
We can de devise a plan saying
that if it's a region, it's this

262
00:14:56,789 --> 00:14:58,619
one, and then sold to is this one.

263
00:14:58,859 --> 00:15:01,529
All I need to do is automatic
this, automate this one so

264
00:15:01,529 --> 00:15:02,969
that the STO can be created.

265
00:15:02,969 --> 00:15:06,899
We don't need a manually interaction
attack with that, the structured framework

266
00:15:07,169 --> 00:15:09,269
A becomes a Bolton, just a bolt-on tool.

267
00:15:09,479 --> 00:15:12,729
We don't want to do this so we
need to have structured approach.

268
00:15:12,789 --> 00:15:17,379
It becomes a trans that can be
transformable and help to build

269
00:15:17,379 --> 00:15:18,969
the enterprise and the data set.

270
00:15:19,119 --> 00:15:20,144
Data can be set right.

271
00:15:20,644 --> 00:15:24,924
Unlike the periodic checks by a user,
unlike the periodic check by the

272
00:15:24,924 --> 00:15:31,134
users, the quality reports, a model
can be trained continuously to monitor

273
00:15:31,134 --> 00:15:33,144
and continuously evolve the data.

274
00:15:33,864 --> 00:15:37,469
It can also assess the data and mediate
automatically, assess as needed.

275
00:15:37,969 --> 00:15:40,184
How do we do the real time
monitoring and preventing right.

276
00:15:40,684 --> 00:15:44,644
Given the business category like an
asset man asset manage asset maintenance

277
00:15:44,644 --> 00:15:48,994
process, a realtime monitoring represents
one of the most significant ones in

278
00:15:48,994 --> 00:15:54,034
the eight one management applications,
such as steam analysis, adaptive

279
00:15:54,034 --> 00:15:56,284
thresholds, and pattern correlation.

280
00:15:57,124 --> 00:16:01,694
In an EM based in an EM objects,
object types, and a maintenance plan

281
00:16:01,694 --> 00:16:04,769
can drive a lot of, based on the
object type and the maintenance plan.

282
00:16:05,279 --> 00:16:07,799
The insights of the asset
objects can be collected and

283
00:16:07,799 --> 00:16:09,719
correlate to identify the pattern.

284
00:16:10,219 --> 00:16:14,359
Incident can be caught before
they escalate with this, right?

285
00:16:14,749 --> 00:16:18,389
For example, a sudden spike of an
rejected purchase order might be

286
00:16:18,389 --> 00:16:22,014
a flagged in a real time by trace
of to a faulty vendor master.

287
00:16:22,014 --> 00:16:27,254
This could be, and this can be corrected,
or if you do not correct this one on time,

288
00:16:27,464 --> 00:16:29,174
it's gonna go into a financial process.

289
00:16:29,849 --> 00:16:35,219
A based solutions can help to alter
alert the preventions by assessing

290
00:16:35,219 --> 00:16:38,639
the business impacts, prioritizing
the risk, and escalate this

291
00:16:39,029 --> 00:16:42,799
dynamically with the trend analysis
and this and the seasonal pattern.

292
00:16:42,899 --> 00:16:46,799
Predictive issues, identification,
help to correlate the analysis and

293
00:16:46,799 --> 00:16:50,309
identify the scenarios and respective
capabilities can be achieved.

294
00:16:50,809 --> 00:16:52,524
Now, we talked about a benefits.

295
00:16:53,024 --> 00:16:53,954
Proactive monitoring.

296
00:16:54,074 --> 00:16:59,564
Also, right now, let's find how this
outcome will help how the outcome

297
00:16:59,664 --> 00:17:01,604
a enhanced master data outcomes.

298
00:17:01,874 --> 00:17:05,924
Our capabilities can accelerate the
root cause of analysis by providing an

299
00:17:05,924 --> 00:17:10,154
intelligent investment support automate
the correlation analysis and pattern

300
00:17:10,154 --> 00:17:12,134
recognition can be a future forward.

301
00:17:12,634 --> 00:17:14,704
How do we accelerate the
root cause analysis, right?

302
00:17:15,204 --> 00:17:20,624
A also accelerate root cause analysis
by automating the lineage tracing shows

303
00:17:20,649 --> 00:17:24,884
where they error occurred, where it
started, and how the data occurred.

304
00:17:25,384 --> 00:17:30,364
NLP interfaces allows the data steward
to ask, why did this error occur?

305
00:17:31,174 --> 00:17:35,644
This allows the data steward to
identify and analysis through the

306
00:17:35,644 --> 00:17:38,164
failure curve and predictive analysis.

307
00:17:38,664 --> 00:17:41,994
Based on the analysis, data
steward can remediate the

308
00:17:41,994 --> 00:17:43,554
data and replicate as needed.

309
00:17:44,154 --> 00:17:47,014
This can be a good training
for their data model as well.

310
00:17:47,514 --> 00:17:51,594
Multidimensional correlations
identifies across system impacts,

311
00:17:51,654 --> 00:17:55,164
such as identifying and impacts and
m and the magnitude is very high.

312
00:17:56,034 --> 00:18:00,414
This helps to prioritize the
investigation in RU root cause analysis.

313
00:18:01,074 --> 00:18:04,194
The result of this
analysis is not just time.

314
00:18:04,809 --> 00:18:09,979
It all it just reduce the time from
a days to an hours resolution becomes

315
00:18:09,979 --> 00:18:12,979
smarter by announcing the detection
analysis, as you all know, right?

316
00:18:13,069 --> 00:18:18,079
You detect early so that the analysis can
be done early and then the capabilities

317
00:18:18,079 --> 00:18:22,389
can be achieved for an incident resolution
activities that can be addressed.

318
00:18:22,629 --> 00:18:25,719
Many data related incident
without human information.

319
00:18:26,219 --> 00:18:31,339
This can be reduced 50% of the data
towards time so that they can focus on

320
00:18:31,609 --> 00:18:35,329
innovating the data solutions rather than
wasting the time on correcting the data.

321
00:18:35,989 --> 00:18:40,199
How do we, the intelligent automation of
the resolution can happen when the, when

322
00:18:40,199 --> 00:18:45,299
we say the resolution becomes smarter, but
then intelligent automation process, there

323
00:18:45,299 --> 00:18:49,164
are some processes such as autonomous
data correction need to be established.

324
00:18:49,664 --> 00:18:53,174
For an example, the system may
automatically correct and misclass

325
00:18:53,234 --> 00:18:54,644
and misclassified the material code.

326
00:18:55,604 --> 00:18:58,214
This can be notified to the
approvers and ensure that

327
00:18:58,214 --> 00:18:59,504
compliance logs can be updated.

328
00:19:00,004 --> 00:19:05,044
Predictive strategies based on the
historical impacts helps, which will help

329
00:19:05,104 --> 00:19:09,919
reduce the resource optimization and find
the algorithms, the timeline predictions,

330
00:19:10,039 --> 00:19:12,019
and model the estimate solutions.

331
00:19:12,519 --> 00:19:17,439
Key benefits of routing the workflow
dynamically and artistry the

332
00:19:17,439 --> 00:19:21,699
stakeholders to support their co
compliance and audit integration

333
00:19:22,659 --> 00:19:24,969
with the release of 2025 and beyond.

334
00:19:25,029 --> 00:19:29,699
SAP performs very heavily on the
a, a transformations a forward

335
00:19:29,704 --> 00:19:31,294
for forward looking aid solutions.

336
00:19:31,794 --> 00:19:34,509
SAP is simplifying the architecture,
as you all know, by introducing

337
00:19:34,509 --> 00:19:37,959
the a and ml capabilities in
the areas such as SAP Hana.

338
00:19:38,394 --> 00:19:42,684
In memory computing where ML libraries
and a real time replication can happen

339
00:19:43,524 --> 00:19:47,574
and implementing an S-A-P-M-D-G solutions
where workflow enhancements have

340
00:19:47,574 --> 00:19:52,614
happening, semantic improvements are
added, which includes the analytics.

341
00:19:52,664 --> 00:19:56,534
Predictive analytics reporting has
been built, okay, but today world,

342
00:19:56,594 --> 00:19:59,444
there, there is no predictive
analytics of the dashboard cannot

343
00:19:59,444 --> 00:20:04,394
be done for a data quality reports
that has to be manually built and it

344
00:20:04,394 --> 00:20:06,139
has to be built outside of the MDG.

345
00:20:07,079 --> 00:20:10,319
By introducing the data spare
into the system where cementing

346
00:20:10,319 --> 00:20:13,349
models cross integrate system
integration can be easily achieved.

347
00:20:13,849 --> 00:20:17,419
As we all know, things are moving towards
the cloud of majority of the cases

348
00:20:17,839 --> 00:20:22,999
as services and security can be very
helpful, this ecosystem, and it brings

349
00:20:22,999 --> 00:20:28,939
the ecosystem with the SAP Hana, MDG data
sphere and then cloud enables the A driven

350
00:20:28,939 --> 00:20:33,739
cognitive enables the A driven cognitive
towards scale to scale enterprise value.

351
00:20:34,239 --> 00:20:37,389
Speaking of the functionality and
benefits of a and ML thus far right

352
00:20:38,019 --> 00:20:41,649
now, how a business or a customer
can benefits out of this, right?

353
00:20:42,099 --> 00:20:45,369
Can or measure the success of
this one By bringing such tools.

354
00:20:45,609 --> 00:20:49,639
It's not just you implement the
tool the business or the customer

355
00:20:49,639 --> 00:20:51,349
has to benefit out of this, right?

356
00:20:51,799 --> 00:20:55,309
How do we measure the success based
on the implementation experience.

357
00:20:55,909 --> 00:20:59,999
In several industries such as the
metrics I have captured on the below,

358
00:21:00,389 --> 00:21:04,269
traditional data quality team, data
quality improvements, and the unique value

359
00:21:04,269 --> 00:21:06,159
proposition on the cogniti capabilities.

360
00:21:06,659 --> 00:21:09,089
Here are some of the KPIs
from the implementation, the.

361
00:21:09,589 --> 00:21:14,889
75 percentage of 75 percentage of
the cleansing effort can be achieved

362
00:21:14,889 --> 00:21:20,020
or reduced over the period by
increasing 95 percentage of clean data.

363
00:21:20,350 --> 00:21:20,680
Okay?

364
00:21:20,770 --> 00:21:25,370
When the data model matures, 90%
of the classification 90% of the

365
00:21:25,370 --> 00:21:29,075
classification of accuracy can be
achieved through the ML algorithms, right?

366
00:21:29,145 --> 00:21:33,440
Achieving with the high accuracy data,
as you all know, which is a very high for

367
00:21:33,500 --> 00:21:35,780
any data product, any data applications.

368
00:21:36,280 --> 00:21:41,260
60% of the time can be reduced by
implementing a cognitive MDM solutions.

369
00:21:41,290 --> 00:21:45,340
How this will be reduced when the user
ask them if there is any user they

370
00:21:45,340 --> 00:21:49,390
have to do a manual approach, finding
an anomaly or finding and predictive

371
00:21:49,390 --> 00:21:54,190
analysis on all those things where system
can do that with the 60% less of time,

372
00:21:54,690 --> 00:21:59,590
80% of the incident can be prevented by
well in advanced predictive analysis.

373
00:22:00,265 --> 00:22:01,375
These are very key.

374
00:22:01,475 --> 00:22:04,575
These are some of the key
things which I have learned from

375
00:22:04,605 --> 00:22:05,895
implementing such solutions.

376
00:22:06,395 --> 00:22:11,455
Again, AM is not a is not an A
MDM is not just a static, right?

377
00:22:11,680 --> 00:22:12,800
It has to be evolving.

378
00:22:12,860 --> 00:22:15,650
When the industry grows or the
compliance landscape grows,

379
00:22:15,680 --> 00:22:17,270
it has to grow appropriately.

380
00:22:18,140 --> 00:22:20,180
How do we implement the
future implications, right?

381
00:22:20,180 --> 00:22:22,070
How do we address the future implications?

382
00:22:22,790 --> 00:22:26,420
Looking ahead the future areas where
future implications can be considered

383
00:22:26,660 --> 00:22:28,130
implementing such things, right?

384
00:22:28,630 --> 00:22:30,340
There are some areas
which we need to focus on.

385
00:22:31,015 --> 00:22:34,045
Where autonomous governance
solution have has to be implemented.

386
00:22:34,545 --> 00:22:38,055
This can be a autonomous governance
solution can be a self-correcting data.

387
00:22:38,145 --> 00:22:42,985
With the quantum of quantum computing
integration where the data automatically

388
00:22:43,040 --> 00:22:46,550
corrects it, or create an incident
as in when needed, wherein there

389
00:22:46,580 --> 00:22:47,780
without a manual intervention.

390
00:22:48,740 --> 00:22:52,340
Industry specific implementation
can be a greater help, as we all

391
00:22:52,340 --> 00:22:58,120
know, such as healthcare, finance,
retail, oil and gas, or can be built.

392
00:22:58,630 --> 00:23:02,680
This can have, this can help
preventive or a reactive process.

393
00:23:03,180 --> 00:23:07,230
Implementing and implementing can
be a heavy, as we all know, right?

394
00:23:07,230 --> 00:23:08,430
It's not something small.

395
00:23:08,610 --> 00:23:14,130
And by supported regularities, these are
needed through a transparency ethics.

396
00:23:14,805 --> 00:23:17,705
And global Standard will be
adapted needed to be adapted.

397
00:23:17,915 --> 00:23:23,045
It can't be just lying by its own
or a or a, or individually managed.

398
00:23:23,075 --> 00:23:26,225
It has to be a global status,
standard, data standard to be

399
00:23:26,225 --> 00:23:28,625
established before you propose.

400
00:23:28,625 --> 00:23:32,395
I would suggest before you propose to
the change before you propose for any

401
00:23:32,395 --> 00:23:36,895
of this change, make sure that you bring
the organizational alignment in this.

402
00:23:37,810 --> 00:23:41,830
As these are the key when you
implement any MDM solutions, right?

403
00:23:42,160 --> 00:23:45,520
'cause you need to be defining
a new rules, new structure.

404
00:23:45,760 --> 00:23:47,470
And culturally they have to adapt.

405
00:23:47,970 --> 00:23:48,780
With this.

406
00:23:49,080 --> 00:23:51,780
With this, we can take a look
into the real time world.

407
00:23:51,900 --> 00:23:55,530
Examples where, how this
results can transpire or how

408
00:23:55,530 --> 00:23:59,180
this results can be achieved,
approved for the patients, right?

409
00:23:59,275 --> 00:24:00,115
You had to wait for that.

410
00:24:00,145 --> 00:24:03,025
How this can be evolved, how this
has been evolved from one to another.

411
00:24:03,525 --> 00:24:07,455
With the oil and gas, a global
retailer where I have implemented

412
00:24:07,515 --> 00:24:12,855
a and ML solutions, now 60% less
manual efforts are getting in ed.

413
00:24:13,695 --> 00:24:18,315
This has been implemented in very recent
past where right now data steward not

414
00:24:18,315 --> 00:24:19,965
spending much time on data collection.

415
00:24:20,465 --> 00:24:24,495
This not only just reduce the data
correction, it also improve the supply

416
00:24:24,495 --> 00:24:29,585
chain efficiency by 15% and in turn,
that does mean what improve the.

417
00:24:30,155 --> 00:24:33,245
Dollar value for you, saving
the dollar value for you, right?

418
00:24:34,145 --> 00:24:37,245
Some of the examples on a healthcare
industries, which is a very

419
00:24:37,245 --> 00:24:41,625
critical, the accuracy of the data
correction need to be very stringent.

420
00:24:42,075 --> 00:24:45,675
It cannot be just a point,
0.1 or two, cannot be done.

421
00:24:46,545 --> 00:24:50,775
Achieving this through a manual or
traditional MDM cannot be easy, right?

422
00:24:51,135 --> 00:24:52,785
Because it's a manual intense process.

423
00:24:52,815 --> 00:24:57,765
It has to be a reactive process, all those
things by implementing an a ML solution.

424
00:24:58,200 --> 00:25:01,830
95% or more passion
records has been improved.

425
00:25:02,760 --> 00:25:07,670
And then compliance has been very happy
addressing these solutions as well in the

426
00:25:07,670 --> 00:25:12,170
form, in the financial firm of financial
sectors, like a banking sector, right?

427
00:25:12,870 --> 00:25:16,320
70% of the onboarding a
customer can be has been.

428
00:25:17,175 --> 00:25:21,285
Okay, earlier, they have to start from
the Salesforce all the way to the lead, to

429
00:25:21,285 --> 00:25:23,515
the pursuit, to the creating a customer.

430
00:25:24,025 --> 00:25:28,055
Now with the vetting process and all
those process, it takes a longer duration.

431
00:25:28,555 --> 00:25:32,515
With implementing A-A-M-L-M-D-M
solutions, what it happens is it

432
00:25:32,515 --> 00:25:36,985
reduces this time and the fast,
but can happen within few minutes.

433
00:25:37,945 --> 00:25:42,625
So this revenue, this ha, helps a
revenue gain of about $5 million,

434
00:25:42,625 --> 00:25:43,915
which I have seen very recently.

435
00:25:44,415 --> 00:25:47,505
These cases can be
demonstrated in A and MDM.

436
00:25:47,555 --> 00:25:49,775
It's not just a theory, right?

437
00:25:49,895 --> 00:25:54,515
As I was explaining, it delivers a
tangible outcomes, as you all know

438
00:25:55,415 --> 00:26:01,475
right now since we talked about a
and ml advancements on in an SAP

439
00:26:01,475 --> 00:26:05,000
platform for a conversional for a
conversational governance, right?

440
00:26:05,500 --> 00:26:09,910
Subduction and a quantum inspired
optimization can be a pro, can be a

441
00:26:09,910 --> 00:26:13,710
helpful way in future organization
that can seamlessly integrate

442
00:26:13,770 --> 00:26:16,830
artificial intelligence into their
fundamental business process.

443
00:26:17,100 --> 00:26:22,080
Creates an adaptive and intelligent
business process and operations and

444
00:26:22,080 --> 00:26:24,480
respond to that incident immediately.

445
00:26:24,930 --> 00:26:28,980
And these challenges can be addressed
continuously, improving the performance.

446
00:26:29,480 --> 00:26:33,200
Creating a data incident today world,
creating a data incident, just not

447
00:26:33,260 --> 00:26:39,270
just it's not just stop by taking time,
it impacts through the cast and it is

448
00:26:39,330 --> 00:26:41,550
disrupting the other process as well.

449
00:26:42,390 --> 00:26:44,790
And traditional governance
can keep up with this one.

450
00:26:45,660 --> 00:26:50,100
The solution forward for this one is A
one MDM solution, then makes a governance,

451
00:26:50,520 --> 00:26:52,950
predictive, proactive, and adaptive.

452
00:26:53,450 --> 00:26:58,330
Real world results shows that implementing
a driven MDM shows a cost savings,

453
00:26:58,780 --> 00:27:01,390
compliance improvement, and agility gains.

454
00:27:01,890 --> 00:27:06,970
With this integration of a in, in an MDM
brings a transformation opportunity for

455
00:27:06,970 --> 00:27:12,340
organizations those seek to enhance their
incident management capabilities so that

456
00:27:12,340 --> 00:27:17,080
the incident management can be a very
immediate and very quick, they don't need

457
00:27:17,080 --> 00:27:18,470
to wait for a reactive process to happen.

458
00:27:19,375 --> 00:27:22,495
This will happen as based
on the preventative analysis

459
00:27:22,495 --> 00:27:23,785
or a time series entries.

460
00:27:23,845 --> 00:27:24,745
These can happen.

461
00:27:24,745 --> 00:27:27,565
The incidents can be
created very immediately.

462
00:27:27,655 --> 00:27:30,505
Whenever there is a, the system
understands that there is a

463
00:27:30,505 --> 00:27:32,095
process issue or the data issue.

464
00:27:32,905 --> 00:27:34,465
This clearly shows a paradigm.

465
00:27:34,465 --> 00:27:38,335
S shift evolves from the liability
of a strategic advantage.

466
00:27:38,835 --> 00:27:42,825
With that, I would like to thank you
spending your time with me for about

467
00:27:42,955 --> 00:27:45,265
on this journey of a MDM journey.

468
00:27:46,165 --> 00:27:46,675
Thank you everyone.

