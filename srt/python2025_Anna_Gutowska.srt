1
00:00:00,040 --> 00:00:00,819
Hi, everyone.

2
00:00:00,900 --> 00:00:01,970
My name is Anna.

3
00:00:02,000 --> 00:00:06,230
I'm a data scientist working
in developer advocacy at IBM.

4
00:00:06,560 --> 00:00:11,040
I'm super excited to talk to you today
a bit about AI agents and how they're

5
00:00:11,040 --> 00:00:14,340
reshaping the future of AI as we speak.

6
00:00:15,000 --> 00:00:19,880
So it goes without saying, over the
last few years, AI has transcended

7
00:00:19,889 --> 00:00:22,169
across almost every industry.

8
00:00:22,680 --> 00:00:28,349
From customer service, healthcare, and
even agriculture, AI is reshaping the way

9
00:00:28,349 --> 00:00:31,200
we work and the way we think about work.

10
00:00:32,049 --> 00:00:36,030
I'm sure many of us have used
a large language model and been

11
00:00:36,030 --> 00:00:38,010
disappointed by its responses.

12
00:00:38,739 --> 00:00:44,290
So why is it that some large language
models are able to successfully complete

13
00:00:44,340 --> 00:00:50,670
complex tasks like writing JavaScript
code, for example, but can't answer simple

14
00:00:50,670 --> 00:00:53,660
questions like, what is today's date?

15
00:00:54,160 --> 00:00:58,709
The answer to filling these
information gaps lies in AI agents.

16
00:00:59,655 --> 00:01:02,185
So what exactly is an AI agent?

17
00:01:03,155 --> 00:01:08,315
An AI agent refers to a system or
program that's capable of autonomously

18
00:01:08,315 --> 00:01:13,905
performing tasks on behalf of a user
or another system by designing its

19
00:01:13,914 --> 00:01:16,394
workflow and using available tools.

20
00:01:17,275 --> 00:01:20,634
So what makes them any different
than a traditional AI assistant

21
00:01:20,764 --> 00:01:22,375
like we've used in the past?

22
00:01:22,925 --> 00:01:28,074
traditional LLMs, like IBM's Granite
models, Meta's Llama models, or

23
00:01:28,075 --> 00:01:32,925
Google's Gemma models, just to name
a few, produce their responses based

24
00:01:32,934 --> 00:01:34,664
on the data used to train them.

25
00:01:34,994 --> 00:01:38,404
And they're bounded by knowledge
and reasoning limitations.

26
00:01:39,244 --> 00:01:43,225
Hence, why an LLM is unable to
provide us with today's date.

27
00:01:43,605 --> 00:01:46,505
It can't access information
it wasn't trained on.

28
00:01:47,419 --> 00:01:51,859
In contrast, Agentech technology
is modular, and it's easier to

29
00:01:51,889 --> 00:01:54,029
adapt to personalized tasks.

30
00:01:54,850 --> 00:01:59,670
Without the need for human intervention,
tool calling is used on the backend

31
00:01:59,989 --> 00:02:06,500
to obtain up to date information,
optimize workflow, and create subtasks

32
00:02:06,500 --> 00:02:08,289
autonomously to achieve complex goals.

33
00:02:09,170 --> 00:02:12,740
In this process, the autonomous
agent learns to adapt to

34
00:02:12,740 --> 00:02:14,749
user expectations over time.

35
00:02:15,695 --> 00:02:21,015
And the agent's ability to store past
interactions in memory and plan future

36
00:02:21,015 --> 00:02:26,825
actions encourages a personalized
experience and comprehensive responses.

37
00:02:27,325 --> 00:02:30,794
This process can be broken
down into three stages.

38
00:02:31,304 --> 00:02:34,434
First there's goal
initialization and planning.

39
00:02:35,154 --> 00:02:39,374
This is where the agent takes in
a user query, extracts the main

40
00:02:39,374 --> 00:02:43,714
goal, and creates a plan of subtasks
in order to reach that goal.

41
00:02:44,214 --> 00:02:46,084
Next, there's tool calling.

42
00:02:46,584 --> 00:02:51,594
In which the AI agent uses its available
tools to fill any information gaps

43
00:02:51,644 --> 00:02:54,124
in the LLM's pre trained knowledge.

44
00:02:54,614 --> 00:03:01,344
These tools can include external datasets,
web searches, APIs, and even other agents.

45
00:03:02,204 --> 00:03:05,654
After the missing information is
retrieved from these tools, the

46
00:03:05,654 --> 00:03:07,714
agent can update its knowledge base.

47
00:03:08,504 --> 00:03:13,049
This means that each step of the
way, The agent reassesses its

48
00:03:13,089 --> 00:03:15,639
plan of action and self corrects.

49
00:03:16,139 --> 00:03:21,009
We have the flexibility to either
create custom tools for our AI agents,

50
00:03:21,564 --> 00:03:26,324
Or use pre built tools like the ones
already available through LangChain.

51
00:03:27,124 --> 00:03:30,594
For anyone unfamiliar with
LangChain, it's an open source

52
00:03:30,654 --> 00:03:32,594
LLM orchestration framework.

53
00:03:33,174 --> 00:03:37,554
Additionally, LangGraph is built on
top of LangChain, and it's a framework

54
00:03:37,554 --> 00:03:39,724
specific to agentic workflows.

55
00:03:40,364 --> 00:03:44,774
It's a specialized library
within the LangChain ecosystem.

56
00:03:45,394 --> 00:03:48,024
And we'll be using both
in the upcoming demo.

57
00:03:48,524 --> 00:03:53,634
The tools available through LangChain
are vast and they include functionality

58
00:03:53,644 --> 00:04:00,164
for search, web browsing, code
interpretation, productivity, database

59
00:04:00,164 --> 00:04:02,254
management, and much, much more.

60
00:04:02,754 --> 00:04:06,945
Lastly, the final stage is
learning and reflection.

61
00:04:07,825 --> 00:04:12,285
This is where an AI agent uses
feedback mechanisms such as other

62
00:04:12,305 --> 00:04:18,585
AI agents or a human in the loop to
improve the accuracy of its responses.

63
00:04:19,324 --> 00:04:23,465
Feedback mechanisms improve the
AI agent's reasoning and accuracy,

64
00:04:23,655 --> 00:04:27,265
and this is commonly referred
to as iterative refinement.

65
00:04:27,765 --> 00:04:33,625
To avoid repeating the same mistakes, AI
agents can also store data about solutions

66
00:04:33,625 --> 00:04:36,174
to previous obstacles in a knowledge base.

67
00:04:36,674 --> 00:04:39,985
Alright, now let's bring
in some real world data.

68
00:04:40,585 --> 00:04:45,565
As seen by a recent survey of
AI developers, a whopping 99

69
00:04:45,565 --> 00:04:50,724
percent of them are exploring and
developing use cases for AI agents.

70
00:04:51,614 --> 00:04:56,344
Clearly, this is a major topic
with lots of growth potential.

71
00:04:56,844 --> 00:05:02,075
Now let's apply this preliminary AI
agent knowledge to an example that

72
00:05:02,075 --> 00:05:04,815
is applicable to many of us today.

73
00:05:05,315 --> 00:05:10,044
Let's say we want to plan a vacation
and we're unsure about the number of

74
00:05:10,044 --> 00:05:12,424
our remaining vacation days at work.

75
00:05:13,294 --> 00:05:19,044
If I were to ask an LLM this user query,
How many vacation days do I have left?

76
00:05:19,594 --> 00:05:24,094
The LLM would either hallucinate or
simply return a response that indicates

77
00:05:24,104 --> 00:05:26,464
it can't provide me with this information.

78
00:05:26,964 --> 00:05:32,904
Not only does the LLM not know who I am
and where I work, but it also doesn't

79
00:05:32,904 --> 00:05:34,874
have the ability to figure that out.

80
00:05:35,654 --> 00:05:41,374
Whereas, if we were to provide the LLM
with a tool that searches a database of

81
00:05:41,374 --> 00:05:47,124
vacation days for each employee, along
with the same user query, an AI agent

82
00:05:47,154 --> 00:05:51,214
would be able to provide us with exactly
the information that we're looking for.

83
00:05:52,054 --> 00:05:56,874
This is a simple example of the
significance of agentic systems.

84
00:05:57,614 --> 00:06:03,064
Of course, as with most things in
AI, we can make this more convoluted

85
00:06:03,444 --> 00:06:05,754
through the use of reasoning paradigms.

86
00:06:06,254 --> 00:06:10,874
There are several reasoning paradigms out
there, but the one most commonly used is

87
00:06:10,884 --> 00:06:14,194
React, short for reasoning and action.

88
00:06:14,634 --> 00:06:19,264
And it's not to be confused with the JS
framework, as I've learned once before.

89
00:06:19,764 --> 00:06:24,234
Essentially, with React, we're
controlling the logic of a compound AI

90
00:06:24,244 --> 00:06:27,514
system by putting the LLM in charge.

91
00:06:28,074 --> 00:06:32,984
In other words, we're designing
the system to think slow, readjust,

92
00:06:33,055 --> 00:06:39,994
As seen in this diagram, the agent
begins with a user query from which it

93
00:06:39,994 --> 00:06:45,284
extracts the main goal, as well as any
subtasks that goal is dependent on.

94
00:06:45,874 --> 00:06:49,224
Then, the agent checks its
tools and determines the

95
00:06:49,224 --> 00:06:51,614
appropriate ones for each subtask.

96
00:06:52,174 --> 00:06:56,474
It then executes the subtasks
and finally provides an output.

97
00:06:56,544 --> 00:06:59,304
The process doesn't end there, however.

98
00:06:59,549 --> 00:07:03,729
Instead, the agent determines
whether the output is satisfactory.

99
00:07:04,289 --> 00:07:08,299
If not, the agent adjusts
and the process is repeated.

100
00:07:08,959 --> 00:07:12,609
Otherwise, the agent returns the
synthesized response to the user.

101
00:07:13,109 --> 00:07:17,309
And so this encapsulates the end
to end process an AI agent goes

102
00:07:17,309 --> 00:07:21,979
through to produce responses
to user queries using React.

103
00:07:22,979 --> 00:07:24,769
don't AI agents seem great?

104
00:07:25,449 --> 00:07:29,249
what if I told you that they're
more powerful when working together?

105
00:07:29,749 --> 00:07:34,629
That's right, multi agent systems
tend to outperform singular agents.

106
00:07:35,179 --> 00:07:40,269
There is strength in numbers due to
the larger pool of shared resources,

107
00:07:40,689 --> 00:07:43,099
optimization, and automation.

108
00:07:43,829 --> 00:07:48,359
Instead of multiple agents learning
the same policies, one agent can

109
00:07:48,359 --> 00:07:51,919
share its learned experiences
with the rest to optimize both

110
00:07:51,959 --> 00:07:54,029
time complexity and efficiency.

111
00:07:54,529 --> 00:07:59,889
In a multi agent system, agents remain
autonomous, but they also cooperate

112
00:07:59,889 --> 00:08:02,289
and coordinate in agent structures.

113
00:08:02,879 --> 00:08:07,859
And each agent within a multi agent
system has individual properties, but

114
00:08:07,929 --> 00:08:13,289
all agents behave collaboratively to
lead to desired global properties.

115
00:08:14,199 --> 00:08:19,519
Multi agent systems are particularly
valuable in completing large scale,

116
00:08:19,529 --> 00:08:24,469
complex tasks that can encompass
hundreds if not thousands of agents.

117
00:08:24,969 --> 00:08:29,119
Multi agent systems can operate
under various architectures.

118
00:08:29,669 --> 00:08:34,929
In centralized networks, a central unit
contains the global knowledge base.

119
00:08:35,429 --> 00:08:39,209
It also connects the agents
and oversees their information.

120
00:08:40,009 --> 00:08:43,749
Some strengths of the structure are
the ease of communication between

121
00:08:43,749 --> 00:08:48,879
agents and uniform knowledge, and
a weakness of the centrality is

122
00:08:48,879 --> 00:08:50,719
the dependence on the central unit.

123
00:08:51,374 --> 00:08:55,104
If it fails, the entire
system of agents fails.

124
00:08:55,974 --> 00:09:01,334
Whereas in decentralized networks, agents
share information with their neighboring

125
00:09:01,334 --> 00:09:04,194
agents instead of a global knowledge base.

126
00:09:04,984 --> 00:09:09,034
And so some benefits of this
are robustness and modularity.

127
00:09:09,034 --> 00:09:13,114
The failure of one agent doesn't
cause the overall system to fail

128
00:09:13,134 --> 00:09:14,784
since there's no central unit.

129
00:09:15,584 --> 00:09:18,424
And one challenge of decentralized agents.

130
00:09:18,784 --> 00:09:23,814
is coordinating agent behavior to
benefit other cooperating agents.

131
00:09:24,314 --> 00:09:28,114
Multi agent systems also
come with their pros and cons

132
00:09:28,124 --> 00:09:30,304
regardless of system structure.

133
00:09:30,914 --> 00:09:32,834
Firstly, they're quite flexible.

134
00:09:33,224 --> 00:09:37,434
We can adjust the system by removing
and adding agents as needed,

135
00:09:37,974 --> 00:09:39,324
which ties into their scalability.

136
00:09:40,099 --> 00:09:44,479
As we can tackle much more complex
goals than a singular agent could.

137
00:09:45,179 --> 00:09:48,519
And each agent comes with its
own domain specialization.

138
00:09:48,639 --> 00:09:51,819
So agents are not relearning
the same information.

139
00:09:52,239 --> 00:09:55,759
Instead, they're collaborating
by sharing information.

140
00:09:56,259 --> 00:09:59,759
In turn, the greater the number
of agents, the greater the chances

141
00:09:59,769 --> 00:10:01,739
are of an agent malfunction.

142
00:10:02,639 --> 00:10:06,199
And the harder it can be to
coordinate each agent to benefit

143
00:10:06,229 --> 00:10:07,919
other cooperating agents.

144
00:10:08,779 --> 00:10:13,049
Since multi agent systems involve
dependencies between agents for

145
00:10:13,059 --> 00:10:18,519
accomplishing subtasks, this means we may
also encounter unpredictable behavior.

146
00:10:19,439 --> 00:10:24,079
This behavior can be due to
infinite feedback loops, changes

147
00:10:24,079 --> 00:10:28,989
in access to certain tools, or
malfunctioning due to design flaws.

148
00:10:29,709 --> 00:10:33,129
And we can mitigate this risk
by incorporating means of

149
00:10:33,129 --> 00:10:37,519
system interruption, human
supervision, and feedback.

150
00:10:38,069 --> 00:10:41,079
This is especially important
when working with sensitive data.

151
00:10:41,579 --> 00:10:46,079
Okay, so given all of this information,
you may still be wondering, why should

152
00:10:46,079 --> 00:10:48,879
I care, and how does this apply to me?

153
00:10:49,839 --> 00:10:54,829
here are just a few of the incredible
ways in which AI agents and multi agent

154
00:10:54,849 --> 00:11:01,399
systems can help us as humans to allocate
our time to more nuanced and critical

155
00:11:01,399 --> 00:11:04,369
tasks that can't be easily automated.

156
00:11:05,279 --> 00:11:10,539
Probably the most common use case of
AI agents today is the integration

157
00:11:10,559 --> 00:11:15,539
into websites and apps to enhance
the customer experience, whether

158
00:11:15,539 --> 00:11:19,399
it's serving as virtual assistants,
providing mental health support,

159
00:11:19,739 --> 00:11:21,919
simulating interviews, and much more.

160
00:11:22,879 --> 00:11:27,409
In healthcare, AI agents have the
potential to alleviate the workload of

161
00:11:27,429 --> 00:11:32,669
medical professionals by overseeing drug
processes and drafting treatment plans.

162
00:11:32,669 --> 00:11:38,174
For Thus allowing their time to be
spent on urgent, hands on tasks.

163
00:11:38,674 --> 00:11:42,634
Additionally, AI agents can
also optimize rescue operations,

164
00:11:42,634 --> 00:11:45,074
in times of natural disasters.

165
00:11:45,454 --> 00:11:48,454
They can do this, by locating
those in need of rescue,

166
00:11:48,474 --> 00:11:50,244
using tools like social media!

167
00:11:50,744 --> 00:11:55,365
Lastly, multi agent system can be a
powerful tool for managing complex

168
00:11:55,365 --> 00:12:00,434
transportation systems, like railroad
systems, truck assignments, or marine

169
00:12:00,435 --> 00:12:02,114
vessels visiting the same ports.

170
00:12:02,614 --> 00:12:07,324
Now having said this, by no means
am I saying AI agents in their

171
00:12:07,324 --> 00:12:12,574
current state can be 100 percent
trusted with these listed use cases.

172
00:12:13,094 --> 00:12:17,384
Agents applied to these use cases
should be under significant supervision

173
00:12:17,754 --> 00:12:21,464
and should undergo thorough testing
before being fully implemented.

174
00:12:22,304 --> 00:12:26,774
Regardless of this, I think we're
at such a pivotal time, of agentic

175
00:12:26,894 --> 00:12:31,254
AI that it's important to put
its capabilities in perspective.

176
00:12:31,754 --> 00:12:36,594
If we look at the current trends of how
enterprise AI developers are using AI

177
00:12:36,594 --> 00:12:41,444
agents, we see that about half of them
are using them for customer service and

178
00:12:41,444 --> 00:12:47,569
support, followed by project management,
serving as a personal assistant, And

179
00:12:47,589 --> 00:12:54,869
content creation, HR, transportation,
healthcare, and only 1 percent of

180
00:12:54,869 --> 00:13:01,379
developers in AI are not currently
exploring or developing AI AJA use cases.

181
00:13:01,879 --> 00:13:05,999
Now that we've established the
foundational understanding of AI agents

182
00:13:06,029 --> 00:13:10,899
and we've seen some real world data
about their significance, let's demo how

183
00:13:10,899 --> 00:13:13,399
to build an AI agent using LangGraph.

184
00:13:13,829 --> 00:13:18,649
We'll use pre built Lang chain
tools for a React agent to showcase

185
00:13:18,649 --> 00:13:23,019
its ability to differentiate
appropriate applications of each tool.

186
00:13:23,519 --> 00:13:29,189
The code that I will share with you is
available on GitHub, as well as on IBM.

187
00:13:29,219 --> 00:13:33,459
com, and I'll include the links to
both at the end of this presentation

188
00:13:33,459 --> 00:13:37,749
if you'd like to run the project on
your own time and experiment with it.

189
00:13:38,229 --> 00:13:39,939
so okay, let's jump right into it.

190
00:13:40,439 --> 00:13:46,049
Alrighty, so since we've covered the
basics of what an AI agent is and how tool

191
00:13:46,049 --> 00:13:51,549
calling works, we can go ahead and take a
look at our prerequisites for this demo.

192
00:13:51,989 --> 00:13:57,059
So there is one, you will need an
IBM cloud account, and keep in mind

193
00:13:57,059 --> 00:14:01,789
there are hyperlinks throughout this
entire demo, so you can go into either

194
00:14:01,789 --> 00:14:04,729
the github repository or the ibm.

195
00:14:04,779 --> 00:14:07,259
com page and, follow along there.

196
00:14:07,919 --> 00:14:13,359
So once you have created an IBM Cloud
account, you can then log in to watsonx.

197
00:14:13,419 --> 00:14:13,959
ai.

198
00:14:14,494 --> 00:14:16,104
Which is in step one.

199
00:14:16,604 --> 00:14:18,974
There you can create a watsonx.

200
00:14:19,034 --> 00:14:26,234
ai project and Make a note of your project
id which we'll need for this demo And

201
00:14:26,234 --> 00:14:32,069
finally you can either create a jupyter
notebook from scratch Or you can import

202
00:14:32,079 --> 00:14:34,399
an already existing Jupyter notebook.

203
00:14:34,399 --> 00:14:39,309
So if you want to go ahead and
download this one from the GitHub

204
00:14:39,319 --> 00:14:40,929
it, directly to what's next.

205
00:14:41,119 --> 00:14:43,499
ai, that is also an option.

206
00:14:43,999 --> 00:14:49,009
Moving along to step number two,
we will set up a what's next.

207
00:14:49,009 --> 00:14:52,179
ai runtime instance and API key.

208
00:14:52,679 --> 00:14:56,959
So you can create a free
instance, choosing the light blue.

209
00:14:57,044 --> 00:14:57,865
plan of WatsonX.

210
00:14:57,865 --> 00:14:59,534
ai runtime.

211
00:15:00,034 --> 00:15:02,124
There you can generate an API key.

212
00:15:03,034 --> 00:15:07,424
And finally, you can associate the
runtime instance to the project

213
00:15:07,424 --> 00:15:09,764
that you just created in step one.

214
00:15:10,264 --> 00:15:14,484
Once we have all these preliminary
steps completed, we can go ahead and

215
00:15:14,494 --> 00:15:19,364
install and import relevant libraries,
as well as set up our credentials.

216
00:15:19,864 --> 00:15:22,284
I've already installed these libraries.

217
00:15:22,324 --> 00:15:27,104
I won't rerun this cell, but I just
want you to see that we've imported

218
00:15:27,574 --> 00:15:32,244
all of the necessary libraries and
modules that we'll need, as well as, we

219
00:15:32,244 --> 00:15:34,164
have loaded our environment variables.

220
00:15:34,174 --> 00:15:36,904
there are several ways of setting
up your environment variables.

221
00:15:37,404 --> 00:15:41,434
My personal preference is
to use a separate env file.

222
00:15:41,844 --> 00:15:44,704
that is what I have done here, using OS.

223
00:15:45,204 --> 00:15:48,894
Here we can also set up our
credentials for the What's Next API,

224
00:15:48,894 --> 00:15:54,514
so that is our API key, our project
ID, as well as the API endpoint.

225
00:15:54,814 --> 00:15:59,734
Your endpoint will be specific to
your region, so please reference the

226
00:15:59,734 --> 00:16:03,744
documentation to make sure you're
using the correct endpoint, otherwise

227
00:16:03,754 --> 00:16:06,594
you will have a hard time connecting.

228
00:16:07,094 --> 00:16:12,254
We can also set up our open weather
API key, Which you can generate by

229
00:16:12,264 --> 00:16:16,514
creating an OpenWeather account,
and all of this is free to create.

230
00:16:16,864 --> 00:16:22,474
We will be using this API in a
later step for a link chain tool.

231
00:16:22,974 --> 00:16:27,074
In step four, we can go
ahead and initialize our LLM.

232
00:16:27,494 --> 00:16:30,928
So in this tutorial, we'll
be using the IBM Granite 3.

233
00:16:30,928 --> 00:16:33,604
1 8B Instruct model.

234
00:16:34,104 --> 00:16:38,374
And I will be setting it up
using the chat Watson X wrapper

235
00:16:38,414 --> 00:16:40,004
available through lang chain.

236
00:16:40,414 --> 00:16:41,904
And this wrapper is pretty neat.

237
00:16:41,924 --> 00:16:45,264
It allows us to integrate
tool calling and chaining.

238
00:16:45,764 --> 00:16:50,144
And to initialize the LLM, I'll set
the model parameters here as well.

239
00:16:50,644 --> 00:16:54,644
One thing to point out here is I
set the temperature to zero to limit

240
00:16:55,034 --> 00:17:00,784
the amount of agent hallucinations
and overall LLM creativity.

241
00:17:01,284 --> 00:17:04,594
Moving right along, we can
establish the built in tools.

242
00:17:04,934 --> 00:17:09,194
So to do we will use the tool
class available through LangChain.

243
00:17:09,714 --> 00:17:14,004
And the first tool that we'll set
up is the OpenWeatherMap tool.

244
00:17:14,514 --> 00:17:18,704
So this uses that API key that
we set up in an earlier step.

245
00:17:19,419 --> 00:17:25,059
And when I set up these tools, I provide
a name for the tool, a description,

246
00:17:25,489 --> 00:17:30,689
and overall, the function that is
meant to be run when calling each tool.

247
00:17:31,189 --> 00:17:34,259
The next tool we'll set up
is the YouTube search tool.

248
00:17:34,759 --> 00:17:36,329
Pretty self explanatory.

249
00:17:36,929 --> 00:17:42,149
It'll return YouTube links to
videos relevant to the user query.

250
00:17:43,019 --> 00:17:44,384
And finally, we can set up a password.

251
00:17:44,524 --> 00:17:47,494
a online shopping tool which uses Ionic.

252
00:17:47,894 --> 00:17:49,904
This is also available through LangChain.

253
00:17:50,354 --> 00:17:55,204
And this is essentially an e commerce
marketplace tool that returns search

254
00:17:55,204 --> 00:17:57,604
results relevant to your user query.

255
00:17:58,144 --> 00:18:02,244
I'll explain a bit more about the
search parameters in a later step.

256
00:18:02,744 --> 00:18:06,284
So now that we have our tools
defined, we can put them into a

257
00:18:06,284 --> 00:18:09,144
list and simply call the list tools.

258
00:18:09,644 --> 00:18:11,464
And here we see how the tool is loaded.

259
00:18:11,939 --> 00:18:18,499
We see their names, their descriptions,
the functions, as well as any API keys.

260
00:18:18,999 --> 00:18:23,139
So now for step six, we will actually
get to implement some tool calling.

261
00:18:23,679 --> 00:18:27,989
And before we jump into creating
an AI agent, I first want to see

262
00:18:27,989 --> 00:18:34,929
how the LLM performs, simply being
provided a user query and its tools.

263
00:18:35,379 --> 00:18:40,189
So we will use the bind tools method
available through link chain, and we

264
00:18:40,189 --> 00:18:46,019
will invoke a user query asking what
are some YouTube videos about Greece?

265
00:18:46,519 --> 00:18:46,809
Okay.

266
00:18:46,829 --> 00:18:51,809
Just to print the response,
additional arguments.

267
00:18:51,859 --> 00:18:54,319
so just to see a little
better what's going on here.

268
00:18:54,689 --> 00:19:00,589
We can see that the function YouTube
search was appropriately selected from

269
00:19:00,589 --> 00:19:06,569
the tool base, and that the argument
of Greece was also successfully

270
00:19:06,649 --> 00:19:08,219
extracted from the user query.

271
00:19:08,639 --> 00:19:13,229
But as you can see here, the actual
tool response is not returned.

272
00:19:13,569 --> 00:19:16,219
That's because we're not
creating an agentic system.

273
00:19:16,229 --> 00:19:19,649
This is simply the LLM with its tools.

274
00:19:19,959 --> 00:19:26,459
moving right along, we can actually create
the React agent using the createReactAgent

275
00:19:26,869 --> 00:19:29,429
method available through LangGraph.

276
00:19:30,409 --> 00:19:34,729
And so as we've discussed, I
won't go too into depth again.

277
00:19:35,079 --> 00:19:41,279
But just to refresh our memory, the
user provides a user query to the LLM.

278
00:19:41,939 --> 00:19:44,359
In our case, this will be a React agent.

279
00:19:44,929 --> 00:19:49,449
The agent then assesses its tool base
and determines the appropriate tools for

280
00:19:49,469 --> 00:19:52,369
each subtask within its broader goal.

281
00:19:53,329 --> 00:19:57,309
Finally, once it collects all of
the tool messages, it formulates a

282
00:19:57,319 --> 00:20:04,109
synthesized response to the user, and
if successful, the process ends there.

283
00:20:04,509 --> 00:20:08,949
If the user is not satisfied with
the results, the process repeats.

284
00:20:09,449 --> 00:20:12,839
So let's go ahead and
initialize our React agent.

285
00:20:13,339 --> 00:20:15,509
Super simple, super clean method.

286
00:20:16,009 --> 00:20:20,419
Okay, so now that we've set up our
agent, let's ask the same user query.

287
00:20:20,439 --> 00:20:23,119
What are some YouTube videos about Greece?

288
00:20:23,619 --> 00:20:24,159
Awesome.

289
00:20:24,169 --> 00:20:28,469
So as you can see, we have the
human message, which contains

290
00:20:28,489 --> 00:20:30,269
our initial user query.

291
00:20:30,579 --> 00:20:36,269
We also have the AI message, which is
The one that you previously saw with

292
00:20:36,309 --> 00:20:39,429
the LLM and the buying tools method.

293
00:20:39,919 --> 00:20:44,429
But the interesting part here is that
our AI agent actually calls the tool,

294
00:20:44,459 --> 00:20:46,489
as you can see by the tool message.

295
00:20:47,029 --> 00:20:50,449
And so once it receives that
tool response, it's able to

296
00:20:50,459 --> 00:20:52,289
formulate a synthesized response.

297
00:20:52,819 --> 00:20:55,269
So here it is within the AI message.

298
00:20:55,269 --> 00:20:59,519
We see the message says, here are
some YouTube videos about grace.

299
00:20:59,859 --> 00:21:01,919
We have the YouTube video title.

300
00:21:02,144 --> 00:21:03,644
Along with the URL.

301
00:21:04,264 --> 00:21:06,934
And here we have two URLs.

302
00:21:07,434 --> 00:21:07,854
Wonderful.

303
00:21:08,329 --> 00:21:13,469
Okay, so now we can move on to testing
whether the AI agent will know when to

304
00:21:13,469 --> 00:21:17,549
use tools for non YouTube related queries.

305
00:21:17,789 --> 00:21:20,089
So let's ask a weather related question.

306
00:21:20,359 --> 00:21:23,209
What is the weather in Athens, Greece?

307
00:21:23,709 --> 00:21:25,479
Okay, let's see what we have here.

308
00:21:25,509 --> 00:21:30,139
In the human message, we
see our initial user input.

309
00:21:30,429 --> 00:21:35,059
In the AI message, we see that the weather
search tool was selected appropriately,

310
00:21:35,379 --> 00:21:41,524
and that the argument of Athens And
Greece was also extracted correctly.

311
00:21:42,044 --> 00:21:46,284
Then in the tool message, we see a
thorough description of the weather

312
00:21:46,294 --> 00:21:51,924
in Athens, Greece, retrieved from the
weather tool, and finally in the AI

313
00:21:51,974 --> 00:21:57,594
message, we see a synthesized response
that lets us know the temperature, as

314
00:21:57,594 --> 00:21:59,794
well as the wind speed and humidity.

315
00:22:00,104 --> 00:22:05,704
And whether there's any rain and
the cloud cover in Athens, Greece.

316
00:22:06,204 --> 00:22:12,084
Okay, so finally, let's test whether
the agent will know to use the e

317
00:22:12,084 --> 00:22:16,824
commerce marketplace search tool
when provided with this user query.

318
00:22:17,344 --> 00:22:22,144
We will ask the agent to find some
suitcases for less than 10, 000 cents.

319
00:22:22,544 --> 00:22:27,194
You might be wondering why I'm
using US cents instead of dollars.

320
00:22:27,784 --> 00:22:30,974
So that's one thing to keep in mind
when using the Ionic search tool.

321
00:22:30,974 --> 00:22:33,294
It actually uses cents and not dollars.

322
00:22:33,744 --> 00:22:37,664
And so the equivalent of
10, 000 cents would be 100.

323
00:22:37,994 --> 00:22:40,924
So just keep that in mind when
running your user queries.

324
00:22:41,624 --> 00:22:43,874
And we can go ahead and run this now.

325
00:22:44,374 --> 00:22:45,944
We have our human message.

326
00:22:45,944 --> 00:22:50,894
We then have our AI message where
we see that the Ionic commerce

327
00:22:50,894 --> 00:22:55,814
shopping tool was correctly selected
and that the argument of suitcases

328
00:22:55,874 --> 00:23:00,574
under 10, 000 cents, those arguments
were also successfully extracted.

329
00:23:01,474 --> 00:23:05,904
So then within our tool message,
we should see suitcases under.

330
00:23:06,659 --> 00:23:07,259
100.

331
00:23:07,299 --> 00:23:11,399
And we can verify this within
our synthesized AI message.

332
00:23:11,669 --> 00:23:15,729
So we see here are some
suitcases under 10, 000 cents.

333
00:23:16,189 --> 00:23:21,279
The first response is a
suitcase at the price of 80.

334
00:23:21,849 --> 00:23:26,949
The next one is a suitcase that costs 34.

335
00:23:27,349 --> 00:23:30,759
So as you can see, these
suitcases fit our criteria.

336
00:23:30,919 --> 00:23:33,799
We have the synthesized
response that we're looking for.

337
00:23:33,979 --> 00:23:37,829
So there's definitely a lot of room here
for creativity and to have fun with this.

338
00:23:37,839 --> 00:23:41,899
So feel free to test out different
user queries on your own time.

339
00:23:42,369 --> 00:23:43,049
And.

340
00:23:43,169 --> 00:23:44,189
Yes, this is it!

341
00:23:44,209 --> 00:23:48,479
This is how you create an AI agent
using LangChain and LangGraph.

342
00:23:48,879 --> 00:23:55,049
So to recap, we created a React
agent in Python using the WatsonX

343
00:23:55,109 --> 00:23:58,719
API, and we used the Granite 3.

344
00:23:58,799 --> 00:24:00,309
1 8 bit instruct model.

345
00:24:00,974 --> 00:24:06,264
We also use the YouTube weather and online
shopping tools available through link

346
00:24:06,274 --> 00:24:11,804
chain and we were able to successfully
receive the output we were looking for.

347
00:24:12,104 --> 00:24:17,484
So I hope that this was fruitful
and I hope you enjoy running your

348
00:24:17,484 --> 00:24:20,084
own user queries on your own time.

349
00:24:20,994 --> 00:24:22,594
Thank you for joining me today.

