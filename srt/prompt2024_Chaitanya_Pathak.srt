1
00:00:00,500 --> 00:00:01,080
Hello, everyone.

2
00:00:02,050 --> 00:00:03,320
My name is Chetan Nepatak.

3
00:00:03,969 --> 00:00:06,320
I am currently working as a
Chief Producting Technology

4
00:00:06,320 --> 00:00:07,899
Officer for Analytica Data Labs.

5
00:00:08,400 --> 00:00:14,149
In today's session, I intend to spend
25 to 30 minutes talking through some

6
00:00:14,149 --> 00:00:18,649
of the Gen AI abilities that we've been
building in our product LEAPS, which is

7
00:00:18,679 --> 00:00:20,209
essentially a low code, no code platform.

8
00:00:20,445 --> 00:00:23,675
and I'll give a bit more context
about that in, in just a few minutes.

9
00:00:24,205 --> 00:00:28,195
but before I get started, a little bit of,
background and introduction about myself.

10
00:00:28,755 --> 00:00:33,085
I have been, working in the
space of, AI, ML deep learning

11
00:00:33,115 --> 00:00:34,665
for the last, 12 years now.

12
00:00:35,305 --> 00:00:38,375
by, By education, I'm,
I've done two masters.

13
00:00:38,425 --> 00:00:43,275
I'm a MBA from me and PC Paris,
and also, master's in advanced

14
00:00:43,275 --> 00:00:45,255
computer science with focus on, AI.

15
00:00:45,975 --> 00:00:50,805
I started off with computer vision,
and, went on to build, a deal models in,

16
00:00:50,845 --> 00:00:53,155
predicting, in price prediction engines.

17
00:00:53,835 --> 00:00:58,475
and then a few other models around, in the
fintech space, which were really about,

18
00:00:58,515 --> 00:01:04,285
doing, evaluations using machine learning
models for, both insurance and loans.

19
00:01:04,825 --> 00:01:07,475
and then the last, one and a half,
two years, been working on the

20
00:01:07,475 --> 00:01:10,315
product to build in, generative
abilities, and that's been the

21
00:01:10,315 --> 00:01:11,955
focus for the last 18 months or so.

22
00:01:12,590 --> 00:01:17,150
and my today's discussion will
revolve around one of the products

23
00:01:17,150 --> 00:01:22,240
that we have built and rolled out,
which is both stable and it's scaling

24
00:01:22,240 --> 00:01:24,990
rapidly, and one of the abilities.

25
00:01:25,050 --> 00:01:29,140
and I will talk through some of
our experiences there, and some

26
00:01:29,140 --> 00:01:33,610
of the best practices that we have
seen that has worked for us as we

27
00:01:33,610 --> 00:01:35,780
moved along from POC to production.

28
00:01:36,230 --> 00:01:39,730
which is, a very apt, topic
for, for discussion, today.

29
00:01:40,230 --> 00:01:43,310
So moving on, four essential
talking points today.

30
00:01:43,350 --> 00:01:47,600
I'll start off by giving the context
of the app, and then I'll move on to,

31
00:01:47,630 --> 00:01:51,850
talk about the various components that
go into, the, the app architecture

32
00:01:51,970 --> 00:01:53,370
or the abilities architecture.

33
00:01:54,020 --> 00:01:58,130
and then a little bit of, discussion on
prompts and rank, rank, and then finally,

34
00:01:58,180 --> 00:02:02,020
quick note on what's coming next and what
the things that we're working on next.

35
00:02:02,790 --> 00:02:07,300
so that's, the agenda, for this
discussion, Coming to the context of

36
00:02:07,300 --> 00:02:11,200
the app, like I mentioned earlier,
the, the app really is built

37
00:02:11,240 --> 00:02:14,520
grounded for, that they're a citizen
for people who are non technical.

38
00:02:15,160 --> 00:02:18,860
This is a low code, no code platform
which does end to end data science, and,

39
00:02:18,860 --> 00:02:23,120
it, you can not only build models, so
it has abilities which are pre modeling,

40
00:02:23,690 --> 00:02:27,320
abilities, it has the modeling abilities,
and of course, the post modeling abilities

41
00:02:27,330 --> 00:02:29,370
which is deploying and serving the models.

42
00:02:30,050 --> 00:02:32,910
and we are continuously enhancing
that as we integrate with the

43
00:02:32,910 --> 00:02:34,540
larger ecosystem in this space.

44
00:02:35,200 --> 00:02:40,040
the, The app that I'm talking
about today in this session is

45
00:02:40,060 --> 00:02:42,160
the RAG based inference engine.

46
00:02:42,660 --> 00:02:45,270
In fact, these are multiple RAG pipelines.

47
00:02:45,770 --> 00:02:51,080
So there is a parent RAG pipeline which
integrates into child pipelines and

48
00:02:51,090 --> 00:02:56,060
the parent RAG pipelines really is the
orchestration this inference engine, is

49
00:02:56,060 --> 00:03:01,880
akin to a copilot, and this, tries to
take the user through, various aspects

50
00:03:01,940 --> 00:03:07,110
of bringing down, the barriers to
learning and the barriers to, working

51
00:03:07,110 --> 00:03:08,740
with the, with the platform as large.

52
00:03:09,360 --> 00:03:12,970
we are trying to address three, broad
umbrella questions, or abilities

53
00:03:12,980 --> 00:03:16,630
with this copilot, the first one
being, what, can I do next, which

54
00:03:16,630 --> 00:03:20,310
is, nothing but the recommendation
engine, again, a RAC pipeline, the

55
00:03:20,310 --> 00:03:22,320
second one being, what else can I do?

56
00:03:22,370 --> 00:03:26,320
This is, this is basically the
scenarios engine where, the LLM

57
00:03:26,640 --> 00:03:31,780
model, and the associated RAC pipeline
come to an agreement in a assisted

58
00:03:31,780 --> 00:03:35,760
mode with the user, as to what the
intent is in terms of the scenario

59
00:03:35,760 --> 00:03:39,650
and then the back, backend workflow,
build those scenarios for the user.

60
00:03:40,150 --> 00:03:44,430
and then lastly is the, do it for
me, which is our processing engine.

61
00:03:44,590 --> 00:03:47,995
again, abilities, different
abilities in, product coming

62
00:03:47,995 --> 00:03:49,665
together in a rack pipeline.

63
00:03:50,325 --> 00:03:53,105
the processing engine
essentially, helps the user.

64
00:03:53,455 --> 00:03:59,145
give a very few inputs and, generate
or either generate models, do,

65
00:03:59,235 --> 00:04:03,565
any kind of pre processing and
even build, charts and dashboards.

66
00:04:04,095 --> 00:04:06,785
So these are the three broad
abilities of the copilot.

67
00:04:06,785 --> 00:04:09,715
And then there are some abilities,
which again, are part of this larger

68
00:04:09,745 --> 00:04:19,445
three, So that's the context of the
app and it is this app that we've been

69
00:04:19,465 --> 00:04:24,355
focused on the last one year and we've
been evolving our RAG architectures

70
00:04:24,855 --> 00:04:26,735
to enable this co pilot abilities.

71
00:04:27,235 --> 00:04:28,395
How did we get started?

72
00:04:28,925 --> 00:04:33,395
Obviously we got started like
everybody else did, building simple

73
00:04:33,815 --> 00:04:35,365
RAG architectures or pipeline.

74
00:04:36,010 --> 00:04:41,520
we obviously had to move on to,
making sure that, whatever that we are

75
00:04:41,550 --> 00:04:46,830
building is, is relevant, to, to the
user and has the, the right, responses.

76
00:04:47,400 --> 00:04:50,840
so we had to quickly move to a
more evaluation driven, development

77
00:04:50,850 --> 00:04:52,080
or metric driven development.

78
00:04:52,135 --> 00:04:55,735
and then gradually, we build our
evaluation landscape, which is

79
00:04:55,735 --> 00:04:58,635
again growing, as there are more
and more tools available and more

80
00:04:58,635 --> 00:05:02,365
and more metrics, become available
for, every component that is there

81
00:05:02,365 --> 00:05:03,805
as part of the entire RAC pipeline.

82
00:05:04,365 --> 00:05:06,505
we are, gradually adopting to that.

83
00:05:06,535 --> 00:05:08,335
But as of now, I think it's time today.

84
00:05:08,895 --> 00:05:12,335
These are three key, moving parts,
to our matrix driven development,

85
00:05:12,385 --> 00:05:14,095
to our entire evaluation landscape.

86
00:05:14,675 --> 00:05:18,125
we are, in terms of approach,
very, reference based, which

87
00:05:18,125 --> 00:05:20,645
means that, everything that we're
doing based on ground truth.

88
00:05:21,305 --> 00:05:23,955
And to do that, obviously,
you need a very, you need rock

89
00:05:23,955 --> 00:05:26,315
solid, gold standard eval data.

90
00:05:26,745 --> 00:05:28,645
We, we are continuously building that.

91
00:05:29,095 --> 00:05:32,565
Again, completely labeled
and annotated by humans.

92
00:05:33,115 --> 00:05:36,535
in terms of, the scope of
evaluation, we do end to end,

93
00:05:36,585 --> 00:05:37,885
and of course, component based.

94
00:05:37,905 --> 00:05:41,905
When it comes to component based, we right
now focus, again, more on, On the, the

95
00:05:41,905 --> 00:05:45,285
retrieval and the generative components,
but we are moving towards, building

96
00:05:45,285 --> 00:05:50,195
more evaluation metrics, including unit
testing as we bring in more complexity and

97
00:05:50,195 --> 00:05:51,975
more components in our, in our pipeline.

98
00:05:52,725 --> 00:05:58,035
so generative, and, retrieval metrics
are, Build using the Raga framework

99
00:05:58,065 --> 00:06:03,915
and we using the standard matrix there
of F1 score which is basically a good

100
00:06:03,925 --> 00:06:09,675
balance between precision and recall as
far as retrieval is concerned and for

101
00:06:09,675 --> 00:06:15,385
generative we are basing our evaluation
on faithfulness and, answer relevancy.

102
00:06:16,045 --> 00:06:19,735
the other element, important element
of our, matrix treatment development

103
00:06:19,785 --> 00:06:21,695
is, is the design consideration.

104
00:06:21,805 --> 00:06:27,275
this is, this is key, Point or guiding
principle rather which helps us figure

105
00:06:27,315 --> 00:06:31,665
out what are the kind of matrix we need
to bring in and Also, what are the kind

106
00:06:31,665 --> 00:06:37,495
of components which we need to either
enhance or what additional layers are

107
00:06:37,525 --> 00:06:43,585
needed In terms of design consideration
we I use three, deterministic versus

108
00:06:43,585 --> 00:06:47,225
non deterministic, which basically means
that whether, how much of large language

109
00:06:47,245 --> 00:06:51,135
models are we going to be using for each
of our components, we are currently using

110
00:06:51,135 --> 00:06:56,005
at two, two, two of our components, use
large language models, and we gradually,

111
00:06:56,005 --> 00:06:59,985
evaluate that, and based on, how much
of, deterministic and non deterministic

112
00:06:59,985 --> 00:07:04,165
components we have, that will drive
our evaluation landscape as well.

113
00:07:04,885 --> 00:07:07,275
and then next, of course,
is, turns, very important.

114
00:07:07,385 --> 00:07:10,435
Now, when we started off, we were
very boundaried, we were, we did

115
00:07:10,435 --> 00:07:11,885
not allow an open conversation.

116
00:07:12,505 --> 00:07:15,505
but now gradually from a single
term conversations, we have

117
00:07:15,515 --> 00:07:17,455
moved on to multiple turns.

118
00:07:17,955 --> 00:07:21,405
and then we will, open up, make
it, a very free flow, text.

119
00:07:21,745 --> 00:07:26,495
we are still a little boundary, but, we
are multi term conversational co pilot.

120
00:07:26,635 --> 00:07:31,455
that's, what the current state is, and
we are, continuously testing that, and

121
00:07:31,455 --> 00:07:36,315
the third important, design consideration
is the prompt flow, based on, again,

122
00:07:36,365 --> 00:07:41,245
whether a single turn, multiple turn, the
complexity, the use case, of the copilot,

123
00:07:41,295 --> 00:07:45,125
and as we build in more and more abilities
in copilot, I've spoken about the three

124
00:07:45,125 --> 00:07:49,005
umbrella, but then within that, there are
a lot of those smaller abilities, that

125
00:07:49,005 --> 00:07:52,085
determines what is the kind of prompt
engineering and prompt flow that will be

126
00:07:52,085 --> 00:07:57,055
needed, whether these are complex queries
which needs decomposition, or they, need

127
00:07:57,075 --> 00:07:59,065
any other query enhancement treatment.

128
00:07:59,545 --> 00:08:02,855
based on, that we decided, what
kind of enhancement or component

129
00:08:02,855 --> 00:08:05,505
we will be needing, and what
metrics we will be needing.

130
00:08:05,555 --> 00:08:09,765
So this is really our, evaluation
landscape and how we go about, bring,

131
00:08:09,865 --> 00:08:13,315
taking these three pillars to drive
our metrics driven development.

132
00:08:13,365 --> 00:08:18,085
in terms of how we progressed on this, we
started off with eyeballing, at the POC

133
00:08:18,095 --> 00:08:22,445
stage, and throughout the POC stage, all
that the teams were doing was eyeballing.

134
00:08:22,485 --> 00:08:26,275
and as we were doing eyeballing,
we had our experts, which is, our,

135
00:08:26,355 --> 00:08:31,145
analytical team, which, started to
use the eyeballing outputs, and the

136
00:08:31,145 --> 00:08:35,930
pairs of query, query context and
responses, to build in the eval data.

137
00:08:36,670 --> 00:08:40,420
so we started building the eval
data right from our, POC stage.

138
00:08:40,850 --> 00:08:45,020
we also use certain synthetic data
generators, to build those pairs.

139
00:08:45,510 --> 00:08:50,350
and then, we moved on to doing, as we
developed more, larger eval data set.

140
00:08:50,840 --> 00:08:54,120
we moved on to doing, structured,
supervised, evaluation.

141
00:08:54,640 --> 00:08:57,360
and now, of course, we're
trying to move to LM as a judge.

142
00:08:57,410 --> 00:08:59,930
this, of course, needs very
sophisticated prompt engineering.

143
00:09:00,010 --> 00:09:04,970
and once we achieve this, we'll
have a full instrumentation or

144
00:09:04,980 --> 00:09:07,340
automation of our evaluation.

145
00:09:07,880 --> 00:09:11,150
these are the three, these are
the three, prominent stages,

146
00:09:11,190 --> 00:09:12,440
in our evaluation journey.

147
00:09:12,940 --> 00:09:16,550
we are, just about starting
to use LLM, as a judge.

148
00:09:16,890 --> 00:09:20,840
but our, we continue to use, eyeballing
and our supervised, ground truth,

149
00:09:21,060 --> 00:09:23,620
evaluation model, is working well for us.

150
00:09:24,120 --> 00:09:27,690
so that was around, around evaluation,
which is really the big piece

151
00:09:27,720 --> 00:09:29,180
and that takes a lot of our time.

152
00:09:29,490 --> 00:09:33,900
and then the next, important element
or pillar, is the data pre processing.

153
00:09:34,490 --> 00:09:37,710
we started off with, various
chunking, methodologies or strategies,

154
00:09:37,710 --> 00:09:38,807
fixed chunk, preprocessing.

155
00:09:38,807 --> 00:09:42,727
Fizz chunking, content based chunking,
but we settled on to semantic chunking

156
00:09:42,737 --> 00:09:47,717
because, when we, did our comparisons,
the semantic chunking was working

157
00:09:47,717 --> 00:09:52,587
best for us, but then, it depends on
the kind of use case and the, source

158
00:09:52,587 --> 00:09:56,497
data, data that you have, you could
potentially, be using a hybrid chunking

159
00:09:56,497 --> 00:09:58,177
strategy, which might just work better.

160
00:09:58,177 --> 00:10:00,177
parsing is of course the
most fundamental thing.

161
00:10:00,957 --> 00:10:03,527
That's where everything starts,
depending on what kind of documents

162
00:10:03,527 --> 00:10:09,027
you have, whether those are code
files, those are, webpages or PDFs,

163
00:10:09,057 --> 00:10:11,277
Word documents or even images.

164
00:10:11,287 --> 00:10:15,657
Depending on that, you would be using
different parsing algorithms or tools.

165
00:10:16,127 --> 00:10:20,747
we've tried many, we've, and our current
tech stack is, inclined more on the,

166
00:10:20,797 --> 00:10:23,027
parser variable from, the Lama landscape.

167
00:10:24,007 --> 00:10:27,787
sparse and dense retrievers, we, we
are starting to feel that we would

168
00:10:27,797 --> 00:10:31,597
be needing dense retrievers, now,
although, sparse retrievers have

169
00:10:31,627 --> 00:10:35,667
worked, for us, the DF, IDF, and
BM25 is what we have used, so far.

170
00:10:36,167 --> 00:10:40,337
but we started to get some vocabulary
mismatch problems, and, our teams

171
00:10:40,337 --> 00:10:43,367
have now started the next POC
of, putting, the Dense Retriever

172
00:10:43,367 --> 00:10:44,927
components, in our RAC pipeline.

173
00:10:45,447 --> 00:10:48,237
we have been focusing on
metadata from day one.

174
00:10:48,327 --> 00:10:51,587
a lot of our, abilities are
driven by this metadata.

175
00:10:52,042 --> 00:10:55,702
and when we say metadata, metadata,
in context of rank obviously is the

176
00:10:55,702 --> 00:11:00,443
metadata of the documents and the,
metadata of the chunks and also the,

177
00:11:00,493 --> 00:11:04,463
potential metadata around, even prompts
if you're doing good prompt versioning,

178
00:11:04,993 --> 00:11:09,503
but we also do metadata around the
context of, the user, and that context

179
00:11:09,503 --> 00:11:14,453
is built in, what we refer to as the, the
organizational business map, and the KPI.

180
00:11:14,473 --> 00:11:16,213
So we captured that metadata too.

181
00:11:16,693 --> 00:11:20,843
And all of this is in our metadata
database, from where we, pull in

182
00:11:21,053 --> 00:11:24,943
the context, which, then gets fed
into, which I earlier mentioned

183
00:11:24,963 --> 00:11:26,793
into our orchestration layer.

184
00:11:27,153 --> 00:11:31,333
and then from where we do the routing
for, the various, RAC pipeline.

185
00:11:31,333 --> 00:11:35,373
so these are the four, Essential elements
of our data pre processing that, we

186
00:11:35,373 --> 00:11:39,833
currently engaged in and, now, starting
to experiment, and bringing the dense,

187
00:11:39,863 --> 00:11:41,733
retrieval capabilities, in a platform.

188
00:11:42,503 --> 00:11:45,913
Query Enhancement, we didn't do
much of it initially, but we, we

189
00:11:45,913 --> 00:11:50,373
wanted to ensure that we have the
best practices in place to make sure

190
00:11:50,373 --> 00:11:52,253
that the intent is fully understood.

191
00:11:52,813 --> 00:11:57,063
and as the, as we opened up and as
things became more conversational and the

192
00:11:57,063 --> 00:12:03,223
conversation boundaries were loosened up,
it was, it became clear that enhancements

193
00:12:03,253 --> 00:12:07,743
would be needed to, break down complex,
Queries, to decompose them to ensure

194
00:12:07,743 --> 00:12:09,293
that the intent becomes very clear.

195
00:12:09,813 --> 00:12:13,703
so we do a query decomposition, and
we use, a large language model there.

196
00:12:14,323 --> 00:12:18,853
the other thing that we started to
do now is to, do, is to do hide.

197
00:12:19,353 --> 00:12:23,553
Which is, again using, which will
be using a large language model.

198
00:12:23,623 --> 00:12:27,823
It really goes a little further
than using a supervised encoder.

199
00:12:28,433 --> 00:12:30,603
and it, builds, theoretical documents.

200
00:12:30,693 --> 00:12:35,243
and those documents can then be, It is
classified as part of one, classification

201
00:12:35,273 --> 00:12:39,223
of documents from where we then
generate, pairs of queries which are

202
00:12:39,223 --> 00:12:40,963
very relevant to that particular chunk.

203
00:12:41,413 --> 00:12:47,003
So chunk classification, is s something
that we intend to build by, not only

204
00:12:47,003 --> 00:12:50,373
using the, document chunks that we
have through our semantic chunking,

205
00:12:50,423 --> 00:12:53,573
but also by, using, the hide technique.

206
00:12:54,233 --> 00:12:58,143
Routing, we've been using this, since day
one because we have different databases.

207
00:12:58,173 --> 00:13:01,483
So we have a routing layer and
this routing layer based, on,

208
00:13:01,813 --> 00:13:05,553
which, which database we need to
send the query to, does its job.

209
00:13:05,603 --> 00:13:08,343
so the routing layer is responsible
to understand the query.

210
00:13:08,413 --> 00:13:12,893
And, again, it's basically, decomposing
as the queries become more complex,

211
00:13:12,923 --> 00:13:14,563
understanding the intent of the query.

212
00:13:14,923 --> 00:13:19,603
and then routing it to the correct place
now as we do all of these things, it is,

213
00:13:19,653 --> 00:13:26,083
it is, one of our challenge is to ensure,
that the complexities that we're building

214
00:13:26,083 --> 00:13:28,463
in, they don't impact the latency.

215
00:13:28,463 --> 00:13:33,233
and so our DevOps team, our infrastructure
team, are all a very integral part of,

216
00:13:33,283 --> 00:13:37,053
doing everything, on the rack pipeline,
and, building the rack abilities.

217
00:13:37,553 --> 00:13:41,563
And what kind of deployment architectures
and infrastructure we can use.

218
00:13:41,563 --> 00:13:44,023
We currently are on AWS.

219
00:13:44,103 --> 00:13:45,673
The product is on AWS.

220
00:13:45,733 --> 00:13:51,253
And we are increasingly evaluating
every service in the JNI ability

221
00:13:51,253 --> 00:13:57,143
on AWS, including the serverless
abilities that AWS has to offer.

222
00:13:57,548 --> 00:14:00,438
To ensure that we offer good latency.

223
00:14:00,918 --> 00:14:06,328
we, in terms of our, in terms of our go
to market, we are, very B2B, a high touch

224
00:14:06,358 --> 00:14:08,478
model, but our abilities are low touch.

225
00:14:08,528 --> 00:14:11,858
while we don't do a hundred
percent SAS, SAS based model.

226
00:14:12,383 --> 00:14:15,473
So it, it is, sometimes
behind the firewalls.

227
00:14:15,693 --> 00:14:18,513
The application is sometimes behind
the firewalls of the customer.

228
00:14:19,013 --> 00:14:24,533
So we have to be very clear in terms
of the various, architectures that are

229
00:14:24,533 --> 00:14:29,493
needed based on the usage and concurrency,
and also the, associated cost.

230
00:14:29,523 --> 00:14:32,953
our trade offs, is very important and
we spend a lot of time understanding

231
00:14:32,953 --> 00:14:36,433
that and building the infrastructure
architecture around that.

232
00:14:36,993 --> 00:14:40,873
so that's the, that's the other,
important piece and element, of our,

233
00:14:40,973 --> 00:14:45,973
of our, larger pipeline, which is,
continuous enhancement of the queries.

234
00:14:45,973 --> 00:14:46,153
Thanks.

235
00:14:47,068 --> 00:14:51,358
the next, the obvious candidate, after
query enhancement, that we worked on,

236
00:14:51,488 --> 00:14:56,128
significantly on and we continue to
work, is, the retriever and re ranking.

237
00:14:56,248 --> 00:15:02,153
we, didn't have time, We had re ranking
from very early days, but, more retriever

238
00:15:02,153 --> 00:15:03,823
abilities, are gradually being built.

239
00:15:04,503 --> 00:15:07,793
we generally classify these
abilities in three broad categories,

240
00:15:07,853 --> 00:15:11,423
is the, is retriever, post
retriever, and, and generation.

241
00:15:12,023 --> 00:15:17,643
and while there are a lot more, techniques
here, I've only, mentioned on the slide.

242
00:15:17,653 --> 00:15:17,713
Thank you.

243
00:15:18,083 --> 00:15:22,363
The ones that we either are using or we
intend to start building, immediately.

244
00:15:22,853 --> 00:15:27,003
iBead Retriever, is, we've had this
since day one, the filter vector search.

245
00:15:27,058 --> 00:15:29,268
which is simply a filter on
top of your vector search.

246
00:15:29,268 --> 00:15:32,818
That's, that, is standard now
in most rank, architectures and,

247
00:15:32,838 --> 00:15:34,735
we, we continue to use that.

248
00:15:34,755 --> 00:15:38,275
re ranking, we, we've tried
both bi coder and cross encoder.

249
00:15:38,725 --> 00:15:43,845
I was settled on, a cross encoder and
we, we found that the cross encoder works

250
00:15:43,845 --> 00:15:48,465
better, in our use cases, simply because
it compares, two sentences and payers.

251
00:15:48,705 --> 00:15:51,985
So as long as you have a
good, training data of payers,

252
00:15:52,045 --> 00:15:53,485
cross and code is a way to go.

253
00:15:54,015 --> 00:15:58,755
and, we currently use the coherent reran,
which is, which works on, cross encoder.

254
00:15:59,595 --> 00:16:04,125
But we do have certain, by, by, by
encoders still working, but I think,

255
00:16:04,205 --> 00:16:05,575
gradually we're going to phase them out.

256
00:16:06,245 --> 00:16:09,685
Hierarchical indexing again,
seems like this has been adopted

257
00:16:09,685 --> 00:16:11,565
well and has become a standard.

258
00:16:11,665 --> 00:16:15,455
this is, this significantly enhances
the precision of the rank application,

259
00:16:15,665 --> 00:16:19,325
You simply, in a hierarchical,
indexing, you, we organize the data in

260
00:16:19,325 --> 00:16:22,695
a hierarchical structure as the name
suggests, and you have categories and

261
00:16:22,695 --> 00:16:27,145
subcategories based on, on relevance and
relationships, and the retrieval process

262
00:16:27,145 --> 00:16:31,425
focuses on those relationships and the
relevance, and the, and they process

263
00:16:31,425 --> 00:16:35,059
the retrieval, by, doing, what we call
as a parent and teacher relationship.

264
00:16:35,180 --> 00:16:36,020
and channel nodes.

265
00:16:36,060 --> 00:16:40,070
hierarchy indexing is we use
extensively, so that's, working for us.

266
00:16:40,120 --> 00:16:44,030
C RAC, CRAC, whichever way you pronounce
it, which is corrective, corrective

267
00:16:44,030 --> 00:16:45,650
RAC, this is, a new technique.

268
00:16:45,660 --> 00:16:49,730
We've started to use this, or experiment
with this, so we have current POCs, which

269
00:16:49,730 --> 00:16:54,850
are running in this, C RAC is, is It, it
brings in another component, which is a

270
00:16:55,210 --> 00:17:01,110
lightweight retriever, and this retriever
really self evaluates the, the quality of

271
00:17:01,160 --> 00:17:05,160
the documents retrieved, and it provides a
confidence index, so we are, we're hopeful

272
00:17:05,170 --> 00:17:11,140
that, this particular component is again,
going to, LLMS as a charge, help us,

273
00:17:11,170 --> 00:17:15,370
instrument, do the full instrumentation
of, of a evaluation, landscape.

274
00:17:15,930 --> 00:17:19,200
like I said that we want to move
towards as much of automated

275
00:17:19,200 --> 00:17:20,420
evaluation as possible.

276
00:17:20,890 --> 00:17:26,950
why we will still be, focused on, making
sure that our, eval datasets are robust.

277
00:17:27,460 --> 00:17:30,979
but having produced those, eval datasets,
we want the rest of the pieces to

278
00:17:30,979 --> 00:17:32,639
be really as automated as possible.

279
00:17:33,169 --> 00:17:35,089
fine tuning, again, very helpful.

280
00:17:35,139 --> 00:17:40,009
this is the, generation, we keep the
LLMs that we use fine tuned, based on

281
00:17:40,009 --> 00:17:44,069
whatever the context of that LLM is, is,
whether it's for generation or whether

282
00:17:44,069 --> 00:17:48,919
it is for query composition or even
some of the other, abilities that we're

283
00:17:48,929 --> 00:17:50,869
building that would require, use of LLMs.

284
00:17:51,324 --> 00:17:55,794
so we, that's a standard practice,
wherever we have data, we fine tune it.

285
00:17:55,794 --> 00:17:59,234
Wherever we don't, we, generate
synthetic data and we fine tune it.

286
00:17:59,734 --> 00:18:03,114
So that's the retrieval and re
ranking, abilities that we have,

287
00:18:03,154 --> 00:18:07,224
and that we're currently using and,
the one, I spoke about C Rank that

288
00:18:07,224 --> 00:18:08,664
we intend to use, going forward.

289
00:18:09,164 --> 00:18:11,814
So that was about the various
principal components that we

290
00:18:11,814 --> 00:18:13,594
have, in, in a RAC pipeline.

291
00:18:13,624 --> 00:18:18,224
A RAC pipeline, at a very high level,
has, looks like, the, The pipeline that

292
00:18:18,224 --> 00:18:21,234
I have on the deck, we have the queries.

293
00:18:21,504 --> 00:18:22,914
Then we have query transformation.

294
00:18:22,994 --> 00:18:25,794
we are routing across
three, different databases.

295
00:18:25,934 --> 00:18:27,304
We have the product docs database.

296
00:18:27,334 --> 00:18:29,794
We have the user history and
what we have the context TV.

297
00:18:30,304 --> 00:18:33,405
The context TV is, is, is really
the context of the business

298
00:18:33,445 --> 00:18:36,285
where we have the business maps,
the processes, the features.

299
00:18:36,850 --> 00:18:39,360
all of which is used to
develop, analytical models.

300
00:18:39,970 --> 00:18:43,110
we're currently using, like I said,
two places, large limit models.

301
00:18:43,110 --> 00:18:46,360
One for query decomposition,
where we're using chain of, chain

302
00:18:46,360 --> 00:18:47,530
of thought, prompt engineering.

303
00:18:48,220 --> 00:18:50,920
and, we're using, prompting
for augmentation process.

304
00:18:50,980 --> 00:18:54,310
so the key takeaway really is
that, prompt engineering and

305
00:18:54,320 --> 00:18:55,880
drag are really tied together.

306
00:18:55,930 --> 00:18:58,890
obviously we don't hope, we don't
want to over engineer, prompt

307
00:18:58,890 --> 00:19:00,610
engineering, wherever it's not required.

308
00:19:00,620 --> 00:19:04,460
But the key takeaway is that, wherever
we use, whichever component uses a

309
00:19:04,460 --> 00:19:08,560
large language model, That is where
we will be using sophisticated prompt

310
00:19:08,560 --> 00:19:12,660
engineering and that is how these
two are really married to each other.

311
00:19:13,660 --> 00:19:17,680
A simple rank probably uses prompt
engineering only in the augmentation

312
00:19:17,680 --> 00:19:22,440
process, but as you bring in more and more
LLMs for different components, as I spoke

313
00:19:22,440 --> 00:19:28,010
about, sophisticated prompt engineering
is absolutely bedrock for, doing, relevant

314
00:19:28,050 --> 00:19:30,748
and, a more, a correct, RAC pipeline.

315
00:19:31,248 --> 00:19:35,248
in terms of our next steps, We are trying
to move to a modular RAC architecture.

316
00:19:35,278 --> 00:19:39,298
This is also the need and, from our
customers, wherein, we are going to

317
00:19:39,308 --> 00:19:41,048
be doing subscription based pricing.

318
00:19:41,048 --> 00:19:45,218
So there are different abilities and
these abilities need to be dockerized and,

319
00:19:45,268 --> 00:19:47,448
deployed, in a microservices architecture.

320
00:19:47,468 --> 00:19:50,258
So making sure that we are ready for that.

321
00:19:50,348 --> 00:19:54,698
And as are each of these components and
these services grow, not in terms of the

322
00:19:54,698 --> 00:19:58,958
usage, but also in terms of, the data
that they're handling and the kind of,

323
00:19:59,058 --> 00:20:00,788
responses that they need to generate.

324
00:20:00,908 --> 00:20:05,318
so as that grows and it becomes more
sophisticated, We, these services need

325
00:20:05,358 --> 00:20:08,038
to, take a life on its own, of their own.

326
00:20:08,088 --> 00:20:11,368
And, we would need to move towards
a modular RAG architecture.

327
00:20:11,958 --> 00:20:14,878
we are, one of our challenges
has been, versioning of prompts.

328
00:20:14,928 --> 00:20:19,748
so we are, evaluating different products
where we can have end to end versioning of

329
00:20:19,758 --> 00:20:26,258
prompts also because like I said, we are
putting in more and more LLMs in different

330
00:20:26,258 --> 00:20:28,038
components of the RAG architecture.

331
00:20:28,733 --> 00:20:32,933
we are almost ready, with the, with the
unit testing, and, we're using ProudFu

332
00:20:32,953 --> 00:20:35,883
for that, and that's something which
has become part of our, development

333
00:20:35,883 --> 00:20:37,798
lifecycle, that is currently, running.

334
00:20:38,128 --> 00:20:43,068
it's almost a practice now, and then
lastly, we're looking at, agentic

335
00:20:43,078 --> 00:20:44,588
abilities wherever they are needed.

336
00:20:44,638 --> 00:20:47,998
like I said, earlier when I was
describing about, the application,

337
00:20:48,578 --> 00:20:53,098
there is, the parent, orchestration,
engine, inference engine, and, right

338
00:20:53,098 --> 00:20:55,468
now it's built on, custom rules.

339
00:20:55,973 --> 00:21:00,633
but we intend to bring in, use of other
tools as well to make sure that, context

340
00:21:00,633 --> 00:21:02,683
is brought in from other data sources.

341
00:21:03,213 --> 00:21:04,823
and we have agenting abilities there.

342
00:21:05,393 --> 00:21:08,193
so those are the, some of the
next steps that we intend to take.

343
00:21:08,243 --> 00:21:11,173
and that's, that was a high level view of.

344
00:21:11,703 --> 00:21:16,153
What our application does, what is,
the current, architecture of our, RAC

345
00:21:16,153 --> 00:21:20,893
pipelines, and some of the, learnings
that we have had, on working on these

346
00:21:20,893 --> 00:21:22,393
abilities, for the last one year.

347
00:21:23,223 --> 00:21:24,893
so I think I'm back on time.

348
00:21:24,893 --> 00:21:28,933
I hope, I hope this, session was
useful and, the audience got, some

349
00:21:28,933 --> 00:21:30,553
important, pointers from this.

350
00:21:31,133 --> 00:21:34,643
I will be very happy to take questions
whenever the opportunity arises.

351
00:21:35,053 --> 00:21:37,723
thank you so much, for,
being there, and listening.

