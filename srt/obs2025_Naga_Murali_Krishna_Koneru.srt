1
00:00:02,250 --> 00:00:02,910
Hello everyone.

2
00:00:03,570 --> 00:00:05,130
I am N Krisna.

3
00:00:05,760 --> 00:00:08,910
I'm a technical architect with
more than 11 years of experience.

4
00:00:10,170 --> 00:00:17,130
I worked on a WS services as a
developer administrator and I'm

5
00:00:17,130 --> 00:00:21,755
working as an architect, for a
S Services, DevOps DevSecOps.

6
00:00:22,260 --> 00:00:25,530
I also work on automations
of all these services.

7
00:00:27,029 --> 00:00:31,290
For performance improvement and
producing the cost to the clients.

8
00:00:32,159 --> 00:00:37,140
today I'm going to discuss about the
topic, observability with open telemetry.

9
00:00:37,560 --> 00:00:42,720
So this technical discussion will
focus on observability principles

10
00:00:43,170 --> 00:00:47,489
and implementing open telemetry
in our modern distributed systems.

11
00:00:48,150 --> 00:00:49,050
Let's get started.

12
00:00:50,070 --> 00:00:51,360
this is the agenda for today.

13
00:00:51,629 --> 00:00:53,250
First, we'll, focus on.

14
00:00:54,435 --> 00:00:58,275
Understanding the observability,
by learning foundations and

15
00:00:58,275 --> 00:00:59,355
key concepts of observability.

16
00:01:00,495 --> 00:01:05,595
Then we'll deep dive with different
types of, tele data types.

17
00:01:06,165 --> 00:01:07,785
And collection methods.

18
00:01:09,345 --> 00:01:14,745
Later we'll focus on the architecture
of Open Telemetry components and

19
00:01:14,745 --> 00:01:18,555
implementation part, which covers open
telemetry essentials as a thought topic.

20
00:01:19,605 --> 00:01:24,855
And the fourth topic would be the data
sources of open telemetry on how can

21
00:01:24,855 --> 00:01:30,315
we integrate open telemetry with other
systems, other tools in our application.

22
00:01:30,975 --> 00:01:33,165
Let's get started with the deep dive.

23
00:01:35,625 --> 00:01:40,994
Before we start, in details, let's focus
on the foundations of observability.

24
00:01:42,824 --> 00:01:46,125
we talk more about tele
data over this, discussion.

25
00:01:46,125 --> 00:01:48,914
So let's talk about
what is telemetry data.

26
00:01:49,604 --> 00:01:56,744
Basically, it's like a collection
and transmission of logs, events and

27
00:01:56,835 --> 00:01:59,145
measurements from various systems.

28
00:01:59,145 --> 00:02:03,750
Could be remote systems or distributed
systems to a central monitoring place.

29
00:02:04,650 --> 00:02:05,190
Analysis.

30
00:02:06,030 --> 00:02:09,690
Once we collect this, data
would be used to locate the

31
00:02:09,690 --> 00:02:13,080
potential problems in the systems.

32
00:02:14,520 --> 00:02:19,950
So basically, DevOps
focus on, two metrics.

33
00:02:21,030 --> 00:02:23,400
any, which looks into these two metrics.

34
00:02:23,430 --> 00:02:26,579
One is called MT td, and another is MTTR.

35
00:02:28,079 --> 00:02:29,700
mean time to detection.

36
00:02:30,480 --> 00:02:32,855
this is a time taken
to identify the issue.

37
00:02:34,620 --> 00:02:37,470
And MTTR like mean time to resolve.

38
00:02:38,100 --> 00:02:43,920
This is a time taken to resolve the
issue after the issue is detected.

39
00:02:44,580 --> 00:02:50,310
So identifying and resolving,
these are the two metrics that are

40
00:02:50,310 --> 00:02:52,530
being measured by organizations.

41
00:02:52,530 --> 00:02:57,540
How quickly we are able to identify
the issue and how quickly we

42
00:02:57,540 --> 00:02:58,465
are able to resolve the issue.

43
00:03:01,245 --> 00:03:02,204
Monitoring methods.

44
00:03:03,195 --> 00:03:06,734
So we'll be collecting different types
of telemetry data, as we discussed

45
00:03:06,734 --> 00:03:08,295
in the previous, slide, right?

46
00:03:09,045 --> 00:03:11,415
So what type of data we
are going to collect.

47
00:03:11,895 --> 00:03:14,745
So the first one is, red method.

48
00:03:15,765 --> 00:03:21,435
the R represents rate E represents
errors, D represents duration rate.

49
00:03:21,855 --> 00:03:25,875
So the number of requests coming
into the system per second,

50
00:03:26,265 --> 00:03:27,825
like requests per second.

51
00:03:28,500 --> 00:03:32,070
Transactions per second error.

52
00:03:32,880 --> 00:03:36,360
The number of failed transactions
or requests in our application

53
00:03:36,360 --> 00:03:38,610
or a system and the duration.

54
00:03:38,820 --> 00:03:45,750
So the response time, may be per request
or per transaction from our system.

55
00:03:47,280 --> 00:03:49,320
And the second method is use method.

56
00:03:49,800 --> 00:03:53,550
In this, it focuses on
utilization of the resources.

57
00:03:54,450 --> 00:03:59,970
Like resource ation, like how much
of CPU used, how much disc is used?

58
00:04:00,450 --> 00:04:03,420
Saturation, like a Q length, for example.

59
00:04:03,420 --> 00:04:07,770
Network packets or network
requests are queing up errors.

60
00:04:08,070 --> 00:04:11,220
So it could be hardware or
software related errors.

61
00:04:12,300 --> 00:04:16,950
Say for example, discre
error, discre IO error.

62
00:04:17,010 --> 00:04:18,985
These are all called as, errors.

63
00:04:20,850 --> 00:04:22,050
Four golden signals.

64
00:04:22,500 --> 00:04:27,300
this method is, recommended by Google
in their set liability documentation.

65
00:04:27,930 --> 00:04:34,980
So four golden, signals, covers the
first, first three, collections,

66
00:04:34,980 --> 00:04:38,100
like red plus saturation.

67
00:04:38,880 --> 00:04:42,270
So the first topic is in
this one is the latency.

68
00:04:43,485 --> 00:04:47,535
the processing time, the delay
happening in the system traffic,

69
00:04:47,595 --> 00:04:52,155
the request volume coming into the
system, that errors the failure rates

70
00:04:52,155 --> 00:04:57,135
in the application of the system,
saturation in the system load, that is

71
00:04:57,135 --> 00:04:59,115
happening within our operating system.

72
00:04:59,115 --> 00:05:01,620
Sir, it would be an overall
system or the application.

73
00:05:03,750 --> 00:05:05,430
And, core web bottles.

74
00:05:06,240 --> 00:05:06,420
Okay.

75
00:05:06,420 --> 00:05:12,390
This is mainly focusing on the web UI or
user interfaces or webpages or websites.

76
00:05:12,870 --> 00:05:17,760
The previous, three methods, what
we focused are, they focus on the

77
00:05:17,760 --> 00:05:23,095
system, the infrastructure side,
system side and services side.

78
00:05:23,580 --> 00:05:29,550
But core web metals will focus on, the
web, user interface, user experiences.

79
00:05:30,210 --> 00:05:32,100
The LCP, the largest.

80
00:05:32,640 --> 00:05:33,060
Content.

81
00:05:33,060 --> 00:05:33,719
Full paint.

82
00:05:33,780 --> 00:05:35,969
It measures loading performance.

83
00:05:36,660 --> 00:05:42,870
FID first input, delay measures,
responsiveness to user, interactions.

84
00:05:44,130 --> 00:05:49,530
CLS accumulate to layout, shift
measures, visual, stability during

85
00:05:49,530 --> 00:05:51,300
the load of the particular webpage.

86
00:05:53,520 --> 00:05:54,659
Now let's talk about,

87
00:06:01,620 --> 00:06:07,469
Tracks known issues and it is best for,
a small systems and monolith systems.

88
00:06:08,159 --> 00:06:10,650
And it shows when the issue occurs.

89
00:06:11,670 --> 00:06:14,370
When it comes to observability,
it's a practical approach.

90
00:06:15,000 --> 00:06:21,195
It uncovers unknown unknowns ideal for
complex systems, and it shows where,

91
00:06:21,510 --> 00:06:23,520
when, and why that issue happened.

92
00:06:24,150 --> 00:06:28,860
So observability gives us more
quicker way of identifying the

93
00:06:28,860 --> 00:06:30,030
issue and resolving the issue.

94
00:06:32,429 --> 00:06:33,750
And tele data type.

95
00:06:33,750 --> 00:06:39,359
So we talked about what is tele data, what
we collect, and what type of data it is.

96
00:06:39,900 --> 00:06:43,140
So there are, different
types of tele data.

97
00:06:43,590 --> 00:06:44,520
one is metrics.

98
00:06:45,780 --> 00:06:48,659
it it, just explains about
the quantitative measurements,

99
00:06:48,659 --> 00:06:49,554
like what is happening.

100
00:06:52,410 --> 00:06:54,090
it comes with numbers, basically.

101
00:06:54,120 --> 00:06:54,450
Okay.

102
00:06:55,380 --> 00:06:55,920
logs.

103
00:06:56,280 --> 00:07:01,500
So it's like timestamped events
that, are decoded in the system.

104
00:07:01,920 --> 00:07:03,305
So what happened when it happened?

105
00:07:04,965 --> 00:07:05,325
Okay.

106
00:07:06,075 --> 00:07:10,065
Traces like this is very important
when we talk about observability.

107
00:07:11,115 --> 00:07:15,375
so it gives us end-to-end request
journey within our application.

108
00:07:15,945 --> 00:07:17,535
So suppose I have five APAs.

109
00:07:17,535 --> 00:07:21,945
So the trace would help us to
identify which APAs performing slow,

110
00:07:21,945 --> 00:07:24,735
or which a PA is actually broken.

111
00:07:26,175 --> 00:07:26,445
Okay?

112
00:07:26,475 --> 00:07:30,705
So it explains about where
the bottle is profiles.

113
00:07:31,605 --> 00:07:33,165
So this will identify.

114
00:07:34,185 --> 00:07:39,645
The resource level diagnostics, why my
system is slow, either it is, because

115
00:07:39,645 --> 00:07:45,555
of CPU utilizations or maybe garbage,
corrections happening during that time.

116
00:07:46,005 --> 00:07:49,635
So this profiling will help us to
identify the resource level diagnostics.

117
00:07:52,065 --> 00:07:57,825
this is the, this slide explains
about a pictorial, way of, your

118
00:07:57,830 --> 00:07:59,775
observability in the motor systems.

119
00:08:00,330 --> 00:08:07,080
So here, you see the application could
be in public, cloud, and the on prime.

120
00:08:07,680 --> 00:08:11,820
And we receive various, tele data.

121
00:08:12,000 --> 00:08:17,220
So we call this melt, informs e for
events and for logs and D traces.

122
00:08:18,870 --> 00:08:22,620
And this, these, collected metrics
would be pushed into observability

123
00:08:23,010 --> 00:08:27,540
solution, which we are going
to, look in, future slides.

124
00:08:29,055 --> 00:08:33,164
And different teams like developers,
monitoring ops, security ops would be

125
00:08:33,435 --> 00:08:37,515
depending on the solution to identify
any issues and to resolve the problems.

126
00:08:38,865 --> 00:08:39,225
Okay?

127
00:08:39,435 --> 00:08:42,794
And this is, just overall
picture of how observability

128
00:08:42,855 --> 00:08:45,015
will be in our, modern systems.

129
00:08:47,955 --> 00:08:49,905
how can we collect these, metrics?

130
00:08:49,995 --> 00:08:53,715
So there are two collection metrics,
actually push method and scrape method.

131
00:08:55,005 --> 00:08:58,454
The push method is like
applications will actively send

132
00:08:58,515 --> 00:09:03,224
the metrics to the collection
endpoint or TCP or UDP protocols.

133
00:09:04,545 --> 00:09:08,714
in this picture you see the backend
services is, sending the metric

134
00:09:08,714 --> 00:09:14,864
to, stats D. Stats D is in turn
sending, that particular metric to

135
00:09:14,864 --> 00:09:17,354
graphite, which is a time database.

136
00:09:18,074 --> 00:09:22,515
Scrape method is something where
applications expose metrics.

137
00:09:23,564 --> 00:09:25,035
For collectors.

138
00:09:25,395 --> 00:09:28,665
So basically, applications
won't push the data.

139
00:09:28,665 --> 00:09:33,885
Instead the collection, services,
the data collectors would pull

140
00:09:33,885 --> 00:09:35,295
the data from the applications.

141
00:09:36,194 --> 00:09:39,464
Here in this example, pro
is actually scraping the

142
00:09:39,464 --> 00:09:41,175
metrics from this application.

143
00:09:41,775 --> 00:09:44,625
So basically we can say it's
actually pulling the data,

144
00:09:45,495 --> 00:09:46,574
from the backend service.

145
00:09:48,375 --> 00:09:50,954
So when can we choose scrape?

146
00:09:50,954 --> 00:09:52,275
When can we choose push?

147
00:09:53,880 --> 00:09:58,920
So choose scrape when, you're using,
Kubernetes or dynamic environments

148
00:09:59,579 --> 00:10:06,780
and preferred, centralized, control
of your all the log management and

149
00:10:06,810 --> 00:10:09,660
when apps can expose HT pinpoints.

150
00:10:10,319 --> 00:10:10,739
Okay.

151
00:10:11,219 --> 00:10:16,410
so basically, yeah, your apps has,
option to expose their end points.

152
00:10:17,640 --> 00:10:24,600
Especially choose the scraping choose
push when apps are shortlived and the

153
00:10:24,600 --> 00:10:29,520
real time metrics are required for us,
and apps run in restricted networks.

154
00:10:30,060 --> 00:10:36,075
So in scrape method, the, the apps
that has HT p endpoint exposure,

155
00:10:36,075 --> 00:10:41,370
yes, the script can be used, but
when apps are running within the

156
00:10:41,670 --> 00:10:44,940
restrict networks and they have no
option to expose their endpoints.

157
00:10:45,360 --> 00:10:49,200
So use the push method now.

158
00:10:49,890 --> 00:10:52,830
we entered into, introduction
to Open Telemetry.

159
00:10:55,260 --> 00:11:01,290
open Telemetry is a open source framework,
which standardizes generation collection

160
00:11:01,350 --> 00:11:03,750
and management of, telemetry data.

161
00:11:04,380 --> 00:11:06,390
It's A-C-N-C-F project.

162
00:11:07,215 --> 00:11:11,235
Basically it's incubated under
Cloud NATO Computing Foundation.

163
00:11:11,295 --> 00:11:15,345
So same foundation is actually
managing, Kubernetes as well.

164
00:11:16,335 --> 00:11:21,825
The key benefits of Open Telemetry are
it's vendor neutral and it supports,

165
00:11:22,035 --> 00:11:26,175
cross languages and multiple languages,
and it provides standardization of,

166
00:11:26,745 --> 00:11:32,085
data collection and it covers a lot of,

167
00:11:34,245 --> 00:11:34,935
metrics like.

168
00:11:35,745 --> 00:11:40,455
Logs metrics, traces into, one framework

169
00:11:43,035 --> 00:11:46,275
and let's, look at, the open architecture.

170
00:11:46,365 --> 00:11:50,685
So the architecture of Work
Telemetry has these, main components.

171
00:11:51,795 --> 00:11:59,895
Instrumentation, libraries, receivers,
collectors, processors, OTLP, protocol

172
00:12:00,240 --> 00:12:03,500
and exporters, instrumentation libraries.

173
00:12:04,155 --> 00:12:10,334
So these, will enhance applications to
generate the telemetry data so that the

174
00:12:10,334 --> 00:12:17,805
application scan pump various metrics,
logs C to open telemetry, and then the

175
00:12:17,805 --> 00:12:23,895
receivers are the ones which will collect
the telemetry data from various sources.

176
00:12:25,080 --> 00:12:26,700
There could be applications as well.

177
00:12:27,600 --> 00:12:34,650
Collectors, they receive a process
and export the tele data processes.

178
00:12:35,370 --> 00:12:39,840
These processes will man plate
the data which was received and

179
00:12:39,840 --> 00:12:45,945
they transform before actually
exporting them to backend services.

180
00:12:45,950 --> 00:12:47,070
OT LB protocol.

181
00:12:47,520 --> 00:12:51,660
It's a standardized protocol
for transforming and

182
00:12:51,660 --> 00:12:53,400
transmitting the telemetry data.

183
00:12:54,735 --> 00:13:00,285
Export, whatever the data that
has been mand and transformed by

184
00:13:00,285 --> 00:13:06,945
processors, the data would be exported
to external observability backs,

185
00:13:11,115 --> 00:13:12,240
open telemetry collector.

186
00:13:12,240 --> 00:13:16,995
This is a very important,
component of open telemetry.

187
00:13:17,085 --> 00:13:21,825
It is a centralized executable that
receives processes and exports.

188
00:13:22,755 --> 00:13:24,885
Tele data to multiple targets,

189
00:13:26,895 --> 00:13:27,735
protocol support.

190
00:13:28,455 --> 00:13:31,965
It works with all the popular
open source, tele protocols.

191
00:13:32,835 --> 00:13:36,795
It acts as an intermediate tree
between, the applications and

192
00:13:37,095 --> 00:13:38,685
the backend, analysis tools.

193
00:13:40,305 --> 00:13:45,015
And it reduces the, resource
consumption, centralize the

194
00:13:45,015 --> 00:13:47,475
configurations, and it'll improve the.

195
00:13:51,695 --> 00:13:54,150
Now we'll talk about,
collector components.

196
00:13:54,150 --> 00:13:59,250
The components of the collector, the
receivers, processors, and exporters.

197
00:14:00,060 --> 00:14:07,110
Receivers would be the entry points for
tele data and they accept various formats.

198
00:14:07,890 --> 00:14:10,110
Processors, would be.

199
00:14:10,724 --> 00:14:17,745
Manipulating the receive data by filtering
or enriching or sampling the data and

200
00:14:17,745 --> 00:14:22,844
send it to the exporters and the exporters
would actually send the process data

201
00:14:23,354 --> 00:14:26,055
back to the backend systems for analysis.

202
00:14:28,755 --> 00:14:33,170
And there are two more components, are
part of optional components of collector.

203
00:14:33,990 --> 00:14:37,290
Connectors, they facilitate the
connection or communication between

204
00:14:37,650 --> 00:14:45,480
the pipelines and they transform,
different, signal types enable a

205
00:14:45,480 --> 00:14:49,230
multi-stage processing flows, extensions.

206
00:14:49,260 --> 00:14:52,680
Basically, they enrich the
component capabilities and

207
00:14:53,370 --> 00:14:55,500
the performance analysis and.

208
00:15:00,675 --> 00:15:04,725
This is a simple, a typical
collector pipeline could be.

209
00:15:05,535 --> 00:15:10,245
So the receivers would be receiving
the data from various sources and

210
00:15:10,245 --> 00:15:15,855
they send it to the processors, which
the process in turn will, transform

211
00:15:15,855 --> 00:15:20,444
the data and send it to the exporters
and the pipeline can have multiple

212
00:15:20,444 --> 00:15:24,735
receivers, multiple processes, and
multiple, exporters in a single pipeline.

213
00:15:27,180 --> 00:15:30,630
And so we are talking about,
open Telemetry would receive the,

214
00:15:31,560 --> 00:15:34,589
telemetry data from various sources.

215
00:15:34,680 --> 00:15:36,120
So what are those data sources?

216
00:15:36,719 --> 00:15:42,209
Typical data sources of, open telemetry
are application instrumentation.

217
00:15:44,250 --> 00:15:47,010
Basically apps using the sdk.

218
00:15:47,430 --> 00:15:54,089
So they send the telemetry data,
log CS metrics to, open telemetry.

219
00:15:54,360 --> 00:15:57,120
So basically applications
are one of the data sources.

220
00:15:57,660 --> 00:16:00,180
And the next ones could be service mesh.

221
00:16:00,630 --> 00:16:05,579
So the traffic metrics and
traces from, the service.

222
00:16:05,579 --> 00:16:10,260
But, mesh tools like SIO
are one of the data sources.

223
00:16:11,010 --> 00:16:13,560
The next one could be node level metrics.

224
00:16:14,280 --> 00:16:18,120
So data from, so this is from, Kubernetes.

225
00:16:18,990 --> 00:16:22,230
the data coming from ATE about
the nodes and running pods

226
00:16:22,980 --> 00:16:24,360
are also the data sources.

227
00:16:25,530 --> 00:16:30,780
Kubernetes events, cluster events,
providing insights into system activities.

228
00:16:30,780 --> 00:16:32,340
This is also one of the data source.

229
00:16:34,380 --> 00:16:39,525
And the other, sources for, open
telemetry are logging demands.

230
00:16:40,545 --> 00:16:46,455
Flu and fluent, which will
collect the data of the logs.

231
00:16:46,455 --> 00:16:51,375
So basically they collect the logs from
the containers within the cluster and

232
00:16:51,375 --> 00:16:55,935
they forward the logs to, open, telemetry.

233
00:16:57,600 --> 00:17:04,230
And various metrics coming from cloud
providers like AWS and GCP and liveliness

234
00:17:04,230 --> 00:17:09,300
and readiness, data, which is, which we
call probes and health checks that are

235
00:17:09,300 --> 00:17:17,280
coming from, Kubernetes clusters and
the container, runtime data, like the

236
00:17:17,280 --> 00:17:22,650
metrics about container, states and,
resource usage of those containers can

237
00:17:22,650 --> 00:17:25,410
also be, sources for open telemetry.

238
00:17:27,254 --> 00:17:30,764
And coming to the implementation
approach for open telemetry.

239
00:17:31,875 --> 00:17:35,175
so there are two ways,
auto instrumentation and

240
00:17:35,295 --> 00:17:36,495
manual instrumentation.

241
00:17:37,245 --> 00:17:41,325
So automatic instrumentation, basically
it's a call, auto instrumentation,

242
00:17:42,645 --> 00:17:47,175
like we can get started immediately for
the visibility of the, entire system.

243
00:17:47,745 --> 00:17:55,665
And, it, it needs less, development
effort as it's a great start point for

244
00:17:55,665 --> 00:18:00,760
the teams to get started to know about
telemetry and, implementation and when

245
00:18:00,764 --> 00:18:02,145
it comes to manual instrumentation.

246
00:18:03,465 --> 00:18:08,055
So here, it gives us more flexibility
to customize the metrics and it gives

247
00:18:08,055 --> 00:18:14,774
us the precise control and we can
focus on business specific insights and

248
00:18:14,774 --> 00:18:16,575
gives us flexibility as we discussed.

249
00:18:18,075 --> 00:18:25,575
So it gives us, what we need and
why we need and when we need.

250
00:18:25,905 --> 00:18:29,415
So the manual instrumentation,
all, it takes effort.

251
00:18:29,655 --> 00:18:32,835
It gives us, the control
on what we want to see.

252
00:18:35,505 --> 00:18:39,915
And this is, the entire,
full observability stack.

253
00:18:40,395 --> 00:18:43,870
So start from the bottom
instrumentation, like adding the code.

254
00:18:45,420 --> 00:18:50,040
like SDK to your application code,
and then the collection starts.

255
00:18:50,280 --> 00:18:55,590
The data collection starts from Open
Telemetry, and then they have to be stored

256
00:18:55,590 --> 00:18:58,050
somewhere in Prometheus, lowkey tempo.

257
00:18:59,220 --> 00:19:02,250
These are different tools based
upon the type of the telemetry

258
00:19:02,250 --> 00:19:03,990
data We'll see in the next slides.

259
00:19:05,595 --> 00:19:08,535
And Grafana is, a dashboard
for visualization.

260
00:19:08,535 --> 00:19:13,125
So this is the simple pyramid, which
explains the entire, observability

261
00:19:13,125 --> 00:19:16,725
stack for any, application system.

262
00:19:19,185 --> 00:19:19,455
Yeah.

263
00:19:19,725 --> 00:19:24,675
typical observation, observability
stack components, like the collector,

264
00:19:25,130 --> 00:19:26,955
like our, open telemetry collector.

265
00:19:28,680 --> 00:19:31,470
Is like a, tracing
system, tracing collected.

266
00:19:31,470 --> 00:19:36,750
So basically it is actually a
distributed, tracing system for a request.

267
00:19:38,129 --> 00:19:43,320
so it explains us how that particular
request had the journey in our system.

268
00:19:44,370 --> 00:19:49,169
Loki, it's like law aggregation
platform, for centralized

269
00:19:49,169 --> 00:19:51,419
log management, Prometheus.

270
00:19:52,440 --> 00:19:54,090
It's basically a storage.

271
00:19:54,180 --> 00:19:54,390
Okay.

272
00:19:54,390 --> 00:19:58,620
It's a time series database for metrics
collection and storage at the end.

273
00:19:58,905 --> 00:19:59,395
Grafana.

274
00:20:00,480 --> 00:20:05,460
so this is going to give a web UI for,
visualization, dashboards and alerting.

275
00:20:07,050 --> 00:20:07,770
And the next slide.

276
00:20:08,400 --> 00:20:11,340
so this slide actually is going
to give you a overall picture.

277
00:20:12,240 --> 00:20:16,950
So this slide on the right side,
it explains so we have a VM

278
00:20:16,950 --> 00:20:22,020
one and VM two, and the data is
actually coming from two VMs.

279
00:20:23,040 --> 00:20:26,580
the fluent bit, if you see here, the
fluent bit is running on both VMs.

280
00:20:26,610 --> 00:20:27,510
So basically it's a log corrector.

281
00:20:28,500 --> 00:20:30,390
It sends the logs to the,

282
00:20:32,820 --> 00:20:33,930
open telemetry collector.

283
00:20:34,935 --> 00:20:40,785
The open tele to connector, would be
actually, collecting the logs, like

284
00:20:40,875 --> 00:20:45,855
coming from and d and other metrics
coming from the VM two, like other

285
00:20:45,855 --> 00:20:47,835
metrics, for example, for node metrics.

286
00:20:48,105 --> 00:20:51,735
So node exporter would send
different metrics, so those

287
00:20:51,735 --> 00:20:55,000
metrics would be sent to M Okay.

288
00:20:55,155 --> 00:20:58,440
And, in the backend, the,
entire data would be.

289
00:20:59,865 --> 00:21:04,935
Host into Grafana database, sorry,
into Grafana user interface.

290
00:21:06,465 --> 00:21:11,715
So here, the applications only interact
with the open tele to correct it.

291
00:21:11,775 --> 00:21:12,705
So they don't know.

292
00:21:12,705 --> 00:21:14,415
In the backend there is, low key.

293
00:21:14,415 --> 00:21:16,065
There is Mimi, there is Grafana.

294
00:21:16,545 --> 00:21:20,445
So applications simply
interact with open telemetry.

295
00:21:22,065 --> 00:21:24,375
but that's what they see in the backend.

296
00:21:24,765 --> 00:21:26,145
Open telemetry collector.

297
00:21:26,715 --> 00:21:31,185
Knows, okay, the log should
be sent to Loki and the

298
00:21:31,185 --> 00:21:32,475
metrics should be sent to Mia.

299
00:21:33,405 --> 00:21:39,195
So in this way, it reduces
a lot of complexity, for the

300
00:21:39,195 --> 00:21:41,505
applications, to interact.

301
00:21:41,505 --> 00:21:43,605
So integration is very less here.

302
00:21:45,465 --> 00:21:49,515
it would be very faster and
easy, to implement, open

303
00:21:49,515 --> 00:21:51,585
telemetry in the applications.

304
00:21:52,515 --> 00:21:54,135
that's all, from my side.

305
00:21:54,585 --> 00:21:55,725
And thank you for your time.

306
00:21:57,195 --> 00:21:57,315
A.

