1
00:00:00,500 --> 00:00:01,160
Hello everyone.

2
00:00:01,819 --> 00:00:03,380
I am N Krisna.

3
00:00:04,010 --> 00:00:07,160
I'm a technical architect with
more than 11 years of experience.

4
00:00:07,920 --> 00:00:15,420
I worked on a WS services as a developer
administrator, and I'm working as an

5
00:00:15,420 --> 00:00:19,370
architect for a services DevOps DevSecOps.

6
00:00:19,880 --> 00:00:20,540
I also.

7
00:00:21,040 --> 00:00:25,300
For performance improvement and
producing the cost to the clients.

8
00:00:25,910 --> 00:00:30,070
Today I'm going to discuss about the
topic observability with open telemetry.

9
00:00:30,490 --> 00:00:36,970
So this technical discussion will focus on
observability principles and implementing

10
00:00:36,970 --> 00:00:40,420
open telemetry in our modern systems.

11
00:00:40,935 --> 00:00:41,285
Let's.

12
00:00:41,785 --> 00:00:44,205
Understanding the observability,
by learning foundations and

13
00:00:44,205 --> 00:00:45,975
key concepts of observability.

14
00:00:46,425 --> 00:00:49,335
Then we deep different types of.

15
00:00:49,835 --> 00:00:51,455
And collection methods.

16
00:00:51,955 --> 00:00:57,355
Later we'll focus on the architecture
of Open Telemetry components and

17
00:00:57,355 --> 00:01:01,165
implementation part, which covers open
telemetry essentials as a thought topic.

18
00:01:01,665 --> 00:01:06,914
And the fourth topic would be the data
sources of open telemetry on how can

19
00:01:06,914 --> 00:01:12,375
we integrate open telemetry with other
systems, other tools in our application.

20
00:01:13,035 --> 00:01:15,225
Let's get started with the deep dive.

21
00:01:15,725 --> 00:01:20,774
Before we start in details, let's focus
on the foundations of observability.

22
00:01:21,735 --> 00:01:24,835
We talk more about tele
data over this discussion.

23
00:01:24,835 --> 00:01:27,625
So let's talk about
what is telemetry data.

24
00:01:28,315 --> 00:01:35,485
Basically, it's like a collection
and transmission of logs, events and

25
00:01:35,545 --> 00:01:37,885
measurements from various systems.

26
00:01:37,885 --> 00:01:42,500
Could be remote systems or distributed
systems to a central monitoring place.

27
00:01:43,000 --> 00:01:43,560
Analysis.

28
00:01:43,565 --> 00:01:47,425
Once we collect this data would
be used to locate the potential

29
00:01:47,485 --> 00:01:50,095
problems in the systems.

30
00:01:50,595 --> 00:01:54,244
So basically, DevOps focus on two metrics.

31
00:01:54,855 --> 00:01:56,965
Any which looks into these two metrics.

32
00:01:56,995 --> 00:01:59,815
One is called mt. Td, another is mtt.

33
00:02:00,065 --> 00:02:01,565
Mean time to detection.

34
00:02:02,205 --> 00:02:04,935
This is a time taken
to identify the issue.

35
00:02:05,435 --> 00:02:08,285
And MTTR like mean time to resolve.

36
00:02:08,915 --> 00:02:14,735
This is a time taken to resolve the
issue after the issue is detected.

37
00:02:15,395 --> 00:02:21,125
So identifying and resolving,
these are the two metrics that are

38
00:02:21,125 --> 00:02:23,345
being measured by organizations.

39
00:02:23,345 --> 00:02:27,335
How quickly we are able to
identify the issue and how

40
00:02:27,335 --> 00:02:29,165
quickly we are able to resolve.

41
00:02:29,665 --> 00:02:30,625
Monitoring methods.

42
00:02:31,615 --> 00:02:35,155
So we'll be collecting different types
of telemetry data, as we discussed

43
00:02:35,155 --> 00:02:36,495
in the previous slide, right?

44
00:02:37,245 --> 00:02:39,615
So what type of data we
are going to collect.

45
00:02:40,095 --> 00:02:42,125
So the first one is red method.

46
00:02:42,645 --> 00:02:48,315
The R represents rate E represents
errors, D represents duration rate.

47
00:02:48,735 --> 00:02:52,275
So the number of requests
coming into the system per

48
00:02:52,275 --> 00:02:54,705
second, like request per second.

49
00:02:55,380 --> 00:02:57,470
Transactions per second error.

50
00:02:58,280 --> 00:03:01,760
The number of failed transactions
or requests in our application

51
00:03:01,760 --> 00:03:04,010
or a system and the duration.

52
00:03:04,220 --> 00:03:10,400
So the response time may be per request
or per transaction from our system.

53
00:03:10,900 --> 00:03:12,940
And the second method is use method.

54
00:03:13,420 --> 00:03:17,200
In this, it focuses on
utilization of the resources.

55
00:03:18,070 --> 00:03:23,590
Like resource ation, like how much
of CPU used, how much disc is used?

56
00:03:24,070 --> 00:03:27,040
Saturation, like a Q length, for example.

57
00:03:27,040 --> 00:03:30,780
Network packets or network
requests are queing up errors.

58
00:03:31,080 --> 00:03:34,230
So it could be hardware or
software related errors.

59
00:03:34,730 --> 00:03:37,875
Say for example discre
error, discre IO error.

60
00:03:38,375 --> 00:03:40,245
These are all called as errors.

61
00:03:40,745 --> 00:03:41,945
Four golden signals.

62
00:03:41,995 --> 00:03:46,535
This method is recommended by Google
in their set liability documentation.

63
00:03:47,165 --> 00:03:52,310
So four golden signals, covers
the first first three collections,

64
00:03:52,310 --> 00:03:54,910
like red plus saturation.

65
00:03:55,690 --> 00:03:59,080
So the first topic is in
this one is the latency.

66
00:03:59,835 --> 00:04:04,995
The processing time, the delay happening
in the system traffic, the request volume

67
00:04:05,025 --> 00:04:09,345
coming into the system, that errors the
failure rates in the application of the

68
00:04:09,345 --> 00:04:14,945
system, saturation in the system load that
is happening within our operating system.

69
00:04:14,945 --> 00:04:17,450
Sir, it would be an overall
system or the application.

70
00:04:17,950 --> 00:04:19,130
And core web bottles.

71
00:04:19,940 --> 00:04:20,120
Okay.

72
00:04:20,120 --> 00:04:26,090
This is mainly focusing on the web UI or
user interfaces or webpages or websites.

73
00:04:26,570 --> 00:04:31,730
The previous three methods, what we
focused are, they focus on the system,

74
00:04:32,420 --> 00:04:37,790
the infrastructure side, system side
and services side, but core web.

75
00:04:38,290 --> 00:04:38,710
Content.

76
00:04:38,710 --> 00:04:39,370
Full paint.

77
00:04:39,430 --> 00:04:41,620
It measures loading performance.

78
00:04:42,310 --> 00:04:48,330
FID first input, delay measures,
responsiveness to user interactions.

79
00:04:48,830 --> 00:04:53,950
CLS accumulate to layout, shift
measures, visual stability during

80
00:04:53,950 --> 00:04:55,960
the load of the particular webpage.

81
00:04:56,460 --> 00:04:58,930
Now let's talk about
difference between monitoring.

82
00:04:59,430 --> 00:05:04,770
Tracks known issues and it is best for
a small systems and monolith systems.

83
00:05:05,460 --> 00:05:07,950
And it shows when the issue occurs.

84
00:05:08,450 --> 00:05:11,150
When it comes to observability,
it's a practical approach.

85
00:05:11,780 --> 00:05:16,735
It uncovers unknown unknowns ideal for
complex systems, and it shows where,

86
00:05:17,050 --> 00:05:19,060
when, and why that issue happened.

87
00:05:19,690 --> 00:05:24,000
So observability gives us more
quicker way of identify the issue.

88
00:05:24,085 --> 00:05:24,435
andSo.

89
00:05:24,935 --> 00:05:26,255
And tele data type.

90
00:05:26,255 --> 00:05:31,865
So we talked about what is tele data, what
we collect, and what type of data it is.

91
00:05:32,405 --> 00:05:34,675
So there are different types of tele data.

92
00:05:34,955 --> 00:05:36,185
One is metrics.

93
00:05:36,645 --> 00:05:39,555
It, it just explains about
the quantitative measurements,

94
00:05:39,555 --> 00:05:40,635
like what is happening.

95
00:05:40,885 --> 00:05:42,535
It comes with numbers, basically.

96
00:05:42,595 --> 00:05:42,925
Okay.

97
00:05:43,365 --> 00:05:43,905
Logs.

98
00:05:44,265 --> 00:05:48,045
So it's like timestamped events
that are decode in the system.

99
00:05:48,465 --> 00:05:49,635
So what happened when it.

100
00:05:50,135 --> 00:05:50,495
Okay.

101
00:05:51,245 --> 00:05:55,235
Traces like this is very important
when we talk about observability.

102
00:05:55,815 --> 00:06:00,075
So it gives us end-to-end request
journey within our application.

103
00:06:00,645 --> 00:06:02,235
So suppose I have five APAs.

104
00:06:02,235 --> 00:06:06,135
So the trace would help us to
identify which APAs performing

105
00:06:06,135 --> 00:06:10,995
slow, or which a PA is actually
okay, so it explains where bottle.

106
00:06:11,495 --> 00:06:16,865
The resource level diagnostics, why my
system is slow, either it is because

107
00:06:16,865 --> 00:06:22,195
of CPU utilizations or maybe garbage
corrections happening during that time.

108
00:06:22,645 --> 00:06:26,275
So this profiling will help us to
identify the resource level diagnostics.

109
00:06:26,525 --> 00:06:31,355
This is the, this slide explains
about a pictorial way of your

110
00:06:31,360 --> 00:06:33,185
observability in the motor systems.

111
00:06:33,860 --> 00:06:39,520
So here you see the application could
be in public cloud and the on prime.

112
00:06:40,120 --> 00:06:43,880
And we receive various tele data.

113
00:06:44,060 --> 00:06:49,080
So we call this melt informs e for
events and for logs and D traces.

114
00:06:49,580 --> 00:06:54,520
And this, these collected metrics would be
pushed into observability solution which

115
00:06:54,520 --> 00:06:56,360
we are going to look in future slides.

116
00:06:56,860 --> 00:07:00,970
And different teams like developers,
monitoring ops, security ops would be

117
00:07:01,240 --> 00:07:05,320
depending on the solution to identify
any issues and to resolve the problems.

118
00:07:05,820 --> 00:07:06,180
Okay?

119
00:07:06,390 --> 00:07:09,500
And this is just overall
picture of how observability

120
00:07:09,560 --> 00:07:11,520
will be in our modern systems.

121
00:07:11,770 --> 00:07:13,630
How can we collect these metrics?

122
00:07:13,690 --> 00:07:17,410
So there are two collection metrics,
actually push method and scrape method.

123
00:07:17,910 --> 00:07:21,360
The push method is like
applications will actively send

124
00:07:21,420 --> 00:07:26,130
the metrics to the collection
endpoint or TCP or UDP protocols.

125
00:07:26,380 --> 00:07:30,369
In this picture you see the backend
services is sending the metric

126
00:07:30,369 --> 00:07:36,059
to stats D. Stats D is in turn
sending that particular metric to

127
00:07:36,059 --> 00:07:38,579
graphite, which is a time database.

128
00:07:39,329 --> 00:07:43,799
Scrape method is something where
applications expose metrics.

129
00:07:44,789 --> 00:07:46,260
For collectors.

130
00:07:46,620 --> 00:07:49,629
So basically applications
won't push the data.

131
00:07:49,629 --> 00:07:54,460
Instead the collection services,
the data collectors would pull

132
00:07:54,460 --> 00:07:55,869
the data from the applications.

133
00:07:56,769 --> 00:08:00,039
Here in this example, pro
is actually scraping the

134
00:08:00,039 --> 00:08:01,749
metrics from this application.

135
00:08:02,349 --> 00:08:06,739
So basically we can say it's actually
pulling the data from the backend service.

136
00:08:07,239 --> 00:08:09,819
So when can we choose scrape?

137
00:08:09,819 --> 00:08:11,139
When can we choose push?

138
00:08:11,639 --> 00:08:16,009
So choose scrape when you're using
Kubernetes or dynamic environments

139
00:08:16,669 --> 00:08:22,089
and preferred centralized control
of your all the log management and

140
00:08:22,119 --> 00:08:24,969
when apps can expose HT pinpoints.

141
00:08:25,629 --> 00:08:26,049
Okay.

142
00:08:26,099 --> 00:08:30,879
So basically, yeah, your apps has
option to expose their endpoint.

143
00:08:31,379 --> 00:08:37,669
Especially choose the scraping choose
push when apps are shortlived and the

144
00:08:37,669 --> 00:08:42,589
real time metrics are required for us,
and apps run in restricted networks.

145
00:08:43,129 --> 00:08:49,579
So in scrape method the the apps that has
HT p endpoint exposure, yes, the script

146
00:08:49,579 --> 00:08:54,859
can be used, but when apps are running
within the restrict networks and they

147
00:08:54,859 --> 00:08:56,839
have no option to expose their end points.

148
00:08:57,229 --> 00:08:59,679
So use the push method now.

149
00:08:59,769 --> 00:09:02,549
We entered into introduction
to Open Telemetry.

150
00:09:02,799 --> 00:09:08,569
Open Telemetry is a open source framework
which standardizes generation collection

151
00:09:08,629 --> 00:09:10,839
and management of telemetry data.

152
00:09:11,469 --> 00:09:13,479
It's A-C-N-C-F project.

153
00:09:14,304 --> 00:09:18,324
Basically it's incubated under
Cloud NATO Computing Foundation.

154
00:09:18,384 --> 00:09:21,964
So same foundation is actually
managing Kubernetes as well.

155
00:09:22,954 --> 00:09:27,904
The key benefits of Open Telemetry
are it's vendor neutral and it

156
00:09:27,904 --> 00:09:31,714
supports cross languages and
multiple languages, and it provides

157
00:09:31,714 --> 00:09:37,069
standardization of data collection
and it covers a lot of, metrics like.

158
00:09:37,759 --> 00:09:45,599
Logs metrics, traces into one framework
and let's look at the open architecture.

159
00:09:45,689 --> 00:09:49,780
So the architecture of Work
Telemetry has these main components.

160
00:09:50,280 --> 00:09:57,620
Instrumentation, libraries, receivers,
collectors, processors, OTLP, protocol

161
00:09:57,965 --> 00:10:01,305
and exporters, instrumentation libraries.

162
00:10:01,880 --> 00:10:07,750
So these will enhance applications to
generate the telemetry data so that the

163
00:10:07,750 --> 00:10:14,579
application scan pump various metrics,
logs C to open telemetry, and then the

164
00:10:14,579 --> 00:10:20,729
receivers are the ones which will collect
the telemetry data from various sources.

165
00:10:21,229 --> 00:10:22,849
There could be applications as well.

166
00:10:23,749 --> 00:10:29,670
Collectors, they receive a process
and export the tele data processes.

167
00:10:30,390 --> 00:10:34,980
These processes will man plate the
data which was received and they

168
00:10:34,980 --> 00:10:40,040
transform before actually exporting
them to backend services protocol.

169
00:10:40,490 --> 00:10:44,630
It's a standardized protocol
for transforming and

170
00:10:44,630 --> 00:10:46,490
transmitting the tele data.

171
00:10:46,990 --> 00:10:51,660
Export, whatever the data that
has been mand and transformed by

172
00:10:51,660 --> 00:10:57,800
processors, the data would be exported
to external observability backs,

173
00:10:58,300 --> 00:10:59,425
open telemetry collector.

174
00:10:59,425 --> 00:11:03,690
This is a very important
component of open telemetry.

175
00:11:03,750 --> 00:11:08,520
It is a centralized executable that
receives processes and exports.

176
00:11:09,420 --> 00:11:12,890
Tele data to multiple
targets, protocol support.

177
00:11:13,610 --> 00:11:16,720
It works with all the popular
open source tele protocols.

178
00:11:17,590 --> 00:11:21,360
It acts as an intermediate tree
between the applications and

179
00:11:21,660 --> 00:11:23,010
the backend analysis tools.

180
00:11:23,510 --> 00:11:27,219
And it reduces the resource
consumption, centralize the

181
00:11:27,219 --> 00:11:29,709
configurations, and it'll improve the.

182
00:11:30,209 --> 00:11:32,430
Now we'll talk about collector components.

183
00:11:32,430 --> 00:11:37,500
The components of the collector, the
receivers, processors, and exporters.

184
00:11:38,340 --> 00:11:44,780
Receivers would be the entry points for
tele data and they accept various formats.

185
00:11:45,590 --> 00:11:47,340
Processors would be.

186
00:11:48,105 --> 00:11:55,125
Manipulating the receive data by filtering
or enriching or sampling the data and

187
00:11:55,125 --> 00:12:00,225
send it to the exporters and the exporters
would actually send the process data

188
00:12:00,735 --> 00:12:03,435
back to the backend systems for analysis.

189
00:12:03,935 --> 00:12:07,880
And there are two more components are
part of optional components of collector.

190
00:12:08,540 --> 00:12:11,840
Connectors, they facilitate the
connection or communication between

191
00:12:12,200 --> 00:12:17,940
the pipelines and they transform
different signal types enable a

192
00:12:17,940 --> 00:12:20,900
multi-stage processing flows, extensions.

193
00:12:20,930 --> 00:12:24,350
Basically, they enrich the
component capabilities and

194
00:12:25,040 --> 00:12:27,170
the performance analysis and.

195
00:12:27,670 --> 00:12:30,860
This is a simple a typical
collector pipeline could be.

196
00:12:31,670 --> 00:12:36,380
So the receivers would be receiving
the data from various sources and

197
00:12:36,380 --> 00:12:41,560
they send it to the processors, which
the process in turn will transform

198
00:12:41,560 --> 00:12:45,629
the data and send it to the exporters
and the pipeline can have multiple

199
00:12:45,629 --> 00:12:49,670
receivers, multiple processes, and
multiple exporters in a single pipeline.

200
00:12:50,170 --> 00:12:53,540
And so we are talking about
open Telemetry would receive the

201
00:12:53,790 --> 00:12:56,850
telemetry data from various sources.

202
00:12:56,910 --> 00:12:58,350
So what are those data sources?

203
00:12:58,950 --> 00:13:03,480
Typical data sources of open telemetry
are application instrumentation.

204
00:13:03,980 --> 00:13:06,740
Basically apps using the sdk.

205
00:13:07,160 --> 00:13:13,190
So they send the telemetry data,
log CS metrics to open telemetry.

206
00:13:13,460 --> 00:13:16,220
So basically applications
are one of the data sources.

207
00:13:16,760 --> 00:13:19,280
And the next ones could be service mesh.

208
00:13:19,730 --> 00:13:23,600
So the traffic metrics and
traces from the service.

209
00:13:23,600 --> 00:13:27,390
But mesh tools like SIO are
one of the data sources.

210
00:13:28,170 --> 00:13:30,720
The next one could be node level metrics.

211
00:13:31,440 --> 00:13:33,960
So data from so this is from Kubernetes.

212
00:13:34,510 --> 00:13:37,750
The data coming from ATE about
the nodes and running pods

213
00:13:38,500 --> 00:13:39,880
are also the data sources.

214
00:13:40,380 --> 00:13:45,350
Kubernetes events, cluster events
providing insights into system activities.

215
00:13:45,350 --> 00:13:50,150
This is also one of the data source
and the other sources for telemetry.

216
00:13:50,650 --> 00:13:56,560
Flu and fluent, which will
collect the data of the logs.

217
00:13:56,560 --> 00:14:01,300
So basically they collect the logs
from the containers within the cluster

218
00:14:01,300 --> 00:14:04,780
and they forwards to open telemetry.

219
00:14:05,280 --> 00:14:10,550
And various metrics coming from cloud
providers like AWS and GCP and liveliness

220
00:14:10,550 --> 00:14:14,740
and readiness data which is, which
we call probes and health checks that

221
00:14:14,740 --> 00:14:20,655
are coming from Kubernetes clusters
and the container runtime data, like

222
00:14:20,715 --> 00:14:25,805
the metrics about container states
and resource of those containers can

223
00:14:25,805 --> 00:14:28,365
also be sources for open telemetry.

224
00:14:28,865 --> 00:14:32,375
And coming to the implementation
approach for open telemetry.

225
00:14:32,925 --> 00:14:37,165
So there are two ways auto instrumentation
and manual instrumentation.

226
00:14:37,915 --> 00:14:42,435
So automatic instrumentation basically
it's a call auto instrumentation, like

227
00:14:42,435 --> 00:14:45,880
we can get started immediately for
the visibility of the entire system.

228
00:14:46,450 --> 00:14:52,545
And it, it needs less development
effort as it's a great start point for

229
00:14:52,545 --> 00:14:56,770
the teams to get started to know about
telemetry and implementation and when

230
00:14:56,775 --> 00:14:58,155
it comes to manual instrumentation.

231
00:14:58,655 --> 00:15:03,245
So here, it gives us more flexibility
to customize the metrics and it gives

232
00:15:03,245 --> 00:15:09,265
us the precise control and we can
focus on business specific insights and

233
00:15:09,265 --> 00:15:11,095
gives us flexibility as we discussed.

234
00:15:11,595 --> 00:15:17,885
So it gives us what we need and
why we need and when we need.

235
00:15:18,215 --> 00:15:21,725
So the manual instrumentation,
all, it takes effort.

236
00:15:21,965 --> 00:15:24,815
It gives us the control
on what we want to see.

237
00:15:25,315 --> 00:15:28,200
And this is the entire full stack.

238
00:15:28,680 --> 00:15:32,430
So start from the bottom
instrumentation, like adding the code.

239
00:15:32,925 --> 00:15:37,545
Like SDK to your application code,
and then the collection starts.

240
00:15:37,785 --> 00:15:43,095
The data collection starts from Open
Telemetry, and then they have to be stored

241
00:15:43,095 --> 00:15:45,555
somewhere in Prometheus, lowkey tempo.

242
00:15:46,055 --> 00:15:49,085
These are different tools based
upon the type of the telemetry

243
00:15:49,085 --> 00:15:50,825
data We'll see in the next slides.

244
00:15:51,325 --> 00:15:53,895
And Grafana is a dashboard
for visualization.

245
00:15:53,895 --> 00:15:57,695
So this is the simple pyramid, which
explains the entire observability

246
00:15:57,695 --> 00:16:00,345
stack for any application system.

247
00:16:00,845 --> 00:16:01,115
Yeah.

248
00:16:01,165 --> 00:16:06,245
Typical observation observability stack
components like the collector like our, is

249
00:16:06,245 --> 00:16:08,320
like a tracing system tracing collected.

250
00:16:08,320 --> 00:16:13,260
So basically it is actually a
distributed tracing system for a request.

251
00:16:13,950 --> 00:16:18,690
So it explains us how that particular
request had the journey in our system.

252
00:16:19,570 --> 00:16:24,420
Loki it's like law aggregation platform
for centralized log management.

253
00:16:24,920 --> 00:16:26,570
It's basically a storage.

254
00:16:26,660 --> 00:16:26,900
Okay.

255
00:16:26,900 --> 00:16:31,100
It's a time series database for metrics
collection and storage at the end.

256
00:16:31,165 --> 00:16:31,655
Grafana.

257
00:16:32,240 --> 00:16:37,010
So this is going to give a web UI for
visualization, dashboards and alerting.

258
00:16:37,510 --> 00:16:38,440
And the next slide.

259
00:16:38,490 --> 00:16:41,430
So this slide actually is going
to give you a overall picture.

260
00:16:42,330 --> 00:16:46,800
So this slide on the right side,
it explains so we have a VM

261
00:16:46,800 --> 00:16:51,460
one and VM two, and the data is
actually coming from two VMs.

262
00:16:52,220 --> 00:16:55,550
The fluent bit, if you see here the
fluent bit is running on both VMs.

263
00:16:55,580 --> 00:16:56,480
So basically it's a log corrector.

264
00:16:57,470 --> 00:17:00,480
It sends the logs to the open.

265
00:17:00,980 --> 00:17:05,880
The open tele to connector would be
actually collecting the logs, like coming

266
00:17:05,880 --> 00:17:11,100
from and d and other metrics coming
from the VM two, like other metrics,

267
00:17:11,160 --> 00:17:15,270
for example, for node metrics, so node
exporter would send different metrics,

268
00:17:15,750 --> 00:17:18,040
so those metrics would be sent to M Okay.

269
00:17:18,195 --> 00:17:19,075
And the.

270
00:17:19,575 --> 00:17:24,420
Host into Grafana database, sorry,
into Grafana user interface.

271
00:17:24,920 --> 00:17:29,940
So here the applications only interact
with the open tele to correct it.

272
00:17:30,000 --> 00:17:30,930
So they don't know.

273
00:17:30,930 --> 00:17:32,490
In the backend there is low key.

274
00:17:32,490 --> 00:17:34,140
There is Mimi, there is Grafana.

275
00:17:34,620 --> 00:17:38,520
So applications simply
interact with open telemetry.

276
00:17:38,780 --> 00:17:41,090
But that's what they see in the backend.

277
00:17:41,480 --> 00:17:42,290
Open telemetry.

278
00:17:42,790 --> 00:17:47,260
Knows, okay, the log should
be sent to Loki and the

279
00:17:47,260 --> 00:17:48,550
metrics should be sent to Mia.

280
00:17:49,480 --> 00:17:53,750
So in this way it reduces
a lot of complexity for the

281
00:17:53,750 --> 00:17:55,680
applications to interact.

282
00:17:55,680 --> 00:17:57,780
So integration is very less here.

283
00:17:58,190 --> 00:18:01,520
It would be very faster
and easy to implement open

284
00:18:01,520 --> 00:18:03,380
telemetry in the applications.

285
00:18:04,260 --> 00:18:05,320
That's all my side.

286
00:18:05,710 --> 00:18:06,220
And thank you.

287
00:18:06,720 --> 00:18:06,840
A.

