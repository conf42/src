1
00:00:00,120 --> 00:00:02,710
Hi everyone and welcome.

2
00:00:02,740 --> 00:00:07,059
I'm very glad to be here
at Conf42 DevOps 2025.

3
00:00:07,060 --> 00:00:08,629
This is the first Conf of the year.

4
00:00:09,090 --> 00:00:13,110
Today I want to talk to you about how
you can pimp your Kubernetes job shooting

5
00:00:13,129 --> 00:00:16,169
skills using something called KCPT.

6
00:00:16,709 --> 00:00:22,279
We'll explore how this AI powered tool
can bring real time insights and help

7
00:00:22,279 --> 00:00:24,449
you resolve your key issues faster.

8
00:00:25,134 --> 00:00:29,354
And more effectively, but before we
get started, let me do a quick intro.

9
00:00:29,854 --> 00:00:32,404
My name is, Cocella AKA cloud dude.

10
00:00:32,464 --> 00:00:35,574
I'm a founder and principal
consultant at cloud thrill.

11
00:00:35,624 --> 00:00:39,094
I have almost, roughly two
decades, almost two decades of

12
00:00:39,225 --> 00:00:41,775
experience in IT and Oracle tech.

13
00:00:42,130 --> 00:00:46,180
I know specialize in multi
cloud operations, DevSecOps,

14
00:00:46,250 --> 00:00:48,920
and a tiny bit of AI inference.

15
00:00:49,400 --> 00:00:53,100
there's not much more to say that
I'm a huge cloud and automation fan.

16
00:00:53,489 --> 00:00:56,859
And I share all my labs
and discoveries on my blog.

17
00:00:56,939 --> 00:00:57,679
now it's cloud.

18
00:00:57,819 --> 00:00:59,200
ca slash blog.

19
00:00:59,519 --> 00:01:02,609
And in my GitHub repost, that's, github.

20
00:01:02,669 --> 00:01:04,209
com slash workdba.

21
00:01:04,384 --> 00:01:05,304
That's not a handle.

22
00:01:05,474 --> 00:01:06,114
Sorry about that.

23
00:01:06,564 --> 00:01:10,364
I'm also the host of TechBeats
Unplugged podcast since a year,

24
00:01:10,364 --> 00:01:11,944
which I'm very excited about.

25
00:01:12,314 --> 00:01:17,574
you can find a cool episode where
I hosted Kelsey Hightower, chilling

26
00:01:17,584 --> 00:01:19,555
about DevOps for almost two hours.

27
00:01:19,945 --> 00:01:22,744
So, please, check the QR code.

28
00:01:23,739 --> 00:01:25,919
If that content, speaks to you.

29
00:01:26,919 --> 00:01:27,389
Okay.

30
00:01:27,869 --> 00:01:29,349
No, that we're done with the intro.

31
00:01:29,369 --> 00:01:31,319
Let's get, to the reason
why we all here today.

32
00:01:31,829 --> 00:01:32,129
Right.

33
00:01:32,149 --> 00:01:33,279
Which is the agenda.

34
00:01:33,779 --> 00:01:35,319
So why are we going to talk about today?

35
00:01:35,689 --> 00:01:39,649
Well, first, we'll talk a bit about,
context and compare, what AI is

36
00:01:39,650 --> 00:01:44,069
good at, versus a traditional job
shooting methods and challenges.

37
00:01:44,604 --> 00:01:48,824
Then in Section 2, we'll learn
more about what's KSGPT, really.

38
00:01:48,824 --> 00:01:52,624
We'll explore key features,
benefits, along with some specs

39
00:01:52,624 --> 00:01:54,934
and AI backends and installations.

40
00:01:55,544 --> 00:01:59,974
Then in Section 3, we'll dive into
all the KSGPT commands you need

41
00:01:59,974 --> 00:02:05,874
to work with and describe basic
and the operator architecture.

42
00:02:06,344 --> 00:02:11,514
Because, you know, there's a CLI and
there's also in cluster, installation.

43
00:02:12,434 --> 00:02:17,694
And finally, we'll have some fun with
a little, demo that I will be, running.

44
00:02:17,954 --> 00:02:20,054
So I hope you will like it.

45
00:02:20,554 --> 00:02:23,374
Okay, but let me start
with the memes, actually.

46
00:02:23,684 --> 00:02:29,399
So Of course, AI, today is stirring up
endless headaches across tech industries.

47
00:02:29,609 --> 00:02:33,489
I don't know if you heard, but Mark
Zuckerberg recently announced AI will

48
00:02:33,519 --> 00:02:37,039
replace his mid level engineers by 2025.

49
00:02:37,539 --> 00:02:40,139
That's a scary thing to tell
your engineers if you ask me.

50
00:02:40,479 --> 00:02:45,209
But hey, this is the same guy who burned
almost 50 billion dollars on Metaverse.

51
00:02:45,994 --> 00:02:46,494
Remember?

52
00:02:47,074 --> 00:02:48,754
so who's right?

53
00:02:48,924 --> 00:02:50,344
will AI replace your job?

54
00:02:51,334 --> 00:02:56,174
Maybe, maybe not, but it
certainly won't hurt you to use

55
00:02:56,214 --> 00:02:58,604
AI today to do your job better.

56
00:02:59,014 --> 00:03:00,284
at least that's my opinion.

57
00:03:00,784 --> 00:03:05,304
On the flip side, you don't want to
completely depend on GPT for your

58
00:03:05,314 --> 00:03:06,944
technical growth in the company, right?

59
00:03:07,394 --> 00:03:11,194
Cause it's not healthy and
fundamentals are still important.

60
00:03:11,694 --> 00:03:16,314
So the key is, is really finding
the balance between the two.

61
00:03:17,019 --> 00:03:20,479
all right, done with the
meme, back to business.

62
00:03:20,879 --> 00:03:25,739
I am not going to talk about what is
AI, but it's important to highlight

63
00:03:25,740 --> 00:03:28,460
some key events or concepts, right?

64
00:03:28,520 --> 00:03:30,499
This is just a language model history.

65
00:03:30,499 --> 00:03:35,510
That's like a timeline of what
happened, and, and when, but I could

66
00:03:35,510 --> 00:03:39,220
also, explain the, We can start
to explain neural networks, right?

67
00:03:39,220 --> 00:03:40,830
So what is a neural network?

68
00:03:41,120 --> 00:03:45,189
Well, neural network, is a network
that helps analyze different, complex

69
00:03:45,189 --> 00:03:49,229
data like text, image, video or audio.

70
00:03:49,579 --> 00:03:53,159
but there are many types of
networks depending on, on the data.

71
00:03:53,904 --> 00:03:55,694
The type of data that you have, right?

72
00:03:55,874 --> 00:04:00,014
For example, for analyzing images,
you'd have to use CNN, which is

73
00:04:00,014 --> 00:04:01,504
Convolutional Neural Network.

74
00:04:01,694 --> 00:04:05,434
This is also used in your
test labs to avoid obstacles.

75
00:04:05,564 --> 00:04:09,764
For text, you would need to use RNN,
which is Recurrent Neural Network.

76
00:04:09,954 --> 00:04:13,804
That's the ancestry, the ancestor
of, recurrent language models.

77
00:04:14,024 --> 00:04:14,374
Right.

78
00:04:14,634 --> 00:04:19,244
The back then there was no record, for
example, of the order of the words,

79
00:04:19,494 --> 00:04:21,234
and he couldn't handle large texts.

80
00:04:21,504 --> 00:04:24,534
So it would forget the first word
by the time it gets to the last one.

81
00:04:24,904 --> 00:04:25,194
Right.

82
00:04:25,434 --> 00:04:27,644
And it was also running sequentially.

83
00:04:28,194 --> 00:04:31,454
So what really happened after that period?

84
00:04:32,204 --> 00:04:37,044
Well, although OpenAI opened up shop
in 2015, what's considered the game

85
00:04:37,044 --> 00:04:43,374
changer in these LLM journey is the
introduction of Transformers architecture.

86
00:04:43,374 --> 00:04:43,424
Sure.

87
00:04:43,784 --> 00:04:49,624
Right back in 2016 and 17, by
researchers from Google and your

88
00:04:49,654 --> 00:04:55,424
University of Toronto, the paper was
called attention is all you need.

89
00:04:55,764 --> 00:05:00,004
And this really marked the shift
from the sequential to self

90
00:05:00,004 --> 00:05:04,664
attention, bringing, More features
like, positional encoding for word

91
00:05:04,704 --> 00:05:06,774
ordering, which is very important.

92
00:05:07,124 --> 00:05:12,174
and also attention, which allows to
more accurate translation, of the words.

93
00:05:12,204 --> 00:05:15,944
Let's say, for example, you
take a sentence, in English,

94
00:05:15,994 --> 00:05:17,244
European union, right?

95
00:05:17,244 --> 00:05:18,904
You would like to translate into French.

96
00:05:18,905 --> 00:05:23,127
Well, in French, it's not
neutral, like in English.

97
00:05:23,127 --> 00:05:24,534
It's l'Union EuropÃ©enne.

98
00:05:24,794 --> 00:05:28,164
Right, so this is a completely
different gender, right?

99
00:05:28,164 --> 00:05:32,814
So the attention is attaching the
right gender link between the words or

100
00:05:32,814 --> 00:05:35,494
flipping them due to the training data.

101
00:05:35,804 --> 00:05:39,864
You also get self attention that allows
the underlying meaning of the words.

102
00:05:40,194 --> 00:05:45,084
I'm talking about grammar, Gender
and tense aware and context aware

103
00:05:45,084 --> 00:05:47,104
synonymous, all that kind of stuff.

104
00:05:47,294 --> 00:05:52,284
And this is on top of handling huge data
sets of gigs and gigs and terabytes.

105
00:05:52,784 --> 00:05:59,124
So the transformer was the discovery, the
big breakthrough that laid the groundwork

106
00:05:59,144 --> 00:06:04,494
for subsequent groundbreaking models up
to the GPT, and nowadays models, right?

107
00:06:04,534 --> 00:06:05,144
And beyond.

108
00:06:05,424 --> 00:06:10,754
Right that there's a link, actually in
the slide, if you want to learn more and

109
00:06:10,764 --> 00:06:15,344
dive deep into it, into the timeline,
but bottom line is the transformers is

110
00:06:15,354 --> 00:06:19,604
why, we're, using GPT chat GPT today.

111
00:06:20,194 --> 00:06:20,554
Right.

112
00:06:20,594 --> 00:06:24,354
So I hope he was, was informative
enough and he gives you, he gave

113
00:06:24,354 --> 00:06:26,904
you a glimpse of the timeline.

114
00:06:27,404 --> 00:06:29,674
Now let's talk about what AI is great at.

115
00:06:30,174 --> 00:06:31,664
It is of course, very good at.

116
00:06:32,299 --> 00:06:35,809
Pattern recognition, looking at
the repetition of a lot of noise,

117
00:06:36,239 --> 00:06:41,729
translation, translate noise into a
signal, and prediction, predicting

118
00:06:41,729 --> 00:06:44,119
the next token, for example, right?

119
00:06:44,519 --> 00:06:48,799
But that's also funny because the
problems we usually struggle with as

120
00:06:48,839 --> 00:06:55,219
SREs and KS clusters are also pattern
recognition, translation, and prediction.

121
00:06:55,739 --> 00:06:56,089
Right.

122
00:06:56,149 --> 00:07:00,549
For example, when you consider the
failures from your workload, the nodes,

123
00:07:00,819 --> 00:07:07,559
the back end and how to actually spot
these patterns, we have also challenges

124
00:07:07,559 --> 00:07:13,379
in how to find out how did something go
wrong and why, which can very be very

125
00:07:13,419 --> 00:07:16,059
complex in Kubernetes clusters, right?

126
00:07:16,069 --> 00:07:18,454
How to correlate those
errors throughout the stack.

127
00:07:18,984 --> 00:07:25,274
The stack, we also have trouble
forecasting or, do some capacity plan.

128
00:07:25,774 --> 00:07:28,144
And, let's say you have a stateful set.

129
00:07:28,264 --> 00:07:30,714
Like I'm just like showing an example.

130
00:07:31,194 --> 00:07:34,904
You have a PVC failure, because
something went wrong with, any other

131
00:07:34,904 --> 00:07:36,764
layer, like the storage, right?

132
00:07:37,064 --> 00:07:41,964
when this happened, You got a lot of
reasons that could lead to this issue.

133
00:07:42,284 --> 00:07:46,574
I'm taking, one managed cluster
in the cloud, for example, OCI.

134
00:07:46,584 --> 00:07:48,574
It could be in any, cloud managed cluster.

135
00:07:48,864 --> 00:07:54,514
let's say that issue that you can have
in a PVC could be because of the wrong

136
00:07:54,514 --> 00:07:59,594
storage class, or it could be because of
the, block storage used with, Was used

137
00:07:59,594 --> 00:08:05,264
with the wrong file system like xt, four,
XT four instead of XFS, for the PV with

138
00:08:05,264 --> 00:08:10,614
the CSI plugin, or somebody just went to
the console and, changed the parameter,

139
00:08:10,894 --> 00:08:16,094
of the file storage that was dynamically,
generated or created by CSI plugin.

140
00:08:16,094 --> 00:08:18,944
So all these can happen
can be the source of your.

141
00:08:19,479 --> 00:08:19,919
Issue.

142
00:08:19,969 --> 00:08:23,159
But how do we correlate all this today?

143
00:08:23,219 --> 00:08:26,849
Like, oftentimes it's painful as
this involves very deep knowledge,

144
00:08:27,349 --> 00:08:30,139
and in every layer of the stack.

145
00:08:30,379 --> 00:08:32,489
And obviously, right?

146
00:08:32,489 --> 00:08:36,869
So once you pass the euphoria of day
zero after deploying a cluster, moving on

147
00:08:36,869 --> 00:08:41,999
your application in your, in your past,
with time, then you realize how painful.

148
00:08:42,244 --> 00:08:47,434
It is to troubleshoot clusters in
production, and the more clusters grow in

149
00:08:47,434 --> 00:08:52,144
size and complexity, the more difficult
spotting the root cause of issues becomes,

150
00:08:52,794 --> 00:08:58,674
especially when multiple components are
added every day from different teams

151
00:08:58,674 --> 00:09:04,424
like ingress, storage, services, CRDs,
operators, you name it, are involved.

152
00:09:04,904 --> 00:09:09,204
Each time you add a Helm chart
or an operator, things can break.

153
00:09:09,964 --> 00:09:11,584
And of course, first thing you do.

154
00:09:11,969 --> 00:09:15,909
Is check the error message or
traces, but they're often cryptic.

155
00:09:15,909 --> 00:09:19,309
Like you wouldn't even know where
the problem is coming from while

156
00:09:19,319 --> 00:09:20,949
sifting through the piles of logs.

157
00:09:21,339 --> 00:09:25,629
thing is many Kubernetes issues
are Linux issues under cover.

158
00:09:26,069 --> 00:09:27,949
You have sometimes you limit issues.

159
00:09:27,949 --> 00:09:32,589
You got system D config issues
and always issues, right?

160
00:09:32,639 --> 00:09:35,699
And the sheer volume of
logs and events and metrics.

161
00:09:36,044 --> 00:09:39,944
In Splunk or any other login system
that needs to be analyzed makes

162
00:09:39,944 --> 00:09:41,904
the remediation painfully long.

163
00:09:42,834 --> 00:09:48,524
And that leads to, that will
slow down your operations or

164
00:09:48,524 --> 00:09:52,604
causing even longer downtime as
we all experienced in the past.

165
00:09:53,414 --> 00:09:57,634
And to make matters worse, all
the best SREs that you have,

166
00:09:57,644 --> 00:09:58,984
they hold that knowledge of.

167
00:09:59,194 --> 00:10:03,844
How every piece works, but could never put
that into paper or documentation because

168
00:10:04,114 --> 00:10:09,374
it's so immense, they don't have time or
it's based on a decade of, experience, so

169
00:10:09,374 --> 00:10:14,644
it stays in their head forever and never
shared with the junior, junior series.

170
00:10:15,054 --> 00:10:15,414
Right.

171
00:10:15,534 --> 00:10:19,754
So imagine how challenging the onboarding
could be, or the first day on call for

172
00:10:19,754 --> 00:10:21,994
a junior, pretty, pretty challenging.

173
00:10:22,124 --> 00:10:23,384
I, I, I must guess.

174
00:10:23,804 --> 00:10:28,174
and, as shown here, once the failure
happens, we have only limited window,

175
00:10:28,414 --> 00:10:31,534
to filter the signal through the noise
and God knows we have a lot of noise

176
00:10:31,534 --> 00:10:33,784
sometimes to get the clarification.

177
00:10:33,994 --> 00:10:34,254
Right?

178
00:10:34,434 --> 00:10:39,244
So this is the kind of issues, a
conundrum, SRAs find themselves

179
00:10:39,244 --> 00:10:40,964
into, during the troubleshooting.

180
00:10:41,434 --> 00:10:44,964
But what is interesting also is
that there is always a pattern that

181
00:10:44,964 --> 00:10:48,844
can be extracted from these use
cases, throughout the lifecycle

182
00:10:48,934 --> 00:10:51,514
of the cluster or of the workload.

183
00:10:51,524 --> 00:10:53,314
So what if we can?

184
00:10:53,724 --> 00:10:58,444
Codify those repeatable conditions
for those failure mods, in order

185
00:10:58,444 --> 00:11:04,474
to get closer to a best guess or a
best effort, type of advice, right?

186
00:11:04,474 --> 00:11:06,284
So what can we do about this?

187
00:11:07,204 --> 00:11:13,114
Well, fortunately for us, some people
start to work on the issue and this,

188
00:11:13,214 --> 00:11:18,264
inspired, people like Alex, John, Alex
Johnson, and a bunch of, maintainers.

189
00:11:18,609 --> 00:11:20,009
I had to create case you pt.

190
00:11:20,499 --> 00:11:22,049
So what is case you pt really?

191
00:11:22,099 --> 00:11:27,879
Well, simply put, it's just a tool that
scans your cluster diagnose and triage

192
00:11:27,879 --> 00:11:31,359
your issues and enrich it, using L.

193
00:11:31,359 --> 00:11:31,679
L.

194
00:11:31,679 --> 00:11:31,869
M.

195
00:11:31,879 --> 00:11:31,959
S.

196
00:11:31,959 --> 00:11:32,379
Or A.

197
00:11:32,379 --> 00:11:32,529
I.

198
00:11:32,549 --> 00:11:33,139
Backends.

199
00:11:33,359 --> 00:11:37,319
Even if you're not seasoned
expert, think of it as a guru.

200
00:11:37,599 --> 00:11:41,729
That would filter the relevant info
from the noise on your behalf and come

201
00:11:41,729 --> 00:11:44,509
up with advices, to fix your problems.

202
00:11:44,589 --> 00:11:44,909
Right.

203
00:11:45,189 --> 00:11:46,449
Sounds like magic, right?

204
00:11:47,069 --> 00:11:50,789
So in a nutshell, this project is
an open source project that was

205
00:11:50,789 --> 00:11:54,589
donated to CNCF, I think a couple
of years ago, with more than 92

206
00:11:54,590 --> 00:11:57,609
contributors, 6, 000 stars in GitHub.

207
00:11:57,609 --> 00:11:59,219
Feel free to give it a star too.

208
00:11:59,619 --> 00:12:04,499
And it allows fast reach with
AI health and issues analysis.

209
00:12:04,829 --> 00:12:09,169
The best part, it has an SRE
experience codified into 19 analyzers.

210
00:12:09,199 --> 00:12:11,829
We'll talk about it,
deeper, in the next slide.

211
00:12:12,179 --> 00:12:16,779
and it converts the complex signal
into understandable suggestions.

212
00:12:16,969 --> 00:12:20,119
This is like the best part where
like you get the, the suggestions

213
00:12:20,119 --> 00:12:23,409
that is, understandable and
ready to use as solution.

214
00:12:24,224 --> 00:12:26,524
It also supports over 12 AI endpoints.

215
00:12:26,554 --> 00:12:29,734
I'm saying 12, but maybe,
it got bigger, right?

216
00:12:29,734 --> 00:12:35,274
So think of any type of, AI endpoints
you could, you could imagine, right?

217
00:12:35,274 --> 00:12:39,764
So, they support open AI, local
AI, cohere, hug and face, all

218
00:12:39,764 --> 00:12:41,774
online, other cloud AI solutions.

219
00:12:41,815 --> 00:12:45,745
I'm saying talking about Azure
open AI, Amazon bedrocks,

220
00:12:45,755 --> 00:12:48,765
Google Vertex, OCI gen, AI.

221
00:12:48,785 --> 00:12:50,895
So the, the whole package.

222
00:12:51,710 --> 00:12:55,560
And last but not least, security,
because security is important.

223
00:12:56,080 --> 00:13:00,630
So KCPT also integrates with,
dynamic scanning tools like Trivi

224
00:13:00,900 --> 00:13:05,570
for a CVE review or scanning,
which is, which is pretty cool.

225
00:13:05,750 --> 00:13:08,180
It's also, integrated with Prometheus.

226
00:13:08,180 --> 00:13:11,400
I will talk about, further
plugins, in the common, slides.

227
00:13:11,780 --> 00:13:16,249
But, as I say, like case GPT
gives the Kubernetes, Kubernetes,

228
00:13:16,250 --> 00:13:19,010
superpowers to everyone, right?

229
00:13:19,340 --> 00:13:24,540
So, because it makes the process so
easy through a one liner instead of a

230
00:13:24,550 --> 00:13:29,120
sick and through like so many commands
that it becomes a no brainer, for

231
00:13:29,160 --> 00:13:33,220
anyone who's stuck and needs help with
Kubernetes, anywhere, no matter how

232
00:13:33,230 --> 00:13:37,470
junior, you could be, and this can
save you, tons of hours, that for sure.

233
00:13:37,970 --> 00:13:39,370
Key features of KGPT.

234
00:13:39,540 --> 00:13:42,690
Well, the bottom line needs to
remember is everything is built around

235
00:13:42,700 --> 00:13:45,650
work smarter, not harder, right?

236
00:13:45,820 --> 00:13:49,760
So we already said that it's,
it has a codified SRA knowledge,

237
00:13:50,080 --> 00:13:53,400
the guru part, that knows what to
look for, where to look for it.

238
00:13:53,710 --> 00:13:57,410
And also the AI would cut through the
noise and give you that suggestion.

239
00:13:57,790 --> 00:13:58,560
That's not all.

240
00:13:59,335 --> 00:14:03,905
Because case GPT is only paper
with AI to improve the text output.

241
00:14:04,285 --> 00:14:10,085
The real secret though, real secret
sauce is the built in analyzers.

242
00:14:10,385 --> 00:14:15,405
And there are 19 covering most
of Kubernetes resources, right?

243
00:14:15,985 --> 00:14:22,815
So we can see here you have a replica
set service, ingress, stateful set, node,

244
00:14:23,135 --> 00:14:26,265
network policy, pod deployments, PVCs.

245
00:14:26,265 --> 00:14:26,669
Cheers.

246
00:14:26,790 --> 00:14:27,630
You name it, right?

247
00:14:27,630 --> 00:14:31,080
So all of those are actually, analyzers.

248
00:14:31,110 --> 00:14:32,570
They call them filters as well.

249
00:14:32,590 --> 00:14:36,790
The we're a low, case you PT to get
the information needed from, those,

250
00:14:37,050 --> 00:14:39,210
primitives from the API server.

251
00:14:39,560 --> 00:14:39,910
Right.

252
00:14:40,360 --> 00:14:45,000
And the good thing is that you can even
build yourself, new and custom analyzers,

253
00:14:45,240 --> 00:14:49,430
if you want to, because it's supported and
you can contribute back to the project.

254
00:14:49,430 --> 00:14:50,750
So that's, that's the cool part of it.

255
00:14:51,650 --> 00:14:52,040
Right.

256
00:14:52,460 --> 00:14:54,100
And then we have anonymization.

257
00:14:54,235 --> 00:14:59,485
So we know that usually, even when you
have an issue with troubleshooting,

258
00:14:59,545 --> 00:15:02,445
with vendors, they can allow
you to sanitize the content.

259
00:15:02,455 --> 00:15:06,525
You don't want to send your sensitive
data, to, to your funder, let

260
00:15:06,525 --> 00:15:08,655
alone, open AI or cohere, right?

261
00:15:08,875 --> 00:15:12,095
So case GPT offers a way to mask the data.

262
00:15:12,365 --> 00:15:16,585
As you can see here, you have the
error reported during the analysis.

263
00:15:16,795 --> 00:15:19,025
We have a stateful set with a full name.

264
00:15:19,350 --> 00:15:19,690
Right.

265
00:15:19,780 --> 00:15:21,160
So that's the original data.

266
00:15:21,190 --> 00:15:24,870
That's not, that's not masked and
what GPT does when you specify the

267
00:15:24,870 --> 00:15:27,720
anonymization, it will mask that data.

268
00:15:27,740 --> 00:15:32,530
That name will be masked before being
packaged into the payload and then sent

269
00:15:32,530 --> 00:15:38,420
to the AI, back end once it's received
and then the variances run on that

270
00:15:38,480 --> 00:15:44,200
input, the AI back end would send back
the information and GPT We'll actually,

271
00:15:44,580 --> 00:15:49,800
process that solution return to the user
and amass the data that was amassed.

272
00:15:49,800 --> 00:15:54,560
As you can see here, you can
see that the final output return

273
00:15:54,560 --> 00:15:56,660
to the user has the right NAM.

274
00:15:56,660 --> 00:15:59,200
So the user would know which
resource are we talking about.

275
00:15:59,505 --> 00:15:59,755
Right.

276
00:15:59,765 --> 00:16:04,765
So that's, the cool part, but be
aware that, some analyzers, not

277
00:16:04,765 --> 00:16:06,605
everything is masked, unfortunately.

278
00:16:06,805 --> 00:16:12,405
So you get, some resources like advance,
replica said pod PVCs aren't, which might,

279
00:16:12,735 --> 00:16:16,005
be problematic in some situations, but.

280
00:16:16,660 --> 00:16:18,440
What option do we have
to solve the problem?

281
00:16:19,150 --> 00:16:25,570
Well, I do have one and that's just
me, but you can go fully private using

282
00:16:25,580 --> 00:16:30,440
local LLMs because you can have an
inference server in the, in the, in

283
00:16:30,460 --> 00:16:34,970
within your data center and you wouldn't
have to worry about sending, sensitive

284
00:16:35,010 --> 00:16:39,170
information to open AI or cohere because
everything is within your data center.

285
00:16:39,170 --> 00:16:39,420
So.

286
00:16:39,730 --> 00:16:40,620
That's more safety.

287
00:16:41,120 --> 00:16:43,400
Anyway, we also have remote caching.

288
00:16:44,250 --> 00:16:48,880
So remote caching also allows to
afloat the cache data to a remote

289
00:16:48,880 --> 00:16:54,880
storage service like S3 or Azure
Blob Storage, stuff like that for

290
00:16:54,890 --> 00:16:57,730
persistency and also sort of relief.

291
00:16:57,930 --> 00:17:00,820
your server, from, storage pressure.

292
00:17:01,040 --> 00:17:04,750
I'm talking specifically for
cases where you have, case GPT

293
00:17:04,800 --> 00:17:06,490
installed as an operator, right?

294
00:17:06,650 --> 00:17:12,390
So you will just, move that storage
out of your nodes, in order just to

295
00:17:12,450 --> 00:17:14,360
release a little bit of, of space.

296
00:17:14,610 --> 00:17:14,970
Right.

297
00:17:15,070 --> 00:17:16,799
And what are these?

298
00:17:16,800 --> 00:17:17,810
Why are these data?

299
00:17:17,860 --> 00:17:18,090
Right.

300
00:17:18,210 --> 00:17:21,020
I was first asked myself,
like, what kind of data can be

301
00:17:21,020 --> 00:17:23,120
cached and can be offloaded?

302
00:17:23,190 --> 00:17:25,890
Well, it could be the analysis results.

303
00:17:25,900 --> 00:17:29,320
It could be, the diagnostic
data, and it could be the key.

304
00:17:29,320 --> 00:17:30,680
It's config data, right?

305
00:17:30,810 --> 00:17:36,740
So specifically for in
cluster installation, right?

306
00:17:36,975 --> 00:17:39,355
and then, we have the integration.

307
00:17:39,355 --> 00:17:41,965
I already spoke about the integration.

308
00:17:42,235 --> 00:17:46,815
you have integration with Prometheus,
which allows case GPT to leverage

309
00:17:46,815 --> 00:17:50,155
real time metrics in order to
give more insights, more concept,

310
00:17:50,165 --> 00:17:54,225
context to the air back end so
they can get the best solution.

311
00:17:54,425 --> 00:17:54,675
Right.

312
00:17:54,675 --> 00:17:57,545
So we could scrap those
metrics from Prometheus server.

313
00:17:57,905 --> 00:18:02,225
And you can, also leverage
Trivia with the integration.

314
00:18:02,345 --> 00:18:07,345
So you can scan the cluster for, potential
vulnerability, and also configuring

315
00:18:07,405 --> 00:18:09,855
misconfiguration, cases as well.

316
00:18:09,875 --> 00:18:14,315
So, and, and I actually could have
put, other plugins cause it's,

317
00:18:14,615 --> 00:18:17,035
also supporting, Kyverno and Kera.

318
00:18:17,205 --> 00:18:25,145
As well, just so for you to, to know,
and, the way to activate, an integration,

319
00:18:25,595 --> 00:18:30,975
is through a simple command, which is
KGPT integration, activate, trivy, and

320
00:18:30,975 --> 00:18:32,695
then right after that, you can just.

321
00:18:32,895 --> 00:18:37,325
do a filter list, filters list,
and then you can see, that

322
00:18:37,325 --> 00:18:39,685
you have two new analyzers.

323
00:18:39,735 --> 00:18:43,335
They're not analyzers really,
because they're linked to the, the

324
00:18:43,335 --> 00:18:44,865
plugin that was integrated to it.

325
00:18:44,945 --> 00:18:47,525
That's why you have the
parentheses and integration.

326
00:18:47,925 --> 00:18:51,215
so you can run, two types of
analysis, which is a vulnerability

327
00:18:51,215 --> 00:18:54,575
report, and for CVS and a config.

328
00:18:54,915 --> 00:18:56,315
Audit report as well.

329
00:18:56,405 --> 00:19:01,275
And that might prove to be very useful if
you want to do everything in one location.

330
00:19:01,775 --> 00:19:06,495
And of course the LLM AI backends,
you can see the list in here.

331
00:19:06,515 --> 00:19:08,395
It's very, very exhaustive.

332
00:19:08,475 --> 00:19:13,405
but if you find a backend that was not
listed or support, feel free to open

333
00:19:13,495 --> 00:19:16,495
an issue or reach out to the team.

334
00:19:16,505 --> 00:19:19,775
But to be honest, I'm pretty
okay with this list because

335
00:19:19,775 --> 00:19:21,085
it's very, very exhaustive.

336
00:19:21,085 --> 00:19:21,375
So.

337
00:19:21,445 --> 00:19:23,365
That, that makes, that makes me happy.

338
00:19:23,375 --> 00:19:27,455
If I want to choose an AI backends
any day or change it, I'm sure

339
00:19:27,515 --> 00:19:29,195
I'll find it in the, in the list.

340
00:19:29,525 --> 00:19:32,245
I just want to share an example.

341
00:19:32,365 --> 00:19:35,385
Let's say OCI generative
AI from Oracle cloud.

342
00:19:35,745 --> 00:19:38,759
what you would need to do
is have a credential to.

343
00:19:38,840 --> 00:19:42,010
have access through API
to your cloud provider.

344
00:19:42,310 --> 00:19:47,010
And then, the second command
is, KCPT auth add backend.

345
00:19:47,010 --> 00:19:49,140
You specify the type of
backend, which is OCI.

346
00:19:49,530 --> 00:19:52,610
And then you'd already
have a model, before.

347
00:19:52,610 --> 00:19:56,420
So you specify the ID of the
model and the compartment, ID as

348
00:19:56,420 --> 00:20:01,020
well, which is like resource group
in Azure or a project in, GCP.

349
00:20:01,020 --> 00:20:01,464
So it's pretty straightforward.

350
00:20:01,655 --> 00:20:08,915
Really straightforward, and right after
that, you can use kcp to analyze issues

351
00:20:09,065 --> 00:20:15,045
to be solved and use the explain flag and
the back end to specify which back end

352
00:20:15,045 --> 00:20:18,305
you want to use to get your solutions.

353
00:20:18,805 --> 00:20:21,435
In terms of installation,
very straightforward.

354
00:20:21,435 --> 00:20:23,025
Again, cross platform.

355
00:20:23,115 --> 00:20:25,825
If you wanna install in Red
Hat, or Enterprise Linux

356
00:20:25,825 --> 00:20:28,735
Fedora, there are RPM available.

357
00:20:29,055 --> 00:20:34,355
if you can run a brew install if
you're in Mac os, or you can, install

358
00:20:34,355 --> 00:20:36,545
in Ubuntu through a Dian package.

359
00:20:36,815 --> 00:20:37,750
You can even install Windows.

360
00:20:38,260 --> 00:20:40,900
And in WSL within Windows as well.

361
00:20:40,910 --> 00:20:44,460
So it's pretty, ubiquitous
in terms of, installations.

362
00:20:44,860 --> 00:20:51,000
And all you need after that actually is
have access to your Kubernetes clusters,

363
00:20:51,180 --> 00:20:53,450
have a context, through kube config.

364
00:20:53,710 --> 00:20:58,550
And after the installation of kcpt,
you may need to, eventually, if

365
00:20:58,550 --> 00:21:02,050
you have access to a backend that
requires an API key, need to create

366
00:21:02,050 --> 00:21:03,520
your API key, as you can see here.

367
00:21:03,760 --> 00:21:05,549
I just chose OpenAI, but it's.

368
00:21:05,710 --> 00:21:07,980
It's pretty, it's the same everywhere.

369
00:21:08,500 --> 00:21:13,780
they now recommend to have project API
keys, maybe for, sort of a security,

370
00:21:13,830 --> 00:21:17,320
purpose, or, you know, to keep track
of all the keys that you create.

371
00:21:17,700 --> 00:21:21,490
And once you create that key, you
run case you beat the off, add.

372
00:21:22,060 --> 00:21:23,460
And you specify the back end.

373
00:21:23,480 --> 00:21:27,060
You don't need to specify open a
back end because it's a default one.

374
00:21:27,060 --> 00:21:33,670
So if you run case you beat the off ad,
it will just ask you for the open a I

375
00:21:33,670 --> 00:21:40,820
key by default without even specify an
open a I once this done, you can see that

376
00:21:40,830 --> 00:21:47,070
the status off the the authentication
or the back end is now active.

377
00:21:47,070 --> 00:21:51,130
That means that you can use it to
explain, On top of the analysis, right?

378
00:21:51,130 --> 00:21:56,640
So you can run the case you pt,
analyze and you put you add the explain

379
00:21:56,640 --> 00:22:00,590
flag plus the back end flag again.

380
00:22:00,960 --> 00:22:05,450
Open AI doesn't require to put the,
dash B open AI, because it's the default

381
00:22:05,470 --> 00:22:10,960
one, if you don't specify any, it will
go directly to use your open AI back.

382
00:22:10,960 --> 00:22:11,800
And if it's defined.

383
00:22:12,300 --> 00:22:15,440
One more thing to notice as well.

384
00:22:15,500 --> 00:22:21,280
So once you, you, installed case
GPT and once you added one back

385
00:22:21,280 --> 00:22:26,290
end, there is a configuration that
is stored, in your user directory.

386
00:22:26,380 --> 00:22:28,130
So let's take unique linux.

387
00:22:28,150 --> 00:22:32,570
For example, it's under, the
home directory dot config

388
00:22:32,630 --> 00:22:34,520
case GPT case GPT dot yaml.

389
00:22:34,970 --> 00:22:37,010
And, one thing you need to know is.

390
00:22:37,510 --> 00:22:40,870
The API key is stored
in plain text, right?

391
00:22:40,930 --> 00:22:44,320
So that's, one of the
things that I, noticed.

392
00:22:44,320 --> 00:22:49,860
So like there is no, encryption
currently, enabled in order to sort of

393
00:22:49,870 --> 00:22:53,020
mask, that, type of, type of secret.

394
00:22:53,310 --> 00:22:53,640
Right.

395
00:22:53,790 --> 00:22:57,940
So you got to be mindful of this, or
maybe try to play with the privileges

396
00:22:57,940 --> 00:23:03,430
of this file or use an elevated
user in order to run GPT eventually.

397
00:23:03,750 --> 00:23:10,220
and again, I also always have my
solution, my option, which is, the, just

398
00:23:10,220 --> 00:23:16,040
go fully private and use, local LLM,
inference, within your, data center.

399
00:23:16,080 --> 00:23:18,970
And when you have that, you
don't need a, an API key.

400
00:23:18,970 --> 00:23:22,680
You will just have like SSL configured
and you have firewall and then

401
00:23:22,680 --> 00:23:24,420
you'd be, safe on that matter.

402
00:23:24,430 --> 00:23:28,950
You won't have to store any API key or
there, there won't be any secret sprawl.

403
00:23:29,450 --> 00:23:29,840
All right.

404
00:23:29,980 --> 00:23:34,060
In terms of CLI is that
it's straight to the point.

405
00:23:34,290 --> 00:23:34,400
All right.

406
00:23:34,450 --> 00:23:36,470
No fluff, just what you need.

407
00:23:36,780 --> 00:23:40,560
so in terms of commands, it's
just like 10 beautiful and

408
00:23:40,650 --> 00:23:43,000
easy, easy to remember commands.

409
00:23:43,180 --> 00:23:48,230
So let's explain a few useful commands and
flags so we can focus on, on what matters.

410
00:23:48,740 --> 00:23:51,370
The first one we just
described, it is the auth.

411
00:23:51,635 --> 00:23:51,875
Right.

412
00:23:51,895 --> 00:23:55,785
If you want to add a back end,
we did that with open AI, right?

413
00:23:55,945 --> 00:23:58,585
You can add list and remove AI back end.

414
00:23:58,835 --> 00:24:02,625
and after that, you can eventually
get some, appearance from your

415
00:24:02,865 --> 00:24:06,415
back end when you were in case you
beat the second one is analyze.

416
00:24:06,625 --> 00:24:10,455
So analyze, would just allow you to
find problems within your communities

417
00:24:10,455 --> 00:24:14,065
cluster and provide you with a list
of issues that need to be resolved.

418
00:24:14,375 --> 00:24:14,695
Right.

419
00:24:14,875 --> 00:24:19,085
So it's like, events or
logs on steroids, right?

420
00:24:19,145 --> 00:24:21,955
It will just show you the
issues that need to be resolved.

421
00:24:22,035 --> 00:24:23,195
It will not reply.

422
00:24:23,285 --> 00:24:25,035
It will not give you, solutions.

423
00:24:25,175 --> 00:24:25,475
Why?

424
00:24:25,485 --> 00:24:28,385
Because at this point, you're not
connecting to your AI backend.

425
00:24:28,885 --> 00:24:33,315
So right, right here, there's just
a list of issues that are listed

426
00:24:33,315 --> 00:24:35,605
through the KGPT with the analyze.

427
00:24:36,075 --> 00:24:38,305
After that, you have the filter filter.

428
00:24:38,625 --> 00:24:43,615
We said that we already said that
we have 19, analyzers, right?

429
00:24:43,815 --> 00:24:45,825
So you have to specify which analyzer.

430
00:24:46,135 --> 00:24:51,525
Analyzer you want to run because sometimes
you have a multi cluster environment

431
00:24:51,655 --> 00:24:56,965
or you have, many namespaces, different
teams with, 20 teams with thousands

432
00:24:56,965 --> 00:24:59,615
of, of, resources, different type.

433
00:25:00,035 --> 00:25:01,205
Across the cluster.

434
00:25:01,435 --> 00:25:04,435
So you don't want to run just the analyze.

435
00:25:04,800 --> 00:25:07,850
Explain, especially if you
add explain, which is crazy.

436
00:25:07,850 --> 00:25:11,990
So you want to run it based on every
type of resource in your cluster.

437
00:25:11,990 --> 00:25:13,840
You want to be a bit more specific, right?

438
00:25:13,910 --> 00:25:17,610
Just to reduce the amount of time
it will take and also reduce the

439
00:25:17,610 --> 00:25:19,370
amount of output you will get, right?

440
00:25:19,430 --> 00:25:23,360
Because if your cluster is filled
with issues, then like you would take

441
00:25:23,370 --> 00:25:25,210
three or four or five pages, right?

442
00:25:25,300 --> 00:25:26,615
And that's not what you want.

443
00:25:27,115 --> 00:25:31,315
And now, this one is special because
this is where the magic happened, right?

444
00:25:31,465 --> 00:25:35,525
So explain or dash E, is the
explain through AI, right?

445
00:25:35,725 --> 00:25:42,185
So this, is the flag that would, trigger
the communication with your AI backend.

446
00:25:42,545 --> 00:25:42,835
Right.

447
00:25:42,845 --> 00:25:45,425
So from this point, you're
actually starting to pay.

448
00:25:45,455 --> 00:25:49,805
If you added your API key from OpenAI
or code here, if you run a command,

449
00:25:49,805 --> 00:25:54,355
analyze, and you edit, explain, that's
where you communicate with the AI

450
00:25:54,365 --> 00:25:56,615
backend and get some info, right?

451
00:25:56,615 --> 00:26:01,395
So before, you won't pay any, but at
this point, that's where the counter

452
00:26:01,435 --> 00:26:04,395
actually is starting to run, right?

453
00:26:04,680 --> 00:26:07,110
Because it's an API call
to your AI back end.

454
00:26:07,780 --> 00:26:13,310
After that you have back end, obviously,
because sometimes, you configured, you

455
00:26:13,310 --> 00:26:18,300
happen to have, you know, good for you,
cohere, anthropic, and, I don't know, it

456
00:26:18,300 --> 00:26:20,610
could be even grok if you want to, right?

457
00:26:20,650 --> 00:26:22,530
You have all, all of them defined.

458
00:26:22,755 --> 00:26:23,995
And you can choose which back end.

459
00:26:24,005 --> 00:26:29,115
The default one is OpenAI, but nothing
stops you from using another one.

460
00:26:29,335 --> 00:26:33,305
And one of the advantages is that you're
actually building your own benchmark

461
00:26:33,525 --> 00:26:37,195
based on the quality and accuracy
of the solution that are provided.

462
00:26:37,195 --> 00:26:43,745
So like you can compare OpenAI with
Anthropic and see Which one is answering

463
00:26:43,755 --> 00:26:46,295
better to you, depending on the use case.

464
00:26:46,345 --> 00:26:50,375
And, you can also think of it
as a second opinion, right?

465
00:26:50,375 --> 00:26:53,255
So it's like when you go to a
doctor, doctor says, yeah, we,

466
00:26:53,265 --> 00:26:56,645
we need to go for amputation and
you're like, Oh, you know what?

467
00:26:56,685 --> 00:26:58,185
I might need another, opinion.

468
00:26:58,295 --> 00:27:01,655
So I, I, I may, I may ask another
doctor just, just to be sure.

469
00:27:02,045 --> 00:27:02,375
Right.

470
00:27:02,385 --> 00:27:06,035
So that's also very interesting feature.

471
00:27:06,910 --> 00:27:12,470
We talked about integration to activate,
remove, or list the integration tree, V

472
00:27:12,730 --> 00:27:14,610
or whatever, all the plugin, available.

473
00:27:15,010 --> 00:27:19,080
And then we have, dash D or,
with doc, this one is cool.

474
00:27:19,110 --> 00:27:20,290
Cause it's a no brainer.

475
00:27:20,560 --> 00:27:24,310
sometimes you just want to
attach the documentation.

476
00:27:24,490 --> 00:27:30,320
So wherever you show or a filter
analyzer, you choose, you can add dash D

477
00:27:30,530 --> 00:27:32,035
and then it gets you the documentation.

478
00:27:32,475 --> 00:27:35,585
The info, the documentation related
to the resource you're trying to

479
00:27:35,585 --> 00:27:39,425
find a, a solution to, which is,
which is kind of, kind of cool.

480
00:27:39,435 --> 00:27:43,025
So instead of a Googling, you'll just
having it, in the same command anonymize,

481
00:27:43,525 --> 00:27:47,985
we talked about anonymized, it allows you
to, you know, mask your sensitive data.

482
00:27:48,960 --> 00:27:50,530
And then we have namespace, right?

483
00:27:50,580 --> 00:27:55,080
I already talked about the filter, so
you can filter the type of resource.

484
00:27:55,440 --> 00:27:57,530
But how about filtering the namespace?

485
00:27:57,590 --> 00:28:01,980
Because sometimes you have so many
namespace, in a cluster because

486
00:28:02,040 --> 00:28:03,550
there's so many teams, right?

487
00:28:03,550 --> 00:28:05,200
So, but if you're actually.

488
00:28:05,435 --> 00:28:07,445
Just responsible for one namespace.

489
00:28:07,465 --> 00:28:11,685
There was an issue in a namespace
and you want to check, or get some

490
00:28:11,685 --> 00:28:15,825
solutions regarding an issue with
that resource in that namespace.

491
00:28:15,935 --> 00:28:18,805
That's your, your, your, your go to shop.

492
00:28:18,875 --> 00:28:22,965
Actually, this is my, my favorite,
company in namespace and filter

493
00:28:22,995 --> 00:28:24,745
is like the best you can think of.

494
00:28:25,085 --> 00:28:29,455
which is, which makes it very, very
more specific and granular in, in

495
00:28:29,455 --> 00:28:31,525
your research and also it's faster.

496
00:28:31,930 --> 00:28:33,490
for getting the answer.

497
00:28:34,400 --> 00:28:35,330
this one is new.

498
00:28:35,550 --> 00:28:41,240
this is, the stats, flag, which,
actually, is only available since,

499
00:28:41,240 --> 00:28:44,780
the version three, 43, not before.

500
00:28:44,870 --> 00:28:45,110
Right.

501
00:28:45,110 --> 00:28:46,130
So it's very recent.

502
00:28:46,170 --> 00:28:51,090
addition, and this will allow you to
display statistics of each analyzer run.

503
00:28:51,435 --> 00:28:51,715
Right.

504
00:28:51,725 --> 00:28:56,495
So, you can just show like how long
it took you to run the analyzer for

505
00:28:56,745 --> 00:28:59,305
this or that, that type of resource.

506
00:28:59,345 --> 00:29:01,575
You can see here that some
of them take milliseconds.

507
00:29:01,575 --> 00:29:05,655
I'll attack seconds to minutes
depending on your workload.

508
00:29:05,675 --> 00:29:09,375
But it might be useful if you're
trying to troubleshoot case

509
00:29:09,375 --> 00:29:11,055
GPT analysis at some point.

510
00:29:11,605 --> 00:29:12,815
So that's that's kind of cool.

511
00:29:13,315 --> 00:29:13,765
All right.

512
00:29:13,855 --> 00:29:16,695
so in terms of
architectures, there are two.

513
00:29:16,765 --> 00:29:19,165
I already talked about the CLI, right?

514
00:29:19,165 --> 00:29:24,975
So the CLI, you can install it in any
operating system, but it's everything.

515
00:29:25,125 --> 00:29:26,695
It's process based.

516
00:29:26,745 --> 00:29:28,565
It's within the host where you run it.

517
00:29:28,960 --> 00:29:29,240
Right.

518
00:29:29,270 --> 00:29:30,580
It's not inside the cluster.

519
00:29:30,690 --> 00:29:32,950
So it's a binary, as you can see here.

520
00:29:32,980 --> 00:29:38,930
So you can have within the binary,
you have the analyzers and when you

521
00:29:38,940 --> 00:29:44,280
run it, analyze and you filter pod,
one of the analyzers, will be chosen.

522
00:29:44,330 --> 00:29:48,780
And that analyzer has, actually a
bunch of, a bunch of, primitive.

523
00:29:49,010 --> 00:29:53,370
Actually, that it gets from the API
servers, related to the, the type of

524
00:29:53,370 --> 00:29:58,540
analyzer, as you can see here, like you
have the pod list advanced status, right.

525
00:29:58,710 --> 00:30:02,990
And all this is actually, sort of
gathered, compacted, and then given

526
00:30:02,990 --> 00:30:06,660
into making it easier to build results.

527
00:30:06,870 --> 00:30:12,670
so he can send it into package it and
send it as a payload to your AI provider.

528
00:30:13,000 --> 00:30:13,340
Right.

529
00:30:13,560 --> 00:30:15,200
So analyzer.

530
00:30:15,415 --> 00:30:19,015
Fetches the data,
organizes it, packages it.

531
00:30:19,365 --> 00:30:22,925
You've got the built results
that can be run with the MNLize.

532
00:30:22,985 --> 00:30:25,935
And then if you added the
explain, it will send all this

533
00:30:25,935 --> 00:30:27,435
information to the AI provider.

534
00:30:27,805 --> 00:30:30,885
The inference, would occur on that input.

535
00:30:30,925 --> 00:30:35,895
And then at the end, the enriched
results are sent back with the solutions.

536
00:30:36,005 --> 00:30:38,925
That's actually the main
loop of KHCPT with AI.

537
00:30:39,235 --> 00:30:43,665
And at the end, the user has
access to, those final suggestions.

538
00:30:43,950 --> 00:30:44,210
Right.

539
00:30:44,280 --> 00:30:48,840
But there's also case GPT
operator, architecture.

540
00:30:48,870 --> 00:30:49,270
Why?

541
00:30:49,580 --> 00:30:55,360
Because this is, this happens when
you, you install it in cluster.

542
00:30:55,490 --> 00:30:57,270
This is what we call in
cluster installation.

543
00:30:57,490 --> 00:30:57,780
Right.

544
00:30:57,970 --> 00:31:02,780
So I'm just trying to, to
actually show you the components.

545
00:31:02,780 --> 00:31:07,570
So we have the case that I will
explain case GPT config case GPT.

546
00:31:07,765 --> 00:31:08,565
Operator.

547
00:31:08,605 --> 00:31:11,315
And then we have the
deployment with the analyzers.

548
00:31:11,635 --> 00:31:12,045
Right?

549
00:31:12,285 --> 00:31:13,145
And oops.

550
00:31:13,545 --> 00:31:17,665
So this has access to the API server,
as I explained with the binary

551
00:31:17,665 --> 00:31:22,325
version, and you will have also access
with whatever integration that is

552
00:31:22,325 --> 00:31:24,365
available, like Trivi or Prometheus.

553
00:31:24,965 --> 00:31:27,525
So we'll scrap the data, the
metrics from Trivi, from Prometheus.

554
00:31:28,025 --> 00:31:33,715
You can run Trivi, scans, Through
GPT, through case GPT, and then the

555
00:31:33,715 --> 00:31:39,945
analyzers will just build those, results,
send them to the, API for inference.

556
00:31:39,995 --> 00:31:43,205
And then after that, it will
bring back the analysis results.

557
00:31:43,955 --> 00:31:46,575
One thing you need to know is
that there is a requirement

558
00:31:46,585 --> 00:31:48,635
to install the kshpt operator.

559
00:31:48,825 --> 00:31:53,065
So the requirement is to install
the operator through the Helm chart.

560
00:31:53,475 --> 00:31:56,395
So this does nothing,
just install the operator.

561
00:31:56,665 --> 00:32:03,205
Then you will need to create a secret to
store the API key of your AI provider.

562
00:32:03,320 --> 00:32:03,600
Why?

563
00:32:03,610 --> 00:32:04,760
Because the CLI, right?

564
00:32:04,790 --> 00:32:06,400
You don't have to do it anymore.

565
00:32:06,400 --> 00:32:08,960
We don't have to store it
or do it interactively.

566
00:32:09,290 --> 00:32:14,070
like with, the CLI with the binary,
everything is stored within the cluster.

567
00:32:14,080 --> 00:32:18,460
So API key has to be a
secret right after that.

568
00:32:19,195 --> 00:32:21,525
Then you can install the config object.

569
00:32:21,565 --> 00:32:23,875
I also talked about KGBT config, right?

570
00:32:24,145 --> 00:32:28,985
So this object, which is a
KGBT resource, can be run.

571
00:32:28,985 --> 00:32:34,065
It's just a manifest that you will
run and will help, the operator create

572
00:32:34,125 --> 00:32:36,345
a deployment and a bunch of CRDs.

573
00:32:36,845 --> 00:32:40,385
And if you want to upgrade, you
just change the value of the

574
00:32:40,385 --> 00:32:43,535
version of KGBT in that manifest,
and it will upgrade it for you.

575
00:32:43,975 --> 00:32:48,675
automatically, and then, so the
operator will allow you to hold

576
00:32:48,715 --> 00:32:52,735
primitives that contain the suggestion
return from your AI model, right?

577
00:32:52,735 --> 00:32:57,105
So instead of having the result
when you run the command in CLI,

578
00:32:57,345 --> 00:33:03,345
now it is stored within special
CRDs that are called results, right?

579
00:33:03,345 --> 00:33:07,945
So these CRDs are called results,
resources, and they can even

580
00:33:07,945 --> 00:33:10,125
be sent to a Grafana dashboard.

581
00:33:10,125 --> 00:33:12,085
I can see here on the left side.

582
00:33:12,205 --> 00:33:12,405
Right.

583
00:33:12,435 --> 00:33:16,075
It can be sent to Grafana so you
can see it within, one of the

584
00:33:16,155 --> 00:33:20,885
dedicated dashboard if you enable
it, in your Helm chart, right.

585
00:33:21,215 --> 00:33:24,565
That would be super nice because
instead of like running kubectl

586
00:33:24,595 --> 00:33:28,435
to get the results, you can have
access in a web browser, right.

587
00:33:29,235 --> 00:33:31,305
And, just, want to show you.

588
00:33:31,795 --> 00:33:36,485
Like the format of that kind of
resource, here, it's a simple example.

589
00:33:36,505 --> 00:33:40,795
So we try to, deploy a pod with,
like a fake or wrong name of, image.

590
00:33:41,115 --> 00:33:44,255
And then this can happen, automatically.

591
00:33:44,425 --> 00:33:45,975
So we didn't have to run anything.

592
00:33:46,210 --> 00:33:48,060
as opposed to the CLI.

593
00:33:48,280 --> 00:33:53,070
And after that, it was directly sent
to AI and then AI got the information

594
00:33:53,280 --> 00:33:55,470
and then send back some suggestions.

595
00:33:55,540 --> 00:33:58,780
As you can see here in the solution,
check the image name, ensure the

596
00:33:58,780 --> 00:34:00,900
image exists, blah, blah, blah.

597
00:34:01,180 --> 00:34:05,520
and this is basically like a
simple back of Poland image, issue.

598
00:34:05,750 --> 00:34:10,990
but that just shows you that, these
resources will be created automatically.

599
00:34:11,210 --> 00:34:15,620
and then it will be just, Pylab
actually as a resource, ready

600
00:34:15,620 --> 00:34:19,210
to be accessed, instead of just
running a command separately.

601
00:34:19,710 --> 00:34:24,310
This is not a diagram, just, just
to show you that the PHP deployment

602
00:34:24,320 --> 00:34:29,250
has, pods where the analyzers would
run and communicate with the API

603
00:34:29,250 --> 00:34:31,830
server and the inference API server.

604
00:34:32,010 --> 00:34:35,680
There's also a way to connect with,
do remote caching and also send

605
00:34:35,680 --> 00:34:37,320
notifications to Slack as well.

606
00:34:37,495 --> 00:34:37,745
Right.

607
00:34:37,745 --> 00:34:43,055
So it's pretty much integrated, to
be honest, I was going to run a gif,

608
00:34:43,095 --> 00:34:45,285
but, there's no way I can play it.

609
00:34:45,525 --> 00:34:46,985
So this is the last frame.

610
00:34:47,025 --> 00:34:49,195
As you can see here,
we have two resources.

611
00:34:49,195 --> 00:34:54,315
We have the controller, controller manager
operator, and we have the deployment,

612
00:34:54,445 --> 00:34:57,530
when you, deploy the case GPT config.

613
00:34:58,030 --> 00:35:00,150
demo time, right?

614
00:35:00,230 --> 00:35:05,210
So, hopefully I, I'm sorry again, if I
took too much, but, I really want you to

615
00:35:05,210 --> 00:35:11,890
have, enough background on the tool and
also, on the challenges and, and AI and

616
00:35:12,380 --> 00:35:15,460
every single, feature or, or, or use case.

617
00:35:15,650 --> 00:35:18,570
but I, I may do something fun.

618
00:35:18,890 --> 00:35:22,430
And right now, maybe I, we
can play something, we can run

619
00:35:22,430 --> 00:35:24,460
some commands for you, right?

620
00:35:24,520 --> 00:35:26,280
Let me see what I can play.

621
00:35:26,780 --> 00:35:27,180
Right.

622
00:35:27,860 --> 00:35:28,220
Okay.

623
00:35:28,270 --> 00:35:33,540
So, I think, what we can do here
may be is what I want to tell you

624
00:35:33,560 --> 00:35:38,270
is that, right now in my terminal,
I, One of the prerequisites is

625
00:35:38,310 --> 00:35:43,170
installing kcpt and also, I have a
kube config that is already set up.

626
00:35:43,260 --> 00:35:50,020
I have access to a managed cloud cluster
within OCI and my version of kcpt is 0.

627
00:35:50,020 --> 00:35:50,020
3.

628
00:35:50,020 --> 00:35:51,270
48.

629
00:35:51,320 --> 00:35:53,330
That's the most recent one, right?

630
00:35:54,270 --> 00:35:56,440
And now we can start to play with it.

631
00:35:56,950 --> 00:36:03,070
So one of the first, command that I
may, need to run is, kcpt auth list.

632
00:36:03,380 --> 00:36:03,710
Right.

633
00:36:04,440 --> 00:36:07,650
You can see here that nothing,
there's a default open AI,

634
00:36:07,650 --> 00:36:08,900
but nothing is configured yet.

635
00:36:09,010 --> 00:36:09,260
Right.

636
00:36:09,330 --> 00:36:14,130
But if I run it here, this is not the
terminal when I, when I already configured

637
00:36:14,570 --> 00:36:19,090
my back ends, I have open AI that is
defined and Olama also that is defined.

638
00:36:19,290 --> 00:36:19,700
Okay.

639
00:36:20,305 --> 00:36:20,615
Right.

640
00:36:20,635 --> 00:36:25,085
So, but if I wanted to enable
something, I could, enable,

641
00:36:25,455 --> 00:36:30,105
Olama because I have actually a
bunch of models that are running.

642
00:36:30,225 --> 00:36:33,295
They're all, quantized models
that are running within my laptop.

643
00:36:33,315 --> 00:36:36,735
I have like a, just a tiny,
graphical card, but they can still

644
00:36:36,735 --> 00:36:39,335
run and I can use it with case GPT.

645
00:36:39,620 --> 00:36:40,550
Easily, right?

646
00:36:40,550 --> 00:36:41,480
So what can we do?

647
00:36:41,560 --> 00:36:46,140
Well, in my I'll share
my repo with read me.

648
00:36:46,320 --> 00:36:50,540
You can see here that there is
a way to add the new back end.

649
00:36:50,540 --> 00:36:52,080
So I'm just copying it here.

650
00:36:52,280 --> 00:36:55,910
So what that means is that I'm
choosing all I'm as a back end.

651
00:36:56,230 --> 00:36:57,780
I'm choosing the model.

652
00:36:58,060 --> 00:37:01,210
Because, this is llama
three latest, right?

653
00:37:01,260 --> 00:37:05,670
I want to specify the model and also
I'll specify the end point, right?

654
00:37:05,860 --> 00:37:08,920
So if I click here, I come here, right?

655
00:37:09,480 --> 00:37:11,610
I could run this, right?

656
00:37:11,680 --> 00:37:15,770
All I'm, that's as straightforward
as it can get, right?

657
00:37:15,870 --> 00:37:22,050
If I do off list right now a second time,
you can see that, Olama has been enabled.

658
00:37:22,795 --> 00:37:25,535
Now we have Olama that is active, right?

659
00:37:25,585 --> 00:37:29,145
So it's enabled, but let's
get back to like the kind of,

660
00:37:29,195 --> 00:37:30,765
analysis that we can, run.

661
00:37:31,225 --> 00:37:38,345
Right now, simple example, I'm not
going to do something crazy, right?

662
00:37:38,385 --> 00:37:43,905
So we have, just, pod and I put
the, that wrong, image name, right?

663
00:37:44,215 --> 00:37:47,055
And I tried to deploy it, right?

664
00:37:47,175 --> 00:37:52,825
And it was in a specific, I call the
broken namespace just to, be sure, right?

665
00:37:52,825 --> 00:37:56,815
See, so if I get the pods in
here, we can see that we have a

666
00:37:57,065 --> 00:37:59,165
image pullback of already, right?

667
00:37:59,295 --> 00:38:02,895
So the first thing you can do
is, yeah, I can run it here.

668
00:38:03,395 --> 00:38:04,525
And then if I run it, it

669
00:38:05,025 --> 00:38:07,625
will actually, no, not this one.

670
00:38:08,235 --> 00:38:14,905
Okay, so I specify the back end,
which is Olama, and then it will run.

671
00:38:15,405 --> 00:38:16,915
And if I duplicate this one,

672
00:38:17,415 --> 00:38:23,420
right, see here, it's taking its time
because Obviously it's locally run.

673
00:38:23,910 --> 00:38:26,280
so it's taking his time
and I'm sharing my screen.

674
00:38:26,280 --> 00:38:31,060
So I think, there's a kind of,
it's capping out a bit, but I can

675
00:38:31,060 --> 00:38:34,010
also do that and call in, open AI.

676
00:38:34,020 --> 00:38:38,480
Cause, I also happen to have
that backend active, right?

677
00:38:38,500 --> 00:38:43,060
So let's see, see, so like this one was
super fast because it was open AI, right?

678
00:38:43,280 --> 00:38:45,510
And then it would just tell you.

679
00:38:45,780 --> 00:38:48,600
That's the ANA analysis part.

680
00:38:48,810 --> 00:38:51,230
And then here we gives you,
gives you the solution.

681
00:38:51,230 --> 00:38:53,000
Same thing that we, you've seen, earlier.

682
00:38:53,030 --> 00:38:55,280
I didn't want to do more right?

683
00:38:55,460 --> 00:38:59,960
But in the mean meantime, I can
actually run, the last thing I could

684
00:38:59,960 --> 00:39:02,210
run is this one vulnerability report.

685
00:39:02,760 --> 00:39:03,060
Right?

686
00:39:03,300 --> 00:39:06,860
I can do this and I can
try to explain it, right?

687
00:39:06,920 --> 00:39:11,150
And if I explain it, I can use
open AI to explain it as well,

688
00:39:11,150 --> 00:39:12,560
but it might take some time.

689
00:39:13,315 --> 00:39:13,565
Right.

690
00:39:13,695 --> 00:39:18,675
So if I do with that explanation,
it will just list all the CVS,

691
00:39:18,935 --> 00:39:25,655
that are actually, triggered in
my, or existing in my cluster.

692
00:39:25,715 --> 00:39:26,885
You see how many we have.

693
00:39:27,275 --> 00:39:27,645
Right.

694
00:39:28,045 --> 00:39:32,405
But if I want to run the, the inference
on it, just to have the suggestions,

695
00:39:32,715 --> 00:39:34,665
this is the kind of CVS you can have.

696
00:39:34,960 --> 00:39:35,850
With the solution.

697
00:39:35,850 --> 00:39:42,060
So the green part is the response
from Olama eventually, right?

698
00:39:42,320 --> 00:39:43,830
Cause there you go.

699
00:39:43,830 --> 00:39:47,200
So this one is Olama and we
have more or less the same.

700
00:39:47,200 --> 00:39:51,550
See, like this is an answer from
a local open source model, right?

701
00:39:51,820 --> 00:39:55,630
And this, this was from, open AI, right?

702
00:39:55,660 --> 00:39:58,070
So they're not depending
on the issue, right?

703
00:39:58,160 --> 00:40:02,150
But of course there's a better
quality when you pay from open AI,

704
00:40:02,550 --> 00:40:04,340
but it tells you that you can run.

705
00:40:04,770 --> 00:40:10,410
Easily a local, appearance, if you
want to sort of, manage your, your,

706
00:40:10,450 --> 00:40:15,820
your expenses, when you use a local
for specific issues and open AI for,

707
00:40:16,000 --> 00:40:18,910
others, but this is just an example.

708
00:40:18,920 --> 00:40:24,310
Let's say, for example, the CVE,
45, 3, 3, 7, you see, it's about.

709
00:40:24,365 --> 00:40:28,775
I think it's about OC4G
or something like that.

710
00:40:28,775 --> 00:40:33,235
So if I come here, it's really hard
to see what is need to be done.

711
00:40:33,435 --> 00:40:33,845
Right.

712
00:40:34,185 --> 00:40:39,565
But the advantage here is that KCBT
leverage, Trivi and then Ascent.

713
00:40:40,040 --> 00:40:45,940
The message or like the, the payload
to AI, and then your LLM would just

714
00:40:45,940 --> 00:40:48,000
give you some, solutions, right?

715
00:40:48,020 --> 00:40:53,050
As you can see here, update Apache
log for G J to version two 19,

716
00:40:53,050 --> 00:40:56,740
consider using a more secure login
library, blah, blah, blah, right?

717
00:40:56,920 --> 00:41:00,330
So this is the kind of information
that it can give you, whether

718
00:41:00,330 --> 00:41:06,140
it's analyzing, resources based
on issue, as I said, right?

719
00:41:06,330 --> 00:41:11,180
Or, Based on vulnerability
or misconfiguration, right?

720
00:41:11,240 --> 00:41:14,480
So I think I'm done with the demo.

721
00:41:14,480 --> 00:41:17,340
I don't want to do more than this
because it's already too much.

722
00:41:17,920 --> 00:41:22,870
And, the new project that the team
has is called a sketch nest, right?

723
00:41:22,870 --> 00:41:28,430
So what is, sketch, sorry about the name,
but like, what is a sketch next is a

724
00:41:28,430 --> 00:41:34,660
Kubernetes scheduler that uses insight
from KCPT to make a intelligent, decision

725
00:41:34,660 --> 00:41:39,310
about where to place your workloads,
instead of a default scheduler scoring,

726
00:41:39,680 --> 00:41:43,990
that is existing, by default, like
the vanilla version of your scheduler.

727
00:41:44,195 --> 00:41:49,775
You can use a sketch next in order to
like smartly, place your, your, workload.

728
00:41:50,035 --> 00:41:54,625
So maybe you don't have any topology
key defined, for example, so sketchness

729
00:41:55,225 --> 00:42:00,075
will, will actually just help you,
like dynamically, schedule, the

730
00:42:00,075 --> 00:42:02,435
resources based on like recent events.

731
00:42:02,695 --> 00:42:07,805
which is not always, maybe accessible
to the, basic, so the, the default

732
00:42:07,815 --> 00:42:11,455
scheduler, because they rely on
like, some very basic scoring.

733
00:42:11,535 --> 00:42:15,865
So this is the, the curing project
that is integrated also with kcpt.

734
00:42:15,865 --> 00:42:18,515
So, feel free to give it a, a look.

735
00:42:18,805 --> 00:42:21,195
but in the meantime, thank you everyone.

736
00:42:21,295 --> 00:42:22,415
I know it was too much.

737
00:42:22,585 --> 00:42:23,715
If you want to reach out to me.

738
00:42:24,540 --> 00:42:29,110
Again, I, I work at cloud thrill.

739
00:42:29,170 --> 00:42:33,510
I can reach out to me on Twitter
or, LinkedIn, dot com as well.

740
00:42:33,900 --> 00:42:35,410
This is my GitHub repo.

741
00:42:35,720 --> 00:42:37,910
So thanks everyone.

742
00:42:37,950 --> 00:42:39,580
And, that was amazing to be with you.

743
00:42:40,120 --> 00:42:40,670
Appreciate it.

