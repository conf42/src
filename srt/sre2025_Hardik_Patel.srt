1
00:00:00,990 --> 00:00:04,740
Let us dive into observability
today and how it helps us

2
00:00:04,800 --> 00:00:06,360
boost operational efficiency.

3
00:00:06,960 --> 00:00:11,580
It is important for us to be operationally
efficient when it comes to maintaining

4
00:00:11,640 --> 00:00:13,440
and scaling distributed systems.

5
00:00:14,130 --> 00:00:15,690
Hi, I'm Harri Patel.

6
00:00:16,230 --> 00:00:19,530
I have around 20 years of experience
in tech industry working for small

7
00:00:19,535 --> 00:00:21,060
startups and large enterprises.

8
00:00:21,420 --> 00:00:24,180
I hold master's degree in software
engineering from Bits Alani.

9
00:00:24,765 --> 00:00:28,425
I have held various tech leadership
roles at high tech places like Yahoo,

10
00:00:28,425 --> 00:00:30,795
Symantec Group on PayPal to name a few.

11
00:00:31,545 --> 00:00:36,255
I have had opportunity to lead teams
of sizes ranging from five people

12
00:00:36,255 --> 00:00:40,815
to 30 plus people, organization,
including engineers, leads and managers.

13
00:00:41,235 --> 00:00:45,765
In my most recent 10 years of experience,
I have had opportunity to design

14
00:00:45,765 --> 00:00:49,575
and develop large scale distributor
systems and big data architectures.

15
00:00:50,075 --> 00:00:55,595
Let us start by going through various
challenges that we face while developing

16
00:00:55,655 --> 00:00:57,455
and maintaining distributed systems.

17
00:00:58,295 --> 00:01:01,145
Distributed systems
are inherently complex.

18
00:01:01,325 --> 00:01:06,695
This complexity stems from the fact
that they provide one system view to

19
00:01:06,695 --> 00:01:11,315
underlying tens or maybe sometimes
hundreds of interconnected services.

20
00:01:11,795 --> 00:01:15,515
Hence, our traditional
monitoring is not adequate.

21
00:01:16,015 --> 00:01:19,465
Distributed systems usually
undergo rapid changes.

22
00:01:19,915 --> 00:01:23,125
With advent of continuous
development and deployment.

23
00:01:23,425 --> 00:01:28,285
Systems are constantly evolving, so
to pinpoint issues it becomes harder.

24
00:01:28,785 --> 00:01:33,945
There are certain scale issues, so when
it comes to reproducing issue, they

25
00:01:33,945 --> 00:01:39,975
only surface at scale, and our current
test systems usually are not equipped to

26
00:01:39,975 --> 00:01:42,705
mimic production scale, which further.

27
00:01:43,140 --> 00:01:45,900
Toughens the problem of
identifying the issues.

28
00:01:46,590 --> 00:01:50,820
Given these challenges, it is
important for us to step back and

29
00:01:50,820 --> 00:01:55,440
understand different ways and means
to achieve observability for such

30
00:01:55,440 --> 00:01:57,660
large scale distributed systems.

31
00:01:58,160 --> 00:02:04,060
So let's take a look at three
pillars of observability that exist.

32
00:02:04,900 --> 00:02:06,940
The first pillar is metrics.

33
00:02:07,510 --> 00:02:10,570
So metrics are essentially
numerical data points.

34
00:02:10,960 --> 00:02:15,580
Collected at regular intervals revealing
system performance patterns and health

35
00:02:16,080 --> 00:02:22,020
enables metrics enable identification
of trends, anomalies, and potential

36
00:02:22,020 --> 00:02:24,120
bottlenecks before they become critical.

37
00:02:24,810 --> 00:02:29,280
Hence, they are key ingredients
in helping us achieve proactivity

38
00:02:30,150 --> 00:02:31,205
instead of reactivity.

39
00:02:31,705 --> 00:02:36,595
The second pillar in observability
are logs, so logs are.

40
00:02:37,285 --> 00:02:41,785
Timestamp records of discrete events
and actions within the system.

41
00:02:42,445 --> 00:02:47,035
They help us by providing rich
contextual information for

42
00:02:47,035 --> 00:02:52,555
debugging forensic analysis and
understanding the sequence of events.

43
00:02:53,055 --> 00:02:56,715
The third pillar of
observability are traces.

44
00:02:57,285 --> 00:03:03,495
So traces are a means to depict end-to-end
journey of a request as they flow through.

45
00:03:03,930 --> 00:03:07,950
Interconnected mesh of services
in distributor systems.

46
00:03:08,459 --> 00:03:13,739
They help in highlighting not only
complex interactions, but also to detect

47
00:03:14,100 --> 00:03:19,590
latency issues and dependencies that
impact overall system performance.

48
00:03:20,090 --> 00:03:23,870
Now that we have gone through key
ingredients that forms the basis

49
00:03:23,870 --> 00:03:28,549
of observable observability, let us
explore vital metrics that really

50
00:03:28,549 --> 00:03:31,160
matter in such distributed systems.

51
00:03:31,660 --> 00:03:37,480
So first popular metric is called system
latency, and it is a measurement of

52
00:03:37,480 --> 00:03:40,239
response time across service boundaries.

53
00:03:40,480 --> 00:03:44,950
So in other words, it is overall
turnaround time taken for a

54
00:03:44,950 --> 00:03:49,869
request from hitting a service to
receiving a final response from it.

55
00:03:50,369 --> 00:03:57,749
We usually track P 95 and P 99 percentiles
to quantify the latency of systems.

56
00:03:58,109 --> 00:03:59,069
And services.

57
00:03:59,569 --> 00:04:04,459
The second metric, which is equally
popular is called error rates, so rate at

58
00:04:04,459 --> 00:04:10,579
which errors occur or are encountered with
respect to successful execution of service

59
00:04:10,579 --> 00:04:13,309
Requests are essentially error rates.

60
00:04:13,879 --> 00:04:18,439
Depending on the business impact
and use cases, we can configure

61
00:04:18,769 --> 00:04:23,990
and watch for different thresholds
of rate at which this error occur.

62
00:04:24,469 --> 00:04:27,169
For instance, mission critical services.

63
00:04:27,755 --> 00:04:31,655
Will have lower thresholds
versus relatively non-critical

64
00:04:31,655 --> 00:04:36,005
services will probably have
higher error rate thresholds.

65
00:04:36,505 --> 00:04:42,414
The third metrics that matter is
resource utilization, so metrics,

66
00:04:42,414 --> 00:04:47,364
collection of resource utilization
is a way of keeping track of various

67
00:04:47,364 --> 00:04:53,335
resources, including compute, memory,
network, IO storage, and so on.

68
00:04:53,755 --> 00:04:54,565
In this case.

69
00:04:54,909 --> 00:05:00,310
The idea is to stay on top of these
utilizations and prevent resource

70
00:05:00,340 --> 00:05:02,800
exhaustion even before they occur.

71
00:05:03,640 --> 00:05:07,750
This one if configured diligently,
can help us stay proactive.

72
00:05:08,250 --> 00:05:11,160
User experiences are
another set of metrics.

73
00:05:11,280 --> 00:05:16,680
They imply measuring interactions
associated with actual user experiences.

74
00:05:17,130 --> 00:05:21,930
It helps us connect backend
performance to front-end experiences.

75
00:05:22,860 --> 00:05:27,450
As you can see, these are some of
the key metrics that we can possibly

76
00:05:27,450 --> 00:05:33,659
integrate and automate for staying on
top of various issues that could occur

77
00:05:33,930 --> 00:05:36,480
in large scale distributed systems.

78
00:05:36,980 --> 00:05:43,055
Now let us take a look at our typical
example of distributed tracing in action.

79
00:05:43,555 --> 00:05:48,425
When it comes to distributed tracing, it
is a sort of a chain or lifecycle from the

80
00:05:48,425 --> 00:05:53,525
time request enters the system and goes
through various hops as it goes through

81
00:05:53,615 --> 00:05:58,355
as part of interconnected subsystem and
services to cater to the end user request.

82
00:05:59,075 --> 00:06:02,225
So it start, as you can see from
the left-hand side, it starts all

83
00:06:02,225 --> 00:06:03,695
the way from front end request.

84
00:06:04,085 --> 00:06:09,455
User interaction initiates a traced
TDP request with unique correlation id.

85
00:06:10,385 --> 00:06:14,075
It then propagates trace context
while routing to downstream.

86
00:06:14,075 --> 00:06:19,205
Microservices at the database query
level spans indicates performance

87
00:06:19,205 --> 00:06:24,054
bottlenecks with 200 millisecond
latency exceeding threshold, and finally

88
00:06:24,385 --> 00:06:30,354
completed trace shows full request path
with timing metrics across services.

89
00:06:30,715 --> 00:06:31,734
It's called response chain.

90
00:06:32,695 --> 00:06:37,914
So now that we have discussed pillars of
observability and key metrics that matter.

91
00:06:38,275 --> 00:06:43,254
Let us understand typical business
impact of observability and what

92
00:06:43,254 --> 00:06:48,534
gains can we possibly realize
by employing such measures in

93
00:06:48,534 --> 00:06:50,664
large scale distributed systems.

94
00:06:51,164 --> 00:06:56,025
So with appropriate observability
in place, we can drastically reduce

95
00:06:56,205 --> 00:07:02,864
time taken to identify and locate the
underlying root cause by at least 60%.

96
00:07:03,825 --> 00:07:04,034
This.

97
00:07:04,534 --> 00:07:09,455
Immediately translates and results
into faster troubleshooting Times

98
00:07:10,445 --> 00:07:15,545
mean time to recovery is a popular
KPI in industry that helps us measure

99
00:07:15,905 --> 00:07:21,125
mean time taken to resolve the issue
through means of observability.

100
00:07:21,575 --> 00:07:26,015
It is seen to be improved by
at least 25% and improved.

101
00:07:26,015 --> 00:07:30,695
MTTR is used to measure
systems overall maturity.

102
00:07:31,195 --> 00:07:36,325
Uptime is another KPI that is widely
used to measure reliability of

103
00:07:36,325 --> 00:07:38,905
highly available user facing system.

104
00:07:39,655 --> 00:07:44,935
And it has been assessed that with due
observability in place we can realize

105
00:07:44,995 --> 00:07:47,695
increase in uptime by at least 30%.

106
00:07:48,655 --> 00:07:52,914
So in summary, with proper attention
to designing and configuring

107
00:07:52,914 --> 00:07:57,534
observability, we can realize
business impact to increase uptime.

108
00:07:58,075 --> 00:07:58,435
Reduce.

109
00:07:58,435 --> 00:07:59,125
MTTR.

110
00:07:59,574 --> 00:08:01,464
And faster root cause analysis.

111
00:08:01,964 --> 00:08:06,765
So on one hand it is about building
observability in the system

112
00:08:07,454 --> 00:08:11,564
through designing and configuring
various metrics and tracking KPIs.

113
00:08:11,804 --> 00:08:16,844
While on the other hand it is about
alerting from the system with when

114
00:08:16,844 --> 00:08:22,094
some or all of these metrics and
thresholds hit at the runtime.

115
00:08:22,594 --> 00:08:24,545
Alerting helps us notify teams.

116
00:08:25,010 --> 00:08:29,869
Systems and stakeholders of detected
anomalies during its operation.

117
00:08:30,619 --> 00:08:34,730
It is systems way of saying something
needs an immediate attention.

118
00:08:35,690 --> 00:08:38,569
As you can see here, it starts
from the bottom of the pyramid.

119
00:08:39,069 --> 00:08:43,245
We usually start by
watching capacity trends.

120
00:08:43,755 --> 00:08:48,364
This capacity could be compute,
storage network, io, and so on.

121
00:08:48,864 --> 00:08:53,064
Through means of thresholds, we keep
track of possible early warning signs,

122
00:08:53,394 --> 00:08:58,494
things that could potentially become
catastrophic through monitoring critical

123
00:08:58,524 --> 00:09:00,714
infrastructure components we treat.

124
00:09:01,104 --> 00:09:03,384
We keep track of overall systems health.

125
00:09:04,134 --> 00:09:08,214
All of these result into configuring
alerts that impact business

126
00:09:08,214 --> 00:09:12,474
metrics, issues that affect
end customers of the service.

127
00:09:12,974 --> 00:09:17,114
After going through all these concept
concepts, you might wonder how do

128
00:09:17,114 --> 00:09:21,944
we go about it and how do we set
ourselves up for success when actually

129
00:09:21,944 --> 00:09:25,154
implementing these observability
measures throughout the system?

130
00:09:25,654 --> 00:09:30,109
So observability implementation roadmap
typically looks something like this.

131
00:09:30,609 --> 00:09:33,249
It starts with defining key metrics.

132
00:09:34,224 --> 00:09:38,664
That identify critical signals
that indicate system health through

133
00:09:38,664 --> 00:09:40,734
keeping focus on business outcomes.

134
00:09:41,234 --> 00:09:43,304
The second aspect is instrumenting code.

135
00:09:43,804 --> 00:09:48,694
Instrumenting code is about adding
metrics, logging, tracing to the

136
00:09:48,694 --> 00:09:53,674
application code through means of using
standard conventions and coding practices.

137
00:09:54,174 --> 00:09:58,134
Once the metrics are collected, once
the metrics are tracked, they're

138
00:09:58,134 --> 00:09:59,724
collected at a centralized place.

139
00:10:00,234 --> 00:10:04,554
So designing solutions to harvest
these metrics into common, configurable

140
00:10:04,884 --> 00:10:10,254
and scalable storage solutions enable
co. It enables correlation across

141
00:10:10,254 --> 00:10:14,424
interconnected services because
they're stored at commonplace.

142
00:10:15,234 --> 00:10:18,294
The last aspect of it is
visualizing and alerting.

143
00:10:18,624 --> 00:10:24,474
So we create dashboards and alerting
rules and carefully ensure to continuously

144
00:10:24,474 --> 00:10:29,574
eliminate noise and false positives
so that it's a high quality alerting.

145
00:10:30,114 --> 00:10:31,404
Display mechanism.

146
00:10:31,904 --> 00:10:33,424
Now let's see.

147
00:10:33,424 --> 00:10:38,344
What are common pitfalls to avoid
while implementing these observ

148
00:10:38,344 --> 00:10:39,604
observability measures in the system?

149
00:10:40,104 --> 00:10:40,854
Alert fatigue.

150
00:10:41,514 --> 00:10:46,494
It is very common to fall trap to too
many alerts resulting into your team

151
00:10:47,019 --> 00:10:52,154
ignoring the critical ones amidst
unmanageable stream of alerts instead.

152
00:10:52,499 --> 00:10:57,059
We should focus on high quality,
actionable alerts that are meaningful

153
00:10:57,479 --> 00:11:02,819
and helps everyone with meaningful
message and corrective actions to be

154
00:11:02,819 --> 00:11:04,889
taken to resolve the issue at hand.

155
00:11:05,389 --> 00:11:10,909
Cost overs, collecting everything and
storing it can turn out to be expensive,

156
00:11:11,599 --> 00:11:16,699
both on the dis storage as well as
the code that further slows down as

157
00:11:16,699 --> 00:11:20,959
it is running metrics computation
logic besides actual business logic.

158
00:11:21,859 --> 00:11:26,539
Idea here is to sample high
volume telemetry and stay at just

159
00:11:26,539 --> 00:11:31,659
enough threshold of collecting
metrics and computing KPIs too.

160
00:11:31,659 --> 00:11:32,229
Overload.

161
00:11:33,009 --> 00:11:37,839
Using too many disparate systems can be
challenging for the teams to adapt, so

162
00:11:37,839 --> 00:11:39,879
try to consolidate wherever possible.

163
00:11:40,149 --> 00:11:45,069
Streamlining and standardizing
tool is an ongoing process.

164
00:11:45,219 --> 00:11:47,139
With system becoming more mature.

165
00:11:47,499 --> 00:11:48,879
Teams tend to gravitate.

166
00:11:49,404 --> 00:11:53,784
To fewer number of tools leading
to system-wide standardization

167
00:11:53,784 --> 00:11:56,274
processes, vanity metrics.

168
00:11:56,724 --> 00:12:00,984
It is easy to fall into the false
notion of everything is important.

169
00:12:01,494 --> 00:12:05,994
Instead of tracking everything,
focus on metrics that tie to business

170
00:12:05,994 --> 00:12:11,364
outcomes, metrics that matter from
enhancing business impact perspective.

171
00:12:11,864 --> 00:12:15,524
Now, as we come close to
the closing this session.

172
00:12:15,884 --> 00:12:19,964
Let us go through key takeaways
that we have learned and

173
00:12:19,964 --> 00:12:21,344
understood as part of this session.

174
00:12:21,844 --> 00:12:27,004
Observability is essential
and not optional for any large

175
00:12:27,004 --> 00:12:28,804
scale distributed systems.

176
00:12:29,734 --> 00:12:31,619
When it comes to wholesome observability.

177
00:12:32,284 --> 00:12:37,234
Integrate all the three pillars,
that is metrics, logs, and tracing.

178
00:12:38,194 --> 00:12:42,694
Measure business impact, connect
technical metrics to business outcomes.

179
00:12:43,144 --> 00:12:49,564
The ones that enhances meaningful business
impact build observability culture.

180
00:12:49,744 --> 00:12:51,154
This one is the most important one.

181
00:12:51,844 --> 00:12:56,284
We have to train our teams to develop
appreciation and I to leverage

182
00:12:56,554 --> 00:13:00,844
these observability metrics that
will help them connect the dots.

183
00:13:01,344 --> 00:13:02,449
I hope this session was.

184
00:13:03,124 --> 00:13:07,774
Helpful to all of you to understand
and acknowledge the importance of

185
00:13:07,774 --> 00:13:12,094
designing and developing various
observability measures to further

186
00:13:12,094 --> 00:13:16,384
enhance operational efficiency in
large scale distributed systems.

187
00:13:17,134 --> 00:13:18,274
Thank you for your time today.

