1
00:00:00,000 --> 00:00:00,690
Good afternoon.

2
00:00:01,200 --> 00:00:04,170
My name is Mi Riz and
I'm Chief Data Officer.

3
00:00:04,230 --> 00:00:08,670
At Stop, we'll talk about how we
approach the uplift ing challenge.

4
00:00:08,730 --> 00:00:12,950
At Mode TV we'll discuss how we
frame the problem, the data we use to

5
00:00:12,950 --> 00:00:14,960
solve and how we work with the data.

6
00:00:15,559 --> 00:00:18,470
Next, we'll focus on the
process of training the model

7
00:00:18,830 --> 00:00:20,030
and challenges we tackled.

8
00:00:20,660 --> 00:00:25,689
Finally, we'll review the results of, we
obtained a brief overview of our company.

9
00:00:26,409 --> 00:00:31,629
More TV is online video services where
users can buy a subscription and renew

10
00:00:31,629 --> 00:00:37,360
it monthly or here to watch ads instead
of subscribing in the what scenario.

11
00:00:37,480 --> 00:00:40,059
We are a revenue as an
advertising platform.

12
00:00:40,559 --> 00:00:43,089
Our goal is to grow our subscribers.

13
00:00:43,449 --> 00:00:49,329
Subscription base or way to do this
is by offering user a discount.

14
00:00:49,929 --> 00:00:50,949
The logic is simple.

15
00:00:51,549 --> 00:00:56,769
It's better to somewhat less from
a user if that secures a recurring

16
00:00:56,889 --> 00:01:02,919
payment, that it's is still more
variable than advertising for revenue.

17
00:01:03,729 --> 00:01:07,479
However, the challenge is in the
defined user who will have subscribed

18
00:01:07,839 --> 00:01:12,549
without a discount, so we don't
lose profit unnecessarily at uplift.

19
00:01:12,729 --> 00:01:16,179
Denning, help us to solve this problem.

20
00:01:16,679 --> 00:01:21,509
The goal of applying for Modern Inc is
to predict how users target variable.

21
00:01:21,989 --> 00:01:28,079
That subscription purchase will differ
if they are targeted, for example,

22
00:01:28,079 --> 00:01:32,759
offer a discount versus if they're
not targeted, we can both target

23
00:01:32,759 --> 00:01:34,379
and not target the same person.

24
00:01:34,709 --> 00:01:37,798
So we're really on the
average treatment effect.

25
00:01:38,774 --> 00:01:42,134
The difference in subscription purchases
between the group that receives the

26
00:01:42,134 --> 00:01:46,814
discount test and the group that
didn't control because we randomly

27
00:01:46,814 --> 00:01:49,814
split users into the test and control.

28
00:01:50,084 --> 00:01:53,644
This metrics meet will in
additional to predict accuracy.

29
00:01:53,704 --> 00:01:58,174
Our main non-functional requirements
are stability and adaptability.

30
00:01:59,164 --> 00:02:02,854
They fall from the high cost
of user acquisition and hence

31
00:02:02,854 --> 00:02:04,474
of user communication data.

32
00:02:04,974 --> 00:02:07,854
And from the elastic nature
of movie TV show demand.

33
00:02:08,754 --> 00:02:13,524
Since there are frequent new
release, the model must not over

34
00:02:13,524 --> 00:02:19,074
feed to specific shows, but should
focus on more timeless indicators

35
00:02:19,574 --> 00:02:23,854
for, we use the data from experiment
in which the test group was offered

36
00:02:23,884 --> 00:02:26,134
a free six days TRIO extension.

37
00:02:26,634 --> 00:02:31,884
While the control group received no offer,
Ana will show on the website so that it

38
00:02:32,154 --> 00:02:37,424
couldn't be missed After the bonus trial
period ended, we checked where the P users

39
00:02:37,484 --> 00:02:39,464
converted to a paid subscription or not.

40
00:02:39,964 --> 00:02:45,834
Hence, we know where the users
was offered the extension and

41
00:02:45,834 --> 00:02:48,174
whether they ultimately subscript.

42
00:02:48,674 --> 00:02:53,769
We, we derive searching features
per users based on how they interact

43
00:02:53,769 --> 00:02:59,784
with smart tv, the player, the
search function and project pages.

44
00:03:00,284 --> 00:03:04,629
For example, for the player,
it's how often he watched project

45
00:03:04,869 --> 00:03:06,849
TV, shows, movie, et cetera.

46
00:03:07,779 --> 00:03:08,859
search function.

47
00:03:08,859 --> 00:03:09,729
It's how.

48
00:03:10,614 --> 00:03:14,094
The number of key that he yielded,
no results and yielded with the

49
00:03:14,094 --> 00:03:16,073
results and, features from project.

50
00:03:16,073 --> 00:03:21,054
It's something connected with,
similar to this most user accuracy

51
00:03:21,054 --> 00:03:23,294
in the player activity in the player.

52
00:03:23,354 --> 00:03:25,544
So that's where most features come from.

53
00:03:26,084 --> 00:03:30,674
Of course, we log much more data
points, but we select the features most

54
00:03:30,764 --> 00:03:33,764
indicative of eventually subscription.

55
00:03:34,264 --> 00:03:38,694
Our ION criteria was a genius score
ing each feature to conversion,

56
00:03:39,194 --> 00:03:40,743
sorry, operation falls.

57
00:03:40,923 --> 00:03:41,763
A standard flow.

58
00:03:42,334 --> 00:03:48,603
We split into train and test sets, train
model, then validate on whole al set.

59
00:03:49,414 --> 00:03:52,863
We measure the score on both
sets and ensure there neither

60
00:03:52,983 --> 00:03:54,573
overfeeding nor underfeeding.

61
00:03:55,073 --> 00:03:55,643
That's it.

62
00:03:55,733 --> 00:03:56,843
Our model is ready.

63
00:03:57,343 --> 00:03:58,664
What is the score we used?

64
00:03:59,164 --> 00:04:02,823
Gene is difference in shared of
success of conversion in test

65
00:04:02,823 --> 00:04:05,128
versus control, but the test.

66
00:04:05,628 --> 00:04:09,888
But for the entire sample, the
difference is always the same.

67
00:04:09,888 --> 00:04:14,508
So how we incorporate the
models prediction, we saw users

68
00:04:14,868 --> 00:04:19,608
in the standing order of the
prediction uplift from high tools.

69
00:04:20,108 --> 00:04:25,299
Lower for each segment, we calculate
gene among the users with a higher score.

70
00:04:25,799 --> 00:04:30,179
We then plot gen against the number
of users conducting something

71
00:04:30,208 --> 00:04:32,038
like the solu line on the chart.

72
00:04:32,538 --> 00:04:37,813
This one, this is a gene curve
representing additional revenue.

73
00:04:38,313 --> 00:04:42,233
We compare it with a random assignment
with this line area between the.

74
00:04:42,953 --> 00:04:45,493
Cur is the gene score V six.

75
00:04:45,493 --> 00:04:49,913
To maximize this one, gene measures
the difference in success of conversion

76
00:04:49,913 --> 00:04:51,953
between the test and control groups.

77
00:04:52,433 --> 00:04:55,163
For the total samples,
the difference is static.

78
00:04:55,883 --> 00:05:00,953
To leverage op prediction, we start
users by the predict, update and compute.

79
00:05:01,453 --> 00:05:05,593
By step Ploting is produced
the gen curve, which shows the

80
00:05:05,593 --> 00:05:07,513
potential extra gain from targeting.

81
00:05:08,013 --> 00:05:11,153
We compare that curve to
a random baseline there.

82
00:05:11,153 --> 00:05:13,883
Between there and the gen
score is our K Metric.

83
00:05:14,453 --> 00:05:16,613
For example, we use sums.

84
00:05:17,113 --> 00:05:18,498
Initially we tried random splits.

85
00:05:18,998 --> 00:05:22,658
Each user had an equal probability
of being in the training or tested.

86
00:05:23,348 --> 00:05:29,378
However, we noticed that depending on
how this speed was done, model performer

87
00:05:29,378 --> 00:05:31,358
could swing to opposite extremes.

88
00:05:32,318 --> 00:05:36,908
Is close to equal or was the
random ranking, which was.

89
00:05:37,408 --> 00:05:41,553
To confirm that the issue was not
memory, unlike validation sets, we

90
00:05:41,553 --> 00:05:45,843
fixed the validation set and assembled
the ring set from the remaining

91
00:05:45,843 --> 00:05:50,193
samples randomly with replacement,
similar to a bolt strip approach.

92
00:05:50,693 --> 00:05:55,793
The validation score still showed a
wide variance and the remains stable

93
00:05:56,213 --> 00:05:59,633
even after 400 experience integrations.

94
00:06:00,293 --> 00:06:02,543
This indicates we need to different.

95
00:06:03,043 --> 00:06:06,223
Splitting approaches to
achieve stable results.

96
00:06:07,033 --> 00:06:12,573
You can hear there is 95%
of rep is stably high,

97
00:06:13,073 --> 00:06:17,183
or we have solution was to
split by user registration date.

98
00:06:17,483 --> 00:06:22,373
We put the more experienced older
users into the training set and

99
00:06:22,373 --> 00:06:24,143
the newest users into the test set.

100
00:06:24,503 --> 00:06:29,093
This also nicely mirrors how
we had handled production.

101
00:06:29,693 --> 00:06:36,163
Whereas a model will predict for a new
arrivals, we used an 80% to trade, 20%

102
00:06:36,163 --> 00:06:42,093
train validation split and train on
a forest from the occasional library.

103
00:06:42,593 --> 00:06:48,393
Looking at the graph, however, users,
spread across a few distant peaks.

104
00:06:48,893 --> 00:06:53,783
You can't is delay the most pro
promising users with just one trace hold.

105
00:06:54,173 --> 00:06:55,463
There are three spikes.

106
00:06:55,463 --> 00:06:58,073
So we tried an other approach as well.

107
00:06:58,433 --> 00:07:03,793
First, second, sir, and we can't
use the threshold unfortunately.

108
00:07:04,293 --> 00:07:07,053
The second approach was
to stratify the data.

109
00:07:07,553 --> 00:07:12,263
If the feature in the training
and test set as disturbed simul,

110
00:07:12,984 --> 00:07:18,193
sorry, similarly and similarly to
the population distribution model

111
00:07:18,193 --> 00:07:19,543
result should be more stable.

112
00:07:20,143 --> 00:07:26,203
But which feature do we use to certify,
including them all produced to many Strat?

113
00:07:26,533 --> 00:07:30,673
So we settled on three, the
user's number of active days.

114
00:07:31,173 --> 00:07:35,163
Where they converted and where
they will offer the discount.

115
00:07:35,974 --> 00:07:39,994
We choose number of activity days
because it has the highest genius score

116
00:07:40,293 --> 00:07:42,123
for prediction subscription conversion.

117
00:07:42,623 --> 00:07:48,744
Our goal is to end up with
80 to 20% speed in the drink.

118
00:07:49,443 --> 00:07:50,583
Train and test sets.

119
00:07:51,123 --> 00:07:56,153
If you're certified to select 50% of
the data as the initial training set

120
00:07:57,053 --> 00:08:01,454
from the remaining half repeatedly
sample 1000 examples, reserve being

121
00:08:01,663 --> 00:08:06,523
stratum proportion, and then to the
training set, train a model, and

122
00:08:06,523 --> 00:08:08,469
then test it on the leftover of that.

123
00:08:09,179 --> 00:08:14,369
If the journey on drain and test
differs by less than 5% while out

124
00:08:14,369 --> 00:08:18,628
performing random ranking, we keep
this 1000 samples in the training set.

125
00:08:19,439 --> 00:08:20,969
Otherwise, we discard them.

126
00:08:21,469 --> 00:08:22,169
We discard them.

127
00:08:22,684 --> 00:08:24,664
We continue until the train set eight.

128
00:08:24,844 --> 00:08:29,464
If 80% of the rolled data,
this reduced the number of

129
00:08:29,464 --> 00:08:31,864
picks on the graphs somewhat.

130
00:08:31,939 --> 00:08:35,389
Two, two picks, but we
still didn't see the desire.

131
00:08:35,749 --> 00:08:36,558
Tight clustering.

132
00:08:37,039 --> 00:08:40,489
At the top of the rank, we
continue can choose the threshold.

133
00:08:40,989 --> 00:08:43,509
Our short approach was
to stomp on sampling.

134
00:08:44,473 --> 00:08:49,329
The idea is that the remaining 50%
of data not in the training test,

135
00:08:49,329 --> 00:08:54,608
it speeds into clusters and we pick
data from the cluster with the higher

136
00:08:55,239 --> 00:08:57,249
rate of successful training attempts.

137
00:08:57,749 --> 00:09:03,359
This is a way we in incorporate
prior each duration outcomes and any

138
00:09:03,359 --> 00:09:06,209
environmental changes for each cluster.

139
00:09:06,209 --> 00:09:12,719
We assign a better function distribution
and update its parameters based on where

140
00:09:12,719 --> 00:09:15,694
the drink attempt was successful or not.

141
00:09:16,194 --> 00:09:20,794
This algorithm is similar to the previous
one, expect except, instead of pulling

142
00:09:20,883 --> 00:09:25,503
data from the entire pool, we pulled
it from just one of the four clusters,

143
00:09:25,924 --> 00:09:31,204
and after trying, we adjust the better
distribution parameter for that cluster.

144
00:09:31,924 --> 00:09:35,733
In theory, it should converge
to a better outcomes.

145
00:09:36,723 --> 00:09:40,324
Unfortunately, in about
health cases, we can get.

146
00:09:40,824 --> 00:09:41,903
It converge.

147
00:09:42,538 --> 00:09:45,983
Converge within one 10,000 iterations.

148
00:09:46,434 --> 00:09:50,243
So there is also, we now, we don't
have any pix, but we continue,

149
00:09:50,753 --> 00:09:52,913
it's hard to choose a threshold.

150
00:09:53,423 --> 00:09:58,673
and our final method, the first
one is combined database spliting

151
00:09:58,823 --> 00:10:04,633
with tons sampling, sorry, is
combination of our, that database.

152
00:10:05,038 --> 00:10:05,848
Registration.

153
00:10:05,848 --> 00:10:11,488
And with Thompson Sampling, we first
pick the oldest 50% of users of for

154
00:10:11,488 --> 00:10:16,078
training and Zen Row from the other
half in cluster via Thompson sampling.

155
00:10:16,578 --> 00:10:22,128
This approach almost always converts
and learn to rank users more

156
00:10:22,218 --> 00:10:23,868
tied in near the top of the list.

157
00:10:24,738 --> 00:10:30,888
So now we can choose the threshold and
we choose the 20%, which is likely zero.

158
00:10:31,388 --> 00:10:32,648
The model's performance.

159
00:10:33,158 --> 00:10:35,828
We take a cohort of new
users to TR on trial.

160
00:10:36,308 --> 00:10:41,159
Five percentage are offered no
discount, and five percentage percent

161
00:10:41,159 --> 00:10:42,959
receives the discount in any key.

162
00:10:43,949 --> 00:10:48,598
This provides our goal standard control
and test group to compare conversion

163
00:10:48,659 --> 00:10:51,539
and see if there a genuine effect.

164
00:10:52,468 --> 00:10:55,529
This scores remind 90% with our model.

165
00:10:55,814 --> 00:11:00,754
Select the top 20% by prediction,
uplift, and give them an offer.

166
00:11:00,934 --> 00:11:03,653
This one, then we compare
subscription conversion.

167
00:11:04,153 --> 00:11:07,123
We expect higher conversion
among those offers.

168
00:11:07,123 --> 00:11:10,423
Discount versus the non no discount group.

169
00:11:11,233 --> 00:11:15,973
While the group that didn't receive
the offer should perform on par

170
00:11:16,303 --> 00:11:17,353
with no offer control group.

171
00:11:18,283 --> 00:11:22,603
Meaning we are not losing potential
subscribe subscribers who should

172
00:11:22,753 --> 00:11:24,223
have been given a discount.

173
00:11:24,723 --> 00:11:27,933
Our next plan to test different
discount among the lengths.

174
00:11:28,433 --> 00:11:32,603
I also personalize lies
the offer even more.

175
00:11:33,203 --> 00:11:34,643
We also intend to find the.

176
00:11:35,143 --> 00:11:39,223
Optimum timing of discount should
appear the first, second, or third weeks

177
00:11:39,223 --> 00:11:43,243
after the initial period and experience
with the offer for users who have

178
00:11:43,323 --> 00:11:47,488
multiple subscription or already, for
example, offer for first subscription,

179
00:11:47,523 --> 00:11:49,563
second subscription, and this third.

180
00:11:50,433 --> 00:11:51,843
So that's all.

181
00:11:51,903 --> 00:11:53,673
Let me show the overview.

182
00:11:53,673 --> 00:11:54,813
What we have done.

183
00:11:55,383 --> 00:11:56,733
We used uplift modeling to.

184
00:11:57,233 --> 00:12:00,353
the, to improve our subscription base.

185
00:12:01,133 --> 00:12:05,733
For that, we use uplift with,
few steps of analyze data.

186
00:12:06,063 --> 00:12:10,373
First one we used, we just,
randomly speeds the test and

187
00:12:10,643 --> 00:12:13,153
control and test and control.

188
00:12:13,653 --> 00:12:20,553
after that we used, Strata function,
diet, that register date and Thompson

189
00:12:20,553 --> 00:12:25,463
sampling and as a result of our
final destination is, combined the

190
00:12:25,463 --> 00:12:28,223
data registration and some sampling.

191
00:12:28,828 --> 00:12:29,448
That's all.

192
00:12:29,698 --> 00:12:30,808
Thank you for watching.

193
00:12:31,628 --> 00:12:31,848
Bye.

