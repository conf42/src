1
00:00:00,500 --> 00:00:01,130
Hi everyone.

2
00:00:01,520 --> 00:00:02,690
I'm Marmo.

3
00:00:02,690 --> 00:00:06,560
I'm currently working as a senior
software engineer at Nvidia, and

4
00:00:06,590 --> 00:00:08,480
I'm very excited about this talk.

5
00:00:08,840 --> 00:00:12,660
And the topic is open telemetry
or open tele solving absorbability

6
00:00:12,660 --> 00:00:14,189
problems for creating new ones.

7
00:00:14,680 --> 00:00:15,779
Let's get started.

8
00:00:16,279 --> 00:00:20,079
The agenda of this topic of the talk is
I will start with the basic introduction

9
00:00:20,079 --> 00:00:25,500
about mental, elementary, and later we'll
into the promise and kind of issues solve.

10
00:00:26,000 --> 00:00:30,700
And later we'll go over the reality
of open telemetry and the problems

11
00:00:30,730 --> 00:00:34,870
the new problems it creates, and and
we'll also discuss about whether does

12
00:00:34,870 --> 00:00:38,850
Open Telemetry makes sense and the
strategies for taming some of the

13
00:00:38,850 --> 00:00:41,520
issues the open telemetry opens up.

14
00:00:42,030 --> 00:00:44,690
And finally, the feature
outlook and the conclusion.

15
00:00:45,190 --> 00:00:49,735
So at first the introduction open Tele
is a collection of a PS and SDKs that

16
00:00:49,735 --> 00:00:54,355
would help users to instrument generate
and collect and export the tele data.

17
00:00:54,665 --> 00:00:58,755
It covers all basic absorbability
signals like metrics, logs, and traces.

18
00:00:59,155 --> 00:01:03,290
If you look into the picture at the left
hand side the open provides a different

19
00:01:03,420 --> 00:01:05,745
a PS SDKs to instrument application.

20
00:01:06,240 --> 00:01:08,550
At the middle, you have a
open Telemetry character.

21
00:01:09,010 --> 00:01:13,500
The Open Telemetry character is very
powerful aggregator that could basically

22
00:01:13,839 --> 00:01:17,645
collect your metrics and send to a
different absorbability backends.

23
00:01:18,145 --> 00:01:22,675
For example ME metrics can be sent
to some of the third party vendors

24
00:01:22,675 --> 00:01:24,304
like graph and Cloud Datadog.

25
00:01:24,804 --> 00:01:29,595
Similarly, locks can be sent to
Elasticsearch Splunk tracers could

26
00:01:29,595 --> 00:01:32,245
be sent to different other vendors.

27
00:01:32,745 --> 00:01:35,945
And the promise and the core
problems on the open solves.

28
00:01:36,445 --> 00:01:39,535
The first most important is
the vendor lock in elimination

29
00:01:39,985 --> 00:01:41,405
pre open telemetry world.

30
00:01:41,585 --> 00:01:46,695
Every third party vendor has a different
proprietary agents for the SDS APIs

31
00:01:47,415 --> 00:01:49,475
and Open Telemetry solve this problem.

32
00:01:49,475 --> 00:01:53,875
So you can basically instrument once
your application and you can send

33
00:01:53,875 --> 00:01:58,005
to whatever third party vendor or
whatever backend you wanna send to.

34
00:01:58,950 --> 00:02:02,070
And the other problem it
solved is unified standards.

35
00:02:02,980 --> 00:02:07,530
It standardized different open standards
like it combined open tracing and open

36
00:02:07,530 --> 00:02:12,385
sensors, and it also standardized tele
collection across different languages.

37
00:02:12,885 --> 00:02:16,145
And the other problem it solved
is complete signal coverage.

38
00:02:16,760 --> 00:02:20,420
As I mentioned before it supports
instrumenting and collecting

39
00:02:20,470 --> 00:02:22,120
metrics, traces, and logs.

40
00:02:22,750 --> 00:02:25,780
And also it solves the problem
of co correlating these

41
00:02:25,840 --> 00:02:27,950
signals to analyze the deeper.

42
00:02:28,450 --> 00:02:31,560
And the other problem it solved
is suppression of con concerns.

43
00:02:32,355 --> 00:02:36,204
It decoupled meta collect telemetric
collection from the analysis.

44
00:02:37,045 --> 00:02:40,195
Yeah, as I mentioned, the open
telemetry is very powerful aggregator

45
00:02:40,825 --> 00:02:44,475
and you can also choose any
compatible backend you want to choose.

46
00:02:44,975 --> 00:02:48,394
And the other important problem
it solved is auto instrumentation

47
00:02:48,394 --> 00:02:49,864
before open telemetry here.

48
00:02:50,294 --> 00:02:55,544
If you wanna, instrument your
code to collect different signals.

49
00:02:56,084 --> 00:03:00,854
You need to write a lot of boiler plate
and custom code and open telemetry.

50
00:03:00,854 --> 00:03:05,364
In many of the cases it provides
auto instrumentation capabilities.

51
00:03:06,234 --> 00:03:11,014
And instead of writing any code, you
can just start exporting over telemetry.

52
00:03:11,514 --> 00:03:15,789
And it also had very
good community adoption.

53
00:03:16,219 --> 00:03:20,514
It's one of the second largest
active CNCF project, and it has

54
00:03:20,514 --> 00:03:25,594
very active roadmap given all the
advantages and problems it solved.

55
00:03:26,054 --> 00:03:28,944
It also contributed to some new problems.

56
00:03:29,334 --> 00:03:35,434
So in reality users and community adapters
have been facing different problems.

57
00:03:35,934 --> 00:03:40,214
The first one is technology, ma if you
look at, to if you look at the open

58
00:03:40,214 --> 00:03:45,494
telemetry documentation if you want to get
started with you'll be worried with the

59
00:03:45,494 --> 00:03:48,994
different technologies like SDKs and APIs.

60
00:03:49,364 --> 00:03:53,929
So it it has too many layers of
indirection and abstractions and also

61
00:03:54,009 --> 00:03:56,119
architecturally it's quite complex.

62
00:03:56,879 --> 00:04:01,799
Each component has its own unique
configurations and different

63
00:04:01,879 --> 00:04:06,719
a lot of components, lot of
exporters, process tickets.

64
00:04:07,409 --> 00:04:09,509
It's not very easy to get started.

65
00:04:10,009 --> 00:04:13,699
And the other problem is the language
implementation in inconsistencies.

66
00:04:14,419 --> 00:04:17,539
So one of the pro, one of the
problems open telemetry solve is if

67
00:04:17,539 --> 00:04:22,564
you, and if your dev environment is
polyglot, it unifies how you collect,

68
00:04:23,044 --> 00:04:24,604
how you instrument your telemetry.

69
00:04:25,104 --> 00:04:29,954
But in reality when you are implementing
augment Elementary in your environment.

70
00:04:30,429 --> 00:04:32,159
There are tricks and trips.

71
00:04:32,789 --> 00:04:36,179
Each language has, and
there are implementation

72
00:04:36,179 --> 00:04:38,519
consistencies inconsistencies.

73
00:04:39,019 --> 00:04:41,059
And the other problem is
the maturity spectrum.

74
00:04:41,939 --> 00:04:44,759
Different components are at
different maturity levels.

75
00:04:45,639 --> 00:04:50,549
For example if you consider the broader
signals tracing is the most most matured.

76
00:04:51,014 --> 00:04:53,774
And later comes the
metrics and the logging.

77
00:04:53,904 --> 00:04:56,084
Logging is very recent entrant.

78
00:04:56,084 --> 00:04:59,859
And it was only when, only recently.

79
00:05:00,359 --> 00:05:03,479
And also getting sorted, decided
as a top barrier to adoption.

80
00:05:03,979 --> 00:05:07,409
And also, yeah, it's very difficult
to debug when something goes wrong.

81
00:05:07,869 --> 00:05:10,909
Problems across instrumentation,
col collection, export.

82
00:05:11,749 --> 00:05:14,239
And other is the character configurations.

83
00:05:14,289 --> 00:05:18,209
So you'll be basically, you'll
see a very big a ML configurations

84
00:05:18,214 --> 00:05:20,149
and mismatched component names.

85
00:05:20,629 --> 00:05:23,989
And sometimes you need to
configure our own authentication.

86
00:05:24,379 --> 00:05:27,199
And they will see lots of
connect connectivity issues.

87
00:05:27,689 --> 00:05:31,449
So if you want to get something
resolved with the community and if

88
00:05:31,449 --> 00:05:35,179
you are trying to file an issue you'll
be bonds between a different reports.

89
00:05:35,679 --> 00:05:40,199
So given the problems it solves and the
kind of implementation challenges we have

90
00:05:40,199 --> 00:05:42,999
seen when does Open telemetry make sense?

91
00:05:43,499 --> 00:05:48,353
So it makes sense when you have, when when
you are organization has a very large and

92
00:05:48,368 --> 00:05:53,013
diverse technology stacks and you wanna
standardize across these environments.

93
00:05:53,513 --> 00:05:57,103
And it helps when value exceeds
the implementation complexity.

94
00:05:57,193 --> 00:06:00,498
So you need to take a call and
look at the tradeoffs there.

95
00:06:00,998 --> 00:06:05,328
And also if your automation is looking
for a very strong rental, neutral

96
00:06:05,853 --> 00:06:11,093
telemetry collection and exporters,
then open telemetry makes sense.

97
00:06:11,593 --> 00:06:16,883
It would be a very long-term investment
and you will have a lot of flexibility

98
00:06:17,213 --> 00:06:18,563
in the observability providers.

99
00:06:19,063 --> 00:06:19,933
It also makes sense.

100
00:06:19,938 --> 00:06:21,163
Very very makes sense.

101
00:06:21,163 --> 00:06:25,383
In the cloud data environments, it
is very ideal for distributed systems

102
00:06:25,713 --> 00:06:29,738
under monitoring container containerized
applications like Kubernetes.

103
00:06:30,238 --> 00:06:35,258
It also provides it makes sense where
you have data flexibility requirements

104
00:06:36,248 --> 00:06:40,218
where you need to have good control over
your data collection and the routing.

105
00:06:40,218 --> 00:06:43,668
And they also need the filtering
capabilities to reduce nice and costs.

106
00:06:44,328 --> 00:06:47,233
And you wanna add custom tag
for your automation searching.

107
00:06:47,733 --> 00:06:52,018
So how do you strategize
and obtain the tele issues?

108
00:06:52,518 --> 00:06:55,058
So you can start with auto
instrumentation options.

109
00:06:55,698 --> 00:06:58,838
Big, you can begin with language
specific auto instrumentation.

110
00:06:59,538 --> 00:07:03,819
For example, in E case E case is
AWS managed Kubernetes service.

111
00:07:04,388 --> 00:07:08,338
So it has open telemetry characters
that they can use by default.

112
00:07:09,158 --> 00:07:12,718
And also you can start with the
more matured signals like as I

113
00:07:12,718 --> 00:07:17,048
mentioned before tracing is the
most matured open telemetry signal.

114
00:07:17,078 --> 00:07:22,008
So you can start with that and later and
expand to metrics and logs and also try to

115
00:07:22,008 --> 00:07:27,808
follow the latest best practices leverage
semantic connections and optimize the

116
00:07:27,808 --> 00:07:29,728
attributes and the labels you're using.

117
00:07:30,568 --> 00:07:32,578
And further faster the troubleshooting.

118
00:07:32,668 --> 00:07:34,408
You can also use the local exporters.

119
00:07:34,908 --> 00:07:38,738
It also makes sense to do implementation
instead of going for one big bank

120
00:07:38,913 --> 00:07:40,853
adoption, it can start small and iterate.

121
00:07:41,353 --> 00:07:45,603
You can focus on critical
user flow at first and expand

122
00:07:45,603 --> 00:07:48,063
gradually as an expertise grows.

123
00:07:48,563 --> 00:07:51,363
And also we can depend on
the community resources.

124
00:07:52,353 --> 00:07:57,103
Instead of only depending on documentation
I can look into community resources

125
00:07:57,103 --> 00:07:59,423
like blogs and different talks.

126
00:07:59,973 --> 00:08:01,493
You can depend on those.

127
00:08:02,493 --> 00:08:07,323
And also vendor distributions can for
adoption, for example, recently Grafana

128
00:08:07,323 --> 00:08:11,898
Cloud has come up with their own open
telemetry folk called Grafana Ally.

129
00:08:12,108 --> 00:08:14,988
So it makes implementation
adoption little easier.

130
00:08:15,488 --> 00:08:18,818
Also, there are lot, lots of active
community support and extinctions.

131
00:08:18,878 --> 00:08:22,288
So we can make use of those to
come out to overcome some of the

132
00:08:22,288 --> 00:08:24,063
challenges and some of the tele.

133
00:08:25,018 --> 00:08:30,008
The open telemetry creates our
future outlook and beyond there

134
00:08:30,008 --> 00:08:31,778
are lots of promising developments.

135
00:08:32,568 --> 00:08:35,653
One is semantic is reaching stability.

136
00:08:36,578 --> 00:08:41,118
This is very promising development
and the Open Telemetry collector

137
00:08:41,208 --> 00:08:43,317
is also approaching version one.

138
00:08:44,042 --> 00:08:48,872
This is a very powerful aggregator
and besides tracing logs and metrics

139
00:08:49,422 --> 00:08:51,692
profiling has been becoming very popular.

140
00:08:51,742 --> 00:08:55,562
Pen telemetry is also adapting that
signal and it's planning to support it.

141
00:08:56,062 --> 00:09:01,022
And gene Absorbability is also integration
within Open Telemetry ecosystem.

142
00:09:01,152 --> 00:09:04,052
It's also promising
the ongoing challenges.

143
00:09:04,512 --> 00:09:07,432
There are still many challenges
like documentation problems

144
00:09:07,497 --> 00:09:10,807
complexity management and
standardizing different test cases.

145
00:09:11,307 --> 00:09:14,647
Given all this open telemetry
is still the number one solution

146
00:09:14,707 --> 00:09:15,397
for your observable needs.

147
00:09:15,897 --> 00:09:20,007
If you're looking for a strong go
neutral all comprehensive solution.

148
00:09:20,507 --> 00:09:21,047
Thank you.

149
00:09:21,077 --> 00:09:22,502
Thank you all for your attention.

