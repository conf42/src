1
00:00:00,240 --> 00:00:01,590
Greetings of today, everyone.

2
00:00:01,890 --> 00:00:03,210
My name is Rahul Gti.

3
00:00:03,420 --> 00:00:04,380
Thanks for being here.

4
00:00:04,980 --> 00:00:06,030
Let's get started.

5
00:00:06,030 --> 00:00:06,600
Right away.

6
00:00:07,590 --> 00:00:12,360
Every minute of every day, a silent,
invisible war is being fought.

7
00:00:12,930 --> 00:00:17,160
It's not a physical battlefield,
but across the digital networks

8
00:00:17,160 --> 00:00:18,780
that power our global economy.

9
00:00:19,620 --> 00:00:23,760
The enemy is sophisticated,
relentless, and increasingly automated.

10
00:00:24,260 --> 00:00:26,690
I am talking of course
about financial fraud.

11
00:00:27,190 --> 00:00:32,530
The slide here quotes a figure
of $32 billion in global losses,

12
00:00:33,340 --> 00:00:37,600
but the reality is the problem is
accelerating at an alarming rate.

13
00:00:38,100 --> 00:00:41,700
Recent data from the US Federal
Trade Commission, a stagger.

14
00:00:42,200 --> 00:00:47,780
In 2024 alone reported consumer
losses to fraud in the us.

15
00:00:48,260 --> 00:00:55,150
Jumped over $12.5 billion, a 25%
increase in just one year, and that's

16
00:00:55,150 --> 00:00:57,430
just what's reported by the consumers.

17
00:00:57,930 --> 00:01:04,290
On the organizational side, a 2025
survey from the Association for Financial

18
00:01:04,290 --> 00:01:09,990
Professionals found that a staggering
79% of the organizations were victims

19
00:01:10,050 --> 00:01:11,850
of payment fraud attempts last year.

20
00:01:12,840 --> 00:01:16,770
This isn't just a numbers game,
it's technological arms race.

21
00:01:17,395 --> 00:01:22,645
More than 70% of the executives
expect financial crime to increase

22
00:01:22,645 --> 00:01:29,365
in 2025, citing the increased use of
AI backed criminals as a top reason

23
00:01:29,995 --> 00:01:31,645
the old defense systems are failing.

24
00:01:32,490 --> 00:01:35,070
The nature of the threat
has fundamentally changed.

25
00:01:35,250 --> 00:01:39,120
The data shows while the number of
fraud reports has remained stable,

26
00:01:39,930 --> 00:01:44,130
the percentage of people who actually
lost money in an attack jumped

27
00:01:44,130 --> 00:01:47,850
from 27% to 38% in a single year.

28
00:01:48,350 --> 00:01:53,150
This means fraudsters are becoming
far more effective in each attempt.

29
00:01:53,420 --> 00:01:55,400
This isn't a volume problem anymore.

30
00:01:55,730 --> 00:01:57,260
It's a sophistication problem.

31
00:01:58,225 --> 00:02:01,915
So today I'm here to talk
about how we engineer the front

32
00:02:01,915 --> 00:02:03,625
lines of this new battlefield.

33
00:02:04,525 --> 00:02:06,895
It's no longer about writing better rules.

34
00:02:07,405 --> 00:02:10,285
It's about building
fundamentally better platforms.

35
00:02:10,525 --> 00:02:16,435
We will explore how to architect and build
resilient AI powered systems that can not

36
00:02:16,435 --> 00:02:21,985
only detect, but anticipate and dismantle
sophisticated fraud at massive scale.

37
00:02:22,485 --> 00:02:26,505
So let's look at the
evolution of fraud detection.

38
00:02:27,005 --> 00:02:32,435
For decades, fraud detection was a game
of cat and mouse played in slow motion.

39
00:02:33,335 --> 00:02:35,675
A new fraud pattern would emerge.

40
00:02:35,975 --> 00:02:40,055
Analysts would study it, write
a new rule and deploy it.

41
00:02:40,925 --> 00:02:45,335
This is the world of traditional
rule-based systems, but these

42
00:02:45,335 --> 00:02:47,285
systems are fundamentally brittle.

43
00:02:48,125 --> 00:02:52,910
Their inflexibility meant we were
always one step behind the criminals.

44
00:02:53,410 --> 00:02:58,770
Their reliance on grid thresholds led
to high false positive rates, which

45
00:02:58,770 --> 00:03:00,210
weren't just a technical problem.

46
00:03:00,810 --> 00:03:05,760
They were a customer experience nightmare
blocking legitimate transactions,

47
00:03:05,760 --> 00:03:07,890
and creating unnecessary friction.

48
00:03:08,605 --> 00:03:13,795
And these false positives have a real
cost, not just in customer frustration,

49
00:03:14,035 --> 00:03:20,095
but an operational overhead, a cost
we later quantified at nearly $5

50
00:03:20,095 --> 00:03:23,365
million a year in our own operations.

51
00:03:23,865 --> 00:03:27,765
Furthermore, these systems
suffered from a limited context.

52
00:03:28,655 --> 00:03:33,515
They could see a single transaction,
but not the broader sinister

53
00:03:33,515 --> 00:03:37,865
pattern it was a part of, and as
transaction volumes exploded with

54
00:03:37,865 --> 00:03:43,415
rise of digital finance, these rigid
rule engines simply couldn't scale.

55
00:03:44,075 --> 00:03:48,725
This brings us to the platform
engineering imperative.

56
00:03:49,430 --> 00:03:52,940
To win this fight, we can't just
deploy a machine learning model.

57
00:03:53,690 --> 00:03:58,970
We must build a comprehensive end-to-end
platform that handles the entire life

58
00:03:58,970 --> 00:04:03,700
cycle from data ingestion, real-time
processing to model deployment,

59
00:04:03,760 --> 00:04:06,960
monitoring, and security and compliance.

60
00:04:07,460 --> 00:04:11,505
It's a foundational shift from writing
rules to engineering intelligence.

61
00:04:12,005 --> 00:04:13,415
Drill foundations.

62
00:04:13,915 --> 00:04:16,825
So what does this platform
actually look like?

63
00:04:17,455 --> 00:04:20,395
Let's walk through the critical
architectural blueprint.

64
00:04:20,455 --> 00:04:26,155
These five core layers work in
concert to deliver real time

65
00:04:26,155 --> 00:04:27,865
decisions in milliseconds.

66
00:04:28,365 --> 00:04:29,715
It all starts with data.

67
00:04:30,585 --> 00:04:36,825
The data ingestion layer is our gateway
to outside world responsible for

68
00:04:36,825 --> 00:04:42,705
collecting massive varieties of data
streams, transaction data, customer

69
00:04:42,705 --> 00:04:47,835
profiles, device information, and even
external threat intelligence feeds.

70
00:04:48,825 --> 00:04:53,295
It's the foundation of everything
that follows ensuring data quality

71
00:04:53,655 --> 00:04:55,515
and consistency from the beginning.

72
00:04:56,015 --> 00:05:03,815
Next is the central nervous system stream
processing engine for real time detection.

73
00:05:03,875 --> 00:05:07,745
We can't wait for the data
to land in the database.

74
00:05:07,895 --> 00:05:13,265
We need to analyze it in flight
where frameworks like Apache Kafka

75
00:05:13,325 --> 00:05:15,335
and Apache Flink are critical.

76
00:05:15,835 --> 00:05:21,835
For those unfamiliar, think of
Kafka as highly durable, scalable

77
00:05:22,675 --> 00:05:24,485
commit log for streaming data.

78
00:05:24,875 --> 00:05:29,315
It allows us to publish and
subscribe to data streams reliably.

79
00:05:29,815 --> 00:05:35,125
Acting as a buffer and decoupling our
data producers from data consumers.

80
00:05:35,395 --> 00:05:41,395
So Flink then acts as the computational
engine on top of these streams.

81
00:05:41,895 --> 00:05:46,125
The third component is one of the
most critical for production ml.

82
00:05:46,625 --> 00:05:51,215
The feature store, this is our
centralized single source of truth

83
00:05:51,215 --> 00:05:52,925
for machine learning features.

84
00:05:53,135 --> 00:06:00,005
It is essentially a dual database system
with an offline component for training and

85
00:06:00,055 --> 00:06:02,575
low latency online component for serving.

86
00:06:03,355 --> 00:06:06,415
It ensures the exact same feature logic.

87
00:06:06,915 --> 00:06:12,105
Is used for both training our models
and serving predictions in real time.

88
00:06:12,255 --> 00:06:16,425
This is absolutely essential to
prevent a notorious problem in

89
00:06:16,425 --> 00:06:22,005
ML lops called Training Serving
sku, where inconsistencies between

90
00:06:22,005 --> 00:06:26,715
training and production data
silently degrade model performance.

91
00:06:27,585 --> 00:06:30,015
Once we have the models,
we need to manage them.

92
00:06:30,645 --> 00:06:36,945
The model Registry is a version control
repository for our trained models.

93
00:06:37,155 --> 00:06:43,155
It's not just storage, it's the control
plane that allows our serving layer to

94
00:06:43,155 --> 00:06:45,555
deploy multiple models simultaneously.

95
00:06:46,410 --> 00:06:52,170
Run A by B tests to see which
performs better and execute gradual

96
00:06:52,170 --> 00:06:57,180
rollouts or instant rollbacks if a
model isn't performing as expected.

97
00:06:57,680 --> 00:07:01,610
Finally, the AI doesn't
always have the last word.

98
00:07:01,940 --> 00:07:07,310
The decision engine is where mission
intelligence meets human expertise.

99
00:07:07,730 --> 00:07:12,380
It takes the model's prediction
scores and combines them with

100
00:07:12,380 --> 00:07:14,330
configurable business rules.

101
00:07:15,260 --> 00:07:19,790
This allows our fraud analysts to fine
tune the platform's response, like

102
00:07:19,880 --> 00:07:25,070
triggering a step up authentication
or flagging an account for review

103
00:07:25,340 --> 00:07:27,315
without writing a single line of code.

104
00:07:27,815 --> 00:07:31,805
This isn't just a logical diagram,
it's a blueprint for agility.

105
00:07:31,985 --> 00:07:35,405
By using an event bus like
Kafka to connect these

106
00:07:35,405 --> 00:07:36,905
components, we decouple them.

107
00:07:37,655 --> 00:07:40,475
So let's see how this
platform performs under fire.

108
00:07:40,975 --> 00:07:44,605
The attack didn't start with the
bank, it started with the whisper.

109
00:07:45,105 --> 00:07:51,150
So a fraudster gains access to consumers
credentials via a phishing campaign.

110
00:07:52,150 --> 00:07:56,380
But instead of smash and
grab, they play a long game.

111
00:07:56,880 --> 00:08:04,230
So from days 1, 2, 3, a small,
seemingly innocent test transactions,

112
00:08:04,740 --> 00:08:09,900
a rule-based system sees nothing
wrong, they start adding new pace,

113
00:08:10,080 --> 00:08:15,030
but cleverly with their names, similar
to existing ones to avoid suspicion.

114
00:08:15,530 --> 00:08:16,875
This is done in days four to five.

115
00:08:17,375 --> 00:08:22,655
On day six, the attack, this is
where our platform's architecture

116
00:08:22,655 --> 00:08:24,125
becomes the hero of the story.

117
00:08:24,625 --> 00:08:29,695
The data ingestion layer didn't just see
the transactions, it saw the context,

118
00:08:29,875 --> 00:08:36,940
it saw the new device fingerprint, the
unusual login location, and the ri.

119
00:08:37,730 --> 00:08:41,670
Mouse moments that were
uncharacteristic of the real customers.

120
00:08:42,170 --> 00:08:45,900
The stream processing engine
analyzed this data in real time

121
00:08:46,260 --> 00:08:48,570
as the new pays were added.

122
00:08:48,960 --> 00:08:53,730
The feature store provided
the crucial history context.

123
00:08:54,390 --> 00:08:58,890
This customer had never added
multiple pays in such a short period.

124
00:08:59,250 --> 00:09:02,460
This was a clear behavioral, an anomaly.

125
00:09:02,960 --> 00:09:05,540
Our end symbol of models served.

126
00:09:05,540 --> 00:09:09,770
The model registry picked upon
this pattern of the behavior.

127
00:09:10,270 --> 00:09:14,710
It wasn't one single event that
was suspicious, but the sequence

128
00:09:14,710 --> 00:09:16,630
of events over the several days.

129
00:09:17,130 --> 00:09:21,900
Finally, the decision engine
orchestrated the response instead

130
00:09:21,900 --> 00:09:25,860
of a simple block, it triggered a
step up authentication challenge.

131
00:09:26,700 --> 00:09:28,650
The fraudster of course, couldn't pass it.

132
00:09:29,145 --> 00:09:32,205
The transfers were blocked
and the account was secured.

133
00:09:33,105 --> 00:09:39,045
The key takeaway here is that no
single rule could have caught this.

134
00:09:39,285 --> 00:09:41,595
The fraud wasn't in one transaction.

135
00:09:42,375 --> 00:09:45,165
It was in the narrative
of the user's behavior.

136
00:09:45,165 --> 00:09:49,600
Over six days, our platform was able
to read that narrative in real time.

137
00:09:50,100 --> 00:09:55,680
Now let's dig a little bit deeper
into the multi-cloud architecture.

138
00:09:56,180 --> 00:10:00,080
A platform this critical cannot
be dependent on a single provider.

139
00:10:00,380 --> 00:10:05,420
We operate in multi-cloud environment,
and this is deliberate strategic

140
00:10:05,420 --> 00:10:07,710
choice for several key reasons.

141
00:10:08,210 --> 00:10:08,560
First.

142
00:10:09,060 --> 00:10:15,300
Avoiding vendor lock-in by building our
core services using portable technologies

143
00:10:15,730 --> 00:10:21,460
containers and Kubernetes, we retain
the flexibility to deploy components

144
00:10:21,460 --> 00:10:23,290
across different cloud providers.

145
00:10:23,790 --> 00:10:27,600
This allows us to choose the best
service for the job without being

146
00:10:27,600 --> 00:10:33,240
tied to a single ecosystem, giving
our organization leverage and ensure

147
00:10:33,240 --> 00:10:37,770
our critical capabilities are not
subject to the fate of a single vendor.

148
00:10:38,270 --> 00:10:41,060
Second, resiliency and redundancy.

149
00:10:41,480 --> 00:10:46,190
An outage in one cloud region
or over an entire provider

150
00:10:46,790 --> 00:10:48,440
won't bring our platform down.

151
00:10:48,940 --> 00:10:53,160
We can route traffic and fail
over services to another cloud,

152
00:10:53,670 --> 00:10:59,065
which is essential for meeting
our 99.99% availability.

153
00:10:59,160 --> 00:11:03,300
Target third, regulatory
and compliance needs.

154
00:11:03,450 --> 00:11:05,820
Different jurisdictions have different.

155
00:11:06,320 --> 00:11:07,850
Data residency requirements.

156
00:11:08,420 --> 00:11:13,550
A multi-cloud architecture allows
us to process and store the data in

157
00:11:13,550 --> 00:11:19,400
specific geographic locations to meet
those complex regulatory demands.

158
00:11:19,900 --> 00:11:21,490
Of course this isn't easy.

159
00:11:22,210 --> 00:11:28,670
It requires sophisticated engineering
for data application and secure the.

160
00:11:29,180 --> 00:11:34,430
Cross cloud networking and unified
monitoring plane to provide a single pane

161
00:11:34,490 --> 00:11:37,820
of glass across all the environments.

162
00:11:38,810 --> 00:11:44,420
The challenges listed here, which
are replication, networking,

163
00:11:45,080 --> 00:11:49,745
monitoring, are exactly why a platform
engineering mindset is so critical.

164
00:11:50,245 --> 00:11:53,725
Now let's take a look at the
data engineering part of it.

165
00:11:54,505 --> 00:12:00,985
At the heart of any great AI system
is a great data engineering For

166
00:12:00,985 --> 00:12:05,395
a financial institution, data is
often scattered across decades of

167
00:12:05,395 --> 00:12:10,390
legacy systems from one core banking
platforms to mobile applications.

168
00:12:10,795 --> 00:12:14,425
The first challenge is
creating a unified data lake.

169
00:12:15,025 --> 00:12:17,545
Data lake is a centralized repository.

170
00:12:17,830 --> 00:12:23,680
That allows us to ingest and store vast
amounts of structured, semi-structured and

171
00:12:23,680 --> 00:12:26,430
unstructured data in its native format.

172
00:12:26,850 --> 00:12:31,530
It becomes the single source of
truth, breaking down data silos, and

173
00:12:31,530 --> 00:12:36,690
enabling the holistic analysis required
for the advanced fraud detection.

174
00:12:37,190 --> 00:12:40,610
This architecture allows
us to embrace the.

175
00:12:41,110 --> 00:12:43,720
Extract, load and transform paradigm.

176
00:12:44,710 --> 00:12:47,725
We ingest the raw data first in its full.

177
00:12:48,225 --> 00:12:53,085
This gives us our data scientists
extra freedom to explore and

178
00:12:53,085 --> 00:12:57,515
engineer new types of features
without being constrained by rigid

179
00:12:58,025 --> 00:13:02,305
predefined schema, which dramatically
accelerates our ability to innovate.

180
00:13:02,805 --> 00:13:08,415
With our data unified, the next step is
to transform it into intelligent signals

181
00:13:08,655 --> 00:13:15,875
or features for our models and to do the
same in real time streaming aggregations.

182
00:13:16,355 --> 00:13:20,225
This is about creating features
that capture behavior over time.

183
00:13:20,855 --> 00:13:24,280
We use our stream processing engine
to compute metrics on the flight.

184
00:13:25,055 --> 00:13:30,335
Like transaction count in the last
five minutes, or average transaction

185
00:13:30,335 --> 00:13:32,375
amount over the last 24 hours.

186
00:13:32,875 --> 00:13:36,655
These time window features
are incredibly powerful for

187
00:13:36,655 --> 00:13:38,695
detecting changes in the behavior.

188
00:13:39,625 --> 00:13:41,935
Then comes the graph based features.

189
00:13:42,385 --> 00:13:44,615
This is where things
get really interesting.

190
00:13:45,245 --> 00:13:48,005
Fraud is rarely a solo activity.

191
00:13:48,425 --> 00:13:50,225
It is a network phenomenon.

192
00:13:50,640 --> 00:13:57,090
By modeling our data as a graph where
customers, accounts and devices are nodes

193
00:13:57,810 --> 00:14:04,410
and transactions are edges, we can compute
features that describes user's position

194
00:14:04,710 --> 00:14:06,395
and relationships within that network.

195
00:14:06,895 --> 00:14:11,425
This allows us to uncover hidden
connections and coordinated activity

196
00:14:12,145 --> 00:14:13,885
that would otherwise be invisible.

197
00:14:14,385 --> 00:14:16,515
And then comes the external enrichment.

198
00:14:17,015 --> 00:14:22,865
We enrich our internal data in real
time with external feeds, pulling in

199
00:14:23,015 --> 00:14:29,940
device reputation scores, IP geolocation
data, and threat intelligence too.

200
00:14:30,440 --> 00:14:33,050
Add even more context
to every transaction.

201
00:14:33,550 --> 00:14:38,860
With graph features, we fundamentally
change the question we are asking.

202
00:14:39,310 --> 00:14:44,410
We move from assessing an individual
in isolation to assessing an individual

203
00:14:44,410 --> 00:14:46,055
in the context of their entire network.

204
00:14:46,555 --> 00:14:51,655
And as we are about to see that change
in perspective makes all the difference.

205
00:14:52,155 --> 00:14:54,855
Now let's get back to our case study.

206
00:14:55,355 --> 00:14:57,275
We blocked the initial.

207
00:14:57,775 --> 00:15:01,315
Fraudulent transfer, but the
investigation was just beginning.

208
00:15:01,815 --> 00:15:03,825
Remember those new pays?

209
00:15:03,885 --> 00:15:07,635
The fraudster added, our
graph algorithms went to work.

210
00:15:07,785 --> 00:15:11,115
They revealed that these
weren't just random accounts.

211
00:15:11,685 --> 00:15:15,955
They were connected to a hidden
network of 47 other accounts across

212
00:15:15,955 --> 00:15:21,025
12 different financial institutions
all created in same two week window.

213
00:15:21,685 --> 00:15:26,605
The graph showed classic signs
of frauding circular money flows

214
00:15:27,135 --> 00:15:31,335
between accounts, shared device
fingerprints, despite different

215
00:15:31,335 --> 00:15:34,655
registered addresses and suspicious.

216
00:15:35,090 --> 00:15:38,160
Temporal correlations and
account creation times.

217
00:15:38,790 --> 00:15:40,740
We weren't fighting a lone wolf.

218
00:15:40,800 --> 00:15:44,400
We are fighting an organized
network simultaneously.

219
00:15:44,700 --> 00:15:49,150
Our real time streaming aggregations
were lighting up like a Christmas tree.

220
00:15:50,080 --> 00:15:53,170
The login velocity from
compromised accounts.

221
00:15:53,260 --> 00:15:58,780
It was up to 400% compared to
customer's six month baseline.

222
00:15:59,410 --> 00:16:03,280
The transaction time shifted from
the customer's typical business

223
00:16:03,280 --> 00:16:09,230
hours to late at night, and our
behavioral biometrics models detected

224
00:16:09,230 --> 00:16:14,990
85% deviation in mouse patterns from
the customer's established profile.

225
00:16:15,560 --> 00:16:19,220
This wasn't just a different
location, it was a different person.

226
00:16:19,720 --> 00:16:21,460
These features computed.

227
00:16:22,330 --> 00:16:29,400
Under 50 milliseconds were the critical
signals that allowed us just not to block

228
00:16:29,400 --> 00:16:35,610
one transfer, but to proactively identify
and dismantle an entire fraud network

229
00:16:36,180 --> 00:16:42,070
preventing an estimated $2.3 million in
losses across the affected institutions.

230
00:16:42,570 --> 00:16:46,775
So this case study demonstrates
a powerful virtuous cycle.

231
00:16:47,275 --> 00:16:50,125
The real time platform stops bleeding.

232
00:16:50,625 --> 00:16:55,935
So building rate models requires
just more than algorithms.

233
00:16:56,415 --> 00:17:00,855
It requires a robust infrastructure
that empowers data scientists

234
00:17:01,305 --> 00:17:06,575
to move from idea to production
With speed and conference, our ML

235
00:17:06,965 --> 00:17:09,275
infrastructure is built on four pillars.

236
00:17:09,275 --> 00:17:13,275
Majorly first sandbox
experimentation platform.

237
00:17:14,090 --> 00:17:19,910
This is where data scientists can safely
explore new data sets, test new feature

238
00:17:19,910 --> 00:17:24,980
ideas, and iterate on models without
impacting production environment.

239
00:17:25,550 --> 00:17:27,970
Second distributed training.

240
00:17:28,510 --> 00:17:33,400
Modern fraud models are massive and
are trained on terabytes of data.

241
00:17:33,400 --> 00:17:36,180
Are distributed training infrastructure.

242
00:17:37,110 --> 00:17:42,810
Allows us to paralyze this process
across clusters of GPUs, reducing

243
00:17:43,110 --> 00:17:45,510
training time from weeks to just ours.

244
00:17:46,320 --> 00:17:53,530
Third automated ML pipelines model
is just not one and done artifact.

245
00:17:53,800 --> 00:17:58,120
It's a living system that needs
to be constantly refreshed.

246
00:17:58,750 --> 00:18:04,750
Our automated ML pipelines handle
the entire life cycle of retraining.

247
00:18:05,250 --> 00:18:10,810
Validation and deployment, and
also ensuring our models never go

248
00:18:10,810 --> 00:18:16,040
stale and are continuously learning
from the latest fraud patterns.

249
00:18:16,540 --> 00:18:21,880
And finally, and most
critically low latency serving.

250
00:18:22,855 --> 00:18:25,885
A prediction that arrives
too late is useless.

251
00:18:26,575 --> 00:18:30,865
Our serving infrastructure is
architected for extreme performance

252
00:18:30,925 --> 00:18:36,355
with model replicas deployed across
multiple availability zones and

253
00:18:36,415 --> 00:18:42,265
automatic failover, all to ensure we
can deliver predictions and well under.

254
00:18:42,490 --> 00:18:45,310
A hundred milliseconds, which is RSLA.

255
00:18:45,810 --> 00:18:51,760
We retreat our ML lifecycle, not
as a research project, but as a

256
00:18:51,760 --> 00:18:53,380
software engineering discipline.

257
00:18:54,160 --> 00:18:57,250
Our infrastructure is designed
to be a model factory.

258
00:18:57,750 --> 00:19:03,010
Enabling us to industrialize with
process of taking promising idea from

259
00:19:03,010 --> 00:19:08,290
a data scientists notebook and turning
it into a hardened production grade

260
00:19:08,290 --> 00:19:11,600
asset that serves millions of customers.

261
00:19:12,320 --> 00:19:17,000
Platform that processes this
much of sensitive financial

262
00:19:17,000 --> 00:19:19,370
data must be a fortress.

263
00:19:19,850 --> 00:19:23,720
A security poster is built
on principle of defense.

264
00:19:23,720 --> 00:19:28,300
In depth, defense in depth is
a strategy that uses multiple

265
00:19:28,630 --> 00:19:30,490
overlapping security measures.

266
00:19:30,990 --> 00:19:35,940
The idea is that if one layer is breached,
another is there to stop the attack.

267
00:19:36,810 --> 00:19:38,790
It is about creating redundancy.

268
00:19:39,675 --> 00:19:44,555
In our defenses and assuming that
no single control is perfect, we

269
00:19:44,555 --> 00:19:46,595
don't add security at the end.

270
00:19:46,865 --> 00:19:50,315
It's embedded in every
architectural decision we make

271
00:19:50,825 --> 00:19:52,625
at the network security layer.

272
00:19:52,685 --> 00:19:54,245
We use a zero trust.

273
00:19:54,295 --> 00:19:59,995
Principles and microsegmentation to
ensure that components can talk to

274
00:19:59,995 --> 00:20:02,635
each other if explicitly authorized.

275
00:20:03,385 --> 00:20:07,735
All communications are encrypted
at the data security layer.

276
00:20:08,545 --> 00:20:13,975
All data is encrypted, both in
transit and addressed with strict

277
00:20:13,975 --> 00:20:19,305
key management protocols that meet
regulatory requirements, access control.

278
00:20:19,720 --> 00:20:24,360
It is being governed by the principle
of least privilege using fine-grained,

279
00:20:24,810 --> 00:20:30,420
role-based access control to ensure
people and services can only access

280
00:20:30,420 --> 00:20:32,400
the data they absolutely need.

281
00:20:32,900 --> 00:20:36,590
And then we maintain the
comprehensive audit logging of every

282
00:20:36,590 --> 00:20:41,210
action taken on the platform for
compliance and forensic analysis.

283
00:20:41,840 --> 00:20:42,830
Let's get into.

284
00:20:43,425 --> 00:20:45,315
The federated learning infrastructure.

285
00:20:46,175 --> 00:20:50,585
So far we have talked about what
we can do with our own data, but

286
00:20:50,585 --> 00:20:54,335
the most sophisticated fraud drinks
don't target one institution.

287
00:20:55,175 --> 00:20:57,905
They attack the entire
financial ecosystem.

288
00:20:58,505 --> 00:21:00,125
What if we couldn't fight back?

289
00:21:01,115 --> 00:21:03,155
This is the promise of federated learning.

290
00:21:03,665 --> 00:21:08,915
It's a machine learning technique
that allows multiple organizations to

291
00:21:08,975 --> 00:21:15,755
collaboratively train a shade model
without ever exposing or exchanging

292
00:21:15,805 --> 00:21:17,895
their raw, sensitive customer data.

293
00:21:18,395 --> 00:21:19,520
The process is iterative.

294
00:21:20,195 --> 00:21:24,935
A central server sends a global model
to each participating institution.

295
00:21:25,685 --> 00:21:30,335
Each institution trains that model
locally on its own private data.

296
00:21:31,205 --> 00:21:35,225
They then send the model
updates, the learned parameters.

297
00:21:36,005 --> 00:21:38,045
Not the data back to the server.

298
00:21:38,545 --> 00:21:43,935
They then send only the model updates,
the learned parameters then the server

299
00:21:43,935 --> 00:21:49,335
aggregates these updates to improve
the global model, which is then sent

300
00:21:49,395 --> 00:21:52,275
back for the next round building.

301
00:21:52,275 --> 00:21:57,165
This is a massive technical
undertaking, but the vision is powerful.

302
00:21:57,665 --> 00:22:02,405
Now let's take a look at the
even driven microservices and

303
00:22:02,435 --> 00:22:04,325
biometric systems integration.

304
00:22:04,825 --> 00:22:08,575
To make all of this work at scale,
we need an architecture that is

305
00:22:08,575 --> 00:22:11,305
flexible, resilient, and scalable.

306
00:22:11,805 --> 00:22:16,455
We have built our platform on an even
driven microservices architecture

307
00:22:16,955 --> 00:22:19,235
in an event driven architecture.

308
00:22:19,550 --> 00:22:24,410
Or EDA services don't make
direct calls to each other.

309
00:22:24,830 --> 00:22:30,410
Instead, they communicate asynchronously
by producing and consuming events.

310
00:22:31,310 --> 00:22:37,580
For example, when a transaction occur,
the ingestion service simply publishes

311
00:22:37,640 --> 00:22:43,330
a transaction, created even downstream
services like our feature engineering

312
00:22:43,360 --> 00:22:45,990
and, model interference services.

313
00:22:46,350 --> 00:22:49,145
Subscribe to that event
and react accordingly.

314
00:22:49,645 --> 00:22:56,395
This decoupling makes the system
incredibly resilient and scalable As

315
00:22:56,395 --> 00:22:59,395
services can fail and scale independently.

316
00:22:59,895 --> 00:23:02,925
We implement this using advanced patterns.

317
00:23:03,495 --> 00:23:11,295
Even sourcing means we store the full
history of all state changes as immutable

318
00:23:11,295 --> 00:23:14,475
sequence of events in an append only log.

319
00:23:15,420 --> 00:23:21,450
This gives us perfect unchangeable
audit trail and allows us to reconstruct

320
00:23:21,450 --> 00:23:27,240
the state of any entity at any
point in time, which is invaluable

321
00:23:27,240 --> 00:23:29,040
for four and six and debugging.

322
00:23:29,850 --> 00:23:35,220
By adopting this, we get a
perfect audit log for free.

323
00:23:35,850 --> 00:23:36,870
For regulators.

324
00:23:37,200 --> 00:23:43,620
This is the gold standard to manage
transactions that span multiple services.

325
00:23:44,120 --> 00:23:45,980
We use the Sega pattern.

326
00:23:46,190 --> 00:23:50,240
A Sega is a sequence
of local transactions.

327
00:23:50,840 --> 00:23:55,610
If any step fails, the Sega
executes compensating transactions

328
00:23:55,610 --> 00:23:57,560
to undo the preceding steps.

329
00:23:58,250 --> 00:24:04,470
This ensures data consistency across
our distributed system without using

330
00:24:04,470 --> 00:24:10,290
slow blocking two face commits, making
our system far more resilient to.

331
00:24:10,680 --> 00:24:15,570
Partial failures that are inevitable
in large scale environment.

332
00:24:16,070 --> 00:24:19,850
And we are exploring blockchain
integration, not for currency,

333
00:24:20,000 --> 00:24:24,490
but it's for original purpose
shared immutable ledger.

334
00:24:25,360 --> 00:24:31,150
This can provide a cryptographically
secure tamper proof audit trail

335
00:24:31,510 --> 00:24:33,190
for high value transactions.

336
00:24:33,460 --> 00:24:39,520
Creating a single source of truth that
is verifiable by multiple parties.

337
00:24:40,020 --> 00:24:42,780
Observability and
performance optimization.

338
00:24:43,280 --> 00:24:45,740
Our strategy is built on three pillars.

339
00:24:46,640 --> 00:24:52,775
Metrics give us the high level
quantitative view, transaction throughput

340
00:24:53,460 --> 00:24:56,460
model accuracy, and CP utilization.

341
00:24:56,960 --> 00:24:58,970
Logging provides us the.

342
00:24:59,345 --> 00:25:04,665
Ground truth, detailed record of what
happened during a specific transaction.

343
00:25:05,165 --> 00:25:08,975
And distributed tracing is the
magic that ties it all together.

344
00:25:09,475 --> 00:25:13,465
It allows us to follow single
request as it jumps across.

345
00:25:13,545 --> 00:25:17,940
A dozen different microservices
letting us pinpoint exactly where

346
00:25:17,940 --> 00:25:22,460
bottlenecks or failures are occurring
and the results speak for themselves.

347
00:25:23,060 --> 00:25:29,030
We achieved median of median or
P 50 latency of 47 milliseconds

348
00:25:30,020 --> 00:25:32,090
even for our 99th percentile.

349
00:25:32,090 --> 00:25:34,175
The slowest 1% of requests.

350
00:25:34,925 --> 00:25:37,175
We are at 89 milliseconds.

351
00:25:37,875 --> 00:25:44,355
Within our a hundred milliseconds SLA, we
focus on both because the P 99 represents

352
00:25:44,355 --> 00:25:47,745
the experience of our un luckiest users.

353
00:25:47,985 --> 00:25:53,325
And, keeping that tail latency
low is critical for consistently

354
00:25:53,325 --> 00:25:54,765
good experience for everyone.

355
00:25:55,515 --> 00:26:01,335
The platform can peak of 45
transactions per second and

356
00:26:01,335 --> 00:26:05,595
maintains 99.99% of availability.

357
00:26:06,095 --> 00:26:08,195
Now at the end of the day.

358
00:26:09,025 --> 00:26:13,945
All this engineering effort is only
valuable if it delivers a real business

359
00:26:13,945 --> 00:26:20,695
impact, and it does for a mid-sized
bank processing, close to 50 billion.

360
00:26:21,115 --> 00:26:22,765
Dollars in transactions.

361
00:26:23,405 --> 00:26:28,745
This platform translates to a
27.2 million in prevented annual

362
00:26:28,745 --> 00:26:32,495
losses by reducing false positives.

363
00:26:32,645 --> 00:26:34,325
We have unblocked 52 plus.

364
00:26:35,060 --> 00:26:40,230
52,000 legitimate transactions
daily improving the customer

365
00:26:40,230 --> 00:26:46,280
experience and saving 4.8 million
dollars in associated service costs.

366
00:26:46,850 --> 00:26:53,390
The ROI is clear, three 40% in the first
year alone, rising to five 80% in the

367
00:26:53,390 --> 00:26:56,000
second year as operational savings.

368
00:26:56,450 --> 00:26:59,190
And of course the customer retention.

369
00:26:59,620 --> 00:27:01,000
Benefits also kick in.

370
00:27:01,840 --> 00:27:05,560
So as you can see, there is
a jump in the second year.

371
00:27:05,830 --> 00:27:09,340
This shows the compounding
value of the platform approach.

372
00:27:09,970 --> 00:27:14,920
The initial return comes from
stopping fraud, but the long-term

373
00:27:14,920 --> 00:27:18,755
sustained value comes from making
the entire business run better.

374
00:27:19,255 --> 00:27:23,905
Reducing the operational friction and
also improving the customer loyalty.

375
00:27:24,405 --> 00:27:27,255
But of course, this arms race never stops.

376
00:27:27,525 --> 00:27:32,685
We are actively exploring the
new next wave of technologies to

377
00:27:32,685 --> 00:27:35,265
stay ahead of these fraudsters.

378
00:27:36,105 --> 00:27:40,620
By using this advanced AI
techniques, generative AI offers

379
00:27:40,620 --> 00:27:42,480
incredible new possibilities.

380
00:27:43,330 --> 00:27:49,360
We can use it to generate highly realistic
synthetic data to train our models on

381
00:27:49,360 --> 00:27:56,005
our rare fraud patterns they have never
seen before, or, even use large language

382
00:27:56,005 --> 00:28:02,325
models to help panelists investigate the
case faster, and also quantum computing

383
00:28:02,415 --> 00:28:04,005
while it's still on the horizon.

384
00:28:04,065 --> 00:28:09,685
Quantum computing holds the potential
to solve optimization and pattern

385
00:28:09,685 --> 00:28:14,280
recognition problems that are in
traceable for classical computers today.

386
00:28:14,780 --> 00:28:18,500
And also we are exploring into
the edge computing and 5G.

387
00:28:19,220 --> 00:28:23,180
So this would allow us to
take the decisions faster.

388
00:28:24,080 --> 00:28:27,320
Building these platforms is
a marathon, not a sprint.

389
00:28:27,820 --> 00:28:33,220
It requires a deep commitment to
engineering excellence, a platform,

390
00:28:33,220 --> 00:28:38,230
first mindset, and a relentless
focus on delivering business value.

391
00:28:38,730 --> 00:28:43,230
The war against fraud is one
we cannot effort to lose.

392
00:28:43,830 --> 00:28:48,120
And with resilient, intelligent
platforms, it's a war we can win.

393
00:28:48,900 --> 00:28:49,320
Thank you.

