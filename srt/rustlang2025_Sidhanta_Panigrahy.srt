1
00:00:00,500 --> 00:00:04,760
Good morning, good evening, good
afternoon, wherever you are.

2
00:00:05,510 --> 00:00:07,850
Thank you for joining the session.

3
00:00:08,350 --> 00:00:10,380
I am goes by Sid.

4
00:00:11,370 --> 00:00:16,860
I'm going to talk about building a high
performance multi-agent AI system in Ross.

5
00:00:17,250 --> 00:00:23,730
How do we use Ross to build a multi-agent
system and how it can achieve 40%

6
00:00:23,730 --> 00:00:27,389
faster enterprise transformation
using its memory safety guarantee?

7
00:00:28,360 --> 00:00:29,980
Let's deep dive into it.

8
00:00:30,480 --> 00:00:30,840
Sure.

9
00:00:31,340 --> 00:00:35,690
The enterprise challenge today,
every digital transformation

10
00:00:36,020 --> 00:00:37,640
passes critical bottleneck.

11
00:00:38,140 --> 00:00:44,560
The 70 per 73% of organization
struggle with the monolithic AI system,

12
00:00:44,560 --> 00:00:46,150
creating a single point of failure.

13
00:00:46,150 --> 00:00:50,350
Everyone they want to build AI
system, AI platform, but they

14
00:00:50,350 --> 00:00:54,490
face a single point of failure
because the design itself is wrong.

15
00:00:55,089 --> 00:00:58,660
The traditional centralized
architecture is definitely a

16
00:00:58,660 --> 00:01:00,040
garbage collected language.

17
00:01:00,040 --> 00:01:02,859
Suffering from an
unpredictable latency spike.

18
00:01:03,790 --> 00:01:08,889
A memory of overhead can deploy
processing up to 300% compared

19
00:01:08,889 --> 00:01:10,780
to RO based distributed approach.

20
00:01:11,280 --> 00:01:16,870
So these are the basic critical bottleneck
people generally doesn't realize.

21
00:01:17,245 --> 00:01:21,415
They're going to face a challenge in
their digital transformation and, and

22
00:01:21,415 --> 00:01:24,175
in enterprise AI challenges together.

23
00:01:24,675 --> 00:01:30,165
But advantage of cost is, for
a multi-agent system is it is

24
00:01:30,225 --> 00:01:31,695
faster in process optimization.

25
00:01:32,685 --> 00:01:35,115
It can reduce your risk.

26
00:01:35,745 --> 00:01:40,485
It has a greater efficiency
and has a zero memory leak.

27
00:01:41,220 --> 00:01:46,160
Compared to traditional language
and framework, Ross is 40% faster

28
00:01:46,760 --> 00:01:51,830
and the lower implementation failure
through compile times safety, 60%.

29
00:01:52,330 --> 00:01:55,150
And it's improve the throughput.

30
00:01:55,210 --> 00:01:59,740
Aging Roth concurrency, which
is like a great efficiency you

31
00:01:59,740 --> 00:02:04,330
get, which is like 80%, 85% more
than the other language we used.

32
00:02:05,110 --> 00:02:07,450
It is always a zero memory leak.

33
00:02:07,870 --> 00:02:14,530
Roth ownership model and zero cost
obstruction enables a back through

34
00:02:14,530 --> 00:02:18,610
multi-agent framework and that deliver
a measurable enterprise advantages.

35
00:02:19,110 --> 00:02:19,980
Let's talk about a little bit into the.

36
00:02:20,480 --> 00:02:21,350
Architecture.

37
00:02:21,790 --> 00:02:28,359
The distributed architecture using
Ross, it has a four different layer.

38
00:02:28,960 --> 00:02:33,119
The first layer is the perception
layer, then cognitive layer,

39
00:02:33,989 --> 00:02:36,269
action layer, coordination layer.

40
00:02:36,769 --> 00:02:40,250
The perception layer is
specialized agent from a data eson.

41
00:02:40,399 --> 00:02:47,089
It is using for filtering, normalization,
using the RO efficient ai preemptives.

42
00:02:48,005 --> 00:02:50,915
The cognitive layer is like
little bit of intelligent

43
00:02:50,915 --> 00:02:53,075
analytical layer, which use lost.

44
00:02:53,575 --> 00:02:57,924
Processing for modern
inference and decision logic.

45
00:02:58,495 --> 00:03:01,304
The external layer is
an education of agent.

46
00:03:01,304 --> 00:03:05,744
It's really what it does and in
implementing your business logic in

47
00:03:05,744 --> 00:03:09,494
the transactional flow and it's get
you the guarantee of the excellence.

48
00:03:10,064 --> 00:03:13,704
The coordination layer is mostly
the orchestration of the managing

49
00:03:13,704 --> 00:03:17,044
different workflow in an across
distributed system and boundary.

50
00:03:17,714 --> 00:03:19,664
The key are.

51
00:03:20,534 --> 00:03:25,154
Using, using ROS are mostly the memory,
safety, concurrency, performance,

52
00:03:25,154 --> 00:03:26,684
reliability, and interoperability.

53
00:03:27,494 --> 00:03:31,664
The memory setti is the
biggest deal using ros.

54
00:03:31,754 --> 00:03:32,894
You like.

55
00:03:33,674 --> 00:03:38,054
There's a zero memory leak across
50 plus million agent interacting

56
00:03:38,054 --> 00:03:44,144
using RO or system concurrency by
using a Tokyo best S Sync on time.

57
00:03:44,594 --> 00:03:49,634
It can handling 250% more concurrent
agent than it's equivalent

58
00:03:50,204 --> 00:03:52,814
Python, or go on the performance.

59
00:03:52,964 --> 00:03:57,194
40% reduction in workflow
education time throughout Ross.

60
00:03:57,224 --> 00:04:00,584
Zero cost abstraction reliability.

61
00:04:00,794 --> 00:04:05,059
It's 60% decrease in system failure
impact, lost compile time error

62
00:04:05,059 --> 00:04:07,249
prevention, interoperability.

63
00:04:08,059 --> 00:04:13,349
P zero three PI oh three and
was binding enables lost.

64
00:04:13,529 --> 00:04:18,719
Its in interoperability with any legacy
system and its ability to do that

65
00:04:18,719 --> 00:04:23,639
is close to 80% successful than any
other language provided in the market.

66
00:04:24,139 --> 00:04:28,519
The memory set in multi-agent system,
which is critical for you to build any

67
00:04:28,519 --> 00:04:30,819
kind of multi-agent distributed system.

68
00:04:31,179 --> 00:04:35,469
The challenge is a complex oxy pattern
of agent of interaction, cascading

69
00:04:35,469 --> 00:04:38,979
failure due to memory leak and garbage
collection, POS disruption, realtime

70
00:04:39,339 --> 00:04:40,629
coordination among the system.

71
00:04:41,349 --> 00:04:42,669
Roster is going to help you on this.

72
00:04:43,149 --> 00:04:44,949
The Ross solution is, it's.

73
00:04:45,654 --> 00:04:51,564
The model and compiled and guarantee
eliminate the entire memory related

74
00:04:51,564 --> 00:04:56,184
bug crucial for your high performance
and real time multi-agent system.

75
00:04:56,724 --> 00:05:00,564
The practical benefit you're going to
get are consistency in performance,

76
00:05:00,564 --> 00:05:02,274
resource efficiency, and reduction.

77
00:05:02,454 --> 00:05:04,854
Bugging our production system.

78
00:05:04,854 --> 00:05:10,044
Demonstrate the zero zero
memory leak across 50 million

79
00:05:10,044 --> 00:05:13,794
plus agent interaction and high
throughput and propag environment.

80
00:05:14,294 --> 00:05:16,514
The concurrency in Tokyo.

81
00:05:16,744 --> 00:05:17,974
West Agent Coordination.

82
00:05:17,974 --> 00:05:21,814
So this is again, one of the
platform Ross provide you to use.

83
00:05:22,144 --> 00:05:23,434
It's an asy on time.

84
00:05:23,494 --> 00:05:26,524
It enables high, concurrent,
and efficient agent coordination

85
00:05:26,524 --> 00:05:28,444
through an async environment.

86
00:05:28,834 --> 00:05:33,304
This approach drastically reduce
your OV rate overhead and boost

87
00:05:33,304 --> 00:05:38,164
responsible multi-agent system,
maximize throughput agent performance.

88
00:05:38,264 --> 00:05:40,604
And then it's help you in my
patient resource utilization.

89
00:05:40,604 --> 00:05:45,014
It's enhance responsiveness
is help you in robustness.

90
00:05:45,554 --> 00:05:51,074
Our system is achieved generally 250%
more concurrent adjunct education than

91
00:05:51,074 --> 00:05:55,064
it's equivalent to Python or go and
any, any other language used for it.

92
00:05:55,574 --> 00:06:03,284
So this is this Tokyo, this, this platform
after us like Tokyo compound its impact

93
00:06:03,284 --> 00:06:07,769
in the real world performance in terms of
a multi, multi-agent distributor system.

94
00:06:08,269 --> 00:06:11,699
Performance is another aspect
of it zero cost obstruction.

95
00:06:12,179 --> 00:06:16,359
If you see the last performance
versus the traditional one, it's, it's

96
00:06:16,869 --> 00:06:19,320
like 40% reduction in workflow time.

97
00:06:19,320 --> 00:06:23,820
Then any other competitor
compiled time optimization, it's

98
00:06:23,849 --> 00:06:25,054
eliminate your on time checks.

99
00:06:25,554 --> 00:06:26,634
No garbage collection.

100
00:06:26,634 --> 00:06:30,304
Pause during critical operation
agent communicate overhead reduced

101
00:06:30,304 --> 00:06:32,524
by 60% because of this architecture.

102
00:06:33,124 --> 00:06:37,144
And this implementation has spread
pretty easy because it's a custom trade.

103
00:06:37,149 --> 00:06:41,389
Zero overhead agent polymorphism
static dispersed, where agents types

104
00:06:41,489 --> 00:06:46,869
are known, efficient serialization for
intelligent communication automatically.

105
00:06:46,869 --> 00:06:48,589
It's built on this architecture by ro.

106
00:06:49,539 --> 00:06:51,939
And then kiros ecosystem and tools.

107
00:06:52,369 --> 00:06:56,129
As I said we used the Tokyo
based, I'm going to talk about

108
00:06:56,189 --> 00:06:57,239
a little bit more on that.

109
00:06:57,239 --> 00:07:00,719
And, but you have other, other different
type of architecture and platform.

110
00:07:00,719 --> 00:07:02,379
You can definitely use it.

111
00:07:02,959 --> 00:07:05,119
We used this Tokyo one, the first one.

112
00:07:05,509 --> 00:07:07,909
It's a, a synchron on time
for an efficient agent,

113
00:07:07,909 --> 00:07:09,079
scheduling and coordination.

114
00:07:09,079 --> 00:07:12,779
It enables non-blocking
your AI across boundaries.

115
00:07:13,289 --> 00:07:15,359
And then it enables
priority based on that.

116
00:07:16,289 --> 00:07:18,659
Support complex workflow
and communication.

117
00:07:18,659 --> 00:07:24,219
So and then similarly you have Actos
and Sled and then Kendall, different

118
00:07:24,219 --> 00:07:28,534
type of interfaces and platform
to think about, system preventing

119
00:07:28,534 --> 00:07:32,804
distributed system bug, like any,
any multi-agent distributor system.

120
00:07:32,804 --> 00:07:35,774
You talk about it, there is a
common enterprise AI failure.

121
00:07:36,304 --> 00:07:39,964
Either it could be a data loss condition,
it could be a parallel state update.

122
00:07:39,964 --> 00:07:43,504
It could be inconsistent error
handling or a protocol violation.

123
00:07:44,194 --> 00:07:48,424
Rust help you to overcome this
because it's a inbuilt compiler

124
00:07:48,424 --> 00:07:50,194
help you to catches these errors.

125
00:07:50,674 --> 00:07:54,394
80% chances, 78 to 87%.

126
00:07:54,454 --> 00:08:00,324
Chances this box will be a catch before
your deployment compared to Python

127
00:08:00,324 --> 00:08:01,884
or go any other languages you use.

128
00:08:01,884 --> 00:08:06,485
So this is one of the greatest
thing you got from rust.

129
00:08:06,985 --> 00:08:08,185
This is another case study.

130
00:08:08,265 --> 00:08:12,295
And in the manufacturing company
we have built the challenge was

131
00:08:12,325 --> 00:08:16,195
it's a global manufacturing company
struggled with an unpredictable

132
00:08:16,195 --> 00:08:18,325
latency in quality control AI system.

133
00:08:18,825 --> 00:08:21,315
Leading to 12% is a production delay.

134
00:08:21,315 --> 00:08:22,484
It is a big deal for them.

135
00:08:23,245 --> 00:08:28,765
When it's a multi billion company with
an MNC you do, this is a big problem.

136
00:08:29,215 --> 00:08:33,414
The result was like 43% reduction
in high quality inspection time

137
00:08:33,414 --> 00:08:34,945
with zero increase in defect.

138
00:08:34,945 --> 00:08:35,305
Right.

139
00:08:35,305 --> 00:08:43,610
And also the latency was less than 50
millisecond with the three X normal load.

140
00:08:44,110 --> 00:08:48,105
And you give three x time of the
actual load still, the LA was.

141
00:08:48,775 --> 00:08:51,685
Less than 50 millisecond, which
is the outcome of this whole

142
00:08:51,685 --> 00:08:53,245
architecture after implementing it.

143
00:08:53,935 --> 00:08:55,315
Soroto multi-agent solution.

144
00:08:55,315 --> 00:08:56,455
It is, it is, it is.

145
00:08:56,455 --> 00:09:00,240
It is like we, we built around
22 specialized agent distributed

146
00:09:00,240 --> 00:09:01,770
across four architecture layer.

147
00:09:01,860 --> 00:09:06,420
The one we we just signed, and the real
time coordination inspections and decision

148
00:09:06,420 --> 00:09:07,970
and routing for different functions.

149
00:09:08,840 --> 00:09:14,050
And the integration among those systems,
and also it bell integrated with the

150
00:09:14,050 --> 00:09:18,045
legacy system of the company using
UI oh three and web centric pages.

151
00:09:19,025 --> 00:09:20,525
Which is a great aspect of rust.

152
00:09:21,215 --> 00:09:25,915
The implementation roadmap generally took
it takes a 20 week, a minimum depending

153
00:09:25,915 --> 00:09:30,675
on what, what you want to do and know
how big or how small it is starting from

154
00:09:30,675 --> 00:09:36,715
your architecture assessment to core
infrastructure to, and is on integration

155
00:09:36,715 --> 00:09:40,015
with existing enterprise system and
production deployment and optimization.

156
00:09:40,515 --> 00:09:44,644
Then the available resources are
like complete rust implementation

157
00:09:45,314 --> 00:09:49,634
performance benchmark and deployment
strategy and integration pattern.

158
00:09:49,694 --> 00:09:55,525
This has to be your main resource to
thought about and, you know go over it.

159
00:09:55,525 --> 00:09:57,625
People, even you think
about implementing it.

160
00:09:58,405 --> 00:10:01,565
Thank you for joining this session.

161
00:10:01,635 --> 00:10:03,525
Hopefully this will help you.

162
00:10:03,645 --> 00:10:04,395
Thank you very much.

