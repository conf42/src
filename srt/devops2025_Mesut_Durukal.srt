1
00:00:00,190 --> 00:00:01,670
Hello, my name is Mesut Erkal.

2
00:00:01,710 --> 00:00:03,550
I'm a software quality assurance engineer.

3
00:00:03,920 --> 00:00:07,670
And as most of my colleagues test
automation is a very important part

4
00:00:07,670 --> 00:00:11,439
of my daily tasks because nowadays
we are not having big releases

5
00:00:11,459 --> 00:00:13,199
or seasonal releases anymore.

6
00:00:13,484 --> 00:00:17,744
But almost every day we are pushing
some new commits and we are implementing

7
00:00:17,744 --> 00:00:21,754
some new features to the working
product in the production environment.

8
00:00:22,025 --> 00:00:26,615
But even if not implementing new features,
sometimes we are changing or updating

9
00:00:26,615 --> 00:00:30,594
the behaviors on the existing features,
which means we are doing the continuous

10
00:00:30,594 --> 00:00:32,944
delivery and continuous integration.

11
00:00:33,380 --> 00:00:36,900
And accordingly, of course, this means
we have to do the continuous testing

12
00:00:36,940 --> 00:00:41,979
as well, because we have to ensure
that these frequent updates or frequent

13
00:00:42,020 --> 00:00:46,970
development activities do not break,
do not break the working functionality.

14
00:00:47,200 --> 00:00:50,289
So we have to do continuously
the testing and verification

15
00:00:50,289 --> 00:00:51,630
and validation activities.

16
00:00:51,960 --> 00:00:55,870
And in this way, we can continuously
ensure the quality and improve the

17
00:00:55,910 --> 00:01:01,280
confidence in our team to deliver
the best product to our customers.

18
00:01:01,740 --> 00:01:03,000
So, in these terms.

19
00:01:03,170 --> 00:01:07,760
Test automation is very important
because if we have only manual testing

20
00:01:07,790 --> 00:01:12,080
activities, of course, with solely
manual testing efforts, it is not

21
00:01:12,110 --> 00:01:15,540
possible to catch up all the verification
activities because there is a huge

22
00:01:15,770 --> 00:01:18,250
and comprehensive verification scope.

23
00:01:18,590 --> 00:01:22,189
So doing this frequently, almost
every day with manual efforts.

24
00:01:23,010 --> 00:01:27,270
It, it will be not possible to catch
up with, to cover all the scope with

25
00:01:27,310 --> 00:01:29,880
limited resources in a limited time.

26
00:01:30,140 --> 00:01:34,890
So if we have already some implemented
test code or the automated test

27
00:01:34,899 --> 00:01:39,760
executions, it will be much more
easy to cover with a, much more fast.

28
00:01:40,035 --> 00:01:43,005
And, reliable, test execution activities.

29
00:01:43,465 --> 00:01:46,775
But in these terms, reliability
and robustness, or even

30
00:01:46,775 --> 00:01:48,305
stability is very important.

31
00:01:48,505 --> 00:01:52,525
So even if we implement test
cases, are we having reliable

32
00:01:52,535 --> 00:01:54,204
results from these test cases?

33
00:01:54,600 --> 00:01:58,860
Or, even if we automate all the
test cases we already designed,

34
00:01:59,220 --> 00:02:03,130
it means, does it mean that we are
already catching all the possible or

35
00:02:03,130 --> 00:02:05,080
potential vulnerabilities or bugs?

36
00:02:05,410 --> 00:02:11,130
So in this session, we will talk about
the potential risks or difficulties or

37
00:02:11,139 --> 00:02:13,309
drawbacks or test automation challenges.

38
00:02:13,569 --> 00:02:17,470
And of course, if we are talking about
challenges or problems, of course,

39
00:02:17,470 --> 00:02:20,760
we will talk about the solutions
and some proposals to cope with

40
00:02:20,810 --> 00:02:22,180
this kind of challenges as well.

41
00:02:22,680 --> 00:02:23,600
So, let's get started.

42
00:02:23,840 --> 00:02:28,950
As we briefly discussed, test automation
has great advantages and benefits.

43
00:02:29,160 --> 00:02:33,110
First of all, it saves time, because
while we are doing the test automation

44
00:02:33,170 --> 00:02:37,520
or executing the test cases manually,
sometimes it may take hours or even days.

45
00:02:37,840 --> 00:02:42,010
But while doing the same thing with an
automated run, we can execute several

46
00:02:42,160 --> 00:02:46,980
scripts to fasten the execution or even we
can create some virtual machines to divide

47
00:02:47,030 --> 00:02:51,519
the whole suite into different subsets and
we can already utilize the parallel runs

48
00:02:51,809 --> 00:02:53,980
to reduce the total execution duration.

49
00:02:54,270 --> 00:02:57,570
And not only the execution duration,
but also we can improve the coverage.

50
00:02:57,760 --> 00:03:00,280
For example, we can perform
the same test scenario.

51
00:03:00,595 --> 00:03:02,825
by providing different data inputs.

52
00:03:03,035 --> 00:03:07,585
So we can perform the data driven
testing to apply not only the positive

53
00:03:07,825 --> 00:03:12,285
scenarios, but also the negative
test cases by providing or inputting

54
00:03:12,285 --> 00:03:17,104
some different negative data values
or with some different data formats.

55
00:03:17,285 --> 00:03:22,024
So all this means we can already eliminate
So, we can reduce the manual effort.

56
00:03:22,364 --> 00:03:26,364
But beyond that, there are some
scenarios in which we cannot

57
00:03:26,414 --> 00:03:28,044
do with only manual testing.

58
00:03:28,064 --> 00:03:32,614
For example, when we try to do
the load testing or performance

59
00:03:32,614 --> 00:03:36,874
testing, we have to send lots of
different concurrent requests.

60
00:03:37,084 --> 00:03:41,424
So we have to create several requests
which will be sent to the servers and

61
00:03:41,464 --> 00:03:45,224
we will be checking the responses or
the responsiveness of the servers.

62
00:03:45,474 --> 00:03:48,364
So for this purpose, of course, we cannot.

63
00:03:48,599 --> 00:03:52,669
Collect a lot of people who will try to
send different requests at the same time.

64
00:03:52,969 --> 00:03:57,709
But instead, we can just create those
requests on our machines and resources.

65
00:03:57,969 --> 00:04:00,929
And then we can do these kind
of load testing activities.

66
00:04:01,179 --> 00:04:05,959
So all these different aspects are great
benefits and advantages, which we can

67
00:04:05,959 --> 00:04:08,289
utilize by performing the test automation.

68
00:04:09,019 --> 00:04:09,499
But.

69
00:04:09,769 --> 00:04:14,469
Of course, there is a bad side
of all these advantages, and of

70
00:04:14,469 --> 00:04:17,249
course there are some difficulties
that we have to cope with.

71
00:04:17,559 --> 00:04:19,709
So, let's start to
discuss them one by one.

72
00:04:20,209 --> 00:04:24,269
The first difficulty that we have to
cope with is the frequent updates or

73
00:04:24,289 --> 00:04:28,244
changes, because Since we are working
in Agile environments, it is very

74
00:04:28,244 --> 00:04:30,594
likely to see some updated behaviors.

75
00:04:30,784 --> 00:04:34,804
Initially, we design our features in a
way, but after going to the customers

76
00:04:34,804 --> 00:04:38,244
or the end users, after getting
some feedback from them, sometimes

77
00:04:38,274 --> 00:04:40,914
we update some, changes or updates.

78
00:04:41,199 --> 00:04:45,919
And we try to improve the usability or the
even the functionality of some features.

79
00:04:46,139 --> 00:04:50,349
So it means that even if we implement the
test scenarios to cover these use cases

80
00:04:50,359 --> 00:04:55,269
once, it doesn't mean that we can execute
them forever without any maintenance.

81
00:04:55,309 --> 00:04:58,469
So sometimes we have to
continuously maintain and pay

82
00:04:58,509 --> 00:05:00,229
attention to these test cases.

83
00:05:00,469 --> 00:05:04,029
Because otherwise, as we can see
in the famous cartoon on this

84
00:05:04,029 --> 00:05:07,589
slide, sometimes the customer
expectation is totally different.

85
00:05:07,914 --> 00:05:12,844
Then what we do or design or provide
to the customers or the end users.

86
00:05:13,034 --> 00:05:17,084
So this is the importance or
the proposal to cope with the

87
00:05:17,084 --> 00:05:18,924
frequent updates or challenges.

88
00:05:19,424 --> 00:05:23,154
In addition to those changes or updates
to the working functionalities or

89
00:05:23,154 --> 00:05:27,294
the features, sometimes even within
the specific feature or use case.

90
00:05:27,624 --> 00:05:29,304
we may have some instabilities.

91
00:05:29,544 --> 00:05:34,054
For example, if we have A B testing
activities, we deploy different instances.

92
00:05:34,274 --> 00:05:36,754
This is why I have a
cute canary in the slide.

93
00:05:37,024 --> 00:05:41,324
So we may have canary deployments,
including different instances,

94
00:05:41,574 --> 00:05:43,244
returning different results.

95
00:05:43,434 --> 00:05:47,864
So sometimes the results coming from
different instances will not match

96
00:05:47,964 --> 00:05:51,964
to our expected conditions because in
these cases we won't be able to know,

97
00:05:52,464 --> 00:05:57,524
Which instance or which version we will
hit during our execution in advance.

98
00:05:58,224 --> 00:06:02,474
And there may be some different
difficulties, namely testability.

99
00:06:02,724 --> 00:06:08,584
Some of the features are not easy to test
because if we are, especially if we are

100
00:06:08,834 --> 00:06:12,964
testing a subsystem in the whole system,
and there are some different interactions

101
00:06:12,964 --> 00:06:17,344
and integrations to the other subsystems,
and sometimes we don't have access to

102
00:06:17,354 --> 00:06:19,494
those other parts of the whole system.

103
00:06:19,764 --> 00:06:21,594
For example, let's assume a feature.

104
00:06:21,969 --> 00:06:27,109
Which is syncing our subsystem which
is under test after a data is created

105
00:06:27,129 --> 00:06:28,519
on the other part of a system.

106
00:06:28,969 --> 00:06:33,349
So when a data or an instance is
created in the other subsystem,

107
00:06:33,709 --> 00:06:38,819
our subsystem which is under test
should sync itself by pulling.

108
00:06:39,204 --> 00:06:41,044
The newly created object.

109
00:06:41,384 --> 00:06:44,914
But in this case, if we don't
have access to create an object

110
00:06:44,914 --> 00:06:48,254
in the other subsystems, then
how can we test this scenario?

111
00:06:48,534 --> 00:06:53,104
So we have to simulate or trigger
this scenario to be able to check

112
00:06:53,364 --> 00:06:57,394
if the communication is done or the
whole interaction is done properly.

113
00:06:57,594 --> 00:06:59,364
First of all, we have to create the data.

114
00:06:59,664 --> 00:07:02,864
But if we don't have access or
right to do that, then we will be

115
00:07:02,874 --> 00:07:04,464
having some testability issues.

116
00:07:04,714 --> 00:07:09,404
We will not be able to trigger this
condition because, we will not be able to

117
00:07:09,404 --> 00:07:11,414
create the relative or relevant condition.

118
00:07:11,799 --> 00:07:13,919
instances on the other subsystems.

119
00:07:14,169 --> 00:07:18,079
So what we can do is, of course, we
can utilize some mocks, or we can

120
00:07:18,089 --> 00:07:24,409
develop some other subsystems, which
is faking as the modules which our

121
00:07:24,889 --> 00:07:27,179
system under test is communicating with.

122
00:07:27,629 --> 00:07:31,289
But what one initiative we can
do in this, in that regard is.

123
00:07:31,524 --> 00:07:34,954
We can communicate to the development
teams and we can try to find

124
00:07:34,964 --> 00:07:36,654
ways to improve the testability.

125
00:07:36,904 --> 00:07:42,224
For example, if we need some public APIs
or other interfaces by which we can create

126
00:07:42,224 --> 00:07:46,214
some instances just for testing purposes,
because we know that they will not be

127
00:07:46,214 --> 00:07:51,734
used in the real production environment,
but just for testing purposes to be able

128
00:07:51,734 --> 00:07:53,614
to trigger the condition that we need.

129
00:07:54,054 --> 00:07:58,264
To perform this scenario, we can
request some additional interfaces from

130
00:07:58,264 --> 00:08:03,004
them, and then after with the help of
development teams, if we have those

131
00:08:03,024 --> 00:08:08,484
interfaces through which we can trigger
our expected conditions, we will be

132
00:08:08,514 --> 00:08:10,694
able to cover these testability issues.

133
00:08:11,194 --> 00:08:15,634
And one more thing which may little
bit make Things difficult for us is

134
00:08:15,634 --> 00:08:21,244
the hardware modules because sometimes
to perform or verify and validate

135
00:08:21,314 --> 00:08:25,264
the interactions, which is done with
the hardware modules, we have to

136
00:08:25,274 --> 00:08:30,654
simulate those kind of messages or
the protocols, which is communicating

137
00:08:30,664 --> 00:08:33,944
the hardware modules with the software
algorithms that we have in our system.

138
00:08:34,534 --> 00:08:38,784
Not only the hardware modules, but
also the AI components is very likely

139
00:08:38,784 --> 00:08:43,334
to be seen in our products nowadays,
because we know that today AI or the

140
00:08:43,334 --> 00:08:46,854
machine learning algorithms is a very
important part of our daily life.

141
00:08:47,074 --> 00:08:51,604
So which means when we are developing
some products or the features or the

142
00:08:51,604 --> 00:08:55,514
functionalities to our customers,
it is very likely to include some

143
00:08:55,544 --> 00:08:59,744
machine learning algorithms to provide
them the best user experiences.

144
00:09:00,044 --> 00:09:02,124
So when we are deploying.

145
00:09:02,309 --> 00:09:07,429
or delivering our products, how can we
ensure the performance of these kind of ML

146
00:09:07,429 --> 00:09:10,409
or AI components involved in our products?

147
00:09:10,579 --> 00:09:13,659
So, of course, there are lots of
different ways to improve the performance

148
00:09:13,659 --> 00:09:15,649
by developing the algorithm itself.

149
00:09:16,039 --> 00:09:20,879
But speaking in terms of the functional
test automation point of view, how

150
00:09:20,879 --> 00:09:24,779
can we ensure the best performance
coming from these AI modules?

151
00:09:24,929 --> 00:09:26,229
So it is a little bit tricky.

152
00:09:26,439 --> 00:09:31,294
And what we can do is maybe we can
perform several experiments and we

153
00:09:31,294 --> 00:09:35,744
can do lots of different benchmark
studies, but just from functional test

154
00:09:35,744 --> 00:09:40,894
automation point of view, it is almost
impossible to perform or ensure the

155
00:09:40,924 --> 00:09:43,904
best performance of this AI components.

156
00:09:44,404 --> 00:09:48,694
And a little bit related to this issue,
there is a non functional aspect of

157
00:09:48,824 --> 00:09:53,074
the quality in our product that we are
delivering or providing to our customers.

158
00:09:53,104 --> 00:09:56,764
It's not on the functionality, but
there are lots of different aspects of

159
00:09:56,804 --> 00:10:01,564
the quality, for example, performance,
how responsive our services are,

160
00:10:02,294 --> 00:10:06,684
even when under load, the how is
the performance of our services.

161
00:10:07,004 --> 00:10:12,284
Or even the usability, how easily
the end users can use our services.

162
00:10:12,614 --> 00:10:16,984
This is just the user experience and
the, usability aspect of quality.

163
00:10:17,284 --> 00:10:21,724
And of course, these, these, all these
aspects and dimensions are very important.

164
00:10:21,964 --> 00:10:25,474
Not only the functionality, but
also all these other aspects of

165
00:10:25,474 --> 00:10:26,824
the quality are very important.

166
00:10:27,034 --> 00:10:29,744
So how can we ensure with
the, test automation?

167
00:10:30,014 --> 00:10:33,589
Of course, it is not, possible
to cover all these aspects, but.

168
00:10:34,274 --> 00:10:38,944
We can support, on top of all our
test automation activities, we

169
00:10:38,944 --> 00:10:42,604
can do several studies, sometimes
manual testing activities, sometimes

170
00:10:42,634 --> 00:10:44,464
exploratory testing activities.

171
00:10:44,964 --> 00:10:49,454
Which means test automation will
never enable us to provide a bug free

172
00:10:49,454 --> 00:10:53,644
software, or even the manual testing
activities will never enable us to

173
00:10:53,644 --> 00:10:56,934
deliver a bug free software, because
bug free software is not possible,

174
00:10:57,214 --> 00:10:59,034
and infinite testing is not possible.

175
00:10:59,264 --> 00:11:02,934
So we will always have some issues
or always have some bugs, but

176
00:11:02,934 --> 00:11:06,904
of course the priority of the
severity of them are very important.

177
00:11:07,114 --> 00:11:12,044
So the important thing is Try to minimize
those kind of issues as much as possible.

178
00:11:12,264 --> 00:11:15,294
Try to reduce the escape
bugs as much as possible.

179
00:11:15,514 --> 00:11:18,674
So, on top of the test
automation activities, the

180
00:11:18,674 --> 00:11:20,664
manual testing is very important.

181
00:11:20,894 --> 00:11:25,934
But, without test automation,
we cannot cover the scope

182
00:11:25,944 --> 00:11:27,574
which is sufficient to deliver.

183
00:11:28,089 --> 00:11:30,009
our products with a certain quality.

184
00:11:30,249 --> 00:11:32,889
So test automation is very
important as the baseline.

185
00:11:33,089 --> 00:11:37,189
But on top of that, we should never
ignore the manual testing activities.

186
00:11:37,429 --> 00:11:42,909
Recently, as an initiative in our team,
we performed a bug bash in which everyone

187
00:11:42,909 --> 00:11:44,559
in the team tried to use the products.

188
00:11:44,729 --> 00:11:47,749
So it was a kind of dog fooding activity.

189
00:11:48,044 --> 00:11:52,394
And we tried to find the issues, all kind
of the functionality and usability issues.

190
00:11:52,624 --> 00:11:54,704
And we found several issues.

191
00:11:54,944 --> 00:11:59,284
So we were questioning in the team,
if so, if this is the case, what are

192
00:11:59,284 --> 00:12:01,524
the automated test case are covering?

193
00:12:01,594 --> 00:12:02,564
What are they finding?

194
00:12:03,024 --> 00:12:05,694
But it doesn't mean that
they don't find any issues.

195
00:12:05,864 --> 00:12:10,424
So we already found several issues
reported by the automated test cases.

196
00:12:10,704 --> 00:12:13,784
But those were the issues
already remaining from the

197
00:12:13,814 --> 00:12:14,664
test automation activities.

198
00:12:14,734 --> 00:12:15,974
They were, they were still.

199
00:12:16,269 --> 00:12:18,959
A lot of issues which can
be fixed or even improved.

200
00:12:19,444 --> 00:12:20,264
in the product.

201
00:12:20,664 --> 00:12:24,544
So both the test automation and
the manual testing activities,

202
00:12:24,854 --> 00:12:26,564
are very important in these terms.

203
00:12:26,804 --> 00:12:30,744
And there will be still a lot
of issues which can be improved.

204
00:12:31,004 --> 00:12:35,984
So what we can do is maybe we can
do some chaos testing activities

205
00:12:36,354 --> 00:12:41,284
to test if something unexpected
happens in some parts of the system.

206
00:12:41,324 --> 00:12:43,484
If some parts are going down.

207
00:12:43,794 --> 00:12:47,734
What will be the other parts or
the other systems will be reacting

208
00:12:47,754 --> 00:12:49,604
to this unexpected situation?

209
00:12:50,254 --> 00:12:54,404
So after these kind of difficulties
stemming from the product or the

210
00:12:54,414 --> 00:12:58,504
way of working off the features or
the functionalities, of course, we

211
00:12:58,504 --> 00:13:02,454
can talk about some difficulties
regarding the implementation itself.

212
00:13:03,414 --> 00:13:06,754
On this slide, I have an example
showing a setup to test the

213
00:13:06,784 --> 00:13:08,974
account or tenant creation feature.

214
00:13:09,334 --> 00:13:12,939
And one requirement of the
feature was After a tenant was

215
00:13:12,939 --> 00:13:17,429
created, The user of this tenant
should be notified by an email.

216
00:13:17,749 --> 00:13:23,039
And the difficulty in this scenario
was, after each time we execute this

217
00:13:23,069 --> 00:13:27,449
test scenario, we should go to the
email account, and we should log in with

218
00:13:27,449 --> 00:13:31,129
the correct credentials, and we should
verify that the email was there with the

219
00:13:31,169 --> 00:13:33,899
relevant subject and the correct context.

220
00:13:34,399 --> 00:13:39,279
Creating unique email IDs after
each run, and managing all the

221
00:13:39,279 --> 00:13:41,349
credentials was super difficult.

222
00:13:41,559 --> 00:13:42,619
So what if we did this?

223
00:13:42,944 --> 00:13:46,474
We set up an email relay, which
was capturing the email to be

224
00:13:46,484 --> 00:13:50,414
sent to an email address, which
is sort of format and forwarding

225
00:13:50,454 --> 00:13:53,444
them to one other email address.

226
00:13:53,584 --> 00:13:58,254
So in this way, whenever an email is
prepared to be sent to an email address,

227
00:13:58,284 --> 00:14:05,094
which is fitting to a certain format, it
was capturing this and forwarding to an

228
00:14:05,094 --> 00:14:08,439
other email address, which managed by us.

229
00:14:08,819 --> 00:14:13,589
But of course, preparing this environment
and utilizing these servers to prepare

230
00:14:13,589 --> 00:14:16,339
the email relay itself was very difficult.

231
00:14:16,579 --> 00:14:21,139
So of course we had to put some effort
and we of course should spend some

232
00:14:21,169 --> 00:14:22,699
time to prepare this environment.

233
00:14:23,149 --> 00:14:26,789
test environment, but not only the
test environment, sometimes the test

234
00:14:26,809 --> 00:14:31,399
code itself is difficult to maintain
or difficult to implement because

235
00:14:31,399 --> 00:14:35,059
we, as we already discussed about
the front end automation, sometimes

236
00:14:35,059 --> 00:14:39,779
the element locators are tricky to
figure out, but even sometimes the

237
00:14:39,799 --> 00:14:45,489
normal algorithms to test the backend
services like sending the responses,

238
00:14:45,499 --> 00:14:48,689
preparing the, correct, format request.

239
00:14:48,974 --> 00:14:50,814
Or even parsing the responses.

240
00:14:51,004 --> 00:14:53,624
Sometimes implementing the
test code is challenging.

241
00:14:53,844 --> 00:14:57,364
So we have to cope with
this kind of difficulties.

242
00:14:57,574 --> 00:15:02,264
And we have to improve the ease of
coding in our test automation framework.

243
00:15:02,554 --> 00:15:07,264
And not only the implementation, but
also the maintenance is very important.

244
00:15:07,494 --> 00:15:10,774
And one aspect of the maintenance
is the execution durations.

245
00:15:11,014 --> 00:15:16,144
So if our test executions are taking
too much time, it means sometimes The

246
00:15:16,144 --> 00:15:20,444
features to be deployed are waiting
for the test results because, as we

247
00:15:20,444 --> 00:15:24,804
discussed in the beginning, normally we
want to integrate our test executions

248
00:15:24,804 --> 00:15:28,984
into our pipelines to ensure that
the frequent updates or changes do

249
00:15:28,984 --> 00:15:31,014
not break the working functionality.

250
00:15:31,344 --> 00:15:36,284
But each time, after each commit,
after each merge request, if we are

251
00:15:36,284 --> 00:15:40,334
running test cases and if they are
waiting, or taking too much time.

252
00:15:40,654 --> 00:15:43,894
Then after some time, the team
members will start to complain.

253
00:15:44,264 --> 00:15:51,344
I'm raising an MRI and I'm waiting for
hours to comment or to march my comments

254
00:15:51,344 --> 00:15:57,279
to my updates and Test cases are really
blocking our development activities.

255
00:15:57,989 --> 00:16:01,859
To avoid these kind of situations,
we can try to reduce the execution

256
00:16:01,899 --> 00:16:03,279
time as much as possible.

257
00:16:03,579 --> 00:16:07,789
As we already discussed previously, we
can, introduce the parallel executions,

258
00:16:08,029 --> 00:16:13,030
but even within the certain test
scenarios, we can, analyze, Which steps

259
00:16:13,240 --> 00:16:17,580
or which operations are taking too
much time and we can try to find out

260
00:16:17,580 --> 00:16:22,250
the root causes and if there are some
dummy ways or there are any other steps,

261
00:16:22,940 --> 00:16:27,710
redundant steps which can be eliminated
to cover the same scope, then we can

262
00:16:27,730 --> 00:16:32,930
already reduce them, eliminate them and
reduce the total execution durations.

263
00:16:33,445 --> 00:16:38,790
And one more aspect which will help
us to improve the maintainability

264
00:16:38,790 --> 00:16:41,130
of test code to implement.

265
00:16:41,390 --> 00:16:47,570
The next test cases in a way faster or
easier way is removing the duplications.

266
00:16:47,830 --> 00:16:52,220
If we already introduced some helper
classes which are providing some methods

267
00:16:52,370 --> 00:16:58,180
duplicated, in lots of different test
scenarios, then whenever we need to

268
00:16:58,180 --> 00:17:03,640
implement, such a scenario, we will be
already having the chance to call these

269
00:17:03,640 --> 00:17:09,160
methods implemented in the, Those helper
classes, and it will already help us to

270
00:17:09,310 --> 00:17:13,430
improve the ease of coding and not only
the ease of coding, but it will help us

271
00:17:13,450 --> 00:17:17,750
to remove the duplication because instead
of having this kind of helper classes in

272
00:17:17,750 --> 00:17:20,040
which the repeated steps are implemented.

273
00:17:20,340 --> 00:17:24,460
If we implement these steps in each
test case separately, then what

274
00:17:24,460 --> 00:17:26,910
will we do when a fix is updated?

275
00:17:27,410 --> 00:17:29,480
We have to update one step.

276
00:17:30,185 --> 00:17:33,785
Repeatedly used in lots of different
test cases or test spec files.

277
00:17:34,075 --> 00:17:37,655
We will go to each spec file
and we will fix this problem.

278
00:17:38,245 --> 00:17:44,135
in each of them separately, but instead,
if we already have the unique point

279
00:17:44,135 --> 00:17:49,655
of source, then we will be, having the
chance to apply our fix to a single point.

280
00:17:50,105 --> 00:17:53,625
Another important aspect of the
maintenance stage of the software

281
00:17:53,625 --> 00:17:56,125
testing lifecycle is managing the bugs.

282
00:17:56,405 --> 00:18:00,005
So of course, when we are doing the
test automation or the automated test

283
00:18:00,005 --> 00:18:02,945
executions, some test tests may fail.

284
00:18:03,245 --> 00:18:05,105
And we have to understand the root causes.

285
00:18:05,115 --> 00:18:08,825
Sometimes they may be false alarms,
but sometimes they may be the real

286
00:18:08,905 --> 00:18:10,865
bugs stemming from the product.

287
00:18:11,255 --> 00:18:15,145
So we should find the root cause
and we have to report our bugs.

288
00:18:15,375 --> 00:18:19,275
But of course, in these cases, the
evidence collection is very important

289
00:18:19,305 --> 00:18:24,145
because we have to provide as much as
possible information to our reports.

290
00:18:24,765 --> 00:18:30,095
So let's a little bit wrap up what we
have discussed in terms of the test

291
00:18:30,125 --> 00:18:32,915
automation challenges and the proposals.

292
00:18:33,110 --> 00:18:35,040
to cope with this kind of challenges.

293
00:18:35,200 --> 00:18:39,890
So we discussed first of all, we have
to cope with this frequent updates

294
00:18:39,890 --> 00:18:43,960
because once the tests are implemented,
it doesn't mean that we can execute

295
00:18:43,960 --> 00:18:48,800
them forever without paying them
paying attention to them anymore.

296
00:18:49,050 --> 00:18:55,930
So what we should do is to cope with the
agile limited time and limited resources.

297
00:18:56,295 --> 00:19:01,445
To have the minimum viable product
in a very limited time, we have to

298
00:19:01,595 --> 00:19:03,545
encourage the early QA involvement.

299
00:19:04,150 --> 00:19:09,370
And to cope with frequent updates, to
be able to cover the correct scope, we

300
00:19:09,370 --> 00:19:14,020
have to continuously maintain our test
cases and do the continuous maintenance.

301
00:19:14,280 --> 00:19:17,760
The next thing was the instabilities,
sometimes stemming from A B

302
00:19:17,760 --> 00:19:21,240
testing activities or sometimes
stemming from some scripts or the

303
00:19:21,240 --> 00:19:23,520
nature of working in our product.

304
00:19:23,810 --> 00:19:28,140
So we have to improve the test
robustness in lots of different ways.

305
00:19:28,355 --> 00:19:34,455
We have to improve to be ready for
a different actual results and to

306
00:19:34,455 --> 00:19:36,695
be able to cover them properly.

307
00:19:37,195 --> 00:19:40,465
And the next thing was
different testability issues.

308
00:19:40,625 --> 00:19:43,625
What we can do is we can collaborate
with the development teams.

309
00:19:43,800 --> 00:19:47,580
And we can try to find different
ways to improve the testability.

310
00:19:47,830 --> 00:19:52,860
And we may have hardware dependencies, or
similarly we may have some AI components

311
00:19:52,890 --> 00:19:54,340
in the products that we are developing.

312
00:19:54,580 --> 00:19:57,880
So what we can do is we can prepare
several simulation environments.

313
00:19:58,130 --> 00:20:01,190
And it's not only the test
automation, but also we can do

314
00:20:01,220 --> 00:20:02,700
the manual testing activities.

315
00:20:03,000 --> 00:20:07,490
Maybe some experiments or exploratory
testing activities to understand.

316
00:20:07,900 --> 00:20:14,010
They are performing with a good
performance and of course, functionality

317
00:20:14,010 --> 00:20:18,900
is not the only aspect of the quality
that we are trying to ensure, but also

318
00:20:18,900 --> 00:20:24,550
the usability, performance, responsiveness
and maintainability, recoverability,

319
00:20:24,810 --> 00:20:27,840
all this kind of non functional
aspects are also very important.

320
00:20:28,150 --> 00:20:31,250
So we can do a lot of different
non functional tests as well.

321
00:20:31,490 --> 00:20:34,660
Especially chaos testing
will help us to ensure.

322
00:20:35,220 --> 00:20:40,540
The responsiveness of the product,
even in the worst cases, when some

323
00:20:40,560 --> 00:20:42,310
parts of the product are down.

324
00:20:42,810 --> 00:20:45,490
And one more aspect or the
difficulty we have to cope with

325
00:20:45,490 --> 00:20:47,640
was the implementation itself.

326
00:20:47,640 --> 00:20:52,270
Sometimes we have to set up some test
harness or test environment and sometimes

327
00:20:52,300 --> 00:20:54,710
the implementation itself can be tricky.

328
00:20:55,040 --> 00:20:59,910
And, in addition to implementation,
the maintenance, the reproduction

329
00:20:59,910 --> 00:21:04,725
of the bugs or the test execution
durations are all related difficulties

330
00:21:04,745 --> 00:21:06,925
or the challenges that we can improve.

331
00:21:07,155 --> 00:21:11,305
So what we can do is we can try
to reduce duplication, eliminate

332
00:21:11,365 --> 00:21:15,955
the duplication, and we can
improve or encourage reusability

333
00:21:15,995 --> 00:21:17,715
in our test automation frameworks.

334
00:21:18,025 --> 00:21:20,575
So we can categorize these
kinds of difficulties.

335
00:21:21,035 --> 00:21:25,395
first of all, The frequent updates,
and the instabilities are the

336
00:21:25,605 --> 00:21:30,465
reasons stemming from the nature of
the product or our implementation

337
00:21:30,465 --> 00:21:35,545
methods like, agile methodologies
or, other, working principles.

338
00:21:35,865 --> 00:21:38,515
And the second category
can be, considered as.

339
00:21:38,650 --> 00:21:41,590
The testability or the
components of the product.

340
00:21:42,000 --> 00:21:45,450
And thirdly, we can talk about
the non-functional aspects

341
00:21:45,720 --> 00:21:49,530
and then we can talk about the
implementation, maintenance, or

342
00:21:49,530 --> 00:21:51,510
execution related difficulties.

343
00:21:52,190 --> 00:21:56,560
So, we talked about lots of different
difficulties, but of course when there

344
00:21:56,560 --> 00:22:00,070
is a difficulty or there is a problem,
of course it means there should be

345
00:22:00,070 --> 00:22:06,220
some solutions which will help us to
ease or, solve these kind of problems.

346
00:22:06,570 --> 00:22:07,180
So, the.

347
00:22:07,755 --> 00:22:13,015
A call for action should be you should
list your problems or the difficulties

348
00:22:13,015 --> 00:22:17,005
in the test automation framework because
there is always something to improve.

349
00:22:17,005 --> 00:22:22,165
There should be always some improvement
rooms and please try to fix them

350
00:22:22,545 --> 00:22:27,435
or try a lot of things to improve
them and solve them as much as

351
00:22:27,435 --> 00:22:31,415
possible and adapt your solutions
in the test automation frameworks.

352
00:22:31,715 --> 00:22:34,905
Thanks for listening and enjoy
the rest of the conference.

