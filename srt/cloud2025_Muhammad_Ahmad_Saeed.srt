1
00:00:00,070 --> 00:00:00,780
Hi everyone.

2
00:00:01,230 --> 00:00:05,319
My name is Mohammad Ahmad Saeed
and today I'm going to talk

3
00:00:05,330 --> 00:00:09,319
about building observability
into cloud native applications.

4
00:00:09,819 --> 00:00:12,109
Let's first look at what is observability.

5
00:00:12,749 --> 00:00:17,079
So observability is the ability to
understand the internal state of a

6
00:00:17,079 --> 00:00:20,069
system based on its external outputs.

7
00:00:21,044 --> 00:00:26,804
In simpler terms, observability is about
answering the question, what's happening

8
00:00:26,814 --> 00:00:30,484
inside my application or system and why?

9
00:00:30,984 --> 00:00:36,134
Observability is often confused with
monitoring, but they are different.

10
00:00:36,634 --> 00:00:42,674
Observability, it goes beyond traditional
monitoring and monitoring simply

11
00:00:42,674 --> 00:00:44,974
tells us if something is wrong or not.

12
00:00:45,214 --> 00:00:49,614
For instance, monitoring will
tell us if my CPU is high or not.

13
00:00:49,904 --> 00:00:55,614
If my response time is slow or
not, but observability helps

14
00:00:55,614 --> 00:00:58,174
us understand why it's wrong.

15
00:00:58,804 --> 00:01:04,324
it empowers us to arbitrary questions
about our systems and get answers

16
00:01:04,364 --> 00:01:09,274
without needing to predict every
possible failure scenario beforehand.

17
00:01:09,774 --> 00:01:14,714
Let's look at what is the pillar of,
what are the pillar of observability.

18
00:01:15,424 --> 00:01:17,674
So observability has three pillars.

19
00:01:18,024 --> 00:01:19,644
The first is the logs.

20
00:01:19,994 --> 00:01:25,304
So logs are the timestamp records of
events that occurred in the system.

21
00:01:25,834 --> 00:01:29,684
For instance, the logs, whenever
there is a booking made, there

22
00:01:29,684 --> 00:01:31,154
is a, the login happened.

23
00:01:31,284 --> 00:01:32,254
the payment is made.

24
00:01:32,564 --> 00:01:37,704
So they are the structured unstructured,
records of events that happened in the

25
00:01:37,704 --> 00:01:42,944
system and they provide us the details,
context, the detail context about like

26
00:01:42,944 --> 00:01:49,434
specific operations and they can be
extremely valuable for debuggings, for

27
00:01:49,474 --> 00:01:53,885
instance, like If there is any exception
happened or if there is some failure

28
00:01:53,895 --> 00:01:59,225
happened then the log will tell me the
exact message of like why that happened

29
00:01:59,305 --> 00:02:01,435
and what exactly was the problem.

30
00:02:01,935 --> 00:02:04,355
The next pillar is the matrix.

31
00:02:04,845 --> 00:02:09,685
matrix It's metrics are the quantitative
data about system performance.

32
00:02:09,735 --> 00:02:15,615
for instance, the CPU usage, the
request latency, the memory usage,

33
00:02:15,665 --> 00:02:20,475
the error rates, the throughputs,
there can be a lot of metrics, but.

34
00:02:20,775 --> 00:02:23,935
yeah, it's more about the
quantitative data rather than

35
00:02:23,935 --> 00:02:26,055
the data about individual events.

36
00:02:26,945 --> 00:02:32,085
And traces are, the end to end, tracking
of the requests as they propagate

37
00:02:32,225 --> 00:02:33,815
through the distributed system.

38
00:02:34,335 --> 00:02:39,905
So these traces help pinpoint performance
bottleneck and understand dependencies.

39
00:02:39,905 --> 00:02:46,665
So using traces, we can Exactly
identify how our request went from

40
00:02:46,875 --> 00:02:49,125
one service into the other service.

41
00:02:49,155 --> 00:02:52,785
And then, yeah, we can track
all the routes that it took,

42
00:02:52,885 --> 00:02:54,685
for that's for a given request.

43
00:02:55,185 --> 00:03:00,655
Now, let's see why is observability
crucial for cloud native.

44
00:03:01,385 --> 00:03:06,505
So cloud native applications
are inherently complex, they are

45
00:03:06,545 --> 00:03:10,915
distributed like microservices, they
have a lot of microservices and those

46
00:03:10,915 --> 00:03:15,765
microservices communicate over network,
which actually introduce latency

47
00:03:15,825 --> 00:03:20,635
and then there are a lot of failure
points because of, of using network.

48
00:03:20,950 --> 00:03:21,940
for communication.

49
00:03:22,440 --> 00:03:24,200
The next is the dynamic.

50
00:03:24,510 --> 00:03:30,120
So all the containers and orchestration
platforms like Kubernetes, they constantly

51
00:03:30,130 --> 00:03:32,280
spin up and tear down resources.

52
00:03:32,290 --> 00:03:37,140
Like for instance, they can, whenever
the demand for the demand grows, they can

53
00:03:37,140 --> 00:03:41,435
create new database, but also when the
demand lowers, they can they can kill that

54
00:03:41,735 --> 00:03:44,025
the specific instances that were created.

55
00:03:44,285 --> 00:03:48,015
So it, it is creating the
resources all the time.

56
00:03:48,015 --> 00:03:50,885
So it is creating and destroying
resources all the time.

57
00:03:51,175 --> 00:03:52,385
And then ephemeral.

58
00:03:52,675 --> 00:03:55,125
So instances are like short lived.

59
00:03:55,155 --> 00:03:59,815
They, and because of that, it is really
hard to actually track what happened.

60
00:03:59,835 --> 00:04:05,275
Because by the time when we start
investigating something, the maybe,

61
00:04:05,365 --> 00:04:09,525
The instance or the platform is
not there without observability.

62
00:04:09,945 --> 00:04:13,985
We are basically, essentially
like we are flying blind.

63
00:04:14,125 --> 00:04:19,715
So when something goes wrong, we need to
quickly identify the root cause, whether

64
00:04:19,715 --> 00:04:24,995
it's like a misconfigured service, a
network bottleneck or a cascading failure.

65
00:04:25,495 --> 00:04:30,030
Let's look at What lack of
observability can do with us?

66
00:04:30,030 --> 00:04:32,590
what are the consequences of
the lack of observability?

67
00:04:32,610 --> 00:04:36,960
The very first is the increased
mean time to resolution.

68
00:04:37,250 --> 00:04:42,880
So if we don't have a proper observability
setup, diagnostic, diagnosing and,

69
00:04:42,900 --> 00:04:44,720
diagnosing and resolving issues.

70
00:04:44,870 --> 00:04:49,690
It takes significantly longer,
which can impact the user experience

71
00:04:49,720 --> 00:04:51,460
and operational efficiency.

72
00:04:51,760 --> 00:04:57,460
for instance, if it takes like few hours
to recover from a failure, then it can

73
00:04:57,460 --> 00:05:00,200
have severe consequences on the business.

74
00:05:00,530 --> 00:05:04,275
in ideal situation, if we
have Observability is set up.

75
00:05:04,835 --> 00:05:10,235
We should be able to quickly identify the
root cause and which will help reduce the,

76
00:05:10,745 --> 00:05:12,865
the, reduce the mean time to resolution.

77
00:05:13,835 --> 00:05:17,155
The next is the limited,
performance optimization.

78
00:05:17,695 --> 00:05:23,255
So if the, if we don't have a proper
observability setup, then performance

79
00:05:23,275 --> 00:05:29,465
bottlenecks in one microservice can
cascade affecting the overall application

80
00:05:29,525 --> 00:05:35,255
and we won't be able to pinpoint
exactly what is causing the problem.

81
00:05:36,065 --> 00:05:39,925
So without matrix and traces,
optimizing performance then

82
00:05:39,925 --> 00:05:41,865
becomes just a guessing game.

83
00:05:42,015 --> 00:05:45,215
Like we can try to like
optimize something, but we don't

84
00:05:45,215 --> 00:05:47,055
know exactly the root cause.

85
00:05:47,075 --> 00:05:50,915
So for instance, if we see that
there is an increased response time

86
00:05:51,305 --> 00:05:55,395
for a given endpoint, then if we
don't have an observability setup,

87
00:05:55,405 --> 00:05:59,565
then we might believe that this
endpoint is slow, it has like slow.

88
00:06:00,035 --> 00:06:03,365
like a slower implementation or it
needs some kind of optimization.

89
00:06:03,655 --> 00:06:09,015
But in reality, there is a possibility
that at that specific time, maybe that

90
00:06:09,025 --> 00:06:11,465
the response time from database increased.

91
00:06:11,555 --> 00:06:14,995
But because we didn't have
observability set up, so we believe

92
00:06:15,025 --> 00:06:17,895
that our endpoint is, it's slower.

93
00:06:17,895 --> 00:06:22,215
And we cannot identify that database
was the actual root cause in that.

94
00:06:22,355 --> 00:06:27,905
And the next is like the
difficulty in ensuring reliability.

95
00:06:27,905 --> 00:06:32,615
So yeah, before, like if there is
any, like if there are any gaps in the

96
00:06:32,615 --> 00:06:38,000
observability, then we cannot ensure
proper reliability because, the number

97
00:06:38,000 --> 00:06:42,210
of microservices grows, ensuring the
reliability of the entire systems.

98
00:06:42,240 --> 00:06:46,930
It becomes challenging without a
holistic view of the system's health.

99
00:06:47,430 --> 00:06:50,755
Let's look at the steps for
implementing observability into

100
00:06:50,755 --> 00:06:52,890
the cloud native application.

101
00:06:52,900 --> 00:06:55,980
So on a high level, there are five steps.

102
00:06:56,230 --> 00:06:58,775
The first is the instrumentation.

103
00:06:59,035 --> 00:07:02,445
Instrumentation is basically
the foundation of observability.

104
00:07:03,025 --> 00:07:08,505
And here we need to instrument our code
to collect metrics, logs, and traces.

105
00:07:08,925 --> 00:07:12,615
We can use libraries and frameworks
that are designed for our

106
00:07:12,625 --> 00:07:14,515
chosen language and frameworks.

107
00:07:15,015 --> 00:07:19,045
The next is the centralized
collection and storage.

108
00:07:19,565 --> 00:07:23,730
So Collecting data from all
the services and then storing

109
00:07:23,730 --> 00:07:25,420
it in a centralized location.

110
00:07:25,640 --> 00:07:30,750
We can use tools like Prometheus for
metrics, Elasticsearch or Loki for logs,

111
00:07:30,750 --> 00:07:33,420
and Jaeger or Zapkin for traces here.

112
00:07:34,040 --> 00:07:38,600
so once we have the data instrumentation
set up and then once we have the

113
00:07:38,600 --> 00:07:41,170
data centralized in, in one place.

114
00:07:41,660 --> 00:07:44,280
The next part is the
visualization and analysis.

115
00:07:44,310 --> 00:07:50,310
So here we can use, dashboards and
visualization tools like Grafana to

116
00:07:50,360 --> 00:07:52,630
explore the data and gain insights.

117
00:07:53,240 --> 00:07:56,910
We can also set up the alerts
to be notified when there is any

118
00:07:56,910 --> 00:07:58,510
critical issue in the system.

119
00:07:59,010 --> 00:08:00,260
So once we have the.

120
00:08:00,655 --> 00:08:05,555
With visualization analysis done, we
can move towards contextualization.

121
00:08:05,645 --> 00:08:13,135
So here we can connect our metrics,
logs, and traces together to provide

122
00:08:13,165 --> 00:08:15,065
a holistic view of the system.

123
00:08:15,255 --> 00:08:20,065
This allows us to correlate events and
understand the relationships between

124
00:08:20,405 --> 00:08:22,195
different parts of the application.

125
00:08:22,695 --> 00:08:24,875
The final step is
basically the automation.

126
00:08:25,760 --> 00:08:31,180
we can, we can automate the whole
process of collecting, analyzing and

127
00:08:31,190 --> 00:08:33,200
visualizing the observability data.

128
00:08:33,750 --> 00:08:37,100
So this allows us to focus
on understanding the system

129
00:08:37,310 --> 00:08:39,120
rather than managing tools.

130
00:08:39,720 --> 00:08:45,630
So using all of these, five steps, we
can, implement observability, properly

131
00:08:45,640 --> 00:08:47,460
into the cloud native applications.

132
00:08:47,960 --> 00:08:48,810
Let's look at the.

133
00:08:49,445 --> 00:08:53,455
Famous tools and technologies
that are available in the market.

134
00:08:53,555 --> 00:08:56,725
the very first is the, for
metrics, we have, we can use

135
00:08:56,865 --> 00:08:59,065
Prometheus, Telegraph or StatsD.

136
00:08:59,845 --> 00:09:05,495
For logs, it's mostly Elasticsearch,
Locky, Filebit and Fluentd.

137
00:09:05,995 --> 00:09:09,885
For traces, it is, like the
most famous is OpenTelemetry.

138
00:09:10,665 --> 00:09:12,505
there is also Zipkin and Jagger.

139
00:09:13,095 --> 00:09:15,775
For visualization, yeah, the most famous.

140
00:09:16,445 --> 00:09:19,065
Are, Kibana and Grafana.

141
00:09:19,835 --> 00:09:22,525
yeah, some of these tools are open source.

142
00:09:22,525 --> 00:09:24,085
Some of those might not be.

143
00:09:24,245 --> 00:09:26,225
let's look at the platforms.

144
00:09:26,725 --> 00:09:29,355
So why we need those platforms.

145
00:09:29,355 --> 00:09:31,245
because we need those platforms because.

146
00:09:31,805 --> 00:09:35,125
They provide us like all
the features in one place.

147
00:09:35,125 --> 00:09:37,355
We don't have to set up individual steps.

148
00:09:37,355 --> 00:09:40,155
We don't have to set up individual
tools and technologies and

149
00:09:40,155 --> 00:09:41,305
try to connect everything.

150
00:09:41,755 --> 00:09:46,935
So using a platform can help get, speed
up the integration of the observability

151
00:09:46,945 --> 00:09:47,885
into our cloud native applications.

152
00:09:47,885 --> 00:09:52,375
The first is the Datadog.

153
00:09:53,010 --> 00:09:56,030
So Datadog is a market leader.

154
00:09:56,060 --> 00:10:01,290
It offers comprehensive monitoring
and analytics across cloud native

155
00:10:01,360 --> 00:10:06,260
environments, including logs,
metrics, traces and events.

156
00:10:07,230 --> 00:10:09,460
The next is the New Relic.

157
00:10:09,750 --> 00:10:14,990
So New Relic is a, it's a comprehensive
observability platform with strong

158
00:10:15,100 --> 00:10:17,410
application performance capabilities.

159
00:10:18,100 --> 00:10:23,480
it is also a very famous platform used by
like millions of users across the world.

160
00:10:24,280 --> 00:10:27,550
The third in this list is the Honeycomb.

161
00:10:27,930 --> 00:10:33,790
So Honeycomb, it stands out because it
is focusing on high cardinality data.

162
00:10:34,180 --> 00:10:37,680
So which means high cardinality
data means the data with

163
00:10:37,740 --> 00:10:39,770
have like many unique values.

164
00:10:40,270 --> 00:10:45,110
And honeycombs excel at event
driven instrumentation So instead

165
00:10:45,110 --> 00:10:50,530
of just monitoring a matrix like cp
usage or request count honeycomb.

166
00:10:50,540 --> 00:10:54,180
Let's let us Analyze individual events.

167
00:10:54,190 --> 00:10:59,743
For example a user logged in an api call
or a database query so we can this is

168
00:10:59,743 --> 00:11:04,316
how you can analyze individual events
using Honeycomb and if we just look at

169
00:11:04,316 --> 00:11:09,693
all the, like the, the key features which
are available in all of this, platform,

170
00:11:09,693 --> 00:11:13,323
there are more platforms other than this,
but these are the top three in my list.

171
00:11:13,823 --> 00:11:16,693
The key features are always
like the real time insights.

172
00:11:16,733 --> 00:11:22,343
So we are collecting and analyzing
metrics, log, traces, and events

173
00:11:22,353 --> 00:11:27,053
from various sources to provide real
time visibility into application

174
00:11:27,053 --> 00:11:28,933
performance and infrastructure health.

175
00:11:29,433 --> 00:11:32,783
All of these platforms,
they support microservices.

176
00:11:32,863 --> 00:11:38,833
So money microservices have a really
complex distributed, architecture.

177
00:11:39,023 --> 00:11:44,483
but yeah, or using these platforms,
we can easily monitor all of those

178
00:11:44,523 --> 00:11:46,653
microservices in just one place.

179
00:11:47,653 --> 00:11:51,898
And They all of them allow us to
create customizable dashboards.

180
00:11:51,908 --> 00:11:57,598
So for instance, if I want to see some
trend over time, what is the P50, P90

181
00:11:57,608 --> 00:12:03,488
for my data, for the events, for, for any
kind of metrics, we can easily set up the

182
00:12:04,298 --> 00:12:09,198
customizable, we can set up the customized
dashboards, using any of these platforms.

183
00:12:09,698 --> 00:12:12,748
Here, let's look at the best practices.

184
00:12:13,288 --> 00:12:19,988
So The very first thing is we have to
instrument early and often, we shouldn't

185
00:12:20,088 --> 00:12:22,918
just leave it till the last moment.

186
00:12:23,358 --> 00:12:27,018
the earlier we start implementing
observability into the cloud

187
00:12:27,018 --> 00:12:31,328
native, the less painful it will
be when the things start scaling.

188
00:12:32,218 --> 00:12:37,298
and then for metrics, we have
to use the meaningful metrics.

189
00:12:37,298 --> 00:12:40,788
So we can focus on the metrics
that are relevant to the business.

190
00:12:40,843 --> 00:12:46,943
And we have to filter
out signal from noise.

191
00:12:46,983 --> 00:12:52,143
There can be a lot of metrics, but we
have to filter a list of metrics that

192
00:12:52,163 --> 00:12:54,323
are most relevant for the business.

193
00:12:54,823 --> 00:12:59,908
And then for logs, The best practice
is to actually structure the logs.

194
00:12:59,938 --> 00:13:03,418
We have to use a consistent
format and make it easier to

195
00:13:03,418 --> 00:13:05,278
search and analyze the logs.

196
00:13:05,338 --> 00:13:10,748
So by, like for instance, we have to,
make sure that, like when we are logging,

197
00:13:10,968 --> 00:13:15,558
something, logging events, so the, for
example, there can be standard fields,

198
00:13:15,558 --> 00:13:16,848
like the pattern can be standard.

199
00:13:16,848 --> 00:13:21,633
For example, there's a timestamp, there is
a system name, there is an application id.

200
00:13:21,633 --> 00:13:22,983
There can be a lot of stuff, but yeah.

201
00:13:23,473 --> 00:13:29,783
Whatever it is, it has to be a consistent
format and then, it's better to if we

202
00:13:29,813 --> 00:13:35,393
are using the same logging format across
all the services because all of these

203
00:13:35,393 --> 00:13:39,793
logs might end up being in the same place
and then it will be easy to analyze.

204
00:13:39,858 --> 00:13:42,008
if the format is the same.

205
00:13:42,508 --> 00:13:44,028
correlation, data correlation.

206
00:13:44,338 --> 00:13:49,858
So here we are connecting metrics,
logs, and traces together to provide

207
00:13:49,938 --> 00:13:52,198
a holistic view of the system.

208
00:13:52,888 --> 00:13:56,298
and then we have to automate
the observability pipeline.

209
00:13:56,598 --> 00:14:01,458
So So all the process of collecting,
analyzing, and visualizing the

210
00:14:01,458 --> 00:14:03,358
data, it has to be automated.

211
00:14:03,438 --> 00:14:08,558
there, there shouldn't be any manual
intervention required whenever we want to,

212
00:14:08,648 --> 00:14:11,068
whenever we want to visualize something.

213
00:14:11,118 --> 00:14:14,748
So I just need to open the
dashboard, open a platform.

214
00:14:14,768 --> 00:14:15,078
Yeah.

215
00:14:15,118 --> 00:14:16,278
The data should be already there.

216
00:14:16,308 --> 00:14:19,048
Everything should be, set
up, in an automated way.

217
00:14:19,548 --> 00:14:22,008
The final thing is the cost management.

218
00:14:22,048 --> 00:14:26,428
So observability can be
expensive, especially at scale.

219
00:14:26,858 --> 00:14:32,608
If we are logging, like billions of event,
millions of event, per day, per hour.

220
00:14:32,918 --> 00:14:37,158
So we have to be careful about,
like the cost that are associated.

221
00:14:37,458 --> 00:14:40,198
with the storage, with the
processing, and all that.

222
00:14:40,588 --> 00:14:45,378
So, to reduce the cost, to reduce the
data that we are collecting, we can set

223
00:14:45,378 --> 00:14:50,808
up some data retention policies and use
like tiered solutions to manage costs.

224
00:14:51,308 --> 00:14:52,698
Let's look at a case study.

225
00:14:53,078 --> 00:14:57,798
assume that there is a cloud native,
e commerce experience, there's a

226
00:14:57,798 --> 00:15:02,178
cloud native application which is
experiencing periodic slowdowns.

227
00:15:02,678 --> 00:15:09,513
So We can use the three pillars of
observability to actually pinpoint

228
00:15:09,543 --> 00:15:11,113
what is the root cause of this.

229
00:15:11,153 --> 00:15:13,503
So the very first is the logs.

230
00:15:13,543 --> 00:15:17,433
So logs will tell us if there
is an increase in the error

231
00:15:17,433 --> 00:15:19,383
rates in a microservice.

232
00:15:19,883 --> 00:15:24,903
Metrics will tell us if there is
a high CPU utilization on a node.

233
00:15:25,778 --> 00:15:32,348
The traces will pinpoint a slow, a slow
database query affecting response times.

234
00:15:32,538 --> 00:15:37,228
using logs, metrics, and traces, we
have identified that, yeah, the problem

235
00:15:37,298 --> 00:15:39,528
goes back to a slow database query.

236
00:15:40,528 --> 00:15:42,938
For resolution, It's straightforward.

237
00:15:43,248 --> 00:15:45,228
We can optimize the query.

238
00:15:45,608 --> 00:15:51,698
We can auto, auto scale the service and,
yeah, then it will reduce the latency.

239
00:15:51,788 --> 00:15:56,578
So we can use these three pillars
of observability to find out

240
00:15:56,598 --> 00:16:00,648
what is the root cause of the
periodic slowdowns in a system.

241
00:16:01,148 --> 00:16:01,668
thank you.

242
00:16:01,738 --> 00:16:05,678
I hope this talk was
useful and, thank you.

