1
00:00:00,300 --> 00:00:05,220
Greetings to 100 present here today
in today's software landscape.

2
00:00:05,580 --> 00:00:10,590
We are in the era of microservice
architecture, where distributed

3
00:00:10,590 --> 00:00:15,630
systems plays a crucial role in
handling both synchronous and a

4
00:00:15,630 --> 00:00:18,120
synchronous messages and responses.

5
00:00:18,960 --> 00:00:23,070
In synchronous system, we can
immediately notify user of

6
00:00:23,070 --> 00:00:25,080
success or failure in real time.

7
00:00:25,580 --> 00:00:27,950
However, what about the
asynchronous system?

8
00:00:28,189 --> 00:00:29,840
Let me illustrate with an example.

9
00:00:30,169 --> 00:00:36,170
Imagine I have exposed a web service that
uses a messaging queue to report events.

10
00:00:36,470 --> 00:00:40,940
When a user reports an event
using my web service, the system

11
00:00:41,150 --> 00:00:44,269
acknowledge the request by
placing the message in the queue.

12
00:00:44,644 --> 00:00:49,894
As a result, the user sees a
success response assuming that event

13
00:00:49,925 --> 00:00:51,875
has been successfully reported.

14
00:00:52,475 --> 00:00:57,364
The problem arises when the messaging
system goes down and fails to process

15
00:00:57,364 --> 00:01:02,614
the event even though the user was told
that event was successfully received.

16
00:01:03,050 --> 00:01:08,510
This situation happens because of the
asynchronous design where the response

17
00:01:08,570 --> 00:01:14,760
is sent to the user without guaranteeing
that the event has been fully processed.

18
00:01:15,300 --> 00:01:20,370
So in today's presentation, I'm going
to discuss about zero data loss at

19
00:01:20,370 --> 00:01:22,560
scale building resilient, asynchronous.

20
00:01:23,060 --> 00:01:27,770
For modern distributed architectures,
battle tested strategies for

21
00:01:28,310 --> 00:01:34,070
SRE and architects to implement
resilient messaging that maintains

22
00:01:34,070 --> 00:01:36,500
data integrity during failures.

23
00:01:37,340 --> 00:01:39,920
By the way, I am Kupa Amarna.

24
00:01:39,980 --> 00:01:44,540
I work as a software engineer
serving multiple clients across the

25
00:01:44,540 --> 00:01:50,210
United States with specialization
in various domains such as tax,

26
00:01:50,210 --> 00:01:51,500
health insurance, and payroll.

27
00:01:52,040 --> 00:01:53,930
Now let me step into my presentation.

28
00:01:54,430 --> 00:01:56,765
The current distributed system challenges.

29
00:01:57,335 --> 00:01:58,804
Common problem me.

30
00:01:59,055 --> 00:02:04,095
Message tracking blind spots refers
to where tracking or monitoring the

31
00:02:04,095 --> 00:02:09,405
flow of messages become difficult,
incomplete, or even impossible.

32
00:02:09,795 --> 00:02:13,705
The next one is the
inadequate recovery mechanism.

33
00:02:14,335 --> 00:02:17,755
It refers to the lack of
effective strategies or processes.

34
00:02:18,370 --> 00:02:22,690
To store a system to a functional
state after a failure occurs

35
00:02:23,110 --> 00:02:25,660
inconsistent state across nodes.

36
00:02:25,900 --> 00:02:31,360
It refers to a situation in distributed
system where different nodes that

37
00:02:31,360 --> 00:02:35,950
are supposed to hold the same
or synchronized data end up with

38
00:02:36,010 --> 00:02:38,260
conflicting or divergent states.

39
00:02:38,920 --> 00:02:42,760
These are very common problems
and the distributed systems.

40
00:02:43,120 --> 00:02:45,130
Now, how this challenge impact sre.

41
00:02:46,090 --> 00:02:51,310
Unpredictable recovery time referred
to the varying or inconsistent amount

42
00:02:51,310 --> 00:02:56,890
of time it take for a system to
recover from a failure or a disruption.

43
00:02:57,280 --> 00:03:02,350
Data integrity issues refers to a
problem where the accuracy, consistency,

44
00:03:02,350 --> 00:03:04,570
and reliability of data or compromise.

45
00:03:05,069 --> 00:03:08,939
In distributor system, asynchronous
architectures and large scale

46
00:03:08,939 --> 00:03:13,979
applications, data integrity is
crucial to ensure that the data remains

47
00:03:14,039 --> 00:03:18,479
accurate, complete and consistent
across all system and services.

48
00:03:18,959 --> 00:03:24,299
Data integrity issues can lead to
inconsistent corruption or loss

49
00:03:24,299 --> 00:03:28,769
of data, resulting in operational
disruption and trust issues for

50
00:03:28,769 --> 00:03:31,109
both users and system administrator.

51
00:03:31,619 --> 00:03:36,599
Complex post failure reconciliation
refers to the challenges and

52
00:03:36,599 --> 00:03:41,849
processes involved in restoring
data integrity and consistency in

53
00:03:41,849 --> 00:03:44,639
a system after ref failure occurs.

54
00:03:45,029 --> 00:03:48,479
Now let's see how to prevent
data loss by message.

55
00:03:48,479 --> 00:03:49,049
Replication.

56
00:03:49,049 --> 00:03:53,909
Architecture first is to distribute
the messages, replicating the

57
00:03:53,909 --> 00:03:55,949
message across multiple nodes.

58
00:03:56,624 --> 00:04:01,724
Then verify them, get confirm,
receive acknowledgement from all

59
00:04:01,724 --> 00:04:03,584
destinations where it transfer.

60
00:04:04,004 --> 00:04:09,254
Next is the synchronize the messages
maintain consistency between replicas.

61
00:04:09,704 --> 00:04:14,295
And final step is protect, ensure
durability during failures.

62
00:04:14,954 --> 00:04:18,135
So here are some advanced
recovery techniques.

63
00:04:18,505 --> 00:04:24,670
Snapshot based recovery, restore system
from consistent point in time Backups.

64
00:04:25,405 --> 00:04:30,235
Enabling rapid recovery without
complex message reconstruction.

65
00:04:30,485 --> 00:04:32,135
Replay based recovery.

66
00:04:32,735 --> 00:04:38,715
So systematically reconstruct systems
state by replaying in transaction

67
00:04:38,715 --> 00:04:42,705
logs, ensuring no messages are
lost during the recovery phase.

68
00:04:43,185 --> 00:04:46,185
And the next one is the
peer assisted recovery.

69
00:04:46,784 --> 00:04:51,534
River leverage healthy notes in the
network to collaboratively rebuild

70
00:04:51,624 --> 00:04:55,974
failed peers, distributing recovery,
workload, and minimizing downtime.

71
00:04:56,474 --> 00:05:00,634
So the, this slide is on distributed
acknowledgement protocol design.

72
00:05:01,099 --> 00:05:03,529
Here are the steps
involved in this design.

73
00:05:03,589 --> 00:05:07,819
First, send the messages this
past message to all the notes that

74
00:05:07,819 --> 00:05:09,199
are involved in the transmission.

75
00:05:09,559 --> 00:05:11,479
The next step is to acknowledge them.

76
00:05:11,779 --> 00:05:15,529
Each note that involved in the
transmission process should need to

77
00:05:15,529 --> 00:05:17,029
provide the confirmation receipt.

78
00:05:17,149 --> 00:05:18,649
That is, they have to acknowledge it.

79
00:05:19,174 --> 00:05:21,514
The next step is to persist the data.

80
00:05:21,764 --> 00:05:25,994
We have to store the data for
a durable period on multiple

81
00:05:25,994 --> 00:05:28,244
nodes to prevent the data loss.

82
00:05:28,394 --> 00:05:30,494
And next is the confirmation verify.

83
00:05:30,494 --> 00:05:33,044
That is verify the complete
distribution is done.

84
00:05:33,544 --> 00:05:38,974
Some of the industry implementations
examples in the financial services

85
00:05:39,194 --> 00:05:43,304
mission critical payment processing
system with guaranteed transaction

86
00:05:43,304 --> 00:05:49,214
integrity across distributed banking
networks in the healthcare real time

87
00:05:49,214 --> 00:05:54,194
patients records synchronization,
ensuring critical media data consistency

88
00:05:54,464 --> 00:05:56,594
across multiple treatment facilities.

89
00:05:56,969 --> 00:06:01,319
E-commerce, fall tolerance, order
management systems, maintaining

90
00:06:01,319 --> 00:06:06,009
seamless customer experience during
high traffic events and flash sales.

91
00:06:06,509 --> 00:06:11,609
Now let us see how to ensure a smooth,
predictable communication and distributed

92
00:06:11,609 --> 00:06:17,279
system by standardizing the message
format, the standardizing message format

93
00:06:17,309 --> 00:06:21,419
referred to the practice of using a
predefined and consistent structure

94
00:06:21,659 --> 00:06:26,279
for the message exchange between
components in a system, especially in

95
00:06:26,279 --> 00:06:28,559
distributed or microservice architecture.

96
00:06:29,279 --> 00:06:33,539
Some of the commonly used
standardized message formats or

97
00:06:33,539 --> 00:06:37,589
JS xml, CCSV, via ml, et cetera.

98
00:06:37,859 --> 00:06:39,929
Why do we need the
standardized messaging format?

99
00:06:40,604 --> 00:06:45,554
For these three reasons, interoperability
system communicates seamlessly

100
00:06:45,704 --> 00:06:50,684
transformation, simplified data
mapping, and validation is very easy.

101
00:06:50,744 --> 00:06:52,874
Automated schema enforcement.

102
00:06:53,534 --> 00:06:56,174
The next one is about the
performance optimization.

103
00:06:56,654 --> 00:07:01,394
It refer to the process of improving
the efficiency, speed, and scalability

104
00:07:01,394 --> 00:07:03,464
of a system or application.

105
00:07:03,864 --> 00:07:07,014
Various ways to optimize the performance.

106
00:07:07,404 --> 00:07:11,804
So the performance optimization
through eventual consistency.

107
00:07:12,554 --> 00:07:17,234
It is an approach to consistency
that allows for the temporary

108
00:07:17,234 --> 00:07:21,224
inconsistency of a data across
different part of the system.

109
00:07:21,559 --> 00:07:26,719
With a guarantee that eventually
all nodes or replica will converge

110
00:07:26,719 --> 00:07:28,369
to the same consistent state.

111
00:07:28,639 --> 00:07:32,869
Some of the benefits are higher
throughput, reduced synchronization

112
00:07:33,019 --> 00:07:36,019
overhead, stale data risk mitigation.

113
00:07:36,979 --> 00:07:39,049
Next one is the strategic caching.

114
00:07:39,349 --> 00:07:44,449
It refers to the deliberate and efficient
use of caching mechanism to improve the

115
00:07:44,449 --> 00:07:49,009
performance and scalability of systems,
especially in distributed environments.

116
00:07:49,349 --> 00:07:53,729
Caching is the process of storing
copies of frequently accessed data

117
00:07:53,789 --> 00:07:59,369
in faster, more readable, available
storage location to reduce the time it

118
00:07:59,369 --> 00:08:03,779
takes to fe the data and dis decrease
the load on the backend systems.

119
00:08:04,224 --> 00:08:06,234
Such as database or ap.

120
00:08:06,594 --> 00:08:10,434
And here are the, some of the benefits
of using the strategic caching.

121
00:08:10,804 --> 00:08:16,204
It lowers the average response time,
reduced backend load, and intelligent

122
00:08:16,204 --> 00:08:18,584
invalidation partisan strategies.

123
00:08:19,164 --> 00:08:24,324
This strategies are crucial in distributor
system and large scale applications

124
00:08:24,354 --> 00:08:29,034
where data need to be distributed
across multiple servers or database.

125
00:08:29,784 --> 00:08:33,174
To ensure scalability,
performance, and high availability.

126
00:08:33,654 --> 00:08:39,864
Partitioning allows large data sets
to be divided into smaller, manageable

127
00:08:39,924 --> 00:08:44,514
pieces that can be distributed across
multiple nodes, enabling parallel

128
00:08:44,514 --> 00:08:46,794
processing and efficient data retrieval.

129
00:08:47,514 --> 00:08:51,234
There are some of the benefits
of using the partisan strategies.

130
00:08:51,574 --> 00:08:56,944
It balance the workload, distribution,
isolate, failure domains, and

131
00:08:56,944 --> 00:08:58,324
the horizontal scalability.

132
00:08:58,824 --> 00:09:03,144
And next, this slide is on the graphical
representation of a performance

133
00:09:03,144 --> 00:09:05,994
versus consistency trade off here.

134
00:09:06,084 --> 00:09:10,314
X axis refers to consistency and
way axis refers to performance.

135
00:09:10,644 --> 00:09:13,254
The dark yellow line refers to latency.

136
00:09:13,524 --> 00:09:16,764
It means that time taken
by the message to travel.

137
00:09:17,619 --> 00:09:22,119
From sender to the receiver and the
light yellow line refers to throughput.

138
00:09:22,369 --> 00:09:25,279
Throughput is the successful
message transmission between

139
00:09:25,279 --> 00:09:26,539
the center and receiver.

140
00:09:26,569 --> 00:09:30,259
So the first one is the strong
consistency, guarantees that the

141
00:09:30,259 --> 00:09:35,209
system always return the most up
to date version of data, no matter

142
00:09:35,269 --> 00:09:40,869
which replica notice access is a
model used in distributed system to.

143
00:09:41,369 --> 00:09:44,609
To provide a balance between
consistency and availability.

144
00:09:44,849 --> 00:09:49,529
And it is about how to manage how many
replicas must participate in a read or a

145
00:09:49,529 --> 00:09:51,719
write operation to consider it successful.

146
00:09:52,219 --> 00:09:53,239
Read your writes.

147
00:09:53,489 --> 00:09:58,619
That consistency is also called a strong
consistency for the writing users.

148
00:09:59,159 --> 00:10:02,459
The users cease their
own rights immediately.

149
00:10:02,579 --> 00:10:05,129
And the last one is the
eventual consistency.

150
00:10:05,444 --> 00:10:07,364
Here the, it's a weak consistency.

151
00:10:07,454 --> 00:10:11,984
Data may be inconsistent temporarily,
but will eventually converse.

152
00:10:12,554 --> 00:10:16,454
Here in the graphical notation,
you can see that as al latency

153
00:10:16,454 --> 00:10:18,524
decreases, the throughput increases.

154
00:10:19,024 --> 00:10:22,109
Below are the steps for the
case study implementation.

155
00:10:22,919 --> 00:10:26,699
The fastest step involved in the case
study should be the problem assessment

156
00:10:27,419 --> 00:10:30,219
data lost during the regional outage.

157
00:10:30,550 --> 00:10:34,899
Next is the architecture
redesign, so multiple regions

158
00:10:35,109 --> 00:10:37,060
replications with the quo rights.

159
00:10:37,300 --> 00:10:43,209
And the third step is monitoring, enhance
enhancement, end to end message tracking.

160
00:10:43,394 --> 00:10:47,380
And the fourth step is the result
where we achieve the data loss.

161
00:10:47,880 --> 00:10:49,950
Some are the key takeaways.

162
00:10:50,325 --> 00:10:52,355
You to cons to take into consideration.

163
00:10:52,385 --> 00:10:55,855
The first one is the safety
First, prioritize data

164
00:10:55,855 --> 00:10:58,225
integrity over raw performance.

165
00:10:58,555 --> 00:11:02,215
The next one is the balance
requirement, match consistency

166
00:11:02,405 --> 00:11:03,755
level two business needs.

167
00:11:03,965 --> 00:11:06,605
The third one is the
implement incrementally.

168
00:11:06,695 --> 00:11:08,745
Start with critical data path.

169
00:11:08,925 --> 00:11:11,040
And the final one is
to measure everything.

170
00:11:11,340 --> 00:11:13,040
Deploy comprehensive monitoring.

171
00:11:13,290 --> 00:11:13,830
Thank you.

172
00:11:13,830 --> 00:11:17,820
Hope you all have enjoyed my
presentation and definitely would

173
00:11:17,820 --> 00:11:21,180
have gained insight into designing
a resilient asynchronous messaging.

