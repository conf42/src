1
00:00:00,500 --> 00:00:05,830
Hi everyone, my name is, so this session
of Con 42 Cy Engineering event of 2025

2
00:00:06,070 --> 00:00:10,930
will focus on contextual understanding
and ation with high dimension using

3
00:00:11,710 --> 00:00:13,270
generative artificial intelligence.

4
00:00:13,670 --> 00:00:16,050
The session, focus on
the solution approach.

5
00:00:16,050 --> 00:00:20,940
So that enhances contextual understanding
and ation by first encoding the user

6
00:00:20,940 --> 00:00:23,070
inputs into the high dimensional embeds.

7
00:00:23,070 --> 00:00:26,900
And these embeddings are then used
for the efficient sematic search

8
00:00:26,900 --> 00:00:31,370
and of the relevant context, which
is inter integrated into prompt.

9
00:00:31,370 --> 00:00:35,220
So for the chat completion model
that combines the powerful sematic

10
00:00:35,340 --> 00:00:39,450
similarity capabilities with advanced
language integration, enabling accurate

11
00:00:39,450 --> 00:00:41,430
and context of our interactions.

12
00:00:41,930 --> 00:00:45,350
So with so much of information,
data, abundance documents, review

13
00:00:45,350 --> 00:00:47,240
and analysis is a difficult task.

14
00:00:47,960 --> 00:00:51,780
The challenge is with huge volume and
unstructured data's tough to extract

15
00:00:51,810 --> 00:00:57,000
meaningful information from the data
and respond in a very personalized

16
00:00:57,000 --> 00:00:59,640
and domain or contextual manner.

17
00:01:00,015 --> 00:01:03,995
So business and product outcomes will be
impacted to not able to derive insights

18
00:01:03,995 --> 00:01:08,065
on those specific domain or context
due to huge amount of data growth.

19
00:01:08,565 --> 00:01:12,615
So there is no solution for domain
specific knowledge for ai applications.

20
00:01:12,615 --> 00:01:15,545
There is no efficient solution
for context Adaptability.

21
00:01:16,360 --> 00:01:20,410
So sentiment analysis model or natural
language processing or other models.

22
00:01:20,410 --> 00:01:24,580
So have a lesser accuracy
on the context analysis.

23
00:01:25,080 --> 00:01:27,025
This is all the solution architecture.

24
00:01:27,125 --> 00:01:30,850
So the approach allows to do
provide domain information

25
00:01:30,950 --> 00:01:32,350
available with the uploaded.

26
00:01:32,850 --> 00:01:35,450
In the chat model what we develop.

27
00:01:35,780 --> 00:01:40,540
So the uploaded document will be converted
to text and text embedding is done a

28
00:01:40,540 --> 00:01:43,750
vector opting through text embedding
model, or stored in the vector dp.

29
00:01:44,440 --> 00:01:48,390
For any new prompt or query ask, it would
do a similarity search from the list of

30
00:01:48,390 --> 00:01:50,745
similar text and as and is filter on the.

31
00:01:51,245 --> 00:01:54,215
Domain based response is return
for the query of the prompts.

32
00:01:54,815 --> 00:01:58,625
And fine tuning helps to produce
the best results by pertaining with

33
00:01:58,625 --> 00:02:03,185
large amounts of information upfront
and domain specific knowledge based

34
00:02:03,185 --> 00:02:04,655
on the document analysis is done.

35
00:02:04,775 --> 00:02:06,365
Analyzing the sentiment domain.

36
00:02:06,675 --> 00:02:10,375
Context and the content of the upload
document, it generates responses

37
00:02:10,375 --> 00:02:14,435
that are not only relevant, but also
empathetic on the circumstances.

38
00:02:14,955 --> 00:02:18,614
Threshold helps to build the accurate
context with the prompt sent.

39
00:02:18,975 --> 00:02:22,334
So with this, we would get the right
context to provide a final response

40
00:02:22,334 --> 00:02:26,475
considering the domain in the text and
the text ratings to capture patterns

41
00:02:26,475 --> 00:02:30,274
and semantics in, data is obtained
by converting the uploaded document

42
00:02:30,545 --> 00:02:33,255
into text using certain passes.

43
00:02:33,255 --> 00:02:37,865
So for our document analysis and
yeah, thereby with this approach, it

44
00:02:37,865 --> 00:02:41,980
allows to provide a domain information
available in the uploaded document.

45
00:02:42,030 --> 00:02:45,125
So this is how the solution we have this.

46
00:02:45,625 --> 00:02:49,225
Web where we can see that can,
there's option to upload the document,

47
00:02:49,225 --> 00:02:54,335
what you wanna derive the knowledge
based on the domain or the context.

48
00:02:54,725 --> 00:02:59,365
So here I've uploaded English or
science textbook and that the uploaded

49
00:02:59,365 --> 00:03:02,105
document content is seen as shown here.

50
00:03:02,795 --> 00:03:08,515
And yeah, like in the chat model, if the
user ask anything related to the domain or

51
00:03:08,515 --> 00:03:11,475
the document we'll get a better accuracy.

52
00:03:11,655 --> 00:03:15,335
The AI assistant would provide
the response to the prompt,

53
00:03:15,335 --> 00:03:21,995
to the query based on the, OR
domain ready inside the, on the.

