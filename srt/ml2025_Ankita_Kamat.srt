1
00:00:01,230 --> 00:00:02,009
Hi everybody.

2
00:00:02,250 --> 00:00:03,270
I'm Anta Kamath.

3
00:00:03,900 --> 00:00:07,680
I'm a senior software engineer at
Microsoft and have spent the last several

4
00:00:07,680 --> 00:00:12,180
years designing and building high scale
distributed systems, especially in

5
00:00:12,180 --> 00:00:14,130
the notification and messaging domain.

6
00:00:14,880 --> 00:00:18,330
I'm thrilled to talk to you today
about combining machine learning

7
00:00:18,600 --> 00:00:22,920
with high performance architecture
to delivers of notifications in real

8
00:00:23,010 --> 00:00:24,930
time efficiently and intelligently.

9
00:00:26,295 --> 00:00:30,435
So let's bring of what is our
notification landscape today, and

10
00:00:30,435 --> 00:00:31,845
let's talk a little bit about it.

11
00:00:33,195 --> 00:00:37,125
It's basically, we are talking about
billions of notifications daily

12
00:00:37,125 --> 00:00:42,135
here, and these are delivered across
apps, browsers, iot, and variables.

13
00:00:42,735 --> 00:00:46,575
Users expect something like a one
millisecond response latency, even

14
00:00:46,575 --> 00:00:51,865
during peak load think Black Friday,
or a large scale breaking news era.

15
00:00:52,555 --> 00:00:57,205
Systems must operate with fine lines
of availability across regions.

16
00:00:57,865 --> 00:01:02,815
To support this, we must decouple
services, ensure low latency paths

17
00:01:02,875 --> 00:01:07,735
using memory-based message buses, and
handle failovers without state loss.

18
00:01:08,455 --> 00:01:13,770
Let's put our problem landscape to be like
speed, scale, and precision at this point.

19
00:01:16,270 --> 00:01:19,900
Briefly touching up on what are the
m service architecture benefits here?

20
00:01:20,570 --> 00:01:24,620
We build notification systems as
a polyguard Microsoft AR m service

21
00:01:24,620 --> 00:01:30,290
architecture broken into components like
event receiver, for example, a Kafka

22
00:01:30,290 --> 00:01:36,740
consumer or HTTP trigger message router
and forter channel adapters, which could

23
00:01:36,740 --> 00:01:39,860
be a push notification email or SMS.

24
00:01:40,550 --> 00:01:45,500
Think of it as triggers or adapters
and analytics and feedback pipelines.

25
00:01:46,280 --> 00:01:51,470
Key architectural choices have known to
be using Kubernetes for orchestration

26
00:01:51,470 --> 00:01:55,789
with horizontal port autoscaling
based on message queue lens at any

27
00:01:55,789 --> 00:01:59,215
point using GRPC or product of APIs.

28
00:01:59,715 --> 00:02:04,865
For service to service communication,
basically primarily due to compact

29
00:02:04,865 --> 00:02:07,384
payloads and cannery rollouts.

30
00:02:07,384 --> 00:02:10,925
Using something like agile
DevOps to ensure zero downtime

31
00:02:10,925 --> 00:02:16,085
deployments, each component scales
independently in this case, and

32
00:02:16,085 --> 00:02:18,395
stateless is the key for all of us.

33
00:02:19,395 --> 00:02:25,375
Our systems are basically fully event
driven and designed around cqrs.

34
00:02:25,494 --> 00:02:30,565
It's primarily known to be command query
response, segregation, and event sourcing.

35
00:02:31,345 --> 00:02:36,535
Enrichment layer adds personalization
by pulling user preferences,

36
00:02:36,565 --> 00:02:41,244
location and history from Redis
backed graph and makes it available.

37
00:02:41,904 --> 00:02:44,994
At runtime or at near runtime scenarios.

38
00:02:45,564 --> 00:02:50,024
Smart delivery involves using ML
models to rank the likelihood of

39
00:02:50,024 --> 00:02:55,124
engagement, for example, at a given
point, what is the user being more

40
00:02:55,124 --> 00:02:59,384
responsible to, whether it's a push
notification or an email or it's visits.

41
00:02:59,384 --> 00:03:04,574
An SMS And our ML models basically
help us rank these in the a certain

42
00:03:04,574 --> 00:03:06,734
order priority based on previous data.

43
00:03:07,444 --> 00:03:09,694
Selecting optimal delivery windows.

44
00:03:10,144 --> 00:03:14,164
We'll talk about the optimal
windows in a bit coming soon in

45
00:03:14,164 --> 00:03:15,394
the late in the presentation.

46
00:03:16,694 --> 00:03:21,194
Feedback loops are being captured
for every event given process.

47
00:03:21,304 --> 00:03:25,654
What is the scale of opens,
clicks, dismissals, uninstall.

48
00:03:26,044 --> 00:03:30,274
We could store all this data that we get
all the plethora of data in something

49
00:03:30,274 --> 00:03:32,524
like Azure Data Explorer, A big query.

50
00:03:32,824 --> 00:03:37,019
And this can be further used to train
reinforcement learning agents and.

51
00:03:37,779 --> 00:03:41,649
It comes back into the system as
feedback loops and can be helped

52
00:03:41,649 --> 00:03:43,304
to train the system holistically.

53
00:03:44,304 --> 00:03:49,984
A brief comparison of different message
brokers, which are being used in the

54
00:03:49,984 --> 00:03:51,904
different notification systems today.

55
00:03:52,334 --> 00:03:54,494
Let's talk about Kafka first.

56
00:03:54,614 --> 00:03:59,174
Primary use cases to ingest high
volume events and it's best for

57
00:03:59,174 --> 00:04:03,174
durability and uses compression
to reduce the throughput costs.

58
00:04:03,174 --> 00:04:05,604
So it's pretty much well known for that.

59
00:04:06,124 --> 00:04:07,144
The second option that we.

60
00:04:07,454 --> 00:04:09,104
Discuss here as RabbitMQ.

61
00:04:09,854 --> 00:04:13,634
It's known for complex routing
and acknowledgement systems,

62
00:04:13,664 --> 00:04:17,714
and it has a strong delivery
guarantees with dead letter queues.

63
00:04:17,714 --> 00:04:24,054
Also ready streams known for ephemeral
messages and low latency and great

64
00:04:24,054 --> 00:04:25,824
for send in for forget pushes.

65
00:04:25,824 --> 00:04:28,494
It's like you don't really
care what the response is.

66
00:04:28,494 --> 00:04:33,114
It's more like it's a fire and forget
scenario, and you just let it go and

67
00:04:33,754 --> 00:04:34,909
let the system takes its own course.

68
00:04:34,909 --> 00:04:39,619
One lesson known one is ser, which
is known primarily as a use case for

69
00:04:39,619 --> 00:04:41,809
geo application and backlog handling.

70
00:04:42,259 --> 00:04:48,209
And it's built in on tiered storage and
partitioning often combined scenarios or

71
00:04:48,209 --> 00:04:53,399
Kafka for ingestion and ready streams for
real time delivery so we can make the best

72
00:04:53,399 --> 00:04:55,749
known use of both of both of the systems.

73
00:04:58,744 --> 00:05:02,434
Next we will touch upon
system resilience strategies.

74
00:05:02,954 --> 00:05:06,764
We use multiple layers of resiliency
in this point, and that's like

75
00:05:06,764 --> 00:05:08,654
primary one is self-healing.

76
00:05:09,144 --> 00:05:14,719
Readiness and liveliness probes are a.
Good for restarting pods alert fatigue

77
00:05:14,719 --> 00:05:20,710
radio use with LY based alerting is like
Grafana or AI model combined can help

78
00:05:20,710 --> 00:05:26,619
us alert and figure out when our system
has cer certain spikes or certain tips

79
00:05:26,619 --> 00:05:32,205
and can basically help without any human
intervention to take quicker action

80
00:05:32,349 --> 00:05:34,510
and self-healing of the entire system.

81
00:05:35,484 --> 00:05:41,044
Circuit breakers implemented via poly
or high stakes like wrappers, defines

82
00:05:41,044 --> 00:05:43,445
timeouts, retries, and fallback handlers.

83
00:05:44,164 --> 00:05:46,984
Another one coming to it as redundancy.

84
00:05:47,135 --> 00:05:50,974
It's basically active deployments
using geo distributed clusters.

85
00:05:51,335 --> 00:05:53,719
We could use something
like Azure or AWS here.

86
00:05:55,385 --> 00:05:56,015
S testing.

87
00:05:56,135 --> 00:06:01,445
We run periodic chaos tests using tools
like Gremlin to simulate broker outages

88
00:06:01,445 --> 00:06:07,055
or CP starvation, and that basically
helps us making our system more resilient.

89
00:06:07,835 --> 00:06:10,925
It's basically, it's
not optional at scale.

90
00:06:10,925 --> 00:06:16,685
Your system has to be reliable and it's
not like an option for us at this point.

91
00:06:16,715 --> 00:06:17,165
You.

92
00:06:17,960 --> 00:06:18,170
It.

93
00:06:18,650 --> 00:06:22,910
Each of these strategies could be
used individually or in combination

94
00:06:22,910 --> 00:06:26,865
of each other to help make the
system more reliable as a whole,

95
00:06:27,865 --> 00:06:32,115
coming to one of the primary
topics of this, of this talk.

96
00:06:32,115 --> 00:06:34,815
And that's what, like how is
machine learning integration?

97
00:06:35,175 --> 00:06:39,945
It's makes it more intelligent
and advanced in terms of delivery,

98
00:06:39,945 --> 00:06:43,155
and that goes beyond the basic
delivery of notifications.

99
00:06:43,635 --> 00:06:46,665
So let's focus on the part where
the system shifts from being

100
00:06:46,665 --> 00:06:50,910
just an infrastructure layer to
becoming a truly intelligent layer.

101
00:06:51,410 --> 00:06:54,825
And this is where machine learning
inter integration transforms the game.

102
00:06:55,840 --> 00:07:00,010
Most traditional systems are
rule-based targeting, send message

103
00:07:00,040 --> 00:07:02,950
X to Y users after Z Minutes, right?

104
00:07:02,950 --> 00:07:04,420
It works until it doesn't.

105
00:07:05,350 --> 00:07:07,120
Rules break at scale.

106
00:07:07,180 --> 00:07:11,980
And this accounts for user
behavior, preference and context.

107
00:07:12,850 --> 00:07:18,570
So this is where ML steps in and
learning from past behaviors, predicting

108
00:07:18,570 --> 00:07:22,475
future preferences, and delivering
real time personalized engagement.

109
00:07:23,525 --> 00:07:27,575
So let's start by talking about
smart filtering and which is more

110
00:07:27,575 --> 00:07:29,375
like classifying a value, right?

111
00:07:29,765 --> 00:07:31,594
What's our primary problem here?

112
00:07:31,594 --> 00:07:33,994
And that's not every
message is meaningful.

113
00:07:34,474 --> 00:07:36,604
Users are constantly bombarded.

114
00:07:37,024 --> 00:07:39,034
How do we filter what to send?

115
00:07:40,070 --> 00:07:41,150
What is our solution?

116
00:07:41,690 --> 00:07:44,090
Use binary classification models.

117
00:07:44,390 --> 00:07:50,659
For example, XG Boost or light,
G-P-M-G-B-M trained on engagement levels.

118
00:07:50,960 --> 00:07:53,960
Open, clicked, dismissed, or ignored.

119
00:07:54,900 --> 00:07:57,725
Input features could include
something like message type.

120
00:07:57,900 --> 00:07:58,830
Is it a promo?

121
00:07:58,830 --> 00:07:59,610
Is it an alert?

122
00:07:59,610 --> 00:08:01,440
Is it a transactional message?

123
00:08:01,900 --> 00:08:04,060
What's the context of the user?

124
00:08:04,060 --> 00:08:05,230
Is it a device os.

125
00:08:05,984 --> 00:08:10,905
Region, historical responsiveness
and time of day and channel.

126
00:08:11,709 --> 00:08:16,209
Basically, does the user historically
respond on the phone during

127
00:08:16,270 --> 00:08:21,129
evenings and more on the say
your system or a desktop during?

128
00:08:21,129 --> 00:08:25,299
That's a channel which allows for the
delivery of the notification during

129
00:08:25,299 --> 00:08:28,959
daytime, and all this is captured
in data and are very important input

130
00:08:28,959 --> 00:08:31,164
features to your machine learning models.

131
00:08:32,069 --> 00:08:32,940
What's your output?

132
00:08:33,329 --> 00:08:35,399
A relevant score per message.

133
00:08:35,399 --> 00:08:36,869
Per user pair, right?

134
00:08:36,899 --> 00:08:41,429
So only messages above, above a
certain threshold make it to delivery.

135
00:08:41,639 --> 00:08:46,740
And that's one of the brief explanations
of what smart filtering could possibly be.

136
00:08:48,480 --> 00:08:50,580
This basically helps to reduce low.

137
00:08:51,145 --> 00:08:57,084
Low I, low importance message noise
low value noise, and helps reduce the

138
00:08:57,084 --> 00:08:58,885
notification fatigue for the user.

139
00:08:59,944 --> 00:09:03,784
The second one where machine learning
is instrumental is targeted content

140
00:09:03,935 --> 00:09:05,734
and its personalization at scale.

141
00:09:07,010 --> 00:09:07,760
Problem.

142
00:09:08,180 --> 00:09:11,030
Let's talk about briefly what the
problem is here, and it's like

143
00:09:11,060 --> 00:09:16,130
generic messages don't convert,
but user content which caters to

144
00:09:16,130 --> 00:09:20,960
a specific user, like handcrafted
content is really impossible to.

145
00:09:21,330 --> 00:09:22,950
Make it for every user.

146
00:09:23,130 --> 00:09:25,830
So how do we make targeted content, right?

147
00:09:26,220 --> 00:09:29,940
So we try to use something which
is like energy, just natural

148
00:09:29,940 --> 00:09:31,440
language generation models.

149
00:09:31,860 --> 00:09:35,460
It's basically either template
based or fine tuned Transformers.

150
00:09:35,490 --> 00:09:38,190
Examples could be TFI or distill GPT.

151
00:09:38,970 --> 00:09:42,000
Let's take an example of an
e-commerce platform here.

152
00:09:42,555 --> 00:09:44,385
You left this in your card.

153
00:09:44,745 --> 00:09:46,605
Have you seen that recently coming to you?

154
00:09:46,605 --> 00:09:48,314
Pretty often, yeah.

155
00:09:48,314 --> 00:09:50,115
Still thinking about Nike Air.

156
00:09:50,115 --> 00:09:51,135
They're almost gone.

157
00:09:51,530 --> 00:09:57,079
What this does is, one, it reminds you
of you left something and you moved on.

158
00:09:57,140 --> 00:10:01,370
You moved on for any reason, but
it basically adds a personalization

159
00:10:01,430 --> 00:10:04,790
tone that it look it things about
what you left in the cart and are

160
00:10:04,790 --> 00:10:06,170
you still thinking about that?

161
00:10:06,770 --> 00:10:10,939
And the almost gone part tells
you that there is an urgency.

162
00:10:10,939 --> 00:10:14,180
This deal is going to be gone
in the next three hours, right?

163
00:10:14,765 --> 00:10:16,115
Is it really gonna be gone?

164
00:10:16,115 --> 00:10:18,785
We don't know, but we are trying
to personalize the content for you.

165
00:10:19,025 --> 00:10:24,865
The notification seems to be more
targeted and that basically helps you add.

166
00:10:25,420 --> 00:10:28,060
Add that targeted audience
to the notification.

167
00:10:28,569 --> 00:10:32,079
Personalization input could
be purchase history, favorite

168
00:10:32,230 --> 00:10:37,030
categories, recent session
behavior and social proof triggers.

169
00:10:37,420 --> 00:10:40,660
For example, what's its ubiquitous,
what's trending near you?

170
00:10:40,660 --> 00:10:43,569
Where do you live, and what's
the local sales going on?

171
00:10:43,600 --> 00:10:45,730
What's the market like in that region?

172
00:10:46,150 --> 00:10:48,340
And these are basically
social proof triggers.

173
00:10:49,270 --> 00:10:54,879
So this is known to engage or
boost engagement by 20 to 50%

174
00:10:54,879 --> 00:10:56,319
in production environments.

175
00:10:57,429 --> 00:11:01,749
Oh, the next one where machine learning
comes into picture as continuous

176
00:11:01,749 --> 00:11:04,059
impro improvement or feedback loops.

177
00:11:04,689 --> 00:11:09,009
User behaviors keep on evolving
and one time model training

178
00:11:09,009 --> 00:11:10,329
leads to stale productions.

179
00:11:10,359 --> 00:11:14,319
What is current today mean
will already be stale tomorrow.

180
00:11:14,319 --> 00:11:19,509
And users and trust as well as, the market
is evolving that fast, that you really

181
00:11:19,509 --> 00:11:21,519
cannot have stale notification data.

182
00:11:22,119 --> 00:11:25,899
So basically we can implement in
the scenario is what it's called,

183
00:11:25,899 --> 00:11:29,829
a closed loop learning system, and
every user interaction, whether it's

184
00:11:29,829 --> 00:11:34,449
a click, ignore, mute, dismiss, is
logged and used as labeled data.

185
00:11:35,139 --> 00:11:40,509
Daily batch jobs run, which retrain
the model and update the weights or the

186
00:11:40,509 --> 00:11:43,779
scores on of each of the feature values.

187
00:11:44,229 --> 00:11:47,769
New models are deployed using
shadow mode, for example, AB

188
00:11:47,829 --> 00:11:49,419
test versus current production.

189
00:11:49,419 --> 00:11:53,289
A scenario to avoid any regression
for on already learned data.

190
00:11:54,554 --> 00:11:59,204
Some of the well-known tooling, which
is used is ML Flow or Azure ML pipelines

191
00:11:59,564 --> 00:12:05,084
for experiment tracking and deployment
feature stores like Feast to manage real

192
00:12:05,084 --> 00:12:07,754
time and historical data consistency.

193
00:12:09,014 --> 00:12:14,384
Then we next move on to multi object
optimization, which involves timing,

194
00:12:14,384 --> 00:12:17,894
channel, and volume beyond just content.

195
00:12:18,104 --> 00:12:21,494
We use the ML pipeline
to optimize when to send.

196
00:12:22,169 --> 00:12:25,859
Using time series predictions
with using something like maybe

197
00:12:25,859 --> 00:12:28,799
profit or where to send, right?

198
00:12:28,799 --> 00:12:32,609
Like we spoke about channels briefly
before as is the push notification

199
00:12:32,609 --> 00:12:37,149
more ac more accurate at the given
point, or is it an SMS or an email?

200
00:12:37,209 --> 00:12:39,759
We have different channels which
are available at our disposal.

201
00:12:40,539 --> 00:12:43,269
And how often do sing, for example.

202
00:12:43,764 --> 00:12:48,924
If you see that a user is continuously
dismissing a particular notification,

203
00:12:49,314 --> 00:12:53,574
then we have to ensure that the user
gets that notification at a much

204
00:12:53,574 --> 00:12:57,324
lower frequency than what is currently
available, and that is something which

205
00:12:57,324 --> 00:12:59,154
is widely known as adaptive throttling.

206
00:13:00,310 --> 00:13:04,900
In some systems, we try to combine
these multi-arm banded frameworks.

207
00:13:05,349 --> 00:13:10,930
Each arm is a content timing channel
combination, and we optimize basically

208
00:13:10,930 --> 00:13:15,069
for accumulative reward, which is user
engagement in our case, while we try

209
00:13:15,069 --> 00:13:18,910
to increase the weights and scores and
determine and explore new strategies.

210
00:13:19,569 --> 00:13:23,920
This approach ensures responsiveness and
adaptability in the fast changing world.

211
00:13:26,829 --> 00:13:32,569
We also start using models like Onyx
and low latency environments or via

212
00:13:32,599 --> 00:13:38,069
like tfs, running our cloud interface
inferences for determining the different

213
00:13:38,310 --> 00:13:42,510
models which serve and what is more
ac accurate based on our adaptive

214
00:13:42,630 --> 00:13:45,120
l continuously learning models.

215
00:13:45,905 --> 00:13:51,815
We use feature gating systems basically
to roll, make rollout safe and ensure

216
00:13:51,845 --> 00:13:56,525
no doubt, like the learning models or
incon incorrect label data does not

217
00:13:56,525 --> 00:14:01,475
cause our models or outputs To fail
always, we need to maintain something

218
00:14:01,475 --> 00:14:04,685
which is called as explainability,
especially in the regulated industries.

219
00:14:05,545 --> 00:14:09,475
Whether it's Lyme can explain health
model decisions and precision is very

220
00:14:09,475 --> 00:14:11,545
important from our learning experiments.

221
00:14:12,325 --> 00:14:16,405
In short, ML doesn't just
make notifications part, it

222
00:14:16,405 --> 00:14:20,125
makes them personal, context
aware and self-improving.

223
00:14:20,845 --> 00:14:24,505
It's the difference between an
ignored ping and a message that

224
00:14:24,505 --> 00:14:26,005
genuinely delights your user.

225
00:14:28,615 --> 00:14:33,925
Moving on to adaptive rate, limiting
traditional rate limiting uses,

226
00:14:34,345 --> 00:14:38,035
fixed thresholds, and it's more like.

227
00:14:38,830 --> 00:14:43,240
We need to go adaptive at this point
and analyze the user data, time of

228
00:14:43,240 --> 00:14:45,910
day, location, historical response.

229
00:14:45,910 --> 00:14:51,189
Windows predict the likelihood of a
user, basically responding to a category,

230
00:14:51,699 --> 00:14:56,050
whether it's a promo system alert or, and
make it more personalized on a weekend.

231
00:14:56,109 --> 00:15:00,839
Maybe a user is more, aligned
towards answering a promo than a

232
00:15:00,839 --> 00:15:02,520
working day in the morning hours.

233
00:15:02,849 --> 00:15:04,349
But this is what data tells us.

234
00:15:04,349 --> 00:15:06,810
This is what our learning
models continuously tell us.

235
00:15:07,560 --> 00:15:12,570
Throttle using priority cues and leaky
bucket or in, in combination of ML

236
00:15:12,660 --> 00:15:18,390
predictor logic rate limits aren't static
and they adapt to per user over time.

237
00:15:19,080 --> 00:15:23,670
This definitely reduces churn and
notification fatigue for the user.

238
00:15:24,670 --> 00:15:28,959
We have known pretty widely
in even our day-to-day lives.

239
00:15:28,959 --> 00:15:33,910
That timing is everything, and that's what
brings us to predictive delivery, timing.

240
00:15:34,689 --> 00:15:39,219
One of the most overlooked aspects of
notifications is when they are delivered.

241
00:15:39,219 --> 00:15:44,859
We intend to focus so much on the
content, on targeting that we.

242
00:15:45,135 --> 00:15:49,064
Generally forget even the most
relevant message when it ends up

243
00:15:49,064 --> 00:15:52,035
on the user's channel or device.

244
00:15:52,155 --> 00:15:53,505
It just gets ignored.

245
00:15:54,194 --> 00:15:57,885
And this is where timing isn't
just delivery optimization, it's

246
00:15:57,885 --> 00:15:59,925
the engagement multiplier for us.

247
00:16:00,555 --> 00:16:03,855
Let me walk you through how we
analyze, predict, and optimize

248
00:16:03,855 --> 00:16:09,310
delivery, basically based on their
data and machine learning combined.

249
00:16:11,105 --> 00:16:14,855
Let's start with something which is known
as let's call it step one, and that's

250
00:16:14,855 --> 00:16:17,015
known as behavioral pattern mining.

251
00:16:17,944 --> 00:16:20,885
We start by ingesting here,
historical engagement logs.

252
00:16:21,680 --> 00:16:25,580
Open times, click times,
mute, unsubscribe events.

253
00:16:25,850 --> 00:16:30,860
And each of this is stacked
with timestamp, user id, device

254
00:16:30,890 --> 00:16:33,110
notification, category and channel.

255
00:16:34,280 --> 00:16:38,570
Using time series clustering
algorithms like K means with dynamic

256
00:16:38,570 --> 00:16:41,240
time wrapping, warping, sorry.

257
00:16:41,290 --> 00:16:44,710
Dynamic time warping DTW or DB scan.

258
00:16:45,190 --> 00:16:49,330
We identify user cohorts with similar
notification engagement rhythms.

259
00:16:49,990 --> 00:16:54,220
We often find patterns like
office workers engage at lunch,

260
00:16:54,250 --> 00:16:55,810
which is like 12 to 1:00 PM.

261
00:16:56,350 --> 00:17:01,060
Students respond post classes
after six to 9:00 PM is the primary

262
00:17:01,060 --> 00:17:05,800
window, and parents engage late
at night, say 9:00 PM to 11:00 PM.

263
00:17:06,460 --> 00:17:10,345
These temporal fingerprints form the
foundation of personalized scheduling.

264
00:17:11,565 --> 00:17:15,825
The next thing we move on to
is the predictive modeling

265
00:17:15,825 --> 00:17:17,055
of what we have captured.

266
00:17:17,055 --> 00:17:17,625
So far.

267
00:17:18,405 --> 00:17:23,375
We have grouped our user cohorts and
we have, we can now have the ability to

268
00:17:23,375 --> 00:17:30,330
train time aware ML models to forecast
the open probability model choice could

269
00:17:30,330 --> 00:17:35,130
be something like gradient boosting
or temporal neural networks like lstm.

270
00:17:36,950 --> 00:17:39,440
What are the primary
input features for us?

271
00:17:39,530 --> 00:17:43,510
Local time of day of week,
users, device status.

272
00:17:43,510 --> 00:17:47,860
For example, screen time, app
usage, and recent engagement trends.

273
00:17:48,880 --> 00:17:53,080
The model outputs a heat map of
likelihood scores for engagement

274
00:17:53,080 --> 00:17:56,320
per hour in the next 24 to 48 hours.

275
00:17:57,190 --> 00:18:01,180
Which brings us to our, now we
have spoken about predictions

276
00:18:01,180 --> 00:18:03,100
and we know what data is there.

277
00:18:03,460 --> 00:18:06,970
It brings us to our next important step,
and which is intelligence scheduling

278
00:18:07,660 --> 00:18:12,340
instead of a fixed delivery window, our
notification service towards the next

279
00:18:12,340 --> 00:18:17,590
best delivery time in the metadata for
each message uses a lightweight scheduler.

280
00:18:17,590 --> 00:18:21,220
It just could be a background
worker or a crown job to NQ

281
00:18:21,220 --> 00:18:23,590
messages into red streams or Kafka.

282
00:18:23,605 --> 00:18:28,045
At the right moment and supports a
snooze fallback if the user hasn't

283
00:18:28,045 --> 00:18:32,725
interacted for say X hours, retry
the second best predicted time.

284
00:18:33,385 --> 00:18:38,395
This allows us to delay non-urgent
messages, prioritize system critical

285
00:18:38,425 --> 00:18:43,135
alerts in real time, and our clustering
of messages around high churn hours.

286
00:18:44,785 --> 00:18:45,205
Now.

287
00:18:45,865 --> 00:18:50,485
We have done the tasks of delivering the
actual notification the right time, but

288
00:18:50,485 --> 00:18:52,525
how do we really know that it worked?

289
00:18:52,915 --> 00:18:57,115
And that's where our la, our last step
of impact measurement comes into picture.

290
00:18:57,955 --> 00:19:01,345
So we compared productive
versus random delivery windows.

291
00:19:01,405 --> 00:19:05,455
And one thing we have realized that
open rates have improved by almost

292
00:19:05,455 --> 00:19:12,015
a. To 35% engagement rose by 45%,
and general uninstall and mute

293
00:19:12,015 --> 00:19:14,625
rates dropped by a whooping 18%.

294
00:19:15,315 --> 00:19:18,900
And this wasn't a one time experiment
as we saw the metrics were.

295
00:19:19,675 --> 00:19:23,335
Gathered over several weeks with
different user segments, and we've

296
00:19:23,335 --> 00:19:26,875
seen this consistently in different
experiments over the industry.

297
00:19:27,625 --> 00:19:33,295
We can really track performance using
real time dashboards, Grafana or influx tv

298
00:19:33,675 --> 00:19:38,595
daily reports, slides by time buckets and
user demographics and longitudinal studies

299
00:19:38,595 --> 00:19:41,175
to verify sustainable sustained impact.

300
00:19:42,345 --> 00:19:44,865
What are the key considerations
for us at this time?

301
00:19:45,465 --> 00:19:49,845
All scheduled messages are item potent
and stored with time to leverage

302
00:19:49,935 --> 00:19:52,665
TTLs to prevent outdated delivery.

303
00:19:53,175 --> 00:19:58,005
Predictive timing works best when
combined with adaptive rate limiting and.

304
00:19:58,425 --> 00:20:01,705
We need to be aware be
aware of notification storm.

305
00:20:02,125 --> 00:20:05,750
Use a distributed scheduler
jitter to prevent spikes.

306
00:20:05,750 --> 00:20:08,660
You don't wanna deliver all
the notifications to a user at

307
00:20:08,660 --> 00:20:12,050
the same time, and it could be
through independent scenarios.

308
00:20:12,050 --> 00:20:13,910
So we need to be really
careful about that.

309
00:20:13,910 --> 00:20:18,350
To add jitters to suddenly increase
a notification fatigue for the user.

310
00:20:19,160 --> 00:20:22,250
So to sum up, great
content needs great timing.

311
00:20:22,580 --> 00:20:26,990
Predictive delivery ensures your message
lands, not just where it matters.

312
00:20:27,430 --> 00:20:31,450
But when it matters most, it
turns your system from reactive to

313
00:20:31,450 --> 00:20:35,020
proactive, and that's a game changer,
which is known in this industry.

314
00:20:36,020 --> 00:20:40,220
Moving on to multi-level caching
strategies and notification system.

315
00:20:40,720 --> 00:20:43,600
One thing that you should think
when you think of caching and

316
00:20:43,600 --> 00:20:47,630
that speed our caching strategy
is generally like in memory.

317
00:20:47,630 --> 00:20:50,990
Something like Redis, it's stored
session and personalization data

318
00:20:51,170 --> 00:20:53,300
and available for quick access.

319
00:20:53,300 --> 00:20:55,300
For example, less than a millisecond.

320
00:20:55,900 --> 00:20:58,330
The second one is more
like a distributed cache.

321
00:20:58,330 --> 00:21:01,900
You could use something like age or
Redis with clustering, and this can be

322
00:21:01,900 --> 00:21:07,180
used for throttling counters or template
data, predictive fetching, and these

323
00:21:07,180 --> 00:21:11,860
are the ML model, preloads most likely
templates and images before usage.

324
00:21:12,250 --> 00:21:13,480
And the last one where we.

325
00:21:13,490 --> 00:21:18,020
Speak about is the persistent
blob storage for cold and archival

326
00:21:18,020 --> 00:21:21,710
storage, and it's used for audit
trails and retries kind of stuff.

327
00:21:22,230 --> 00:21:27,540
We benchmark the cash hit ratio after
every release targeting 90% or greater

328
00:21:27,540 --> 00:21:29,580
than 90% hit rates for hot paths.

329
00:21:30,000 --> 00:21:33,730
And those are very, the hot parts
are primary important factor here.

330
00:21:35,240 --> 00:21:39,590
Let's briefly talk about a case
study based on a e-commerce platform.

331
00:21:40,780 --> 00:21:43,990
And this is let's talk about
it as a real success story.

332
00:21:44,710 --> 00:21:49,300
Client basically had, say, a
68 person cart abandonment.

333
00:21:49,390 --> 00:21:53,650
And the previous solution used
batch based fixed schedule emails.

334
00:21:53,650 --> 00:21:55,450
Open rates was like 4%.

335
00:21:55,450 --> 00:21:59,755
See, every night at 10:00 PM you get an
email about what you left in your cart.

336
00:22:00,655 --> 00:22:02,035
Do you really care about it?

337
00:22:02,875 --> 00:22:04,285
Mostly people won't.

338
00:22:05,095 --> 00:22:09,985
What's our solution is like real
time eventing for cart abandonment.

339
00:22:10,315 --> 00:22:12,685
We just spoke about that
example where you get, Hey, are

340
00:22:12,685 --> 00:22:13,915
you still interested in this?

341
00:22:13,915 --> 00:22:15,055
This is gonna be gone soon.

342
00:22:15,095 --> 00:22:19,085
And that's real time eventing
ML model predicted intent.

343
00:22:19,160 --> 00:22:24,240
To purchase within one to three hours
and messages had personalized spec

344
00:22:24,290 --> 00:22:27,800
subject lines and discount triggers
based on past purchase history.

345
00:22:28,220 --> 00:22:29,720
You bought this previously.

346
00:22:30,320 --> 00:22:31,880
Are you still interested in this?

347
00:22:31,970 --> 00:22:35,180
You bought a mattress, you still
want a mattress cover, right?

348
00:22:35,990 --> 00:22:36,380
It really.

349
00:22:37,040 --> 00:22:41,480
Triggers you and you feel like you
need that stuff when you don't know

350
00:22:41,480 --> 00:22:44,720
how much you really need it at the
given point, but the message still

351
00:22:44,720 --> 00:22:46,400
ends up as a notification for you.

352
00:22:47,090 --> 00:22:48,770
What's the impact that we saw?

353
00:22:48,980 --> 00:22:56,960
A 42% increase in recovery, 28%
fewer messages sent and 37% higher

354
00:22:56,960 --> 00:23:01,650
click through rates and section
second reaction rates isn't Those

355
00:23:01,650 --> 00:23:03,420
numbers sound really promising.

356
00:23:04,420 --> 00:23:10,270
Now let's talk about an implementation
roadmap or our playbook for

357
00:23:10,270 --> 00:23:11,590
building something similar.

358
00:23:12,460 --> 00:23:15,160
One is the Microservice Foundation.

359
00:23:15,670 --> 00:23:19,845
Break your system into core
services, ingestion, formatting,

360
00:23:20,405 --> 00:23:21,405
delivery, and analytics.

361
00:23:22,265 --> 00:23:25,365
Use scalable brokers and
content based deployments.

362
00:23:26,620 --> 00:23:28,240
Have an intelligent layer.

363
00:23:28,240 --> 00:23:33,010
Start with engagement prediction
models, add adaptive rate limiting,

364
00:23:33,010 --> 00:23:35,170
and dynamic channel ranking over it.

365
00:23:35,830 --> 00:23:40,180
Lastly, introduced natural language
graph for content personalization.

366
00:23:41,650 --> 00:23:46,210
And one primary important thing that
we talk about in machine learning

367
00:23:46,210 --> 00:23:48,430
systems is continuous optimization.

368
00:23:49,090 --> 00:23:52,475
Use AB tests to evaluate
every model change.

369
00:23:53,395 --> 00:23:59,485
Build automated retraining pipelines using
airflow ML flow and Azure ML pipelines.

370
00:24:00,175 --> 00:24:06,445
Track long-term LTVs as lifetime value
and not just CDRs, and this is a very

371
00:24:06,445 --> 00:24:11,815
good recipe or just a high level playbook
for you to implement an notification

372
00:24:11,815 --> 00:24:17,130
system which integrates with basically
all the important parameters or

373
00:24:17,130 --> 00:24:19,735
important gotchas of ML integration.

374
00:24:21,355 --> 00:24:24,715
Thank you so much for your time
and building scalable, intelligent

375
00:24:24,715 --> 00:24:28,495
notification system as a marriage
of real time infrastructure and ML

376
00:24:28,495 --> 00:24:32,935
intelligence is challenging, but
incredibly rewarding, and especially

377
00:24:32,935 --> 00:24:35,695
when users experience your craft.

378
00:24:36,415 --> 00:24:39,805
I'd love to hear from you and
what challenges you're facing with

379
00:24:39,805 --> 00:24:41,605
engagement or delivery systems.

380
00:24:42,025 --> 00:24:45,865
You can find me on LinkedIn
or just let me know whatever

381
00:24:45,865 --> 00:24:47,275
questions you have regarding dread.

382
00:24:47,275 --> 00:24:48,925
So thank you so much for your time.

