1
00:00:00,500 --> 00:00:01,339
Hi everyone.

2
00:00:01,640 --> 00:00:02,360
Good morning.

3
00:00:02,860 --> 00:00:07,480
Thank you for ha attending my session
and also a big thank you to the

4
00:00:07,480 --> 00:00:09,640
organizers for having this conference.

5
00:00:10,600 --> 00:00:11,980
I'm Anush Wicker.

6
00:00:12,460 --> 00:00:18,505
I am the software engineering manager
at ai and today I would like to tell you

7
00:00:18,505 --> 00:00:21,955
about my interest of using Rust with ai.

8
00:00:22,455 --> 00:00:28,005
Russ has been redefining edge AI
combining safety, performance, and

9
00:00:28,005 --> 00:00:32,985
fine-grain control to meet the real world
constraints of embedded intelligence.

10
00:00:33,485 --> 00:00:42,220
Now we do see that the Edge AI market
is exploring with the 44.2% of CAGR.

11
00:00:42,905 --> 00:00:44,345
Now, this is not a hype.

12
00:00:44,795 --> 00:00:48,455
This is just the adoption driven
by real performance demands,

13
00:00:48,955 --> 00:00:54,505
27.8 billion market size by 2026.

14
00:00:55,435 --> 00:00:58,705
That means there's a lot of app
opportunity for rust developers.

15
00:00:59,205 --> 00:01:04,694
Also, the less than 50 millisecond
latency as a holy grail for edge

16
00:01:04,754 --> 00:01:09,435
ai, which the cloud infrastructures
cannot reliably deliver This.

17
00:01:10,259 --> 00:01:13,320
We need an optimize on device computation.

18
00:01:13,820 --> 00:01:21,759
Okay, let me walk through some of the
advantages of using rust on Edge ai.

19
00:01:22,259 --> 00:01:24,420
First is the memory Safety.

20
00:01:24,479 --> 00:01:29,149
Without garbage collection, we
can avoid memory leaks and data

21
00:01:29,149 --> 00:01:33,589
traces with the garbage without a
garbage collector slowing us down.

22
00:01:34,089 --> 00:01:42,159
Also, we do have zero cost abstractions,
so the ability to write clean, expressive

23
00:01:42,159 --> 00:01:45,009
code without paying in performance.

24
00:01:45,509 --> 00:01:51,289
Also, it has a fine grain system
controlled, which means that an edge ai,

25
00:01:51,289 --> 00:01:54,554
every byte in every CPU cycle matters.

26
00:01:55,054 --> 00:01:59,285
Let's talk about some of the
real world performance advantages

27
00:01:59,375 --> 00:02:00,815
that we have with Rust.

28
00:02:01,315 --> 00:02:05,185
There is a 92% performance
improvement over other languages,

29
00:02:05,634 --> 00:02:07,435
and these are production numbers.

30
00:02:08,185 --> 00:02:14,905
Also, 82% cost reduction as
a big business driver also.

31
00:02:15,894 --> 00:02:19,285
73.2% of memory usage reduction.

32
00:02:19,704 --> 00:02:23,575
Now, this can be the difference
between fitting your model

33
00:02:23,605 --> 00:02:25,584
on device or not at all.

34
00:02:26,084 --> 00:02:31,324
Let's talk about some of the secret
weapons for using Rust of Edge ai.

35
00:02:31,824 --> 00:02:36,855
First is the safe concurrency for a
multi-core arm, we can scale safely

36
00:02:36,975 --> 00:02:39,494
across course without runtime penalties.

37
00:02:39,994 --> 00:02:48,544
Also using an efficient single instruction
multiple demand with portable SIMD.

38
00:02:48,964 --> 00:02:54,664
That is two of six x speed
without handwritten assembly.

39
00:02:55,164 --> 00:02:59,754
There is also a seamless
hardware acceleration integration

40
00:03:00,084 --> 00:03:02,604
that is from NPUs to DSPs.

41
00:03:02,964 --> 00:03:04,974
Rust plays nicely with them.

42
00:03:05,604 --> 00:03:07,794
Even in no SDD environments,

43
00:03:08,294 --> 00:03:11,534
let's talk about a case
study on autonomous vehicles.

44
00:03:12,034 --> 00:03:17,994
The challenge that we have here is
we need a 15 millisecond obstacle

45
00:03:17,994 --> 00:03:25,114
detection challenge, and also we need
a 99.2% top detection success rate.

46
00:03:25,614 --> 00:03:30,624
12.7 millisecond inference
time and 99.99% uptime.

47
00:03:31,584 --> 00:03:36,744
That is why rusts is reliable
in safety critical applications.

48
00:03:37,244 --> 00:03:43,274
Rusts compile time also guarantees
eliminating a lot of runtime errors, which

49
00:03:43,274 --> 00:03:45,524
are actually being plagued to c plus.

50
00:03:45,524 --> 00:03:46,419
This applications.

51
00:03:46,919 --> 00:03:50,699
Let's talk about a case study,
which is a different one now.

52
00:03:50,729 --> 00:03:53,039
It's called Industrial IOT Security.

53
00:03:53,539 --> 00:03:57,889
There is a 99.85% of threat
detection accuracy, which is

54
00:03:57,889 --> 00:03:59,539
observed on modest hardware.

55
00:03:59,989 --> 00:04:07,339
With this rust on edge ai also we have,
we see a 22 millisecond response time

56
00:04:07,639 --> 00:04:11,479
and a 4.8 years of battery life with.

57
00:04:11,914 --> 00:04:12,694
P hardware.

58
00:04:12,994 --> 00:04:17,495
So we do see a predictable
performance, which makes low power

59
00:04:17,495 --> 00:04:20,015
edge devices viable for yours.

60
00:04:20,515 --> 00:04:26,744
The Edge AI ecosystem consists of
candle code, which is a high performance

61
00:04:26,984 --> 00:04:32,659
network library, which is used for
inferences with minimal dependencies.

62
00:04:33,159 --> 00:04:37,599
Next there is a burn, which is a
deep learning framework with strong

63
00:04:37,929 --> 00:04:42,339
type system and modular backends,
which enables model training.

64
00:04:43,329 --> 00:04:50,170
And finally, we have a smart core, which
is machine learning, library implementing

65
00:04:50,469 --> 00:04:56,350
traditional machine learning algorithms
and is also compatible with no SD.

66
00:04:56,850 --> 00:05:02,670
Now this ecosystem is rapidly maturing,
which creates new creates and capabilities

67
00:05:03,000 --> 00:05:08,250
emerging monthly to support the
entire edge AI development lifecycle.

68
00:05:08,750 --> 00:05:11,570
Let's talk about the
implementation patterns for a

69
00:05:11,570 --> 00:05:13,640
custom neural network operators.

70
00:05:14,390 --> 00:05:20,575
So whenever we are creating a
neural network operator for rust.

71
00:05:21,075 --> 00:05:24,855
In a GI, we need precise optimization.

72
00:05:25,355 --> 00:05:29,705
Also, the there, these are some
of the key patterns to achieve

73
00:05:29,705 --> 00:05:32,075
maximum performance and efficiency.

74
00:05:32,575 --> 00:05:38,365
With no heap allocations, we achieve no
STD compatibility, which is very crucial

75
00:05:38,485 --> 00:05:40,525
for highly constrained embedded systems.

76
00:05:41,500 --> 00:05:46,060
And also guarantees deterministic
and low latency operations.

77
00:05:46,560 --> 00:05:53,350
Optimized cache utilization, which will
be implementing cache friendly memory

78
00:05:53,350 --> 00:05:59,290
access patterns dramatically reduces
the memory latency leads to a faster

79
00:05:59,290 --> 00:06:02,050
processing time and execution speed.

80
00:06:02,550 --> 00:06:08,460
Manual loop unrolling enhances the CPU
in instruction pipeline efficiency,

81
00:06:08,940 --> 00:06:14,360
and also provides a high predictable
execution times for real time edge

82
00:06:14,360 --> 00:06:16,540
AI task direct slides manipulation.

83
00:06:17,040 --> 00:06:20,465
Optimized to remove the bound
checks in the release mode,

84
00:06:20,795 --> 00:06:22,505
ensures maximum performance.

85
00:06:22,835 --> 00:06:26,705
While maintaining RUS
score safety GA guarantees.

86
00:06:27,205 --> 00:06:32,585
Now let's talk in detail about the
implementation patterns for optimizing

87
00:06:33,395 --> 00:06:36,335
the arm and the risk processes.

88
00:06:36,835 --> 00:06:40,765
Russ lets us combine binaries
that fully exploit the hardware.

89
00:06:41,245 --> 00:06:41,905
So for example.

90
00:06:42,550 --> 00:06:47,770
We can use Garbo features and CFG
attributes to enable the instruction

91
00:06:47,770 --> 00:06:50,770
sets, which are specific to A CPU.

92
00:06:51,280 --> 00:06:57,100
And then the RAs compiler generates a
highly optimized ARCHITE specific binaries

93
00:06:57,400 --> 00:07:02,970
that actually leverage the capabilities
of ARM and the risk P processes, which

94
00:07:03,390 --> 00:07:05,790
eventually leads to a peak performance.

95
00:07:06,290 --> 00:07:06,530
Okay.

96
00:07:07,320 --> 00:07:13,130
Using rust is actually better
as we have some of the drawbacks

97
00:07:13,160 --> 00:07:17,940
of like c programming language
which can be nullified.

98
00:07:18,330 --> 00:07:24,350
One thing is the direct safe control
of the hardware, which is possible

99
00:07:24,350 --> 00:07:26,540
with memory wad hardware, accelerators.

100
00:07:27,040 --> 00:07:31,415
The real world impact of using rust before
and after are mentioned in this slide.

101
00:07:31,915 --> 00:07:35,590
Rust improves with the
memory related crashes.

102
00:07:36,090 --> 00:07:42,415
Also, it reduces the average
inference time to 12.3 milliseconds.

103
00:07:42,915 --> 00:07:48,075
It also helps with the heat dissipation,
issues with cooler operating temperatures,

104
00:07:48,795 --> 00:07:55,155
and it has been instrumental in
extending the battery life by 4.7 years.

105
00:07:55,655 --> 00:08:01,585
Also the mist detection rate has
been reduced to 0.08 percents now.

106
00:08:02,125 --> 00:08:07,195
Rust actually changes this equation
and actually is more capable with

107
00:08:07,195 --> 00:08:09,835
less cost and more reliability.

108
00:08:10,335 --> 00:08:16,455
Some of the key takeaways from today's
session is that Rust and Edge AI will

109
00:08:16,515 --> 00:08:22,365
actually enhance the performance of the
next generation intelligent systems.

110
00:08:22,865 --> 00:08:28,390
Rust is also memory safe without
any compromises, so we can eliminate

111
00:08:28,390 --> 00:08:29,950
in an entire class of bugs.

112
00:08:30,325 --> 00:08:35,755
Without sacrificing performance of
systems programming for mission critical

113
00:08:35,785 --> 00:08:41,295
edge applications, the Rust Edge AI
ecosystem is also rapidly maturing with

114
00:08:41,295 --> 00:08:44,355
high quality of libraries and frameworks.

115
00:08:44,685 --> 00:08:50,355
So there are a lot of opportunities and
alternatives while offering superior

116
00:08:50,355 --> 00:08:56,255
safety guarantees the production
deployments, which you demonstrate trust.

117
00:08:56,675 --> 00:09:02,035
Have advantages of 90% of performance
improvements, 70% of memory

118
00:09:02,035 --> 00:09:05,845
reduction, and 99.9% reliability.

119
00:09:06,595 --> 00:09:11,335
As edge computing continues its
explosive growth, rust is position to

120
00:09:11,335 --> 00:09:16,255
become the foundation of intelligence
systems that combine unprecedented

121
00:09:16,345 --> 00:09:18,505
performance with reliability.

122
00:09:19,005 --> 00:09:24,585
You can always start with rust
on your system by using cargo at

123
00:09:24,585 --> 00:09:28,185
Kind Core Burn and Smart Core.

124
00:09:28,685 --> 00:09:31,085
Please let me know if
you have any questions.

125
00:09:31,295 --> 00:09:35,675
You can reach out to me via chat
and also on my LinkedIn profile.

126
00:09:36,305 --> 00:09:40,475
And once again, thank you to the
organizers of this conference.

127
00:09:41,240 --> 00:09:43,370
Also you, the audience.

128
00:09:43,870 --> 00:09:43,900
Okay.

