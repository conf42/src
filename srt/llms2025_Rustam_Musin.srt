1
00:00:00,000 --> 00:00:01,110
Hello, my name is Ruta.

2
00:00:01,470 --> 00:00:03,810
Welcome to this talk on after
making podcast localization

3
00:00:03,810 --> 00:00:06,030
using open eyes, API Stack.

4
00:00:06,180 --> 00:00:09,450
And this talk we'll explore how to
convert English podcasts into Russian

5
00:00:09,900 --> 00:00:11,370
while maintaining tone and style.

6
00:00:11,670 --> 00:00:14,820
We'll go through architecture,
technical challenges, and real examples.

7
00:00:15,060 --> 00:00:15,720
Let's get started.

8
00:00:16,219 --> 00:00:19,550
the main question is why we want to
automate podcast localization, and

9
00:00:19,550 --> 00:00:21,140
there are two, two main reasons.

10
00:00:21,380 --> 00:00:24,740
The first reason is to make content
accessible to a wider audience.

11
00:00:24,950 --> 00:00:28,940
Podcasts which are only in English can
now be consumed by Russian speaking people

12
00:00:29,240 --> 00:00:33,860
without any knowledge of English I. The
second reason is to reduce manual effort

13
00:00:33,860 --> 00:00:35,510
while enduring high quality results.

14
00:00:35,989 --> 00:00:39,290
In other words, automation makes
it simpler to translate podcasts

15
00:00:39,349 --> 00:00:40,670
without human intervention.

16
00:00:41,360 --> 00:00:45,200
While doing so, we want to maintain
tone and style and translation,

17
00:00:45,260 --> 00:00:48,800
and GBT four O helps with that by
allowing us to translate English

18
00:00:48,800 --> 00:00:52,680
speaking speech, to Russian while
preserving the original tone and style.

19
00:00:53,180 --> 00:00:54,770
A solution overview.

20
00:00:55,070 --> 00:00:57,620
Here is the overall structure
of our localization system.

21
00:00:57,800 --> 00:01:00,010
Each step plays a critical
role in transforming English

22
00:01:00,010 --> 00:01:01,269
podcast, into a Russian one.

23
00:01:01,900 --> 00:01:05,860
The first step is podcast download
where we download the podcast

24
00:01:05,890 --> 00:01:09,640
metadata such as title and
description and the empathy file.

25
00:01:10,210 --> 00:01:13,210
And then there is a
second step transcription.

26
00:01:13,509 --> 00:01:19,150
We have to transcript this empathy file
into a text, and then text processing.

27
00:01:19,720 --> 00:01:20,289
We.

28
00:01:20,680 --> 00:01:24,580
Give this text to process
into GPT-4 oh model.

29
00:01:25,030 --> 00:01:29,669
The processing includes, adding all the
punctuation marks, adding, fixing all

30
00:01:29,669 --> 00:01:35,970
the grammar and so on so that the speech
sounds more natural and sounds more live.

31
00:01:36,929 --> 00:01:41,699
Then we have speech synthesis and
here is where we, take the TTS

32
00:01:41,699 --> 00:01:46,929
one model and produce the Russian
track, on this translated text.

33
00:01:47,754 --> 00:01:48,894
And audio assembly.

34
00:01:49,314 --> 00:01:53,694
and this step is needed because
when we use cts one model, it

35
00:01:53,694 --> 00:01:58,524
has a very small restriction in
about 4,000 characters at once.

36
00:01:58,614 --> 00:02:04,474
So we can only give it to 400 characters
to, To make an MP three track from it.

37
00:02:04,684 --> 00:02:08,524
And if the podcast is long enough, we
have to split the podcast into multiple

38
00:02:08,524 --> 00:02:10,954
chunks and then merge this audio files.

39
00:02:11,914 --> 00:02:16,774
And the next step is RSS generation,
where we generate an R Ss feed, which

40
00:02:16,774 --> 00:02:19,424
is then consumed by, podcast platforms.

41
00:02:19,664 --> 00:02:24,794
And they can check this errors sheet later
on and see that if there is a new podcast,

42
00:02:24,854 --> 00:02:27,014
then there is a new episode of a podcast.

43
00:02:27,314 --> 00:02:30,884
They add it to their platform
and notify users and whatnot.

44
00:02:31,384 --> 00:02:35,284
And here is the line of
pipeline, and as you can see.

45
00:02:35,989 --> 00:02:38,464
All the steps are going after each other.

46
00:02:38,554 --> 00:02:42,244
So we don't load the track, then we
transcribe it, then we enhance the

47
00:02:42,244 --> 00:02:45,734
transcription, then we translate
in enhanced track, and so on.

48
00:02:46,544 --> 00:02:50,474
And this design not only helps to
maintain clarity, but also allows

49
00:02:50,474 --> 00:02:52,454
for easy scalability and improvement.

50
00:02:52,994 --> 00:02:55,514
Each phase in the pipeline plays
a specific role in ensuring the

51
00:02:55,514 --> 00:02:58,994
quantity is processed, translated and
delivered in the best possible way.

52
00:02:59,654 --> 00:03:02,084
All these chunks are
independent of each other.

53
00:03:02,474 --> 00:03:06,934
And this plays a huge role in
this pipeline, key technologies.

54
00:03:07,504 --> 00:03:11,074
so we use Kotlin here because
we're most familiar with Kotlin.

55
00:03:11,794 --> 00:03:17,314
We use Podcast four J as a framework for
using with podcast index.org, whereas

56
00:03:17,344 --> 00:03:21,274
podcast index.org is a huge database of.

57
00:03:21,859 --> 00:03:28,309
Of podcasts and you can ask them about
any podcasts, title, description,

58
00:03:28,909 --> 00:03:32,819
track, and for example, thumbnail.

59
00:03:33,159 --> 00:03:34,899
many info you can take from there.

60
00:03:35,769 --> 00:03:35,919
And.

61
00:03:36,774 --> 00:03:41,034
Open AI API, and we will, we
use three models from there.

62
00:03:41,424 --> 00:03:45,684
We use whisper one to transcribe
audio from the inventory track.

63
00:03:46,194 --> 00:03:51,474
We use GPT-4 oh to work on the
transcribed text and to enhance

64
00:03:51,474 --> 00:03:53,154
it and to translate basically.

65
00:03:53,574 --> 00:03:57,084
And then we use TTS one to
convert this translated text

66
00:03:57,414 --> 00:04:00,354
into the Russian MP three track.

67
00:04:00,854 --> 00:04:06,824
we use Cater with ish TP to make
all the HGTP requests, whereas

68
00:04:07,334 --> 00:04:14,874
Podcast four J has its own client
for the open ai, API we use ish TP.

69
00:04:15,654 --> 00:04:17,784
We use Jackson for all the JSON data.

70
00:04:18,304 --> 00:04:22,594
we use Java X XML APIs
for building RSS feed.

71
00:04:23,314 --> 00:04:30,514
And we are planning to use FMB to
merge the chunks of ber three files.

72
00:04:31,504 --> 00:04:36,404
And, this will allow us to merge
these chunks in the correct way.

73
00:04:36,464 --> 00:04:40,514
'cause if you just merge their
content, there might be problems

74
00:04:40,514 --> 00:04:42,104
with, for example, playback.

75
00:04:42,284 --> 00:04:47,544
You cannot play it from the middle
of the track because each, empathy

76
00:04:47,544 --> 00:04:49,494
file has its own metadata, including.

77
00:04:49,839 --> 00:04:54,609
The length of the track, so you may
jump to a wrong place, basically.

78
00:04:54,849 --> 00:05:01,979
And FFMP, allows to merge these track
to merge the metadata to, to make

79
00:05:01,979 --> 00:05:04,499
the audio levels on the same level.

80
00:05:04,889 --> 00:05:10,634
So you don't hear, big changes in
the loudness and it just makes,

81
00:05:11,064 --> 00:05:12,984
audio files more listenable.

82
00:05:13,484 --> 00:05:14,384
Podcast downloading.

83
00:05:15,094 --> 00:05:17,914
the first step of the pipeline is
downloading podcast metadata in

84
00:05:17,914 --> 00:05:22,784
order from the for new episodes from
podcast dot index podcast index.org.

85
00:05:23,354 --> 00:05:24,834
Using in podcast four J library.

86
00:05:25,334 --> 00:05:28,094
once the metadata is retrieved,
we can then download and the

87
00:05:28,094 --> 00:05:29,744
corresponding number three audio files.

88
00:05:29,864 --> 00:05:33,314
These files are the core content
that will be processed in the

89
00:05:33,344 --> 00:05:35,084
subsequent stages of the pipeline.

90
00:05:36,074 --> 00:05:37,934
Transcription, translation, et cetera.

91
00:05:38,834 --> 00:05:42,644
Now that we have podcast information,
we could, we can move to the next step,

92
00:05:43,244 --> 00:05:46,184
which is speech to text with Whisper.

93
00:05:46,874 --> 00:05:51,074
And in the next step of the pipeline,
we use the whisper one, API, to convert

94
00:05:51,074 --> 00:05:53,354
it and loaded podcast order into text.

95
00:05:53,924 --> 00:05:58,634
And basically we just give this,
give the MPT track to the whisper

96
00:05:58,634 --> 00:06:02,744
one API, and it returns us the text.

97
00:06:03,344 --> 00:06:08,834
One problem with that is that it works
well, only four files under 25 megabytes.

98
00:06:09,524 --> 00:06:13,554
most of the podcasts we used,
we work with are less than 25

99
00:06:13,554 --> 00:06:15,204
megabytes, but there are bigger ones.

100
00:06:15,624 --> 00:06:20,134
And if, the file is bigger, we have
to split it into multiple chunks and

101
00:06:20,134 --> 00:06:22,834
then process each chunk independently.

102
00:06:23,284 --> 00:06:26,314
This is just the,
requirement of whisper one.

103
00:06:26,314 --> 00:06:30,514
It just does not accept
false beer than 25 megabytes.

104
00:06:30,784 --> 00:06:33,334
It's not a big problem,
but it is what it is.

105
00:06:33,834 --> 00:06:36,534
A text enhancement and translation.

106
00:06:37,374 --> 00:06:41,874
first GPT-4 row enhances grammar,
punctuation, and readability here.

107
00:06:42,504 --> 00:06:45,144
And for the prompt, we say context.

108
00:06:45,144 --> 00:06:48,444
This is the transcription
of a podcast in English.

109
00:06:48,504 --> 00:06:51,414
Fix the grammar and punctuation
or translated to English if

110
00:06:51,414 --> 00:06:52,374
it's in the wrong language.

111
00:06:52,704 --> 00:06:56,364
The where podcast starts and
cut, unrelated contented, start

112
00:06:56,994 --> 00:07:00,174
output format and output on with.

113
00:07:01,014 --> 00:07:03,834
Output with no introduction
on the output text.

114
00:07:04,704 --> 00:07:06,114
Other text is polished.

115
00:07:06,684 --> 00:07:10,644
We sent another request to GPT-4 oh
and this time to translate text into

116
00:07:10,644 --> 00:07:16,284
Russian, and the prompt is translate
Text below to the Russian language.

117
00:07:16,554 --> 00:07:20,004
Keep the translation is close to the
original in tone and style as you can.

118
00:07:20,724 --> 00:07:22,404
And we just give it a text.

119
00:07:23,034 --> 00:07:26,874
This way, GPT for all translate text
into Russian while preserving, reserving

120
00:07:26,874 --> 00:07:28,584
the nuances of the original text.

121
00:07:29,304 --> 00:07:32,064
This enjoys that the podcast
conversational style, humor, and

122
00:07:32,064 --> 00:07:35,904
personality are preserved, making
it engaging and relatable to the

123
00:07:35,904 --> 00:07:39,624
Russian speaking audience, just as
it is to the English speaking one.

124
00:07:40,124 --> 00:07:41,864
Speech synthesis with TTS one.

125
00:07:42,224 --> 00:07:45,884
Next, let's dive into the process of
converting the transcript text into

126
00:07:45,884 --> 00:07:51,014
Russian audio is an OpenAI TTS one model,
along with challenges faced in this step.

127
00:07:51,514 --> 00:07:57,564
And in this step we just use TTS
one model, with Russian text.

128
00:07:58,029 --> 00:08:02,359
And it, returns as MP three
tracks with Russian voice.

129
00:08:03,149 --> 00:08:06,149
while the synthesized voices are
quite good, they still carry a

130
00:08:06,149 --> 00:08:09,689
slight American accent, which may
not always sound perfectly natural

131
00:08:09,689 --> 00:08:11,429
for Russian speaking audience.

132
00:08:12,119 --> 00:08:15,749
For example, the intro in English
might be Welcome to Nature Podcast,

133
00:08:15,749 --> 00:08:21,089
sponsored by X, which is translated
to Developer Ledge podcast, nature X.

134
00:08:21,749 --> 00:08:25,619
When comparing the original
audio ai, AI is transforming

135
00:08:25,619 --> 00:08:27,209
science with localized version.

136
00:08:27,709 --> 00:08:31,809
You may notice that while the
translation is accurate, the TTS

137
00:08:31,929 --> 00:08:34,059
voice still carries the American tone.

138
00:08:34,659 --> 00:08:38,119
The slight accent issue can impact
the overall feel of the podcast.

139
00:08:38,619 --> 00:08:39,849
Audio assembly challenges.

140
00:08:40,179 --> 00:08:42,789
Next, let's dive into one
of the key challenges in the

141
00:08:42,789 --> 00:08:44,349
pipeline merging audio files.

142
00:08:44,629 --> 00:08:48,260
it may seem like a straightforward, as the
process is combining of combining multiple

143
00:08:48,260 --> 00:08:54,449
MP three files, presents some technical
hurdles and yeah, as I already said, MP

144
00:08:54,449 --> 00:09:00,750
three metadata can conflict, conflicts,
can create playback issues, and currently

145
00:09:00,750 --> 00:09:03,839
we're just merging the empathy files.

146
00:09:04,275 --> 00:09:07,845
Together, taking their bite
race and merging them together.

147
00:09:08,415 --> 00:09:10,965
It may not work properly, but it works.

148
00:09:10,965 --> 00:09:14,295
If you just listen to the podcast
from this, from start to finish.

149
00:09:14,715 --> 00:09:19,035
If you try to listen to it from the
middle, you may have issues in some

150
00:09:19,035 --> 00:09:21,525
players, in others, it might work.

151
00:09:22,025 --> 00:09:27,775
And also mp, different T files may
have vary BRATE sample rates and coding

152
00:09:27,775 --> 00:09:30,894
methods, volume levels, all this stuff.

153
00:09:31,314 --> 00:09:36,864
And we need to work on it with FFMP,
but this is not the priority right now.

154
00:09:37,364 --> 00:09:38,745
R Ss feed generation.

155
00:09:38,805 --> 00:09:42,045
Now let's look at the final step in our
localization pipeline, which is publishing

156
00:09:42,045 --> 00:09:47,265
the Translated podcast through an RS
feed to import aspects of the process for

157
00:09:47,265 --> 00:09:52,875
distributing the Translated podcast is X
ml based RS feed creation and translated

158
00:09:53,055 --> 00:09:54,610
metadata for better discoverability.

159
00:09:55,470 --> 00:10:01,640
The first one, XML based success fit
creation, is about creating the XML

160
00:10:01,790 --> 00:10:08,770
with, RSS feed and then, feed this
RSS feed into the podcast platforms so

161
00:10:08,770 --> 00:10:13,880
that they can access it, they can see
if we have new episodes, and then they

162
00:10:13,970 --> 00:10:15,470
add new episodes to their platform.

163
00:10:16,220 --> 00:10:20,620
The second thing is translate metadata
for better discoverability, basically

164
00:10:20,620 --> 00:10:26,390
means that we take all titles, all
the, descriptions and translate

165
00:10:26,390 --> 00:10:32,540
them to Russian so people can then
easier find what they want to find.

166
00:10:33,020 --> 00:10:36,850
'cause it would be weird if you
have, a Russian podcast with

167
00:10:36,850 --> 00:10:38,410
English description, right?

168
00:10:38,910 --> 00:10:44,580
Some of the core challenges so far
were file size limits in Whisper, so

169
00:10:44,580 --> 00:10:49,980
we have to split original MP three
files into smaller chunks sometimes.

170
00:10:50,580 --> 00:10:55,159
Second one is style preservation
and translation, and here we

171
00:10:55,159 --> 00:10:57,139
rely on the OpenAI models.

172
00:10:57,890 --> 00:11:03,949
And rely on our prompts so that
we do not just translate the text

173
00:11:03,979 --> 00:11:08,300
as, for example, Google Translate
or any other translate platform.

174
00:11:08,719 --> 00:11:14,750
But we also preserve the style,
preserve the terminology and everything

175
00:11:14,780 --> 00:11:20,510
else using the open areas models
and all the immersion complexities.

176
00:11:21,000 --> 00:11:25,980
it's just FFMP should solve our
problems, but it'll take some time.

177
00:11:26,480 --> 00:11:29,330
in order to endure high quality
translations, we use various

178
00:11:29,330 --> 00:11:31,190
techniques to fine tune GPT-4 O.

179
00:11:31,700 --> 00:11:36,200
This include grammar correction,
prompt to fix whispers output handling

180
00:11:36,200 --> 00:11:41,370
met, mix it language content GBT four
O can translate text into Russian.

181
00:11:41,430 --> 00:11:44,040
So there are only Russian words.

182
00:11:44,790 --> 00:11:49,230
Tone preservation techniques, we ask
GPT-4 O to preserve the tone of the

183
00:11:49,230 --> 00:11:51,090
text while it translates into Russian.

184
00:11:51,590 --> 00:11:52,610
let's look at the example.

185
00:11:53,000 --> 00:11:56,870
and it says the input is AI
school and in Russian Kuta.

186
00:11:57,660 --> 00:12:00,570
here you can see that we have
both English and Russian words.

187
00:12:01,245 --> 00:12:05,595
And for the transcript we will have
AI school and in Russian Kruta,

188
00:12:05,955 --> 00:12:11,295
which is all in English letters, and
then we translate it into Russian

189
00:12:11,295 --> 00:12:16,355
and get, I. This example highlights
how fine tuning the this prompts.

190
00:12:16,505 --> 00:12:20,495
The prompts ensures that GPT-4 O preserves
not just the meaning, but also the

191
00:12:20,495 --> 00:12:22,205
tone and style of the original message.

192
00:12:22,625 --> 00:12:26,165
In this case, it ensures that the use
of cool and Kta fits naturally within

193
00:12:26,165 --> 00:12:29,945
the context and keeps the conversational
tone intact in the translation.

194
00:12:30,445 --> 00:12:34,045
maintaining the original tone of a
podcast is essential for keeping the

195
00:12:34,045 --> 00:12:39,085
audience engaged, and we do this by fine
tuning GPT for Rose translation with

196
00:12:39,085 --> 00:12:41,095
specific prompts to preserve the tone.

197
00:12:41,575 --> 00:12:44,965
In addition, we selected voices that
match the energy level of the speaker.

198
00:12:45,475 --> 00:12:48,325
Let's explore some examples
that demonstrate how we address

199
00:12:48,325 --> 00:12:52,255
challenges related to the tone and
personalization in translation.

200
00:12:52,755 --> 00:12:56,625
on the left you can see that we
use a slight American accent, so

201
00:12:56,625 --> 00:12:58,495
the result, sounds non-native.

202
00:12:58,555 --> 00:13:01,435
It's usable, but we will
improve the voice later on.

203
00:13:01,935 --> 00:13:05,265
we translate all intros, outros, and ads.

204
00:13:05,625 --> 00:13:11,175
We have plans to either remove ads
or adopt them for Russian audience,

205
00:13:11,505 --> 00:13:16,165
but for now, we just translate it
as it is a part of, of a podcast.

206
00:13:17,125 --> 00:13:22,335
And, on the right side, you can see,
before and after comparison example, AI

207
00:13:22,335 --> 00:13:25,365
is transforming science, localized to ae.

208
00:13:25,865 --> 00:13:30,395
And it has like American accent
and it doesn't sound that natural

209
00:13:30,395 --> 00:13:31,985
to Russian speaking persons.

210
00:13:32,485 --> 00:13:35,395
And we also have to work on this part.

211
00:13:35,895 --> 00:13:37,215
Quality assurance measures.

212
00:13:37,785 --> 00:13:42,105
Currently, we enjoy translation accuracy
through manual reviews where we check

213
00:13:42,105 --> 00:13:46,335
for nuances and consistencies and turn
shifts that automated systems might miss.

214
00:13:47,085 --> 00:13:50,295
This helps maintain the original
intent and style of the podcast, but

215
00:13:50,295 --> 00:13:53,745
the process is time consuming and
not easily scalable as we expand to

216
00:13:53,745 --> 00:13:57,975
more podcasting languages to improve
efficiency, consistency in the future.

217
00:13:58,335 --> 00:14:02,475
We plan to add an automated quality
scoring measures like blue scores,

218
00:14:02,775 --> 00:14:05,715
which compare machine generated
translations to human translations

219
00:14:05,775 --> 00:14:08,265
and native speaker evaluations.

220
00:14:08,775 --> 00:14:12,505
Blue scores provide, a quantitative
measure of translation accuracy, while

221
00:14:12,505 --> 00:14:16,885
native speaker feedback ensures that
translation sounds natural and cultural,

222
00:14:16,945 --> 00:14:19,015
culturally approvable appropriate.

223
00:14:19,515 --> 00:14:22,995
These improvements will speed up the
review process and help maintain high

224
00:14:22,995 --> 00:14:25,305
translation quality as the system scales.

225
00:14:25,805 --> 00:14:30,995
And here I will show some of the key
code snippets that we have, and this

226
00:14:30,995 --> 00:14:35,165
is one of the first parts, which
is downloading podcast episodes.

227
00:14:35,495 --> 00:14:39,015
We have a podcast ID for the
podcast where we want to download.

228
00:14:39,825 --> 00:14:44,445
And here we take this podcast,
download all the episodes for this

229
00:14:44,445 --> 00:14:50,355
podcast, and later we download all
the MP three files for this podcast.

230
00:14:50,855 --> 00:14:55,415
Another part is transcribing audio
with Whisper, which is pretty simple.

231
00:14:56,255 --> 00:15:02,325
And here we have to take the
file, the audio file and send

232
00:15:02,325 --> 00:15:06,585
it to the Open AI client without
any prompts, without anything.

233
00:15:07,365 --> 00:15:10,725
And we have to say that we
want to use Whisper one model.

234
00:15:11,295 --> 00:15:12,525
We have to say that we use this.

235
00:15:13,110 --> 00:15:17,230
Specific audio file and it just
translates, transcribes the

236
00:15:17,230 --> 00:15:19,270
file and returns us the text.

237
00:15:19,770 --> 00:15:23,850
Another one is improved
transcription method, which takes

238
00:15:23,850 --> 00:15:29,820
the transcription and source language
and improves this transcription.

239
00:15:30,060 --> 00:15:35,280
And as you can see in the prompt
here, it improves grammar and

240
00:15:35,280 --> 00:15:39,700
punctuation, translates everything
to source language, which is English.

241
00:15:40,120 --> 00:15:41,230
If it's in the wrong language.

242
00:15:41,260 --> 00:15:45,460
So in the podcast you may have
multiple languages, let's say English

243
00:15:45,460 --> 00:15:48,220
and French, or English and Russian.

244
00:15:48,370 --> 00:15:53,430
And for better understanding, you
have to first translate everything to

245
00:15:53,430 --> 00:15:58,560
English and then everything from English
to Russian, it just works better.

246
00:15:59,060 --> 00:16:03,110
and here is another one,
generating speech with dts One.

247
00:16:04,055 --> 00:16:08,275
here, we take the text
that we want to translate.

248
00:16:08,875 --> 00:16:14,705
We split it in the chunks of not more
than 4,000, characters each, because this

249
00:16:14,705 --> 00:16:18,185
is a restriction of the TTS one model.

250
00:16:18,265 --> 00:16:23,275
you cannot generate speech for more
than 4,000 something characters at once.

251
00:16:23,785 --> 00:16:26,875
So we split in the chunks of smaller text.

252
00:16:27,835 --> 00:16:33,775
Then we create, then we generate
MP three files, and then we merge

253
00:16:33,775 --> 00:16:36,745
them together into single by array.

254
00:16:37,405 --> 00:16:43,075
And this will be our MP three file in
Russian, which we will later use for

255
00:16:43,075 --> 00:16:49,495
distribution Generating errors as feed
is pretty simple here as we use JX XML

256
00:16:49,525 --> 00:16:53,965
library, which is included in Java,
and we don't need any other libraries.

257
00:16:54,805 --> 00:17:03,045
And here we create, the ssas feed
in XML format at, add the podcast

258
00:17:03,045 --> 00:17:07,605
info such as title, description,
link language, everything.

259
00:17:08,105 --> 00:17:10,875
And then we add all the
info for the episodes.

260
00:17:11,295 --> 00:17:16,605
And it includes title, description,
a publication date, enclosure, which

261
00:17:16,605 --> 00:17:19,785
is the path, a link to the file.

262
00:17:20,490 --> 00:17:27,460
And some idea which has to be unique
among all the, episodes in this podcast.

263
00:17:27,960 --> 00:17:28,980
for example, output.

264
00:17:29,490 --> 00:17:33,300
to wrap up, this is the result of a
translation of translation, a part

265
00:17:33,300 --> 00:17:34,950
of an English podcast into Russian.

266
00:17:35,430 --> 00:17:36,720
Notice the American accent.

267
00:17:36,720 --> 00:17:37,740
In the Russian speech.

268
00:17:38,130 --> 00:17:40,950
We're also creating the S field
behind the scenes for distribution.

269
00:17:41,280 --> 00:17:42,535
And now let's hear it.

270
00:17:43,485 --> 00:17:46,590
So we have this, example in English.

271
00:17:47,420 --> 00:17:47,900
Let's hear it.

272
00:17:48,400 --> 00:17:51,610
This is episode two of What's in a Name.

273
00:17:52,270 --> 00:17:56,620
In the previous episode, we learned
how scientists name species and

274
00:17:56,620 --> 00:18:01,300
the controversies that can result
from those names, but names

275
00:18:01,300 --> 00:18:03,430
don't just matter to scientists.

276
00:18:03,670 --> 00:18:05,530
They can impact all of us.

277
00:18:05,800 --> 00:18:09,880
In this episode, we are moving outta
the universities and scientific

278
00:18:09,880 --> 00:18:12,280
publications where names are chosen.

279
00:18:12,655 --> 00:18:18,505
And into the public realm where names
chosen by scientists, meet non-scientists.

280
00:18:19,345 --> 00:18:23,460
This was the English version, and
now was going to Russian version.

281
00:18:23,960 --> 00:18:29,210
Here, you can see, you can hear
that the Russian speech has this

282
00:18:29,210 --> 00:18:34,120
slight American accent, but the,
translation is pretty close.

283
00:18:34,690 --> 00:18:39,970
the text is pretty close, so
Russian speaking audience can just

284
00:18:39,970 --> 00:18:44,370
listen to this, to this text, to
this speech, and understand what's

285
00:18:44,370 --> 00:18:46,560
going on in the original podcast.

286
00:18:47,060 --> 00:18:48,200
Future improvements.

287
00:18:48,570 --> 00:18:50,790
we've come a long way, but
there is still room for growth.

288
00:18:51,675 --> 00:18:53,625
Future updates will make this even better.

289
00:18:54,075 --> 00:18:57,255
As we refine our podcast localization
pipeline, we're looking ahead to

290
00:18:57,255 --> 00:19:01,245
key enhancements that will improve
efficiency in the audio quality.

291
00:19:01,635 --> 00:19:04,395
Our next steps include automating
episodes, pleading for better

292
00:19:04,395 --> 00:19:10,215
segment control, integrating FFMP for
seamless audio merging and developing

293
00:19:10,215 --> 00:19:14,415
custom trained TTS voices to enhance
naturalness and authenticity.

294
00:19:15,105 --> 00:19:18,675
These improvements will help create a
more polished and engaging listening

295
00:19:18,675 --> 00:19:20,355
experience for localized content.

296
00:19:20,855 --> 00:19:24,515
As we wrap up, let's reflect on key
takeaways from this presentation.

297
00:19:25,445 --> 00:19:29,495
First, deploying machine learning
is in real world applications

298
00:19:29,555 --> 00:19:31,055
is an alterna process.

299
00:19:31,325 --> 00:19:34,595
We continuously refine our approach
based on feedback, performance

300
00:19:34,595 --> 00:19:37,115
evaluations, and advancements in ai.

301
00:19:37,505 --> 00:19:38,975
This world doesn't stop deployment.

302
00:19:38,975 --> 00:19:41,220
It evolves to meet new challenges.

303
00:19:42,215 --> 00:19:46,925
Second by Strateg strategically combining
open AI tools, including Whisper for

304
00:19:46,925 --> 00:19:51,875
transcription, GPT-4 oh for translation
and text refinement and tts one for

305
00:19:51,875 --> 00:19:55,625
voice synthesis, we can achieve high
quality localization while preserving

306
00:19:55,925 --> 00:19:58,025
the regional content syn intent and tone.

307
00:19:58,505 --> 00:20:02,165
This AI models work together to streamline
the process and maintain consistency

308
00:20:02,165 --> 00:20:03,815
across different podcast elements.

309
00:20:04,655 --> 00:20:07,085
And finally, there is
still room for improvement.

310
00:20:07,490 --> 00:20:12,150
Future enhancements such as automated
episode splitting, ffm, pet Burst, based

311
00:20:12,150 --> 00:20:16,830
merging and custom voice training for
TTS will refine the process even further.

312
00:20:17,310 --> 00:20:20,040
As we continue developing these
solutions, our goal is to make

313
00:20:20,040 --> 00:20:24,840
localized podcasts feel as natural and
seamless as their original versions.

314
00:20:25,340 --> 00:20:26,600
Thank you all for your attention.

315
00:20:26,750 --> 00:20:29,420
This project is an exciting step,
forward breaking language barriers

316
00:20:29,420 --> 00:20:32,810
and podcasting, and we're looking
forward to what comes next.

317
00:20:33,140 --> 00:20:33,620
Thank you.

