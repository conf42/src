1
00:00:00,500 --> 00:00:00,960
Hi everyone.

2
00:00:01,100 --> 00:00:05,125
I'm Manoja, and today we're exploring
how to build AI platforms that

3
00:00:05,125 --> 00:00:08,875
actually work in prediction systems,
handling millions of realtime

4
00:00:08,875 --> 00:00:11,065
decisions without breaking down.

5
00:00:11,454 --> 00:00:14,305
We'll understand the engineering
practices that separate successful

6
00:00:14,364 --> 00:00:16,915
AI platforms from failed experiments.

7
00:00:17,415 --> 00:00:20,730
We'll cover the complete lifecycle
designing containerized ML

8
00:00:20,730 --> 00:00:24,630
pipelines, implementing efficient
models, serving architectures,

9
00:00:24,780 --> 00:00:26,970
establishing observability frameworks.

10
00:00:27,495 --> 00:00:30,314
Building self-healing, fault
tolerant infrastructure.

11
00:00:30,795 --> 00:00:32,715
These are theoretical concepts.

12
00:00:32,865 --> 00:00:36,684
These are proven practices from
real deployments processing

13
00:00:36,684 --> 00:00:40,165
millions of requests daily with
measurable business impact.

14
00:00:40,665 --> 00:00:44,085
The transition from traditional
software to AI driven platforms

15
00:00:44,085 --> 00:00:46,065
introduces fundamental changes.

16
00:00:46,574 --> 00:00:51,495
AI platforms must handle compute intensive
GPU workloads, massive real-time data

17
00:00:51,495 --> 00:00:53,865
ingestion models, lifecycle management.

18
00:00:54,675 --> 00:00:59,204
Dynamic scaling requirements for
computer vision applications, autonomous

19
00:00:59,204 --> 00:01:01,844
systems, surveillance, quality control.

20
00:01:01,995 --> 00:01:03,764
These challenges are amplified.

21
00:01:04,425 --> 00:01:08,565
Processing visual data at scale
with millisecond response time

22
00:01:08,984 --> 00:01:13,155
requires a resilient engineering
foundation, integrating automation,

23
00:01:13,155 --> 00:01:14,384
scalability, and observability.

24
00:01:14,884 --> 00:01:18,410
Traditional DevOps provides
static point but is insufficient.

25
00:01:19,070 --> 00:01:23,450
Three foundational principles guide
success infrastructure as code.

26
00:01:23,690 --> 00:01:27,740
Using terraform or cloud formation
enables consistent replication of

27
00:01:27,830 --> 00:01:32,270
GPU enabled environments and version
control infrastructure evolution.

28
00:01:32,990 --> 00:01:38,045
GitHub's workflows treat GIT as the
single source of truth with automated

29
00:01:38,524 --> 00:01:42,740
synchronization tools, ensuring
immutable deployments and automated

30
00:01:42,740 --> 00:01:46,210
rollbacks automated testing strategies.

31
00:01:46,810 --> 00:01:51,789
Require specialized frameworks for
data validation, model validation, and

32
00:01:51,789 --> 00:01:56,410
integration tests for end-to-end pipeline
Workflows fundamentally different

33
00:01:56,410 --> 00:01:57,970
from traditional software testing.

34
00:01:58,470 --> 00:02:04,830
Containerization delivers reproducibility
and modularity through modular pipelines

35
00:02:04,890 --> 00:02:09,990
with separate containers for ingestion,
pre-processing, training, and inference.

36
00:02:10,560 --> 00:02:12,600
GPU enable enablement.

37
00:02:12,975 --> 00:02:18,345
Leverages Nvidia Docker runtime
and Kubernetes device plugins while

38
00:02:18,525 --> 00:02:22,635
version bills ensure deterministic
bills tied to GI comets.

39
00:02:23,135 --> 00:02:27,935
Kubernetes orchestration handles
spot scheduling with GPU constraints,

40
00:02:28,415 --> 00:02:33,395
horizontal autoscaling for inference,
workloads, and node pools optimized

41
00:02:33,395 --> 00:02:34,985
for different pipeline stages.

42
00:02:35,485 --> 00:02:37,165
Here's how this works in practice.

43
00:02:37,285 --> 00:02:39,265
Data ingestion bots.

44
00:02:39,765 --> 00:02:41,955
Pull video streams from IOT sensors.

45
00:02:41,955 --> 00:02:45,735
Pre-processing pods apply
transformations like normalization

46
00:02:45,885 --> 00:02:48,135
and augmentation model training pods.

47
00:02:48,195 --> 00:02:51,405
Leverage distributed
GPUs and inference pods.

48
00:02:51,615 --> 00:02:55,635
Serve predictions via
REST or GRPC endpoints.

49
00:02:56,135 --> 00:03:01,605
This enterprise scale vision system
creates an end-to-end pipeline efficiently

50
00:03:01,640 --> 00:03:05,750
processing visual data while maintaining
high availability and performance.

51
00:03:06,250 --> 00:03:11,380
Serving models at a low latency
while ensuring reliability requires

52
00:03:11,440 --> 00:03:13,270
specific deployment patterns.

53
00:03:14,110 --> 00:03:17,770
Bluegreen deployments run new
model versions parallel with old

54
00:03:17,770 --> 00:03:20,110
ones switching traffic seamlessly.

55
00:03:20,740 --> 00:03:23,685
Canary releases gradually
rollout model to user subsets.

56
00:03:24,185 --> 00:03:27,575
Shadow deployments test model in
product production environments

57
00:03:27,815 --> 00:03:29,975
without exposing outputs to users.

58
00:03:30,635 --> 00:03:35,945
Each pattern addresses different risk
tolerance and validation requirements

59
00:03:36,334 --> 00:03:38,765
for production model updates.

60
00:03:39,265 --> 00:03:43,845
Three Key optimizations delivered dramatic
performance improvements, batching

61
00:03:43,845 --> 00:03:48,165
and fairness Request groups multiple
requests to maximize GPU utilization

62
00:03:48,345 --> 00:03:49,760
and reduce per request overhead.

63
00:03:50,325 --> 00:03:56,999
Model caching and W starts keep frequency
access models in memory, eliminating

64
00:03:56,999 --> 00:04:02,100
cold start latency, accelerated serving
frameworks like Tenser rt, Triton

65
00:04:02,160 --> 00:04:08,100
inference server, and tot serve optimized
model execution on specified hardware.

66
00:04:08,600 --> 00:04:13,249
These optimizations typically provide
three to five x throughput improvements

67
00:04:13,399 --> 00:04:17,240
while reducing latency from 200
milliseconds to 15 milliseconds.

68
00:04:17,740 --> 00:04:21,520
Observability transcends infrastructure
monitoring by incorporating model and

69
00:04:21,520 --> 00:04:24,630
data centric metrics across three layers.

70
00:04:25,440 --> 00:04:29,100
Infrastructure metrics tracks,
C-P-U-G-P-U, utilization,

71
00:04:29,280 --> 00:04:30,840
memory and network throughput.

72
00:04:31,170 --> 00:04:35,250
Pipeline monitoring covers success
rates, Q latencies and data integrity

73
00:04:35,250 --> 00:04:39,500
checks, model observability,
monitors, prediction, drift latency,

74
00:04:39,560 --> 00:04:42,500
error rates, and famous metrics.

75
00:04:43,000 --> 00:04:48,120
This comprehensive approach
enables detection anomalies before

76
00:04:48,120 --> 00:04:53,500
they impact users such as GPU
saturation, rising inference,

77
00:04:53,500 --> 00:04:56,170
latency, or degraded model accuracy.

78
00:04:56,670 --> 00:04:59,905
The tooling ecosystem combines
traditional and ML specific monitoring.

79
00:05:00,435 --> 00:05:03,990
Prometheus plus Grafana provide
comprehensive infrastructure

80
00:05:03,990 --> 00:05:06,630
dashboards, tracking resources, usage.

81
00:05:07,170 --> 00:05:12,510
And System Health Open Telemetry
enables distributed tracing

82
00:05:12,630 --> 00:05:17,910
across ML pipelines, identifying
bottlenecks and latency issues.

83
00:05:18,410 --> 00:05:24,770
Custom ML monitoring tools like YAPS
eyes, AI handle data drift and bias

84
00:05:24,770 --> 00:05:30,410
detection coupling observability with
alert thresholds, enable systems to detect

85
00:05:30,470 --> 00:05:33,290
and respond to anomalies automatically.

86
00:05:33,790 --> 00:05:37,690
Resilient platforms must recover
automatically without manual intervention.

87
00:05:38,500 --> 00:05:40,120
Through several mechanisms.

88
00:05:40,620 --> 00:05:46,740
Kubernetes liveness readiness probes
automatically restart failing containers.

89
00:05:46,740 --> 00:05:51,360
When health check fails cluster
auto-scaling dynamically adjust compute

90
00:05:51,360 --> 00:05:53,665
resources based on workload demands.

91
00:05:54,525 --> 00:05:59,445
Chaos Engineering uses using tools
like chaos mesh injects failures

92
00:05:59,505 --> 00:06:03,495
to violate system resilience
under unexpected conditions.

93
00:06:03,995 --> 00:06:08,225
These mechanisms ensure continuous
service availability and

94
00:06:08,435 --> 00:06:10,085
optimal resource utilization.

95
00:06:10,585 --> 00:06:14,200
Eliminate single point of failure
requires comprehensive distribution.

96
00:06:14,700 --> 00:06:18,510
Distributed processing pipelines
ensure no single point of failure

97
00:06:18,510 --> 00:06:22,590
by distributing workloads across
multiple nodes and regions.

98
00:06:23,400 --> 00:06:27,330
Geo-redundant clusters support
global AI workloads with

99
00:06:27,330 --> 00:06:31,440
multi-region deployments for disaster
recovery and low latency serving.

100
00:06:31,940 --> 00:06:37,280
Event driven recovery provides automated
rerouting of workloads on node failure

101
00:06:37,970 --> 00:06:40,460
through event based orchestration systems.

102
00:06:40,960 --> 00:06:44,590
Organization, imple implementing
these principles report

103
00:06:44,590 --> 00:06:47,680
significant improvement, 99.9%.

104
00:06:47,680 --> 00:06:49,600
Uptime and reliability.

105
00:06:49,990 --> 00:06:50,380
SLA.

106
00:06:50,380 --> 00:06:55,420
Compliance in production AI systems means
less than nine hours downtime per year.

107
00:06:56,140 --> 00:07:02,560
Deployment velocity measured in ours,
model updates deployed within hours

108
00:07:02,560 --> 00:07:04,480
versus weeks in traditional workflows.

109
00:07:04,980 --> 00:07:09,930
20 to 40% cost reduction through optimized
GPU scheduling and resource allocation.

110
00:07:10,430 --> 00:07:13,910
Increased developer productivity
teams focus on in innovation

111
00:07:13,970 --> 00:07:15,620
instead of firefighting operations.

112
00:07:16,310 --> 00:07:21,020
These are, these metrics demonstrate
clear business value, justifying

113
00:07:21,110 --> 00:07:26,145
implementation complexity, the conversions
of platform engineering and ML ops.

114
00:07:26,875 --> 00:07:32,065
Represents a paradigm shift enabling
faster time to market through accelerated

115
00:07:32,065 --> 00:07:36,865
delivery of AI products via streamlined
deployment, pipelines and automated

116
00:07:36,865 --> 00:07:43,795
workflows, reduced operational overhead
with lower maintenance costs, through

117
00:07:43,945 --> 00:07:49,425
comprehensive automation of routine tasks
and self feeling systems sustained trust

118
00:07:49,425 --> 00:07:51,165
with enhanced confidence in AI systems.

119
00:07:52,005 --> 00:07:55,755
By ensuring transparency, fairness,
and consistent performance.

120
00:07:56,385 --> 00:08:01,845
These practices extend beyond computer
vision to NLP recommendation systems

121
00:08:02,235 --> 00:08:07,005
and generative ai, where real time
processing is equally critical.

122
00:08:07,505 --> 00:08:10,505
Building resilient AI platforms
at scale is fundamentally about

123
00:08:10,505 --> 00:08:15,605
engineering trust into AI systems
through containerized ML pipelines

124
00:08:15,815 --> 00:08:18,065
efficient model serving architecture.

125
00:08:18,680 --> 00:08:23,420
Comprehensive observability and
self-healing infrastructure organizations

126
00:08:23,420 --> 00:08:28,050
deploy computer vision systems that
are both high, perform high performing,

127
00:08:28,170 --> 00:08:32,400
and relatable by applying modern
platform engineering principles,

128
00:08:32,460 --> 00:08:34,890
infrastructure as code GitHubs.

129
00:08:34,980 --> 00:08:39,690
Automated testing and fault
tolerant design enterprises achieve

130
00:08:39,840 --> 00:08:43,650
operational resilience while
unlocking faster innovation cycles

131
00:08:43,920 --> 00:08:46,350
and enhanced developer productivity.

132
00:08:46,850 --> 00:08:52,675
As such, your current AI de deployment
practices prioritize containerization and

133
00:08:52,675 --> 00:08:56,545
monitoring as foundational capabilities
and implement automation testing

134
00:08:56,545 --> 00:08:58,345
for both infrastructure and models.

135
00:08:58,675 --> 00:09:03,325
As realtime AI continues transforming
industries, the ability of ability to

136
00:09:03,325 --> 00:09:06,525
engineer resilience, scalable platforms
will define the next generation

137
00:09:06,525 --> 00:09:08,450
of enterprise success stories.

138
00:09:09,230 --> 00:09:09,740
Thank you.

