1
00:00:00,000 --> 00:00:02,730
Hello and welcome to
Comfort to Machine Learning.

2
00:00:02,760 --> 00:00:07,170
I'm Mi Flo and I'm excited to have
you here with me at my session today.

3
00:00:07,350 --> 00:00:11,430
I have a very special story
from AWS Community Dark 2024.

4
00:00:11,640 --> 00:00:15,149
It's elevating human
photography workflows with AWS.

5
00:00:15,479 --> 00:00:17,160
So I'm not holding you, let's.

6
00:00:17,195 --> 00:00:21,305
Go directly to the session, but
before we begin, Sierra's from Vienna,

7
00:00:21,575 --> 00:00:25,230
and I would like to mention that
this is not just a technical story.

8
00:00:25,230 --> 00:00:29,430
This is a story about our AWS
community, about the technical

9
00:00:29,430 --> 00:00:33,900
knowledge, how technical creativity
brings something interesting that.

10
00:00:34,050 --> 00:00:37,320
To let us resolve some magnificent things.

11
00:00:37,500 --> 00:00:41,370
And here I would like to quote that
technology alone is not enough.

12
00:00:41,550 --> 00:00:42,330
It's technology.

13
00:00:42,330 --> 00:00:46,680
Married with the liberal arts, married
with the humanities that yields

14
00:00:46,680 --> 00:00:48,880
the results that make our hering.

15
00:00:49,390 --> 00:00:52,150
And this is actually the story that fully.

16
00:00:52,870 --> 00:00:55,550
Complies with this quote and yeah.

17
00:00:55,600 --> 00:00:57,730
And a quick introduction of myself.

18
00:00:57,760 --> 00:00:58,960
I am Ra Kanka.

19
00:00:58,960 --> 00:01:01,030
I am cloud architect at app.

20
00:01:01,450 --> 00:01:03,160
I am AWS community builder.

21
00:01:03,220 --> 00:01:07,850
I am AWS user group leader at Vien
and Leans, and I am together with

22
00:01:07,850 --> 00:01:11,030
my colleagues via, are working
on AWS community in Vienna.

23
00:01:11,240 --> 00:01:12,530
I'm a big it geek.

24
00:01:12,590 --> 00:01:12,800
I love.

25
00:01:13,125 --> 00:01:18,405
Everything which is related to te and
I'm holding master since communications

26
00:01:18,405 --> 00:01:20,405
Bachelor's in business management.

27
00:01:20,405 --> 00:01:24,725
And I'm working with AWS who focus
on AWS for the last five years.

28
00:01:24,905 --> 00:01:26,495
And I'm a big photography fan.

29
00:01:26,705 --> 00:01:31,445
And actually those things that we have
here that I'm IT gig, that I'm working

30
00:01:31,445 --> 00:01:36,485
with a and that I'm a photography fan and
hobbyist, so they're all collided here.

31
00:01:36,485 --> 00:01:41,905
This is why I have this story for you and,
so in this session, we will talk about

32
00:01:41,905 --> 00:01:45,985
the challenge that, first of all, we will
take my, as I mentioned, passion for the

33
00:01:45,985 --> 00:01:50,815
photography and that I wanted to make lots
of magnificent pictures for our community.

34
00:01:50,815 --> 00:01:55,435
That we do a big job preparing
a community dark with our team.

35
00:01:55,435 --> 00:02:00,025
And I wanted to make it memorable for us,
for our speakers, for us, for sponsors

36
00:02:00,025 --> 00:02:01,855
that, for example, we could back.

37
00:02:01,870 --> 00:02:05,779
After some years and say that
yeah, so it was the thing

38
00:02:05,779 --> 00:02:07,219
and we have done it together.

39
00:02:07,499 --> 00:02:08,379
And yeah.

40
00:02:08,439 --> 00:02:15,399
Then this is why it's actually related to
the technical event that how a LS let me

41
00:02:15,399 --> 00:02:20,444
achieve much more efficient workflow for
the photo processing that let us deliver.

42
00:02:21,009 --> 00:02:24,639
The photos to our marketing team, to
the speakers, to everyone involved,

43
00:02:24,819 --> 00:02:29,289
and to reduce the management and
all the processing overhead that

44
00:02:29,289 --> 00:02:31,359
comes after the photo shoot.

45
00:02:31,389 --> 00:02:35,049
And let's also talk about the
technical perspective and what

46
00:02:35,049 --> 00:02:36,849
kind of results does it bring.

47
00:02:37,209 --> 00:02:41,109
But before we go to the technical
details, so some words about myself, I,

48
00:02:41,159 --> 00:02:42,929
raised surrounded with the photography.

49
00:02:43,139 --> 00:02:44,879
I'm a big fan of the technical side.

50
00:02:44,879 --> 00:02:46,439
I really like to research.

51
00:02:46,779 --> 00:02:50,719
So all the technical things
like sensor manufacturing image

52
00:02:50,719 --> 00:02:52,399
data processing, so everything.

53
00:02:52,399 --> 00:02:54,739
And I also dealt with another photography.

54
00:02:55,019 --> 00:02:59,419
And it's a big passion because it
combines creativity, technical expertise.

55
00:02:59,419 --> 00:03:02,804
And it's also one field
where I can express myself.

56
00:03:02,804 --> 00:03:08,444
So I have done photo shooting of different
events such as Formula one TM, factory

57
00:03:08,444 --> 00:03:13,554
team and I also was photographing
different AWS related events, secluding

58
00:03:13,554 --> 00:03:15,774
our community days, our user groups.

59
00:03:15,774 --> 00:03:20,094
So I was photographing AWS Stars such
as Victoria, Ziman, Anton, Bianca.

60
00:03:20,094 --> 00:03:22,914
So lots of other exciting
people in our community.

61
00:03:23,184 --> 00:03:27,174
And of course I also part of different
exhibitions for the festivals.

62
00:03:27,274 --> 00:03:28,054
And I have.

63
00:03:28,114 --> 00:03:31,714
Photographed Playboy models I
have was winning competitions.

64
00:03:31,954 --> 00:03:35,854
So it's a pretty long way that I'm doing,
besides my main professional activity

65
00:03:35,854 --> 00:03:40,714
related to AWS and bringing this, all
this experience to a s community doc.

66
00:03:41,234 --> 00:03:47,684
So I used to take over 8,000 pictures,
30 speakers, about 650 attendees,

67
00:03:47,924 --> 00:03:52,784
and the main challenge here, so what
should I do with this amount of things.

68
00:03:53,559 --> 00:03:57,429
And normally, so even we are talking about
the photo processing, it's a huge process

69
00:03:57,429 --> 00:04:02,139
because it starts from the planning of
the photo shoot you are shooting, you can

70
00:04:02,679 --> 00:04:06,759
I make some adjustment of the amount of
work you can do if you shoot properly.

71
00:04:06,999 --> 00:04:11,859
And since I'm a technician, for me it was
the question, how can I make it more easy?

72
00:04:11,889 --> 00:04:12,279
Easy.

73
00:04:12,609 --> 00:04:16,239
And I, first of all, I started to
research what do we have on market

74
00:04:16,239 --> 00:04:17,409
from the commercial solution.

75
00:04:17,439 --> 00:04:21,009
And since the story was about the
summer of the last year, I was.

76
00:04:21,109 --> 00:04:25,129
Surprised that there are not many
AI solutions powered, AI powered

77
00:04:25,129 --> 00:04:30,469
solutions, and none of them, they was
capable to do what I wanted to do.

78
00:04:30,529 --> 00:04:32,659
And since we are builders,
we love to build.

79
00:04:32,899 --> 00:04:38,749
So that's why I was thinking, okay,
let's maybe try to do it on AWS and.

80
00:04:39,709 --> 00:04:44,749
So the whole process and together with
our marketing team, thank you to Susanna.

81
00:04:44,869 --> 00:04:45,109
Hans.

82
00:04:45,379 --> 00:04:46,549
Linda, you are amazing.

83
00:04:46,759 --> 00:04:50,634
So we planned what, where,
and how and when we would like

84
00:04:50,634 --> 00:04:55,834
to have, so then my task as a
photographer was to to be in time.

85
00:04:56,524 --> 00:05:00,274
And to put the thing, so to capture
it, that we could have an image.

86
00:05:00,274 --> 00:05:04,744
So for example, me with the guys,
we have done all the pre-planning

87
00:05:05,144 --> 00:05:09,464
together with a LinkedIn post,
with the text, with all the needed

88
00:05:09,464 --> 00:05:11,864
surrounding materials such as photos.

89
00:05:12,134 --> 00:05:13,394
So where and how.

90
00:05:13,479 --> 00:05:18,959
And we were thinking so how to
use it properly to maximize the

91
00:05:19,139 --> 00:05:21,179
coverage for our media presence.

92
00:05:21,359 --> 00:05:25,819
Then of course, it, my part came because
I was actually performing a shooting.

93
00:05:25,879 --> 00:05:30,139
I was using two Sony Alpha cameras
because amount is the best system on the

94
00:05:30,139 --> 00:05:32,359
market and no one can keep up with it.

95
00:05:32,439 --> 00:05:34,709
And those cameras, they
extremely reliable.

96
00:05:34,709 --> 00:05:40,119
I will, the main camera was Sony
Alpha nine Mark three with a 7,200

97
00:05:40,119 --> 00:05:44,649
G master lens, and the second camera
was Alpha seven four with a 24 70.

98
00:05:45,189 --> 00:05:48,999
And, I was shooting with the two
cameras simultaneously to, to have

99
00:05:48,999 --> 00:05:53,299
different perspectives, but also my task
was to use the technical advantages.

100
00:05:53,299 --> 00:05:55,159
For example, like iPhone nine.

101
00:05:55,399 --> 00:05:57,919
It's because of its global sensory doubt.

102
00:05:57,919 --> 00:06:01,829
We were, I was not afraid of the
light flicker or some other things.

103
00:06:02,129 --> 00:06:06,309
And I was able to use both cameras
in pretty aggressive setup.

104
00:06:06,309 --> 00:06:09,039
For example, taking ER images, which is.

105
00:06:09,179 --> 00:06:12,964
Absolutely possible with the
current Sony sensors and, yeah.

106
00:06:12,964 --> 00:06:15,874
And also they have extremely
variable of the focus and they

107
00:06:15,874 --> 00:06:17,494
actually saved lot of work.

108
00:06:17,524 --> 00:06:21,774
But still all this actually all this
gap that gets introduced by the faulty

109
00:06:21,774 --> 00:06:26,634
auto focus, especially on the DSLRs that
are not capable to do face tracking.

110
00:06:26,994 --> 00:06:29,184
So it causes more and more in work.

111
00:06:29,214 --> 00:06:32,994
And then we are going to the point
when AWS is capable to step in.

112
00:06:33,204 --> 00:06:35,794
So in this project I was trying to re.

113
00:06:36,089 --> 00:06:41,109
So to reproduce the process that I'm
doing myself, so how I'm sourcing the

114
00:06:41,109 --> 00:06:43,179
pictures, all this cognitive process.

115
00:06:43,399 --> 00:06:48,499
So how basically the mission was
intended to do what I would to do

116
00:06:48,709 --> 00:06:54,019
and to my target was to use technical
opportunities by AWS to represent

117
00:06:54,019 --> 00:06:56,219
my way of thinking and all the.

118
00:06:56,459 --> 00:06:57,689
Photography process.

119
00:06:57,779 --> 00:07:01,409
And of course also to automate
the processing to perform

120
00:07:01,409 --> 00:07:02,639
the automatic corrections.

121
00:07:02,729 --> 00:07:05,519
And here we have a full
conjunction of different a s

122
00:07:05,519 --> 00:07:07,139
services to perform this task.

123
00:07:07,439 --> 00:07:08,369
And yeah.

124
00:07:08,729 --> 00:07:13,109
But before I go directly to the technical
solutions, so in all my previous session,

125
00:07:13,109 --> 00:07:19,349
if you have ever attended mine inclusive
at, so I'm always thinking that when we

126
00:07:19,349 --> 00:07:22,899
are building some something on the Italy.

127
00:07:23,194 --> 00:07:27,544
We treat the data and architecture
that interchangeable between

128
00:07:28,054 --> 00:07:30,454
humans, machines, and software.

129
00:07:30,574 --> 00:07:35,794
So all of those are, must be
orchestrated together and, and when

130
00:07:35,794 --> 00:07:40,474
I'm starting any kind of project
on AWS my goal is to achieve unity

131
00:07:40,474 --> 00:07:42,274
between technology and human needs.

132
00:07:42,634 --> 00:07:46,794
And here AWS acts as a connector
between technical systems, all the

133
00:07:46,794 --> 00:07:51,234
software and human requirements, and
using its services we can build it.

134
00:07:51,769 --> 00:07:55,459
And talking about the building
when I'm, I see some process, some

135
00:07:55,459 --> 00:07:58,069
applications, something that runs on AWS.

136
00:07:58,489 --> 00:08:02,869
I always try to imagine it in a sort
of the waterfall, and this is why we

137
00:08:02,869 --> 00:08:09,199
actually have a waterfall image and the
current set of AWS services, it deeply

138
00:08:09,199 --> 00:08:14,119
reminds me as Swiss Army knife because
you have lots of the services, but if you

139
00:08:14,119 --> 00:08:19,789
master serverless, Lambdas Dyna db, if
you know how to do the step functions.

140
00:08:19,809 --> 00:08:23,529
So if you do it in proper way with
the CICD cloud formation, it's

141
00:08:23,529 --> 00:08:25,509
already your key to the success.

142
00:08:25,659 --> 00:08:30,699
And of course with the junctions, like
for, I don't know, SQA, if you use SQS, if

143
00:08:30,699 --> 00:08:33,819
you use I dunno, Kafka, whatever you like.

144
00:08:33,819 --> 00:08:38,439
So you can build resilience, scalable
systems that just they data is

145
00:08:38,439 --> 00:08:40,689
like a bottle of fall is incoming.

146
00:08:40,779 --> 00:08:45,519
All this flow of the data gets protest and
you deliver your technical vision for your

147
00:08:45,519 --> 00:08:47,739
businesses, for your pet project because.

148
00:08:48,479 --> 00:08:49,679
This project, it's what?

149
00:08:49,709 --> 00:08:53,149
It was not coming out
from the just abnormal.

150
00:08:53,449 --> 00:08:54,559
I was thinking a lot.

151
00:08:54,919 --> 00:08:57,289
So for example, how to
conjunction different things.

152
00:08:57,289 --> 00:09:02,389
How can some step of my normal cognitive
process that I'm doing myself when I'm

153
00:09:02,389 --> 00:09:08,249
processing pictures, what function,
which service can be in back, end of it?

154
00:09:08,529 --> 00:09:09,489
And yeah.

155
00:09:10,099 --> 00:09:13,279
And all this vision, it always
comes to the orchestrated a

156
00:09:13,489 --> 00:09:15,049
s services working together.

157
00:09:15,379 --> 00:09:18,869
And our target is as an engineer
to interconnect them in the way

158
00:09:18,869 --> 00:09:20,459
to make a comprehensive solution.

159
00:09:20,859 --> 00:09:24,449
And basically, yeah, as I mentioned,
it's, it didn't come up from the

160
00:09:24,449 --> 00:09:29,669
empty place before I even had spoken
about it at Con City last year.

161
00:09:29,859 --> 00:09:34,599
So I was doing numerous variations of
system integrations of data processing,

162
00:09:34,599 --> 00:09:39,159
data collection from a, from our third
party services that we have in app attack.

163
00:09:39,410 --> 00:09:40,949
And that how we can.

164
00:09:41,505 --> 00:09:45,975
Transform all this data to make
it a even driven that we could

165
00:09:46,035 --> 00:09:50,625
interconnect transparently for our
teams, for users, for the people

166
00:09:50,805 --> 00:09:53,060
who are not like AWS proficient.

167
00:09:54,100 --> 00:09:58,449
Just to normally use the system to get
the data they need to make a daily job

168
00:09:58,449 --> 00:10:00,850
they need, and looking to this experience.

169
00:10:00,850 --> 00:10:05,170
For example, how I was integrating our
CICD processes, security processes,

170
00:10:05,530 --> 00:10:09,940
configuration item management, inventory
management, et cetera, image building.

171
00:10:10,180 --> 00:10:13,750
So it already gave me
the backbone that was.

172
00:10:13,920 --> 00:10:17,190
Lay down the foundation of
this photography project.

173
00:10:17,410 --> 00:10:23,170
And actually idea of it came just
from a talk with my colleague

174
00:10:23,170 --> 00:10:27,640
because he was working with AWS
recognition for some proof of concept.

175
00:10:28,000 --> 00:10:32,370
And we were targeting to train them
to recognize Austrian celebrities.

176
00:10:32,580 --> 00:10:37,230
I'm not aware myself of, unfortunately,
that's why it's even tricky for a os

177
00:10:37,230 --> 00:10:39,240
recognition, but it was a use case.

178
00:10:39,245 --> 00:10:42,745
And I was thinking, but then I
actually forgot about the fit because

179
00:10:42,745 --> 00:10:44,575
we were doing lots of reparations.

180
00:10:44,665 --> 00:10:48,375
It's not only about the photos
because I was also helping with

181
00:10:48,375 --> 00:10:50,625
the sponsorship of community data.

182
00:10:50,625 --> 00:10:51,945
I was helping with everyone.

183
00:10:52,275 --> 00:10:56,585
And at some point I just started think,
okay, let's translate my A risks.

184
00:10:56,595 --> 00:11:01,965
Experience to save up lots of time
for myself, for my family, for even

185
00:11:01,965 --> 00:11:06,625
for the beers and the result of
translating my photography workflow.

186
00:11:07,290 --> 00:11:13,350
Including the experience that I have had
with AWS services before is this, and I

187
00:11:13,350 --> 00:11:15,420
would call it community Photo Factory.

188
00:11:15,690 --> 00:11:21,070
So the most important was to
first of all to get the pictures.

189
00:11:21,070 --> 00:11:21,340
Yeah.

190
00:11:21,370 --> 00:11:23,950
That's why I delegated it
to myself with Sony cameras.

191
00:11:24,130 --> 00:11:28,430
I really love them, as I mentioned
and we gather quality files

192
00:11:28,430 --> 00:11:30,380
that with which we can work.

193
00:11:30,650 --> 00:11:34,010
Then the next target was to
put them somehow to a OS.

194
00:11:34,595 --> 00:11:37,645
And of course we are working
with S3 bucket events.

195
00:11:37,645 --> 00:11:40,085
We are working with a event breach.

196
00:11:40,115 --> 00:11:43,355
So we are having the events
that to preserve because we have

197
00:11:43,355 --> 00:11:44,765
to have everything processed.

198
00:11:44,975 --> 00:11:48,815
I put them in this Q Qs, of course,
with the debt ladder, qe, and

199
00:11:48,815 --> 00:11:52,415
here then we are stepping in with
the two different step functions.

200
00:11:52,625 --> 00:11:56,825
So the actual, the processing step
function that does the whole process.

201
00:11:57,215 --> 00:12:02,305
And, of the processing of the incoming
files because it takes out the

202
00:12:02,305 --> 00:12:04,555
metadata that we have into the file.

203
00:12:04,765 --> 00:12:08,815
We are performing the pre-processing
based on our weights that are

204
00:12:08,815 --> 00:12:11,725
used to calibrate AWS recognition.

205
00:12:11,725 --> 00:12:15,655
In this case, we have a custom written
liberal lambda, which is actually

206
00:12:15,655 --> 00:12:20,545
make us possible to work with the
Air W files that are incoming from

207
00:12:20,545 --> 00:12:22,675
Sony Alpha cameras and to actually.

208
00:12:22,945 --> 00:12:27,465
Lets us to extract the data and I
develop them into different things.

209
00:12:27,685 --> 00:12:31,215
And we store metadata in
the various dynamics tables.

210
00:12:31,215 --> 00:12:35,985
We process the pictures, we sort them
based on the timestamps information.

211
00:12:35,985 --> 00:12:39,615
We recognize the speaker
or kind of medium.

212
00:12:40,245 --> 00:12:42,345
The photo was taken and we sorted.

213
00:12:42,735 --> 00:12:46,305
And also using the metadata
recognized by Libro.

214
00:12:46,640 --> 00:12:50,990
We feed through the bedrock cloud
haiku, then we compare it with

215
00:12:50,990 --> 00:12:53,330
the comparable photo samples.

216
00:12:53,330 --> 00:12:57,050
Then we the select the editing
strategy, and then it gets

217
00:12:57,050 --> 00:12:58,820
put into the following bucket.

218
00:12:59,120 --> 00:13:04,760
So this is the scheme that does
the, all the steps of the process.

219
00:13:04,790 --> 00:13:09,440
Starting from the click of the button,
it gets uploaded to AWS, we do the pro.

220
00:13:09,475 --> 00:13:12,475
Pre-processing of the image,
we recognize what is happening.

221
00:13:12,505 --> 00:13:17,770
We detect faces, we get out metadata, we
compare with our already known weights.

222
00:13:17,920 --> 00:13:21,390
We process it and we have a picture
that for example colleagues of

223
00:13:21,390 --> 00:13:23,040
mind, they could just come and take.

224
00:13:23,040 --> 00:13:27,085
And then we can simply share
those folder with our speaker.

225
00:13:27,325 --> 00:13:29,215
And you can also notice.

226
00:13:29,215 --> 00:13:34,695
The second step step function, metadata,
and yeah, one of the evenings I was

227
00:13:34,725 --> 00:13:36,585
wondering how can I approach it?

228
00:13:36,825 --> 00:13:40,695
And thankfully I have already enough
archives, so I have lots of photos from

229
00:13:40,695 --> 00:13:45,015
the past community days, from our OS
community stage, from our user groups.

230
00:13:45,105 --> 00:13:51,645
And I took pictures of some of the
speakers, of course, of Linda and some and

231
00:13:51,715 --> 00:13:53,785
whatever, just to perform some testings.

232
00:13:54,115 --> 00:13:58,885
And interesting fact, Claude
is afraid of the glasses.

233
00:13:59,125 --> 00:14:03,085
And for example, when you are
taking, selecting the pictures I

234
00:14:03,085 --> 00:14:06,415
think it's very important to have
the person with the open eyes on it.

235
00:14:06,745 --> 00:14:08,755
And this is the core thing.

236
00:14:08,875 --> 00:14:14,170
The clot at the time, 3.5 it was failing
because I took some pictures of Linda.

237
00:14:14,210 --> 00:14:18,080
Both with open and closed
eyes, I gave them to the court

238
00:14:18,230 --> 00:14:19,790
the prompt that I would like.

239
00:14:19,970 --> 00:14:22,880
So you are working for the
professional press agency and you

240
00:14:22,880 --> 00:14:26,390
are picking the picture if it's
suitable for the publication.

241
00:14:26,980 --> 00:14:31,860
And yeah, Claude was recognizing any
kind of I state at Linda, so basically

242
00:14:31,860 --> 00:14:35,310
opened and I also went and they
collected other people in the glasses.

243
00:14:35,310 --> 00:14:39,420
So Claude was failing and it was very
sad because I thought to make it in

244
00:14:39,420 --> 00:14:43,890
some modern way that we are delegating
it to the AI model, but unfortunately.

245
00:14:44,565 --> 00:14:45,345
It failed here.

246
00:14:45,915 --> 00:14:49,335
And then I actually remember it
to, to the story with my colleague

247
00:14:49,335 --> 00:14:50,565
that I have already mentioned.

248
00:14:50,565 --> 00:14:55,245
And then I decided, okay, let's try
AWS recognition and AWS recognition.

249
00:14:55,525 --> 00:14:59,455
And it actually gave me
basically just like this, I

250
00:14:59,455 --> 00:15:00,356
don't know what to give to you.

251
00:15:00,685 --> 00:15:05,785
I have this year so that all the
data that actually I would need,

252
00:15:05,815 --> 00:15:08,005
all the metrics, all the weights.

253
00:15:08,040 --> 00:15:09,450
That I could process that.

254
00:15:09,450 --> 00:15:13,070
For example, as far as you can
see, we can have sharpness metrics.

255
00:15:13,070 --> 00:15:14,840
We can have exposure metrics.

256
00:15:14,840 --> 00:15:18,750
So we can have the different facial
parameters as you can see from the slide.

257
00:15:18,970 --> 00:15:23,915
And here I. What I have done, I have
aggregated the data based on our previous

258
00:15:23,915 --> 00:15:28,865
data sets for the photos I picked and
I didn't pick, and it allowed me to set

259
00:15:28,865 --> 00:15:31,145
up the thresholds and such a thresholds.

260
00:15:31,145 --> 00:15:35,555
I collected them in Dynamic DB and
they were referenced for the Lambda

261
00:15:35,825 --> 00:15:37,415
in the main processing workflow.

262
00:15:37,415 --> 00:15:38,375
That was the sizing.

263
00:15:38,375 --> 00:15:40,385
If we are taking picture or we are not.

264
00:15:40,805 --> 00:15:44,675
Okay, so we have first
piece of our puzzle.

265
00:15:44,735 --> 00:15:46,565
The second one, thankfully.

266
00:15:46,860 --> 00:15:51,700
I can win an award to linking the systems
which are not intended to be linked.

267
00:15:51,760 --> 00:15:52,800
And I don't know.

268
00:15:52,800 --> 00:15:57,360
I think some of those crazy Japanese
engineers in Sony, they didn't expect

269
00:15:57,360 --> 00:16:03,240
that someone would try to throw the
files through the ft PS services in.

270
00:16:03,475 --> 00:16:06,445
Directly to a OS because
this is a normal approach.

271
00:16:06,485 --> 00:16:11,165
Since in APA we have a lot of photography
colleagues who are coming, they are taking

272
00:16:11,165 --> 00:16:15,845
pictures of sport events, different other
live events, and normally, especially

273
00:16:15,845 --> 00:16:19,985
at sports, pictures are getting
uploaded to FCP host and I thought,

274
00:16:19,985 --> 00:16:21,575
okay, let's try to use this function.

275
00:16:22,205 --> 00:16:26,255
And AWS is offering transfer
gateways that are actually, have

276
00:16:26,255 --> 00:16:28,715
done the jobs absolutely perfectly.

277
00:16:29,035 --> 00:16:34,015
But thankfully I'm community builder
and for it compensated my mistake.

278
00:16:34,225 --> 00:16:38,665
And you have to be extremely careful
keeping the transfer family up and

279
00:16:38,665 --> 00:16:43,625
running, because in my case, it took
over $220 just because I thought.

280
00:16:43,920 --> 00:16:47,700
So it has bit more serverless
approach for the pricing, so

281
00:16:47,700 --> 00:16:49,170
please be extremely careful.

282
00:16:49,320 --> 00:16:53,730
But yes, it's possible to give the
transfer gateway, endpoint the sensing

283
00:16:53,730 --> 00:16:57,930
of Sonic cameras and directly stream
your pictures to the S3 bucket.

284
00:16:58,050 --> 00:17:01,980
And when you have already the data on
S3 bucket, then we are in business.

285
00:17:02,190 --> 00:17:02,670
We can.

286
00:17:02,950 --> 00:17:03,640
Go through that.

287
00:17:03,920 --> 00:17:08,150
As I already mentioned, I was
collecting the metrics and let's

288
00:17:08,150 --> 00:17:09,710
first of all start with the things.

289
00:17:09,710 --> 00:17:13,160
So for example, how I
would like to work with it.

290
00:17:13,410 --> 00:17:17,080
Training phase, it involved calibration
with the existing data sets.

291
00:17:17,350 --> 00:17:20,380
First of all, I collected
pictures from meetups.

292
00:17:20,500 --> 00:17:24,910
I passed them through the recognition,
I aggregated the data and for me it

293
00:17:24,910 --> 00:17:27,340
was the most important to know if.

294
00:17:27,370 --> 00:17:30,040
Eyes are open and the picture is sharp.

295
00:17:30,070 --> 00:17:35,320
So those are two main things
that I would personally open and.

296
00:17:36,150 --> 00:17:37,680
Come and see for the views.

297
00:17:37,890 --> 00:17:42,380
Also for for me it was important to have
confidence in the face detection that

298
00:17:42,380 --> 00:17:47,510
we have faces and because of the faces,
we were recognizing the biggest face

299
00:17:47,660 --> 00:17:51,680
and the sharp face because sometimes
you have a few persons and we are trying

300
00:17:51,710 --> 00:17:57,470
to get it or, and it can be potentially
a marker of the faulty outer focus.

301
00:17:57,830 --> 00:18:01,610
And yeah, we can also estimate
the post that, for example, I

302
00:18:01,610 --> 00:18:03,050
can automatically throw away.

303
00:18:03,550 --> 00:18:07,660
Some, I don't know, crazy facial
ex expressions that no one

304
00:18:07,660 --> 00:18:10,030
would post on LinkedIn and yeah.

305
00:18:10,850 --> 00:18:17,490
And basically I was using detect face
CPI and detect label CPI and, and it was

306
00:18:17,490 --> 00:18:21,570
in all dedicated S3 bucket of training
photos, and it was not intercepting.

307
00:18:21,780 --> 00:18:24,150
And I was with the threshold analysis.

308
00:18:24,150 --> 00:18:27,180
I was extracting facial
expressions and also raw metadata.

309
00:18:27,180 --> 00:18:31,170
Raw metadata was the core here
that I could implement the

310
00:18:31,170 --> 00:18:32,820
actual processing core here.

311
00:18:33,070 --> 00:18:33,790
And wait.

312
00:18:34,240 --> 00:18:39,940
And and, speaking about the parameters,
for me it was the most important to get

313
00:18:39,940 --> 00:18:43,960
the sharpness eyes open, confidence, fa,
face detection, confidence parameters

314
00:18:43,960 --> 00:18:46,355
that we were actually storing in the gb.

315
00:18:46,605 --> 00:18:49,965
And then we are going, when we
already have the thresholds, we

316
00:18:49,965 --> 00:18:54,685
can already so prewarm our system
to do what is it intended to do,

317
00:18:54,895 --> 00:18:56,725
and in the production workflow.

318
00:18:56,975 --> 00:19:01,205
Here, as I already mentioned, we have a
trigger, so we are coming then before each

319
00:19:01,205 --> 00:19:05,505
individual picture, and it was extremely
valuable because in any case it was

320
00:19:05,505 --> 00:19:08,115
processing for the processing workflow.

321
00:19:08,145 --> 00:19:10,575
It does not matter what
actually this picture is.

322
00:19:10,785 --> 00:19:15,215
It's already was built to work with
the A RW files that were incoming

323
00:19:15,215 --> 00:19:19,910
from the Sonic Camera and, all this
process was completely orchestrated.

324
00:19:19,970 --> 00:19:22,010
I was extremely happy with the results.

325
00:19:22,370 --> 00:19:25,820
And we were extracting the
metadata as I already mentioned.

326
00:19:26,120 --> 00:19:30,680
So we were performing analysis with
the recognition that we could get

327
00:19:30,680 --> 00:19:34,910
the metrics and, we were collecting
the parameter thresholds, we were

328
00:19:34,970 --> 00:19:37,070
detecting who is actually this person.

329
00:19:37,340 --> 00:19:41,845
And we, it was automatically taking
decision if it's taken or rejected.

330
00:19:42,085 --> 00:19:45,805
And that's why we have to
separate packets because yeah

331
00:19:45,855 --> 00:19:47,925
it mes can still make a mistake.

332
00:19:47,925 --> 00:19:50,655
So we were just to make
pre-approved and approved appro

333
00:19:50,745 --> 00:19:52,795
an unapproved approach here.

334
00:19:53,015 --> 00:19:54,715
And what is the most important?

335
00:19:54,775 --> 00:20:00,095
It's actually discussed in written liberal
lambda, which is using the pyro library.

336
00:20:00,365 --> 00:20:05,090
And here we just starting from the
camera, we are delivering presorted

337
00:20:05,150 --> 00:20:06,920
completely good pictures to our team.

338
00:20:07,280 --> 00:20:10,470
And talking about the
recognition API strategy.

339
00:20:10,740 --> 00:20:15,300
So I was mainly using the detect
phases API, yeah, because I had to

340
00:20:15,300 --> 00:20:19,570
get the scores, as you can see on the
screenshot, and I was also using the

341
00:20:19,570 --> 00:20:26,630
detect labels for the analysis and to
reduced the price usage of recognition.

342
00:20:26,660 --> 00:20:28,160
I was not using index faces.

343
00:20:28,560 --> 00:20:32,310
Because we already have information
about what is present and I wanted

344
00:20:32,310 --> 00:20:36,420
to work just specifically with one
phase and it was the most important.

345
00:20:36,670 --> 00:20:42,270
And we were also using detect moderation,
labels as secondary filter and just

346
00:20:42,270 --> 00:20:46,620
not to overcome the service and
to avoid any kind of API TRT link.

347
00:20:47,580 --> 00:20:48,450
We also had some.

348
00:20:49,720 --> 00:20:53,780
Dynamic calling so that we have
some jitter in calls that we are not

349
00:20:53,840 --> 00:20:56,060
hitting any kind of service API limits.

350
00:20:56,240 --> 00:21:00,590
And of course, we had the lamb
concurrency here and also what was

351
00:21:00,590 --> 00:21:04,640
important, for example, sometimes when
I'm shooting, so I'm shooting series

352
00:21:04,640 --> 00:21:08,640
of the pictures and sometimes you can
have almost similar pictures with a.

353
00:21:09,685 --> 00:21:12,025
Pretty tight timestamps.

354
00:21:12,025 --> 00:21:16,075
So I was sending such pictures
of a batch to the recognition.

355
00:21:16,315 --> 00:21:18,955
So for example, because sometimes
you can have four pictures

356
00:21:18,955 --> 00:21:20,575
and only one of it is sharp.

357
00:21:20,605 --> 00:21:25,535
And to reduce this aggregation to
reduce number of API counts so yeah.

358
00:21:25,925 --> 00:21:32,535
We have taken a out more efficiency
from AWS recognition and also I used AWS

359
00:21:32,535 --> 00:21:37,305
Lambda Power Tools, which is an amazing
library that gives you lots of backbone

360
00:21:37,305 --> 00:21:42,345
to boost your development, for example,
for ex extensive logging, error tracing.

361
00:21:42,345 --> 00:21:43,515
So it's extremely useful.

362
00:21:44,145 --> 00:21:48,345
And you must use AWS Lambda
Power Tools in your projects.

363
00:21:48,565 --> 00:21:49,425
And yeah.

364
00:21:49,825 --> 00:21:53,635
For example, here you can see an
example of some piece of Lambda

365
00:21:53,635 --> 00:21:58,625
code I have, and, so in terms of
calibration of the sharpness data,

366
00:21:58,625 --> 00:22:00,655
it was a logarithmic function.

367
00:22:00,685 --> 00:22:02,745
So it was logarithmic scale.

368
00:22:02,745 --> 00:22:07,125
So that goes 25 to 100 usually,
and we were targeting pictures

369
00:22:07,125 --> 00:22:09,435
that usually hitting over 70%.

370
00:22:09,985 --> 00:22:14,295
And yeah, we, I would say it was
even 80 for the speakers and 65

371
00:22:14,295 --> 00:22:19,855
for the more general photos because
they are usually like, have more.

372
00:22:20,350 --> 00:22:25,790
Fine grain details that are getting
lost and for me, it's also to reinforce

373
00:22:25,790 --> 00:22:29,120
the like quality of open eyes.

374
00:22:29,120 --> 00:22:33,790
So I have went through them, over 500
pictures that just to be confident

375
00:22:33,790 --> 00:22:37,930
enough and I haven't done any additional
pre-training of the recognition

376
00:22:37,930 --> 00:22:42,310
because it was already very like
reliable and I absolutely love it.

377
00:22:42,640 --> 00:22:45,040
And also the Lambda was controlling.

378
00:22:45,370 --> 00:22:51,610
So if we actually recognizing single
eye or both eyes and, but it was like

379
00:22:51,610 --> 00:22:56,800
some of the third party, like second
priority metrics because mainly we,

380
00:22:57,215 --> 00:23:02,795
I was getting normal metrics for both
open ice and also I was taking the

381
00:23:03,005 --> 00:23:07,365
official expression analysis and actually
one of good ideas of development of

382
00:23:07,365 --> 00:23:09,865
this project that we could count the.

383
00:23:09,910 --> 00:23:14,560
Amount of happy, surprised,
cold, angry to get more like

384
00:23:14,620 --> 00:23:19,780
statistical overview of the mood and
atmosphere on the conference part.

385
00:23:20,535 --> 00:23:22,305
We will speak about it a bit later.

386
00:23:22,545 --> 00:23:22,875
Yeah.

387
00:23:23,115 --> 00:23:27,395
And post assessment is important
because we can already drawn out

388
00:23:27,395 --> 00:23:30,875
some pictures that have some strange
positions of the hands, et cetera,

389
00:23:30,875 --> 00:23:32,495
in combination with the wear face.

390
00:23:32,735 --> 00:23:35,435
And it already saved lots of work here.

391
00:23:35,615 --> 00:23:39,195
So we are getting properly
exposed pictures from the set.

392
00:23:39,195 --> 00:23:44,915
We are having high confident eye detection
and here, and we are already cutting down.

393
00:23:45,710 --> 00:23:49,790
A good piece of input that could be
potentially not useful in our project.

394
00:23:49,840 --> 00:23:55,330
And one of the pillars of this projects
and I was thinking a lot what actually

395
00:23:55,330 --> 00:23:59,380
could have been on this slide because
I was considering different options.

396
00:24:00,070 --> 00:24:02,945
I. Starting from running some
E two instance, which had a GPU

397
00:24:03,005 --> 00:24:07,035
with some kind of windows script
automation to perform editing.

398
00:24:07,035 --> 00:24:11,295
Then I was considering running any
kind of commercial solution and, but

399
00:24:11,295 --> 00:24:13,470
unfortunately only solutions with by topa.

400
00:24:14,130 --> 00:24:20,040
Are capable to provide UCL access and
I haven't worked with the topos much,

401
00:24:20,040 --> 00:24:21,810
that's why I abandoned this idea.

402
00:24:22,080 --> 00:24:26,530
'cause I'm mostly use Luminar Neo and
the XO photo app in my processing.

403
00:24:26,530 --> 00:24:31,270
So Luminar is amazing for portrayed
or studio sessions and the so is

404
00:24:31,270 --> 00:24:34,960
great when you are processing huge
events like diesel or some, I dunno.

405
00:24:35,960 --> 00:24:38,360
Yeah, when you don't
need to weak the faces.

406
00:24:38,660 --> 00:24:43,230
And then I was thinking and I looked in
the direction of the open source things.

407
00:24:43,230 --> 00:24:46,370
And yeah, we have a very good
known liberal library, which

408
00:24:46,370 --> 00:24:49,100
is used for example, in dark
table in the road therapy.

409
00:24:49,250 --> 00:24:50,570
And I thought, give it a try.

410
00:24:50,570 --> 00:24:55,700
I. And the reason, actually, you could
ask me, Dima, why do you need to do it?

411
00:24:55,700 --> 00:24:59,690
Because you can already have GPX from
the camera, and this is a thing when you

412
00:24:59,690 --> 00:25:03,950
are working with the profiles, you have
a file which has 14 bits of information.

413
00:25:04,280 --> 00:25:08,360
It means that in our situation when
most of the speakers are standing

414
00:25:08,360 --> 00:25:13,080
behind the s with a tors, with the
bright or dark slides, and we, I

415
00:25:13,080 --> 00:25:14,970
was trying not using the flash.

416
00:25:15,265 --> 00:25:18,415
Because I didn't want to disturb
attendees, not to disturb

417
00:25:18,415 --> 00:25:20,275
speakers, to keep everyone focused.

418
00:25:20,275 --> 00:25:22,135
So basically, I was a ghost.

419
00:25:22,855 --> 00:25:27,325
So that we keep our attendees to
focus on the technical topics, to

420
00:25:27,325 --> 00:25:32,025
let them enjoy the conference and
not to disturb them with, all this.

421
00:25:32,895 --> 00:25:35,925
So how is sometimes
called welding and Yeah.

422
00:25:35,985 --> 00:25:39,735
When you are shooting GP you have
eight bit files and you cannot simply

423
00:25:39,735 --> 00:25:41,685
recover the highlights or shadows.

424
00:25:41,685 --> 00:25:42,885
You can, but just a bit.

425
00:25:43,185 --> 00:25:47,845
And here, for example, when you're working
with the row, just by working with the.

426
00:25:48,725 --> 00:25:52,565
Specific functions, you can recover
all the background that have e

427
00:25:53,075 --> 00:25:55,905
equally equalized ex exposed picture.

428
00:25:55,965 --> 00:26:01,545
So here, using the liberal library, I was
also considering if I would like to run

429
00:26:01,545 --> 00:26:04,215
it on the ECS or run it like a Lambda.

430
00:26:04,425 --> 00:26:09,565
But I also noticed that, if you lambda,
since we are receiving the picture and

431
00:26:09,715 --> 00:26:15,315
so there is no, there is always a gap
between like supplying of the pictures.

432
00:26:15,315 --> 00:26:15,585
Yeah.

433
00:26:15,585 --> 00:26:19,235
There would be some idling time when
you are running the container and I

434
00:26:19,235 --> 00:26:24,775
noticed that if I was running Lambda
with the capacity of memory of one and

435
00:26:24,775 --> 00:26:29,545
half gigabytes, it was giving you much,
I was receiving much better performance.

436
00:26:30,080 --> 00:26:32,870
Then a comparable container
running on the Fargate.

437
00:26:33,320 --> 00:26:37,270
This is the first false response
time was within 10 seconds, and we

438
00:26:37,270 --> 00:26:39,460
already had processed image on the.

439
00:26:39,750 --> 00:26:43,770
On the storage and I'm
using AMA algorithm.

440
00:26:43,770 --> 00:26:46,990
There are lots of algorithms
from the basic ones.

441
00:26:46,990 --> 00:26:52,860
So ama, it's so the idea is that
it does an detection of the edges

442
00:26:52,860 --> 00:26:57,530
that allows you to reduce more
and also some kind of steps.

443
00:26:57,555 --> 00:27:00,915
On the edges, and this is the
most advanced algorithms which

444
00:27:00,915 --> 00:27:02,745
are available like an open source.

445
00:27:03,095 --> 00:27:06,395
And LiRo, actually this lamb
that works in two functions

446
00:27:06,395 --> 00:27:08,255
based on the event it receives.

447
00:27:08,255 --> 00:27:14,045
The first scenario is every
profile, TNGC two, nf, IRV,

448
00:27:14,375 --> 00:27:16,955
rough, they have the miniature.

449
00:27:17,710 --> 00:27:20,920
Which is extracted by photo viewing
software when you are coming to

450
00:27:20,920 --> 00:27:25,060
the row, because sometimes it's
a very like performance demanding

451
00:27:25,060 --> 00:27:26,830
operation performed in the mosaic.

452
00:27:27,100 --> 00:27:31,940
That's why camera always includes a
small like preview miniature inside

453
00:27:31,940 --> 00:27:35,610
of the file, which is taken by
the photo photo viewing software.

454
00:27:35,640 --> 00:27:41,200
And I used to extract this picture,
actually like to perform pre-processing.

455
00:27:42,005 --> 00:27:47,545
On the recognition and to already save
the time and cost of recognition, not to

456
00:27:47,545 --> 00:27:51,835
waste it processing every single image
because this resolution, it was already

457
00:27:51,835 --> 00:27:55,625
enough to perform the person examination.

458
00:27:55,895 --> 00:27:56,165
Yeah.

459
00:27:56,165 --> 00:27:57,875
And then we were taking the right one.

460
00:27:57,875 --> 00:28:01,945
Then of course we could take the
bigger one and perform more precise.

461
00:28:02,305 --> 00:28:03,295
Analysis of the quality.

462
00:28:03,295 --> 00:28:08,335
So basically we were taking and working
with more progressive options here.

463
00:28:08,395 --> 00:28:08,695
Yeah.

464
00:28:08,965 --> 00:28:12,715
And also already mentioned, we have
already aggregated loss of metadata,

465
00:28:12,745 --> 00:28:16,255
which, so basically I was telling,
okay, we have this picture based on

466
00:28:16,255 --> 00:28:18,935
this recognition data plus metadata.

467
00:28:18,995 --> 00:28:21,095
And I would process it like, like this.

468
00:28:21,305 --> 00:28:23,765
And here we are pushing
metadata of the sample.

469
00:28:23,765 --> 00:28:25,445
We are campaigning it with the weights.

470
00:28:25,475 --> 00:28:26,765
It all goes to cloud.

471
00:28:27,935 --> 00:28:30,485
CLO through the bedrock, and
it was suggesting the potential

472
00:28:30,485 --> 00:28:34,985
scenario, and it was extremely
good because it was compensating

473
00:28:34,985 --> 00:28:36,455
the highlights very precisely.

474
00:28:36,455 --> 00:28:40,725
I was happy how it was adjusting
the wide balance and, also all my

475
00:28:40,725 --> 00:28:45,045
profiles, they had extremely aggressive
highlight and shadow reconstruction.

476
00:28:45,235 --> 00:28:51,235
I was achieving with this lambda, so the
quality and coloring and processing that

477
00:28:51,235 --> 00:28:55,885
I was not able to achieve, for example, by
using the picture profile on the cameras.

478
00:28:55,885 --> 00:29:00,895
But mainly because of the limitations
of the loss of the dynamic range on the

479
00:29:00,895 --> 00:29:03,965
file that is caused by eight BT GP files.

480
00:29:04,215 --> 00:29:05,025
And yeah.

481
00:29:05,680 --> 00:29:10,130
This thing, it was it done most
of the job here because not only

482
00:29:10,130 --> 00:29:11,510
selection takes lots of time.

483
00:29:11,510 --> 00:29:14,510
The actual processing, it
actually can take even more.

484
00:29:14,690 --> 00:29:17,935
And it's always mu it must be
consistent because sometimes you

485
00:29:17,935 --> 00:29:19,705
can start processing one day.

486
00:29:20,035 --> 00:29:22,675
Then I know you had something,
you are coming back on the next

487
00:29:22,675 --> 00:29:23,570
day and then you're looking.

488
00:29:23,855 --> 00:29:25,925
Oh my God, everything is green.

489
00:29:26,135 --> 00:29:26,525
No.

490
00:29:26,615 --> 00:29:28,355
So here it was also consistent.

491
00:29:28,535 --> 00:29:32,225
It was very fast, very efficient,
and it's just a must have

492
00:29:32,225 --> 00:29:33,665
and big win of this project.

493
00:29:34,055 --> 00:29:39,125
And yeah, as I already mentioned, so
we were cutting the small batching

494
00:29:39,125 --> 00:29:44,405
logic so that I was combining
the series, comparable pictures,

495
00:29:44,405 --> 00:29:46,745
and to reduce the number of the.

496
00:29:47,785 --> 00:29:51,965
Calls to the AWS bedrock and
I think all these miniatures,

497
00:29:51,965 --> 00:29:54,515
they were around 1,200 pixels.

498
00:29:54,855 --> 00:29:57,965
And also it was going
to the step functions.

499
00:29:57,965 --> 00:30:02,960
They were concurrent and we were, I was
also dynamically adjusting the concurrency

500
00:30:02,960 --> 00:30:04,700
based on the number of the events.

501
00:30:04,920 --> 00:30:06,210
And it was very parallel.

502
00:30:07,005 --> 00:30:07,205
Parallel.

503
00:30:07,320 --> 00:30:10,320
And pictures were coming one
by one and they were not.

504
00:30:10,920 --> 00:30:12,840
Interact, interacting between each other.

505
00:30:13,110 --> 00:30:15,510
So this is a good technical part of it.

506
00:30:15,960 --> 00:30:17,280
Looking here, the results.

507
00:30:17,280 --> 00:30:20,610
First of all, I, it was extremely
memorable when such an amazing

508
00:30:20,610 --> 00:30:25,100
people like Luke, like Jan, they
published all these pictures.

509
00:30:25,100 --> 00:30:29,055
I. So they are LinkedIns and first
of all, it's good memory for them.

510
00:30:29,295 --> 00:30:32,025
It's support of their
work that they are doing.

511
00:30:32,025 --> 00:30:36,825
As a speakers, as a technicians, as
a part of AWS community, I got lots

512
00:30:36,825 --> 00:30:41,555
of amazing feedback on the email and
it already give lots of powers for

513
00:30:41,555 --> 00:30:45,245
me because physically it was very
exhausting to shoot such a big event.

514
00:30:45,695 --> 00:30:50,785
And yeah, from the AWS community
side, we expanded the, so we enhanced.

515
00:30:51,305 --> 00:30:54,205
Our impression and community experience.

516
00:30:54,205 --> 00:30:57,955
So we could use these pictures to have
more community restaurants because we

517
00:30:57,955 --> 00:31:03,025
can show to the people in the good way
with the cool photos, what are we doing?

518
00:31:03,115 --> 00:31:06,800
And this is a good memory that, for
example, when I will be old and I

519
00:31:06,800 --> 00:31:10,670
don't know all of us, one day we'll
be old unfortunately, and we could

520
00:31:10,670 --> 00:31:12,710
back to it and see, hey, we were cool.

521
00:31:12,770 --> 00:31:15,890
And for the speakers, it's
also the support of their.

522
00:31:15,915 --> 00:31:19,515
Brands, brands development,
it's support of their employers.

523
00:31:19,815 --> 00:31:25,205
And for me personally, it was a huge
win because I spent about I don't know,

524
00:31:26,045 --> 00:31:32,055
I would say less than I. I would say
maybe 15, 20 hours to get it done,

525
00:31:32,055 --> 00:31:36,975
to work very relaxed without any rush
or crunch, but it saved potentially

526
00:31:36,975 --> 00:31:40,155
over 60 plus H hours of manual work.

527
00:31:40,185 --> 00:31:45,255
But I believe even more because from
8,000 pictures, the whole processing,

528
00:31:45,285 --> 00:31:48,705
it took out 4,200 candidates.

529
00:31:49,090 --> 00:31:50,170
They were pre preferences.

530
00:31:50,410 --> 00:31:54,640
We were just performed additional pre
selection based on our needs that we

531
00:31:54,640 --> 00:31:59,290
have preplanned with our marketing
team and talking about the costs.

532
00:31:59,500 --> 00:32:04,330
It's absolutely worth it because
I spent $20 on a s recognition.

533
00:32:04,390 --> 00:32:08,590
I spent $30 on AWS Lambda orchestration.

534
00:32:08,770 --> 00:32:11,200
They name a DB step
function transfer family.

535
00:32:11,745 --> 00:32:17,295
So if counting the price only for the day
of the conference, and in total we spend

536
00:32:17,295 --> 00:32:21,465
$50 and less than 1 cent per picture.

537
00:32:22,065 --> 00:32:22,900
This is an amazing.

538
00:32:23,565 --> 00:32:29,335
Values just because time and for
example, my health that my mind that

539
00:32:29,335 --> 00:32:34,915
I'm using to process the pictures, it's
all probably would cost more than $50.

540
00:32:35,155 --> 00:32:35,905
Definitely.

541
00:32:36,085 --> 00:32:38,065
And such a big response.

542
00:32:38,065 --> 00:32:38,665
How much.

543
00:32:38,790 --> 00:32:44,400
Effort it saved and how it in allowed
us to develop the process also to have

544
00:32:44,400 --> 00:32:46,170
a good reason to give a speech for you.

545
00:32:46,170 --> 00:32:50,550
And it was absolutely worth it because
it done job even more than four

546
00:32:50,550 --> 00:32:53,790
$50 and talking about the things.

547
00:32:53,790 --> 00:32:57,690
So that I would like to reflect
the, to the Steve Jobs quote

548
00:32:57,750 --> 00:32:59,100
that I have had in the beginning.

549
00:32:59,430 --> 00:33:01,680
So that technology alone is not enough.

550
00:33:02,100 --> 00:33:08,125
And and a s. I never speak about of
it, just like about the call provider.

551
00:33:08,125 --> 00:33:12,355
It's a toolkit that provides and let us
solve the problems in the creative ways.

552
00:33:12,355 --> 00:33:17,335
When you are equipped with those
tools, using our unique skills,

553
00:33:17,575 --> 00:33:19,675
you can create unexpected value.

554
00:33:20,035 --> 00:33:20,185
So I.

555
00:33:21,095 --> 00:33:28,205
Guys, UCWS don't think just you are
running virtual machines, go beyond your

556
00:33:28,205 --> 00:33:33,575
engineering division and make a real
projects like this one that might make

557
00:33:33,575 --> 00:33:36,485
an impact on some, something significant.

558
00:33:36,485 --> 00:33:38,465
For example, like on a s community.

559
00:33:39,125 --> 00:33:43,475
And here we have achieved a good
foundation that can, in the future,

560
00:33:43,475 --> 00:33:45,485
can be developed in automatic.

561
00:33:45,500 --> 00:33:49,820
Collection generation and delivery
platform for any kind of event.

562
00:33:50,060 --> 00:33:53,750
For example, for publishing, for
realtime events that, for example,

563
00:33:53,750 --> 00:33:57,500
people, they are on the N, they can
sunk your code and come and see it.

564
00:33:57,710 --> 00:34:00,950
But we have a technical backbone
and for me, the task would

565
00:34:00,950 --> 00:34:03,080
be to have even more for it.

566
00:34:03,080 --> 00:34:06,620
So to make a, not only at the point
when you can come and take it,

567
00:34:06,620 --> 00:34:08,450
but to make it in the way that.

568
00:34:09,215 --> 00:34:10,685
Pictures are coming to you.

569
00:34:11,525 --> 00:34:17,165
So looking to the takeaways from all of
this story, first of all, the, so AWS

570
00:34:17,165 --> 00:34:21,435
services, they are amazing and they can
be combined creativity beyond traditional

571
00:34:21,435 --> 00:34:25,785
use case or for what they're intended
to do and combining with the things

572
00:34:25,785 --> 00:34:27,795
that are intended to do something else.

573
00:34:27,795 --> 00:34:30,435
But for some reason, they're
useful and we have it here.

574
00:34:30,565 --> 00:34:34,195
For example, that FCP function
streams directly to S3 bucket

575
00:34:34,495 --> 00:34:35,990
and let us work with the data.

576
00:34:36,660 --> 00:34:41,010
And I have combined here recognition,
step function, Lambda S3 bedrock

577
00:34:41,010 --> 00:34:45,210
in the way that actually they
were not like, designed for.

578
00:34:45,210 --> 00:34:51,480
And it's just going knowledge and seeing
beyond the intended use of a LS service.

579
00:34:51,900 --> 00:34:56,190
And they are all the services
there building blocks that can

580
00:34:56,190 --> 00:34:58,110
solve any problem in any domain.

581
00:34:58,110 --> 00:34:58,590
You just.

582
00:34:58,975 --> 00:35:00,475
Come and solve it.

583
00:35:00,475 --> 00:35:04,545
And I think it's not a regular case
when AWS services in that matter,

584
00:35:04,545 --> 00:35:07,975
they're solving photography tasks
in the way like a human would

585
00:35:07,975 --> 00:35:10,075
work with the same photo data set.

586
00:35:10,315 --> 00:35:10,615
Yeah.

587
00:35:10,945 --> 00:35:14,335
And this project also
shows wise is amazing.

588
00:35:14,395 --> 00:35:17,095
And you can make you can delegate to.

589
00:35:17,315 --> 00:35:20,195
Labor intensive tasks without
of any management overhead.

590
00:35:20,195 --> 00:35:25,235
You're just coming and creating
the logics that brings economical,

591
00:35:25,265 --> 00:35:27,485
strategical business value to you.

592
00:35:28,175 --> 00:35:35,295
And all this orchestration, it turned
hours of manual work to the amazing thing.

593
00:35:35,705 --> 00:35:40,115
And since we pay only for use, it's
also very economical, effective, and,

594
00:35:40,145 --> 00:35:44,765
so yeah, if you have some projects with
such behavior, feel free to continue

595
00:35:44,975 --> 00:35:47,555
with and it'll solve your tasks.

596
00:35:47,675 --> 00:35:48,035
Yeah.

597
00:35:48,245 --> 00:35:51,900
And the most important, all this
technical part, it allowed us to

598
00:35:51,900 --> 00:35:56,450
develop human connections and make
us a good memory of the conference

599
00:35:56,450 --> 00:35:57,860
that we have done altogether.

600
00:35:58,280 --> 00:35:58,580
Yeah.

601
00:36:00,150 --> 00:36:01,410
This is What about was it?

602
00:36:01,410 --> 00:36:02,670
So thank you very much.

603
00:36:03,010 --> 00:36:08,170
I'm always happy to discuss any, anything
technical, AWS, whatever you like.

604
00:36:08,170 --> 00:36:09,370
Even formal one.

605
00:36:09,430 --> 00:36:12,430
Please come to me or add
me on LinkedIn please.

606
00:36:12,490 --> 00:36:15,440
I. So I'm open for any
kind of discussions.

607
00:36:15,440 --> 00:36:16,430
Thank you very much.

608
00:36:16,460 --> 00:36:17,690
I hope you enjoy conference.

609
00:36:17,690 --> 00:36:18,020
You do.

610
00:36:18,230 --> 00:36:22,010
I'm very thankful to, to the
mark for having all this idea,

611
00:36:22,010 --> 00:36:23,150
pushing all this community.

612
00:36:23,150 --> 00:36:28,695
And this is the second time this year and
I'm exciting to be here in support of you.

613
00:36:28,695 --> 00:36:30,395
So please enjoy the conference.

614
00:36:30,605 --> 00:36:35,015
I hope you like the session, and we will
see us any other time on the clouds.

615
00:36:35,045 --> 00:36:35,525
Thank you.

