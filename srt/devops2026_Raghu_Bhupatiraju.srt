1
00:00:00,510 --> 00:00:02,070
Speaker 33: Hi, I'm Ragu.

2
00:00:02,610 --> 00:00:08,100
I work as a senior software engineer
at Expeditors in Global Supply chains.

3
00:00:08,340 --> 00:00:13,980
Minutes of failure can cost hundreds
of thousands of dollars, and most of

4
00:00:13,980 --> 00:00:19,470
the time we don't hear about these
failures from our monitoring tools, but

5
00:00:19,470 --> 00:00:21,090
we hear about them from our customer.

6
00:00:21,690 --> 00:00:26,190
Today I'm going to talk about how
to move from reacting to failures.

7
00:00:26,250 --> 00:00:28,700
Two, predicting them and preventing them.

8
00:00:29,200 --> 00:00:32,710
Modern supply chains are
not just applications.

9
00:00:33,070 --> 00:00:40,390
They're made up of APIs, carriers,
iot devices, weather systems,

10
00:00:40,660 --> 00:00:43,740
warehouses, and don't fade alone.

11
00:00:43,830 --> 00:00:46,530
They propagate from one
system to the other.

12
00:00:47,030 --> 00:00:48,890
A small delay becomes a missed.

13
00:00:49,390 --> 00:00:51,340
A missed pickup becomes a missed.

14
00:00:52,074 --> 00:00:55,255
A missed flight becomes a customer impact.

15
00:00:55,755 --> 00:00:59,824
Traditional monitoring tools answers
one question what went wrong?

16
00:01:00,324 --> 00:01:04,984
Say for example whenever something
happens, we have these monitoring

17
00:01:05,044 --> 00:01:10,115
tools triggering alerts only after
the performance has already declined

18
00:01:10,615 --> 00:01:14,335
and leaving the team responding to
problems rather than preventing them.

19
00:01:15,040 --> 00:01:16,510
And root cause discovery.

20
00:01:16,540 --> 00:01:22,330
During impact, engineers must diagnose
issues via customer experience disruption,

21
00:01:22,810 --> 00:01:27,210
increasing the pressure and extending
the re resolution time, cascading

22
00:01:27,210 --> 00:01:32,850
failure, complexity, multiple failures
occurring simultaneously, obscure

23
00:01:32,855 --> 00:01:37,530
the original root cause, and making
diagnosis exponentially more difficult.

24
00:01:38,430 --> 00:01:43,170
External signal blindness, critical
external factors like weather events.

25
00:01:43,245 --> 00:01:48,285
Carrier operational issues and
traffic patterns remain invisible

26
00:01:48,285 --> 00:01:49,875
to application level monitoring.

27
00:01:50,375 --> 00:01:54,544
The result would be teams spending
their time firefighting incidents

28
00:01:54,664 --> 00:01:57,484
rather than preventing them from
occurring in the first place.

29
00:01:57,984 --> 00:01:59,994
So what is Predictor Observability?

30
00:02:00,414 --> 00:02:04,584
Predictor Observability is
observability with the foresight.

31
00:02:05,274 --> 00:02:10,044
So we learn from the failures instead
of waiting for the system to fail.

32
00:02:10,435 --> 00:02:16,424
We learned the failure behavior, so
we look at the historical pattern

33
00:02:16,424 --> 00:02:21,704
analysis, analyzing the past instance
to identify recurring patterns and

34
00:02:21,704 --> 00:02:27,945
failure signatures, real time telemetric,
continuous monitoring of system metrics,

35
00:02:28,005 --> 00:02:33,634
logs and dis distributed traces, and
integrating weather carrier status

36
00:02:33,634 --> 00:02:35,619
traffic, and other environmental factors.

37
00:02:36,274 --> 00:02:41,284
Which are outside of the applications,
proactive actions enabling

38
00:02:41,494 --> 00:02:44,254
intervention hours or even days before.

39
00:02:44,884 --> 00:02:48,994
It's the difference between a smoke
detector and a fire prevention.

40
00:02:49,384 --> 00:02:51,754
The goal is not better dashboards.

41
00:02:51,844 --> 00:02:54,184
The goal is to have fewer incidents.

42
00:02:54,684 --> 00:02:57,744
How should the architecture of
this observability look like?

43
00:02:57,834 --> 00:03:01,765
There are five integrated layers
working in concrete to transform the

44
00:03:01,765 --> 00:03:03,859
raw signal into actionable intelligence.

45
00:03:04,359 --> 00:03:09,519
Real time observability signals,
foundational layer, capturing metrics,

46
00:03:09,640 --> 00:03:15,249
logs, traces and events from all
system components in real historical

47
00:03:15,249 --> 00:03:20,884
pattern analysis, time series databases
and analytical engines, identifying

48
00:03:20,884 --> 00:03:24,755
recurring patterns and seasonal trends,
external intelligence integration.

49
00:03:25,549 --> 00:03:31,310
APIs carrier status speeds and traffic
data and market indicators and risk.

50
00:03:31,310 --> 00:03:36,489
The internal telemetry, predictive
processing engine, machine learning models

51
00:03:36,489 --> 00:03:41,559
and statistical algorithms, detecting
anomalies and forecasting failures.

52
00:03:42,059 --> 00:03:43,409
Action orchestration.

53
00:03:43,889 --> 00:03:49,049
Automated response system triggers
alerts and running remediation playbooks

54
00:03:49,049 --> 00:03:50,729
and coordinating human intervention.

55
00:03:51,229 --> 00:03:51,649
Events.

56
00:03:51,649 --> 00:03:57,219
Flow into the events, flow into
the streams and predictive services

57
00:03:57,429 --> 00:03:59,939
learned from the behavior models.

58
00:03:59,999 --> 00:04:03,859
Forecast Orchestrations enables actions.

59
00:04:04,359 --> 00:04:08,589
Our prediction systems are allowed to
fail, but are not Our production systems,

60
00:04:09,089 --> 00:04:11,199
event driven architecture for prediction.

61
00:04:11,839 --> 00:04:16,609
Event driven architecture provides
the foundation for scalable, resilient

62
00:04:16,669 --> 00:04:22,939
predictive systems by using streaming
backbones like AP Apache Kafka and

63
00:04:22,939 --> 00:04:27,769
AWS Kinesis Prediction Logic operates
independently from the production

64
00:04:27,769 --> 00:04:33,159
systems, and so the fine main things
that is happening is stream streaming

65
00:04:33,159 --> 00:04:38,259
backbone, Kafka or Kinesis, handling
millions of events per second.

66
00:04:38,904 --> 00:04:44,304
Continuous signal ingestion, real time
data from all system components and

67
00:04:44,304 --> 00:04:49,724
external services, real time anomaly
detection, immediate pattern recognition

68
00:04:49,724 --> 00:04:55,244
and deviation identification, decoupled
prediction services, independent

69
00:04:55,244 --> 00:04:58,064
scaling and evolution of ML models.

70
00:04:58,564 --> 00:05:02,199
Prediction logic never impacts
the production stability, failed

71
00:05:02,199 --> 00:05:05,799
predictions or isolated incidents
and not systemwide outages.

72
00:05:06,299 --> 00:05:07,649
Why Microservices?

73
00:05:08,459 --> 00:05:13,079
Microservices gives you the independent
Scaling Machine Learning Inference

74
00:05:13,319 --> 00:05:18,119
Services scale separately from core
business logic technology evolution.

75
00:05:18,269 --> 00:05:23,339
Update prediction algorithms without
touching production code failure,

76
00:05:23,339 --> 00:05:28,109
isolation prediction service failures
don't cascade to operational systems.

77
00:05:28,609 --> 00:05:29,689
Team autonomy.

78
00:05:30,019 --> 00:05:33,049
Data science teams deploy
models independently.

79
00:05:33,549 --> 00:05:36,219
And what about the
distributed tracing power?

80
00:05:37,029 --> 00:05:38,619
Casual dependency mapping.

81
00:05:38,649 --> 00:05:41,289
Understand how services
depend on each other.

82
00:05:41,979 --> 00:05:45,999
Failure propagation prediction
forecast how issues will

83
00:05:45,999 --> 00:05:47,679
cascade through the system.

84
00:05:48,399 --> 00:05:50,799
Intervention window estimate.

85
00:05:51,369 --> 00:05:54,099
Calculate how much time
exists before impact.

86
00:05:54,909 --> 00:05:59,409
Bottleneck identification,
pinpoint where failures originate.

87
00:06:00,369 --> 00:06:05,859
This architectural approach ensures that
predictor capabilities enhance rather

88
00:06:05,859 --> 00:06:07,869
than compromise system reliability.

89
00:06:08,159 --> 00:06:09,989
Let's take a simple example.

90
00:06:10,349 --> 00:06:12,179
Transportation network failures.

91
00:06:12,929 --> 00:06:15,044
Say for example, there is
a severe weather event.

92
00:06:15,544 --> 00:06:18,934
That disrupts the transportation
networks causing cascading

93
00:06:18,934 --> 00:06:21,034
delays across the supply chain.

94
00:06:21,424 --> 00:06:24,364
Traditional approaches detect
these issues only after the

95
00:06:24,364 --> 00:06:25,894
shipments are already delayed.

96
00:06:26,394 --> 00:06:29,694
So the new thing, what we are going
to do with the predictive analysis

97
00:06:29,724 --> 00:06:34,974
is we'll take the weather forecast
integrion, the severe storm prediction

98
00:06:35,064 --> 00:06:40,104
in major transit corridors, and we
look at the traffic patterns like

99
00:06:40,284 --> 00:06:42,834
how much will be the delay in.

100
00:06:43,374 --> 00:06:49,044
For during those situations, it might
be usually like four to six hours.

101
00:06:49,344 --> 00:06:55,824
And we also analyze the carrier routes if
the routes carrier routes are on the same

102
00:06:56,604 --> 00:06:58,764
path with respect to the weather forecast.

103
00:06:59,184 --> 00:07:04,764
And we might try to get alternate backup
carriers instead of the carriers that

104
00:07:04,764 --> 00:07:07,784
are going to be affected and due to this.

105
00:07:08,219 --> 00:07:11,729
Three to six hours early, we
will, we are going to get three

106
00:07:11,729 --> 00:07:16,649
to six hours of early warnings and
we can reduce the delay by 90%.

107
00:07:17,149 --> 00:07:23,599
The second scenario is ca Carrier,
API Degradation third party carrier.

108
00:07:23,599 --> 00:07:28,879
A PS gradually slow down, creating subtle
performance degradation that eventually

109
00:07:28,879 --> 00:07:32,824
cascade into system-wide failures
by the time traditional alerts fire.

110
00:07:33,414 --> 00:07:37,464
Downstream systems are already
experiencing timeouts and errors,

111
00:07:37,964 --> 00:07:44,144
predictive signals, response time trends
showing consistent increase about 20 to

112
00:07:44,144 --> 00:07:51,704
30 minutes, error rate acceleration from
0.1 to 2% or short timeframes, seasonal

113
00:07:51,704 --> 00:07:54,164
patterns indicating peak hour degradation.

114
00:07:54,164 --> 00:07:58,094
Likelihood correlated slowdowns
across multiple API endpoints.

115
00:07:58,594 --> 00:08:05,044
Detection a P response time trending
upwards 30 to 60 minutes before failure.

116
00:08:05,044 --> 00:08:07,144
Threshold prediction.

117
00:08:07,714 --> 00:08:13,384
ML model forecast complete degradation
within 45 minutes based on acceleration.

118
00:08:13,384 --> 00:08:18,564
Pattern action, circuit breaker,
activated caching, layer enabled

119
00:08:18,744 --> 00:08:22,019
backup carrier routes prepared outcome.

120
00:08:22,854 --> 00:08:28,584
Cascade prevented user experience,
briefly delays instead of complete outage.

121
00:08:29,084 --> 00:08:32,204
The third scenario would be
cold chain sensor failures.

122
00:08:32,594 --> 00:08:37,214
Say for example, refriger refrigeration
failures in temperature control

123
00:08:37,214 --> 00:08:42,254
logistics can result in hundreds of
thousands of dollars in spoiled products.

124
00:08:42,764 --> 00:08:46,544
Traditional monitoring de
detects failures only after the

125
00:08:46,544 --> 00:08:48,550
temperature thresholds are breached.

126
00:08:49,409 --> 00:08:52,799
Often too late to save the
cargo with the new system.

127
00:08:53,249 --> 00:08:58,679
First, we analyze the temperature,
variance detection, SubT inconsistencies

128
00:08:58,739 --> 00:09:00,839
in cooling patterns identified.

129
00:09:01,499 --> 00:09:08,084
Then we rate of change analysis,
temperature, drift, acceleration

130
00:09:08,084 --> 00:09:10,244
signals, compress compression issues.

131
00:09:10,514 --> 00:09:16,544
So we check the rate of change in the
temperature sensor consistency patterns.

132
00:09:17,044 --> 00:09:22,124
And with the ch rate of change
data, we also compare with the other

133
00:09:22,259 --> 00:09:24,659
compressor datas to find the anomalies.

134
00:09:25,559 --> 00:09:29,249
Cross validation across multiple
sensors reveals anomalies.

135
00:09:30,179 --> 00:09:35,789
So what this leads, so this leads to
predictive alert, 15 to 30 minutes

136
00:09:35,789 --> 00:09:37,619
warning before critical threshold.

137
00:09:38,119 --> 00:09:43,099
And vehicle diversion reroute to the
nearest facility for product transfer.

138
00:09:43,639 --> 00:09:49,924
And that will save, give us time to
prevent the spoiling of the cargo and

139
00:09:50,074 --> 00:09:52,534
loss prevention and product is saved.

140
00:09:53,034 --> 00:09:56,269
Does the same ML model
work for all the alerts?

141
00:09:57,054 --> 00:09:58,164
The answer is no.

142
00:09:58,554 --> 00:10:01,824
We need to have different
types of alerts for different.

143
00:10:02,244 --> 00:10:07,134
Time timeframes, say for example,
short term is the ones which

144
00:10:07,134 --> 00:10:09,684
are like the live data crossing.

145
00:10:09,684 --> 00:10:16,014
The live data and the hours need to be
between 15 to 60 minutes and medium term

146
00:10:16,014 --> 00:10:21,764
is like one to six hours and long term,
maybe with the days or weeks coming to

147
00:10:21,764 --> 00:10:27,224
the short term, the ca, they capture the
temporal dependencies in time series data.

148
00:10:27,724 --> 00:10:32,194
And rapid detection of out of
control processes for use case,

149
00:10:32,254 --> 00:10:34,234
immediate system health degradation.

150
00:10:34,734 --> 00:10:38,894
And coming to the medium term,
combine multiple weak predictors for

151
00:10:38,894 --> 00:10:44,144
robust forecast, handle seasonality
and holiday efforts in time series.

152
00:10:44,644 --> 00:10:50,734
Feature importance for interpretable
predictions, use case transportation

153
00:10:50,734 --> 00:10:52,279
delays, and API degradation.

154
00:10:52,779 --> 00:10:57,309
Long term, so long-term are something
like we, we analyze both the short

155
00:10:57,309 --> 00:11:02,709
term and medium term and come up with
a plan for the long term analysis.

156
00:11:02,979 --> 00:11:06,789
Say for example, with these
disruptions, we are going to make

157
00:11:06,789 --> 00:11:11,229
changes to the capacity planning
and seasonal demand shifts,

158
00:11:11,729 --> 00:11:13,679
model explainability, and trust.

159
00:11:14,129 --> 00:11:15,269
Why trust matters.

160
00:11:15,689 --> 00:11:20,159
Operators will not act on black box
predictions, especially when those

161
00:11:20,159 --> 00:11:25,049
actions involve significant operational
changes or resource allocation.

162
00:11:25,559 --> 00:11:30,809
Automation requests clear
justification for every decision in

163
00:11:30,809 --> 00:11:32,819
high stakes logistics and enrollment.

164
00:11:33,539 --> 00:11:37,379
A single false post can cost
thousands in unnecessary routing.

165
00:11:37,879 --> 00:11:42,604
A missed prediction can cost millions
in lost product or customer penalties.

166
00:11:43,104 --> 00:11:45,744
So some of them are SHAP values.

167
00:11:46,434 --> 00:11:51,264
Quantify each feature contribution
to individual predictions, showing

168
00:11:51,264 --> 00:11:56,964
exactly which factors throw the
alert, feature importance, rank input

169
00:11:56,964 --> 00:12:01,044
signals by their predictive power
across all historical incidents.

170
00:12:01,544 --> 00:12:07,489
Attention visualization for neural
networks display, which time windows the

171
00:12:07,489 --> 00:12:09,809
model focused on when making prediction.

172
00:12:10,309 --> 00:12:12,229
Counterfactual explanations.

173
00:12:12,769 --> 00:12:16,699
If the a p response time has
stayed below 500 milliseconds,

174
00:12:17,179 --> 00:12:18,889
this alert would not have fired.

175
00:12:19,389 --> 00:12:24,309
Operators receive actionable, credible
predictions with clear reasoning,

176
00:12:24,729 --> 00:12:29,019
enabling confident decision making,
and higher automation adoption

177
00:12:29,019 --> 00:12:31,859
rates, automation decision framework.

178
00:12:32,399 --> 00:12:34,594
Not all predictions should
trigger the same response.

179
00:12:35,444 --> 00:12:39,704
A risk based framework determines
when to automate, when to involve

180
00:12:39,704 --> 00:12:44,704
humans, and when to simply alert
fully automated risk level.

181
00:12:45,124 --> 00:12:48,634
Low conference required greater than 95%.

182
00:12:48,994 --> 00:12:54,754
Example, cash warmup, request
throttling, circuit break activation.

183
00:12:55,254 --> 00:12:59,989
Rational actions are reversible, low
cost, and have proven effectiveness.

184
00:13:00,489 --> 00:13:06,369
Alert only risk level, high
confidence required less than 80%.

185
00:13:07,029 --> 00:13:07,749
Examples.

186
00:13:08,199 --> 00:13:13,929
Major infrastructure changes, vendor
escalations, customer communications.

187
00:13:14,769 --> 00:13:20,169
Rational high stakes decisions require
full context and strategy consideration.

188
00:13:20,669 --> 00:13:21,779
Showman in that loop.

189
00:13:22,289 --> 00:13:26,954
Risk level, medium confidence
required 80 to 95%.

190
00:13:27,749 --> 00:13:33,059
Example, carrier rerouting inventory,
relocation and scaling conditions.

191
00:13:33,749 --> 00:13:39,029
Rational significant operational impact
requests, human judgment and approval.

192
00:13:39,529 --> 00:13:44,629
This framework evolves our time as
confidence improves actions initially

193
00:13:44,629 --> 00:13:50,179
requires human approval, can graduate
to full automation as trust builds

194
00:13:50,179 --> 00:13:51,919
through the demonstrated accuracy.

195
00:13:52,419 --> 00:13:53,889
Measuring the business impact.

196
00:13:54,399 --> 00:13:58,209
So what's the impact of the
system and on the business?

197
00:13:58,839 --> 00:14:03,159
So the impact is we are going to
avoid ma major incidents prevented,

198
00:14:03,729 --> 00:14:09,269
and we have we also have a cost for
the system investment and we have a

199
00:14:09,269 --> 00:14:14,729
cost for the annual cost avoidance
and we have the return of investment.

200
00:14:15,229 --> 00:14:15,559
Same.

201
00:14:15,559 --> 00:14:19,989
And these are some of the numbers which
I collected with few of the scenarios.

202
00:14:20,349 --> 00:14:25,439
And it clearly states that investing in
those these systems is going to prevent

203
00:14:25,439 --> 00:14:31,079
the incidents a lot, but even though there
is a cost for it, and the key metrics

204
00:14:31,079 --> 00:14:36,689
are prevention window hours of advanced
warning gained before outage impact.

205
00:14:37,189 --> 00:14:40,789
Severity reduction, decrease
in the customer facing downtime

206
00:14:40,879 --> 00:14:42,259
and service degradation.

207
00:14:43,129 --> 00:14:48,439
Percentage of predictions that don't
materialize into actual incidents and

208
00:14:48,439 --> 00:14:53,299
propagation of automated responses
that successfully prevent outages.

209
00:14:54,199 --> 00:14:58,689
Reduction in the time between failure,
initiation and alert, coming to

210
00:14:58,689 --> 00:15:00,819
the conclusions and key takeaways.

211
00:15:01,449 --> 00:15:06,579
Predictive observability fundamentally
shifts reliability engineering from

212
00:15:06,579 --> 00:15:10,539
reactive firefighting to prevent
maintenance, preventive maintenance.

213
00:15:11,079 --> 00:15:16,659
By detecting failures, signatures before
they manifest, organizations can transform

214
00:15:16,659 --> 00:15:19,389
potential outages into non-events.

215
00:15:19,889 --> 00:15:24,539
Paradigm shift move from reactive
incident response to proactive

216
00:15:24,539 --> 00:15:28,679
disruption prevention through
early detection and intervention.

217
00:15:29,489 --> 00:15:34,109
Transform outages early detection,
converts major incidents into

218
00:15:34,109 --> 00:15:38,519
minor hiccups, protecting customer
experience and business continuity.

219
00:15:39,019 --> 00:15:42,499
Scalable architecture, event
driven systems combined with

220
00:15:42,559 --> 00:15:47,749
explainable ml, create resilient
trustworthy prediction platforms.

221
00:15:48,709 --> 00:15:54,664
Proven results demonstrated
effectiveness across S Networks, a P

222
00:15:54,714 --> 00:15:57,229
ecosystems, and IOT sensor deployments.

223
00:15:57,729 --> 00:15:58,929
Implementation path.

224
00:15:59,889 --> 00:16:04,899
Start small with low risk use cases,
validate prediction to build trust,

225
00:16:05,349 --> 00:16:07,569
then progressively automate responses.

226
00:16:08,069 --> 00:16:11,849
And finally, the best incident
is the one that never happens.

227
00:16:12,839 --> 00:16:14,402
Thank you for giving me the opportunity.

