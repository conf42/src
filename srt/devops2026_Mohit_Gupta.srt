1
00:00:00,500 --> 00:00:01,370
Speaker 21: Hello everyone.

2
00:00:01,470 --> 00:00:03,270
My name is Mohi Gupta.

3
00:00:03,810 --> 00:00:08,010
I'm a staff GP performance
verification engineer at Intel.

4
00:00:08,889 --> 00:00:13,209
Today I will talk about how we can
make these GP performance a first

5
00:00:13,209 --> 00:00:18,154
class citizen in the CICD pipelines,
especially for the modern AI

6
00:00:18,154 --> 00:00:23,740
infrastructure where GPUs are expensive,
shared and performance sensitive.

7
00:00:24,699 --> 00:00:28,360
When I say CACD, that stands
for this continuous integration

8
00:00:28,449 --> 00:00:30,159
and continuous deployment.

9
00:00:30,659 --> 00:00:37,020
The key challenges with the GP performance
to scale is often discovered when

10
00:00:37,020 --> 00:00:39,419
you're, when you do after deployment.

11
00:00:39,960 --> 00:00:45,570
So at that point, the feedback
loops are slow and costly and the

12
00:00:45,570 --> 00:00:47,460
traditional post-deployment testing.

13
00:00:48,030 --> 00:00:53,970
Doesn't work well when GPUs are shared
across many workloads and teams.

14
00:00:54,470 --> 00:00:58,160
So when we say widely, the
performance validation matters.

15
00:00:58,339 --> 00:01:01,160
There are three main reasons this matters.

16
00:01:01,699 --> 00:01:03,470
The first one is the cost.

17
00:01:04,099 --> 00:01:08,990
So GPUs are major infrastructure
investments and regression,

18
00:01:08,990 --> 00:01:11,360
actually waste compute resources.

19
00:01:12,229 --> 00:01:13,910
The second one is the reliability.

20
00:01:14,839 --> 00:01:20,600
So AI workloads needs predictable
trainings and inference performances.

21
00:01:21,560 --> 00:01:24,020
And the third one is the early detection.

22
00:01:24,440 --> 00:01:28,670
So when you're catching issues in
the CACD, it prevents production

23
00:01:28,670 --> 00:01:32,330
incidents and keep teams moving fast.

24
00:01:32,829 --> 00:01:38,019
Going with this framework overview,
the solution we proposed is

25
00:01:38,019 --> 00:01:40,029
embedding GPU performance validation.

26
00:01:40,734 --> 00:01:42,714
Directly into the CICD.

27
00:01:43,404 --> 00:01:48,354
So when the framework focuses on GPU
micro architectural behaviors, and

28
00:01:48,354 --> 00:01:54,354
it reduces quantitative metrices,
automated performance gains, and all

29
00:01:54,354 --> 00:01:59,304
these observable signals that actually
persist throughout the deployment cycle.

30
00:01:59,804 --> 00:02:02,924
So understanding these workloads
characteristics, not all GP

31
00:02:02,924 --> 00:02:04,269
workloads behave the same.

32
00:02:04,769 --> 00:02:06,089
So there are two major ones.

33
00:02:06,149 --> 00:02:08,429
One is the compute bound
and then the memory bound.

34
00:02:08,879 --> 00:02:13,379
So if we talk about compute bound
workloads, they're dominated by

35
00:02:13,379 --> 00:02:19,259
math operations and expect high A LU
utilizations with low memory stalls.

36
00:02:20,039 --> 00:02:23,339
But when it comes to memory bound
workloads, they're limited to data

37
00:02:23,339 --> 00:02:30,404
movements such as cache misses, bandwidth
saturations access pattern, where it

38
00:02:30,404 --> 00:02:33,239
matters more than the actual raw compute.

39
00:02:33,739 --> 00:02:38,809
So the classification criteria for these
quantitative metrices, so we classify

40
00:02:38,809 --> 00:02:45,230
workloads using measurable GPU counters,
things like a LU utilization, cash hit

41
00:02:45,230 --> 00:02:52,070
rates, memory stall cycles, bandwidth,
the usage and coalescing efficiencies.

42
00:02:52,700 --> 00:02:56,299
So these gives us objective
signals instead of relying on

43
00:02:56,299 --> 00:02:58,849
subjective performance debugging.

44
00:02:59,349 --> 00:03:04,929
So the validation methodology uses
three categories of benchmarks.

45
00:03:05,259 --> 00:03:10,839
The first one is the dense linear
algebra for compute heavy AI workloads.

46
00:03:11,419 --> 00:03:15,529
The second one is irregular
memory access patterns such as

47
00:03:15,529 --> 00:03:18,229
graphs and spars operations.

48
00:03:18,499 --> 00:03:22,969
And the third most important one is
the hybrid workloads that combine both

49
00:03:22,969 --> 00:03:25,189
the compute and the memory behavior.

50
00:03:25,669 --> 00:03:28,489
To reflect real production systems.

51
00:03:29,329 --> 00:03:32,059
So let's go with compute
bound work workloads.

52
00:03:32,509 --> 00:03:40,009
So we have seen that, we can see that
the sustained A LU utilizations around

53
00:03:40,069 --> 00:03:42,709
85% in the compute bound workload.

54
00:03:43,279 --> 00:03:49,214
We have strong L one cash localities
and memory minimal memory stall cycles.

55
00:03:49,714 --> 00:03:53,105
So these results confirm that
are benchmark effectively.

56
00:03:53,435 --> 00:03:58,465
Stress compute pipelines without being
memory limited, but when we talk about

57
00:03:58,465 --> 00:04:05,815
memory bound results, the bandwidth
utilization reaches about 75, 70 5%, and

58
00:04:06,115 --> 00:04:11,545
we all see a clear difference between
structured and the irregular access

59
00:04:11,545 --> 00:04:16,255
patents, especially high coalescing
efficiencies for all the structure

60
00:04:16,255 --> 00:04:21,355
accesses, and much lower efficiencies
for irregular ones highlighting.

61
00:04:21,700 --> 00:04:25,239
The optimization opportunities
for these workloads.

62
00:04:25,739 --> 00:04:30,479
So the critical discovery is this
mixed workload interaction in which,

63
00:04:30,539 --> 00:04:35,339
when compute bound and memory bound
workloads run concurrently, so the

64
00:04:35,339 --> 00:04:40,289
performance degradation appears that
isolated testing completely misses.

65
00:04:40,919 --> 00:04:44,909
So cash, contentions, and
resource interference.

66
00:04:45,434 --> 00:04:51,434
Change performance behavior, which is why
mixed workload validation is essential.

67
00:04:51,934 --> 00:04:57,134
So implementing this automated
practice, this means we are defining

68
00:04:57,134 --> 00:05:03,434
performance gates in CICD, automating
benchmark executions in a control

69
00:05:03,434 --> 00:05:09,374
environment, and actually capturing
GPU Metricses as a part of every build.

70
00:05:10,034 --> 00:05:12,044
So the performance become code.

71
00:05:12,404 --> 00:05:14,984
Version, repeatable and enforceable.

72
00:05:15,484 --> 00:05:19,744
Some of the platform engineering
capabilities approach, if we talk

73
00:05:19,744 --> 00:05:25,294
about it, helps actually to prevent
regressions, gain continuous

74
00:05:25,324 --> 00:05:31,234
visibility into performance trends,
and actually shifts optimization

75
00:05:32,014 --> 00:05:34,114
earlier in the deployment cycle.

76
00:05:35,104 --> 00:05:38,224
So when the fixes are
cheaper and actually faster.

77
00:05:38,724 --> 00:05:45,024
The same metrics used for validation
feed directly into the observability.

78
00:05:45,564 --> 00:05:51,504
The GPU utilization trends, the bandwidth
saturations, the cash degradation alerts,

79
00:05:51,804 --> 00:05:56,994
and the workload mix actually give the
SRE teams the data they need to manage

80
00:05:56,994 --> 00:06:00,864
reliability and capacity proactively.

81
00:06:01,364 --> 00:06:06,704
So some of the key takeaways from
these for the platform teams, if

82
00:06:06,704 --> 00:06:10,484
I have to summarize, is the first
one is the embedded performance

83
00:06:10,484 --> 00:06:13,964
validation into the CICD.

84
00:06:14,464 --> 00:06:19,414
The second would be use quantitative
metricses to classify workloads.

85
00:06:19,864 --> 00:06:23,944
The most important that to test
mixed workloads, especially

86
00:06:23,944 --> 00:06:25,684
not just isolated benchmarks.

87
00:06:26,184 --> 00:06:30,564
And the fourth one is the to
build observable systems so

88
00:06:30,564 --> 00:06:35,904
that the GPU performance remains
predictable as AI platform scales.

89
00:06:36,804 --> 00:06:39,084
At last, I would like to
thank you for your time.

90
00:06:39,084 --> 00:06:42,804
I'm happy to take questions or discuss
how this approach can be adapted

91
00:06:43,464 --> 00:06:46,794
to our CACD and AI infrastructure.

92
00:06:47,424 --> 00:06:49,074
So thank you so much.

