1
00:00:00,480 --> 00:00:01,320
Hello everyone.

2
00:00:02,220 --> 00:00:03,300
Welcome to this session.

3
00:00:03,540 --> 00:00:11,940
My name is Ajani and I'm excited to
share my approach of how one of the

4
00:00:11,940 --> 00:00:17,700
most pressing challenges in telecom
industry assuring reliability in an

5
00:00:17,700 --> 00:00:23,715
increasingly complex environment as it
as telecom networks evolve and adapt.

6
00:00:24,215 --> 00:00:27,485
To cloud native architectures,
the traditional ways of

7
00:00:27,485 --> 00:00:31,145
monitoring and managing service
health are just not enough.

8
00:00:31,925 --> 00:00:38,295
This talk walks you through our transf
transformation from a reactive monitoring

9
00:00:38,295 --> 00:00:41,325
tool, proactive AI powered observability.

10
00:00:41,835 --> 00:00:42,585
Let's dive in.

11
00:00:43,085 --> 00:00:47,105
Before we dive, let me
share a quick story.

12
00:00:47,605 --> 00:00:48,834
A couple of years ago.

13
00:00:49,404 --> 00:00:51,294
We had a critical outage.

14
00:00:51,834 --> 00:00:54,355
We, and we were flooded with alerts.

15
00:00:54,444 --> 00:00:57,474
Dozens coming in from different systems.

16
00:00:57,955 --> 00:01:06,995
None of them are clear, so it took hours
to trace a root cause it turned out the

17
00:01:06,995 --> 00:01:10,925
signals were that there were days earlier.

18
00:01:11,705 --> 00:01:14,255
That moment made something clear.

19
00:01:14,375 --> 00:01:16,745
We don't need more alerts.

20
00:01:16,745 --> 00:01:17,375
We need.

21
00:01:17,780 --> 00:01:19,310
Better intelligence.

22
00:01:19,810 --> 00:01:21,430
So let's talk about scale.

23
00:01:21,760 --> 00:01:27,280
Telecom industry and telecom networks
can generate up to 25 terabytes

24
00:01:27,340 --> 00:01:29,605
of operational data each day.

25
00:01:30,105 --> 00:01:36,135
And the number is only growing
with 5G and iot as raises.

26
00:01:37,045 --> 00:01:38,515
But there is the problem.

27
00:01:38,905 --> 00:01:39,775
Here's the problem.

28
00:01:40,165 --> 00:01:46,945
Despite all the data, nearly 70%
of all the outages are preventable.

29
00:01:47,445 --> 00:01:52,365
We just don't have the right tooling
in place to catch early signals.

30
00:01:52,605 --> 00:01:56,265
Air helps bridge the
gap in our experience.

31
00:01:56,355 --> 00:02:01,965
Applying anomaly detection reduces
mean time to repair by over 40%,

32
00:02:02,565 --> 00:02:07,755
which is massive in an industry where
seconds of downtime costs millions.

33
00:02:08,255 --> 00:02:13,475
This sets the foundation of
our shift in mindset from data

34
00:02:13,475 --> 00:02:15,364
overload to data-driven action.

35
00:02:15,935 --> 00:02:19,204
And here's the bus, here's
the business reality.

36
00:02:20,135 --> 00:02:25,054
Every minute of telecom downtown
downtime can cost thousands,

37
00:02:25,475 --> 00:02:27,845
if not millions, garner.

38
00:02:28,660 --> 00:02:37,240
Gartner estimates the average
cost of around $55,600 per minute.

39
00:02:37,740 --> 00:02:41,070
When we reduce meantime to repair by 41%.

40
00:02:41,130 --> 00:02:47,430
It wasn't just a technical win, it was a
massive cost saving SLA boosting outcome.

41
00:02:47,930 --> 00:02:50,405
Traditional monitoring
has three big flaws.

42
00:02:50,690 --> 00:02:52,640
The first, it's reactive.

43
00:02:53,240 --> 00:02:54,950
We find issue after.

44
00:02:55,370 --> 00:02:57,560
They, it's already affected the users.

45
00:02:57,560 --> 00:03:04,190
Second, it's siloed means which
each part of the system, our network

46
00:03:04,220 --> 00:03:08,480
and infrastructure and applications
all are monitored separately.

47
00:03:09,079 --> 00:03:10,730
The third is context.

48
00:03:11,120 --> 00:03:16,994
So Alexa, based on narrow metrics without
any bigger picture to it to understand

49
00:03:17,444 --> 00:03:23,204
it makes this makes incident response
slower and troubleshooting harder.

50
00:03:23,999 --> 00:03:28,170
It's like trying to solve a puzzle
with half the pieces missing.

51
00:03:28,670 --> 00:03:31,579
Observability changes the game.

52
00:03:32,079 --> 00:03:38,410
Instead of focusing on predefined metrics
and thresholds, it's about understanding

53
00:03:38,410 --> 00:03:40,540
the system behavior as a whole.

54
00:03:41,040 --> 00:03:45,690
We collect telemetric data across
domains, metrics, logs, traces.

55
00:03:46,080 --> 00:03:52,200
Use AI to spot anomalies
before they become incidents.

56
00:03:52,700 --> 00:03:57,579
So dynamic baselining helps
us to avoid alert storms of.

57
00:03:58,449 --> 00:04:02,859
From normal fluctuations, while
self-learning models continuously

58
00:04:02,859 --> 00:04:07,840
evolve, this allows us to
predict, prevent, and self-heal.

59
00:04:08,199 --> 00:04:13,069
It's not just a monitoring monitoring
anymore, it's just it's intelligent

60
00:04:13,069 --> 00:04:15,889
service assistance or assurance.

61
00:04:16,390 --> 00:04:21,640
So how does AI enhance the
observability components?

62
00:04:22,240 --> 00:04:28,920
So AI enhance observability has
four pillars, metrics, so high

63
00:04:29,460 --> 00:04:32,010
dimensional time series data.

64
00:04:32,970 --> 00:04:38,490
So where subtle shifts in can
reveal performance degradations,

65
00:04:39,330 --> 00:04:41,070
and we can also have traces.

66
00:04:41,430 --> 00:04:45,840
These traces provide end-to-end
visibility into service

67
00:04:45,840 --> 00:04:48,480
requests across microservices.

68
00:04:48,600 --> 00:04:53,059
Invaluable in modern cloud
native systems and logs.

69
00:04:53,479 --> 00:04:57,739
The story behind the numbers,
offering a rich context with error

70
00:04:57,739 --> 00:05:00,020
codes stacked tracings, and more.

71
00:05:00,520 --> 00:05:02,770
And then comes to a analysis.

72
00:05:03,100 --> 00:05:04,150
This is the brain.

73
00:05:04,240 --> 00:05:09,130
It co co. It correlates all the
data across the data types and

74
00:05:09,130 --> 00:05:14,200
identifies patterns, predictive
issues, and then prescribes fixes.

75
00:05:14,590 --> 00:05:20,230
Together these elements give us real
time con, contextual and predictive

76
00:05:20,230 --> 00:05:22,120
insights into service health.

77
00:05:22,620 --> 00:05:26,640
Let me get a bit more
technical for metrics we use.

78
00:05:26,730 --> 00:05:33,270
We used LSTM based models to understand
the temporal anomalies for logs.

79
00:05:33,270 --> 00:05:36,810
We applied natural language
processing to surface meaningful

80
00:05:36,810 --> 00:05:39,000
patterns across unstructured data.

81
00:05:39,500 --> 00:05:43,460
This hybrid approach
combining the structured time.

82
00:05:44,345 --> 00:05:48,695
Series with unstructured logs
lets us correlate signals across

83
00:05:48,695 --> 00:05:53,705
the systems in a way that the
traditional tools could not match.

84
00:05:54,205 --> 00:05:54,565
Okay.

85
00:05:54,595 --> 00:06:00,055
Our journey started with building the
data foundation, so aggregating 18

86
00:06:00,055 --> 00:06:03,295
months of telemetry from various systems.

87
00:06:03,355 --> 00:06:07,705
Then we trained deep learning
models specific to telecom

88
00:06:07,705 --> 00:06:12,085
patterns, which is very different
from standard enterprise data.

89
00:06:13,045 --> 00:06:18,055
Next, we integrated tracing
every layer from hardware to.

90
00:06:18,555 --> 00:06:19,485
Virtual functions.

91
00:06:19,545 --> 00:06:24,555
And most importantly, we work to
work closely with the ops team to

92
00:06:24,555 --> 00:06:27,135
continuously refine that what we build.

93
00:06:27,635 --> 00:06:34,435
It was a feedback driven loop, test,
learn, improve, so it, so the loop

94
00:06:34,435 --> 00:06:41,185
was essential for building and driving
the adoption, but the biggest hurdle.

95
00:06:41,890 --> 00:06:45,580
Wasn't the just the tech,
so it was the culture.

96
00:06:46,119 --> 00:06:47,859
People were skeptical, obviously.

97
00:06:48,010 --> 00:06:52,330
So we bought Operation
Team on from the day one.

98
00:06:52,869 --> 00:06:55,780
So we didn't just build
tools for operation team,

99
00:06:55,780 --> 00:06:58,090
we built with them for them.

100
00:06:58,509 --> 00:07:03,159
So they tested the models, flagged the
false positives, and suggested new inputs.

101
00:07:03,659 --> 00:07:06,570
So that buy-in changed everything.

102
00:07:07,070 --> 00:07:13,599
So let's talk outcomes first, we saw
a major boost in detection, accuracy.

103
00:07:13,749 --> 00:07:17,229
We were catching issues
we never saw before.

104
00:07:17,829 --> 00:07:23,699
Mean meantime to repair dropped,
which meant fewer escalations

105
00:07:23,699 --> 00:07:25,439
and faster resolutions.

106
00:07:25,939 --> 00:07:29,780
And we also saw fewer service
impacting incidents overall.

107
00:07:30,280 --> 00:07:35,440
And because our alerts were
very more accurate, the ops team

108
00:07:35,440 --> 00:07:37,780
experienced less test fatigue.

109
00:07:38,280 --> 00:07:39,450
Alert fatigue, sorry.

110
00:07:40,020 --> 00:07:45,165
So this could focus on real
problems, not chasing the.

111
00:07:45,794 --> 00:07:52,034
Ghosts From business perspective, this
translated into better SLAs, happier

112
00:07:52,034 --> 00:07:54,525
customers, and real operational savings.

113
00:07:55,025 --> 00:07:58,595
Of course, this did not
come without challenges.

114
00:07:59,015 --> 00:08:05,425
First, there is a large data volume
to handle terabytes of data per day.

115
00:08:05,755 --> 00:08:10,015
We had to implement edge filtering and
intelligent sampling without losing.

116
00:08:10,515 --> 00:08:13,095
And cross domain core correlation.

117
00:08:13,215 --> 00:08:18,705
We developed a unified entity model
to that tied together infrastructure,

118
00:08:18,885 --> 00:08:20,430
virtual functions, and services.

119
00:08:20,930 --> 00:08:28,160
And on top of that, we had an explainable
e ai, which we built using visual tools

120
00:08:28,250 --> 00:08:34,419
that led operations to see why there was
an alert trigger, improving the trust

121
00:08:34,419 --> 00:08:37,479
and cutting the false positives by 27%.

122
00:08:38,140 --> 00:08:43,329
Overall, these made our solution
usable, scalable, and real world

123
00:08:43,959 --> 00:08:45,520
in the real world environment.

124
00:08:46,020 --> 00:08:49,200
So here's what the
architecture looked like.

125
00:08:49,700 --> 00:08:51,319
So there is a data layer.

126
00:08:51,680 --> 00:08:56,360
Distributed agents collected high
fidelity telemetry from across the

127
00:08:56,360 --> 00:09:01,130
network, and then there is this
processing and analytical layer.

128
00:09:01,189 --> 00:09:05,540
We used stream processing
with ML pipelines to analyze

129
00:09:05,540 --> 00:09:06,770
the data in real time.

130
00:09:07,639 --> 00:09:09,949
Then there is knowledge
and automation layer.

131
00:09:10,400 --> 00:09:17,270
This layer drove automation, auto
remediation, and model refinement.

132
00:09:18,170 --> 00:09:24,199
This structure ensured we could scale the
whole positive response and enable closed

133
00:09:24,199 --> 00:09:27,680
loop operations with no human in the loop.

134
00:09:28,180 --> 00:09:33,909
Then if achieving this fineness
reliability in the holy Grail.

135
00:09:34,824 --> 00:09:40,744
Holy Grail in telecom, our observability,
a lube based help us helped us

136
00:09:40,744 --> 00:09:47,255
here we went from anomaly detection
to root cause analysis with auto

137
00:09:47,255 --> 00:09:49,744
remediation and back to back learning.

138
00:09:49,775 --> 00:09:52,114
Each incident made the system smarter.

139
00:09:52,775 --> 00:09:58,714
This closed loops feedback, that is
what allowed us to quickly recover

140
00:09:58,714 --> 00:10:01,275
and improve the system continuously.

141
00:10:01,775 --> 00:10:07,345
For anyone who wants to start this journey
as a, here is the roadmap to follow.

142
00:10:07,885 --> 00:10:13,155
Assess your current stack and identify
where you lack observability, and

143
00:10:13,155 --> 00:10:18,285
then pilot one domain to validate
your architecture and models.

144
00:10:18,785 --> 00:10:24,275
Then from there you have to scale
the solution gradually, making sure

145
00:10:24,275 --> 00:10:30,635
the data is unified across domains,
and then automate remediation.

146
00:10:30,665 --> 00:10:35,755
Using AI to truly close the loop,
a phase approach lets you build

147
00:10:35,755 --> 00:10:41,005
momentum, demonstrate value, and
then reduce deployment risks.

148
00:10:41,505 --> 00:10:43,695
And that brings us to the end.

149
00:10:44,610 --> 00:10:49,920
So we've seen how observability,
when combined with AI, turns raw

150
00:10:49,920 --> 00:10:52,170
data into actionable intelligence.

151
00:10:52,500 --> 00:10:54,750
This just isn't about cool tech.

152
00:10:55,050 --> 00:10:59,599
It's about delivering more
reliable, scalable services

153
00:10:59,599 --> 00:11:01,459
to the people who count on us.

154
00:11:02,390 --> 00:11:06,770
And thanks so much for
watching, and if you'd like to

155
00:11:06,770 --> 00:11:08,314
connect or have any questions.

156
00:11:08,814 --> 00:11:12,025
Please feel free to
connect our chat with me.

157
00:11:12,085 --> 00:11:14,095
I will allow that and thank you.

