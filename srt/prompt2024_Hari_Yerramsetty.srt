1
00:00:00,290 --> 00:00:04,600
My name is Hari Ramshetty
and I'm a software engineer

2
00:00:04,630 --> 00:00:05,979
on the infrastructure team.

3
00:00:06,560 --> 00:00:12,780
today I'll be talking about cloud
cost optimizations and how you can

4
00:00:12,789 --> 00:00:17,889
use FinOps and FinOps practices
to reduce your AWS cloud costs.

5
00:00:18,389 --> 00:00:22,150
Today I'll also touch briefly
on how you can use AI powered

6
00:00:22,220 --> 00:00:25,480
tools like ChargerBT, cloud.

7
00:00:25,884 --> 00:00:29,775
Gemini and Llama to help
you reduce the cloud cost.

8
00:00:30,154 --> 00:00:35,815
I'll also touch briefly on the AI
agentic approach using the Lang chain

9
00:00:35,895 --> 00:00:41,254
and crew AI where you can build your
own agents that will help you with

10
00:00:41,755 --> 00:00:43,844
the cloud cost optimization process.

11
00:00:44,294 --> 00:00:45,549
I'm excited for this talk.

12
00:00:45,980 --> 00:00:47,580
So let's just get started.

13
00:00:48,339 --> 00:00:49,550
some introductions.

14
00:00:49,990 --> 00:00:54,779
I'll be going through, introducing what
is a cloud native cost optimization.

15
00:00:55,220 --> 00:00:58,780
What are some of the cost drivers
in cloud native platforms?

16
00:00:59,245 --> 00:01:01,615
What are some of the resource
management techniques?

17
00:01:02,115 --> 00:01:07,565
some container and serverless
optimization, some storage and

18
00:01:07,565 --> 00:01:10,765
data management, monitoring
and cost observability.

19
00:01:11,305 --> 00:01:12,265
what is finops?

20
00:01:12,565 --> 00:01:15,565
A cultural approach to
what cost optimization.

21
00:01:16,275 --> 00:01:19,960
And then I'll deep dive into
leveraging prompt engineering and

22
00:01:20,025 --> 00:01:22,185
finops to drive cloud efficiency.

23
00:01:22,995 --> 00:01:24,615
So let's get started.

24
00:01:25,525 --> 00:01:27,585
So the first thing is.

25
00:01:28,085 --> 00:01:29,785
Like what is a cloud native platform?

26
00:01:30,665 --> 00:01:36,615
The cloud native platform
is a platform that lets you

27
00:01:36,805 --> 00:01:41,724
build and deploy applications
seamlessly on the public cloud.

28
00:01:42,224 --> 00:01:48,114
It can be on any container orchestration
platform like Kubernetes, ECS or EKS.

29
00:01:48,614 --> 00:01:51,874
You have AKS for Azure
Community Service or GCP.

30
00:01:52,084 --> 00:01:53,774
So whatever the public cloud may be.

31
00:01:54,274 --> 00:01:56,434
So those are called as
cloud related platforms.

32
00:01:56,664 --> 00:01:59,064
So this is where you
deploy your applications.

33
00:01:59,794 --> 00:02:05,744
And these environments tend to be dynamic
and complex in nature because setting up

34
00:02:05,754 --> 00:02:10,694
requires like you need to set up a VPC,
you need to set up a security groups, you

35
00:02:10,694 --> 00:02:16,314
need to set up a whole bunch of virtual
networking, and also you need to deploy

36
00:02:16,314 --> 00:02:22,004
the deploy and maintain the virtual
machines, which we call EC2 instances.

37
00:02:22,524 --> 00:02:25,844
so each cloud providers
have their own terminology.

38
00:02:26,124 --> 00:02:28,524
At the end of the day, it's
just like virtual machines.

39
00:02:29,024 --> 00:02:34,254
so some of the statistics show that,
30 percent of the cloud spending is

40
00:02:34,254 --> 00:02:36,504
basically due to resource mismanagement.

41
00:02:37,054 --> 00:02:43,184
And this tends to be true, because
you often have engineering teams, who

42
00:02:43,424 --> 00:02:48,594
spin up these instances, spin up the
new databases for testing purposes.

43
00:02:49,554 --> 00:02:55,214
they tend to build new features, which are
sometimes abandoned because the business

44
00:02:55,214 --> 00:03:00,534
doesn't require them and they're never
turned off or decommissioned properly.

45
00:03:00,984 --> 00:03:04,559
this is the source of the problem.

46
00:03:05,060 --> 00:03:10,940
Like increasing cloud cost and, the
objective of this presentation covers

47
00:03:10,950 --> 00:03:17,730
strategies for optimizing costs in
cloud entity setups and also enabling

48
00:03:17,730 --> 00:03:22,465
financial responsibility without
compromising on agility or scalability.

49
00:03:23,455 --> 00:03:25,865
So let's get started.

50
00:03:26,365 --> 00:03:29,575
So what are some of the cost
drivers in cloud native platforms?

51
00:03:29,865 --> 00:03:34,514
The first thing that comes to our
mind is virtual machines, compute.

52
00:03:35,414 --> 00:03:38,154
So compute comes in
various different forms.

53
00:03:38,355 --> 00:03:45,825
It can be like easy to virtual machines
that are managed by us or it can be

54
00:03:45,955 --> 00:03:51,644
like a lambda, like function as a
service that can be, managed by AWS.

55
00:03:51,645 --> 00:03:52,204
AWS.

56
00:03:52,704 --> 00:03:58,224
So for the virtual machines that are
managed by us, like the cloud providers

57
00:03:58,264 --> 00:04:00,774
give us a variety of virtual machines.

58
00:04:01,364 --> 00:04:08,324
They're like the smaller virtual
machines and some are like a very

59
00:04:08,334 --> 00:04:12,064
resource intensive, CPU intensive or
memory intensive virtual machines.

60
00:04:12,564 --> 00:04:20,534
Now each have their own pricing model
and, Data like they tend to be more

61
00:04:20,614 --> 00:04:22,794
expensive, as they scale vertically.

62
00:04:23,294 --> 00:04:30,724
Now, the serverless executions are
a tricky bit because it lets you

63
00:04:30,814 --> 00:04:32,744
execute a function as a service.

64
00:04:32,764 --> 00:04:39,474
But if you call that function like 100,
000 times, it tends to get expensive.

65
00:04:39,754 --> 00:04:44,334
So there's no benefit of
using function as a service.

66
00:04:45,144 --> 00:04:47,884
when you're calling it frequently.

67
00:04:48,384 --> 00:04:52,324
So the next type of, the
cost driver is storage.

68
00:04:52,554 --> 00:04:54,764
Storage comes in three forms.

69
00:04:55,224 --> 00:05:02,644
You have block storage, you have object
storage, and you have RDS, databases.

70
00:05:03,464 --> 00:05:05,924
Now the object storage is S3.

71
00:05:06,084 --> 00:05:08,714
So S3 is pretty scalable.

72
00:05:09,034 --> 00:05:13,074
So we tend to fill up our
S3 buckets with S3 buckets.

73
00:05:13,389 --> 00:05:19,039
We have a bucket sprawl, where we
store tons, like terabytes of data.

74
00:05:19,629 --> 00:05:23,339
Sometimes this data is used,
sometimes it's not used.

75
00:05:23,809 --> 00:05:29,109
we tend to ship most of our logs
into these buckets, and these

76
00:05:29,109 --> 00:05:30,739
are put in sanity arguments.

77
00:05:31,359 --> 00:05:38,619
And if we forget to put a lifecycle
policy on this, it tends to get expensive.

78
00:05:39,249 --> 00:05:45,349
That is one of the cost drivers
and it applies the same for AWS

79
00:05:45,909 --> 00:05:47,849
block store like EBS volumes.

80
00:05:48,329 --> 00:05:53,099
So every virtual machine has a
block store, like EBS volumes.

81
00:05:53,569 --> 00:05:57,859
You delete the virtual machine,
but you don't delete the volumes.

82
00:05:57,889 --> 00:06:03,909
The volume is still available, but it's
detached from the eStroke machine, but you

83
00:06:03,909 --> 00:06:06,679
are still being charged for the storage.

84
00:06:07,619 --> 00:06:10,309
The next one is RDS databases.

85
00:06:11,109 --> 00:06:18,679
the databases are like Aurora PostgreSQL
or like similar such databases.

86
00:06:19,399 --> 00:06:24,269
sometimes these databases are over
provisioned with much higher IOPS.

87
00:06:24,929 --> 00:06:31,189
like you don't need that scale
of RDS databases because you

88
00:06:31,189 --> 00:06:32,469
don't have that much volume.

89
00:06:33,089 --> 00:06:39,219
We tend to over provision things because
we expect the volume to grow someday.

90
00:06:39,749 --> 00:06:43,489
But that is a problem for the another day.

91
00:06:43,989 --> 00:06:46,819
The next cost driver is data transfer.

92
00:06:47,319 --> 00:06:53,019
So Data transfer charges are
often overlooked because they

93
00:06:53,649 --> 00:06:55,839
Creep up in your AWS cloud.

94
00:06:56,649 --> 00:07:01,819
So think of this as in an organization
It's not just like one single account

95
00:07:02,559 --> 00:07:05,169
you have 10 different accounts.

96
00:07:05,389 --> 00:07:06,259
Some are broad.

97
00:07:06,259 --> 00:07:07,299
Some are non prod.

98
00:07:07,689 --> 00:07:14,204
You have one account per team You And
they have their own VPC and they want to

99
00:07:14,204 --> 00:07:16,569
connect to another VPC in another account.

100
00:07:16,899 --> 00:07:20,689
You have the NAT gateways, you have
the transfer gateways, you do VPC

101
00:07:20,689 --> 00:07:24,029
peering, you do cross AZ transfers.

102
00:07:24,279 --> 00:07:28,519
there are multiple different
layers of networking abstractions

103
00:07:29,039 --> 00:07:33,429
that is, that really blends this.

104
00:07:34,354 --> 00:07:42,584
Data transfer, charges you don't
expect these charges to be like, simple

105
00:07:43,084 --> 00:07:48,664
There's okay cut here so the next one is
data transfer charges So the data transfer

106
00:07:48,724 --> 00:07:55,079
charges are the cost from network egress
charges, which is if you have multiple,

107
00:07:55,389 --> 00:07:59,739
AWS accounts in an organization and
each account has its own VPC and you're

108
00:07:59,739 --> 00:08:06,209
trying to connect these VPCs using net
gateways or VPC pairings and you have

109
00:08:06,509 --> 00:08:10,949
applications in multiple different VPCs
trying to continues to talk to each other.

110
00:08:11,629 --> 00:08:17,610
There's a charge for that, and these, if
not control, these charges tend to be.

111
00:08:18,369 --> 00:08:21,789
increasing if there's, for
example, there's a spike in a

112
00:08:21,789 --> 00:08:27,099
traffic, from one VPC to another,
you see a data transfer charges.

113
00:08:28,009 --> 00:08:31,399
The next one, the most probably
is a third party services.

114
00:08:31,969 --> 00:08:36,759
So all the cloud providers,
provide, third party APIs.

115
00:08:37,064 --> 00:08:41,594
Through their portal and basically they
have their own subscription models.

116
00:08:41,604 --> 00:08:47,144
For example, you have red hat licenses
for the ec2 machines That are provisioned

117
00:08:47,644 --> 00:08:55,134
through aws account now these Sometimes
these licenses are managed through

118
00:08:55,294 --> 00:09:01,174
your cloud provider but if not managed
properly these tend to Add additional

119
00:09:01,194 --> 00:09:03,344
burden to your AWS cloud build.

120
00:09:03,844 --> 00:09:05,884
So what are the common challenges?

121
00:09:05,894 --> 00:09:11,234
So these challenges are pretty much
common over entire cloud architectures.

122
00:09:11,764 --> 00:09:13,184
One is over provisioning.

123
00:09:13,864 --> 00:09:20,214
So over provisioning means you're
over provisioning, compute for the

124
00:09:20,254 --> 00:09:23,344
application that it doesn't require.

125
00:09:23,864 --> 00:09:31,389
So you are giving excessive resources
To the applications and this

126
00:09:31,989 --> 00:09:37,429
causes so for example, you have an
application that uses like only 10

127
00:09:37,439 --> 00:09:41,969
percent of the CPU and you are And the
remaining 90 percent of the cpu time

128
00:09:41,969 --> 00:09:44,519
is under that is over provisioning.

129
00:09:45,019 --> 00:09:53,579
The second one is lack of visibility so
Resource usage is not often clear because

130
00:09:54,079 --> 00:09:58,819
It's easy for, in the cloud providers
make it easy for you to provision

131
00:09:58,829 --> 00:10:05,779
resources and you don't see the impact of
provisioning these resources immediately.

132
00:10:06,149 --> 00:10:13,739
Until you get a bill at the end of the
month, so There is not an instant alert

133
00:10:14,309 --> 00:10:20,399
that lets you know that okay this action
that I have taken Is increasing the

134
00:10:20,399 --> 00:10:26,319
cloud cost so the lack of visibility
is often one of the common challenges

135
00:10:27,079 --> 00:10:29,399
There's multi cloud complexity.

136
00:10:29,539 --> 00:10:36,159
So Most of the organizations are on
single, cloud provider, but there are

137
00:10:36,949 --> 00:10:43,729
other, organizations that do multi cloud,
where some of those resources are on AWS

138
00:10:43,729 --> 00:10:45,349
and some of the resources are on GCP.

139
00:10:46,139 --> 00:10:52,019
we had an instance where, some of the
engineers were working on a hackathon

140
00:10:52,249 --> 00:10:56,959
project, and, This was like three
years ago and they forgot to turn

141
00:10:56,959 --> 00:11:04,539
off the instances in like the google
cloud account because most of our Work

142
00:11:04,669 --> 00:11:06,549
goes in one single cloud provider.

143
00:11:06,579 --> 00:11:12,249
It's hard to keep track of all the
resources in a multi cloud environment

144
00:11:12,749 --> 00:11:18,959
so resource managing techniques Right
sizing so right sizing ensures that

145
00:11:19,059 --> 00:11:21,159
the allocation matches the workload.

146
00:11:21,659 --> 00:11:26,304
So You There are multiple
tools that help us do this.

147
00:11:26,484 --> 00:11:29,644
There's And this works on
various different levels.

148
00:11:29,744 --> 00:11:35,459
So for example, you have AWS tools
like AWS trusted advisor Which lets you

149
00:11:35,459 --> 00:11:41,849
know, okay, these are the databases that
haven't had connections in the past few

150
00:11:41,849 --> 00:11:46,939
days or These are the idle instances
that are not getting any traffic.

151
00:11:47,309 --> 00:11:51,999
These are the idle EBS volumes Which
are not attached to any EC2 instances.

152
00:11:52,379 --> 00:11:58,939
So The AWS Trusted Advisor is such
a tool that's really helpful for

153
00:11:58,939 --> 00:12:03,649
you to know which resources are
not used anymore so that you can

154
00:12:03,649 --> 00:12:06,079
deprovision them appropriately.

155
00:12:06,579 --> 00:12:12,309
And also the right sizing, I would,
and when it comes to containers,

156
00:12:12,309 --> 00:12:16,079
so the right sizing, like for
example, you have Kubernetes.

157
00:12:16,494 --> 00:12:21,974
And kubernetes has limits and requests
so requests make sure that you have

158
00:12:21,974 --> 00:12:27,424
certain amount of cpu and memory And
there's a limit so, understanding how

159
00:12:27,424 --> 00:12:32,274
much your application needs Because you
have the observability tools in the mix.

160
00:12:32,584 --> 00:12:37,554
So once you have these observability
tools you can Say, Hey, how much,

161
00:12:37,554 --> 00:12:40,024
this is the amount of CPU that I need.

162
00:12:40,044 --> 00:12:44,714
I don't need one gig, memory
and five virtual CPUs.

163
00:12:45,214 --> 00:12:48,034
I can just get by one virtual CPU.

164
00:12:48,449 --> 00:12:49,369
And like 4.

165
00:12:49,469 --> 00:12:50,709
5 gigs of RAM.

166
00:12:51,189 --> 00:12:56,969
Now this, so understanding what
your application requires and

167
00:12:57,209 --> 00:13:02,039
appropriately setting those
configurations is rightsizing.

168
00:13:02,959 --> 00:13:03,499
Autoscaling.

169
00:13:03,779 --> 00:13:09,019
So autoscaling is dynamically adjusting
your resources based on real time demand.

170
00:13:10,019 --> 00:13:17,639
And this is much more impractical scenario
applied on various levels of abstraction.

171
00:13:18,079 --> 00:13:23,394
So AWS provides what's called as
an auto scaling group where like

172
00:13:23,394 --> 00:13:28,624
you can provision more nodes in
the cluster Like automatically

173
00:13:28,624 --> 00:13:30,154
based on a certain threshold.

174
00:13:30,754 --> 00:13:36,904
So for example, let's just say you have 10
ec2 instances In an auto scaling loop and

175
00:13:36,914 --> 00:13:41,364
you have a spike in traffic because you
are running some thanksgiving Promotion

176
00:13:41,554 --> 00:13:47,169
and you're expecting these traffic
to go up and you need more instances.

177
00:13:47,529 --> 00:13:52,599
Now setting an autoscaling group and
letting it expand, let the autoscaling

178
00:13:52,599 --> 00:13:57,729
group add more nodes to deploy
applications like, horizontal scalability

179
00:13:58,209 --> 00:14:03,479
is called autoscaling and basically you
need to be aggressive with autoscaling.

180
00:14:03,719 --> 00:14:09,834
You have to set up proper thresholds
because once It's not just scale up.

181
00:14:09,834 --> 00:14:13,194
You should also scale down
once the peak is over.

182
00:14:13,694 --> 00:14:16,304
The next one is instance types.

183
00:14:16,514 --> 00:14:22,314
So one of the instance types that all
the cloud provider I think all the cloud

184
00:14:22,314 --> 00:14:24,224
providers provide is like spot instances.

185
00:14:25,114 --> 00:14:30,734
So spot instances are like much cheaper
than the regular instances, but they

186
00:14:30,764 --> 00:14:38,004
don't Guarantee the availability they
come at much lesser cost but They can

187
00:14:38,014 --> 00:14:43,944
be terminated at any point of time by
your cloud provider Now these, spot

188
00:14:43,944 --> 00:14:48,974
instances are pretty much useful for
various different tasks like CICD,

189
00:14:48,974 --> 00:14:53,204
you have like batch processing, where
you have the one off job where you

190
00:14:53,204 --> 00:14:58,654
want to process a bunch of records
and you spin up these spot instances.

191
00:14:59,154 --> 00:15:00,564
The next one is reserved instances.

192
00:15:00,574 --> 00:15:05,599
So reserved instances are ones you know
that you need a minimum number of records.

193
00:15:06,299 --> 00:15:12,489
instances in your autoscaling group
or your cluster and instead of like

194
00:15:12,489 --> 00:15:16,819
dynamically provisioning it you said,
Hey, I need this number of cbus at all

195
00:15:16,899 --> 00:15:22,569
time And that's when you go to your cloud
provider and say hey, I need this compute

196
00:15:22,569 --> 00:15:30,039
365 days 24 hours a day And that's when
you go to the reserved instances to make

197
00:15:30,039 --> 00:15:37,549
sure like you get a long term discount
and of course Like that's the best for the

198
00:15:38,279 --> 00:15:44,734
applications that run 365 days 24 hours
And the second one is on demand instances.

199
00:15:44,994 --> 00:15:49,234
So the on demand instances are
used for short term variable needs.

200
00:15:49,274 --> 00:15:52,744
As you all know, this is the most common
type of the easy to use instances that

201
00:15:52,744 --> 00:15:55,054
we use, in our cloud architectures.

202
00:15:55,554 --> 00:16:00,824
So one more thing I want to talk about
here is the density optimization.

203
00:16:01,454 --> 00:16:05,709
so in containers and serverless,
Models, you have a container

204
00:16:06,069 --> 00:16:07,259
that runs your application.

205
00:16:07,259 --> 00:16:13,059
You have a bunch of various small tiny
containers that run on a single node.

206
00:16:13,579 --> 00:16:19,309
So thanks to docker and kubernetes
Building and deploying containers has

207
00:16:19,309 --> 00:16:26,959
become pretty much easy, for everyone
and also like Integrating kubernetes

208
00:16:27,709 --> 00:16:32,464
has proven to be a substantial
feature cost savings, for the cloud.

209
00:16:32,854 --> 00:16:35,584
one such thing is the
density optimization.

210
00:16:35,794 --> 00:16:41,444
density optimization means you include
more number of containers per node.

211
00:16:42,124 --> 00:16:49,884
you provision, one big node and basically,
deploy multiple small containers or,

212
00:16:50,324 --> 00:16:56,724
configure your Kubernetes, to deploy
these applications on like a single node.

213
00:16:57,074 --> 00:17:02,769
So that is density optimization like
More number of, pods on a single node.

214
00:17:03,169 --> 00:17:09,109
So this helps you like use less
nodes, but also like you have

215
00:17:09,339 --> 00:17:10,899
like more number of containers.

216
00:17:11,319 --> 00:17:16,119
There's no idle CPU time or idle
memory that gets wasted here.

217
00:17:16,849 --> 00:17:19,599
So the next one is node autoscaling.

218
00:17:20,129 --> 00:17:24,459
So the node autoscaling, as we talked
before, it's similar to, auto scaling

219
00:17:24,459 --> 00:17:29,209
group you as you get more and more
demand, you add different nodes.

220
00:17:29,669 --> 00:17:34,019
So in the Kubernetes, environments,
we use, carpenter, one of the

221
00:17:34,019 --> 00:17:37,199
cluster, and also there is a cluster
auto scaler, which adds the nodes.

222
00:17:37,699 --> 00:17:38,949
To kubernetes

223
00:17:39,449 --> 00:17:43,169
and also There are some of
the optimizations that you

224
00:17:43,169 --> 00:17:45,679
can do is execution times.

225
00:17:46,059 --> 00:17:51,469
So One other thing is we want to see like
for example, if there is a job kubernetes

226
00:17:51,569 --> 00:17:58,249
job that's running in a pod and Basically
that part is stuck in a flashback loop.

227
00:17:58,749 --> 00:17:59,169
Now.

228
00:17:59,199 --> 00:18:06,439
We need to keep track of these
Restarts And make sure that this

229
00:18:06,439 --> 00:18:11,289
don't occur because Oftentimes,
this is a wastage of resource.

230
00:18:11,369 --> 00:18:16,249
So a single kubernetes job is
supposed to perform a job and then

231
00:18:16,749 --> 00:18:19,539
Just complete it the part should die.

232
00:18:20,039 --> 00:18:24,989
and the other one is reducing idle
times so implement efficient cold

233
00:18:24,999 --> 00:18:30,199
start strategies to minimize idle
costs, so Whenever there's a new part

234
00:18:30,199 --> 00:18:33,874
spins up you have the application
inside it running You The application

235
00:18:33,874 --> 00:18:39,634
needs to spin up whatever the JVM or
other, software that it needs to run.

236
00:18:40,094 --> 00:18:46,464
so we, we can do some strategies at the
application layer to reduce the idle time.

237
00:18:46,964 --> 00:18:48,584
Next one is code optimization.

238
00:18:48,584 --> 00:18:52,624
So minimum minimize dependencies and
optimize code for better memory and

239
00:18:52,624 --> 00:18:57,934
cpu usage you can take a look at the
flame graphs Like see if there's any

240
00:18:57,954 --> 00:19:02,384
like potential memory leaks in your
application and fix those there's

241
00:19:03,304 --> 00:19:07,464
These are the smaller optimizations,
but overall they compound to,

242
00:19:07,974 --> 00:19:10,314
significant cost optimizations.

243
00:19:10,814 --> 00:19:12,314
The storage and data management.

244
00:19:12,424 --> 00:19:16,534
So one of the things that we can
do for cloud cost optimization is

245
00:19:16,554 --> 00:19:21,894
implement policies, to move data across
storage tiers based on expertise.

246
00:19:22,374 --> 00:19:27,524
For example, you have, Like a doc that
you want to store for the compliance

247
00:19:27,524 --> 00:19:31,144
reasons, but it's not Accessed frequently.

248
00:19:31,314 --> 00:19:32,154
So what do you do?

249
00:19:32,644 --> 00:19:41,134
You store it in a like less accessed
year, which is lesser cost and basically

250
00:19:41,934 --> 00:19:47,204
you implement a lifecycle policy where
An object you can it might be a document

251
00:19:47,214 --> 00:19:52,484
or any other it's a log file like it's
goes through a different phases of

252
00:19:52,524 --> 00:20:02,344
tiers And it's stored in archived, and
this helps you reduce like the storage

253
00:20:02,424 --> 00:20:06,174
cost for S3 or other object storage.

254
00:20:06,884 --> 00:20:12,374
The other thing that we can do is
data compression and deduplication.

255
00:20:12,794 --> 00:20:17,959
So techniques like data deep compression,
And the application reduced storage needs.

256
00:20:18,529 --> 00:20:23,229
basically because you have a hundred
DB file, you can just compress

257
00:20:23,229 --> 00:20:28,549
it aggressively to make sure like
you have 10 GB or 20 GB file.

258
00:20:29,049 --> 00:20:30,379
the regular audits.

259
00:20:30,509 --> 00:20:35,519
So routine audits also help identify
and remove unnecessary data.

260
00:20:36,009 --> 00:20:38,829
sometimes you only want to
store seven years worth of data.

261
00:20:39,279 --> 00:20:43,099
Data and the data that's
more than seven years.

262
00:20:43,469 --> 00:20:44,119
You don't need it.

263
00:20:44,439 --> 00:20:52,059
So Performing regular audits on the
data helps you Like access like reduce

264
00:20:52,059 --> 00:20:58,314
your cloud costs monitoring and cost
visibility, so Continuous monitoring.

265
00:20:58,714 --> 00:21:01,914
So continuous monitoring is
essential for identifying

266
00:21:01,914 --> 00:21:06,494
unexpected usage spikes and tracking
resources like utilization trends.

267
00:21:07,034 --> 00:21:13,084
So this means that we need to always
expect that if there is a spike,

268
00:21:13,339 --> 00:21:18,509
There's actually a bug somewhere that's
causing the spike and we need to set

269
00:21:18,509 --> 00:21:23,679
up appropriate monitoring and alerting
to let know to let us know that, hey,

270
00:21:23,909 --> 00:21:28,569
there's a spike that means something or
there's a bug and production or other

271
00:21:28,619 --> 00:21:29,959
environments that's causing the spike.

272
00:21:30,459 --> 00:21:32,659
There's AWS Cost Visibility Tools.

273
00:21:32,759 --> 00:21:38,609
AWS Cost Explorer is one such tool
that helps us deep dive into what

274
00:21:38,609 --> 00:21:43,009
resources are we using, like what are
the cost patterns, like how much we

275
00:21:43,019 --> 00:21:47,909
are going to be spending, in particular
month based on the current usage.

276
00:21:48,329 --> 00:21:54,879
And this gives us a visibility into
how much the change in configuration

277
00:21:54,879 --> 00:22:01,329
can lead to the increase in cloud
costs So and also we can set up budgets

278
00:22:01,329 --> 00:22:07,269
and alerts so we can do spending
thresholds On a particular aws account.

279
00:22:07,279 --> 00:22:14,174
Let's just say we have a thousand dollars
Maximum budget on an AWS account running

280
00:22:14,254 --> 00:22:20,334
as example application now We can set up
alerts when basically there is a spike or

281
00:22:20,674 --> 00:22:28,704
when the forecast is more than The current
budget and we can set up alerts And we

282
00:22:28,704 --> 00:22:34,194
can fix what's causing what resources were
provisioned That's causing this alerts to

283
00:22:34,194 --> 00:22:40,314
get fired up There's cost allocation tags,
the so the cost allocation tags is one of

284
00:22:40,314 --> 00:22:47,554
the crucial parts of Cloud cost management
because it lets you know which team which

285
00:22:47,554 --> 00:22:54,154
project or which department you this
resource belongs to and how much it costs

286
00:22:54,174 --> 00:22:56,999
because It's all about unit economics.

287
00:22:56,999 --> 00:23:01,759
So how much so for example, if you're
doing a transaction of hundred dollars

288
00:23:02,069 --> 00:23:05,889
How much you're actually spending
for the cloud is what matters?

289
00:23:06,269 --> 00:23:11,239
so if you're making a hundred dollars
in a transaction and you're spending

290
00:23:11,239 --> 00:23:15,619
eighty dollars on a cloud cost
That's not a viable business model

291
00:23:16,119 --> 00:23:16,739
finops.

292
00:23:16,899 --> 00:23:22,769
So finops is a cultural approach to
cost Optimization So finops provides

293
00:23:22,769 --> 00:23:26,899
a framework for cost management that
integrates financial accountability into

294
00:23:26,899 --> 00:23:33,429
cloud spending it just means that It's
a culture shift where finance teams are

295
00:23:33,429 --> 00:23:40,119
more involved, with the engineering teams
like we Like it's a shared responsibility

296
00:23:40,119 --> 00:23:43,929
between all the teams to make sure that
we are operating the cloud effectively

297
00:23:44,669 --> 00:23:51,459
and basically, like at a low at a
lower cost and this also One of the

298
00:23:51,479 --> 00:23:57,499
principles of the FinOps is that the,
the engineering teams should be able

299
00:23:57,539 --> 00:24:02,769
to know, what are the repercussions of
their actions of provisioning resources.

300
00:24:03,219 --> 00:24:10,219
And it should be near instant, or at
least it should be like, the predicted

301
00:24:10,219 --> 00:24:15,429
cost should be like, visible to the
team so that they can take active, steps

302
00:24:15,649 --> 00:24:17,949
to like, to not cross their budgets.

303
00:24:17,949 --> 00:24:18,169
Thanks.

304
00:24:19,019 --> 00:24:19,089
Etc.

305
00:24:19,939 --> 00:24:26,349
And so this helps, developers and
the engineering teams know that, hey,

306
00:24:26,849 --> 00:24:32,189
I want to make a design decision,
but cost is also one of them.

307
00:24:32,349 --> 00:24:37,589
So these are all the principles
of FinOps and implementing FinOps,

308
00:24:38,489 --> 00:24:45,214
will help like organizations
make like cloud use much easier.

309
00:24:45,714 --> 00:24:49,824
leveraging AI and FinOps
to drive cloud efficiency.

310
00:24:50,324 --> 00:24:55,384
AI powered tools can continuously monitor
cloud usage and expenses in real time.

311
00:24:55,964 --> 00:25:01,194
for example, you have all this data
about billing and cloud usage, like

312
00:25:01,194 --> 00:25:05,184
how much cloud we are using, how
much idle time, how much busy time.

313
00:25:05,684 --> 00:25:10,504
Now, we can train some AI models,
Based on the data that we collect

314
00:25:11,104 --> 00:25:18,084
and based on that, we can design the
tools that can say, Hey, at this point

315
00:25:18,094 --> 00:25:23,684
in time, you, like you are going to
have a spike in load and that way.

316
00:25:23,704 --> 00:25:29,994
So you can predict that you might need
resources at certain point of time.

317
00:25:30,394 --> 00:25:35,604
And this helps team prepare for
if they need any resources at

318
00:25:35,604 --> 00:25:37,504
certain point anomaly detection.

319
00:25:37,979 --> 00:25:42,489
So AI algorithms can also analyze
historical spending data to detect cost

320
00:25:42,709 --> 00:25:46,679
anomalies and irregularities allowing
businesses to address these issues from

321
00:25:47,599 --> 00:25:55,739
So there's always anomalies in the data
so It might be like as I said before it

322
00:25:55,739 --> 00:26:00,779
might be some bug that's causing a spike
at one point of time Another for example

323
00:26:01,469 --> 00:26:03,959
There is if you are, the NAT gateway cost.

324
00:26:03,979 --> 00:26:08,499
So the data transfer cost, there's
a spike There's a huge bunch

325
00:26:08,499 --> 00:26:10,079
of requests that's going out.

326
00:26:10,229 --> 00:26:15,029
There's data that's coming in There's
ingress data and basically that's there.

327
00:26:15,069 --> 00:26:18,959
That's an anomaly because some
there's a misconfiguration on the

328
00:26:19,769 --> 00:26:21,569
Network side that's caused this spike.

329
00:26:21,959 --> 00:26:27,819
Now AI algorithms can Detect this
cost anomalies and attributed to hey

330
00:26:27,859 --> 00:26:34,189
this change has cost this much to the
organization eliminating inefficient

331
00:26:34,199 --> 00:26:39,629
resource use so ai can help eliminate
idle cloud resources and unused resources

332
00:26:39,659 --> 00:26:45,059
by automatically shutting down or
resizing them Reducing wasteful spending.

333
00:26:45,519 --> 00:26:49,889
I'll talk more about this in the ai
agentic approach yeah, let's move forward.

334
00:26:50,339 --> 00:26:52,139
Demand forecasting and autoscaling.

335
00:26:52,409 --> 00:26:55,489
As I already said, AI can predict
the future demand for the cloud

336
00:26:55,499 --> 00:27:00,259
resources, enabling better planning and
deployment, and dynamically adjusting

337
00:27:00,269 --> 00:27:02,439
resources to avoid over provisioning.

338
00:27:02,939 --> 00:27:05,969
using prompt engineering for
achieving cloud efficiency.

339
00:27:05,979 --> 00:27:08,149
This is what we have been waiting for.

340
00:27:08,429 --> 00:27:11,899
As you guys already know, the
prompt engineering is how you

341
00:27:12,109 --> 00:27:16,199
talk to AI models to get the job.

342
00:27:16,699 --> 00:27:21,269
And one of the key things about the
prompt engineering is role prompting.

343
00:27:21,459 --> 00:27:22,489
So what is role prompting?

344
00:27:22,739 --> 00:27:26,479
So role prompting is a
technique in prompt engineering.

345
00:27:26,659 --> 00:27:29,739
to control the output generated
by the model by assigning a

346
00:27:29,739 --> 00:27:31,599
specific role to the AI model.

347
00:27:32,129 --> 00:27:33,019
This can be any model.

348
00:27:33,119 --> 00:27:37,349
I just used shared GPT example
here, but it can be cloud, it

349
00:27:37,349 --> 00:27:43,129
can be llama, it can be Gemini
or any AI model that's GPT based.

350
00:27:43,629 --> 00:27:48,119
So we can make use of rules like
FinOps Expert and craft prompts by

351
00:27:48,119 --> 00:27:50,489
providing more context to the prompt.

352
00:27:51,229 --> 00:27:52,779
Let's see a couple of examples.

353
00:27:53,449 --> 00:27:57,179
So some of the prompts using
the FinOps Expert rule.

354
00:27:57,259 --> 00:28:03,799
So here what I did try was, as a
FinOps Expert, can you please help

355
00:28:03,809 --> 00:28:05,659
deep dive into our AWS Cloud Build?

356
00:28:06,409 --> 00:28:13,439
Please explain what is different
unplanted costs And I'm an amortized cost.

357
00:28:13,729 --> 00:28:19,339
So as someone who is coming
to like cloud billing Like

358
00:28:19,339 --> 00:28:20,959
specifically it was cloud billing.

359
00:28:21,409 --> 00:28:25,239
There are multiple different types
of costs like you have like unplanned

360
00:28:25,289 --> 00:28:28,749
costs You have amortized costs and
there are multiple different costs.

361
00:28:28,759 --> 00:28:36,929
So to get you Understand, AMRLs can
definitely help you to do that and you

362
00:28:36,929 --> 00:28:42,919
can use roles like FinOps Expert to help
you guide how to implement the FinOps

363
00:28:42,949 --> 00:28:45,059
best practices in your organization.

364
00:28:45,559 --> 00:28:47,429
This is one of the experiments that I did.

365
00:28:47,479 --> 00:28:50,139
So you can also use as a FinOps Expert.

366
00:28:50,709 --> 00:28:56,899
Can you analyze our AWS invoice
and let us know why our AWS

367
00:28:56,899 --> 00:28:58,469
bill was higher than usual?

368
00:28:58,989 --> 00:29:03,089
Can you please provide details,
detailed report on how could

369
00:29:03,089 --> 00:29:04,519
we reduce our AWS spend?

370
00:29:05,099 --> 00:29:10,219
Now, this is a very specific prompt
and I'm also giving some context

371
00:29:10,219 --> 00:29:12,719
to the AI model so that it knows.

372
00:29:13,239 --> 00:29:21,909
I've also gave the invoice and let the
AI Like why was the spend like, you

373
00:29:21,919 --> 00:29:28,029
know increased in the previous month so
Since we are talking on the same page.

374
00:29:28,149 --> 00:29:33,839
so one of the things that is popular
is Like most people are trying to

375
00:29:33,839 --> 00:29:35,779
get now is ai agentic approach.

376
00:29:36,509 --> 00:29:42,629
So ai agentic approach is Like we
build ai agents to get the job done.

377
00:29:42,999 --> 00:29:48,869
So for example You can build
an ai agent That would monitor

378
00:29:49,479 --> 00:29:50,769
The usage of a resource.

379
00:29:51,289 --> 00:29:54,639
Let's just say there is a
resource that says hey this

380
00:29:54,909 --> 00:29:57,339
Resource is been idle for a while.

381
00:29:57,349 --> 00:29:59,319
It's not even taking connections.

382
00:29:59,409 --> 00:30:04,919
Let me you know, shut down that
server I will let the infrastructure

383
00:30:04,919 --> 00:30:11,769
institute know that this is happening
and I will let them and i'll shut

384
00:30:11,769 --> 00:30:18,119
down the like the database temporarily
Now this is what an ai is Agentic.

385
00:30:18,934 --> 00:30:24,414
AI approaches so we can build
like simple ai agents So

386
00:30:24,464 --> 00:30:27,234
there's two amazing resources.

387
00:30:27,254 --> 00:30:28,164
One is lang chain.

388
00:30:28,184 --> 00:30:33,914
One is crew ai They use prompts under
the hood the prompt engineering so they

389
00:30:33,914 --> 00:30:39,424
can act as a part of automation And they
can talk to any of the ai models that are

390
00:30:39,484 --> 00:30:45,714
currently available like chat gpt cloud
or any other open source models, and

391
00:30:45,884 --> 00:30:53,994
basically, like you build an AI agent that
will help you, implement these actions,

392
00:30:54,334 --> 00:30:56,214
for cost optimization on your behalf.

393
00:30:56,714 --> 00:30:58,484
let's get to the conclusion.

394
00:30:58,914 --> 00:31:02,814
so cost optimization in cloud platforms
requires a comprehensive approach.

395
00:31:03,619 --> 00:31:07,159
that balances technical strategies
with organization shifts.

396
00:31:07,519 --> 00:31:09,109
it's not always easy.

397
00:31:09,389 --> 00:31:13,039
the cloud native platforms
are, like, increasing.

398
00:31:13,489 --> 00:31:17,649
there's a need for the
cloud platforms that operate

399
00:31:17,689 --> 00:31:20,019
efficiently and at a lower cost.

400
00:31:20,519 --> 00:31:24,659
By understanding the primary cost drivers
such as compute resources, storage,

401
00:31:24,659 --> 00:31:29,209
data transfer, third party service
organizations, we can implement like

402
00:31:29,329 --> 00:31:32,909
tailored techniques to reduce expenses
without compromising performance.

403
00:31:33,479 --> 00:31:38,899
more resources, is not equal
to like more performance.

404
00:31:39,609 --> 00:31:45,149
That's true that you can run like, a
big instance and throw an application

405
00:31:45,149 --> 00:31:46,969
on it, but that's not how it works.

406
00:31:47,469 --> 00:31:51,579
resource management practices like right
sizing auto scaling and diversified

407
00:31:51,589 --> 00:31:56,279
instance types from the backbone of
effective cost optimization at the

408
00:31:56,279 --> 00:32:01,469
end of the day at the end of the day
These are the core principles like use

409
00:32:01,509 --> 00:32:08,429
how much you need Auto scale whenever
you need and use the right resources.

410
00:32:08,929 --> 00:32:09,339
That's it.

411
00:32:10,209 --> 00:32:14,589
And additionally, when it comes to
container and serverless, make sure

412
00:32:14,619 --> 00:32:19,919
you use like limits and requests
appropriately, coupled with when it

413
00:32:19,919 --> 00:32:24,499
comes to databases and block storage,
use data lifecycle management,

414
00:32:24,719 --> 00:32:30,619
lifecycle policies, and to make sure
that the data is stored, securely.

415
00:32:31,124 --> 00:32:36,354
And also in a cost efficient way
and, and also like I want to put a

416
00:32:36,354 --> 00:32:42,224
strong emphasis on monitoring and
cost visibility framework is really

417
00:32:42,224 --> 00:32:47,924
important because, without adequate
monitoring, you don't even know what

418
00:32:47,924 --> 00:32:50,654
resources you have, what are the spikes.

419
00:32:50,994 --> 00:32:55,414
So having a strong monitoring
foundation, having a budget alerts,

420
00:32:55,424 --> 00:33:01,434
having a proper utilization alerts
will help you track resources even

421
00:33:01,434 --> 00:33:04,704
before the AWS cloud lands at you.

422
00:33:05,204 --> 00:33:08,854
So FinOps principles bring a
cultural dimension to this strategy,

423
00:33:09,114 --> 00:33:13,374
encouraging cross functional
collaboration and fostering cost

424
00:33:13,374 --> 00:33:14,834
awareness within development teams.

425
00:33:14,844 --> 00:33:21,589
I would reiterate that FinOps will help
business teams Finance teams understand

426
00:33:21,599 --> 00:33:27,729
the cloud expenditure, with the help
of the engineering teams and also The

427
00:33:27,729 --> 00:33:34,104
engineering teams would be responsible
For the cloud costs and the actions

428
00:33:34,104 --> 00:33:41,234
that they take for provisioning new
cloud resources So this financial

429
00:33:41,444 --> 00:33:46,784
accountability in every stage of cloud
management Organizations can align

430
00:33:46,784 --> 00:33:50,114
spending with business goals creating
a culture of continuous improvement.

431
00:33:50,614 --> 00:33:55,889
Thank you That was my talk
for today hope you liked it.

432
00:33:56,159 --> 00:34:01,879
There's a great future for cloud
cost optimizations Using agentic AI

433
00:34:02,079 --> 00:34:03,969
approach, which i'm truly excited about.

434
00:34:04,529 --> 00:34:06,639
thank you everyone have
a good rest of your day

