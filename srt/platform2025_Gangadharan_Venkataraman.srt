1
00:00:00,500 --> 00:00:00,890
Hey.

2
00:00:01,520 --> 00:00:02,360
Hi everyone.

3
00:00:02,410 --> 00:00:07,030
I'm, and today I'm going to talk
more about building how to build

4
00:00:07,030 --> 00:00:10,360
a developer centric machine
learning inference platform.

5
00:00:10,360 --> 00:00:16,540
So the major thing we, I'm going to
talk about is what are all the different

6
00:00:16,780 --> 00:00:21,200
challenges you face while developing
a ML centric inference platform and

7
00:00:21,200 --> 00:00:26,790
how better you can, serve the models
at scale and what are the basic

8
00:00:26,790 --> 00:00:29,220
things you, we can follow as a team?

9
00:00:29,269 --> 00:00:32,820
Kubernetes is the underlying
infrastructure we use for machine learning

10
00:00:32,820 --> 00:00:37,475
models, but how better we can leverage the
infrastructure and the surrounding tools.

11
00:00:38,214 --> 00:00:43,339
Involved and the process involved
and how well the whole ML platform

12
00:00:43,339 --> 00:00:45,019
can scale and serve the customer.

13
00:00:45,019 --> 00:00:49,209
So those are the things we, which
we are going to talk about today.

14
00:00:49,629 --> 00:00:53,000
Let's deep dive more in the next slides.

15
00:00:53,500 --> 00:00:53,830
Yeah.

16
00:00:54,250 --> 00:00:57,860
So if you see this evaluation of
ML platform engineering, right?

17
00:00:58,279 --> 00:01:00,499
It, it has three main components to it.

18
00:01:00,874 --> 00:01:08,274
One is the resource intensive nature
how well you are able to see what

19
00:01:08,274 --> 00:01:12,944
kind of resources are required for a
model to serve the production load.

20
00:01:13,334 --> 00:01:16,274
For example, when you're trying to
develop a model, you might need only one.

21
00:01:17,069 --> 00:01:21,269
But when you're trying to deploy the
model and serve it to, for some use

22
00:01:21,269 --> 00:01:25,649
case let's take an e-commerce use case,
a marketing use case, for example.

23
00:01:26,039 --> 00:01:29,069
In that case, you might need a
hundred parts or thousand parts.

24
00:01:29,459 --> 00:01:32,099
And it depends on the latency
requirements and what kind of

25
00:01:32,099 --> 00:01:33,509
features required for the model.

26
00:01:33,619 --> 00:01:37,619
And that's the second point we are talking
about the computational requirements

27
00:01:37,619 --> 00:01:43,834
required for ml. Platform and the
rapid experimentation cycles involved.

28
00:01:44,294 --> 00:01:48,614
Basically you can't have a mo the
same model which can work for all

29
00:01:48,614 --> 00:01:51,334
the use cases or all the users.

30
00:01:51,784 --> 00:01:55,714
You try to experiment with
different versions of the same

31
00:01:55,714 --> 00:02:00,844
model or even different models
and see which is be the best fit.

32
00:02:01,279 --> 00:02:03,834
Maybe a model can work
for a particular country.

33
00:02:03,934 --> 00:02:09,229
It might not work for another country,
and some models may work for a teenage,

34
00:02:09,439 --> 00:02:13,599
teen population, but it may not work
for the other kind of population.

35
00:02:13,649 --> 00:02:18,189
And may, maybe some models are built
specifically for like the women

36
00:02:18,189 --> 00:02:19,869
population or something like that.

37
00:02:20,169 --> 00:02:21,819
So it depends on the use case.

38
00:02:21,879 --> 00:02:22,599
It changes.

39
00:02:22,809 --> 00:02:24,689
So we need rapid experimentation cycle.

40
00:02:25,529 --> 00:02:30,384
And Kubernetes it provides you the
base, like the, it provides you with a

41
00:02:30,434 --> 00:02:35,324
abstraction layer, but you should have a
robust automation and deep understanding

42
00:02:35,324 --> 00:02:38,594
of both machine learning workflows
and developer experience principles.

43
00:02:39,044 --> 00:02:43,824
So you can continue to evolve for
for this machine learning platform.

44
00:02:43,874 --> 00:02:49,244
So let me deep dive more on what are
all the different things involved here?

45
00:02:49,744 --> 00:02:50,104
Yeah.

46
00:02:50,584 --> 00:02:56,774
So when we talk about the architectural
foundations designing for scale and

47
00:02:56,774 --> 00:02:59,624
flexibility is something very important.

48
00:02:59,724 --> 00:03:00,234
When you.

49
00:03:00,954 --> 00:03:02,244
Try to talk about architecture.

50
00:03:02,484 --> 00:03:04,344
So there are three different pillars here.

51
00:03:04,614 --> 00:03:07,434
One is the orchestration
layer, and the second is the

52
00:03:07,434 --> 00:03:08,844
model serving infrastructure.

53
00:03:09,054 --> 00:03:12,794
And third, and last but not the least,
is the data pipeline layer, right?

54
00:03:13,094 --> 00:03:14,684
All these three go hand in hand.

55
00:03:15,074 --> 00:03:20,444
So the orchestration layer, it provides
you with the built in Kubernetes.

56
00:03:20,944 --> 00:03:25,474
Which is there, and you have, you should
have a foundational capabilities for

57
00:03:25,474 --> 00:03:30,424
scheduling, resource management, container
lifecycle, resource allocation, service

58
00:03:30,424 --> 00:03:34,804
discovery, all those kind of, where you
handle all the machine learning workflows

59
00:03:35,084 --> 00:03:36,734
workloads required for the model.

60
00:03:37,124 --> 00:03:39,795
And in some cases, you
might even need GPU.

61
00:03:39,855 --> 00:03:42,644
So g scheduling is also part
of the orchestration layer.

62
00:03:43,215 --> 00:03:47,165
And the model serving infrastructure is
basically where you have a trained model.

63
00:03:47,749 --> 00:03:51,230
You're trying to make the model
readily available to be consumed by

64
00:03:51,230 --> 00:03:55,710
some a PA or even by your homepage
or any other place where the

65
00:03:55,710 --> 00:03:57,420
model is going to be used, right?

66
00:03:57,689 --> 00:03:59,520
So you, you need to have a way to.

67
00:04:00,374 --> 00:04:04,754
Load the model, route the
model, optimize the model.

68
00:04:04,754 --> 00:04:08,715
Sometimes it requires batch optimization
and then the response formatting.

69
00:04:09,254 --> 00:04:12,915
The model might give you response
in a, in some format, but the

70
00:04:12,915 --> 00:04:16,034
client or the application might
need in a different format.

71
00:04:16,034 --> 00:04:20,674
You should have some way to format
that kind of response and complex

72
00:04:21,094 --> 00:04:24,814
stem from diversity of model
formats and serving requirements.

73
00:04:24,864 --> 00:04:28,614
Those kind of things should, are part
of the model serving infrastructure

74
00:04:29,034 --> 00:04:30,294
and the data pipeline layer.

75
00:04:30,405 --> 00:04:35,114
So the data pipeline layer is basically
when you're trying to develop a

76
00:04:35,114 --> 00:04:38,329
model it requires a lot of features.

77
00:04:38,569 --> 00:04:41,839
Some are realtime features,
some are near realtime features

78
00:04:42,109 --> 00:04:43,609
and some more offline features.

79
00:04:43,979 --> 00:04:47,959
Let's take an example where
you try to quote your shop

80
00:04:47,959 --> 00:04:49,124
and purchase an item, right?

81
00:04:49,804 --> 00:04:52,684
And similarly, you
purchase an item online.

82
00:04:52,734 --> 00:04:58,129
So you're trying to develop a model to see
what is the buying pattern of a customer.

83
00:04:58,849 --> 00:05:00,140
So it requires a lot of data.

84
00:05:00,140 --> 00:05:05,724
It may require historical data of
what kind of purchases or what's the

85
00:05:05,724 --> 00:05:11,634
items the user is trying to browse or
is trying to bid or is trying to buy.

86
00:05:11,844 --> 00:05:16,524
So those kind of data is required
and sometimes near real time data.

87
00:05:16,624 --> 00:05:23,064
You you try to listen to some Kafka stream
or some kind of near stream to listen to

88
00:05:23,064 --> 00:05:25,189
those kind of topics and try to ingest it.

89
00:05:25,924 --> 00:05:29,134
Near real time and serve it
as a feature for the model.

90
00:05:29,134 --> 00:05:32,064
And some cases you have real data, right?

91
00:05:32,364 --> 00:05:37,274
Even before the model output is served
to the actual user, we try to check

92
00:05:37,274 --> 00:05:38,804
if that item is still available.

93
00:05:38,834 --> 00:05:43,264
For example, you try and find like 10
different items which the user can buy.

94
00:05:43,684 --> 00:05:46,774
You have to check whether the
item is in stock or not before

95
00:05:46,774 --> 00:05:49,084
showing it to the actual customer.

96
00:05:49,324 --> 00:05:51,034
So those kind of real time checks.

97
00:05:51,819 --> 00:05:57,114
Part of this data pipeline and our
caching up in, in the way you pro

98
00:05:57,114 --> 00:05:59,669
provide the in the model, right?

99
00:05:59,939 --> 00:06:03,239
So these are the three
different things with respect to

100
00:06:03,239 --> 00:06:04,889
architecture we need to consider.

101
00:06:05,389 --> 00:06:11,314
So I was talking more about the Kuber
Kubernetes orchestration before.

102
00:06:11,674 --> 00:06:17,634
If you go deep dive into that CRDs
play a pivotal role in extending

103
00:06:17,634 --> 00:06:21,114
the Kubernetes to support machine
learning specific concept, right?

104
00:06:21,504 --> 00:06:25,644
These extensions actually enable the
teams to define higher level abstraction,

105
00:06:25,974 --> 00:06:30,294
like model deployment feature, pipeline
experimentation, runs, everything is.

106
00:06:30,794 --> 00:06:34,844
Enabled through this custom
resource definitions and basically

107
00:06:34,844 --> 00:06:36,164
there are different patterns.

108
00:06:36,434 --> 00:06:41,249
Operator patterns are the one which
actually, which is valuable for

109
00:06:41,309 --> 00:06:44,489
managing all the ML workload lifecycles.

110
00:06:44,489 --> 00:06:48,089
Custom operators can handle both
deployment workflow, auto scaling.

111
00:06:48,889 --> 00:06:50,029
On inference load.

112
00:06:50,079 --> 00:06:53,409
And also integration with
external systems, like feature

113
00:06:53,409 --> 00:06:55,029
stores or model registry.

114
00:06:55,369 --> 00:07:00,539
If you're familiar with Databricks,
Databricks is one external product all

115
00:07:00,539 --> 00:07:04,979
in the market where you have a end-to-end
model development, like cycle in place.

116
00:07:04,979 --> 00:07:08,339
Like you, you have a training
infrastructure, you have a feature

117
00:07:08,339 --> 00:07:10,604
store where you can write the data into.

118
00:07:11,254 --> 00:07:12,964
Like some schema, right?

119
00:07:13,294 --> 00:07:17,734
And then it can also integrate with
external system like red, this or any

120
00:07:17,734 --> 00:07:21,504
other, suppose you are listening to
some Kafka or near realtime data that

121
00:07:21,504 --> 00:07:23,484
can even have or any, anything else.

122
00:07:23,964 --> 00:07:29,184
So it can also interact with
Microsoft Azure Kubernetes services

123
00:07:29,184 --> 00:07:33,384
or AWS or they have connectors
available in place that way.

124
00:07:34,309 --> 00:07:37,899
You the integration with other
platform is seamless, so that,

125
00:07:37,899 --> 00:07:41,969
that's part of the orchestration
layer and then developer experience.

126
00:07:42,059 --> 00:07:47,109
So when I talk about developer experience
it's like how easily you are trying to

127
00:07:47,979 --> 00:07:50,199
provide this kind of capabilities, right?

128
00:07:50,499 --> 00:07:52,299
The abstracting, the complexity.

129
00:07:52,799 --> 00:07:58,199
In terms of a simple UI or some
self-service capabilities, developer,

130
00:07:58,349 --> 00:08:02,500
when he is trying to deploy a model, you
should not run into like multiple commands

131
00:08:02,500 --> 00:08:04,960
or go into multiple pages to deploy.

132
00:08:04,960 --> 00:08:09,500
It should be seamless because I try
to check in a code into my branch,

133
00:08:09,740 --> 00:08:13,340
develop branch if they, once you
check in, if there is an automated

134
00:08:13,340 --> 00:08:15,375
way to deploy it to the the developer.

135
00:08:15,875 --> 00:08:19,480
Development namespace are the
development environment, right?

136
00:08:19,689 --> 00:08:21,140
Then that's the best thing to do.

137
00:08:21,530 --> 00:08:26,200
And if a code is merged to main, if
there are like pipelines, automatic

138
00:08:26,200 --> 00:08:33,100
pipelines integrated with the CACD,
which can completely test, validate,

139
00:08:33,100 --> 00:08:39,160
and deploy to production at scale,
that's a, that, that actually enhances

140
00:08:39,160 --> 00:08:40,960
the model development lifecycle.

141
00:08:41,500 --> 00:08:44,239
By 10 times because, 10
times or a hundred times.

142
00:08:44,510 --> 00:08:49,670
So you can, the, you can do faster
deployments and faster testing with

143
00:08:49,670 --> 00:08:53,540
these kind of automated approaches
and how well to achieve that will

144
00:08:53,569 --> 00:08:54,665
we'll see in the upcoming slides.

145
00:08:55,165 --> 00:09:00,325
So I was talking about the automated
CACD for ML in the previous slide, right?

146
00:09:00,595 --> 00:09:06,235
So it, if you see the automated
CACD, it's just if you see there

147
00:09:06,235 --> 00:09:07,255
are like three different things.

148
00:09:07,755 --> 00:09:10,155
High level one is the model validation.

149
00:09:10,425 --> 00:09:14,205
So when you're trying to push a new
change to the model, there should

150
00:09:14,205 --> 00:09:15,645
be some way to validate the model.

151
00:09:15,705 --> 00:09:18,615
Like you can manually validate
the model before pushing.

152
00:09:18,625 --> 00:09:18,925
That's.

153
00:09:19,425 --> 00:09:21,165
Crude way of validating the model.

154
00:09:21,435 --> 00:09:26,265
But if you have all the regression
integration and sanity test smoke tests

155
00:09:26,265 --> 00:09:30,765
in place, which are already automated
and it's part of your pipeline, then

156
00:09:30,765 --> 00:09:32,415
you don't need to do this manual check.

157
00:09:32,925 --> 00:09:36,555
Whenever you deploy the model, the
automated validation kicks in and if it

158
00:09:36,555 --> 00:09:39,255
fails, the deployment won't even happen.

159
00:09:39,885 --> 00:09:41,415
And post deployment.

160
00:09:41,415 --> 00:09:46,015
Also, you can have validations in
place to monitor and if you see the

161
00:09:46,015 --> 00:09:51,095
failures are above some threshold, there
should be automated rollback option.

162
00:09:51,725 --> 00:09:54,815
So that's when the artifact
management plays a key role, right?

163
00:09:55,385 --> 00:09:58,985
When you have multiple versions of
the model, like at least the past

164
00:09:58,985 --> 00:10:02,795
three versions or four versions
of the model or past 10 version

165
00:10:02,795 --> 00:10:04,025
depends on your requirement.

166
00:10:04,640 --> 00:10:08,550
It's easy to scale back or roll
back to that version, the last

167
00:10:08,550 --> 00:10:10,320
stable version of the model, right?

168
00:10:10,620 --> 00:10:14,090
That way you're not disrupting
the production environment and you

169
00:10:14,090 --> 00:10:15,890
have several deployment strategies.

170
00:10:15,950 --> 00:10:20,730
For example, a canary deployment
is one thing you have thousand pods

171
00:10:20,970 --> 00:10:22,350
which are serving for the model.

172
00:10:22,590 --> 00:10:26,760
You, you can first deploy to one
sanity, test pod, and then see

173
00:10:26,830 --> 00:10:29,870
how better, the traffic coming
to the pod is working, right?

174
00:10:30,180 --> 00:10:33,720
If there are more failures in that
part, then there's automated rollback

175
00:10:33,750 --> 00:10:38,590
you can do that way you are not
disrupting the whole set of users.

176
00:10:38,710 --> 00:10:44,110
Maybe a few users are getting impacted
still, but, and similarly, gradual traffic

177
00:10:44,110 --> 00:10:48,190
shifting is mo is most important because
like when you're trying to deploy the

178
00:10:48,190 --> 00:10:51,340
model at scale, you cannot actually.

179
00:10:51,730 --> 00:10:56,910
Affect the a hundred percent traffic
instead, if there is a way to 1%, 5%,

180
00:10:56,910 --> 00:11:01,830
10%, and then a hundred percent, that
kind of deployment is, it is very

181
00:11:01,830 --> 00:11:03,480
important and it should change it.

182
00:11:03,480 --> 00:11:06,580
Or suppose you're trying to do
a hard fix and you are trying

183
00:11:06,580 --> 00:11:08,020
to deploy without the dar fix.

184
00:11:08,020 --> 00:11:11,800
If the whole functionality breaks,
then in that case you should be able

185
00:11:11,800 --> 00:11:13,300
to a hundred percent deploy the change.

186
00:11:13,720 --> 00:11:17,760
So those are the flexibility
we need to provide in terms of.

187
00:11:18,410 --> 00:11:19,640
Deployment strategy,

188
00:11:20,140 --> 00:11:22,270
feature store, and data
pipeline architecture, right?

189
00:11:22,270 --> 00:11:24,010
We talked this, talked about this.

190
00:11:24,425 --> 00:11:28,745
At high level, when you go deep
dive for feature store, it addresses

191
00:11:28,745 --> 00:11:32,825
the fundamental challenge of
serving features for both batch

192
00:11:32,825 --> 00:11:34,445
training and real time inference.

193
00:11:34,655 --> 00:11:37,775
So basically you can consider it
as two different things, right?

194
00:11:37,835 --> 00:11:38,945
Online, offline.

195
00:11:39,185 --> 00:11:45,295
So offline is something for historical
data batch processing, you can

196
00:11:45,295 --> 00:11:48,805
have a nightly job or weekly job,
which can ingest those features.

197
00:11:49,205 --> 00:11:53,230
Online is a real time or near
real time inferencing rate.

198
00:11:53,570 --> 00:11:58,340
You listen to some Kafka topic or you
directly hit an a PA even before the

199
00:11:58,340 --> 00:12:00,260
actual output is served to the customer.

200
00:12:00,260 --> 00:12:06,160
So those are two different data and you
should have a your architecture should

201
00:12:06,160 --> 00:12:11,180
accommodate all, both the patterns, both
online, out and offline patterns so it can

202
00:12:11,180 --> 00:12:13,565
better serve the model to the customers.

203
00:12:14,065 --> 00:12:17,555
And this is like how you are
going to serve the model, right?

204
00:12:17,885 --> 00:12:21,475
In general, there are three
three different cases here.

205
00:12:21,475 --> 00:12:25,245
One is the container optimization
for machine learning, and second is

206
00:12:25,245 --> 00:12:27,005
the serverless serving framework.

207
00:12:27,395 --> 00:12:28,640
And third is the code start.

208
00:12:29,270 --> 00:12:30,020
Optimization.

209
00:12:30,070 --> 00:12:33,370
If you take the container
optimization, it requires special

210
00:12:33,370 --> 00:12:37,030
techniques that account for large
model artifacts and GP dependencies.

211
00:12:37,480 --> 00:12:40,990
And in some cases you need
multi-stage build process and

212
00:12:41,290 --> 00:12:44,740
which can minimize the container
image size by separating the build

213
00:12:44,740 --> 00:12:46,840
dependencies from runtime environments.

214
00:12:46,890 --> 00:12:50,740
At runtime you may request certain and
things, but during building you you

215
00:12:50,740 --> 00:12:52,660
have to make sure the image size is.

216
00:12:53,245 --> 00:12:56,505
Optimized that way you reduce the space.

217
00:12:56,985 --> 00:13:01,005
And for serverless serving,
you have to abstract away from

218
00:13:01,005 --> 00:13:04,185
cluster management while providing
automatic scaling capabilities.

219
00:13:04,485 --> 00:13:09,475
So basically you deploy a
model with thousand parts.

220
00:13:10,035 --> 00:13:13,575
And you just receive like five,
fire request per second, right.

221
00:13:13,575 --> 00:13:17,865
Thousand parts might not be required
for that model, but there are times when

222
00:13:17,915 --> 00:13:22,750
you may receive like 20,000 requests per
second, or 30,000 requests per second.

223
00:13:23,245 --> 00:13:28,985
And if a part can handle like fire
request, then you obviously need

224
00:13:29,035 --> 00:13:32,605
depends on like per five request
per second, a part can handle.

225
00:13:32,605 --> 00:13:36,025
And you have 5,000 requests
and you need thousand parts.

226
00:13:36,385 --> 00:13:43,435
So how can you do this so that's when this
automatic scaling place a key road, right?

227
00:13:43,765 --> 00:13:47,355
You should, for example, when
you have a best part which can

228
00:13:47,355 --> 00:13:49,425
automatically scale, you have.

229
00:13:49,925 --> 00:13:55,685
Minimum par parts required are always
there, like one part or 10 part like, or a

230
00:13:55,685 --> 00:13:57,545
hundred parts which will sell the traffic.

231
00:13:57,905 --> 00:14:03,090
But when there is a huge traffic spike
slowly you see the infrastructure

232
00:14:03,090 --> 00:14:04,615
scales, the number of parts required.

233
00:14:05,325 --> 00:14:06,945
That way, there is no disruption.

234
00:14:06,995 --> 00:14:10,625
And we are able to serve the
customers without any latency issues.

235
00:14:11,225 --> 00:14:15,005
And cold start optimization is
another important thing which you

236
00:14:15,005 --> 00:14:18,275
need to consider when you are trying
to do the model serving, right?

237
00:14:18,595 --> 00:14:22,585
Like model preloading,
lazy initialization, and

238
00:14:22,585 --> 00:14:24,085
shared model caches, right?

239
00:14:24,445 --> 00:14:27,480
So for example, if your pod is restarting.

240
00:14:27,980 --> 00:14:29,750
It means your cash is gone.

241
00:14:29,840 --> 00:14:32,810
Whatever you have in your
local, those caches are gone.

242
00:14:33,140 --> 00:14:38,130
So if you have a persistent cash
multi-level cash concept in your design,

243
00:14:38,520 --> 00:14:44,220
that way you still get the data from
the shared persistent cash, right?

244
00:14:44,825 --> 00:14:47,415
And at least the latency
wise, it's not that big.

245
00:14:47,525 --> 00:14:51,425
It might not be as good as the
local cache, but it's still in few

246
00:14:51,425 --> 00:14:56,465
milliseconds and you are not hitting
the actual DBR actual source or a

247
00:14:56,465 --> 00:14:58,655
PA call for that particular data.

248
00:14:59,105 --> 00:15:02,705
So those are the things you
need to consider just to

249
00:15:02,705 --> 00:15:05,615
avoid those latency issues.

250
00:15:05,665 --> 00:15:09,590
And, once you have the model in
production and you handle all those

251
00:15:09,590 --> 00:15:14,630
latency and all the other issues during
deployment, the next thing which comes

252
00:15:14,630 --> 00:15:17,030
into picture is the monitoring, right?

253
00:15:17,240 --> 00:15:20,720
You constantly monitor the
model for failures, maybe.

254
00:15:21,030 --> 00:15:26,270
The input data changed, or the pattern
in which the customers are using, the

255
00:15:26,270 --> 00:15:30,760
model changed or the performance of
the model is deteriorating over time.

256
00:15:31,150 --> 00:15:35,030
So these are the things you, you
do through constant monitoring

257
00:15:35,120 --> 00:15:38,360
and then observability and
performance optimization, right?

258
00:15:38,720 --> 00:15:41,600
So there are like several
metrics you need to monitor.

259
00:15:41,940 --> 00:15:44,040
Some of the metrics are accuracy metrics.

260
00:15:44,625 --> 00:15:48,755
And then prediction, distribution
analysis feature drift reduction

261
00:15:48,755 --> 00:15:50,205
is one of the key metrics.

262
00:15:50,205 --> 00:15:54,180
Suppose there is a drift in the
feature, then you can retain the model.

263
00:15:54,240 --> 00:15:57,905
You don't need to try retain
the model on a schedule basis

264
00:15:57,905 --> 00:15:59,315
or on a daily basis, right?

265
00:15:59,645 --> 00:16:02,105
You can monitor for
feature drift or model.

266
00:16:02,900 --> 00:16:06,200
And then you can take the a accordingly.

267
00:16:06,200 --> 00:16:10,370
You can take the action of whether you
need to train the model or you need the

268
00:16:10,370 --> 00:16:12,710
new model to replace the existing model.

269
00:16:13,070 --> 00:16:15,245
So those kind of things you need to have.

270
00:16:15,745 --> 00:16:19,915
So the, in this slide we are mainly
talking about the organization excellence.

271
00:16:20,185 --> 00:16:23,815
So once you have the marketing
capabilities in place, you have

272
00:16:23,815 --> 00:16:26,755
the deployment capabilities in
place and there are like automated.

273
00:16:27,260 --> 00:16:28,580
Scaling capabilities.

274
00:16:28,890 --> 00:16:30,690
How well you are working as a team.

275
00:16:30,840 --> 00:16:34,620
So nothing can be done
by a single person here.

276
00:16:34,920 --> 00:16:38,880
There are several teams which you are
going to work for a particular use case.

277
00:16:39,120 --> 00:16:43,500
For example, when you are trying to
develop a model, you need to know

278
00:16:43,500 --> 00:16:45,210
what problem you are trying to solve.

279
00:16:45,240 --> 00:16:49,110
So you work with the business to see what
kind of problems we are currently facing.

280
00:16:49,690 --> 00:16:51,820
Let's take example of Starbucks, right?

281
00:16:52,150 --> 00:16:53,650
You have 50,000 stores.

282
00:16:54,070 --> 00:16:58,630
You might have a problem where some
store is constantly busy and the

283
00:16:58,630 --> 00:17:01,870
coffee serving time is more than
like 10 minutes or 15 minutes.

284
00:17:02,110 --> 00:17:06,210
So what how a machine learning model
can help, in this case, how to optimize

285
00:17:06,210 --> 00:17:11,640
the resources and how to bring more
stores are more people like baristas

286
00:17:11,640 --> 00:17:13,980
to sell coffee at that store, right?

287
00:17:14,190 --> 00:17:18,240
So these are the problems
which we need first to find

288
00:17:18,240 --> 00:17:19,355
the solution for the problem.

289
00:17:20,085 --> 00:17:23,295
So that requires collaboration
with different teams, different

290
00:17:23,345 --> 00:17:26,875
stores those kind of locations to
understand what problems they're

291
00:17:26,875 --> 00:17:29,705
facing and in generally you, if you.

292
00:17:30,425 --> 00:17:32,345
Divide all this into three.

293
00:17:32,765 --> 00:17:34,865
You can divide broadly
into three categories.

294
00:17:34,865 --> 00:17:36,875
One is the platform team composition.

295
00:17:37,145 --> 00:17:41,975
So when you try to deploy a model, you
basically need a platform where you build

296
00:17:41,975 --> 00:17:46,685
a model, train a model, deploy a model,
and serve it and monitor the model, right?

297
00:17:46,925 --> 00:17:51,290
So there's a platform team which works
on improving the infrastructure and

298
00:17:51,650 --> 00:17:56,810
making a, making sure the infrastructure
stands over time or whenever it requires

299
00:17:56,810 --> 00:17:59,090
a revamp, they revamp the platform.

300
00:17:59,930 --> 00:18:03,700
And do constant updates to the platform,
and cross-functional collaboration.

301
00:18:04,030 --> 00:18:06,370
So there are teams who use the platform.

302
00:18:06,430 --> 00:18:10,000
There are teams who build the platform,
and there are scientists who try to

303
00:18:10,000 --> 00:18:12,160
develop models on top of the platform.

304
00:18:12,520 --> 00:18:16,330
And there are domain teams
who consume the model from the

305
00:18:16,330 --> 00:18:17,910
pla the model output, right?

306
00:18:18,210 --> 00:18:20,460
So there should be alignment across teams.

307
00:18:20,960 --> 00:18:25,220
When you are trying to solve the
problem and adoption strategies, right?

308
00:18:25,490 --> 00:18:29,660
You have to, whenever there's a
change or trying to push, it's very

309
00:18:29,660 --> 00:18:34,110
important that the change is there's
a lot of governance around the change.

310
00:18:34,370 --> 00:18:37,950
Like security issues or any
other checks in place, right?

311
00:18:37,950 --> 00:18:40,020
Suppose you, you are
trying to push a change.

312
00:18:40,020 --> 00:18:42,480
It's very important that you create
a pull request for the change.

313
00:18:43,020 --> 00:18:44,610
And then there's a review mechanism.

314
00:18:44,790 --> 00:18:47,850
Even before the change, there
should be a design review in

315
00:18:47,850 --> 00:18:49,530
place if there's a major change.

316
00:18:50,130 --> 00:18:53,070
And even for small bug fixes,
you should have reviews in place.

317
00:18:53,280 --> 00:18:56,670
And once the reviews are approved there,
there should be some kind of a security

318
00:18:56,670 --> 00:19:00,660
scan in place, which can detect any
security or vulnerability issues and block

319
00:19:00,660 --> 00:19:05,740
the merge even before the change gets
pushed to the development environment.

320
00:19:05,790 --> 00:19:08,275
And then there should be automated
strategies where you can.

321
00:19:08,775 --> 00:19:09,885
Work with teams.

322
00:19:10,185 --> 00:19:15,725
So every use case is tested and the
whole workflow is done seamlessly, right?

323
00:19:15,995 --> 00:19:18,905
So these kind of adoption
strategies needs to be there.

324
00:19:19,275 --> 00:19:22,905
So whenever there, there is a, for
example, you're trying to migrate as

325
00:19:22,905 --> 00:19:25,215
a team to some higher version of the.

326
00:19:25,715 --> 00:19:29,645
And it means you need to have a
proper way to communicate that

327
00:19:29,915 --> 00:19:31,865
migration going is going to happen.

328
00:19:32,045 --> 00:19:35,705
So the teams who are using your platform
are ready for that particular change.

329
00:19:36,185 --> 00:19:41,915
So tho those are the things which
we need to take into account for

330
00:19:41,915 --> 00:19:46,615
organization excellence and the
next and most important thing here

331
00:19:46,615 --> 00:19:48,955
is the scaling challenges, right?

332
00:19:49,405 --> 00:19:53,275
This, I'm just telling you, based on
my past experience, when we started

333
00:19:53,275 --> 00:19:58,790
building the ML platform we started
with a very small pilot model, and

334
00:19:58,790 --> 00:20:03,710
then finally we went at scale to handle
three to four plus models, right?

335
00:20:04,310 --> 00:20:07,130
So when you are trying do that.

336
00:20:07,630 --> 00:20:11,960
When you're trying to evolve along with
the teams, along with the scientists it

337
00:20:12,170 --> 00:20:16,460
requires a lot of optimization strategies
and a lot of caching strategies.

338
00:20:16,880 --> 00:20:21,960
So like request batching when when you
have like single to multiple requests,

339
00:20:22,230 --> 00:20:27,810
the throughput is so important and
the latency is more so important.

340
00:20:28,170 --> 00:20:31,280
So in order to handle that,
because batching is something

341
00:20:31,280 --> 00:20:33,110
which you need to take care.

342
00:20:33,875 --> 00:20:35,255
Caching strategies, right?

343
00:20:35,255 --> 00:20:37,955
This we discussed like
in the previous slides.

344
00:20:38,315 --> 00:20:44,145
Basically, you should have a way to have
support multi-level caches so that way you

345
00:20:44,145 --> 00:20:50,565
can eliminate lot of a PA calls, database
calls, and when you have multiple models

346
00:20:50,685 --> 00:20:52,395
which require transformation, right?

347
00:20:52,455 --> 00:20:54,165
Like model chaining kind of things.

348
00:20:54,705 --> 00:20:56,055
Caching is always useful.

349
00:20:56,575 --> 00:20:58,645
You don't hit the model unless.

350
00:20:59,135 --> 00:21:00,575
You are out of that cash, right?

351
00:21:00,575 --> 00:21:02,255
You don't have a cash in place.

352
00:21:02,525 --> 00:21:07,155
So that helps a lot when it
comes to model serving, right?

353
00:21:07,725 --> 00:21:11,165
And hardware aware
optimization is another thing.

354
00:21:11,505 --> 00:21:16,530
So whether you are using GPU or
TPU depends on how large your model

355
00:21:16,530 --> 00:21:18,210
is and how large your scale is.

356
00:21:18,570 --> 00:21:21,750
So that kind of hardware aware
optimization is required.

357
00:21:21,780 --> 00:21:23,580
Multi-tenancy is another thing.

358
00:21:23,940 --> 00:21:27,565
So you always cannot have a single
point of failure, so you should

359
00:21:27,565 --> 00:21:31,505
have this multitenancy and and
it involves like multiple sites

360
00:21:31,595 --> 00:21:32,975
or multiple countries, right?

361
00:21:33,185 --> 00:21:36,575
You should, your server should
be located as close to the site.

362
00:21:36,785 --> 00:21:39,725
So the latency is latency is quite good.

363
00:21:40,085 --> 00:21:44,790
So those are the things that
you need to consider geographic

364
00:21:44,790 --> 00:21:46,770
distribution, optimizing global.

365
00:21:47,595 --> 00:21:50,685
Latency and then edge deployment patterns.

366
00:21:50,895 --> 00:21:52,635
CDN for example, Netflix.

367
00:21:53,185 --> 00:21:58,015
If you see Netflix as a company, all
their models, CDN plays a MA major

368
00:21:58,015 --> 00:22:02,695
role because the way they serve their
infrastructure is built on top of CDNs.

369
00:22:03,085 --> 00:22:06,145
There's no call which goes beyond
the CDN to the actual server.

370
00:22:06,775 --> 00:22:08,335
So that's the way the
infrastructure built.

371
00:22:09,085 --> 00:22:12,265
So that's how you are able
to see the movies so fast.

372
00:22:12,685 --> 00:22:15,215
So the streaming is so
fast in Netflix, right?

373
00:22:15,275 --> 00:22:15,915
That's one of the reason.

374
00:22:16,415 --> 00:22:19,595
Now we are going to talk
about the security, compliance

375
00:22:19,595 --> 00:22:20,975
and governance, right?

376
00:22:21,335 --> 00:22:26,005
So I'll tell you some of the use
cases which I encountered in the past.

377
00:22:26,395 --> 00:22:29,405
So there are cases
you'll handle data with.

378
00:22:30,100 --> 00:22:35,720
PA information and like credit card
information or in some cases you'll

379
00:22:35,720 --> 00:22:37,910
handle very sensitive data, right?

380
00:22:38,240 --> 00:22:42,050
You should have proper security and
compliance in place to, before even

381
00:22:42,050 --> 00:22:43,580
dealing with that kind of data.

382
00:22:44,180 --> 00:22:48,920
So it's very important that those data are
masked and not leaked anywhere outside.

383
00:22:49,310 --> 00:22:50,340
And in some cases you.

384
00:22:50,795 --> 00:22:53,665
You have to manage those
legal regulated requirements.

385
00:22:53,665 --> 00:22:57,065
Also, when you're dealing with
health healthcare, or any other

386
00:22:57,065 --> 00:22:59,615
financial related models, right?

387
00:22:59,915 --> 00:23:03,365
You should make sure all these
regulated requirements are in place.

388
00:23:03,785 --> 00:23:04,595
GDPR, hipa.

389
00:23:05,095 --> 00:23:07,825
Financial regulations
and automated complaints.

390
00:23:07,825 --> 00:23:08,515
Checking, right?

391
00:23:09,205 --> 00:23:10,675
These are all most important.

392
00:23:10,765 --> 00:23:13,765
Even though you try to automate
everything, there should be proper

393
00:23:13,765 --> 00:23:17,845
audit trail of what is being done,
and data lineage is another thing.

394
00:23:18,175 --> 00:23:22,370
Suppose there is a feature you are trying
to use, we should know from where the

395
00:23:22,370 --> 00:23:26,030
feature is getting generated, who is
consuming the feature, and what are all

396
00:23:26,030 --> 00:23:30,459
the different places the feature will
go, that way you can backtrack and see.

397
00:23:30,970 --> 00:23:33,670
If at all, there's a leak, you
can see where there's a leak.

398
00:23:34,270 --> 00:23:36,910
If they, even if there's a error,
you can know where there's an error.

399
00:23:36,960 --> 00:23:40,470
And it's very important to involve
the security team in each stage.

400
00:23:40,800 --> 00:23:43,939
Even if you're trying to use a
open source or trying to introduce

401
00:23:43,939 --> 00:23:45,649
a new component in your platform.

402
00:23:46,010 --> 00:23:49,909
It's very important that the
security and the governance is

403
00:23:49,909 --> 00:23:51,590
in place for all those kind of.

404
00:23:51,934 --> 00:23:53,254
Changes you're trying to make.

405
00:23:53,554 --> 00:23:57,664
That way you don't have any
surprises or any leaks, right?

406
00:23:57,934 --> 00:24:03,054
So that creates a lot of financial
and other problems if there is a leak.

407
00:24:03,474 --> 00:24:08,494
So in order to avoid that, it's
better to have the security

408
00:24:08,494 --> 00:24:09,844
checks in place beforehand.

409
00:24:10,344 --> 00:24:15,114
So when it comes to feature direct
trends and emerging trend, these

410
00:24:15,114 --> 00:24:16,764
are the four different things.

411
00:24:17,094 --> 00:24:21,264
Edge computation, real time learning,
federated learning and auto ML

412
00:24:21,264 --> 00:24:25,164
integration, or something which you
need to account for in feature, right?

413
00:24:25,464 --> 00:24:29,604
For example, auto ml. It reduces the
expertise required for model development.

414
00:24:29,724 --> 00:24:32,054
Suppose you're trying to rapidly.

415
00:24:32,820 --> 00:24:34,020
Push the models right?

416
00:24:34,320 --> 00:24:38,080
It's always good to have some
auto ML integration in place.

417
00:24:38,080 --> 00:24:39,699
Your platform should support that.

418
00:24:40,060 --> 00:24:45,469
That way it automatically trains
and tries to deploy new versions

419
00:24:45,469 --> 00:24:48,884
of models, and you should have
proper monitoring capabilities.

420
00:24:49,850 --> 00:24:56,299
So this auto ml model, which is getting
generated is properly validated and edge

421
00:24:56,299 --> 00:25:01,219
computing is something which is close
to data sources and end users, right?

422
00:25:01,459 --> 00:25:02,870
Sometimes platform architecture.

423
00:25:03,379 --> 00:25:08,209
It should manage distributed deployments
across diverse hardware, so that,

424
00:25:08,239 --> 00:25:12,114
that's when this edge computing plays
a key role and real time learning.

425
00:25:12,614 --> 00:25:17,289
So based on new data, your model
should be able to learn and we

426
00:25:17,289 --> 00:25:20,669
should be able to fix the model
and adapt to the new data, right?

427
00:25:20,969 --> 00:25:23,789
So that's when you need
this real time learning.

428
00:25:24,119 --> 00:25:28,349
And your platform should support all the
online learning algorithms, streaming data

429
00:25:28,349 --> 00:25:33,039
processing, and dynamic model updating to
support this kind of real time learning.

430
00:25:33,399 --> 00:25:37,309
Federated learning is enabling
model development across.

431
00:25:37,879 --> 00:25:40,729
Distributed data sets without
centralizing the data.

432
00:25:41,060 --> 00:25:46,340
So it requires specific coordination
mechanisms like privacy, preserving

433
00:25:46,340 --> 00:25:49,129
techniques, and distributed
model aggregation capabilities.

434
00:25:49,139 --> 00:25:54,179
These are some of the f components
for feature emerging trends.

435
00:25:54,179 --> 00:25:58,289
One year, once your model is at
scale, in order to keep up with

436
00:25:58,289 --> 00:26:01,589
the feature, you need all these
kind of capabilities in place.

437
00:26:02,089 --> 00:26:05,629
To add on to what we discussed
in the previous slide, right?

438
00:26:05,989 --> 00:26:10,069
In order to create a successful
ML inference platform, you

439
00:26:10,069 --> 00:26:11,389
require a balance between.

440
00:26:11,889 --> 00:26:12,969
Multiple things.

441
00:26:13,239 --> 00:26:16,209
One is the performance and
the second is the cost.

442
00:26:16,569 --> 00:26:20,679
Third is the developer
productivity and operation control.

443
00:26:21,309 --> 00:26:26,349
Sometimes innovation is so important,
especially with the generative ai.

444
00:26:26,379 --> 00:26:30,549
Now, innovation plays a
key role and reliability.

445
00:26:30,549 --> 00:26:32,499
How reliable is the data you give?

446
00:26:32,579 --> 00:26:35,909
For example, people try to go
for Amazon Prime as a membership

447
00:26:35,909 --> 00:26:36,959
because they find that.

448
00:26:37,539 --> 00:26:39,939
Whatever they search
in Amazon is relatable.

449
00:26:40,579 --> 00:26:45,979
But the reliability is out of our picture,
then it cause a lot of other concerns.

450
00:26:46,189 --> 00:26:51,359
Similarly, how can you rely on a
platform if it's able to serve all the

451
00:26:51,359 --> 00:26:52,734
kind of traffic without any issues?

452
00:26:53,599 --> 00:26:56,774
If we can autoscale if you
can really that, that's why

453
00:26:56,774 --> 00:26:58,304
reliability is most important.

454
00:26:58,754 --> 00:27:02,274
And the other thing is you should
achieve a balance through thoughtful

455
00:27:02,274 --> 00:27:06,144
architecture, robust automation,
and strong organizational alignment.

456
00:27:06,244 --> 00:27:11,214
This investment is is mainly important
for building sophisticated ML platforms

457
00:27:11,664 --> 00:27:16,929
and you try to reduce any operational
or add r. Any other overheads which

458
00:27:16,929 --> 00:27:18,489
can arise in the platform, right?

459
00:27:18,909 --> 00:27:22,019
And make sure your deployments
are faster and seamless.

460
00:27:22,289 --> 00:27:26,099
That way you go to the market
on time or even ahead of time.

461
00:27:26,519 --> 00:27:28,519
So that's the main goal.

462
00:27:29,019 --> 00:27:34,330
And cross team collaboration and platform
excellence are part of that goal.

463
00:27:34,580 --> 00:27:39,439
Security, whatever we discussed in
the previous slides, those are all the

464
00:27:39,439 --> 00:27:41,629
building blocks to achieve that goal.

465
00:27:41,929 --> 00:27:42,290
Yeah.

466
00:27:42,790 --> 00:27:46,990
Thank you team for listening to me
patiently, and if you have any doubts

467
00:27:46,990 --> 00:27:49,570
or any questions, feel free to ask me.

468
00:27:49,980 --> 00:27:51,420
I can get back to you on this.

469
00:27:51,920 --> 00:27:52,430
Thank you.

