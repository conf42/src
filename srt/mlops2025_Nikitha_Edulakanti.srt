1
00:00:00,500 --> 00:00:01,220
Hello everyone.

2
00:00:01,580 --> 00:00:02,270
I'm Nikita ti.

3
00:00:03,230 --> 00:00:06,230
I'm a manager of Data and AI Solutions.

4
00:00:06,730 --> 00:00:11,860
It's an honor to be here at conference 42
to share my perspective on a topic that

5
00:00:11,860 --> 00:00:17,130
is shaping the future of M Healthcare
M Lops at scale designing govern

6
00:00:17,310 --> 00:00:19,470
AI pipelines for healthcare impact.

7
00:00:19,970 --> 00:00:22,735
And I like to open with this
statement from the deck.

8
00:00:23,235 --> 00:00:26,195
In healthcare, AI doesn't
just need to be powerful.

9
00:00:26,405 --> 00:00:27,485
It needs to be trusted.

10
00:00:27,985 --> 00:00:30,835
That single line captures the
heart of today's discussion.

11
00:00:31,335 --> 00:00:32,505
Let me give you an example.

12
00:00:33,375 --> 00:00:39,335
Think about a model that predicts ICU
admissions with 95% accuracy on paper.

13
00:00:39,340 --> 00:00:43,595
It's extremely powerful, but if
clinicians and regulators contrast

14
00:00:43,715 --> 00:00:44,910
how it reach those predictions.

15
00:00:45,785 --> 00:00:47,225
It may actually never be used.

16
00:00:47,725 --> 00:00:51,475
Governance is what makes that
model usable and impactful.

17
00:00:51,975 --> 00:00:57,035
Why MOPS matters in healthcare,
AI is transforming healthcare.

18
00:00:57,965 --> 00:01:01,925
It's enabling everything from
advanced diagnosis to improved

19
00:01:01,985 --> 00:01:03,125
operational efficiency.

20
00:01:04,055 --> 00:01:07,835
But if we look at the challenges
highlighted here, we see that

21
00:01:07,835 --> 00:01:09,965
innovation often stalls because of.

22
00:01:10,445 --> 00:01:14,615
Fragmented pipelines, data
silos and compliance risks.

23
00:01:15,115 --> 00:01:18,805
Without a structured approach,
trust is difficult to establish.

24
00:01:19,015 --> 00:01:22,615
And scaling AI across healthcare
systems become nearly impossible.

25
00:01:23,115 --> 00:01:24,225
How can we solve this?

26
00:01:24,735 --> 00:01:30,075
Governed, scalable, and secure MLO
pipelines address these issues by

27
00:01:30,075 --> 00:01:34,485
unifying workflows and embedding
compliance into every stage.

28
00:01:34,985 --> 00:01:39,005
This enables faster innovation,
safer integration into clinical

29
00:01:39,005 --> 00:01:41,615
practice, and more impactful outcomes.

30
00:01:42,115 --> 00:01:45,355
The result is better patient care
and more efficient operations.

31
00:01:45,855 --> 00:01:49,815
An example would be a hospital
that builds a pneumonia detection

32
00:01:49,815 --> 00:01:51,375
model from chest x-rays.

33
00:01:51,875 --> 00:01:55,145
It works extremely well, but
fails to expand across the

34
00:01:55,145 --> 00:01:59,090
system due to inconsistent data
formats and compliance concerns.

35
00:01:59,590 --> 00:02:03,190
A govern pipeline standardizes
and secures the flow, allowing

36
00:02:03,190 --> 00:02:04,720
that model to scale safely.

37
00:02:05,220 --> 00:02:11,490
So we see that a govern pipeline is what
solves for it, solves for scalability.

38
00:02:11,490 --> 00:02:11,640
Here

39
00:02:12,140 --> 00:02:15,575
we have four major challenges
we must overcome to scale AI

40
00:02:15,575 --> 00:02:16,835
responsibly in healthcare.

41
00:02:17,335 --> 00:02:18,655
First is data governance.

42
00:02:18,745 --> 00:02:20,095
Second is model trust.

43
00:02:20,575 --> 00:02:24,295
Third one is integration, and fourth
one is operational scalability.

44
00:02:24,795 --> 00:02:26,085
What does data governance mean?

45
00:02:26,925 --> 00:02:32,475
It's ensuring that we are compliant
with HIPAA in US GDPR in Europe

46
00:02:33,225 --> 00:02:36,885
and protecting PHI and PAI at
every stage of the pipeline.

47
00:02:37,385 --> 00:02:42,005
If lab results are ingested without proper
de-identification, a single breach could

48
00:02:42,005 --> 00:02:43,805
compromise thousands of patient records.

49
00:02:44,765 --> 00:02:46,475
So governance is extremely important.

50
00:02:46,975 --> 00:02:48,175
How do we model trust?

51
00:02:49,105 --> 00:02:53,515
We model trust by addressing
bias, drift and explainability.

52
00:02:53,515 --> 00:02:57,525
To build confidence in AI decisions,
clinicians need to understand

53
00:02:57,525 --> 00:03:02,090
and trust why a model is making a
recommendation and integrating these

54
00:03:02,510 --> 00:03:04,250
seamlessly into clinical workflow.

55
00:03:04,750 --> 00:03:08,680
If the tool disrupts care delivery
or adds extra burdens, they won't

56
00:03:08,680 --> 00:03:10,990
be adopted by doctors or clinicians.

57
00:03:11,490 --> 00:03:13,440
Let's say there's an AI trash tool.

58
00:03:13,980 --> 00:03:16,230
It requires doctor to log
into a separate portal.

59
00:03:17,070 --> 00:03:23,400
It often fails the same tool integrated
directly into EHR would more likely

60
00:03:23,400 --> 00:03:25,470
succeed because there's no extra clicks.

61
00:03:25,470 --> 00:03:28,080
There's no extra logins,
and how do we scale it?

62
00:03:28,580 --> 00:03:31,460
Expanding from small
pilots to enterprise wide.

63
00:03:31,460 --> 00:03:35,030
AI deployments remain one
of the toughest barriers.

64
00:03:35,530 --> 00:03:40,690
Example, a readmission risk model
may be piloted in one hospital, but

65
00:03:40,690 --> 00:03:45,430
scaling across 50 requires standards,
pipelines, automation and monitoring.

66
00:03:46,390 --> 00:03:51,340
So taking all this together, these
challenges highlight that AI success is

67
00:03:51,340 --> 00:03:53,500
not just about developing advanced models.

68
00:03:54,355 --> 00:03:58,615
It's about building governance,
building trust, and infrastructure

69
00:03:58,615 --> 00:04:00,355
required for adoption at scale.

70
00:04:00,855 --> 00:04:03,255
How do we define ML ops for healthcare?

71
00:04:03,755 --> 00:04:09,274
ML ops in healthcare combines the best of
DevOps practices with the AI ML lifecycle

72
00:04:09,784 --> 00:04:13,505
while embedding strict governance to
ensure compliance, security, and trust.

73
00:04:14,005 --> 00:04:19,065
The MOPS lifecycle consists of
data ion pre-processing, training,

74
00:04:19,185 --> 00:04:20,805
deployment, and monitoring.

75
00:04:21,305 --> 00:04:24,724
The key difference in healthcare is
that compliance and security must

76
00:04:24,724 --> 00:04:29,224
be embedded at every stage, so it's
not an afterthought, but in every

77
00:04:29,224 --> 00:04:32,854
step of the lifecycle, we want to
embed a compliance and security.

78
00:04:33,354 --> 00:04:34,614
What does that this mean?

79
00:04:35,019 --> 00:04:38,979
It means that all data flowing through
the pipelines is traceable and auditable.

80
00:04:39,479 --> 00:04:45,469
Models are built on high quality bias,
free data sets, accuracy, accountability,

81
00:04:45,500 --> 00:04:47,690
and compliance are maintained end-to-end.

82
00:04:48,190 --> 00:04:50,469
So I work for a dialysis company.

83
00:04:50,770 --> 00:04:52,150
So let me give you an example.

84
00:04:52,650 --> 00:04:55,740
Kidney disease progression
model that ingest EMR data.

85
00:04:56,455 --> 00:05:02,159
We processs it with PHA, masking trains
with bias checks deploys via secure

86
00:05:02,189 --> 00:05:05,580
APIs and monitors Drift quarterly.

87
00:05:06,359 --> 00:05:07,679
This is ML Ops in action.

88
00:05:07,919 --> 00:05:10,049
It's not just powerful, it's trusted.

89
00:05:10,549 --> 00:05:13,374
There are four pillars to
support responsible AI delivery.

90
00:05:13,874 --> 00:05:19,424
Pillars of governed AI pipelines,
data lineage and quality model

91
00:05:19,424 --> 00:05:24,554
governance, security and compliance,
scalability, automation and monitoring.

92
00:05:25,054 --> 00:05:26,584
What is data lineage and quality?

93
00:05:27,084 --> 00:05:31,014
It's ensuring all data is
traceable, accurate, and we are

94
00:05:31,014 --> 00:05:32,754
building a trustworthy foundation.

95
00:05:33,254 --> 00:05:34,694
And how do we model governance?

96
00:05:35,194 --> 00:05:40,444
We want AI models to undergo validation,
explainability checks, and ethical

97
00:05:40,444 --> 00:05:44,364
reviews to safeguard responsible
use for security and compliance.

98
00:05:44,815 --> 00:05:47,395
We want sensitive patient
data to be protected through

99
00:05:47,455 --> 00:05:51,824
encryption and monitoring that
aligns with HIPAA and GDPR.

100
00:05:52,324 --> 00:05:54,274
How do we scale, automate, and monitor?

101
00:05:54,774 --> 00:05:55,974
CICD pipelines.

102
00:05:55,974 --> 00:06:00,174
Accelerate deployment and continuous
monitoring with drift detection

103
00:06:00,354 --> 00:06:01,974
ensures AI remains effective.

104
00:06:02,474 --> 00:06:07,544
So together these pillars provide the
re reliability and transparency that

105
00:06:07,544 --> 00:06:11,924
clinicians, regulators, and patients
need to embrace AI in healthcare.

106
00:06:12,424 --> 00:06:15,109
Let me walk you through
the workflow step by step.

107
00:06:15,609 --> 00:06:18,669
So this is the architecture
of a govern ML ops pipeline.

108
00:06:19,169 --> 00:06:20,609
We have ingestion first.

109
00:06:21,109 --> 00:06:25,719
The first step in the workflow data
is collected from various sources,

110
00:06:26,259 --> 00:06:32,079
from EMRs, from IOT devices, imaging
systems and claims platforms.

111
00:06:32,579 --> 00:06:36,679
This creates a rich foundation for
robust models, and in the governance

112
00:06:36,679 --> 00:06:38,599
layer we have data catalogs.

113
00:06:39,589 --> 00:06:45,109
We put in access controls and audit trails
to enforce compliance and ensure trust.

114
00:06:45,609 --> 00:06:50,854
And for ML workflow, we train the
models, we validate them, and we

115
00:06:50,854 --> 00:06:53,524
check for explainability before
they're put into production.

116
00:06:54,024 --> 00:06:59,969
And for deployment models are
deployed securely through APIs and

117
00:07:00,749 --> 00:07:03,359
containerized environments with hybrid.

118
00:07:04,004 --> 00:07:07,864
Our multi-cloud setups providing
flexibility and for monitoring,

119
00:07:08,644 --> 00:07:12,894
we continuously monitor to
detect drifts, anomalies and

120
00:07:12,894 --> 00:07:14,454
performance issues in real time.

121
00:07:14,954 --> 00:07:18,194
Human in the loop validation
ensures the AI demands clinically

122
00:07:18,194 --> 00:07:19,395
relevant and trustworthy.

123
00:07:19,669 --> 00:07:24,789
For example, IOT devices
from dialysis stream patient

124
00:07:24,789 --> 00:07:26,289
vitals into carbon pipelines.

125
00:07:27,039 --> 00:07:30,939
If sudden anomalies like a drop in
blood pressure appear, clinicians are

126
00:07:31,000 --> 00:07:32,860
alerted before the patient deteriorates.

127
00:07:33,189 --> 00:07:34,809
This is ML Lops Saving Lives.

128
00:07:35,309 --> 00:07:35,520
Okay.

129
00:07:36,020 --> 00:07:38,569
Generative AI in healthcare, ML Lops.

130
00:07:39,069 --> 00:07:44,669
This shows how generative AI is adding
new capabilities to healthcare ML lops by

131
00:07:44,669 --> 00:07:46,919
automating data curation and automation.

132
00:07:47,549 --> 00:07:53,130
By enhancing explainability producing
clinician friendly summaries, accelerating

133
00:07:53,130 --> 00:07:58,140
documentation and coding workflows,
adding responsible guardrails such as

134
00:07:58,140 --> 00:08:00,510
bias mitigation and clinical validation.

135
00:08:01,010 --> 00:08:03,919
This means that Gen AI can
bridge the gap between complex

136
00:08:03,919 --> 00:08:05,809
models and human decision making.

137
00:08:06,309 --> 00:08:10,474
Instead of putting only a numeric risk
score, a Gen AI layer can explain.

138
00:08:10,974 --> 00:08:15,174
The patient is at elevated risk due
to abnormal creatine levels, history

139
00:08:15,174 --> 00:08:18,804
of hypertension, and two prior
admissions in the last six months.

140
00:08:19,304 --> 00:08:23,625
So it gives us the reasoning
behind it, not just the score.

141
00:08:23,924 --> 00:08:28,984
So it's explaining why the patient
is at risk, but while the potential

142
00:08:28,984 --> 00:08:30,454
is immense, so are the risk.

143
00:08:31,324 --> 00:08:35,014
Without governance, gene AI could
hallucinate or amplify bias.

144
00:08:35,899 --> 00:08:39,439
That is why governance remains
very critical here as well.

145
00:08:39,939 --> 00:08:41,919
What is the impact across healthcare?

146
00:08:42,419 --> 00:08:46,199
When govern mop pipelines are
in place, the impact across

147
00:08:46,199 --> 00:08:47,459
healthcare is substantial.

148
00:08:47,959 --> 00:08:49,729
We see improved patient outcomes.

149
00:08:50,569 --> 00:08:56,389
We see reduced operational costs, strong
compliance, accelerated innovation cycles.

150
00:08:56,889 --> 00:08:58,810
How do we see improved patient outcomes?

151
00:08:59,310 --> 00:09:03,389
AI powered insights enable earlier
interventions and better treatment

152
00:09:03,389 --> 00:09:06,989
decisions resulting in healthier
patients and fewer readmissions.

153
00:09:07,489 --> 00:09:12,520
For example, a sepsis model
deployed in IC flagged risk six

154
00:09:12,520 --> 00:09:14,620
hours before symptoms enable.

155
00:09:15,120 --> 00:09:19,819
So this is life saving early treatment,
and how do we reduce operational costs?

156
00:09:20,319 --> 00:09:24,069
Automation cuts, administrative
overhead and optimizes workflow.

157
00:09:24,939 --> 00:09:29,949
Automating claims adjudication reduced
manually review workloads by 40% in

158
00:09:29,949 --> 00:09:35,234
some health systems, and for compliance
govern, pipelines ensure alignment with

159
00:09:35,324 --> 00:09:37,364
regulations such as HIPAA and GDPR.

160
00:09:38,204 --> 00:09:41,204
That minimize exposure and
building patient trust.

161
00:09:41,704 --> 00:09:43,774
An example would be a full audit trail.

162
00:09:44,224 --> 00:09:48,214
Short regulators, exactly how
an oncology AI system made its

163
00:09:48,214 --> 00:09:53,155
predictions, avoiding finalities
and accelerated innovation cycles.

164
00:09:54,025 --> 00:09:56,754
Pipelines enable faster movement
from pilot to enterprise

165
00:09:56,754 --> 00:10:00,564
deployment, driving quicker
adoption and continuous improvement.

166
00:10:01,064 --> 00:10:05,175
So in short, government ML lops delivers
value on multiple friends, clinical,

167
00:10:05,295 --> 00:10:07,935
operational, regulatory, and strategic.

168
00:10:08,435 --> 00:10:12,724
To conclude, ML Lops at scale
is essential for ensuring that

169
00:10:12,724 --> 00:10:17,015
healthcare organizations can adopt
AI in a sustainable and impact way.

170
00:10:17,515 --> 00:10:21,865
Without structured pipelines, projects
will remain stuck as pilots and fail

171
00:10:21,865 --> 00:10:26,175
to reach enterprise scale Governance
plays a central role by embedding

172
00:10:26,175 --> 00:10:30,525
trust, compliance, and safety at
every stage of the AI lifecycle.

173
00:10:31,025 --> 00:10:36,545
And while generative AI can acceler
development and insights, it

174
00:10:36,545 --> 00:10:38,225
must be integrated responsibly.

175
00:10:38,725 --> 00:10:39,955
So as this slide summarizes.

176
00:10:40,455 --> 00:10:44,565
Successes, technical scalability
plus clinical adoption plus

177
00:10:44,565 --> 00:10:45,765
compliance first design.

178
00:10:46,265 --> 00:10:48,334
So governance is not
the break on innovation.

179
00:10:48,395 --> 00:10:52,745
It's the steering wheel that guides AI
safely and effectively into healthcare.

180
00:10:53,245 --> 00:10:58,255
It's just as seat belts and traffic lights
that don't slow down cars, but makes safe

181
00:10:58,255 --> 00:11:03,010
driving governance ensures AI can operate
at full speed without crashing trust.

182
00:11:03,510 --> 00:11:05,550
Thank you for your time and attention.

183
00:11:05,980 --> 00:11:09,460
I hope this session has given you a
clear understanding of why governance

184
00:11:09,460 --> 00:11:13,480
in ML Lops is not just a regulatory
requirement, but the foundation for

185
00:11:13,480 --> 00:11:15,220
building trust in healthcare ai.

186
00:11:15,720 --> 00:11:16,230
Thank you.

