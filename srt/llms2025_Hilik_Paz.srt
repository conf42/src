1
00:00:00,090 --> 00:00:01,290
Hi everyone, and welcome.

2
00:00:01,470 --> 00:00:03,270
I'm LIC Pass from Marto ai.

3
00:00:03,870 --> 00:00:06,840
ATO is a platform for
managing your gen AI assets.

4
00:00:06,900 --> 00:00:11,070
This includes your prompts, model
configurations, data sets, and events

5
00:00:11,580 --> 00:00:15,420
from the minute you write your initial
prompt testing and experimenting with it

6
00:00:15,420 --> 00:00:19,620
to make sure it performs as you expect
to the time it's running in production

7
00:00:19,620 --> 00:00:21,720
with detailed observability and metrics.

8
00:00:23,235 --> 00:00:26,805
In this session, we will take a
look at the key role evils play in

9
00:00:26,805 --> 00:00:28,905
bringing your Gen AI up to production.

10
00:00:29,535 --> 00:00:33,285
We'll see the process of designing,
evaluating, and refining prompts

11
00:00:33,315 --> 00:00:34,965
for an LLM based application.

12
00:00:35,415 --> 00:00:36,075
So let's start.

13
00:00:37,215 --> 00:00:38,085
So what are evils?

14
00:00:39,045 --> 00:00:42,585
Evils are a systematic method we
use to measure the performance

15
00:00:42,585 --> 00:00:46,129
capabilities and basically the
replies that we get from AI models.

16
00:00:47,355 --> 00:00:51,345
They are key in determining how well
a prompt or a model output meets the

17
00:00:51,345 --> 00:00:53,145
specific objectives that we have.

18
00:00:53,805 --> 00:00:58,155
The key features for evals are being
measurable, being able to quantify

19
00:00:58,155 --> 00:01:04,905
various aspects like accuracy, relevancy,
structure, repeatability, meaning

20
00:01:04,965 --> 00:01:09,525
consistent assessment across different
iterations, and being actionable,

21
00:01:09,675 --> 00:01:13,815
provide the insights we need to refine
the prompt and to improve the outcome.

22
00:01:16,065 --> 00:01:17,354
So what have changed?

23
00:01:17,414 --> 00:01:19,964
Software testing had
been around for decades.

24
00:01:20,024 --> 00:01:22,335
Why are we talking about
a new method of testing?

25
00:01:23,655 --> 00:01:25,365
The first thing is the boundary.

26
00:01:26,235 --> 00:01:30,554
We move from a very well-defined
and structured output and error

27
00:01:30,554 --> 00:01:34,994
format in traditional APIs
to complex and unpredictable

28
00:01:34,994 --> 00:01:37,005
formats, errors and mistakes.

29
00:01:38,505 --> 00:01:42,375
We are moving toward a non-deterministic
world where even similar and

30
00:01:42,375 --> 00:01:46,395
sometimes identical input receives
or might receive different outputs.

31
00:01:47,025 --> 00:01:52,365
So we are moving from a very clear pass
or fail criteria to a world where we

32
00:01:52,365 --> 00:01:56,804
would measure different aspects of the
replies that we get, and we will compute

33
00:01:56,804 --> 00:02:00,495
some kind of a scoring that will tell
us if we are hitting the target or not.

34
00:02:02,024 --> 00:02:05,625
EVAs transform prompt engineering
from guesswork into a scientific

35
00:02:05,625 --> 00:02:09,794
process by making interactions
measurable and repeatable.

36
00:02:10,514 --> 00:02:14,595
They will ensure LLM output aligns
with our business objectives, enable

37
00:02:14,595 --> 00:02:18,795
data-driven decision making and
prompt refinement and reduce the risk

38
00:02:18,795 --> 00:02:20,625
of unforeseen issues in production.

39
00:02:23,204 --> 00:02:25,365
So let's take a look
at an example use case.

40
00:02:27,015 --> 00:02:28,665
This is our demo application.

41
00:02:29,144 --> 00:02:32,625
Imagine that you were given a task
of developing a technical support

42
00:02:32,625 --> 00:02:34,605
bot for a company called upma.

43
00:02:36,915 --> 00:02:39,584
The app Master Support bot
is designed to help technical

44
00:02:39,584 --> 00:02:41,565
users find answers efficiently.

45
00:02:41,954 --> 00:02:45,975
It pulls information from various sources
and a knowledge base, and it aims to

46
00:02:45,975 --> 00:02:48,345
provide an accurate, concise response.

47
00:02:48,915 --> 00:02:52,065
Our challenge is to craft a
prompt that will ensure the bot

48
00:02:52,125 --> 00:02:53,715
delivers high quality answers.

49
00:02:56,025 --> 00:02:59,805
So let's take a look at our initial
prompt and the app master support bot.

50
00:03:01,785 --> 00:03:04,515
Here's the first version of
our app Master Support bot.

51
00:03:05,565 --> 00:03:06,825
Let's try to ask something.

52
00:03:12,915 --> 00:03:17,475
We got a very simplistic reply and not
something that would really help our

53
00:03:17,475 --> 00:03:19,905
users, so let's see how we can improve.

54
00:03:21,524 --> 00:03:25,755
So we got our vote up and running,
but how do we measure success?

55
00:03:26,355 --> 00:03:29,234
We'll need to define criteria
for each business requirement.

56
00:03:29,234 --> 00:03:31,905
We got, for example, response relevancy.

57
00:03:31,905 --> 00:03:35,595
Its ability to build on the knowledge
we pass in the context, et cetera.

58
00:03:36,135 --> 00:03:38,894
We'll use different evil
methods for each criteria.

59
00:03:38,984 --> 00:03:43,665
We'll see some examples in a minute, and
we will build test data, which we can use

60
00:03:43,665 --> 00:03:46,035
to iterate and have a complete test case.

61
00:03:46,740 --> 00:03:50,340
We've seen that good evils are aligned
with the business goals that we have.

62
00:03:50,430 --> 00:03:54,690
In our specific example, that master
support bot evils could measure

63
00:03:54,720 --> 00:03:58,950
accuracy, politeness, response
times, and the expected output

64
00:03:58,950 --> 00:04:01,620
format that our code expects to get.

65
00:04:03,359 --> 00:04:07,079
So let's first analyze the
different types of evils we can use.

66
00:04:07,200 --> 00:04:10,320
In the first category is
the content-based events.

67
00:04:10,709 --> 00:04:14,459
In our example, we have a data
set with samples for expected

68
00:04:14,459 --> 00:04:16,079
input and expected output.

69
00:04:16,620 --> 00:04:19,980
We can compare the actual
responses that we will get in our

70
00:04:19,980 --> 00:04:21,990
experiment with the expected one.

71
00:04:22,830 --> 00:04:27,060
Such a comparison will use vector
similarities, which is a mechanism

72
00:04:27,060 --> 00:04:30,690
for determining the contextual
distance between two text box.

73
00:04:31,590 --> 00:04:36,210
Other content-based evils might be
checking for existence of certain

74
00:04:36,210 --> 00:04:40,680
words, maybe checking for the
absence of sensitive data, et cetera.

75
00:04:42,540 --> 00:04:44,130
The second category is the format.

76
00:04:44,370 --> 00:04:48,450
It's very often a requirement to return
a response in a very specific format.

77
00:04:48,960 --> 00:04:54,270
It can be that our code depends on such
a structure or fits the user expectation.

78
00:04:54,780 --> 00:04:58,170
Either way, we will need to
look at the format and validate

79
00:04:58,170 --> 00:04:59,490
it against our requirements.

80
00:05:02,565 --> 00:05:06,045
In our example, the code
expects a certain JSO schema.

81
00:05:06,104 --> 00:05:08,025
We will see in a minute how to verify it.

82
00:05:09,315 --> 00:05:13,755
Third category is various qualities
like making sure that the bot is using

83
00:05:13,755 --> 00:05:17,655
the documents that we are passing as
part of the context and is grounding

84
00:05:17,655 --> 00:05:19,515
the answers based on these documents.

85
00:05:20,505 --> 00:05:25,125
And of course, other guard rails or
non-functional aspects like politeness.

86
00:05:25,125 --> 00:05:29,055
In our use case, which is one of the
requirements we got for building the bot.

87
00:05:31,830 --> 00:05:35,190
We can use different mechanisms
for running our evals.

88
00:05:35,190 --> 00:05:39,719
This can be deterministic or rule-based
evals for checking, text matching,

89
00:05:39,719 --> 00:05:44,880
for example, or regular expressions
or model-based events that can use LLM

90
00:05:44,880 --> 00:05:49,020
as a judge or other models for other
capabilities like vector similarity.

91
00:05:49,980 --> 00:05:53,850
In our example, we will combine both
mechanisms where possible we will

92
00:05:53,850 --> 00:05:57,540
be using a rule-based one and where
required we will use a model-based one.

93
00:06:00,525 --> 00:06:02,775
The pros and cones are quite obvious.

94
00:06:02,775 --> 00:06:06,075
The deterministic ones will be
very fast, very cheap to use,

95
00:06:06,075 --> 00:06:08,385
but sometimes limited and rigid.

96
00:06:08,745 --> 00:06:12,825
While the LLM based ones will be
very flexible, we can basically

97
00:06:12,825 --> 00:06:14,685
ask any question we would like.

98
00:06:15,060 --> 00:06:19,320
They will be relatively easy to use,
but they can be expensive and they

99
00:06:19,320 --> 00:06:21,300
themselves are non-deterministic.

100
00:06:21,300 --> 00:06:24,659
So we need to be very careful
of how we measure or how we look

101
00:06:24,659 --> 00:06:26,219
at the answers that they reply.

102
00:06:28,710 --> 00:06:32,760
So let's see a few examples we will
use to optimize our app support bot.

103
00:06:35,325 --> 00:06:37,169
The first one, vector similarity.

104
00:06:38,190 --> 00:06:42,510
As part of the requirement for our
support bot, we got an example of how

105
00:06:42,510 --> 00:06:44,520
an expected output should look like.

106
00:06:44,790 --> 00:06:48,630
This includes both the structure and
the content we expect to get for a

107
00:06:48,630 --> 00:06:51,090
specific set of inputs or user question.

108
00:06:52,890 --> 00:06:57,570
When we run the actual experiment,
we get a reply back from the LLM.

109
00:06:58,260 --> 00:07:01,200
We can read all this text
and try to evaluate ourselves

110
00:07:01,200 --> 00:07:02,400
if they are similar or not.

111
00:07:02,400 --> 00:07:05,255
But in our case, we will
use vector similarity.

112
00:07:06,015 --> 00:07:09,405
That will save us the trouble of
going through all those details.

113
00:07:09,915 --> 00:07:13,844
The response that we got back is very
similar from a contextual point of view.

114
00:07:15,554 --> 00:07:18,164
The second evil will be
a response format eval.

115
00:07:19,754 --> 00:07:24,194
Here we can use a very simple,
deterministic based evil for checking,

116
00:07:24,194 --> 00:07:28,244
for instance, certain regular
expression that will match the expected

117
00:07:28,244 --> 00:07:31,004
J schema that our code requires.

118
00:07:33,509 --> 00:07:35,969
And lastly, we will use
some LLM based evals.

119
00:07:36,689 --> 00:07:40,589
In this example, we wanna verify
that the bot answers in a polite

120
00:07:40,589 --> 00:07:45,149
manner and mentions that it is the
friendly app master support bot.

121
00:07:45,299 --> 00:07:47,789
So we will use another
model to verify this.

122
00:07:50,114 --> 00:07:52,574
So how do we put those evils into action?

123
00:07:53,144 --> 00:07:55,514
We've defined our evils criteria.

124
00:07:55,634 --> 00:07:56,444
What's next?

125
00:07:57,014 --> 00:07:59,264
We will now experiment with our prompt.

126
00:07:59,324 --> 00:08:03,704
We will first make a template out
of our prompt putting variables

127
00:08:03,764 --> 00:08:07,484
or placeholders in the places
we wanna inject dynamic data.

128
00:08:08,024 --> 00:08:14,114
We'll prepare test data, which will be our
data set, and we'll iterate over it with

129
00:08:14,114 --> 00:08:15,944
the evil metrics that we've just defined.

130
00:08:17,955 --> 00:08:20,175
We mentioned the need
to prepare test data.

131
00:08:20,414 --> 00:08:23,474
What makes a good data set
for such an experiment?

132
00:08:24,104 --> 00:08:28,515
The data should represent real world
scenarios, meaning the inputs that we

133
00:08:28,515 --> 00:08:34,244
expect users will enter in our upma
support board app, but we should also

134
00:08:34,244 --> 00:08:39,285
make sure to include data that represents
edge cases and unexpected inputs

135
00:08:39,315 --> 00:08:41,775
that users might enter into our app.

136
00:08:44,055 --> 00:08:47,474
So let's see a live experiment of
everything that we've just defined.

137
00:08:50,984 --> 00:08:53,474
So this is our app support bot notebook.

138
00:08:53,504 --> 00:08:56,595
It includes the prompt and
the instructions that we give

139
00:08:56,599 --> 00:09:01,035
the LLM, the dataset that we
will use for our experiment.

140
00:09:02,565 --> 00:09:05,355
And we already have a couple
of evals that we've defined.

141
00:09:05,714 --> 00:09:12,194
The first one is using for validating that
the bot is answering in a polite manner.

142
00:09:12,855 --> 00:09:17,895
The second one is a simple deterministic
one, making sure that we create the user.

143
00:09:19,785 --> 00:09:24,165
Let's add a couple of others who
will pick the relevancy evil for

144
00:09:24,165 --> 00:09:27,254
making sure that the results are
grounded with the documents that

145
00:09:27,254 --> 00:09:34,305
we've passed, and we can even validate
the JSON schema that we require.

146
00:09:34,665 --> 00:09:37,635
In a deterministic manner
using a regular expression.

147
00:09:40,425 --> 00:09:43,784
We'll run the experiment and
see the results that we get.

148
00:09:48,524 --> 00:09:54,014
So as we can see, we get a relatively
poor results on several of our

149
00:09:54,405 --> 00:09:57,105
ours, including the Jason Schema.

150
00:10:02,474 --> 00:10:06,135
And we can see the individual
failures and specific inputs.

151
00:10:11,355 --> 00:10:15,764
So let's go ahead and improve the prompt
and the instructions we gave to our bot.

152
00:10:19,879 --> 00:10:23,744
We will include a more detailed
example for the response format

153
00:10:23,805 --> 00:10:27,579
as well as strengthening other
instructions, and we'll run it again.

154
00:10:33,030 --> 00:10:37,650
We can also pick another model
and see if that will have any

155
00:10:37,650 --> 00:10:40,319
effect on the results that we get.

156
00:10:40,380 --> 00:10:46,319
So we'll pick CLO and we'll run it again
and let's take a look at the responses

157
00:10:46,319 --> 00:10:48,420
that we got and the evil results.

158
00:10:53,145 --> 00:10:58,635
So as you can see, we got a much better
results this time, and all of our evals

159
00:10:58,754 --> 00:11:01,395
have passed with 100% success rate.

160
00:11:06,794 --> 00:11:09,524
This is true for both
models that we've tried.

161
00:11:09,524 --> 00:11:14,534
So the improvement we did to our
instructions made the difference.

162
00:11:15,645 --> 00:11:18,554
Let's compare all three
experiments that we've run.

163
00:11:21,284 --> 00:11:23,895
And as you can see, we improved
the instructions we gave.

164
00:11:24,494 --> 00:11:28,665
We still get very high similarity
score comparing to the expected results

165
00:11:28,665 --> 00:11:33,675
that we gave as part of the dataset,
but this time we have a much higher

166
00:11:33,675 --> 00:11:37,185
success rate, actually a hundred
percent success rate in our events.

167
00:11:49,005 --> 00:11:52,545
So let's push our new prompt
into production and see

168
00:11:52,545 --> 00:11:54,255
how the new bot behaves.

169
00:11:57,555 --> 00:11:58,994
We'll ask the same question,

170
00:12:01,305 --> 00:12:05,805
and this time we get a much more detailed
answer with various options that would

171
00:12:05,895 --> 00:12:08,204
assist the user in solving his problem.

172
00:12:18,359 --> 00:12:23,159
So to sum up, we've seen how we can
use evils to iterate and improve

173
00:12:23,159 --> 00:12:27,149
until we reach a prompt that
satisfies our business requirements.

174
00:12:29,025 --> 00:12:30,765
Thank you very much for your time today.

175
00:12:30,825 --> 00:12:32,954
I hope this session had been insightful.

176
00:12:33,435 --> 00:12:36,525
If you have any questions,
comments, or would just like to

177
00:12:36,525 --> 00:12:40,335
keep in touch, please follow us
on LinkedIn or visit our website.

178
00:12:40,335 --> 00:12:42,255
And you are welcome to
try us out at arra ai.

