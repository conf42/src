1
00:00:00,500 --> 00:00:02,300
Good morning and good afternoon.

2
00:00:03,200 --> 00:00:09,080
Thank you Con 42 and the organizers for
providing me the amazing opportunity.

3
00:00:09,580 --> 00:00:13,830
And let me start with a brief background
of the problem that you are going

4
00:00:13,830 --> 00:00:15,810
to talk about and how to solve that.

5
00:00:16,309 --> 00:00:21,830
So in the biomedical research field,
there are more than a million of.

6
00:00:22,735 --> 00:00:28,845
Research papers are being published every
year, and if you take the citations of

7
00:00:28,845 --> 00:00:36,235
those research papers it'll multifold
such tsunami of information is out there.

8
00:00:36,735 --> 00:00:41,714
When a researcher comes to do a
research in that field, they first

9
00:00:41,714 --> 00:00:44,175
look for doing the literature review.

10
00:00:44,535 --> 00:00:49,205
That's the first step in any
literature any research process.

11
00:00:49,705 --> 00:00:55,064
When they attempt to do that, they have
to go through these millions of records.

12
00:00:55,214 --> 00:01:00,455
Probably they can do a quick search in
somewhere, but in spite of that, finding

13
00:01:00,455 --> 00:01:03,784
the relevant literature is very difficult.

14
00:01:03,784 --> 00:01:06,935
First of all, there may be
a good literature out there.

15
00:01:07,280 --> 00:01:10,709
That may be hidden from
the researcher search.

16
00:01:11,579 --> 00:01:12,899
That's also not good.

17
00:01:13,399 --> 00:01:17,980
There may be processing issues like
if they take into these millions of

18
00:01:17,980 --> 00:01:22,500
records into account it will take
forever to do that literature review.

19
00:01:23,000 --> 00:01:27,759
So in sum up I would say the average,
the researchers spend like a total of

20
00:01:27,850 --> 00:01:32,969
eight, more than 80 percentage of time
just for doing this literature review.

21
00:01:33,469 --> 00:01:35,479
So this is the clear problem statement.

22
00:01:35,979 --> 00:01:42,899
This slide we already discussed about
it, and our solution for this problem

23
00:01:43,199 --> 00:01:46,679
is intelligent AI literature agents.

24
00:01:47,179 --> 00:01:50,550
It contains four, four

25
00:01:50,670 --> 00:01:54,780
subdomains, like domain adapted lms.

26
00:01:55,390 --> 00:02:00,580
That's LLM is large language
model, advanced rag system.

27
00:02:00,789 --> 00:02:01,389
It is.

28
00:02:02,074 --> 00:02:08,164
Advanced retrieval augmented generation
system, precision, NER System.

29
00:02:08,164 --> 00:02:15,475
N-E-S-N-E-R is nothing but entity
recognition for genes, proteins, and drug

30
00:02:15,725 --> 00:02:19,984
directions, robust ML ops infrastructure.

31
00:02:20,484 --> 00:02:21,984
Let's go through this agenda.

32
00:02:22,255 --> 00:02:26,665
We'll first start, talk about talking
about the ML ops architecture.

33
00:02:27,549 --> 00:02:31,329
And then we'll move on to
biomedical NLP Pipeline.

34
00:02:31,829 --> 00:02:36,559
We'll also talk about vector database
scaling after that and following

35
00:02:36,929 --> 00:02:40,139
followed by monitoring and observability.

36
00:02:41,069 --> 00:02:44,519
And finally, we'll close with
the continuous experimentation

37
00:02:44,549 --> 00:02:46,319
and deployment strategies,

38
00:02:46,819 --> 00:02:49,114
a ML Ops architecture overview.

39
00:02:49,614 --> 00:02:54,854
So when we talk about ML lops
everyone might have cared about this.

40
00:02:54,854 --> 00:02:55,394
ML lops.

41
00:02:55,424 --> 00:02:59,509
It's a machine learning how
to ma operate, operationalize

42
00:02:59,509 --> 00:03:00,859
the machine learning pipeline.

43
00:03:00,859 --> 00:03:03,989
So it's, ML ops is is a critical part.

44
00:03:03,989 --> 00:03:07,689
Like just by developing the models,
we cannot achieve everything.

45
00:03:07,689 --> 00:03:10,149
We have to implement it and
make it production ready.

46
00:03:10,489 --> 00:03:14,764
ML ops is a crucial role in
any machine learning lifecycle.

47
00:03:15,264 --> 00:03:20,894
So effective lops, if you consider
that, if you ask me to define an

48
00:03:20,894 --> 00:03:26,644
effective lops architecture I would
say that few components are necessary.

49
00:03:27,604 --> 00:03:31,054
The first one is
contentized microservices.

50
00:03:31,084 --> 00:03:36,034
It's for modular scalability
and version versioning.

51
00:03:36,034 --> 00:03:37,534
This model registry.

52
00:03:37,909 --> 00:03:43,259
So models keep getting updated,
so we need to have it versioned in

53
00:03:43,259 --> 00:03:47,839
the model registry, a synchronous
processing pipelines for efficient

54
00:03:47,869 --> 00:03:53,159
batch citation updates because in
research company is very vibrant the

55
00:03:53,159 --> 00:03:59,029
citation results and and citation
count, those things will vary every day.

56
00:03:59,029 --> 00:04:01,429
So we need to get the latest information.

57
00:04:01,999 --> 00:04:07,399
To give the correct picture of the
literature to the researcher, clear

58
00:04:07,399 --> 00:04:11,989
separation of embedding generation
from retrieval services real time

59
00:04:11,989 --> 00:04:18,999
inference, AI A PA layer, engineered
for subsecond responses and dedicated

60
00:04:18,999 --> 00:04:24,489
evaluation enrollment to ensure
rigorous scientific validation.

61
00:04:24,989 --> 00:04:30,389
So when we look at the biomedical
NLP pipeline there are a few

62
00:04:30,389 --> 00:04:32,279
challenges with the domain adaption.

63
00:04:32,779 --> 00:04:38,604
Because biomedical is something
which only few people who are really

64
00:04:38,604 --> 00:04:43,884
into the bioTE, biotechnology and
bio biology and healthcare and those

65
00:04:43,884 --> 00:04:48,874
people are interested in, and it has
lots of jargons and technical things.

66
00:04:48,874 --> 00:04:53,934
And not all of them will work on
the can understand this biomedical,

67
00:04:54,424 --> 00:04:59,264
vocabularies, even the language
and, the researchers out there.

68
00:04:59,764 --> 00:05:03,794
So it processes it, it poses sorry.

69
00:05:03,794 --> 00:05:10,004
It poses some challenges because the
biomedical language it's complex.

70
00:05:10,504 --> 00:05:14,644
It's because it's highly specialized
vocabulary across sub-disciplines.

71
00:05:15,289 --> 00:05:21,329
Entity relationship, recurring domain
expertise like gene protein interactions

72
00:05:21,449 --> 00:05:26,399
that needs a domain expert to, give
good understanding to the researcher.

73
00:05:27,269 --> 00:05:33,679
Contextual meaning that changes across
research areas need for continual

74
00:05:33,679 --> 00:05:36,469
updates as a new discoveries emerge.

75
00:05:37,279 --> 00:05:40,789
Traditional NLP five plants
failed in, in this domain without

76
00:05:40,789 --> 00:05:42,919
specialized adaption techniques.

77
00:05:43,419 --> 00:05:48,549
So as a machine learning engineer
or somebody who does the NLP on this

78
00:05:48,879 --> 00:05:52,269
biomedical data, not everyone can do that.

79
00:05:52,269 --> 00:05:57,849
They should have certain knowledge
about this domain and the languages

80
00:05:57,849 --> 00:05:59,559
and certain level of understanding.

81
00:06:00,059 --> 00:06:03,059
Model training and
deployment over workflow.

82
00:06:03,539 --> 00:06:08,219
So model training, it starts with
data ingestion and cleaning and

83
00:06:08,219 --> 00:06:10,469
doing the exploratory data analysis.

84
00:06:10,659 --> 00:06:14,189
Those are typical steps
in any machine learning.

85
00:06:14,789 --> 00:06:18,839
And once model is you do all those
things, you'll develop the model

86
00:06:18,844 --> 00:06:22,484
and, you will have it checked with
the test set and validation set,

87
00:06:22,934 --> 00:06:24,584
and you'll have a working model.

88
00:06:24,704 --> 00:06:28,504
So imagine that it all happens
and data ingestion happens.

89
00:06:28,594 --> 00:06:28,864
Okay?

90
00:06:29,734 --> 00:06:32,884
And then you will go and training the
pipeline, you'll run the training,

91
00:06:32,884 --> 00:06:35,914
the pipeline and evaluation framework.

92
00:06:35,914 --> 00:06:41,374
So we need to have a specialized
metrics for biomedical accuracy

93
00:06:42,074 --> 00:06:43,454
with the domain expert review.

94
00:06:43,874 --> 00:06:46,074
And then we finally deploy the models.

95
00:06:46,574 --> 00:06:51,084
Scaling vector databases for
30 plus million citations.

96
00:06:51,584 --> 00:06:55,399
So the operational challenges is like
efficiently generating a biddings for

97
00:06:55,399 --> 00:07:00,519
massive document car and balancing
recall against computational cost,

98
00:07:01,019 --> 00:07:02,459
managing seamless index updates.

99
00:07:02,854 --> 00:07:06,939
These are like issues with the
operational issues with the vector.

100
00:07:07,819 --> 00:07:08,899
Vector embeddings.

101
00:07:09,399 --> 00:07:13,749
And with our ML op solution to
encounter that is a synchronous

102
00:07:13,749 --> 00:07:18,699
embedding generation pipelines with
batch processing, hierarchical indexing

103
00:07:18,699 --> 00:07:25,420
strategies and then read replicas, which
staged updates, optimist query caching.

104
00:07:25,720 --> 00:07:29,360
So these are the techniques to
encounter those shortfalls or

105
00:07:29,360 --> 00:07:30,530
challenges like I would say.

106
00:07:31,030 --> 00:07:33,640
Rag architecture and
production implementation.

107
00:07:33,850 --> 00:07:38,140
There are lots of key components like
domain specific impacting models,

108
00:07:38,140 --> 00:07:42,100
multi-stage retrieval, pipeline
citation, network enrichment,

109
00:07:42,310 --> 00:07:44,530
and context window optimization.

110
00:07:45,490 --> 00:07:51,140
And but with respect to performance
metrics we have to, evaluate the things

111
00:07:51,140 --> 00:07:56,149
like evaluate any, the performance
against baseline, I would say to

112
00:07:56,179 --> 00:08:01,930
make sure that the performance has
indeed has improved like subsequent

113
00:08:01,960 --> 00:08:06,580
correl latency 90 percentage accu
accuracy in the entity recognition.

114
00:08:07,555 --> 00:08:11,845
And citation relevance score
is coming up more than 85%.

115
00:08:11,845 --> 00:08:16,285
As such, KPAs are really important
when evaluating performance.

116
00:08:16,285 --> 00:08:19,215
It's not about just doing the things.

117
00:08:19,245 --> 00:08:21,735
We also need to make sure that
we are doing the right thing

118
00:08:21,735 --> 00:08:24,705
and getting the right expected
results within the stipulated time.

119
00:08:25,205 --> 00:08:29,345
So the final one is, yeah, reduction
in the researcher literature searched.

120
00:08:29,845 --> 00:08:32,485
Monitoring and observability framework.

121
00:08:32,985 --> 00:08:39,315
So once we deploy the model, and
the data may change, it's evolving.

122
00:08:39,705 --> 00:08:43,525
The model which work efficiently
while we implement it, first time

123
00:08:43,525 --> 00:08:44,980
may not work over the period.

124
00:08:44,980 --> 00:08:49,660
So we need to constantly monitor the
models and then do the fine tuning.

125
00:08:50,595 --> 00:08:54,825
So model performance tracking,
scientific accuracy, validation,

126
00:08:55,365 --> 00:08:57,195
and user interaction analysis.

127
00:08:57,195 --> 00:09:01,485
They're really important and we have
to, once we are done with the work,

128
00:09:01,485 --> 00:09:03,885
we cannot be, we cannot say that.

129
00:09:03,915 --> 00:09:05,985
Yeah, it's all done and
we don't need to revisit.

130
00:09:06,045 --> 00:09:06,880
We have to come up.

131
00:09:07,485 --> 00:09:12,255
Come back again and we have to have a
certain metrics to evaluate every time

132
00:09:12,255 --> 00:09:17,285
and make sure that if it's derailing
or maybe deviating from the desired

133
00:09:17,285 --> 00:09:21,665
expected outcome, then we need to
intervene and fine tune the model.

134
00:09:21,665 --> 00:09:26,795
Or maybe enhance the ecosystem
to, to produce the right output.

135
00:09:27,295 --> 00:09:29,125
Real time monitoring dashboard.

136
00:09:29,365 --> 00:09:33,355
Our custom monitoring solution provides
both ML engineers and scientific

137
00:09:33,355 --> 00:09:39,755
stakeholders with visibility into model
drift detection, citation accuracy system

138
00:09:39,755 --> 00:09:45,185
health and performance metrics, user
query patterns and success rates, resource

139
00:09:45,185 --> 00:09:51,225
utilization and scaling triggers A and B
a RB testing, a performance comparison.

140
00:09:51,725 --> 00:09:53,885
Continuous experimentation methodology.

141
00:09:54,385 --> 00:09:58,945
We have implemented AB testing
framework that balance experimentation

142
00:09:58,945 --> 00:10:04,085
with scientific reliability, so it
enables targeted HO cohort testing.

143
00:10:04,385 --> 00:10:08,010
My research domain measures both
technical metrics and research

144
00:10:08,010 --> 00:10:11,940
outcomes and provides statistical
confidence for biomedical application.

145
00:10:12,480 --> 00:10:16,020
Supports multivariate testing
across model components.

146
00:10:16,520 --> 00:10:21,210
If this approach has yielded 80 percentage
reduction in ture search time while

147
00:10:21,210 --> 00:10:23,340
maintaining scientific rigor and results,

148
00:10:23,840 --> 00:10:28,420
infrastructure, scaling patterns, so we
have to have a baseline infrastructure

149
00:10:28,490 --> 00:10:32,610
it's core component size of our
average load with two times redundancy,

150
00:10:33,210 --> 00:10:37,710
elastic scaling layers, autoscaling
inference endpoints based upon query

151
00:10:37,710 --> 00:10:42,800
volume and scheduling, scheduled
scaling events predictive scaling for

152
00:10:42,800 --> 00:10:47,815
known search patterns like especially
maybe sometime towards academic.

153
00:10:48,400 --> 00:10:51,500
Term then if you observe that sorry.

154
00:10:51,860 --> 00:10:54,920
If you observe that the demand
increases, we may have to plan for

155
00:10:54,920 --> 00:10:59,840
the scaling in advance, specialized
to compute GPO allocation for embedded

156
00:11:00,050 --> 00:11:01,880
embedding generation and inference.

157
00:11:02,660 --> 00:11:07,100
Our infrastructure scales efficiently
across both batch processing needs

158
00:11:07,745 --> 00:11:09,580
and real time query patterns.

159
00:11:10,240 --> 00:11:15,450
So this is really important, while
making sure that we are not doing less

160
00:11:15,510 --> 00:11:17,670
or more, we are doing the right thing.

161
00:11:18,170 --> 00:11:20,720
Key lops learnings from biomedical ai.

162
00:11:21,220 --> 00:11:24,670
So we have to, yeah, already
we saw that we have the, in

163
00:11:24,760 --> 00:11:26,410
integrating domain expertise.

164
00:11:26,440 --> 00:11:27,460
That's really important.

165
00:11:28,460 --> 00:11:32,230
Without the involvement from domain
scientists, it's it's difficult

166
00:11:32,230 --> 00:11:37,270
to do a right lops without the
domain experts help developing

167
00:11:37,270 --> 00:11:39,250
scientific validation pipelines.

168
00:11:39,750 --> 00:11:46,280
That's also another important, we cannot
just be sure that the performance has

169
00:11:46,520 --> 00:11:49,375
increased just because the time to search.

170
00:11:50,140 --> 00:11:50,860
Has come down.

171
00:11:51,040 --> 00:11:56,350
We have to also measure based upon the
other scientific variables and KPIs

172
00:11:56,850 --> 00:11:59,070
enabling continuous corpus updates.

173
00:11:59,460 --> 00:12:01,290
This is really important.

174
00:12:01,470 --> 00:12:07,580
Corpus is increasing, so we have to keep
up to date for the latest and greatest

175
00:12:07,580 --> 00:12:10,460
information, prioritizing explainability.

176
00:12:10,960 --> 00:12:15,100
Biomedical research application necess
creates significantly higher transparency

177
00:12:15,100 --> 00:12:20,650
and inter, relatively interpretability
standards compared to consumer AI system.

178
00:12:21,150 --> 00:12:22,620
And with that, I'm concluding.

179
00:12:22,620 --> 00:12:26,065
And thank you for this
opportunity t thanks a lot.

