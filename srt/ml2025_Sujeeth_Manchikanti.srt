1
00:00:00,500 --> 00:00:04,720
So today I'm, I have come up with
an unique topic that will help you,

2
00:00:04,779 --> 00:00:09,129
to optimize your test automation
and be successful in your endeavor.

3
00:00:09,970 --> 00:00:14,319
So before going into the topic, I
would like to thank Con 42 for giving

4
00:00:14,319 --> 00:00:19,784
me this opportunities to exchange
our ideas and for common benefit.

5
00:00:20,380 --> 00:00:25,689
Okay, now the topic is about rethinking
test automation, a utility based,

6
00:00:25,689 --> 00:00:28,000
modern approach to manage complexity.

7
00:00:29,049 --> 00:00:33,819
Alright, so right now in
software engineering and mainly

8
00:00:33,819 --> 00:00:37,219
with test automation, since
it is not a conventional.

9
00:00:38,434 --> 00:00:42,235
Department or con, conventional
part of software engineering.

10
00:00:42,425 --> 00:00:46,095
There's still, there is lot of
maturity needs to be achieved and

11
00:00:46,245 --> 00:00:50,475
there is lot of failure rate in
this, especially in this area.

12
00:00:50,745 --> 00:00:54,605
So this is where I'm going to
focus and walk you through how

13
00:00:54,605 --> 00:00:56,855
we can rate maximum benefits.

14
00:00:57,004 --> 00:00:57,184
Okay.

15
00:00:57,695 --> 00:01:00,514
Before getting into the topic,
I would like to take you through

16
00:01:00,514 --> 00:01:02,704
the evolution of test automation.

17
00:01:04,444 --> 00:01:05,405
Early 2000.

18
00:01:05,975 --> 00:01:12,525
2000, we have a, simple and tools
like, with the limited maintainability

19
00:01:12,585 --> 00:01:16,605
and limited scope it helps to cover
application of four to five screens

20
00:01:17,295 --> 00:01:21,215
and with it's like a simple, it
doesn't have any help, any integrations

21
00:01:21,215 --> 00:01:24,890
or APIs or any new s right.

22
00:01:26,320 --> 00:01:30,610
And 2010, we have come up with
the page object model, open source

23
00:01:30,610 --> 00:01:33,540
software to test the application which.

24
00:01:36,520 --> 00:01:41,860
Even though we are able to progress a
lot with the increase of software in

25
00:01:41,860 --> 00:01:46,870
our life day-to-day life, the success
rates still stay at the same level

26
00:01:47,230 --> 00:01:52,690
as in the original days and even the
present day with a lot of technological

27
00:01:52,690 --> 00:01:58,810
shifts, advancements, we have advanced
systems like Selfing Scripts, ml,

28
00:01:59,350 --> 00:02:03,310
visual Recognition Analysis, but still.

29
00:02:04,195 --> 00:02:05,545
The success rate remains same.

30
00:02:05,545 --> 00:02:05,785
Why?

31
00:02:05,785 --> 00:02:10,405
Because these are still evolving and
there is lot of scope to evolve in this.

32
00:02:10,735 --> 00:02:16,405
So the right approach, we take the
right place, we invest our money today

33
00:02:17,045 --> 00:02:21,815
helps us to reap the maximum benefits
of these technological advances we

34
00:02:21,815 --> 00:02:24,275
are going to see in the coming years.

35
00:02:26,345 --> 00:02:29,315
Okay, so what are the
current day challenges?

36
00:02:30,110 --> 00:02:32,960
So current day challenges
is the growing complexity.

37
00:02:32,960 --> 00:02:38,350
Now we have seen the software is
there in every minute of our lives.

38
00:02:38,410 --> 00:02:43,470
Every minute we live, we are using, we are
depending on some part of the software.

39
00:02:43,835 --> 00:02:49,895
So that's how the complexity of it's
growing and it needs to be more integrated

40
00:02:50,285 --> 00:02:56,175
and more there is no chance of failure
because it can result in huge loss

41
00:02:56,175 --> 00:02:58,575
and huge customer dissatisfaction.

42
00:02:59,785 --> 00:03:04,335
So that is the, significance of
software test automation where we

43
00:03:04,335 --> 00:03:10,185
have, where it'll help us to test all
these bits and pieces of softwares and

44
00:03:10,185 --> 00:03:13,495
make sure there is no overhead costs.

45
00:03:13,675 --> 00:03:17,605
That is the failure of the co
software is going to create us

46
00:03:17,605 --> 00:03:19,615
to avoid those failure costs.

47
00:03:19,615 --> 00:03:24,985
We have to have it thorough testing, and
the test automation helps to achieve that.

48
00:03:26,124 --> 00:03:27,084
The technology shift?

49
00:03:27,684 --> 00:03:28,374
Yes.

50
00:03:29,845 --> 00:03:33,935
The pace at which the technology
is changing is unforeseen.

51
00:03:34,295 --> 00:03:36,010
Nobody has imagined to this level.

52
00:03:36,670 --> 00:03:38,825
And this is just a starting point.

53
00:03:38,825 --> 00:03:41,285
We are just still in the
first step and right.

54
00:03:41,585 --> 00:03:43,715
So there is a lot more to go through.

55
00:03:43,715 --> 00:03:46,265
Long way to go in this technology channel.

56
00:03:46,885 --> 00:03:51,445
So given the, this scenario, what
are the common pitfall pitfalls?

57
00:03:51,445 --> 00:03:55,585
Organizations are attempting to
automate more than 60% of test cases

58
00:03:55,585 --> 00:04:01,315
with first year experience, 78% failure
rate teams managing over a thousand

59
00:04:01,315 --> 00:04:06,355
test cases spend around four to five
hours weekly on maintenance, while

60
00:04:06,355 --> 00:04:12,775
67% of automation product fails due to
improper test case selection, right?

61
00:04:12,925 --> 00:04:14,485
So what this gives us.

62
00:04:15,395 --> 00:04:23,945
This common pitfall is the coverage or the
results of automation is not as expected.

63
00:04:23,975 --> 00:04:27,725
Like we are expecting a hundred
percent, but we are achieving only

64
00:04:27,725 --> 00:04:31,475
seven 32%, where 78% is the failure.

65
00:04:32,045 --> 00:04:38,515
Second thing, we are spend in huge
amount of time in maintaining the

66
00:04:38,515 --> 00:04:44,925
software and why we fail, because
why we fail in achieving the coverage

67
00:04:44,925 --> 00:04:49,035
or in achieving the maintenance
health of the software we developed.

68
00:04:49,215 --> 00:04:49,545
Why?

69
00:04:49,545 --> 00:04:57,225
Because we are failing in
automation, test selection.

70
00:04:57,225 --> 00:05:01,695
We are failing in identifying
the right automation candidate.

71
00:05:02,880 --> 00:05:08,320
So that is where that tech strategy
comes in, and we have to spend time on

72
00:05:08,320 --> 00:05:10,090
this strategy to achieve the results.

73
00:05:11,335 --> 00:05:15,544
Okay we have seen theoretically,
but practically what is it happening

74
00:05:15,604 --> 00:05:19,794
in, on ground is we expect a
hundred percent pho rate, but we

75
00:05:19,794 --> 00:05:22,764
are achieving 62% in the first run.

76
00:05:23,094 --> 00:05:27,560
And as the age we have seen
the previous slide, right?

77
00:05:27,775 --> 00:05:30,935
So we have to keep on
investing money on maintenance.

78
00:05:31,145 --> 00:05:35,975
If we don't maintain it, this
62% will fall to 26% very soon.

79
00:05:36,695 --> 00:05:40,445
And then the test coverage, we expect 80%.

80
00:05:40,445 --> 00:05:42,245
We are achieving 54%.

81
00:05:42,665 --> 00:05:44,945
There is a huge gap of 26%.

82
00:05:44,945 --> 00:05:52,025
And mainly the CICD integration, we are
still in the native primitive standards.

83
00:05:52,025 --> 00:05:54,455
We are still not there where we can see.

84
00:05:55,110 --> 00:05:57,780
The, our target of achieving
a hundred percent success.

85
00:05:57,900 --> 00:05:59,490
And same with the defect detection.

86
00:05:59,820 --> 00:06:00,180
Why?

87
00:06:00,180 --> 00:06:04,230
Because most of our tests failed
due to lack of maintenance.

88
00:06:04,560 --> 00:06:09,540
There is still, majority of our scripts
doesn't get an opportunity to be

89
00:06:09,540 --> 00:06:13,075
executed and do identify that defects.

90
00:06:14,580 --> 00:06:17,910
So giving this background,
what do you see?

91
00:06:17,910 --> 00:06:19,410
So we see that, right?

92
00:06:19,800 --> 00:06:25,710
There is a huge investment we are putting
in, but for less result, less output.

93
00:06:26,040 --> 00:06:29,880
So that is what we call it
as a white elephant syndrome.

94
00:06:30,600 --> 00:06:31,980
So why do we call this?

95
00:06:31,980 --> 00:06:37,900
Because it's test automation
is a kind of a black hole where

96
00:06:37,900 --> 00:06:39,790
it drains all our resources.

97
00:06:41,415 --> 00:06:46,275
Because we have to invest tons
in building the big elephant.

98
00:06:46,785 --> 00:06:49,255
And it's not done by building an elephant.

99
00:06:49,315 --> 00:06:51,685
I have to feed it every day.

100
00:06:52,525 --> 00:06:58,425
So unless there is a proper approach
to use proper environment, eco

101
00:06:58,425 --> 00:07:04,005
ecosystem to use this elephant, it
is going to eat all my resources.

102
00:07:05,475 --> 00:07:08,475
Just imagine you are repeating,
you are petting elephant today.

103
00:07:08,895 --> 00:07:09,885
What is the use?

104
00:07:09,915 --> 00:07:12,405
No, but you have to spend
a lot to mainten it.

105
00:07:13,185 --> 00:07:18,105
So similarly, the maintenance challenges
as we discussed, it's a huge maintenance.

106
00:07:18,485 --> 00:07:23,815
Like even, any company in generally
small software project has to invest

107
00:07:23,815 --> 00:07:31,490
in 2.5 fulltime engineers with
each engineer about hundred K 25.

108
00:07:32,315 --> 00:07:36,184
Just in maintenance in
the resource cost, right?

109
00:07:36,395 --> 00:07:43,215
And tools and then failures, and then
technology shifting, upgrades migrations.

110
00:07:43,215 --> 00:07:44,864
These are all additional, right?

111
00:07:46,590 --> 00:07:51,599
So how does the annual cost looks like
the breakup, as I told you right, the

112
00:07:51,629 --> 00:07:56,789
tools and licenses they cost a huge,
actually if I member team or 10 member

113
00:07:56,789 --> 00:08:01,409
team roughly, it would cost about one
20 k. And as you discussed, the huge

114
00:08:01,439 --> 00:08:06,714
maintenance cost and the personal cost
as I told you, 2.5 full-time employees

115
00:08:07,074 --> 00:08:09,564
and a direct and opportunity cost.

116
00:08:10,214 --> 00:08:14,444
So these are direct end opportunity
costs or the failed initiative costs

117
00:08:14,834 --> 00:08:16,979
directly impacting roughly around two.

118
00:08:17,994 --> 00:08:22,685
For any decent size of the software
team with five to 10 testers, and while

119
00:08:22,715 --> 00:08:28,565
opportunity costs reach to 300 k, the cost
per test case execution raises from two

120
00:08:28,565 --> 00:08:31,774
to $3 to eight to $10 within two years.

121
00:08:32,075 --> 00:08:35,804
With the raising with the raising
raising, the resource cost,

122
00:08:35,804 --> 00:08:39,044
personal cost infrastructure tools.

123
00:08:39,299 --> 00:08:42,510
All these costs are going to add
up and it's going to multiply

124
00:08:42,510 --> 00:08:44,310
our costs in near future.

125
00:08:44,579 --> 00:08:49,290
So I would say this is the high and
that we spend time on the proper

126
00:08:49,290 --> 00:08:57,544
strategy and we invest on the tools
wisely so that we can be saved or we

127
00:08:57,544 --> 00:09:00,374
can sustain in this global market.

128
00:09:01,334 --> 00:09:01,604
Okay.

129
00:09:01,604 --> 00:09:03,494
What is my proposed solution?

130
00:09:03,524 --> 00:09:05,054
So my proposed solution is based.

131
00:09:06,629 --> 00:09:12,349
In our model framework here the
core strategy comes into play in

132
00:09:12,379 --> 00:09:14,689
identifying the testing candidate.

133
00:09:14,989 --> 00:09:20,300
So the testing candidate should be in such
a way that it is to, it has to help the

134
00:09:20,300 --> 00:09:26,959
manual testing speed up their most complex
jobs with the simplest script, right?

135
00:09:27,290 --> 00:09:28,729
And less maintenance.

136
00:09:29,060 --> 00:09:30,949
This is where the strategy comes up.

137
00:09:31,219 --> 00:09:33,739
So when you implement this strategy.

138
00:09:34,804 --> 00:09:38,374
The manual testing resources,
the manual testing personal

139
00:09:38,494 --> 00:09:43,204
could be drastically reduced as
majority of the heavy weight load.

140
00:09:43,489 --> 00:09:45,739
Is taken by these utilities.

141
00:09:46,099 --> 00:09:49,729
So why I would say this utility,
I can say it as a normal test

142
00:09:49,729 --> 00:09:53,619
automation framework test case
flow or something I can say, right?

143
00:09:53,920 --> 00:09:55,599
Why I'm calling this as utilities.

144
00:09:55,930 --> 00:09:59,949
So these utilities will have,
everything will have unique entry

145
00:09:59,949 --> 00:10:02,410
and exit points, unique capabilities.

146
00:10:02,900 --> 00:10:09,255
Like for example I have to test a
data a data set of 1 million records.

147
00:10:10,305 --> 00:10:14,805
So manual testing, manual, it'll
take me five days, six days

148
00:10:14,835 --> 00:10:17,544
with sampling technique, right?

149
00:10:17,634 --> 00:10:20,525
But this utility technique,
we can implement.

150
00:10:20,944 --> 00:10:23,204
Forget about the conventional
testing approach.

151
00:10:23,475 --> 00:10:25,305
So we develop utilities.

152
00:10:25,334 --> 00:10:29,814
You take any technology you bring in
a new technology that is completely

153
00:10:29,814 --> 00:10:31,314
different to your technology stack.

154
00:10:31,314 --> 00:10:32,874
For example, Python.

155
00:10:35,499 --> 00:10:40,909
You validate that data set and give
a result in a standard format, right?

156
00:10:40,999 --> 00:10:46,159
So these utilities will help us to
solve the main pain areas of the

157
00:10:46,159 --> 00:10:51,169
software testing or the manual testers,
and these utilities will fit into

158
00:10:51,169 --> 00:10:57,109
our overall enterprise framework of
keyword driven, and then our standard

159
00:10:57,109 --> 00:10:59,024
logging and logging framework.

160
00:11:00,029 --> 00:11:05,399
That way the output of this utility
will become in input further next

161
00:11:05,399 --> 00:11:07,859
utility to carry on to carry upon.

162
00:11:08,219 --> 00:11:13,709
So that's how we are decoupling
these complex pieces, calling them

163
00:11:13,709 --> 00:11:18,049
as utilities, building in its own
ecosystem, its own technology stack.

164
00:11:18,319 --> 00:11:22,999
And then integrating them with
our life framework, which includes

165
00:11:23,359 --> 00:11:25,459
the enterprise level logging.

166
00:11:25,969 --> 00:11:26,719
You got it.

167
00:11:26,719 --> 00:11:31,369
So that's how we are going
to scope our test automation.

168
00:11:31,369 --> 00:11:35,999
We, we are not going to, with attack the
whole hundred per a hundred percent of

169
00:11:35,999 --> 00:11:41,459
test cases, testing testing landscape,
and pitfall unable to achieve it.

170
00:11:41,699 --> 00:11:46,589
So here we are wise enough to
choose what is to, what is most

171
00:11:46,589 --> 00:11:51,869
required to be automated, where it
is going to help us more for that.

172
00:11:51,869 --> 00:11:56,949
We take the help of this universal
framework and universal login.

173
00:11:58,224 --> 00:11:58,514
Okay.

174
00:11:58,964 --> 00:12:01,724
So with this approach,
what did we achieve?

175
00:12:01,814 --> 00:12:04,934
We achieved 85% of maintainability.

176
00:12:04,934 --> 00:12:05,984
It's very easy.

177
00:12:06,039 --> 00:12:08,649
We have reduced 85% in maintenance costs.

178
00:12:09,039 --> 00:12:14,289
And then since these are utilities
we focused more on API based testing

179
00:12:14,349 --> 00:12:19,589
rather than UI based testing because
the major pain or the major failures

180
00:12:19,589 --> 00:12:22,229
happen at API are integration level.

181
00:12:22,584 --> 00:12:27,004
And then we have implemented
separate tools for UI testing alone.

182
00:12:27,004 --> 00:12:30,944
That way we have we, we know
the strategy, like where we are

183
00:12:30,944 --> 00:12:32,594
going to cover what component.

184
00:12:32,984 --> 00:12:36,224
That's how we are able to
achieve better reliability and

185
00:12:36,224 --> 00:12:37,759
then the better reusability.

186
00:12:37,899 --> 00:12:38,924
Yes, of course.

187
00:12:38,984 --> 00:12:43,484
So if I develop a utility in my
team, I can definitely use it

188
00:12:43,854 --> 00:12:45,999
anywhere else wherever it is needed.

189
00:12:46,839 --> 00:12:48,219
And then faster execution.

190
00:12:48,519 --> 00:12:52,329
Since this is not a conventional
testing, we are taking every approach

191
00:12:52,329 --> 00:12:57,909
to test database EAPI or UA layer
separately, disintegration of UA layer.

192
00:12:57,909 --> 00:12:58,569
Separately.

193
00:12:58,629 --> 00:13:00,729
Our execution is very faster.

194
00:13:01,179 --> 00:13:06,049
And main importantly, more importantly,
it is about the sanity testing.

195
00:13:06,109 --> 00:13:11,299
We are able to san test the sanity
of any application within minutes.

196
00:13:12,799 --> 00:13:13,279
Sorry.

197
00:13:14,279 --> 00:13:17,009
So what are the benefits
of this utility approach?

198
00:13:17,729 --> 00:13:21,499
As I told you, the, the improved
scope management, it's not

199
00:13:21,499 --> 00:13:22,949
like I'm planning to cover.

200
00:13:24,944 --> 00:13:32,714
And I'm able to achieve 25%, but here
I'm sc Descoping my the coverage and then

201
00:13:32,714 --> 00:13:37,814
I'm trying to reach, achieve a hundred
percent of the redefined coverage.

202
00:13:39,359 --> 00:13:43,979
So that way I know what I'm doing, what
I'm expecting, and how much money to put.

203
00:13:44,099 --> 00:13:48,339
I'm not building resources to
automate everything a hundred percent.

204
00:13:48,759 --> 00:13:54,284
Just putting resources to automate
my 25% and hundred percent of it.

205
00:13:56,959 --> 00:13:59,060
And then the tool flexibility.

206
00:13:59,060 --> 00:14:00,199
Yes.

207
00:14:00,339 --> 00:14:03,279
And then faster implementation,
reduced maintenance.

208
00:14:03,309 --> 00:14:03,729
Yes.

209
00:14:04,389 --> 00:14:06,999
Overall with the technology
shifts, new tools coming in,

210
00:14:06,999 --> 00:14:08,409
new technologies coming in.

211
00:14:08,409 --> 00:14:14,209
Since my standard approach is fixed, my
platform is fixed, I just have to, migrate

212
00:14:14,209 --> 00:14:16,249
from one technology to another technology.

213
00:14:16,249 --> 00:14:22,180
But my strategy, my automation resources
are going to stay safe forever.

214
00:14:23,454 --> 00:14:25,764
So as in long run, right?

215
00:14:26,015 --> 00:14:30,745
In long run since the strategy is good,
somebody who knows the strategy, it's

216
00:14:30,745 --> 00:14:36,610
just a matter of with the latest we
have the GitHub co-pilot or charge GBT.

217
00:14:36,610 --> 00:14:39,010
It's very easy to migrate
from one to others.

218
00:14:40,090 --> 00:14:41,980
And then the implementation strategy.

219
00:14:42,290 --> 00:14:45,230
This is like more of generic,
established, clear objective.

220
00:14:45,280 --> 00:14:51,160
To say, here, establish a clear strategy
on how much to automate, what to

221
00:14:51,160 --> 00:14:53,290
automate, what component to automate.

222
00:14:53,650 --> 00:14:55,240
Just forget about everything.

223
00:14:55,240 --> 00:14:58,870
Focus on that component,
develop the utility, and then

224
00:14:58,870 --> 00:15:00,275
we can integrate with others.

225
00:15:01,900 --> 00:15:03,670
So build organizational support.

226
00:15:03,790 --> 00:15:07,120
Yeah, do analysis and get
the stakeholder buying.

227
00:15:07,420 --> 00:15:08,890
Implement gradually.

228
00:15:08,890 --> 00:15:09,700
Measure and optimize.

229
00:15:11,395 --> 00:15:12,655
So measuring success?

230
00:15:12,685 --> 00:15:13,135
Yes.

231
00:15:13,195 --> 00:15:14,815
Key performance indicators.

232
00:15:15,055 --> 00:15:19,585
So define your key performance indicators
and track your written on investment.

233
00:15:19,885 --> 00:15:24,595
So in my projects, wherever I have
implemented utilities, so they

234
00:15:24,595 --> 00:15:26,785
are like independent utilities.

235
00:15:26,845 --> 00:15:32,245
Most of the cases where we have
achieved return on investment, it's 300%

236
00:15:32,245 --> 00:15:34,074
return investment in first few months.

237
00:15:35,114 --> 00:15:38,624
And then, and there are some comp,
some utilities where we had to fit

238
00:15:38,624 --> 00:15:42,505
into the enterprise architecture
for the continuity of the flow.

239
00:15:42,654 --> 00:15:47,465
So this is like a top down or bottom
up approach the conventional testing

240
00:15:47,555 --> 00:15:52,074
where we come with list of test cases
to be automated while automating it.

241
00:15:52,074 --> 00:15:55,525
I develop utilities slowly
and then go on right.

242
00:15:55,749 --> 00:15:57,729
But here it is like bottom up approach.

243
00:15:57,779 --> 00:16:02,640
I, first, I know the utilities where
I can help to manual testing to

244
00:16:02,640 --> 00:16:07,860
ease up their complexities charts
and later if time permits or if I

245
00:16:07,860 --> 00:16:12,630
need, I can build on test cases by,
by integrating multiple utilities

246
00:16:15,060 --> 00:16:19,230
so that way we know where we are
going to, how much we have to

247
00:16:19,290 --> 00:16:22,080
invest, and then quality first.

248
00:16:23,795 --> 00:16:27,425
Teams should always monitor the
automated execution results.

249
00:16:27,755 --> 00:16:33,335
But still we have the standard logging
system and the logging pattern is

250
00:16:33,335 --> 00:16:35,975
what integrates from one utility.

251
00:16:35,975 --> 00:16:37,685
It very easy to track and.

252
00:16:40,175 --> 00:16:40,535
Okay.

253
00:16:41,015 --> 00:16:43,115
Thank you friends for
giving me this opportunity.

254
00:16:43,865 --> 00:16:50,425
So hope you would have got some idea
on how these unconventional strategies

255
00:16:50,585 --> 00:16:55,665
maverick thing thinking implementations
will help ease up our life.

256
00:16:56,170 --> 00:17:00,280
In software testing space and
especially in software test automation.

257
00:17:00,700 --> 00:17:05,920
So if you need any help or future
guidance or some case studies of my

258
00:17:05,980 --> 00:17:08,170
previous works, I'm happy to share.

259
00:17:08,440 --> 00:17:10,330
So please do reach out to me.

260
00:17:10,510 --> 00:17:11,110
Thank you.

261
00:17:11,200 --> 00:17:11,560
Bye.

