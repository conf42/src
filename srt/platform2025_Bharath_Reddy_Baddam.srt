1
00:00:00,500 --> 00:00:01,009
Hi everyone.

2
00:00:01,160 --> 00:00:02,000
My name is Bar.

3
00:00:02,500 --> 00:00:06,129
I'm currently working as senior
Salesforce consultant with over

4
00:00:06,129 --> 00:00:09,940
nine years of experience in
Salesforce and cloud technologies.

5
00:00:10,629 --> 00:00:14,200
Over these many years, I have
delivered Salesforce implementations,

6
00:00:14,710 --> 00:00:20,410
cloud integrations, and AI driven
solutions across industries such as

7
00:00:20,470 --> 00:00:22,720
finance, healthcare, and registry.

8
00:00:23,380 --> 00:00:26,260
In today's session, I will
walk you through the topic,

9
00:00:26,950 --> 00:00:28,930
architecting AI native platforms.

10
00:00:29,800 --> 00:00:34,870
This talk will focus on how
infrastructure, workloads, and governance

11
00:00:34,870 --> 00:00:37,810
come together to make AI work at scale.

12
00:00:38,650 --> 00:00:41,709
We'll also look at real
world implementation

13
00:00:41,709 --> 00:00:43,870
patterns and future threats.

14
00:00:44,495 --> 00:00:48,489
By the end of this session, you will
have a clear understanding of the

15
00:00:48,489 --> 00:00:51,910
challenges, best practices, and takeaways.

16
00:00:52,555 --> 00:00:55,825
For building scalable AI native platforms,

17
00:00:56,325 --> 00:01:00,215
the infrastructure imperative,
the starting point for AI

18
00:01:00,215 --> 00:01:02,135
initiative is infrastructure.

19
00:01:02,855 --> 00:01:08,405
Without the right infrastructure, most
AI projects remain in experimental

20
00:01:08,405 --> 00:01:11,135
phases and fail to reach production.

21
00:01:11,635 --> 00:01:14,485
AI requires compute intensive gps.

22
00:01:15,310 --> 00:01:18,850
High performance networking
and scalable storage.

23
00:01:19,350 --> 00:01:22,080
There are two risks to highlight here.

24
00:01:22,580 --> 00:01:27,920
First, organization that embrace
infrastructure can achieve a

25
00:01:27,920 --> 00:01:34,010
competitive advantage, deploying
AI models faster and more reliably.

26
00:01:34,510 --> 00:01:39,100
Second, those that focus on
experiments without production.

27
00:01:39,820 --> 00:01:44,380
Ready infrastructure fall into
what I call the experimental cloud.

28
00:01:45,220 --> 00:01:48,880
This means AI never skills beyond pilots.

29
00:01:49,510 --> 00:01:50,830
So the message is clear.

30
00:01:51,100 --> 00:01:55,030
Create infrastructure as
the foundation of your ai.

31
00:01:55,530 --> 00:01:58,350
Understanding AI workload characteristics.

32
00:01:58,850 --> 00:02:01,910
A workloads are very different
from traditional applications.

33
00:02:02,410 --> 00:02:08,230
Training workloads require massive
parallel processing where GPU Shine

34
00:02:08,949 --> 00:02:14,019
inference workloads, on the other
hand, focus on speed and scalability.

35
00:02:14,519 --> 00:02:19,589
Think of recommendation engines,
chart bots, fraud detection models.

36
00:02:20,429 --> 00:02:22,649
They need millisecond responses.

37
00:02:23,149 --> 00:02:25,134
This means infrastructure must.

38
00:02:25,634 --> 00:02:26,894
Consider both sides.

39
00:02:27,524 --> 00:02:32,744
Training environments that are compute
heavy and inference environment

40
00:02:32,804 --> 00:02:34,904
that are lightweight, but scalable.

41
00:02:35,404 --> 00:02:39,484
If we don't understand
workload characteristics, we

42
00:02:39,484 --> 00:02:44,674
risk over provisioning, under
utilization and spiraling costs.

43
00:02:45,174 --> 00:02:51,254
Data pipeline, I. Data is the fuel of ai
without well-structured and governed data

44
00:02:51,254 --> 00:02:57,845
pipelines, even the most sophisticated
models will fit a robust data pipeline.

45
00:02:58,174 --> 00:03:03,904
Ensures data is collected, lean,
transformed, and served consistent.

46
00:03:04,404 --> 00:03:07,314
Future stores are becoming
a critical component.

47
00:03:07,814 --> 00:03:11,239
They allow teams to reuse
features across models.

48
00:03:12,134 --> 00:03:15,454
Ensure data consists stream processing.

49
00:03:15,784 --> 00:03:19,444
Add another dimension, real time insights.

50
00:03:19,504 --> 00:03:26,824
For example, in fraud detection, if data
pipelines lack even by a few cycles,

51
00:03:27,484 --> 00:03:30,454
the opportunity to stop fraud is lost.

52
00:03:30,954 --> 00:03:34,344
Infrastructure patterns
for scalable model trade.

53
00:03:34,844 --> 00:03:37,034
Scaling model training is not driver.

54
00:03:37,534 --> 00:03:43,864
We face challenges in resource management,
container isolation, and network topology.

55
00:03:44,364 --> 00:03:49,224
Kubernetes and container orchestration
solve many of these challenges,

56
00:03:50,034 --> 00:03:55,914
but GPU scheduling, network
optimization and distributed training

57
00:03:55,914 --> 00:03:58,524
strategies are equally important.

58
00:03:59,024 --> 00:04:05,709
For example, let's say distributed data
parallelism allow us to train large models

59
00:04:05,829 --> 00:04:13,199
across the multiple GPUs while tolerance
mechanism ensure that even if one not

60
00:04:13,199 --> 00:04:15,449
fail, training continues the seamless.

61
00:04:15,949 --> 00:04:17,749
Resource management challenges.

62
00:04:18,249 --> 00:04:20,049
Managing resources is a balancing act.

63
00:04:20,919 --> 00:04:27,099
The key challenges include allocating
GPU and CPU resources effectively.

64
00:04:27,599 --> 00:04:30,659
Isolating workloads
through containerization.

65
00:04:31,159 --> 00:04:35,559
Designing network topologies
that support high data building

66
00:04:35,559 --> 00:04:37,539
system T to hardware failure.

67
00:04:38,039 --> 00:04:42,599
If resource management is not
handled properly, fast train

68
00:04:42,599 --> 00:04:44,700
rocket and innovation slows.

69
00:04:45,200 --> 00:04:46,784
That's why AI n native two platform.

70
00:04:47,780 --> 00:04:50,600
Must embed resource governance from day

71
00:04:51,100 --> 00:04:53,350
GPU and CPU optimization.

72
00:04:54,130 --> 00:04:59,110
AI workloads often involve
a mix of CPUs and GPUs.

73
00:04:59,610 --> 00:05:04,710
CPUs are great for general purposes
tasks while GPUs accelerate

74
00:05:04,710 --> 00:05:08,550
metrics, heavy competitions in
model training and inference.

75
00:05:09,450 --> 00:05:14,990
The challenge is in optimizing utilization
of both eternal genius resources.

76
00:05:14,990 --> 00:05:20,540
Scheduling ensures that workload are
directed to the right compute layer.

77
00:05:21,040 --> 00:05:24,255
This improves efficiency and lowers cost.

78
00:05:24,755 --> 00:05:29,860
For instance, lightweight reprocessing
me run on CPUs while the heavy

79
00:05:29,860 --> 00:05:32,110
model training runs on gpu.

80
00:05:32,610 --> 00:05:38,300
Data pipeline architectures, modern
AI platforms rely on advanced data

81
00:05:38,300 --> 00:05:45,250
pipelines, a future store, ensure that
right data is consistently available

82
00:05:45,250 --> 00:05:51,100
for training and inference frame
processing, handles real time data,

83
00:05:51,190 --> 00:05:53,470
allowing systems to react immediately.

84
00:05:53,970 --> 00:05:58,260
The architecture must balance
batch and real-time processing.

85
00:05:58,590 --> 00:06:03,870
Batch pipelines are great for large
historical data sets while stream

86
00:06:03,960 --> 00:06:06,000
pipelines ensure responsiveness.

87
00:06:06,000 --> 00:06:12,420
Together they provide a comprehensive data
bone backbone for ai YouTube platforms.

88
00:06:12,920 --> 00:06:15,200
Observability and monitoring for ai.

89
00:06:15,700 --> 00:06:21,790
Unlike traditional systems, AI platform
requires observability and multiple

90
00:06:21,790 --> 00:06:25,180
levels, infrastructure, data, and models.

91
00:06:25,990 --> 00:06:30,220
We need to monitor GPU, utilization,
pipeline Health, and most

92
00:06:30,220 --> 00:06:32,530
importantly, model performance.

93
00:06:33,355 --> 00:06:38,725
Metrics such as accuracy, precision,
recall, fairness indicator

94
00:06:38,785 --> 00:06:40,375
must be continuously tried.

95
00:06:40,875 --> 00:06:47,385
Observability help us detect entire
drift bias and performance degradation

96
00:06:47,715 --> 00:06:50,254
early, preventing the costly failures,

97
00:06:50,754 --> 00:06:53,050
real world implementation patterns.

98
00:06:53,710 --> 00:06:55,270
AI native platform.

99
00:06:55,765 --> 00:06:58,104
Looks very different across industries.

100
00:06:58,974 --> 00:07:01,945
Some examples, high frequency trading.

101
00:07:02,545 --> 00:07:07,825
It requires ultra load latency,
infrastructure, and real time pipelines.

102
00:07:08,325 --> 00:07:12,675
Content recommendation, it
needs scalable system that

103
00:07:12,675 --> 00:07:14,320
personalized the individual level.

104
00:07:15,300 --> 00:07:16,450
Healthcare here.

105
00:07:17,265 --> 00:07:22,715
It particularly focuses on compliance,
accuracy, and ethical safeguards.

106
00:07:23,215 --> 00:07:29,185
These industry specific examples
demand us that there is no one size

107
00:07:29,185 --> 00:07:34,404
fits at the level of AI platform
Architecture must align with

108
00:07:34,404 --> 00:07:37,254
business goals and complex needs.

109
00:07:37,754 --> 00:07:39,075
Performance optimization.

110
00:07:39,575 --> 00:07:44,700
Performance optimization is about making
sure resources are used efficient.

111
00:07:45,200 --> 00:07:51,200
These involves optimizing GBU memory
usage, improving storage performance

112
00:07:51,290 --> 00:07:57,170
with MVM and tuning models,
serving layers to reduce latency.

113
00:07:58,160 --> 00:08:05,420
For example, batching interface request
can reduce overhead while catching the

114
00:08:05,420 --> 00:08:08,989
frequently accessed futures improve.

115
00:08:09,489 --> 00:08:13,719
Small optimizations at scale
create massive performance scales.

116
00:08:14,219 --> 00:08:21,244
Security and governance in AI platform
in AI platforms cannot succeed without

117
00:08:21,244 --> 00:08:23,119
robust security and governance.

118
00:08:23,969 --> 00:08:24,799
These include.

119
00:08:25,579 --> 00:08:31,459
Protecting models from ARISAL
attacks, ensuring data privacy and

120
00:08:31,549 --> 00:08:33,529
implementing role-based access.

121
00:08:34,029 --> 00:08:39,429
Governance also means ethical
oversight, making sure AI decisions

122
00:08:39,429 --> 00:08:47,154
are transparent, explainable and T with
regulations such as GDPR and hiphop.

123
00:08:47,654 --> 00:08:49,904
Future trends in AI infrastructure.

124
00:08:50,414 --> 00:08:56,474
Looking here, several trends will
shape AI native platforms, each AI

125
00:08:56,984 --> 00:09:01,934
bringing intelligence closer to the
source of that quantum computing,

126
00:09:02,114 --> 00:09:04,334
unlocking optimization problems.

127
00:09:04,754 --> 00:09:08,314
Traditional hardware struggles
with Pneumo, morphic computing.

128
00:09:08,719 --> 00:09:11,539
Mimicking the human brain for efficiency.

129
00:09:12,529 --> 00:09:17,739
Automated EML and explainable
AI democratizing ai while

130
00:09:17,829 --> 00:09:19,269
keeping it transparent.

131
00:09:20,139 --> 00:09:25,029
These trends will transform the way
we think about scale and adoption.

132
00:09:25,529 --> 00:09:29,914
Building the roadmap for the
foundation of AI driven innovation.

133
00:09:30,414 --> 00:09:33,234
Implement AI native platform successfully.

134
00:09:33,984 --> 00:09:36,384
Organizations particularly need a roadmap.

135
00:09:37,164 --> 00:09:41,544
These include short term wins,
such as building feature tools,

136
00:09:41,934 --> 00:09:47,324
medium term goals, like integrating
observability and long-term strategies

137
00:09:47,324 --> 00:09:50,054
like adopting hr, quantum compute.

138
00:09:50,954 --> 00:09:54,164
The roadmap should balance
innovation with governance,

139
00:09:54,764 --> 00:09:56,324
ensuring sustainable AI adoption.

140
00:09:56,824 --> 00:09:59,314
Key takeaways and the conclusion.

141
00:09:59,814 --> 00:10:07,799
Coning AI native platform is able uniting
infrastructure, workloads, and governance.

142
00:10:08,249 --> 00:10:09,569
Here are the key takeaways.

143
00:10:10,069 --> 00:10:13,219
Infrastructure is the
foundation of scalable.

144
00:10:13,719 --> 00:10:19,569
Understanding workload characteristics
for effective design data pipelines

145
00:10:19,569 --> 00:10:21,879
are the backbone of reliable ai.

146
00:10:22,379 --> 00:10:28,259
Observability ensures continuous implement
governance, build trust and compliance

147
00:10:28,919 --> 00:10:31,379
future trends, demand ongoing division.

148
00:10:31,879 --> 00:10:33,379
Thank you for joining this session.

149
00:10:33,979 --> 00:10:34,944
I hope this helps you.

150
00:10:35,689 --> 00:10:38,154
Strategically about
building a to platform.

151
00:10:38,934 --> 00:10:39,384
Thank you.

