1
00:00:00,500 --> 00:00:01,010
Good morning.

2
00:00:01,290 --> 00:00:05,120
My name is, I am working for the
Salesforce as a lead engineer.

3
00:00:05,620 --> 00:00:09,640
Today I want to talk about an I
starting using the multiple zone

4
00:00:09,850 --> 00:00:11,950
to achieve the high availability.

5
00:00:12,450 --> 00:00:18,580
I have been working in software industry
from past 13 years, and I have mostly

6
00:00:18,580 --> 00:00:19,870
been working as a backend engineer.

7
00:00:20,785 --> 00:00:25,784
Recently I have been working on
the infrastructure services and

8
00:00:25,784 --> 00:00:29,785
that's where I got the opportunity
to to work on a problem where we

9
00:00:30,285 --> 00:00:34,335
wanted to make our infrastructure
service very highly available.

10
00:00:34,835 --> 00:00:39,435
Even though if there is an complete
outage of one of the avail zone.

11
00:00:39,935 --> 00:00:43,055
So with that context, I will start
with the with with the slides.

12
00:00:43,325 --> 00:00:50,115
And the idea here is that in the modern
application we have to have a very high

13
00:00:50,115 --> 00:00:51,795
availability of the services, right?

14
00:00:52,295 --> 00:00:55,615
And and then how can we attribute right.

15
00:00:56,115 --> 00:01:00,945
For the agenda first I will be talking
about the importance of the highly

16
00:01:00,945 --> 00:01:06,155
available fault tolerance system,
and then the foundational principles

17
00:01:07,035 --> 00:01:10,965
the different components in the
architecture and how we can use the

18
00:01:10,965 --> 00:01:12,345
Kubernetes to implement the same.

19
00:01:12,845 --> 00:01:17,865
And then I will also touch upon
how we can have the consistent

20
00:01:18,855 --> 00:01:21,940
routing and at the end the the op.

21
00:01:22,440 --> 00:01:27,180
Before we actually talk about I
available system the first thing

22
00:01:27,180 --> 00:01:28,440
is that why do we need it right?

23
00:01:28,940 --> 00:01:34,560
In a modern day-to-day, the there
are services which if not up

24
00:01:34,650 --> 00:01:36,450
they will be losing the money.

25
00:01:36,840 --> 00:01:40,039
And also if it's not up then you
are losing the customer trust.

26
00:01:40,550 --> 00:01:42,850
So in another way, again,
losing the money, right?

27
00:01:42,910 --> 00:01:45,910
So it is very important to make sure
that your service is very highly

28
00:01:45,910 --> 00:01:50,650
available and, and with the concept of
the microservices how we can achieve it.

29
00:01:51,150 --> 00:01:55,420
So the monolithic service is the problem
with the monolithic services, that it's

30
00:01:55,420 --> 00:01:56,920
the single point of this area, right?

31
00:01:56,980 --> 00:02:00,040
So that's where the microservices
architecture comes into the picture.

32
00:02:00,540 --> 00:02:03,780
With the mi microservice architecture,
we will have the multiple,

33
00:02:04,290 --> 00:02:07,650
we can have, we can start our
services into the multiple zone.

34
00:02:08,020 --> 00:02:09,640
And let me explain about this.

35
00:02:09,760 --> 00:02:15,080
When I say multiple zone the most of
the cloud providers, they have the

36
00:02:15,750 --> 00:02:20,290
they have the multiple availability
zone and the availability zone.

37
00:02:20,290 --> 00:02:23,840
You can think it's a self-contained
set of infrastructure.

38
00:02:24,110 --> 00:02:27,320
And when I say self-contained,
it means that if something has

39
00:02:27,320 --> 00:02:30,950
to go wrong, it'll not affect the
other availability zone, right?

40
00:02:31,050 --> 00:02:35,840
So with that logic, if we have a
service deployed in the multiple

41
00:02:35,840 --> 00:02:40,280
availability zone, what happens
if one availability zone is down?

42
00:02:40,280 --> 00:02:43,785
Your service is still functional your
services is still available, right?

43
00:02:44,285 --> 00:02:48,055
So the the foundational principle
so as I explained, there are

44
00:02:48,055 --> 00:02:49,405
multiple availability zone.

45
00:02:49,495 --> 00:02:51,835
We can treat the each one separately.

46
00:02:51,895 --> 00:02:55,935
One going down should not
affect the the other one, right?

47
00:02:56,435 --> 00:02:59,155
The stateful services
we have to be released.

48
00:02:59,655 --> 00:03:03,885
Careful when we do the sharding
between multiple availabilities known

49
00:03:03,885 --> 00:03:07,495
for the stateful services because
the stateful services generally means

50
00:03:07,495 --> 00:03:12,865
that there is an there is an state
of the data with the portal, right?

51
00:03:13,045 --> 00:03:18,055
So we have to think when the service
upscale or downscale, how do we

52
00:03:18,055 --> 00:03:20,255
maintain the state of the data, right?

53
00:03:20,755 --> 00:03:21,775
The data locality.

54
00:03:21,845 --> 00:03:24,935
We should try to keep the data
not flowing into the multiple

55
00:03:24,935 --> 00:03:26,714
zones right to minimize the flow.

56
00:03:27,214 --> 00:03:31,869
Partial failure design when there
is there is issue with the one zone.

57
00:03:32,049 --> 00:03:33,444
The service code still be functional.

58
00:03:33,944 --> 00:03:36,314
And we need the operational transparency.

59
00:03:36,374 --> 00:03:40,589
We need to have the enough monitoring
and the alerting to monitor the the

60
00:03:40,589 --> 00:03:43,319
status of the different services
in the different availability zone.

61
00:03:43,819 --> 00:03:45,499
So architectural component, right?

62
00:03:45,509 --> 00:03:49,609
So now since we have multiple
zones, our service is deployed in

63
00:03:49,609 --> 00:03:52,570
multiple zones, we need to know.

64
00:03:53,070 --> 00:03:59,279
That which customer request will be
served from the which zone, right?

65
00:04:00,239 --> 00:04:04,790
So that means that we need
some kind of metadata service

66
00:04:05,269 --> 00:04:07,250
to provide that information.

67
00:04:07,909 --> 00:04:13,409
Think of this metadata service, which it's
keep in thick of the your customer versus

68
00:04:13,409 --> 00:04:15,494
which zone service the customer, right?

69
00:04:16,379 --> 00:04:18,689
It's responsible mainly
for the shared assignment.

70
00:04:18,689 --> 00:04:22,689
So whenever a new customer comes, it's
it'll be able to assign that particular

71
00:04:22,689 --> 00:04:24,564
customer to one of the existing card.

72
00:04:25,064 --> 00:04:32,404
It'll also be help full monitoring
the health of the services, and also

73
00:04:32,404 --> 00:04:35,704
routing policies like whenever the
request come for the existing customer,

74
00:04:35,704 --> 00:04:38,369
we start to serve the request.

75
00:04:38,869 --> 00:04:42,289
Starting into the multiple zone,
also help reduce the block radius.

76
00:04:42,709 --> 00:04:45,839
Okay so service design
for multi zone resilience.

77
00:04:46,769 --> 00:04:51,479
So injury service registration that
includes zone information, capacity

78
00:04:51,479 --> 00:04:56,129
indicators, and dependency relationship
enables in intelligent client side

79
00:04:56,129 --> 00:04:57,419
load balancing and availability.

80
00:04:57,919 --> 00:05:01,484
A stateful component, isolation clear
separation of a stateful component

81
00:05:01,514 --> 00:05:03,824
from a stateless processing logic.

82
00:05:04,324 --> 00:05:07,654
And that scale configuration will
help us to maintain the global

83
00:05:07,654 --> 00:05:12,514
configuration, keeping the Joni specific
configuration as an option to override.

84
00:05:13,014 --> 00:05:17,354
When we, if you have microservices,
you have, you are implementing

85
00:05:17,354 --> 00:05:18,254
using the Kubernetes.

86
00:05:18,254 --> 00:05:19,694
These are the best practice to follow.

87
00:05:19,694 --> 00:05:21,914
You need to have the past
distribution strategy.

88
00:05:22,414 --> 00:05:26,764
You also need to have the
persistent volume management the

89
00:05:26,944 --> 00:05:28,324
persistent volume management.

90
00:05:29,014 --> 00:05:32,454
Whenever we create a stateful
pod, we can actually have the

91
00:05:32,454 --> 00:05:35,354
pod affinity in in the topology.

92
00:05:35,854 --> 00:05:40,324
To tell the different parts
to come up in a, to fall into

93
00:05:40,324 --> 00:05:41,734
the different topology, right?

94
00:05:42,234 --> 00:05:43,504
The service consideration.

95
00:05:44,004 --> 00:05:49,084
And also we can have the zone
aware scaling deployment, right?

96
00:05:49,144 --> 00:05:54,209
This will be helpful when you have
the one zone down and then you want to

97
00:05:54,209 --> 00:05:55,979
redirect the traffic to the other zone.

98
00:05:56,524 --> 00:06:01,354
If you have the zone of very scaling that
time you don't have to worry about other

99
00:06:01,354 --> 00:06:03,574
zone, able to handle all the traffic.

100
00:06:04,074 --> 00:06:04,374
Okay.

101
00:06:04,834 --> 00:06:09,044
We'll do, I do want to talk a little
bit more about the the request routing

102
00:06:09,134 --> 00:06:14,415
and the load balancing the metadata
service, which keeps the state of the

103
00:06:14,520 --> 00:06:15,795
which knows the state of all the drones.

104
00:06:16,295 --> 00:06:20,425
It also knows that which customer
is being come from the Wi Zone, so

105
00:06:20,665 --> 00:06:24,745
it'll be able to act as an intelligent
router and also as a load balancer.

106
00:06:25,245 --> 00:06:28,605
We also need to make sure that we are
using the consistent testing because

107
00:06:28,655 --> 00:06:30,915
the number of the Jones is not fixed.

108
00:06:30,915 --> 00:06:32,205
It can we might have.

109
00:06:32,875 --> 00:06:37,825
The requirement to add more zones or
the requirement of removing a zone.

110
00:06:38,395 --> 00:06:42,335
In this case, we need to use the
consistent housing which will, and we

111
00:06:42,335 --> 00:06:49,660
need to make sure that the the the data
is being moved in the correct zone so

112
00:06:49,660 --> 00:06:54,090
that the customer can be served correctly,
okay, so for the data consist consistency

113
00:06:54,870 --> 00:06:57,060
and the state management data consistency.

114
00:06:57,060 --> 00:07:00,930
If you have higher consistency
requirements than what you want to

115
00:07:00,930 --> 00:07:05,050
do before you replicate the data
across the zone, you have to you the

116
00:07:05,230 --> 00:07:08,450
request will only be successful if
the data is replicated across all the

117
00:07:08,450 --> 00:07:10,910
Jones, which is highly consistent.

118
00:07:11,030 --> 00:07:11,390
From.

119
00:07:12,155 --> 00:07:15,125
From the ki you can know
like the consistency and

120
00:07:15,125 --> 00:07:16,775
availability goes hand to hand.

121
00:07:17,495 --> 00:07:20,975
So if you try to make the
system high consistency, your

122
00:07:20,975 --> 00:07:22,385
availability will go for a toss.

123
00:07:22,625 --> 00:07:25,835
And the other way also, if you want to
keep the system for a highly available,

124
00:07:25,835 --> 00:07:27,635
the consistency will go for a toss, right?

125
00:07:27,635 --> 00:07:33,190
So if you go for high consistency, you are
saying that you want to write to all the.

126
00:07:33,690 --> 00:07:38,900
Before you confirm the completion of
the request, which means that if any

127
00:07:38,930 --> 00:07:43,590
drone is not available, then then you
are you will not be able to write.

128
00:07:43,590 --> 00:07:46,470
So you're saying I'm going for
the high consistency, but then

129
00:07:46,470 --> 00:07:47,820
you are reducing the availability.

130
00:07:48,550 --> 00:07:52,030
My suggestion is to go with the
eventual consistency because our

131
00:07:52,030 --> 00:07:53,620
focus is the high availability.

132
00:07:54,420 --> 00:07:57,960
So it should be okay if the other
zones eventually get the data.

133
00:07:58,460 --> 00:08:01,280
And then Joan Aware database charting.

134
00:08:01,610 --> 00:08:06,740
So we can like place complete the
data participant within Joan while

135
00:08:06,800 --> 00:08:08,510
maintaining the global consistency.

136
00:08:09,010 --> 00:08:09,905
For the conflict solution.

137
00:08:10,355 --> 00:08:15,815
We can have the simple last slide
win, or maybe we can have the better

138
00:08:16,085 --> 00:08:19,495
complicated, algorithm That depends
on the requirement or requirement.

139
00:08:19,995 --> 00:08:24,135
It's also very important to have the
monitoring and the observability.

140
00:08:25,135 --> 00:08:28,710
We need to make sure that the different
zone of what are their capacity.

141
00:08:29,210 --> 00:08:33,960
And based on that, we have to
pre-provision the, another drone or

142
00:08:33,960 --> 00:08:35,490
increase the capacity of the drone.

143
00:08:35,555 --> 00:08:40,415
So it's very important to monitor the
the health of the services in the each

144
00:08:40,415 --> 00:08:43,765
zone since it's now multiple zones.

145
00:08:44,265 --> 00:08:47,445
Debugging any issue is harder.

146
00:08:47,625 --> 00:08:52,825
That's why it is if you have a distributed
testing it'll help you trace the issue.

147
00:08:53,725 --> 00:08:58,520
And and also having the locks
will help find the two better.

148
00:08:59,020 --> 00:09:01,180
This is also very important,
the cost optimization.

149
00:09:01,830 --> 00:09:05,470
When we go for the high availability
what we are doing actually is

150
00:09:05,470 --> 00:09:07,300
duplicating everything, right?

151
00:09:07,330 --> 00:09:11,670
So we are duplicating infrastructure and
then, which means that the more cost there

152
00:09:11,670 --> 00:09:16,825
are few things which we can do to make
sure that we have a check on the call.

153
00:09:17,325 --> 00:09:20,385
First thing is that we can,
based on the pop test, we can

154
00:09:20,715 --> 00:09:22,425
rightsize the instance, right?

155
00:09:22,455 --> 00:09:27,485
So on the different zone, there is
also concept of the reverse reserve

156
00:09:27,485 --> 00:09:32,375
instance, which means that we, we book
the the instance like in advance which

157
00:09:32,375 --> 00:09:33,905
comes at the very discounted rate.

158
00:09:34,875 --> 00:09:36,805
So that can save us the save us well.

159
00:09:37,305 --> 00:09:41,415
We have to be careful, like how do we
be, we communicate between the Jones.

160
00:09:41,725 --> 00:09:44,755
There are different
options based on the cost.

161
00:09:44,965 --> 00:09:48,645
We can choose the one the Joan
Aware auto Scaling policy.

162
00:09:49,065 --> 00:09:49,755
This will help us

163
00:09:50,235 --> 00:09:55,895
to not over provision the zone and
only autoscale when it is needed.

164
00:09:56,555 --> 00:09:56,795
Yeah.

165
00:09:57,295 --> 00:09:59,395
Yeah, so operational best practice.

166
00:09:59,875 --> 00:10:05,625
We can actually have the CICD pipeline,
which actually also have a canary.

167
00:10:05,745 --> 00:10:09,405
So before we deploy in June, we
can actually test our solution

168
00:10:09,975 --> 00:10:11,445
to reduce the blast radius.

169
00:10:11,945 --> 00:10:12,185
We can.

170
00:10:12,685 --> 00:10:16,405
We also need to be, make sure
that the changes that we are

171
00:10:16,405 --> 00:10:18,585
doing is is not zone dependent.

172
00:10:18,635 --> 00:10:21,814
So like your change work on the
one zone and not onto the other.

173
00:10:21,814 --> 00:10:25,524
So your service need to be
agnostic of it and it should be

174
00:10:25,524 --> 00:10:27,935
able to to work on the any zone.

175
00:10:28,435 --> 00:10:29,755
Okay, so in conclusion.

176
00:10:30,255 --> 00:10:35,715
Your service across multiple zones will
help you achieve the higher availability.

177
00:10:36,215 --> 00:10:42,535
But then there is additional complexity
to maintain the the metadata service,

178
00:10:42,535 --> 00:10:44,095
which is required for the routing.

179
00:10:44,095 --> 00:10:49,020
There is additional cost and there
is an additional complexity when

180
00:10:49,020 --> 00:10:50,140
you want to debug the atrial.

181
00:10:50,770 --> 00:10:55,800
So depending on the application use
we have, we need to see if charting

182
00:10:55,950 --> 00:10:57,990
across multiple zone is required.

183
00:10:58,490 --> 00:11:02,420
The one of the use case, which I
can think is like the database,

184
00:11:03,110 --> 00:11:07,370
when you have a database, services
where you actually store the data.

185
00:11:07,870 --> 00:11:12,880
If you charge your service on
the multiple zone, then and then.

186
00:11:13,405 --> 00:11:14,485
You replicate, right?

187
00:11:14,535 --> 00:11:17,650
So what happens in this case, even
if you, one of the zone is down, you

188
00:11:17,650 --> 00:11:21,460
still will be able to serve the data
from the other zone if it's serving

189
00:11:21,460 --> 00:11:22,990
a mission critical services, right?

190
00:11:23,040 --> 00:11:24,180
Or the TGO services.

191
00:11:24,210 --> 00:11:26,940
So for those use cases, it makes sense.

192
00:11:27,450 --> 00:11:30,000
Yeah, so I think I will stop here.

193
00:11:30,250 --> 00:11:30,940
Thank you very much.

