1
00:00:00,160 --> 00:00:01,360
This is Srinivasa Bhitla.

2
00:00:02,170 --> 00:00:05,449
Before I proceed, I would like
to make a quick disclaimer.

3
00:00:06,300 --> 00:00:10,969
All views expressed here are my
own and do not reflect the opinions

4
00:00:10,970 --> 00:00:13,090
of any affiliated organization.

5
00:00:13,590 --> 00:00:16,860
Today's topic is going to be
on revolutionizing software

6
00:00:16,860 --> 00:00:22,570
testing with AI and ML, driving
scalability and accuracy in QA.

7
00:00:23,070 --> 00:00:27,480
So the agenda for today's talk is
I'm going to introduce the Then

8
00:00:27,480 --> 00:00:30,910
I'm going to explain about the
challenges in traditional testing

9
00:00:30,910 --> 00:00:34,530
and introduce AI and ML testing.

10
00:00:35,030 --> 00:00:38,870
Compare with traditional
testing with AI and ML testing.

11
00:00:39,370 --> 00:00:44,019
Then I'm going to explain about
how AI and ML enhances the testing.

12
00:00:44,299 --> 00:00:48,270
Where I'm going to explain
about some case studies, demos.

13
00:00:49,210 --> 00:00:53,590
Then I'm going to talk about tools
and technologies in AI and ML testing.

14
00:00:54,370 --> 00:00:57,319
And challenges in adopting
AI and ML in testing.

15
00:00:58,185 --> 00:01:02,935
Then I'm finally going to cover
about, future of QA and key takeaways.

16
00:01:03,435 --> 00:01:04,885
Introduction to software testing.

17
00:01:05,385 --> 00:01:08,615
Traditionally, how we have been
doing the software testing, right?

18
00:01:08,615 --> 00:01:14,575
So any software or any application under
test that we carry out the testing,

19
00:01:14,954 --> 00:01:20,924
We ensure that the quality standards
are met and consistently the software

20
00:01:20,934 --> 00:01:23,134
works according to the expectations.

21
00:01:23,634 --> 00:01:28,044
So we generally used to follow like two
types of testings, like one is manual

22
00:01:28,074 --> 00:01:30,654
testing and another is automated testing.

23
00:01:31,634 --> 00:01:37,714
In manual testing, we traditionally used
to capture the test cases and test steps.

24
00:01:38,365 --> 00:01:43,535
either in the test management tool or in
a typical spreadsheet, Excel spreadsheet.

25
00:01:44,514 --> 00:01:50,235
When we interact with the application
under test, capture the results and

26
00:01:50,244 --> 00:01:54,395
mark respective test as a pass or fail.

27
00:01:54,895 --> 00:02:01,075
And we traditionally used to execute step
by step and ensure that the each step

28
00:02:01,145 --> 00:02:02,965
is actually meeting the expectations.

29
00:02:03,465 --> 00:02:05,435
That is all about the manual testing.

30
00:02:05,815 --> 00:02:09,425
In the automation testing,
Same step by step interactions.

31
00:02:09,615 --> 00:02:11,455
We used to do it like a script.

32
00:02:11,955 --> 00:02:15,555
The script used to, have
the expected results.

33
00:02:16,075 --> 00:02:17,587
And that's what you're going to verify.

34
00:02:17,587 --> 00:02:22,205
You're going to write the verifications
as a script and feed those scripts

35
00:02:22,234 --> 00:02:29,125
to the automation tool, execute them
and see whether a automated test is

36
00:02:29,195 --> 00:02:31,585
passing or failing automation test.

37
00:02:31,605 --> 00:02:35,495
We generally, introduce
for any repetitive tasks.

38
00:02:35,995 --> 00:02:36,785
For example.

39
00:02:37,160 --> 00:02:41,360
If you are running in, running the
test on the cross browsers, or if

40
00:02:41,360 --> 00:02:45,230
you want to run on different versions
of the software, or if you want to,

41
00:02:45,470 --> 00:02:49,160
do a frequent releases, that's where
the automation testing is scalable.

42
00:02:49,660 --> 00:02:53,400
So now let's get on to what are the
challenges in traditional testing.

43
00:02:53,900 --> 00:02:59,850
So manual testing is definitely
time consuming because a software

44
00:02:59,940 --> 00:03:01,590
test engineer need to sit.

45
00:03:02,435 --> 00:03:05,095
And he has to interact
with the system manually.

46
00:03:06,015 --> 00:03:08,705
And, this is definitely
a time consuming thing.

47
00:03:08,755 --> 00:03:12,055
And human errors are typical problems.

48
00:03:12,115 --> 00:03:16,765
If you do any kind of step, if
you miss, or if any test case is

49
00:03:16,815 --> 00:03:18,385
missed, that is error prone thing.

50
00:03:19,185 --> 00:03:20,155
And it is hard to scale.

51
00:03:20,655 --> 00:03:22,325
When it comes to automation testing.

52
00:03:22,825 --> 00:03:25,135
So it is always, high maintenance.

53
00:03:25,425 --> 00:03:29,195
The reason is if the software
is undergoing frequent changes,

54
00:03:29,505 --> 00:03:30,715
you have to update the scripts.

55
00:03:31,215 --> 00:03:33,085
So that is where, the challenges are.

56
00:03:33,585 --> 00:03:38,455
And also when it comes to the complex
applications, you have to do a

57
00:03:38,485 --> 00:03:43,415
comprehensive testing, otherwise you
can't release, especially any financial

58
00:03:43,925 --> 00:03:45,675
healthcare products or mission kit.

59
00:03:46,175 --> 00:03:49,265
So definitely, you have to
do the comprehensive testing.

60
00:03:49,295 --> 00:03:54,805
That's where, you have to spend quite a
bit of time to check for the, quality.

61
00:03:55,305 --> 00:03:58,655
So the question for you is, can
current testing methods keep up

62
00:03:58,655 --> 00:04:00,135
with the rapid software releases?

63
00:04:00,635 --> 00:04:01,155
Let's see.

64
00:04:01,655 --> 00:04:04,635
So that's where we
introduce AI and ML testing.

65
00:04:05,135 --> 00:04:08,205
So here we are going to talk about AI.

66
00:04:08,205 --> 00:04:11,065
AI is nothing but artificial intelligence.

67
00:04:11,565 --> 00:04:16,715
So if you really, if I want to define in
a single sentence, which mimics the human

68
00:04:16,725 --> 00:04:20,355
intelligence for a problem solving, right?

69
00:04:20,855 --> 00:04:21,135
Yeah.

70
00:04:21,265 --> 00:04:24,295
So you can always read
more about AI elsewhere.

71
00:04:24,445 --> 00:04:26,375
I don't want to go too
much detail into it.

72
00:04:26,995 --> 00:04:27,935
Machine learning is.

73
00:04:28,435 --> 00:04:34,905
learns the patterns from a given
existing data to make the predictions.

74
00:04:35,405 --> 00:04:38,685
So if you want to predict something, you
need to give some kind of, feeder data.

75
00:04:38,805 --> 00:04:43,585
Large volume of data is always better
to do the accurate predictions.

76
00:04:44,575 --> 00:04:48,785
So these AI and ML, we are going
to introduce to the testing groups.

77
00:04:49,335 --> 00:04:54,305
How you can introduce a human
intelligence in a tool and how you can

78
00:04:54,305 --> 00:04:59,295
actually give the data to the system
and predict how The test results is

79
00:04:59,295 --> 00:05:03,305
going to be in the future and how the
system is going to behave in the future.

80
00:05:03,735 --> 00:05:05,105
So that's what we are going to predict.

81
00:05:05,605 --> 00:05:09,724
So now the question for you is,
how could AI ML reduce testing

82
00:05:09,725 --> 00:05:11,125
bottlenecks in your projects?

83
00:05:11,625 --> 00:05:14,435
Let's go into deep and
then see what's coming up.

84
00:05:14,935 --> 00:05:18,315
So this is where we are
comparing traditional testing

85
00:05:18,335 --> 00:05:19,745
versus AI driven testing.

86
00:05:20,245 --> 00:05:25,305
So here I divided the
features into five categories.

87
00:05:25,805 --> 00:05:27,195
One is test case creation.

88
00:05:27,695 --> 00:05:30,205
How it actually done in
the traditional testing.

89
00:05:30,205 --> 00:05:32,325
It is in the manual or the scripted way.

90
00:05:32,325 --> 00:05:37,915
In the AI driven testing, it is
automatically generated, used based

91
00:05:37,915 --> 00:05:39,365
on AI, artificial intelligence.

92
00:05:39,865 --> 00:05:42,115
And script maintenance,
especially in traditional

93
00:05:42,185 --> 00:05:43,515
testing, it is very high effort.

94
00:05:44,355 --> 00:05:47,625
In AI driven testing,
self healing scripts.

95
00:05:48,255 --> 00:05:55,705
Meaning like the tool itself will let
you to correct some mistakes on the fly.

96
00:05:56,205 --> 00:06:00,335
And defect detection in traditional
testing, it is always reactive, right?

97
00:06:00,365 --> 00:06:02,445
Once it happens, you are
going to go act on it.

98
00:06:02,945 --> 00:06:07,275
In AI driven testing, you forecast
and predict what can go wrong.

99
00:06:07,955 --> 00:06:09,095
And then you come up with the remedies.

100
00:06:09,595 --> 00:06:12,385
And scalability in traditional
testing is very limited.

101
00:06:12,885 --> 00:06:16,905
In AI driven testing, it is highly
scalable because the less effort

102
00:06:16,905 --> 00:06:21,875
you are going to spend on Accuracy
in traditional testing human errors

103
00:06:22,105 --> 00:06:24,435
are possible in AI driven testing.

104
00:06:24,625 --> 00:06:25,625
It's high precision.

105
00:06:26,125 --> 00:06:31,765
So the question for you is which feature
do you think makes AI testing is superior?

106
00:06:32,265 --> 00:06:37,175
So you have five features and
giving a food for thought.

107
00:06:37,215 --> 00:06:40,285
You can think what could be
appropriate based on your project.

108
00:06:40,285 --> 00:06:43,444
How AI and ML enhance testing.

109
00:06:43,944 --> 00:06:49,904
Here we have so many test artifacts
we generate, or we create, in a

110
00:06:49,944 --> 00:06:54,804
traditional testing phases, you
actually manually produce, you

111
00:06:54,814 --> 00:06:56,264
manually write a lot of things.

112
00:06:56,764 --> 00:07:04,144
So in the AI ML enhanced testing, AI will
help you to generate the test artifacts

113
00:07:04,584 --> 00:07:09,184
based on the historical information
that your organization already has it.

114
00:07:09,974 --> 00:07:13,644
So once you feed all the historical
data to your specific model.

115
00:07:14,379 --> 00:07:19,799
You should be able to generate a new
document or new test strategy like the

116
00:07:19,799 --> 00:07:26,239
artifact one of that would be a test
process or manual test cases or automated

117
00:07:26,259 --> 00:07:29,749
BDD tests from existing historical data.

118
00:07:30,249 --> 00:07:34,139
To do that, of course, you need
to have your, machine learning

119
00:07:34,149 --> 00:07:37,529
models deployed, and you may need
to feed all the historical data,

120
00:07:37,669 --> 00:07:41,049
and you need to train, then you may
be able to generate all of these.

121
00:07:41,549 --> 00:07:43,689
So that's the process we
are going to learn later.

122
00:07:44,169 --> 00:07:45,209
But that's how it works.

123
00:07:45,959 --> 00:07:51,789
And that self healing scripts, if
something changes while you, maintaining

124
00:07:51,789 --> 00:07:56,290
your tests or running your tests, you'll
also get a chance to, self heal by itself.

125
00:07:57,160 --> 00:08:01,240
And then you can also do the predictive
analysis where you can forecast

126
00:08:01,870 --> 00:08:03,569
high risk areas in applications.

127
00:08:03,569 --> 00:08:07,659
So what can go wrong based on the
historical defect trend, based on

128
00:08:07,669 --> 00:08:11,029
the historical changes that happened
in the application in the test?

129
00:08:11,495 --> 00:08:13,265
How do you predict you're going to learn?

130
00:08:13,765 --> 00:08:15,645
So then dynamic test strategy.

131
00:08:15,735 --> 00:08:18,485
So how do you generate a test strategy?

132
00:08:19,275 --> 00:08:23,415
here I am using the model,
LLM model, chart GPT 4.

133
00:08:23,474 --> 00:08:28,744
0. So here I'm going to give
you a prompt to the chart GPT.

134
00:08:29,244 --> 00:08:34,504
And throughout my presentation, I'm taking
an e commerce application as an example.

135
00:08:35,474 --> 00:08:40,994
So here, the prompt that I'm
giving to chart GPT Is I work as

136
00:08:40,994 --> 00:08:43,064
a software QA engineering manager.

137
00:08:43,564 --> 00:08:46,614
Our organization is developing
an e commerce application.

138
00:08:47,454 --> 00:08:52,254
Can you generate a test strategy
for e commerce application?

139
00:08:53,204 --> 00:08:54,484
This is the prompt I'm giving.

140
00:08:55,374 --> 00:08:59,044
So now what I would get the
output from the chart GPT.

141
00:08:59,544 --> 00:09:03,724
So here is the, comprehensive test
strategy generated by chart GPT, where

142
00:09:03,724 --> 00:09:08,264
it described the high level objective
and the And also it defined the

143
00:09:08,264 --> 00:09:10,964
scope of the test stat, the testing.

144
00:09:11,464 --> 00:09:15,834
And then it also generates what is the
testing approach you may need to follow.

145
00:09:16,464 --> 00:09:17,474
What are the test levels?

146
00:09:18,184 --> 00:09:19,509
What are the test slides?

147
00:09:20,230 --> 00:09:24,120
That you may need to follow to carry out
the testing for the e commerce application

148
00:09:24,620 --> 00:09:29,740
and which are the tools that your tools
and technologies that you may recommend

149
00:09:29,760 --> 00:09:35,120
based on your historical information
and also what are the test environment

150
00:09:35,130 --> 00:09:39,420
you may need to set up and the test
deliverables what is expected out of the

151
00:09:39,420 --> 00:09:44,990
testing like test plan, test cases, test
execution reports, defect reports, right?

152
00:09:45,380 --> 00:09:49,520
And also, you can also get the roles
and responsibilities, like what kind of

153
00:09:49,540 --> 00:09:54,320
roles and responsibilities are needed
for carrying out these tasks, like

154
00:09:54,340 --> 00:09:59,120
QA engineering manager, QA engineers,
developers, product owners, DevOps

155
00:09:59,150 --> 00:10:03,400
team, and what is the entry criteria
and what is the exit criteria, right?

156
00:10:03,900 --> 00:10:08,330
And what is the risk and mitigation,
techniques that you may need to follow?

157
00:10:09,070 --> 00:10:11,190
And what are the test metrics
you may need to produce?

158
00:10:11,690 --> 00:10:15,450
And how do you want to,
continuously improve your, testing.

159
00:10:16,150 --> 00:10:20,040
ChartGPT generated pretty much
everything just by giving some prompt.

160
00:10:20,540 --> 00:10:25,970
And I don't recommend you to take this as
is, but if your organization is already

161
00:10:25,980 --> 00:10:31,740
having some kind of, documentations,
you feed it to your own privately

162
00:10:31,750 --> 00:10:37,630
deployed models, LLNs, and then make
it trained, and then use this prompt.

163
00:10:38,130 --> 00:10:44,740
And I don't recommend you to upload
your documents in the public card, GPT

164
00:10:44,740 --> 00:10:52,045
or any LS that may actually know, leak
your pri privacy or any kind, copyright

165
00:10:52,075 --> 00:10:56,540
data you are sharing on the public
domains that may not be advisable.

166
00:10:56,720 --> 00:11:03,310
I strictly don't recommend you to put it
on any public, GPT charge, GPT or any LLS.

167
00:11:03,720 --> 00:11:03,870
Okay?

168
00:11:03,870 --> 00:11:06,125
If you're any internal
things you can do that.

169
00:11:07,025 --> 00:11:12,675
train and then use these prompts, but
if you want to generate a generic test

170
00:11:12,935 --> 00:11:18,885
strategy or a generic information, I
would suggest you to use this, but never

171
00:11:18,885 --> 00:11:20,375
keep your private information out there.

172
00:11:20,875 --> 00:11:26,035
And then this is the dynamic strategy,
which is generated with one single prompt.

173
00:11:26,075 --> 00:11:27,775
You got so much of information.

174
00:11:27,785 --> 00:11:30,635
You mean you don't need to
search anywhere else, right?

175
00:11:30,675 --> 00:11:32,305
The test strategy document is generated.

176
00:11:32,615 --> 00:11:35,305
Now you can use this as
part of your, testing.

177
00:11:35,805 --> 00:11:38,495
And another prompt is for
test process generation.

178
00:11:39,085 --> 00:11:41,845
So the prompt is I worked as a
software testing professional,

179
00:11:42,185 --> 00:11:46,595
outline the process I would follow
if I were conducting a manual test.

180
00:11:47,095 --> 00:11:50,045
So here is the process that
you are supposed to follow.

181
00:11:50,155 --> 00:11:54,065
Understand the requirements,
do a test planning, develop the

182
00:11:54,115 --> 00:11:59,074
test case design, set up the test
environment, execute the test cases.

183
00:11:59,574 --> 00:12:01,384
And log the defects.

184
00:12:01,454 --> 00:12:07,644
If there are any failures, retest and
regression test, retest is like whenever

185
00:12:07,674 --> 00:12:12,504
the new features are coming up, you do
retest whenever the issues are fixed.

186
00:12:12,504 --> 00:12:13,984
So you do the regression test.

187
00:12:14,634 --> 00:12:19,384
And then finally, if the application
meets the standards, do a test closure

188
00:12:20,154 --> 00:12:23,654
and do the continuous improvement
as the product evolves and what are

189
00:12:23,654 --> 00:12:29,174
the best practices you want to, do
it for your test process, then the

190
00:12:29,174 --> 00:12:30,814
dynamic manual test case generation.

191
00:12:31,314 --> 00:12:36,264
So now again, I'm going to use
another prompt to generate the test

192
00:12:36,264 --> 00:12:38,224
cases for my application under test.

193
00:12:38,724 --> 00:12:43,554
So the prompt is, I work as a software
testing professional, our organization

194
00:12:43,564 --> 00:12:45,364
is developing an e commerce application.

195
00:12:45,904 --> 00:12:49,134
Can you generate manual
test cases for such feature?

196
00:12:49,464 --> 00:12:53,524
Here, I'm specifically saying,
generate the manual test

197
00:12:53,714 --> 00:12:54,844
cases for the such feature.

198
00:12:55,344 --> 00:12:57,644
So now let's see what
chart GPT does for us.

199
00:12:58,144 --> 00:12:59,274
So functional test cases.

200
00:12:59,894 --> 00:13:03,024
So it listed about five test
cases where you have test case

201
00:13:03,024 --> 00:13:08,304
description and test steps to evaluate
expected results, preconditions,

202
00:13:08,305 --> 00:13:11,464
and usability test cases, right?

203
00:13:11,534 --> 00:13:15,234
Again, you've got the same thing,
then boundary and negative test cases,

204
00:13:16,144 --> 00:13:19,014
performance test cases, edge test cases.

205
00:13:19,514 --> 00:13:24,284
So with single prompt, you've got so
much of data in a tabular format, and

206
00:13:24,294 --> 00:13:29,434
you may not use as it is, make the
changes according to your requirements.

207
00:13:30,169 --> 00:13:32,179
And then you can carry out those testings.

208
00:13:32,679 --> 00:13:35,709
And if you have a historical
test case document fed to your

209
00:13:36,639 --> 00:13:42,079
AIML model, you may regenerate
automatically without, sweating.

210
00:13:42,579 --> 00:13:46,499
Then dynamic BDD automation
test case generation.

211
00:13:47,339 --> 00:13:49,819
So this is like completely automated.

212
00:13:50,319 --> 00:13:53,909
So BDD meaning behavioral
driven automation testing.

213
00:13:54,889 --> 00:13:57,159
So here I'm giving you a prompt.

214
00:13:58,144 --> 00:14:01,464
Again to the chart GPT on
e commerce application.

215
00:14:02,304 --> 00:14:06,764
So generate BDD scenarios and
Java behavioral test for searching

216
00:14:06,804 --> 00:14:11,104
products in an e commerce application,
add the files such as e commerce

217
00:14:11,104 --> 00:14:17,234
application methods, step definitions,
feature files, runner file, and pom.

218
00:14:17,234 --> 00:14:20,234
xml with explanation of each file.

219
00:14:21,024 --> 00:14:24,554
So this is the prompt I'm giving
it to the chart GPT model.

220
00:14:24,554 --> 00:14:24,624
Okay.

221
00:14:25,419 --> 00:14:26,229
Now see what it generates.

222
00:14:26,729 --> 00:14:33,249
It generated a BDD feature file where
you have three scenarios listed for such

223
00:14:33,259 --> 00:14:40,529
feature and then I got a step definition
java file which, which is having your

224
00:14:40,579 --> 00:14:46,744
imports and the step definitions which
are generated like with given and then

225
00:14:46,754 --> 00:14:53,714
and whatever the methods are required
by those BDD specific test steps

226
00:14:53,774 --> 00:14:55,974
associated with the step definitions.

227
00:14:56,514 --> 00:15:00,164
I didn't list everything
because of the space constraint.

228
00:15:00,894 --> 00:15:06,194
And then it generated a test runner class,
which has associated with the feature

229
00:15:06,204 --> 00:15:13,614
file and also blue, which folder the
step definition files are supposed to go.

230
00:15:13,624 --> 00:15:13,684
Thank you.

231
00:15:14,379 --> 00:15:16,489
And this is the way
test runner is defined.

232
00:15:17,449 --> 00:15:19,229
Then an e commerce application method.

233
00:15:20,189 --> 00:15:23,049
So this is like typical
implementation of your application,

234
00:15:23,079 --> 00:15:24,369
how it's been implemented.

235
00:15:24,369 --> 00:15:27,219
And this is what the method will
be called from the step definitions

236
00:15:27,719 --> 00:15:29,269
and then the project structure.

237
00:15:30,059 --> 00:15:34,049
So typical projects are structured, how
the files are supposed to be kept as

238
00:15:34,049 --> 00:15:39,249
part of your application folder or the
test folder that you are going to create.

239
00:15:39,309 --> 00:15:43,914
It could be an IntelliJ or Eclipse or
wherever you want to keep your files.

240
00:15:44,814 --> 00:15:47,224
And then the maven can configuration palm.

241
00:15:47,224 --> 00:15:47,854
xml.

242
00:15:48,484 --> 00:15:53,584
So here it actually describes about, all
the file, all the dependent libraries

243
00:15:53,624 --> 00:15:55,734
that are needed for your PDD test.

244
00:15:56,254 --> 00:16:01,184
That may include your cucumber
jars and the selenium.

245
00:16:01,254 --> 00:16:04,994
If you are using selenium related
dependent jars, and if you are

246
00:16:05,014 --> 00:16:08,674
using any other dependence, it's
going to generate from here.

247
00:16:09,454 --> 00:16:12,624
And then you have the
explanation of each file.

248
00:16:13,079 --> 00:16:17,239
Which file is intended for what and
it also gave you the commands like

249
00:16:17,279 --> 00:16:19,139
how you want to run your tests.

250
00:16:20,099 --> 00:16:23,849
So with a click of your prompt,
you got all the information that

251
00:16:24,049 --> 00:16:25,489
is needed, including the code.

252
00:16:26,239 --> 00:16:31,239
I also generated, the same code
and I created a git repository.

253
00:16:32,129 --> 00:16:37,499
If you want to explore and if you
want to learn how it is generated

254
00:16:37,969 --> 00:16:41,309
and there are some kind of, runtime
errors you may face when you set it

255
00:16:41,309 --> 00:16:44,579
up because the packages and all that
you may need to configure it properly.

256
00:16:45,179 --> 00:16:49,139
if you want to play around, you can
go here, download and run from there.

257
00:16:49,809 --> 00:16:54,079
So I can give you a quick demo
of the same test that is created

258
00:16:54,119 --> 00:16:57,279
from, the prompt from chat GPT.

259
00:16:57,839 --> 00:16:59,489
So I'm opening the IntelliJ.

260
00:17:00,089 --> 00:17:01,869
And then I'm going to, play from there.

261
00:17:02,369 --> 00:17:04,389
So here is my IntelliJ.

262
00:17:04,889 --> 00:17:06,989
So here is my, feature file.

263
00:17:07,609 --> 00:17:09,989
Here you see search for
products by package.

264
00:17:10,779 --> 00:17:12,099
So I want to enter this step.

265
00:17:12,599 --> 00:17:14,049
Yeah, I want to enter this step.

266
00:17:14,549 --> 00:17:17,409
So it went to the step definition file.

267
00:17:17,909 --> 00:17:20,119
So this is the step definition file.

268
00:17:20,119 --> 00:17:21,509
And this is the e commerce app.

269
00:17:22,409 --> 00:17:24,809
In the e commerce app,
I see load homepage.

270
00:17:24,999 --> 00:17:26,119
This is the load homepage.

271
00:17:26,959 --> 00:17:30,329
This is where all my, application
specific methods are defined.

272
00:17:31,109 --> 00:17:32,559
And this is my runner class.

273
00:17:33,279 --> 00:17:35,539
Here you see the feature files.

274
00:17:36,449 --> 00:17:41,629
Here, test, com, e commerce,
yeah, test, com, e commerce.

275
00:17:42,129 --> 00:17:42,879
Right features.

276
00:17:43,099 --> 00:17:44,859
So this is where my feature file is there.

277
00:17:45,419 --> 00:17:49,489
And this is what my runner class and
these are step definitions, right?

278
00:17:50,029 --> 00:17:54,769
And glue is you're gluing to the
step definitions folder just to come

279
00:17:54,769 --> 00:17:59,530
commerce step definitions And this
is where your palm dot xml is So this

280
00:17:59,530 --> 00:18:03,760
is the the full full fledged palm dot
xml And you may sometimes, sometimes

281
00:18:03,950 --> 00:18:08,360
because it is chart GPT, you may
get some hallucinated, plugins it

282
00:18:08,360 --> 00:18:10,430
may add, sometimes it may not work.

283
00:18:10,930 --> 00:18:15,100
So I recommend you to download
and then make it run from here.

284
00:18:15,300 --> 00:18:18,720
some of the plugins you may need to add
or some of them you may need to delete.

285
00:18:19,150 --> 00:18:24,550
Because this is all about, the LLMs, which
you may not have the right amount of data.

286
00:18:24,590 --> 00:18:28,230
If you want to run from here, run
it, execute and capture the results.

287
00:18:29,190 --> 00:18:36,090
So this is all about, how you can actually
use, your, chart GPT to generate the

288
00:18:36,650 --> 00:18:40,090
whole behavioral driven test cases.

289
00:18:40,170 --> 00:18:42,310
And then you can use
it as part of, testing.

290
00:18:42,830 --> 00:18:47,240
So though these B, the BDDs
are not directly useful to you.

291
00:18:47,760 --> 00:18:53,760
If somebody want to generate a BDD
driven tests, and if you don't know how

292
00:18:53,760 --> 00:18:59,050
to do it, you still, go to charge GPT,
get the whole structure and customize

293
00:18:59,100 --> 00:19:04,730
these automated, that tests according
to your, application under test needs.

294
00:19:05,080 --> 00:19:07,470
At least you'll get the framework
structure and then you can

295
00:19:07,470 --> 00:19:08,760
start building on top of it.

296
00:19:09,460 --> 00:19:13,040
Even if you're not using for the e
commerce application, you can get the

297
00:19:13,190 --> 00:19:14,890
basic structure and play around with that.

298
00:19:15,390 --> 00:19:19,700
So this is all about BDD and
let's move on to the next slides.

299
00:19:20,200 --> 00:19:24,110
So ML models for BDD and
automated test case generation.

300
00:19:24,900 --> 00:19:31,200
So here you see so many, you
that are here OpenAI model and

301
00:19:31,570 --> 00:19:33,820
DeepMind alpha models and MLflow.

302
00:19:34,170 --> 00:19:40,880
So these models are going to be useful
for you to feed your existing, the files

303
00:19:41,040 --> 00:19:47,320
that you have that are like related to
BDD or any, anything related to CACD.

304
00:19:47,820 --> 00:19:52,830
So all of this information, you can
feed it to your locally deployed.

305
00:19:53,330 --> 00:20:00,040
LLMs and then you can use for generating
your own personalized company specific

306
00:20:00,080 --> 00:20:05,050
code and these are the capabilities
and you may also have challenges when

307
00:20:05,050 --> 00:20:06,480
you are deploying all of these things.

308
00:20:06,980 --> 00:20:12,470
So if you don't have enough data, these
LLMs also do hallucination and that's

309
00:20:12,480 --> 00:20:14,480
when you may not get the accurate results.

310
00:20:14,650 --> 00:20:17,070
So you need to be very careful with that.

311
00:20:17,720 --> 00:20:21,410
So something similar to Codex,
you also have other models you

312
00:20:21,410 --> 00:20:26,450
can leverage, and you can also see
some AIML tools for the scalability

313
00:20:26,450 --> 00:20:28,860
and accuracy in testing, right?

314
00:20:29,180 --> 00:20:33,840
So some of the tools you can see,
those are, these tools can be used

315
00:20:33,920 --> 00:20:37,990
for test case generation, code
generation, and you can also see

316
00:20:37,990 --> 00:20:42,580
which are the supported frameworks
and whether it is AI powered or not.

317
00:20:43,260 --> 00:20:46,710
So here OpenAI Codex, can
it generate the test cases?

318
00:20:46,830 --> 00:20:47,120
Yes.

319
00:20:47,120 --> 00:20:48,760
OpenAI Codex Can it generate the code?

320
00:20:48,900 --> 00:20:49,260
Yes.

321
00:20:50,060 --> 00:20:51,950
Which are the supported frameworks?

322
00:20:51,950 --> 00:20:54,700
Cucumber, Behave, SpecFlow,
and so many others.

323
00:20:55,200 --> 00:20:59,340
And similarly, you can
also see, the chat GPT.

324
00:20:59,840 --> 00:21:01,060
Again, these all are yes.

325
00:21:01,570 --> 00:21:04,550
It also supports Behave
and Cucumber, right?

326
00:21:04,550 --> 00:21:09,690
And Cucumber itself has some
kind of AI related features.

327
00:21:10,380 --> 00:21:13,550
but yeah, so it supports
Java, JavaScript, and Python.

328
00:21:14,050 --> 00:21:14,330
Okay.

329
00:21:14,670 --> 00:21:16,010
So now let's get on to the.

330
00:21:16,475 --> 00:21:18,845
How A and ML enhance the testing.

331
00:21:19,345 --> 00:21:24,905
So for example, you are using Selenium
and you are using a locator feature

332
00:21:24,945 --> 00:21:31,165
to identify an object by name search
or by ID search button in the next

333
00:21:31,165 --> 00:21:37,315
release, somebody changed the search
identity to find and find button.

334
00:21:37,815 --> 00:21:45,071
So in a typical test execution phase, when
the locator is not found, the test will

335
00:21:45,071 --> 00:21:48,685
fail and then it will not proceed further.

336
00:21:49,185 --> 00:21:55,445
But if you are implementing the same
thing with Helium, here you can see Helium

337
00:21:55,525 --> 00:22:00,135
WebDriver which works on top of Selenium
WebDriver if you use this dependency

338
00:22:00,965 --> 00:22:03,545
and if you run the tests, right?

339
00:22:04,025 --> 00:22:09,515
So even if it is changed to find,
search to find, the Helium will

340
00:22:09,575 --> 00:22:15,295
find out, scan all the identifiers
and see which is closest to name.

341
00:22:16,090 --> 00:22:20,950
It'll identify the locator and it'll make
the test to be successfully executed.

342
00:22:21,870 --> 00:22:27,280
And then it'll also give you a
provision to update back that specific

343
00:22:27,550 --> 00:22:32,870
identity in your test script, so you
don't need to manually maintain it.

344
00:22:33,400 --> 00:22:38,540
It'll automatically gives you an
option to update the locator from

345
00:22:38,540 --> 00:22:39,865
search to find in the script.

346
00:22:40,755 --> 00:22:43,455
And the next time it is going
to run without any issues.

347
00:22:43,585 --> 00:22:46,175
Even in the current test, it will
give you a warning saying that this

348
00:22:46,225 --> 00:22:47,525
is the object which is changed.

349
00:22:47,595 --> 00:22:50,085
Do you want to update
your automated scripts?

350
00:22:50,615 --> 00:22:51,785
So that's how it's going to work.

351
00:22:52,585 --> 00:22:54,645
So you can see the helium demo here.

352
00:22:55,405 --> 00:22:56,665
And you can also play around.

353
00:22:56,675 --> 00:23:01,275
One of my, ex colleague friend has
developed, some kind of, the, The example

354
00:23:01,325 --> 00:23:06,035
kind of thing here, you can download and
see experiment with the example here.

355
00:23:06,535 --> 00:23:11,045
So as I mentioned, Hellenium will detect
the failures automatically and updates

356
00:23:11,275 --> 00:23:13,835
the DOM object as a broken locator.

357
00:23:14,335 --> 00:23:21,155
So with this self healing, so it
is going to update the self, the

358
00:23:21,155 --> 00:23:25,445
Hellenium will update all the broken
links and if there are any kind of

359
00:23:25,495 --> 00:23:28,395
flow is broken, all of those things
will be automatically updated.

360
00:23:28,395 --> 00:23:28,485
Okay.

361
00:23:29,090 --> 00:23:34,070
So AI detection will optimize
your execution time and also

362
00:23:34,210 --> 00:23:35,170
it will save a lot of time.

363
00:23:35,900 --> 00:23:40,290
So as a result, you can see like 30
percent of reduction in testing time,

364
00:23:40,970 --> 00:23:43,030
45 percent is in the bug detection data.

365
00:23:43,800 --> 00:23:46,960
So real bugs can be detected
rather than just updating the,

366
00:23:46,970 --> 00:23:48,100
field names or whatever it is.

367
00:23:48,600 --> 00:23:52,960
So the question for you is how would
faster bug detection impacts your

368
00:23:52,960 --> 00:23:55,630
product definitely positive, right?

369
00:23:56,130 --> 00:23:57,490
So predictive analysis.

370
00:23:57,990 --> 00:23:59,800
So what is prediction?

371
00:23:59,810 --> 00:24:01,870
Like, how is it going to be in the future?

372
00:24:01,890 --> 00:24:03,240
So that's what the
prediction is all about.

373
00:24:03,820 --> 00:24:05,090
So how do you predict?

374
00:24:05,590 --> 00:24:09,300
Unless you give some kind of a data,
it is very hard to do the predictions.

375
00:24:10,050 --> 00:24:14,620
So whatever the metrics you may have,
you may need to feed it to the system and

376
00:24:14,620 --> 00:24:17,090
then play in the model and then predict.

377
00:24:17,930 --> 00:24:19,020
So I'm going to explain you.

378
00:24:19,115 --> 00:24:20,695
Step by step model here.

379
00:24:21,195 --> 00:24:25,375
So if you want to do any prediction,
first you need to do data collection.

380
00:24:25,915 --> 00:24:29,215
So for any testing, what
are the data items you have?

381
00:24:30,075 --> 00:24:34,435
One could be the defect reports,
code metrics, test metrics, release

382
00:24:34,435 --> 00:24:36,055
data, or developer activity.

383
00:24:36,555 --> 00:24:38,595
So then the data pre processing.

384
00:24:39,205 --> 00:24:42,065
So based on the data that you
collected, you need to pre process

385
00:24:42,105 --> 00:24:47,805
everything, meaning format and
make it like, unstructured data,

386
00:24:47,805 --> 00:24:49,175
make it like a structured one.

387
00:24:49,675 --> 00:24:54,215
Then exploratory data, do the
correlations, like whatever the data

388
00:24:54,265 --> 00:24:59,405
elements that you have, and make it like a
formatted data so that they are relatable.

389
00:24:59,905 --> 00:25:03,445
And feature selection, some of the
things you may need to really, feed

390
00:25:03,445 --> 00:25:05,215
it, like code complexity metrics.

391
00:25:05,305 --> 00:25:08,915
It's not related to testing, but
these are input data which will make

392
00:25:09,135 --> 00:25:10,795
the model to, predict way better.

393
00:25:11,395 --> 00:25:13,125
Change metrics that are
happening in the code.

394
00:25:13,870 --> 00:25:18,160
And then test coverage, what is the
coverage of test in respect to the

395
00:25:18,530 --> 00:25:22,630
code that is produced and developer
activity, like how many frequent

396
00:25:22,640 --> 00:25:27,360
check ins, frequent failures are
coming based on the code, right?

397
00:25:27,390 --> 00:25:31,780
So those are the metrics you may need
to do with the feature selection, right?

398
00:25:31,820 --> 00:25:33,250
Then you need to select the model.

399
00:25:33,750 --> 00:25:36,940
So this model is specific to the AIML.

400
00:25:36,950 --> 00:25:40,340
So you may need to find
out what kind of models are

401
00:25:41,070 --> 00:25:43,282
effective for this kind of data.

402
00:25:43,282 --> 00:25:44,370
Thanks a lot.

403
00:25:44,820 --> 00:25:48,200
So is it a classification model you
want to choose, a regression model

404
00:25:48,200 --> 00:25:51,870
you want to choose, or do you want to
use any deep learning models, right?

405
00:25:52,360 --> 00:25:55,030
And then model training and evaluation.

406
00:25:55,650 --> 00:26:00,660
So once you get all of this data, you
may need to feed to the, the model.

407
00:26:01,230 --> 00:26:04,540
So when you are feeding this data
to the model, you may need to

408
00:26:04,540 --> 00:26:08,880
split the data into two categories,
training data and test data.

409
00:26:08,880 --> 00:26:09,030
Thank you.

410
00:26:09,730 --> 00:26:12,510
So generally training data,
people will take about 80, 70

411
00:26:12,550 --> 00:26:14,860
to 80 percentage tested data.

412
00:26:14,870 --> 00:26:17,200
They'll take from, 20 to 30 percentage.

413
00:26:17,700 --> 00:26:18,610
Then you check.

414
00:26:19,355 --> 00:26:24,125
Whether the model is predicting properly
or not, you find out the score F1 score

415
00:26:24,125 --> 00:26:28,505
and different types of scores are there
to see whether the model is really

416
00:26:28,505 --> 00:26:33,665
predicting according to the test data or
not, then start doing the predictions.

417
00:26:34,015 --> 00:26:38,165
So once you have the train trained
model, once it is giving accurate

418
00:26:38,215 --> 00:26:41,965
results, start predicting like what
can go wrong based on the historical

419
00:26:41,965 --> 00:26:44,525
information and then collect the data.

420
00:26:44,985 --> 00:26:45,485
And then.

421
00:26:45,965 --> 00:26:50,975
improvise over the period of time based
on the data that is producing, whether

422
00:26:51,035 --> 00:26:52,795
the prediction is coming right or wrong.

423
00:26:52,805 --> 00:26:55,795
If you want to tune the model and
all that, you may need to do it.

424
00:26:56,135 --> 00:27:02,015
So all of this is related to training
the model based on, test artifacts.

425
00:27:02,515 --> 00:27:05,105
So ML in mobile app testing.

426
00:27:05,605 --> 00:27:07,935
So far I'm talking about
software application.

427
00:27:07,935 --> 00:27:10,675
I didn't specify about any
device, but here this is

428
00:27:10,675 --> 00:27:12,175
specific to mobile applications.

429
00:27:12,675 --> 00:27:17,035
So I'm working as a software testing
professional, our organization

430
00:27:17,035 --> 00:27:18,725
developing an e commerce application.

431
00:27:19,035 --> 00:27:21,955
We tested the application for
two years based on the data.

432
00:27:22,455 --> 00:27:25,005
Again, this is e commerce
related mobile app.

433
00:27:25,505 --> 00:27:28,825
So then how do you actually,
predict the defects, right?

434
00:27:29,155 --> 00:27:32,275
So here you have approach
to the defect prediction.

435
00:27:32,315 --> 00:27:34,875
So you feed your first,
you do the data collection.

436
00:27:35,435 --> 00:27:37,775
What are the factors
influencing the defects?

437
00:27:38,575 --> 00:27:39,685
Then predictive models.

438
00:27:39,805 --> 00:27:42,515
What are the models you
are actually using, right?

439
00:27:42,515 --> 00:27:45,285
What are the defect prediction
trends are coming up?

440
00:27:45,455 --> 00:27:49,105
So all of these things you are
actually, pre processing and some of

441
00:27:49,105 --> 00:27:50,575
them are your feeding and all that.

442
00:27:51,425 --> 00:27:55,405
And then visualization of the
predicts, how you want to, visualize

443
00:27:55,475 --> 00:27:58,885
the predictions, whether you want
to generate a bar graph or stack bar

444
00:27:58,945 --> 00:28:00,645
graph or pie chart or whatever it is.

445
00:28:01,335 --> 00:28:02,325
Once you have everything.

446
00:28:03,175 --> 00:28:06,115
So what are the tools you want
to use for the defect prediction?

447
00:28:06,615 --> 00:28:06,915
Okay.

448
00:28:07,410 --> 00:28:14,300
So now, once you capture everything, you
may need to get historical information

449
00:28:14,330 --> 00:28:16,500
versus what is predicted, right?

450
00:28:16,500 --> 00:28:18,980
So here I'm just describing
with some metrics.

451
00:28:19,870 --> 00:28:22,790
for example, you have for an e
commerce application, you have

452
00:28:23,370 --> 00:28:28,020
search, checkout, payment gateway,
recommendations and user profile.

453
00:28:28,060 --> 00:28:29,000
These are the modules.

454
00:28:29,500 --> 00:28:34,650
And the past defects are for search,
you have 120 checkout, 200 payments.

455
00:28:34,790 --> 00:28:41,930
150 recommendation 80 and user profile
50 and due to recent code changes.

456
00:28:42,880 --> 00:28:46,970
So what are the type of, what
is the level of code change?

457
00:28:47,100 --> 00:28:51,010
High code level changes, medium
level, high level, low and medium.

458
00:28:51,860 --> 00:28:55,640
So based on the past historical
information and based on the

459
00:28:55,640 --> 00:28:59,720
recent code changes and what is
the prediction, predicted number

460
00:28:59,720 --> 00:29:02,290
of defects here you see, right?

461
00:29:02,790 --> 00:29:03,700
This may be like.

462
00:29:04,255 --> 00:29:08,505
Fixed month's data or one year data
or five years data, you don't, but the

463
00:29:08,975 --> 00:29:10,725
past defects are definitely way lesser.

464
00:29:11,605 --> 00:29:13,865
and it could be like very latest data.

465
00:29:13,875 --> 00:29:16,615
That's why you're getting these
many number of defects it may come.

466
00:29:16,625 --> 00:29:18,485
So this is a prediction it is making.

467
00:29:19,065 --> 00:29:22,965
So the more data you have, the
accurate prediction you make it.

468
00:29:23,655 --> 00:29:24,105
Okay.

469
00:29:24,345 --> 00:29:28,165
But again, it is based on only historical
data, what you train, what you get.

470
00:29:28,665 --> 00:29:28,905
Okay.

471
00:29:29,275 --> 00:29:31,495
So this is all about
a predictive analysis.

472
00:29:31,995 --> 00:29:36,335
And let's see how A and ML
enhancing the testing here.

473
00:29:36,475 --> 00:29:38,575
here I'm also talking
about some of the tools.

474
00:29:39,395 --> 00:29:45,055
so some tools like this may be specific
to, specific predictions and all that.

475
00:29:45,695 --> 00:29:48,875
And, you also check when you're
choosing your tool, whether it

476
00:29:48,875 --> 00:29:50,515
can be integrated with CACD.

477
00:29:51,195 --> 00:29:55,595
And you also check whether this tool
has any data analysis capability or not.

478
00:29:56,165 --> 00:29:59,775
And see whether it can support AIML,
if it supports, whether it supports

479
00:29:59,775 --> 00:30:04,185
like strong medium kind of thing
and what kind of use cases it can.

480
00:30:04,675 --> 00:30:08,335
So these are the things you may need to,
understand before you, choosing your tool.

481
00:30:08,915 --> 00:30:14,555
So here you got tools like
Azure Machine Learning, IBM SPSS

482
00:30:14,555 --> 00:30:16,775
Modeler, SonarQube, Jenkins.

483
00:30:17,395 --> 00:30:21,225
So you see, which are the tools and
what kind of purpose or what kind

484
00:30:21,225 --> 00:30:25,665
of use cases they are catering to
and you can choose accordingly and

485
00:30:25,665 --> 00:30:27,665
then implement your predictions.

486
00:30:28,165 --> 00:30:32,265
So here, when you are talking about the
prediction, so you may need to capture

487
00:30:32,285 --> 00:30:38,185
the data, feed it, analyze and predict,
analyze and feed the data to the model.

488
00:30:38,995 --> 00:30:41,565
And then finally, you
can do the, predictions.

489
00:30:42,065 --> 00:30:45,145
OK, and then before they
actually occur in the.

490
00:30:45,735 --> 00:30:49,965
application under test, you may predict
and then take the course corrections.

491
00:30:50,465 --> 00:30:54,835
So again, coming to the same mobile app
testing, let's say if you're doing, if

492
00:30:55,025 --> 00:30:59,715
you're having a device fragmentation,
if it causes any inconsistent in user

493
00:30:59,715 --> 00:31:02,215
experience, how do you really solve it?

494
00:31:02,365 --> 00:31:05,685
Device fragmentation is the one
which is the biggest challenge.

495
00:31:05,765 --> 00:31:09,385
For example, if you are doing
a mobile testing, you got like

496
00:31:09,425 --> 00:31:11,685
various, sizes of the devices.

497
00:31:12,045 --> 00:31:13,895
If you go to Android in Samsung.

498
00:31:14,460 --> 00:31:15,730
Oh, it's like unimaginable.

499
00:31:16,490 --> 00:31:20,520
If you are testing that kind of a
device fragmentation for every device,

500
00:31:20,560 --> 00:31:24,600
whenever the locator changes, look at
locator position changes, it's very

501
00:31:24,600 --> 00:31:26,450
hard, like even if you do automation.

502
00:31:27,050 --> 00:31:33,080
So that's where you use the AAML device,
device compatible things where the AAML

503
00:31:33,120 --> 00:31:37,750
can automatically go detect the object
based on certain predefined conditions,

504
00:31:37,830 --> 00:31:40,055
and then it will optimize the solution.

505
00:31:40,885 --> 00:31:45,425
So in these kind of scenarios,
AIML definitely scales high.

506
00:31:46,045 --> 00:31:50,835
If you really look at it, the results
have shown that more than 50 percent

507
00:31:50,835 --> 00:31:55,245
of reduction in app crashes, 60 percent
increase in device compatibility.

508
00:31:55,745 --> 00:31:59,385
Okay, so this is the kind of
scaling you can see with the AIML,

509
00:31:59,695 --> 00:32:01,885
especially in the mobile app world.

510
00:32:02,385 --> 00:32:05,545
The question for you is, do
you face challenges testing

511
00:32:05,545 --> 00:32:06,945
across multiple devices?

512
00:32:07,445 --> 00:32:09,695
So mobile testers can
answer that question.

513
00:32:10,255 --> 00:32:15,935
So the metrics that matter, speed
coverage and accuracy a reduces the test

514
00:32:15,935 --> 00:32:21,925
execution time by up to 70 percentage,
and coverage expands by 60 percentage,

515
00:32:22,575 --> 00:32:25,065
and accuracy improves by 40 percentage.

516
00:32:25,975 --> 00:32:30,295
So this is the kind of, historical data
that is being captured from charge GPT.

517
00:32:31,065 --> 00:32:36,025
So you can always go take it out, if you
start implementing you, whether you may

518
00:32:36,025 --> 00:32:37,885
see this kind of accuracy and all that.

519
00:32:38,440 --> 00:32:41,530
That purely depends on what kind
of data that you provided to your

520
00:32:41,530 --> 00:32:46,440
AI and ML and how you trained
is also very important, right?

521
00:32:46,940 --> 00:32:49,180
Tools and technologies
in AI and ML testing.

522
00:32:49,680 --> 00:32:53,520
So the popular tools are
Selenium with Helium, Test.

523
00:32:53,520 --> 00:32:56,050
AI, AppliTool, Mable.

524
00:32:56,070 --> 00:32:58,370
These are some kind of, UI specific tools.

525
00:32:59,180 --> 00:33:02,980
And technologies are like
natural language processing, NLP.

526
00:33:03,480 --> 00:33:05,750
Predictive analytics and computer vision.

527
00:33:05,750 --> 00:33:09,770
So these are the technology you can
implement and see how those are useful

528
00:33:09,770 --> 00:33:11,280
in your regular day to day testing.

529
00:33:12,120 --> 00:33:16,080
The question for you is which AI tool
would you like to explore further?

530
00:33:16,580 --> 00:33:20,960
So if you are going with open source
Selenium, I would recommend a couple of

531
00:33:20,960 --> 00:33:22,490
other commercial tools also there here.

532
00:33:22,990 --> 00:33:25,050
Implementing AI or ML in QA.

533
00:33:25,970 --> 00:33:29,170
So I would divide this implementing
AI or ML into four steps.

534
00:33:29,860 --> 00:33:32,810
Step one, identify
repetitive testing tasks.

535
00:33:33,310 --> 00:33:37,700
So generally you do in automation, even
in the AIML, you can do the same thing.

536
00:33:38,270 --> 00:33:41,210
Choose the suitable AIML
testing tool, right?

537
00:33:41,290 --> 00:33:42,790
And then start the pilot project.

538
00:33:43,290 --> 00:33:44,800
Don't do everything at one go.

539
00:33:45,590 --> 00:33:48,350
Scale AI integration across workflows.

540
00:33:49,220 --> 00:33:54,480
And see where and all you can actually,
start expanding your AI integration.

541
00:33:54,980 --> 00:33:59,640
The question for you is, what's the first
step your team can take toward AI testing?

542
00:34:00,140 --> 00:34:04,420
So it is still in the beginning phase,
but see where and how you want to

543
00:34:04,440 --> 00:34:06,750
take your first step in AI testing.

544
00:34:07,250 --> 00:34:10,260
Challenges in adopting AI ML for testing.

545
00:34:11,640 --> 00:34:16,850
because AI ML is not 100 percent
there yet, but still, it is evolving.

546
00:34:17,510 --> 00:34:20,470
it, the first thing is the
lack of skill resources.

547
00:34:20,955 --> 00:34:23,915
Especially in testing for AIML.

548
00:34:24,655 --> 00:34:28,835
So a person needs to know a little bit
of data science, a little bit of machine

549
00:34:28,835 --> 00:34:31,685
learning algorithms, AI model development.

550
00:34:32,485 --> 00:34:38,215
So with all of this, the person needs to
have software testing knowledge as well.

551
00:34:39,035 --> 00:34:44,305
So it is a lack of skills at this
moment, but a lot of people are picking

552
00:34:44,325 --> 00:34:46,025
up and, eventually they'll be there.

553
00:34:46,525 --> 00:34:48,535
So again, AIML is not.

554
00:34:49,320 --> 00:34:51,360
Like anybody can go and then implement it.

555
00:34:51,370 --> 00:34:53,580
It also requires like initial costs.

556
00:34:54,080 --> 00:34:59,170
so for example, if you may need to,
get a hardware where the AI, the

557
00:35:00,050 --> 00:35:03,820
machine learning algorithms need
to process where it needs a lot of

558
00:35:03,850 --> 00:35:05,640
GPUs and they are really expensive.

559
00:35:05,740 --> 00:35:08,860
and sometimes you may need to
pay for the models if you are

560
00:35:08,930 --> 00:35:11,020
using any paid models, right?

561
00:35:11,050 --> 00:35:13,000
And also you have data dependency.

562
00:35:13,500 --> 00:35:17,950
So the data, do you have any
historical data to really feed it to?

563
00:35:18,445 --> 00:35:23,485
You need to get quality data and then
you need to data massage to fit to

564
00:35:23,485 --> 00:35:25,915
the AI model and change management.

565
00:35:26,665 --> 00:35:27,935
So are you ready?

566
00:35:28,095 --> 00:35:30,005
Is your team ready to change?

567
00:35:30,485 --> 00:35:33,065
And which needs learning
curve and all that.

568
00:35:33,725 --> 00:35:38,355
So that's another problem and
explainability and trust in AI.

569
00:35:39,265 --> 00:35:42,715
So yeah, if you don't give the
right amount of data, as I said,

570
00:35:42,725 --> 00:35:46,910
it will hallucinate and may
give produce the wrong results.

571
00:35:47,530 --> 00:35:51,540
So that's where you don't know
how this, specific, hallucination

572
00:35:51,540 --> 00:35:55,960
came into the documentation or
a test of the result, right?

573
00:35:55,960 --> 00:35:58,840
So that's where, you have to
be extremely careful, right?

574
00:35:59,570 --> 00:36:04,400
So the question for you is what
challenges could your team face when

575
00:36:04,470 --> 00:36:09,040
adopting AI in testing, if some of
you already implemented, I would

576
00:36:09,040 --> 00:36:14,290
like to hear from you the future of
QA with AI ML autonomous testing,

577
00:36:15,120 --> 00:36:16,840
AI will handle testing end to end.

578
00:36:17,050 --> 00:36:21,170
without you sitting there, without
you correcting the test cases, without

579
00:36:21,180 --> 00:36:25,670
you correcting any kind of, changes
in your, the links or buttons of

580
00:36:25,720 --> 00:36:27,880
the properties or whatever, right?

581
00:36:28,010 --> 00:36:32,380
So how can you achieve the autonomous
testing and real time defect prediction?

582
00:36:33,150 --> 00:36:38,890
So as the test is running it, but
what it can foresee, Hey, this

583
00:36:38,900 --> 00:36:40,470
feature is completely changed.

584
00:36:41,130 --> 00:36:46,610
I may foresee another 20 tests failing
before it reaches to the 20th test itself.

585
00:36:46,610 --> 00:36:50,250
Because of the dependency and its
learning algorithms, continuous

586
00:36:50,250 --> 00:36:53,420
learning, AI adapts to new technology.

587
00:36:53,420 --> 00:36:58,520
So it also actually learns from the
current data, and then it'll try to train

588
00:36:58,730 --> 00:37:01,480
itself and then becomes more robust.

589
00:37:01,980 --> 00:37:05,580
So the question for you is, how do you
envision the future of software testing

590
00:37:06,080 --> 00:37:11,520
key takeaways, air ml boost testing,
speed, accuracy, and scalability.

591
00:37:12,020 --> 00:37:16,990
If you do it in the right way, I want,
that is the kind of a prerequisite.

592
00:37:17,500 --> 00:37:21,020
Real results, proven case studies
show measurable improvements.

593
00:37:21,770 --> 00:37:26,380
Again, the feeder data and the
AI ML model is very important.

594
00:37:26,580 --> 00:37:26,930
Yes.

595
00:37:27,120 --> 00:37:29,740
Proven case studies show there
are definitely improvements.

596
00:37:30,580 --> 00:37:31,210
Adoption.

597
00:37:31,710 --> 00:37:35,465
Don't do everything in the beginning
on the step one, it's a start small

598
00:37:36,375 --> 00:37:38,005
and slowly scale with the confidence.

599
00:37:38,505 --> 00:37:39,445
The question for you is.

600
00:37:40,115 --> 00:37:42,925
What key insights would you
apply to your QA process?

601
00:37:43,425 --> 00:37:48,445
So I, when I prepared this material, I
also, gone through some of the, the case

602
00:37:48,455 --> 00:37:50,605
studies and some of the, the papers.

603
00:37:50,955 --> 00:37:54,785
So if you have any questions, if you
want to further learn, you can feel

604
00:37:54,785 --> 00:37:58,505
free to use these acknowledgements
and the documents or write papers.

605
00:37:59,005 --> 00:38:02,625
And, so this is almost the
closing of the session.

606
00:38:02,665 --> 00:38:03,735
If you have any questions.

607
00:38:04,295 --> 00:38:09,035
feel free to reach me with my email or
LinkedIn profile, and this is my website.

608
00:38:09,665 --> 00:38:14,715
The question for you is, what would you
like to explore more in AI Driven QA?

609
00:38:15,215 --> 00:38:15,945
Thank you guys.

