1
00:00:00,500 --> 00:00:01,400
Hey everyone.

2
00:00:02,030 --> 00:00:03,890
Thanks so much for joining today.

3
00:00:04,390 --> 00:00:09,370
Before we go further, a little
bit about me, I am Dennis Tomer

4
00:00:09,670 --> 00:00:12,060
de, and welcome to my talk.

5
00:00:13,020 --> 00:00:16,530
And my talk is dashboards
are not dramas anymore.

6
00:00:17,250 --> 00:00:18,270
So let's start.

7
00:00:19,169 --> 00:00:23,490
Have you ever been right in the middle
of debugging a critical production issue

8
00:00:24,330 --> 00:00:26,265
and when suddenly you get a message?

9
00:00:26,805 --> 00:00:33,045
From someone in finance saying, Hey,
our cloud bill just increased by $5,000.

10
00:00:33,885 --> 00:00:34,665
What happened?

11
00:00:35,165 --> 00:00:38,735
Yeah, that syncing feeling
isn't pleasant, right?

12
00:00:39,515 --> 00:00:42,995
All of a sudden you are not
just trying to fix the problem.

13
00:00:43,505 --> 00:00:48,515
You are also stressed about how much
monitoring tools you are using might

14
00:00:48,515 --> 00:00:50,464
be cost while you are solving it.

15
00:00:50,964 --> 00:00:54,565
Now in theory, monitoring our
system should be straightforward.

16
00:00:55,464 --> 00:01:00,775
Ideally, it'll give us clear visibility
to catch issues before users do

17
00:01:01,734 --> 00:01:07,615
help us quickly develop problems
when they occur, give us insight

18
00:01:07,615 --> 00:01:13,195
into our system performance, and
also help us plan capacity needs,

19
00:01:13,854 --> 00:01:18,595
and sometimes source stakeholders
that everything's running smoothly.

20
00:01:19,389 --> 00:01:21,130
Sound reasonable, doesn't it?

21
00:01:21,639 --> 00:01:25,570
But the reality in most cloud
environment is quite different.

22
00:01:26,070 --> 00:01:32,780
We often end up in what I called the
monitoring fear cycle, as you can see in

23
00:01:32,780 --> 00:01:38,495
this slide, which looks something like
we deploy a new service and set up basic

24
00:01:38,590 --> 00:01:42,550
monitoring, then an incident happened.

25
00:01:43,345 --> 00:01:48,805
When we realize our visibility
isn't enough, so we add more

26
00:01:48,805 --> 00:01:54,715
metrics, logs, tracing, but then
cloud bill spike unexpectedly.

27
00:01:55,215 --> 00:02:00,375
So someone from finance
team ask us to cut costs.

28
00:02:01,005 --> 00:02:03,075
So we scale back monitoring.

29
00:02:03,575 --> 00:02:09,035
But again, another incident happened
and be back to the Esquire one.

30
00:02:09,470 --> 00:02:13,680
This cycle repeats again
and this in justly.

31
00:02:14,180 --> 00:02:15,710
I personally seen this happen.

32
00:02:16,340 --> 00:02:22,130
A team I work with built great dashboards
for their service, the tracking

33
00:02:22,220 --> 00:02:27,050
everything from response time and
error rates to database transformation.

34
00:02:27,550 --> 00:02:31,765
But as their service grew from
10 to 50, their monitoring

35
00:02:31,765 --> 00:02:33,285
cost increased dramatically.

36
00:02:34,225 --> 00:02:37,465
Eventually they had to delete
many dashboards and sample their

37
00:02:37,465 --> 00:02:40,855
metrics at only 10% to manage costs.

38
00:02:41,355 --> 00:02:46,635
Yeah, so there are some
points of practical impact.

39
00:02:47,595 --> 00:02:52,565
First one is self sensor engineering
don't create the dashboards they

40
00:02:52,565 --> 00:02:55,895
need because they're afraid of costs.

41
00:02:56,735 --> 00:02:59,285
Second one is delayed detentions.

42
00:02:59,785 --> 00:03:04,945
Go unnoticed longer because we are
not collecting the right data we want.

43
00:03:05,905 --> 00:03:07,675
Third one is blind debugging.

44
00:03:08,175 --> 00:03:14,655
Sometime when problem occur, we lack the
visibility to solve the them quickly.

45
00:03:15,645 --> 00:03:17,175
Fourth one, crisis monitoring.

46
00:03:18,045 --> 00:03:24,075
We only turn on the full monitoring
during emergencies, which is exactly

47
00:03:24,435 --> 00:03:26,805
when we don't need extra stress.

48
00:03:27,510 --> 00:03:29,040
Fifth one is knowledge gap.

49
00:03:29,820 --> 00:03:34,230
New team member never learned to
use observability tool because

50
00:03:34,290 --> 00:03:36,420
it seems as a scare resources.

51
00:03:37,200 --> 00:03:41,610
Let me show you how this play out
in a typical incident response.

52
00:03:42,110 --> 00:03:46,580
For example, consider how this
play out in a typical incident.

53
00:03:47,080 --> 00:03:52,300
As you can see in this slide at
10:00 AM users report slowness.

54
00:03:52,855 --> 00:03:54,415
But there are no early volume.

55
00:03:55,345 --> 00:04:00,775
By 10 15, the team start looking at
basic metrics, but they have no idea,

56
00:04:01,275 --> 00:04:05,835
and then they request permission to
enable detail details monitoring,

57
00:04:06,405 --> 00:04:09,495
which only happen at after 30 minutes.

58
00:04:10,395 --> 00:04:14,865
After waiting another 30 minutes
for data, they finally pin pinpoint

59
00:04:14,925 --> 00:04:21,405
the database bottleneck at 11:15
AM So resolve the issue by.

60
00:04:21,840 --> 00:04:26,860
After 15 minute, but the next
day monitoring is scaled back

61
00:04:26,860 --> 00:04:32,290
down again to save cost, like
nearly two hours of impact.

62
00:04:32,380 --> 00:04:34,870
Mostly just wasting for visibility.

63
00:04:35,800 --> 00:04:40,320
It's not just incident every day
development suffer to, I have

64
00:04:40,320 --> 00:04:45,120
seen many developers avoid adding
essential custom metrics because

65
00:04:45,150 --> 00:04:47,370
it, its needs management approvals.

66
00:04:47,870 --> 00:04:53,039
Team often settle for generic
dashboards that don't match their needs.

67
00:04:53,609 --> 00:04:58,950
Historical data is quickly deleted, making
them exporting trends Im impossible.

68
00:04:59,880 --> 00:05:05,039
Logging levels are set so high so they
miss valuable debugging information.

69
00:05:05,070 --> 00:05:08,249
Also, all because of cost concern.

70
00:05:08,580 --> 00:05:09,359
That's not right.

71
00:05:09,859 --> 00:05:13,030
I also once was a senior engineer.

72
00:05:13,270 --> 00:05:18,729
Spent three hours optimizing
monitoring just to save $200 per month.

73
00:05:19,419 --> 00:05:25,780
A clear misuse of valuable time and worst
off, all these costs are unpredictable.

74
00:05:26,280 --> 00:05:30,299
Sometime it's 200, sometime
is 300, sometime's 500.

75
00:05:31,109 --> 00:05:32,760
These are unpredictables.

76
00:05:33,405 --> 00:05:36,224
Traffic spikes or bug unexpectedly.

77
00:05:36,224 --> 00:05:38,924
Inhale your monitoring bills overnight.

78
00:05:39,424 --> 00:05:43,254
So exactly what, why, exactly.

79
00:05:43,314 --> 00:05:45,294
Why is monitoring so expensive?

80
00:05:45,774 --> 00:05:51,144
It boils down to how cloud and platform
observability typically is worse.

81
00:05:51,864 --> 00:05:57,114
First agent, collect your data
from servers, then send it off to

82
00:05:57,114 --> 00:05:58,824
the central collection services.

83
00:05:59,324 --> 00:06:04,064
Data is stored, indexed, and run
curries, though the dashboard alert,

84
00:06:04,564 --> 00:06:10,384
this is, and so this architecture
create four separate cost drivers.

85
00:06:11,074 --> 00:06:12,844
First one is data transfer.

86
00:06:13,804 --> 00:06:18,364
Moving data from your instance to
monitoring service, which is cost money,

87
00:06:18,784 --> 00:06:23,584
especially across different regions,
all to the different third party tools.

88
00:06:24,094 --> 00:06:26,854
Second one is ingest processing.

89
00:06:27,784 --> 00:06:32,224
Passing, transforming and
indexing monitoring data,

90
00:06:32,224 --> 00:06:34,294
required more compute resources.

91
00:06:34,924 --> 00:06:36,874
And third one is storage.

92
00:06:37,564 --> 00:06:41,704
Keeping your data available for queries,
especially at higher resolutions.

93
00:06:42,334 --> 00:06:44,134
And last one is query cost.

94
00:06:44,704 --> 00:06:48,514
Sometime providers even charge
for your own, accessing your

95
00:06:48,514 --> 00:06:51,124
own data, which is not correct.

96
00:06:51,624 --> 00:06:56,544
This cost structure for us to build
compromised monitoring system.

97
00:06:57,414 --> 00:07:01,674
As you can see in this slide, how much
code we have to write to get some little

98
00:07:01,674 --> 00:07:05,694
bit idea and also how much it is complex.

99
00:07:06,144 --> 00:07:09,534
And another one you can see
is this setup, alerting.

100
00:07:10,134 --> 00:07:16,074
This is also too much complex to
just set up an alert, a simple task.

101
00:07:16,574 --> 00:07:17,924
So what's the alternative?

102
00:07:18,424 --> 00:07:22,054
The key is making observability
a built-in feature for your in

103
00:07:22,414 --> 00:07:25,234
infrastructure, but not expensive.

104
00:07:25,234 --> 00:07:27,724
Add-on in a fixed cloud model.

105
00:07:28,594 --> 00:07:33,454
Fixed first cloud model monitoring
become part of the platform mat

106
00:07:33,874 --> 00:07:38,524
logs and T traces are collected
automatically without additional charge.

107
00:07:39,024 --> 00:07:44,934
There are no data transfer fees, retention
periods are predictable and included and

108
00:07:44,934 --> 00:07:46,974
curing your data doesn't extra charge.

109
00:07:47,544 --> 00:07:48,594
So that's the good way.

110
00:07:49,134 --> 00:07:49,434
Yeah.

111
00:07:49,934 --> 00:07:54,739
So let me show you what this
look like with Seamless, a

112
00:07:54,739 --> 00:07:56,390
fixed cost cloud platform.

113
00:07:56,989 --> 00:08:00,424
I have working with, as you
can see in the dashboard slide,

114
00:08:01,414 --> 00:08:03,214
which you create a server.

115
00:08:03,650 --> 00:08:08,989
Dashboards covering CPU memories,
disc io and network performance

116
00:08:08,989 --> 00:08:14,780
and more With thir 30 days of high
resolution historical data, there are

117
00:08:14,780 --> 00:08:19,819
no setup, no additional cost, and no
complicated pricing that look good.

118
00:08:20,179 --> 00:08:20,510
Yeah.

119
00:08:21,079 --> 00:08:26,234
Also look logs work similarly, again,
without not worrying about the charges.

120
00:08:26,734 --> 00:08:30,305
Here's the difference between
make in the real world incident

121
00:08:30,305 --> 00:08:35,194
management at 10 and 10:00 AM
monitoring catches issu immediately.

122
00:08:35,555 --> 00:08:38,585
Then firing an early alert within minutes.

123
00:08:38,645 --> 00:08:43,234
Detailed metrics are accessible and
allow team to quickly identify a

124
00:08:43,234 --> 00:08:48,095
database connection issue by after
10 minutes, the issue is fully

125
00:08:48,095 --> 00:08:50,645
resolved immediately after that Word.

126
00:08:51,170 --> 00:08:55,664
Afterward the team easily create
an additional data board to

127
00:08:55,664 --> 00:08:57,254
track this scenario better.

128
00:08:58,124 --> 00:08:59,504
All without cost worries.

129
00:09:00,194 --> 00:09:05,234
This means the issue is resolved in
25 minutes instead of nearly two hours

130
00:09:05,564 --> 00:09:10,034
waiting for, to get some ideas reducing.

131
00:09:10,034 --> 00:09:14,764
And this co this will also reduce
stress and improving outcomes.

132
00:09:15,544 --> 00:09:18,674
Ultimately observability should
tend to be something we fear.

133
00:09:19,214 --> 00:09:21,554
It should be something
we rely on every day.

134
00:09:22,184 --> 00:09:25,804
Whether you are exploring, like
platform or rethinking your current

135
00:09:25,804 --> 00:09:27,934
setup, the goal should be clear.

136
00:09:28,654 --> 00:09:32,854
After all, you can't fix what you
can't see, and you'll never look

137
00:09:32,944 --> 00:09:34,564
if you are scared of the bills.

138
00:09:35,524 --> 00:09:37,194
So thanks so much.

139
00:09:37,809 --> 00:09:42,549
Thank you so much as this and this is
a prerecorded session, so if you have

140
00:09:42,549 --> 00:09:47,409
any questions or any doubt regarding
this talk or want to chat about new

141
00:09:47,409 --> 00:09:52,569
tech or developer problems, feel free
to ping me up on the LinkedIn or tutor

142
00:09:53,229 --> 00:09:56,109
and these are my handles, so bye-bye.

143
00:09:56,229 --> 00:09:57,429
Thank you everyone.

