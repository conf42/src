1
00:00:00,150 --> 00:00:00,830
Hello, everyone.

2
00:00:01,190 --> 00:00:06,000
I'm Modi and I'm excited to talk
with you today about how we can

3
00:00:06,030 --> 00:00:11,969
improve AI and network security using
technologies like Kafka, secure proxies.

4
00:00:12,475 --> 00:00:14,105
and modern software architecture.

5
00:00:14,925 --> 00:00:21,585
As we depend more on data and connected
systems, making sure they are secure and

6
00:00:21,595 --> 00:00:24,055
reliable becomes even more important.

7
00:00:24,984 --> 00:00:30,945
Today I'll go over some of the topics
here and we'll understand more about

8
00:00:30,945 --> 00:00:33,535
AI and Kafka's presence in the AI.

9
00:00:34,035 --> 00:00:37,415
So introduction to AI and Kafka
for real time data processing.

10
00:00:37,970 --> 00:00:43,050
And we'll go through the key features
of Apache Kafka for AI workloads, the

11
00:00:43,050 --> 00:00:49,410
real time AI use case powered by Kafka,
securing AI data pipelines with secure

12
00:00:49,420 --> 00:00:56,349
proxies, and how to integrate AI workloads
with Kafka Connect, and how to implement

13
00:00:56,569 --> 00:00:58,630
zero trust architecture with Kafka.

14
00:00:59,130 --> 00:01:03,530
Before going this, we'll understand
what is zero trust architecture.

15
00:01:04,385 --> 00:01:09,565
And a case study on AI and Kafka in
action and we'll go through some best

16
00:01:09,565 --> 00:01:14,945
practices, industry best practices for
building secure, scalable AI pipelines.

17
00:01:15,445 --> 00:01:16,505
Okay, let's start.

18
00:01:16,685 --> 00:01:22,585
So and again by the end of this
talk, you'll see how these tools

19
00:01:22,645 --> 00:01:28,525
work together to create a strong
foundation for AI and secure networking.

20
00:01:29,025 --> 00:01:31,774
Okay, let's get started.

21
00:01:32,274 --> 00:01:38,274
So the growing need for real time AI So
as technology advances, there is a rising

22
00:01:38,284 --> 00:01:40,764
need for AI that operates in real time.

23
00:01:41,504 --> 00:01:46,044
If you notice, we are no longer
just storing and processing

24
00:01:46,044 --> 00:01:47,484
data in large batches.

25
00:01:47,984 --> 00:01:53,759
Now, industries like finance, healthcare,
manufacturing, and e commerce rely on

26
00:01:53,809 --> 00:02:00,849
AI to make instant decisions, anomaly
detection, and natural processing

27
00:02:00,849 --> 00:02:03,289
language based on the live data.

28
00:02:04,059 --> 00:02:08,929
So think of fraud detection banking
where AI systems need to flag unusual

29
00:02:08,929 --> 00:02:13,629
transactions as they happen or in
a healthcare where real time AI

30
00:02:13,779 --> 00:02:18,429
can support doctors in making quick
informed decisions during surgeries.

31
00:02:18,929 --> 00:02:24,104
When it comes to Kafka role, Apache
Kafka is a powerful tool for handling

32
00:02:24,104 --> 00:02:25,884
high speed data streams in real time.

33
00:02:26,384 --> 00:02:32,964
Essentially, it acts as a central hub
that gathers, stores, and distributes data

34
00:02:33,134 --> 00:02:37,614
continuously with high throughput, which
is crucial for real time AI applications.

35
00:02:38,114 --> 00:02:43,954
In a real time AI, data needs to move
from multiple sources, sensors, using

36
00:02:44,014 --> 00:02:46,624
user interactions, and internal systems.

37
00:02:46,695 --> 00:02:49,404
to the AI models instantly.

38
00:02:49,904 --> 00:02:54,014
Kafka allows this by processing
data as it's created,

39
00:02:54,854 --> 00:02:57,324
enabling real time decisions.

40
00:02:57,964 --> 00:03:04,334
For example, in an e commerce application,
Kafka can track every click and

41
00:03:04,754 --> 00:03:08,204
purchase in real time, so AI models can
instantly recommend real time decisions.

42
00:03:08,744 --> 00:03:15,354
products or spot potential fraud and
Kafka also supports secure and reliable

43
00:03:15,584 --> 00:03:22,174
data handling with features like
data replication and fault tolerance.

44
00:03:22,814 --> 00:03:27,394
Kafka makes sure data flows
smoothly, even when issues arise.

45
00:03:27,894 --> 00:03:31,034
And, there are like challenges in
the traditional systems, right?

46
00:03:31,994 --> 00:03:36,734
So traditional systems are often
built around batch processing,

47
00:03:37,314 --> 00:03:41,814
where data is collected, stored,
and then processed at set intervals.

48
00:03:42,724 --> 00:03:47,594
So this approach for certain use
cases But it's a, yeah, it's good

49
00:03:47,614 --> 00:03:52,194
for certain use cases, but it's a
big limitation for the applications

50
00:03:52,244 --> 00:03:55,814
that need real time insights, right?

51
00:03:56,194 --> 00:04:02,019
for example, in fields like finance and
healthcare, Delays in data processing

52
00:04:02,279 --> 00:04:08,029
can mean missed opportunities or
even risk to security and safety.

53
00:04:08,529 --> 00:04:11,349
Another major challenge
is scalability, right?

54
00:04:11,809 --> 00:04:16,889
So traditional systems can struggle
to keep up as data volumes increase.

55
00:04:17,544 --> 00:04:22,144
often becoming slow and requiring
costly hardware upgrades.

56
00:04:22,704 --> 00:04:28,414
This makes it hard to scale applications
that rely on constant data flow, like

57
00:04:28,454 --> 00:04:31,194
live monitoring or, predictive analysis.

58
00:04:31,844 --> 00:04:35,764
Kafka addresses these challenges
by using a distributed and

59
00:04:35,764 --> 00:04:39,894
scalable architecture that allows
for real time event processing.

60
00:04:40,394 --> 00:04:45,964
talk about the key features of
Apache Kafka for AI workloads.

61
00:04:46,464 --> 00:04:50,294
Apache Kafka is an ideal
choice for AI applications.

62
00:04:50,794 --> 00:04:55,634
To support real time AI and advanced
analytics, We need tools that can

63
00:04:55,674 --> 00:05:02,864
process and analyze data as it
flows and without any delays, right?

64
00:05:03,464 --> 00:05:08,554
So that's where Kafka Stream
Processing API and ksql come into play.

65
00:05:09,054 --> 00:05:14,854
Both are designed to handle real time data
streams effectively, enabling instant data

66
00:05:15,104 --> 00:05:17,284
transformation, filtering, and analysis.

67
00:05:17,784 --> 00:05:21,204
So Stream Processing API and ksql.

68
00:05:21,604 --> 00:05:22,334
So let's.

69
00:05:22,849 --> 00:05:24,419
discuss more about this.

70
00:05:25,199 --> 00:05:32,009
So this feature Allows developers to
create sophisticated data pipelines

71
00:05:32,019 --> 00:05:38,969
for AI tasks such as a real time
sentimental analysis anomaly detection and

72
00:05:39,029 --> 00:05:43,929
predictive maintenance So when it comes
to stream processing API, particularly,

73
00:05:44,569 --> 00:05:50,959
and this is a powerful API within
Kafka that allows us to build custom

74
00:05:50,989 --> 00:05:53,629
applications that process data streams.

75
00:05:54,129 --> 00:05:58,809
With this API, we can perform
complex operations like joining

76
00:05:58,829 --> 00:06:04,639
streams, aggregating data, or even
transforming messages as they're mixed.

77
00:06:05,139 --> 00:06:10,354
For example, in a real time fraud
detection system, The stream processing.

78
00:06:10,354 --> 00:06:16,294
A PA could be used to continuously
analyze transaction patterns and detect

79
00:06:16,324 --> 00:06:18,304
anomalies as soon as they're occur.

80
00:06:18,334 --> 00:06:19,084
That's pretty much it.

81
00:06:19,114 --> 00:06:20,074
Pretty important, right?

82
00:06:20,944 --> 00:06:21,364
yeah.

83
00:06:22,054 --> 00:06:26,689
When it comes to K sql, K sql, which is
a calf of query language, is a SQL like

84
00:06:26,869 --> 00:06:31,829
language, built for, Kafka that allows us
to write streaming queries on live data.

85
00:06:32,329 --> 00:06:34,099
Case QL makes it easier.

86
00:06:34,599 --> 00:06:40,679
To work, streaming data since we don't
have to write complex code Just like

87
00:06:40,809 --> 00:06:44,729
this straightforward sql commands
to filter transform or join data

88
00:06:45,289 --> 00:06:49,689
for instance If you wanted to filter
specific type of transactions in a

89
00:06:49,689 --> 00:06:55,219
financial application We could use
ksql to pull only the data we need in

90
00:06:55,229 --> 00:06:57,049
real time without heavy processing.

91
00:06:57,549 --> 00:07:04,669
So together The Stream Processing API and
ksql offers flexibility and simplicity

92
00:07:04,689 --> 00:07:06,429
for working with streaming data.

93
00:07:07,259 --> 00:07:13,569
They enable us to perform real time data
transformations and analyze directly

94
00:07:13,569 --> 00:07:15,849
on Kafka, which is essential for us.

95
00:07:16,169 --> 00:07:20,949
for supporting real time AI
applications that need, fast

96
00:07:21,009 --> 00:07:23,889
and fast accurate data insights.

97
00:07:24,389 --> 00:07:29,909
When it comes to integration with,
data systems, Kafka Connect is a tool

98
00:07:30,649 --> 00:07:36,239
that is a part of cap Kafka ecosystem,
which is pretty much designed to

99
00:07:36,249 --> 00:07:41,839
simplify and automate the process of
streamlining data between Kafka and

100
00:07:41,839 --> 00:07:46,359
other data systems, like simplifying
the data flow of AI applications.

101
00:07:46,909 --> 00:07:54,229
and, the big advantage of, using, the
Kafka's approach in AI is, so it gives

102
00:07:54,229 --> 00:07:56,499
you a high throughput and low latency.

103
00:07:57,089 --> 00:08:01,569
Like Kafka itself is designed to
handle large scale, data ingestion,

104
00:08:02,379 --> 00:08:04,269
like a millions of, messages.

105
00:08:04,999 --> 00:08:06,029
And it'll process.

106
00:08:06,529 --> 00:08:12,659
in a lightning time and slow latency
enabling its enables real time processing

107
00:08:12,879 --> 00:08:15,460
latencies within below 10 milliseconds.

108
00:08:16,240 --> 00:08:18,860
So these are pretty good, the kafkas.

109
00:08:19,360 --> 00:08:23,160
Let's discuss about a real
time AI use case, Kafka.

110
00:08:23,710 --> 00:08:26,530
as we earlier discussed about
the anomaly detection, right?

111
00:08:26,550 --> 00:08:28,070
this time we'll go a little bit deeper.

112
00:08:28,570 --> 00:08:32,030
A little bit deeper about what
this anomaly detection is and how

113
00:08:32,030 --> 00:08:36,980
this will be useful for our end
to end, day to day lives by AI.

114
00:08:37,530 --> 00:08:42,080
anomaly detection is essential in
today's AI driven systems, especially

115
00:08:42,150 --> 00:08:48,150
for applications in security, finance,
and operations, where spotting

116
00:08:48,440 --> 00:08:51,404
unusual patterns is critical, right?

117
00:08:52,085 --> 00:08:56,575
Anomaly detection helps identify
unexpected or abnormal events in data.

118
00:08:57,075 --> 00:09:01,065
Think like unusual login items,
irregular financial transactions,

119
00:09:01,115 --> 00:09:02,674
or system performance issues.

120
00:09:02,675 --> 00:09:08,095
In a real time, AI, anomaly
detection takes on even greater

121
00:09:08,095 --> 00:09:13,335
importance because it allows
organizations to respond instantly.

122
00:09:13,835 --> 00:09:20,675
For example, in the cyber security,
detecting an anomaly might mean

123
00:09:21,275 --> 00:09:23,655
identifying a potential attack.

124
00:09:24,075 --> 00:09:30,165
As it's happening, allowing for immediate
action to mitigate threats or the

125
00:09:30,165 --> 00:09:35,925
financial services, real time anomaly
detection can help flag fraudulent

126
00:09:35,935 --> 00:09:39,025
transactions before they're processed.

127
00:09:39,525 --> 00:09:44,445
So one of the, the other, real
time use case Is, natural language

128
00:09:44,465 --> 00:09:47,405
processing, which is aka NLP.

129
00:09:47,905 --> 00:09:51,975
Kafka facilitates this, the
real time processing of language

130
00:09:52,005 --> 00:09:55,325
data for applications such as,
chatbots or voice assistants.

131
00:09:55,825 --> 00:09:57,955
on the social media platforms, right?

132
00:09:58,525 --> 00:10:03,205
So using this, natural language
processing, integrating this lab, having

133
00:10:03,205 --> 00:10:07,785
this natural language processing with
Kafka, it enables real time analysis

134
00:10:07,915 --> 00:10:10,055
and processing of text data streams.

135
00:10:10,765 --> 00:10:15,395
Open it's open up the possibilities for
applications like, sentiment analysis.

136
00:10:15,915 --> 00:10:19,755
Contact, content link, content
filterings, chatbots, and

137
00:10:19,765 --> 00:10:21,175
more in dynamic environments.

138
00:10:21,815 --> 00:10:27,295
By combining NLP models with Kafka's
powerful data streaming capabilities,

139
00:10:27,705 --> 00:10:33,885
organizations can create scalable
responsive systems that analyze test

140
00:10:33,965 --> 00:10:36,575
data as it flows through various sources.

141
00:10:37,075 --> 00:10:41,425
So the other, another important
thing is a predictive maintenance.

142
00:10:41,935 --> 00:10:47,795
So AI models leverages its real time
streaming capabilities to prevent when

143
00:10:47,795 --> 00:10:52,635
a failure occurs, thereby reducing
the downtime and maintenance cost.

144
00:10:53,135 --> 00:10:59,515
Decision Supporting Systems aka DSS
with Kafka, which enables organizations

145
00:11:00,175 --> 00:11:04,855
to make real time data driven
decisions by processing, Analyzing and

146
00:11:04,995 --> 00:11:11,465
integrating information from various
sources by utilizing Kafka's robust

147
00:11:11,465 --> 00:11:17,075
data streaming capabilities, decision
support systems can gather and process

148
00:11:17,075 --> 00:11:20,169
information in a real time that helps.

149
00:11:20,660 --> 00:11:25,010
in a critical decision making
across various domains like finance,

150
00:11:25,070 --> 00:11:28,920
healthcare, e commerce, and operations.

151
00:11:29,810 --> 00:11:35,290
for example, in a healthcare, real
time AI processing can provide

152
00:11:35,450 --> 00:11:42,310
doctors with insights based on the
patient data, assisting in diagnostic

153
00:11:42,330 --> 00:11:44,180
and treatment planning, right?

154
00:11:44,680 --> 00:11:47,210
this is very important, like
additional support systems.

155
00:11:47,945 --> 00:11:51,885
With Kafka, we can create
wonders using the help of AI.

156
00:11:52,385 --> 00:11:58,525
Let's talk about, the security, securing
AI data pipelines with secure proxies.

157
00:11:59,025 --> 00:12:04,115
securing AI data pipelines with secure
proxies is critical for, protecting

158
00:12:04,115 --> 00:12:08,645
sensitive information as it moves between
different components in a distributed

159
00:12:09,135 --> 00:12:10,255
real time processing environment.

160
00:12:10,755 --> 00:12:12,515
It acts as intermediaries.

161
00:12:13,015 --> 00:12:17,505
It acts as an intermediary that
enforces security policies, monitoring

162
00:12:17,565 --> 00:12:22,515
traffic, and masks underlying system
details, ensuring that AI data

163
00:12:22,515 --> 00:12:27,035
pipelines are robust against attacks,
unauthorized access, and data leaks.

164
00:12:27,535 --> 00:12:32,015
There are many examples of using secure
proxies for securing AI data pipelines.

165
00:12:32,515 --> 00:12:34,395
And we can discuss some of them here.

166
00:12:34,895 --> 00:12:37,935
For instance, like compliance
with data regulations.

167
00:12:38,915 --> 00:12:43,325
This helps organizations meet
their private, meet privacy laws.

168
00:12:44,055 --> 00:12:46,875
For example, GDPR, General
Data Privacy Regulation.

169
00:12:47,395 --> 00:12:54,055
And, CCPA California Consumer Privacy
Act, then ensuring the sensitivity,

170
00:12:54,115 --> 00:12:59,055
the sensitive data is not, is handled
securely throughout the pipeline.

171
00:12:59,555 --> 00:13:02,425
And one other example
is the risk mitigation.

172
00:13:02,925 --> 00:13:08,265
while incorporating secure proxies,
in a Kafka based CA system, it

173
00:13:08,385 --> 00:13:10,515
reduces the risk of data breaches.

174
00:13:11,015 --> 00:13:15,805
Nowadays, the big financial institutions
and, other companies, they're

175
00:13:16,075 --> 00:13:18,375
focusing main on the data breach.

176
00:13:18,585 --> 00:13:21,765
We have seen many instances,
the data got leaked.

177
00:13:22,265 --> 00:13:27,335
So considering that you using
Kafka, we can avoid the situation.

178
00:13:27,865 --> 00:13:29,305
performance considerations, right?

179
00:13:29,305 --> 00:13:33,555
When it comes to performance, Like
despite adding all these layers of

180
00:13:33,555 --> 00:13:39,495
security, secure proxies are optimized
to ensure that there is no significant

181
00:13:39,625 --> 00:13:41,595
impact on data processing latency.

182
00:13:42,095 --> 00:13:46,675
Let's talk about integrating AI
workloads with Kafka Connect.

183
00:13:47,175 --> 00:13:50,655
integrating AI workloads with
Kafka Connect creates a powerful

184
00:13:50,785 --> 00:13:56,075
scalable solution for, streaming
data into machine learning models

185
00:13:56,115 --> 00:13:57,555
and AI systems in real time.

186
00:13:58,405 --> 00:13:59,835
Kafka Connect as a.

187
00:14:00,400 --> 00:14:05,080
Character framework allows for seamless
data movement between Apache Kafka

188
00:14:05,080 --> 00:14:07,170
and other data systems like databases.

189
00:14:07,715 --> 00:14:10,005
file storage and cloud services.

190
00:14:10,985 --> 00:14:15,735
This integration enables AI
applications to leverage real time

191
00:14:15,735 --> 00:14:20,705
data flows, providing insights
and actions based on the latest

192
00:14:20,735 --> 00:14:23,325
data without manual data movement.

193
00:14:23,825 --> 00:14:28,535
So by scaling these AI pipelines
with Kafka Connect, we can

194
00:14:28,535 --> 00:14:34,645
achieve seamless AI pipelines,
sorry, seamless data integration.

195
00:14:35,235 --> 00:14:41,210
So it allows organizations to easily
connect AI workloads with external data

196
00:14:41,270 --> 00:14:47,750
systems, such as cloud data warehouses,
data lakes, and, on prem databases.

197
00:14:48,250 --> 00:14:52,280
and one, one other, thing using AI
pipelines with Kafka Connect we can

198
00:14:52,280 --> 00:14:54,440
achieve is the scaling improvements.

199
00:14:54,970 --> 00:14:59,730
Kafka Connect can deliver up to a 50
percent improvement in data scalability.

200
00:15:00,160 --> 00:15:04,290
and optimization, accommodating
growing data volumes, pre

201
00:15:04,290 --> 00:15:06,080
built and custom connectors.

202
00:15:06,240 --> 00:15:10,930
So we can utilize a wide range of pre
built connectors for a proper data sources

203
00:15:10,980 --> 00:15:16,900
or develop customer, custom connectors
tailored for our specific use case.

204
00:15:17,400 --> 00:15:23,520
one real world example is that, a retail
company integrated its machine learning

205
00:15:23,530 --> 00:15:26,120
models with Kafka Connect to enable.

206
00:15:26,660 --> 00:15:29,990
real time inventory management,
which leads to significant

207
00:15:30,490 --> 00:15:34,600
reductions in stockouts and their,
and the excessive inventory.

208
00:15:35,100 --> 00:15:40,300
Let's talk about implementing a
zero, trust architecture with Kafka.

209
00:15:41,040 --> 00:15:46,120
So implementing zero trust architecture
with Kafka is essential for securing,

210
00:15:46,220 --> 00:15:48,130
data flows in real time applications.

211
00:15:48,635 --> 00:15:50,295
and distributed systems.

212
00:15:51,245 --> 00:15:56,355
Zero trust assumes that every
user, device, and application

213
00:15:56,695 --> 00:16:00,675
inside or outside the organization
should not be trusted by default.

214
00:16:01,635 --> 00:16:08,255
So this approach enforces strict
identity verification and continuous

215
00:16:08,255 --> 00:16:13,005
validation, ensuring that data
integrity and privacy are maintained

216
00:16:13,005 --> 00:16:15,215
across Kafka based architectures.

217
00:16:15,715 --> 00:16:20,245
We can, enhance, security
with zero trust architecture.

218
00:16:20,465 --> 00:16:26,785
Let's talk about some key items, zero
trust security principles, primarily

219
00:16:27,295 --> 00:16:29,095
zero trust security principles.

220
00:16:29,595 --> 00:16:34,455
So employ a never trust
always verify approach.

221
00:16:34,515 --> 00:16:39,435
So this approach, where every data access
request is authenticated and encrypted.

222
00:16:39,435 --> 00:16:39,715
Okay.

223
00:16:40,390 --> 00:16:44,750
Like a continuous authentication, Kafka
integrates with zero trust frameworks

224
00:16:45,350 --> 00:16:50,020
to ensure the data is continuously
protected at every point in the pipeline.

225
00:16:50,520 --> 00:16:52,780
So middleman attacks, right?

226
00:16:52,880 --> 00:16:57,250
so enforcing by enforcing this
encryption and secure authentication

227
00:16:58,030 --> 00:17:02,830
protocols, we can help, preventing
the middle, middle man in the middle

228
00:17:02,830 --> 00:17:04,990
attacks and other security threats.

229
00:17:05,490 --> 00:17:10,130
Some of the, yep, some of the best
practices, for building, secure

230
00:17:10,160 --> 00:17:12,700
scalable AI pipelines are listed here.

231
00:17:13,565 --> 00:17:19,605
So this guy, we can have different
items listed here, which is

232
00:17:19,605 --> 00:17:21,275
like design recommendations.

233
00:17:21,835 --> 00:17:27,045
So using event driven and microservice
architecture to manage the complexities

234
00:17:27,045 --> 00:17:32,715
of real time data processing, security
considerations, incorporating,

235
00:17:32,845 --> 00:17:38,590
encryption, secure policies, and
zero trust principles to protect

236
00:17:38,690 --> 00:17:40,500
the data throughout the pipeline.

237
00:17:41,000 --> 00:17:44,620
And as we already discussed about
the performance optimization tips,

238
00:17:44,890 --> 00:17:49,560
so we can use, we can optimize the
Kafka configurations, such as, topic

239
00:17:49,910 --> 00:17:51,820
partitioning and replication factors.

240
00:17:52,165 --> 00:17:55,115
To make sure it has a high
throughput and low latency.

241
00:17:55,115 --> 00:17:59,895
That's pretty much important So when it
comes to monitoring and alerting by while

242
00:17:59,955 --> 00:18:04,095
setting up the continuous monitoring and
alerting for Pipelines performance and

243
00:18:04,095 --> 00:18:08,995
security event to detect and in response
to issues promptly So the moment when

244
00:18:09,065 --> 00:18:13,780
when we set this proper alerting in
case of any issues It will alert you

245
00:18:13,910 --> 00:18:16,630
on time and we can mitigate the risk.

246
00:18:16,840 --> 00:18:17,520
So

247
00:18:18,020 --> 00:18:23,650
on to conclude this, so integrating
Apache Kafka with EA systems.

248
00:18:23,995 --> 00:18:28,025
secure proxies and zero trust
principles, which creates a secure

249
00:18:28,755 --> 00:18:30,385
high performance data pipeline.

250
00:18:30,885 --> 00:18:37,255
So this combination allows real time
data processing while ensuring only

251
00:18:37,335 --> 00:18:42,515
trusted users and devices access the
data, protecting sensitive information

252
00:18:42,765 --> 00:18:47,945
and enabling AI applications to
act on up to date available data.

253
00:18:48,445 --> 00:18:52,135
It's a powerful way to make
data more secure, scalable,

254
00:18:52,405 --> 00:18:54,685
and responsive across systems.

255
00:18:55,525 --> 00:19:02,115
By adopting these modern architectures,
organizations can enhance the accuracy

256
00:19:02,155 --> 00:19:07,235
and reliability of AI systems while
maintaining robust data protection.

257
00:19:07,735 --> 00:19:08,655
Thank you so much.

