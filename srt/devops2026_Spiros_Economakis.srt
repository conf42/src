1
00:00:00,500 --> 00:00:03,710
Speaker 40: Hi everyone, and
welcome to this presentation.

2
00:00:04,710 --> 00:00:09,600
I'm gonna talk about how AI is
redefining SRE and customer experience.

3
00:00:10,140 --> 00:00:16,240
And this talk isn't about replacing SREs
or changing, the next AI hype cycle.

4
00:00:16,780 --> 00:00:21,550
It's about how reliability work
is changing and why customer

5
00:00:21,550 --> 00:00:26,020
experience is now tightly
connected to how we run production.

6
00:00:26,520 --> 00:00:30,389
Everything else here today comes
from being on call and running real

7
00:00:30,840 --> 00:00:36,370
production systems and building no
fire while Watson AI dramatically

8
00:00:36,370 --> 00:00:38,140
increased the pace of a change.

9
00:00:39,010 --> 00:00:42,250
And lastly, this presentations,
I'm pretty sure that is gonna be

10
00:00:42,280 --> 00:00:44,620
totally different in a year from now.

11
00:00:45,120 --> 00:00:50,279
I spent over a decade building and
operating production systems that

12
00:00:50,279 --> 00:00:53,130
changed faster than their documentation.

13
00:00:53,710 --> 00:00:58,210
I've been the person that people DM
at 3:00 AM because you know how this

14
00:00:58,260 --> 00:00:59,730
really works when you're on call.

15
00:01:00,360 --> 00:01:04,739
And that experience led me here,
not because tooling was bad, but

16
00:01:04,739 --> 00:01:06,690
because context kept disappearing.

17
00:01:07,560 --> 00:01:11,180
So let's start with reality, not
with just an architecture diagram.

18
00:01:11,180 --> 00:01:15,865
We wish we were through, let's see, the
world engineers actually living today.

19
00:01:16,465 --> 00:01:18,925
And this is not a critique,
it's a recognition.

20
00:01:19,615 --> 00:01:22,965
Most of our work doesn't
happen in clean abstractions.

21
00:01:23,385 --> 00:01:27,855
It happens in exceptions edge
kcs and half known systems.

22
00:01:28,395 --> 00:01:31,835
And that reality has shifted
dramatically in the last, two years.

23
00:01:32,335 --> 00:01:33,535
This used to be hard.

24
00:01:33,725 --> 00:01:34,745
It's not something new.

25
00:01:35,315 --> 00:01:39,455
I think now it's something totally
different, especially with all this

26
00:01:39,455 --> 00:01:41,975
AI generated code and vibe coding.

27
00:01:42,605 --> 00:01:45,574
We fish, we, we seep faster than ever.

28
00:01:45,634 --> 00:01:47,765
So the production changes constantly.

29
00:01:48,265 --> 00:01:52,695
Reliability didn't get harder
because teams got worse.

30
00:01:53,195 --> 00:01:58,895
It got harder because teams grow system
now change faster than the humans can

31
00:01:58,895 --> 00:02:02,135
really build up a stable mental model.

32
00:02:02,635 --> 00:02:04,765
It's not that AI created this, right?

33
00:02:04,765 --> 00:02:07,975
It just accelerated this because
right now, as I mentioned, we

34
00:02:07,975 --> 00:02:13,495
see faster than ever and when the
systems outpace, understanding the

35
00:02:13,495 --> 00:02:17,815
first thing that breaks isn't only
the uptime, it's also the clarity.

36
00:02:18,315 --> 00:02:23,885
If you see this diagram, this is what
a production actually looks like today

37
00:02:24,215 --> 00:02:27,275
and most of the years in the past.

38
00:02:28,125 --> 00:02:31,875
At the bottom we have a couple of
services and systems, which is,

39
00:02:31,875 --> 00:02:33,524
mostly our production environment.

40
00:02:34,045 --> 00:02:39,454
Code infrastructure, telemetry
tools knowledge, different

41
00:02:39,454 --> 00:02:40,744
kind of various places.

42
00:02:41,244 --> 00:02:46,364
On top of this, there is a couple of
workflows like releases, incidents,

43
00:02:46,844 --> 00:02:53,134
security, cost, and we have also the teams
each of them owning a piece of, of of a

44
00:02:53,134 --> 00:02:56,734
slice, but not knowing the whole, right?

45
00:02:56,764 --> 00:02:58,839
Not nobody understands the
full production system.

46
00:02:59,739 --> 00:03:03,999
So no single person really sees
and understands all this at once.

47
00:03:04,384 --> 00:03:09,184
Yeah, every incident, cut across
boundaries that were designed to work

48
00:03:09,184 --> 00:03:12,484
together, and each handoff loses context.

49
00:03:13,174 --> 00:03:16,594
This is where most reliability,
pain actually lives between underst

50
00:03:16,594 --> 00:03:21,754
lives, not in one service, not
in one dashboard, in the gaps.

51
00:03:22,354 --> 00:03:26,374
And it's obvious that we don't
like data, we don't like tools.

52
00:03:26,374 --> 00:03:31,524
If you see the diagram, we lack a common
and a certain understanding and meaning.

53
00:03:32,154 --> 00:03:35,364
Of how these changes turned into outcomes.

54
00:03:36,204 --> 00:03:39,834
The systems are connected teams
are divided and production

55
00:03:39,834 --> 00:03:40,944
live somewhere in between.

56
00:03:41,444 --> 00:03:47,024
And when engineers struggle to navigate
this customers fill this immediately.

57
00:03:47,524 --> 00:03:53,364
Engineers, engineers struggle and because
of that, incidents take hours or days.

58
00:03:53,919 --> 00:03:58,859
Customers wait and stand wondering if
they can really rely on us next time.

59
00:03:59,439 --> 00:04:01,569
It impacts revenue and our reputation.

60
00:04:02,059 --> 00:04:04,729
Customer report these issues first, right?

61
00:04:04,849 --> 00:04:07,369
We learn something is broken
from a support ticket, not

62
00:04:07,369 --> 00:04:09,829
from our systems or to link.

63
00:04:10,459 --> 00:04:12,799
Engineers become single points of failure.

64
00:04:12,849 --> 00:04:16,409
A few people carry, the full
knowledge of a production environment.

65
00:04:16,929 --> 00:04:17,484
They're burned out.

66
00:04:18,414 --> 00:04:21,654
Or they leave and not only
when they leave, they get this

67
00:04:21,654 --> 00:04:22,734
knowledge together, right?

68
00:04:22,734 --> 00:04:24,954
So lots of people, they have
no idea what's happening.

69
00:04:25,674 --> 00:04:29,844
Customer experience is no longer
separate from reliability.

70
00:04:30,264 --> 00:04:35,034
What customers feel is the external
result of an internal confusion.

71
00:04:35,534 --> 00:04:40,334
And the problem isn't that engineers
don't care is that systems don't

72
00:04:40,334 --> 00:04:46,314
really remember, even when people do
every investigation starts from zero.

73
00:04:46,474 --> 00:04:51,124
Because contact doesn't survive
change, which led to the

74
00:04:51,124 --> 00:04:52,924
fixes we've all tried, right?

75
00:04:52,924 --> 00:04:55,234
More processes, more tooling than others.

76
00:04:55,354 --> 00:04:56,164
We'll discuss this.

77
00:04:57,064 --> 00:04:59,344
So we try to fix that, right?

78
00:04:59,374 --> 00:05:02,224
What we, and we're trying
to do the ob obvious things.

79
00:05:03,014 --> 00:05:04,784
The first instinct is visibility.

80
00:05:04,784 --> 00:05:10,424
So what we do, we add more dashboards,
more metrics, more alerts, but

81
00:05:10,454 --> 00:05:14,894
visibility without structure
just increases the mental load.

82
00:05:15,744 --> 00:05:20,934
We didn't reduce uncertainty, we
multiplied, so we moved from more

83
00:05:20,934 --> 00:05:23,514
data to smarter looking data.

84
00:05:24,014 --> 00:05:28,664
And we taught systems because of
this, to find patterns, right?

85
00:05:28,724 --> 00:05:31,924
But patterns without the real cause.

86
00:05:32,404 --> 00:05:33,484
Don't tell you what changed.

87
00:05:34,294 --> 00:05:37,114
Correlation helps you react fast, right?

88
00:05:37,144 --> 00:05:38,374
That's a correlation trap.

89
00:05:38,884 --> 00:05:44,769
It doesn't help you understand why this
bloke, this incident, happened this time.

90
00:05:45,269 --> 00:05:51,069
And when that, that still didn't
work, we did a, another trap, right?

91
00:05:51,069 --> 00:05:53,499
It's what I call the tooling trap.

92
00:05:53,949 --> 00:05:55,059
We added more tools.

93
00:05:55,659 --> 00:06:00,109
Every new problem, got a new
tool or a new workflow or a

94
00:06:00,109 --> 00:06:01,789
new processes or a new policy.

95
00:06:02,089 --> 00:06:04,519
So now we have also AI tools.

96
00:06:04,519 --> 00:06:08,599
You have more AI tools to do a
couple of other things, and each tool

97
00:06:08,719 --> 00:06:11,989
sold a slice, but added handoffs.

98
00:06:12,829 --> 00:06:18,769
Ownership gaps and context loss,
the system became operatable,

99
00:06:18,799 --> 00:06:20,539
but not understandable.

100
00:06:21,169 --> 00:06:24,949
So the question isn't
how do we react faster?

101
00:06:25,669 --> 00:06:32,359
It's how we keep up, in a constant change
of a production, which is happening

102
00:06:32,419 --> 00:06:35,129
in a tremendous speed at this moment.

103
00:06:35,129 --> 00:06:35,809
And today.

104
00:06:36,309 --> 00:06:40,359
AI didn't just help us, to do
the same work faster, right?

105
00:06:40,359 --> 00:06:43,549
So things has changed for many ways.

106
00:06:44,270 --> 00:06:47,450
It changed what system
can do at all, right?

107
00:06:47,550 --> 00:06:54,140
Until recently, systems mostly
emitted, row signals, numbers of

108
00:06:54,140 --> 00:06:57,920
logs, traces, commits, deployments.

109
00:06:57,950 --> 00:06:59,450
There's a lot of fragments here, right?

110
00:06:59,950 --> 00:07:01,030
With modern ai.

111
00:07:01,150 --> 00:07:02,350
There's a shift.

112
00:07:03,070 --> 00:07:06,130
Understanding doesn't have to
be reconstructed later, right?

113
00:07:06,490 --> 00:07:11,560
It can exist earlier, it can be
persist right close to where the

114
00:07:11,560 --> 00:07:12,970
production is actually operating.

115
00:07:13,600 --> 00:07:19,710
So this is a move from raw signals
to certain meaning from isolated

116
00:07:19,710 --> 00:07:24,300
metrics to system awareness, and
from reconstruction after the

117
00:07:24,300 --> 00:07:27,155
fact to recognition in the moment.

118
00:07:27,570 --> 00:07:32,935
It, it changed, where and how
understanding lives in what form.

119
00:07:33,715 --> 00:07:37,135
And once understanding moves
closers to the production and

120
00:07:37,135 --> 00:07:43,185
to your systems, it completely
changes how we respond for years.

121
00:07:43,605 --> 00:07:47,414
The main question we've asked
during incidence symbol, what broke?

122
00:07:48,345 --> 00:07:49,305
Is it disservice?

123
00:07:49,305 --> 00:07:50,055
Is it the node?

124
00:07:50,085 --> 00:07:50,260
What is it?

125
00:07:51,225 --> 00:07:56,505
That question assumes failures
is a starting point, but when

126
00:07:56,805 --> 00:08:01,095
you can track systems over time,
you can ask a better question.

127
00:08:01,455 --> 00:08:06,495
Not just what broke, but what change
and what did that change affect.

128
00:08:07,215 --> 00:08:12,435
This is the difference between reacting
symptoms and understanding code.

129
00:08:12,935 --> 00:08:15,364
To do that, we need to follow systems.

130
00:08:15,364 --> 00:08:16,550
That way they actually evolve, right?

131
00:08:17,119 --> 00:08:22,040
How your production is operating
consistently and continuously.

132
00:08:22,540 --> 00:08:28,320
So production doesn't fail in
isolation, production is changing.

133
00:08:28,320 --> 00:08:34,249
There's configs code, service
dependencies, new infrastructure, traffic

134
00:08:34,249 --> 00:08:37,009
changes, and those changes can rip.

135
00:08:37,729 --> 00:08:40,099
So the view you see here is.

136
00:08:40,969 --> 00:08:46,639
How connects these three things
continuously from what changed,

137
00:08:47,060 --> 00:08:50,569
where it landed, what is the
current state of the behavior.

138
00:08:50,810 --> 00:08:55,909
So instead of treating every incident
as a one off, the system keeps

139
00:08:55,999 --> 00:09:00,739
our running, understanding every
incident adds knowledge instead of

140
00:09:00,739 --> 00:09:03,174
wiping the slate clean and that.

141
00:09:03,904 --> 00:09:07,944
Mother matters a lot before
something breaks, right?

142
00:09:07,944 --> 00:09:11,425
So there is a persistent
understanding across time.

143
00:09:11,925 --> 00:09:15,524
Antifa system continuously
understands what changed, where it

144
00:09:15,524 --> 00:09:18,224
landed, and how behavior shifted.

145
00:09:18,734 --> 00:09:20,939
The reliability doesn't
start at the alert.

146
00:09:21,614 --> 00:09:24,824
It starts before the
incident even exists, right?

147
00:09:25,214 --> 00:09:29,474
The ability decisions happen before
anything breaks while I'm coding.

148
00:09:29,894 --> 00:09:32,714
So history stops being something
we look back on or we are

149
00:09:32,714 --> 00:09:34,124
just have a few people, right?

150
00:09:34,574 --> 00:09:37,214
It becomes something you used
to decide what to do next.

151
00:09:37,604 --> 00:09:41,104
This isn't about, predicting
the future perfectly.

152
00:09:41,594 --> 00:09:43,874
It's about not being blind to risk.

153
00:09:44,084 --> 00:09:48,014
We've already seen before,
and this is foresight.

154
00:09:48,494 --> 00:09:51,614
Grounded in how production
actually behaves over time.

155
00:09:52,305 --> 00:09:56,324
And once you have that reliability
moves to a very different place.

156
00:09:56,824 --> 00:10:02,314
This is reliability embedded directly into
the workflow of how we work every day.

157
00:10:02,824 --> 00:10:07,115
Before code sips, the system already
understands what changed, what

158
00:10:07,115 --> 00:10:11,375
depends on it, what is going to
change and what's already unstable.

159
00:10:11,795 --> 00:10:13,745
So engineers don't need
to remember everything.

160
00:10:14,344 --> 00:10:20,294
The system brings the context to them
and, automatically a deployment happens,

161
00:10:20,834 --> 00:10:26,485
triggers a deployment analysis on every
PR because incidents don't be keen.

162
00:10:26,485 --> 00:10:29,515
The deploy time, they definitely
don't be begin at the alert time.

163
00:10:30,145 --> 00:10:34,345
So you have reliability, not
after users feel the pain.

164
00:10:34,845 --> 00:10:40,064
And this isn't just incident data,
it's how the service normally behaves.

165
00:10:40,860 --> 00:10:46,620
It's how often it change what actually
goes wrong after those changes?

166
00:10:46,650 --> 00:10:50,010
It's like a validation based on
the change we're gonna, we're gonna

167
00:10:50,010 --> 00:10:54,300
apply and that history is always
there, even when the team changes.

168
00:10:54,840 --> 00:10:58,260
And once you have that memory
availability, steps being

169
00:10:58,885 --> 00:11:01,355
stops, being a moment in time.

170
00:11:01,855 --> 00:11:05,474
And reliability, traditionally
used to live in best, right?

171
00:11:05,535 --> 00:11:09,555
We were deploying, there was an
incident, we had a postmortem,

172
00:11:09,824 --> 00:11:11,204
we had, tasks after that.

173
00:11:11,864 --> 00:11:14,954
We have already forgotten, after
a few months what happened.

174
00:11:15,454 --> 00:11:20,555
But now with, all these context graphs
and the advancements of ai, you can

175
00:11:20,555 --> 00:11:26,495
spot risky changes when you code so you
can understand the impact of attains.

176
00:11:26,900 --> 00:11:32,390
Early on when you really actually doing
coding in your ID find the real cause when

177
00:11:32,390 --> 00:11:36,860
there is an incident and now it starts
becoming also a continuous loop, right?

178
00:11:36,920 --> 00:11:41,630
Every change, every incident,
every outcome adds to understanding

179
00:11:42,230 --> 00:11:43,819
as a continuous feedback loop.

180
00:11:44,390 --> 00:11:48,520
And this is where, where we call
this a full context embedded des

181
00:11:49,089 --> 00:11:52,600
and this is where the things are
moving the next couple of years.

182
00:11:53,575 --> 00:11:57,645
Everything I described so far might,
sound familiar to most of you.

183
00:11:58,125 --> 00:12:01,115
And we have all of us tried,
better dashboards, better

184
00:12:01,115 --> 00:12:02,765
alerts, better runbooks.

185
00:12:03,275 --> 00:12:05,555
So what's actually different this time?

186
00:12:06,055 --> 00:12:10,855
The system right now can drag
change and this change, as I

187
00:12:10,855 --> 00:12:13,195
mentioned, can have, right?

188
00:12:13,195 --> 00:12:14,275
Can have a certain meaning.

189
00:12:14,680 --> 00:12:16,330
Can have, can present the system.

190
00:12:16,330 --> 00:12:22,420
Awareness can also not only present
the system awareness, but also,

191
00:12:22,420 --> 00:12:25,990
reconstruct it later from the
context you have already captured.

192
00:12:26,650 --> 00:12:33,400
And these are not snapshots on, not point
in time metrics, but how code config,

193
00:12:33,520 --> 00:12:38,500
dependencies, deployments, signals
telemetry evolve through the time.

194
00:12:39,000 --> 00:12:39,900
Second.

195
00:12:40,485 --> 00:12:45,135
Right now we can inter, we can connect
these to a cause and effect relationships.

196
00:12:45,585 --> 00:12:51,315
So not just these things move together,
but these change led to that outcome.

197
00:12:51,815 --> 00:12:57,335
And third, as we discussed earlier,
we can keep learning between

198
00:12:57,335 --> 00:13:00,635
different kind of incidents, between
different kind of architectural

199
00:13:00,635 --> 00:13:04,595
documents, between our collaboration
in different kinds of places.

200
00:13:04,595 --> 00:13:06,515
How work in communication platforms.

201
00:13:06,905 --> 00:13:09,215
So there's no reset
button after a postmortem.

202
00:13:09,215 --> 00:13:13,265
Now what The system learn sticks.

203
00:13:13,675 --> 00:13:17,905
There's no hero X, no, starting from
zero 3:00 AM there's no reset button.

204
00:13:18,505 --> 00:13:25,815
And when systems stop forgetting the
impact isn't just internal for customers.

205
00:13:25,845 --> 00:13:27,645
This shows up in various ways, right?

206
00:13:27,765 --> 00:13:30,765
Few surprises because right now, so
there's a lot of benefits, right?

207
00:13:30,765 --> 00:13:32,355
There is a few surprises to the customer.

208
00:13:32,715 --> 00:13:35,625
Because risky changes are caught earlier.

209
00:13:36,125 --> 00:13:39,665
Faster recovery right now because
engineers aren't guessing.

210
00:13:39,935 --> 00:13:44,615
They're acting in a full context
and in a behavior over time.

211
00:13:45,305 --> 00:13:49,365
More confidence, in more predictable
changes and releases and deployments

212
00:13:49,725 --> 00:13:52,065
because reliability isn't like anymore.

213
00:13:52,455 --> 00:13:57,735
It's informed decision making and
where reliability improves, right?

214
00:13:57,795 --> 00:14:01,965
Customer experience follows and
not as a downstream metric, right?

215
00:14:02,085 --> 00:14:06,075
But as a direct result and
impact to our business.

216
00:14:06,340 --> 00:14:10,420
And that shift also changes what
it means to be an engineer anymore.

217
00:14:10,900 --> 00:14:14,160
With all these a advancements
of ai, this is where the human

218
00:14:14,160 --> 00:14:15,690
impact really shows up, right?

219
00:14:16,170 --> 00:14:19,320
Engineers right now,
stop chasing symptoms.

220
00:14:19,935 --> 00:14:23,955
And start shaping out outcomes
because they stop paying, WAC

221
00:14:24,045 --> 00:14:25,785
playing guacamole with alerts.

222
00:14:26,205 --> 00:14:31,335
Instead, they start shaping outcomes,
as I mentioned, deciding when to see,

223
00:14:31,695 --> 00:14:36,615
deciding when to wait, decide how risks
should be managed before users fill it

224
00:14:37,195 --> 00:14:39,115
and the system can carry this memory.

225
00:14:39,585 --> 00:14:44,235
So engineers can focus on
adjustment, not just recall.

226
00:14:44,955 --> 00:14:49,865
And this leads to very different future
for SRE and for everyone in the industry.

227
00:14:50,315 --> 00:14:51,755
And for observability in general.

228
00:14:52,685 --> 00:14:58,355
For a long time, we've optimized SRE
for speed, faster detection, faster

229
00:14:58,355 --> 00:15:03,935
response, faster root cause analysis, but
speed alone doesn't reduce risk, right?

230
00:15:03,965 --> 00:15:05,105
Understanding does.

231
00:15:05,645 --> 00:15:08,225
The future of SRE isn't
just faster reaction.

232
00:15:08,225 --> 00:15:12,065
It's be better decision much more
early in the process before we

233
00:15:12,065 --> 00:15:15,365
deploy, before there is an escalation
before customers feel the pain.

234
00:15:15,995 --> 00:15:18,275
And that's a shift we are building toward.

235
00:15:18,775 --> 00:15:19,975
I leave you with this idea.

236
00:15:20,425 --> 00:15:23,755
Reliability doesn't live
in alerts, that's for sure.

237
00:15:24,305 --> 00:15:28,655
It lives in understanding how
production change over time and when

238
00:15:28,705 --> 00:15:30,835
systems, especially with ai, remember.

239
00:15:31,315 --> 00:15:35,515
Teams move faster with less fear and
customers really feel the difference.

240
00:15:36,265 --> 00:15:36,745
Thank you.

