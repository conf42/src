1
00:00:00,840 --> 00:00:01,380
Speaker: Hey everyone.

2
00:00:01,620 --> 00:00:03,540
Welcome to today's talk on
building Enterprise Ready,

3
00:00:03,540 --> 00:00:06,120
CICD pipelines using Agent ai.

4
00:00:07,080 --> 00:00:11,250
My name is Chen Mike Aqua, and I'm
responsible for the technical marketing

5
00:00:11,340 --> 00:00:13,800
of all of the AI products at Harness.

6
00:00:14,220 --> 00:00:17,140
Previously, I've worked for
companies in the DevOps Kubernetes

7
00:00:17,140 --> 00:00:18,690
apps, I observability spaces.

8
00:00:19,470 --> 00:00:20,610
So let's get into the topic.

9
00:00:21,090 --> 00:00:23,280
The agenda for today looks very simple.

10
00:00:23,700 --> 00:00:27,270
It's the what's and whys of
enterprise readiness, the role of

11
00:00:27,270 --> 00:00:28,890
agentic AI and knowledge craft.

12
00:00:29,610 --> 00:00:34,320
And last, but not the least, one of the
most important topics of governance.

13
00:00:34,820 --> 00:00:36,260
Let's start with enterprise readiness.

14
00:00:36,529 --> 00:00:40,970
Before we get into what an enterprise
ready pipeline looks like, let's take

15
00:00:40,970 --> 00:00:45,290
a broader view of the problems in
the CICD space or the DevOps space.

16
00:00:45,495 --> 00:00:50,084
So software delivery workflows today
are very manual and involve a lot

17
00:00:50,084 --> 00:00:54,015
of toil, which means that a lot of
companies still use homegrown scripts.

18
00:00:54,525 --> 00:00:57,285
And point solutions to
manage these pipelines.

19
00:00:57,765 --> 00:01:03,045
And because of this, the velocity at
which the customer gets product updates or

20
00:01:03,045 --> 00:01:05,625
feature updates goes down by quite a bit.

21
00:01:06,135 --> 00:01:10,385
The efficiency of the engineering
team, the security of the code being

22
00:01:10,385 --> 00:01:14,914
delivered to the customers as well
as the resiliency go down as well.

23
00:01:15,414 --> 00:01:20,389
With AI generated code, this problem is
multiplied or it grows exponentially.

24
00:01:20,889 --> 00:01:24,759
As you can see, the bottleneck is
still the software delivery pipeline,

25
00:01:25,059 --> 00:01:28,959
which means that testing, securing,
deploying, and optimizing need to

26
00:01:28,959 --> 00:01:31,749
expand to match the AI generated code.

27
00:01:32,249 --> 00:01:38,160
We've seen a lot of organizations using AI
prototypes to figure out how to use AI to

28
00:01:38,160 --> 00:01:40,229
expand their software delivery pipelines.

29
00:01:40,729 --> 00:01:43,205
AI prototypes take less time to build.

30
00:01:44,104 --> 00:01:48,964
Used to solve the initial capacity problem
and they stop at prompt engineering.

31
00:01:49,624 --> 00:01:53,584
However, with enterprise ai,
you need a robust architecture.

32
00:01:54,094 --> 00:01:58,354
You need something that demands
consistency and reliability, and you

33
00:01:58,354 --> 00:02:03,304
also need something that masters context
engineering We'll get into what is the

34
00:02:03,304 --> 00:02:06,724
difference between prompt engineering
and context engineering a bit later in

35
00:02:06,724 --> 00:02:11,584
the session, but because of this, these
differences, majority of the prototypes

36
00:02:11,584 --> 00:02:13,265
fail to scale at enterprise level.

37
00:02:13,765 --> 00:02:16,915
So the need for enterprise readiness
basically comes from the fact that

38
00:02:16,975 --> 00:02:21,595
almost 80% of the SDLC failures
don't happen during code generation.

39
00:02:21,595 --> 00:02:23,605
They happen after the code is written.

40
00:02:24,105 --> 00:02:26,145
The tools sprawl doesn't
help this problem.

41
00:02:27,105 --> 00:02:28,500
It basically amplifies it.

42
00:02:29,055 --> 00:02:33,795
So with tools sprawl, you have a lot
of unshared context, which basically

43
00:02:33,795 --> 00:02:37,394
means that you create fragile
pipelines, which basically means that.

44
00:02:37,409 --> 00:02:42,179
The code is not being delivered to the
customers in a secure and reliable way.

45
00:02:42,679 --> 00:02:46,609
Manual policy enforcement is another
blocker to this, which basically means

46
00:02:46,609 --> 00:02:50,869
that you have a lot of bottlenecks in the
governance and security aspect of things.

47
00:02:51,369 --> 00:02:55,570
All of this basically means that teams are
stuck balancing between speed and safety.

48
00:02:56,070 --> 00:02:59,970
So enterprise pipelines need to solve
the velocity and the control problem

49
00:02:59,970 --> 00:03:02,105
simultaneously, and which is where.

50
00:03:02,805 --> 00:03:04,995
Agent AI can be really effective.

51
00:03:05,495 --> 00:03:07,955
Let's define what an
enterprise pipeline means.

52
00:03:08,455 --> 00:03:11,245
Here's a simple layout of a pipeline.

53
00:03:11,275 --> 00:03:16,315
I know enterprise pipelines can
get really complex, but developer

54
00:03:16,315 --> 00:03:18,505
commits a code into code repository.

55
00:03:18,925 --> 00:03:20,815
The code is built, tested, and deployed.

56
00:03:20,965 --> 00:03:22,465
So that's like a very simple pipeline.

57
00:03:23,005 --> 00:03:26,125
What makes this pipeline
enterprise ready is it is scalable.

58
00:03:26,635 --> 00:03:28,495
It's secure and it is compliant.

59
00:03:28,995 --> 00:03:30,525
What do these things mean though?

60
00:03:31,025 --> 00:03:34,775
So by scalable we mean that the pipeline
should be able to support multiple

61
00:03:34,775 --> 00:03:36,785
environments through natural language.

62
00:03:37,285 --> 00:03:40,734
The pipeline should be able to
automatically figure out resource

63
00:03:40,734 --> 00:03:42,745
requirements based on workload patterns.

64
00:03:43,585 --> 00:03:47,545
It should be able to provision
infrastructure based on deployment demand.

65
00:03:48,045 --> 00:03:50,715
And it should also do intelligent
caching and artifact management

66
00:03:50,804 --> 00:03:52,124
across different teams.

67
00:03:52,624 --> 00:03:56,574
From a security perspective, there should
be real time vulnerability scanning.

68
00:03:56,574 --> 00:03:59,394
So SaaS and das scanning across the board.

69
00:03:59,694 --> 00:04:02,665
And this is done during code
generation, during build.

70
00:04:02,694 --> 00:04:04,554
At each stage of SDLC.

71
00:04:05,054 --> 00:04:08,295
Supply chain integrity is becoming
really critical these days, so tracking

72
00:04:08,295 --> 00:04:12,465
the provenance of every artifact and
dependency has become extremely important.

73
00:04:12,965 --> 00:04:14,135
And secret management.

74
00:04:14,195 --> 00:04:18,545
Basically rotating the secrets as well
as giving the least privileged model.

75
00:04:18,815 --> 00:04:23,065
Access has also become very important
on the compliance side of things.

76
00:04:23,515 --> 00:04:27,265
The compliance should be a
default, not a reactive measure.

77
00:04:27,765 --> 00:04:31,965
Audit trails for everything that is
generated right from code to bills to

78
00:04:31,980 --> 00:04:34,220
artifacts should be a mandated thing.

79
00:04:34,720 --> 00:04:38,470
There should be regulatory requirement
mapping such as HIPAA or SOC two.

80
00:04:39,430 --> 00:04:41,800
And finally, there should be
documentation for each and

81
00:04:41,800 --> 00:04:42,940
everything that's being generated.

82
00:04:43,440 --> 00:04:48,180
So let's look at how Agentic AI helps you
to achieve enterprise ready pipelines.

83
00:04:48,450 --> 00:04:53,115
With the help of knowledge graphs,
the role of agentic AI basically

84
00:04:53,115 --> 00:04:57,405
is to make sure that there is
autonomous problem solving.

85
00:04:57,930 --> 00:05:03,270
So the agents can actually be proactive
in perce perceiving failures and

86
00:05:03,270 --> 00:05:04,860
reasoning, the root cause, et cetera.

87
00:05:05,360 --> 00:05:09,260
There should be specialized
agents, for example, DevOps agent,

88
00:05:09,260 --> 00:05:11,210
SRE agent, across the board.

89
00:05:11,540 --> 00:05:14,150
And it should not be orchestrated
by humans, it should be

90
00:05:14,150 --> 00:05:15,545
orchestrated by an agent.

91
00:05:15,545 --> 00:05:16,190
Take ai.

92
00:05:16,690 --> 00:05:18,520
It should also be a
continuous learning pattern.

93
00:05:18,520 --> 00:05:22,420
So AI is really great at learning
about different patterns.

94
00:05:22,960 --> 00:05:28,510
And then the, that feedback loop should
be fed back into it so that next time,

95
00:05:28,510 --> 00:05:32,080
whenever it comes across a similar
pattern, it can action accordingly.

96
00:05:32,580 --> 00:05:37,500
And policy as an intent should be the
fundamental for TKI, which basically

97
00:05:37,500 --> 00:05:42,000
means that AI should understand what
are the enterprises policies and

98
00:05:42,000 --> 00:05:43,680
best practices and implement them.

99
00:05:44,180 --> 00:05:46,970
Let's look at context engineering
versus prompt engineering.

100
00:05:47,470 --> 00:05:49,870
Andre Card Party said, plus
one for context engineering

101
00:05:49,870 --> 00:05:51,010
versus prompt engineering.

102
00:05:51,730 --> 00:05:52,930
And I completely agree with that.

103
00:05:53,020 --> 00:05:53,920
And let's see why.

104
00:05:54,420 --> 00:05:57,870
Prompt engineering is basically
dependent on the user's skill and

105
00:05:57,870 --> 00:06:03,540
specificity, whereas context engineering
is actually dependent on your systems'

106
00:06:03,540 --> 00:06:07,440
knowledge, so your enterprises
policies, templates, and infrastructure.

107
00:06:08,220 --> 00:06:10,770
So it's way more comprehensive
than prompt engineering.

108
00:06:11,270 --> 00:06:12,290
Let's look at an example.

109
00:06:12,665 --> 00:06:13,805
Enterprise, CICD.

110
00:06:13,865 --> 00:06:19,315
When the user says, build me a pipeline,
the AI has, which has access to rich

111
00:06:19,315 --> 00:06:23,515
context, will figure out your governance,
your templates, your infrastructure,

112
00:06:23,605 --> 00:06:27,475
and your team standards to build
pipelines that are secure and compliant.

113
00:06:28,435 --> 00:06:32,385
This is by design and not by
luck, so that's why this reframes

114
00:06:32,385 --> 00:06:37,455
why knowledge graph and strong
governance matters and your context

115
00:06:37,515 --> 00:06:39,435
essentially makes AI really reliable.

116
00:06:39,935 --> 00:06:40,925
At an enterprise scale.

117
00:06:41,425 --> 00:06:45,625
So put this, to put this in a
diagrammatic view, whenever a user

118
00:06:45,625 --> 00:06:51,115
prompt comes into ai, AI uses the
context which it has access to, to

119
00:06:51,115 --> 00:06:56,035
create enterprise ready pipelines that
are scalable, secure, and compliant.

120
00:06:56,485 --> 00:06:59,275
So that brings the entire picture
that we discussed together.

121
00:06:59,775 --> 00:07:01,365
Let's look at how exactly.

122
00:07:01,865 --> 00:07:03,575
We'd be build knowledge graphs.

123
00:07:04,355 --> 00:07:07,565
So first of all, let's get into
what a rag and a knowledge graph is.

124
00:07:08,345 --> 00:07:13,655
A knowledge graph is basically structured
data that is organized as nodes and

125
00:07:13,655 --> 00:07:15,575
the relationships between those nodes.

126
00:07:16,085 --> 00:07:17,555
We'll look at an example a bit later.

127
00:07:18,055 --> 00:07:21,145
Rag essentially is unstructured
data from external sources.

128
00:07:21,145 --> 00:07:25,525
So if you have like playbooks in
Google Docs or Word, that would be a

129
00:07:25,525 --> 00:07:27,090
good example of unstructured content.

130
00:07:27,590 --> 00:07:33,590
And then the hybrid approach is making
these knowledge graphs rich using drag

131
00:07:33,680 --> 00:07:35,390
as an input to these knowledge graphs.

132
00:07:35,890 --> 00:07:39,939
So for DevOps, in a DevOps world,
everything is relationship based.

133
00:07:40,329 --> 00:07:44,980
So for example, let's say an e-commerce
business has hundreds of microservices.

134
00:07:45,579 --> 00:07:50,469
And let's say if I update service
A, I need to figure out which

135
00:07:50,469 --> 00:07:51,969
downstream services are affected.

136
00:07:52,390 --> 00:07:53,140
And that basically.

137
00:07:54,010 --> 00:07:57,700
I need to figure out the relationship
between different services and basically

138
00:07:57,700 --> 00:08:00,040
points to creating a rich knowledge graph.

139
00:08:00,540 --> 00:08:04,110
What we recommend for DevOps use
cases is using a hybrid approach,

140
00:08:04,440 --> 00:08:08,190
which is enrich knowledge graph,
which is ingested with rack.

141
00:08:08,690 --> 00:08:11,119
So let's see how we can
build such a knowledge graph.

142
00:08:11,630 --> 00:08:15,680
So first, you need to extract entities
such as services, users, and incidents

143
00:08:16,190 --> 00:08:18,410
then need to enrich with metadata.

144
00:08:18,905 --> 00:08:21,665
So you need to figure out the
owner's versions and the policies.

145
00:08:22,295 --> 00:08:26,405
Then you need to connect these together
so you have a relationship between who

146
00:08:26,405 --> 00:08:32,615
owns what and what depends on what, and
then finally expose this to the AI agent

147
00:08:32,615 --> 00:08:34,115
so that they can make use of this data.

148
00:08:34,539 --> 00:08:37,560
A fellow engineer said
this pretty accurately.

149
00:08:37,950 --> 00:08:41,400
If context is a new code,
knowledge graph is its compiler.

150
00:08:41,940 --> 00:08:42,720
I really love that code.

151
00:08:43,220 --> 00:08:46,310
So again, in a diagrammatic way,
this is this very simplistic

152
00:08:46,310 --> 00:08:47,180
view of knowledge craft.

153
00:08:47,690 --> 00:08:52,220
So you have entities, events, and third
party data, and they are all connected.

154
00:08:52,220 --> 00:08:54,890
So you know what the relationship
between different entities,

155
00:08:54,980 --> 00:08:56,540
events and third party data is,

156
00:08:57,040 --> 00:08:58,030
let's talk about governance.

157
00:08:58,030 --> 00:08:58,300
Now.

158
00:08:58,800 --> 00:09:03,060
For governance, we need to figure
out who, what, how, and why.

159
00:09:03,560 --> 00:09:09,410
Basically who has access to what, and
RAC is a great example of figuring that

160
00:09:09,410 --> 00:09:11,660
out or giving access to specific users.

161
00:09:12,160 --> 00:09:14,860
What access does AI have to your data?

162
00:09:14,980 --> 00:09:19,870
So what data is being used to train
where the data flows from, et cetera.

163
00:09:20,410 --> 00:09:24,970
These days, a lot of LLMs have
zero data retention policies, so

164
00:09:24,970 --> 00:09:26,380
your data is not used for training.

165
00:09:26,710 --> 00:09:29,560
This is a great example of
data and privacy card rails.

166
00:09:30,355 --> 00:09:33,325
The how focus is on policy
enforcement and guardrails.

167
00:09:33,805 --> 00:09:37,825
So essentially how AI behaves
can set guardrails so that the AI

168
00:09:37,825 --> 00:09:40,855
doesn't break those guardrails and
operates within a safe environment.

169
00:09:41,575 --> 00:09:43,855
And the why is basically auditability.

170
00:09:44,185 --> 00:09:48,295
So for everything that AI does, we
need to audit it, need to tag it.

171
00:09:48,295 --> 00:09:52,465
So for example, if an AI creates
a pipeline, you should tag it as

172
00:09:52,555 --> 00:09:57,025
AI generated pipeline so that your
compliance team can figure out what was AI

173
00:09:57,025 --> 00:09:58,615
generated and what was not AI generated.

174
00:09:59,115 --> 00:10:00,495
So again, a different code.

175
00:10:00,495 --> 00:10:04,305
This time context is a new code,
and governance is, its new runtime.

176
00:10:04,805 --> 00:10:07,555
Let's talk about RAC
for a second with RAC.

177
00:10:07,735 --> 00:10:08,755
It's very interesting.

178
00:10:09,035 --> 00:10:13,175
The question always is, should
AI have its own RAC or is there a

179
00:10:13,175 --> 00:10:15,005
different mechanism for RAC for ai?

180
00:10:15,505 --> 00:10:20,115
Our view on this is that the
AI is an extension of the user.

181
00:10:20,775 --> 00:10:25,365
Whatever RAC is assigned to a user
should be applicable to the AI as well.

182
00:10:25,865 --> 00:10:30,575
An example is given here, example,
if a user cannot deploy to

183
00:10:30,575 --> 00:10:34,115
production, that the AI should not
be able to deploy to production.

184
00:10:34,805 --> 00:10:37,295
And the example is modifying policies.

185
00:10:37,745 --> 00:10:41,675
Only admins in organizations
are supposed to modify policies.

186
00:10:42,365 --> 00:10:48,045
And as far as AI is concerned, the admin
AI can modify policies, not a user.

187
00:10:48,545 --> 00:10:51,845
So essentially AI becomes an
extension of the user, and thus

188
00:10:51,875 --> 00:10:54,005
the RPAC is also tied in that way.

189
00:10:54,505 --> 00:10:57,775
So the enterprise adoption framework
that we have seen a lot of customers use

190
00:10:57,775 --> 00:11:00,745
and be successful is there is a prompt.

191
00:11:01,615 --> 00:11:05,965
AI generates the pipeline, the
audit trail is updated, the user

192
00:11:05,965 --> 00:11:07,435
saves or executes the pipeline.

193
00:11:07,945 --> 00:11:11,095
In this case, the RAC is checked unsafe.

194
00:11:11,595 --> 00:11:12,435
The policies kick in.

195
00:11:12,935 --> 00:11:17,165
Depending on the RAC permissions and
the policies, the pipeline is either

196
00:11:17,165 --> 00:11:22,715
executed or it fails, and then a real
time feedback is given back to the user

197
00:11:22,925 --> 00:11:26,975
so that they can modify the pipeline
or involve the necessary people to

198
00:11:26,975 --> 00:11:28,595
make sure that this pipeline executes.

199
00:11:29,285 --> 00:11:31,865
It's a very simplistic F frame
framework that we have seen a lot of

200
00:11:31,865 --> 00:11:33,950
our customers use and scale their ai.

201
00:11:34,450 --> 00:11:37,720
Let's look at an example of how
we have implemented enterprise

202
00:11:37,720 --> 00:11:39,430
Ready CI ICD, pipeline creation.

203
00:11:39,850 --> 00:11:42,370
Just to give you a brief
overview of Harness platform

204
00:11:42,370 --> 00:11:43,720
for those unfamiliar with it.

205
00:11:44,220 --> 00:11:47,940
So we have a lot of products
around 18 products and everything

206
00:11:47,940 --> 00:11:49,320
is powered by harness ai.

207
00:11:49,590 --> 00:11:52,800
So essentially we make sure that
you create CI ICD policies or

208
00:11:52,800 --> 00:11:56,700
infrastructure using harness ai
and they are enterprise ready.

209
00:11:57,200 --> 00:12:02,820
So what we do is whenever a user gives a
prompt, a unified agent takes a prompt and

210
00:12:02,820 --> 00:12:08,700
divides it into different specific agents
that are specialized in specific domains.

211
00:12:08,860 --> 00:12:11,950
For example, the DevOps agent
can take care of CICD pipelines.

212
00:12:11,950 --> 00:12:15,520
The release agent can take care of feature
management, pipe feature management

213
00:12:15,520 --> 00:12:19,510
work, the reliability agent can take
care of chaos, engineering, et cetera.

214
00:12:20,410 --> 00:12:23,950
And then once the agent takes care
of that work, the output of this.

215
00:12:24,790 --> 00:12:27,790
Either pull requests or
pipelines or dashboards.

216
00:12:28,290 --> 00:12:31,980
But what powers all of
this is the context.

217
00:12:32,640 --> 00:12:37,350
The context basically is as you can
see from top down knowledge graph.

218
00:12:37,740 --> 00:12:41,010
So whatever the knowledge graph is
created based on harness actions,

219
00:12:41,370 --> 00:12:46,290
so building, deploying, et cetera,
and as well as external data.

220
00:12:46,290 --> 00:12:49,740
So if you have a Jira ticket
somewhere, so getting context

221
00:12:49,740 --> 00:12:51,480
from that Jira ticket example.

222
00:12:51,980 --> 00:12:56,210
The other layer of context is essentially
your enterprise rules and policies.

223
00:12:56,690 --> 00:12:59,090
This is the governance aspect
of things that we discussed.

224
00:12:59,240 --> 00:13:04,880
So this creates a, for the AI to
take action on, and memory is also

225
00:13:04,880 --> 00:13:08,570
critically important because then
the user doesn't have to restart

226
00:13:08,990 --> 00:13:10,550
from scratch every time they log in.

227
00:13:11,030 --> 00:13:14,870
There is memory and there is context
saved in that memory, but the user can

228
00:13:14,870 --> 00:13:17,000
reuse for the AI to be more effective.

229
00:13:17,500 --> 00:13:21,520
So that's an a very practical example of
how we have implemented all the things

230
00:13:21,520 --> 00:13:23,050
that we discussed in this talk today.

231
00:13:23,800 --> 00:13:25,900
And I le leave you with
this practical example.

232
00:13:26,200 --> 00:13:30,430
I hope you had a good understanding
of how to create CI ICD pipelines

233
00:13:30,670 --> 00:13:34,900
using tic ai that are enterprise
ready and can be done at scale.

234
00:13:35,620 --> 00:13:37,210
Again, thank you for
listening to this talk.

235
00:13:37,750 --> 00:13:41,530
If you have any questions, please feel
free to reach out to me on LinkedIn.

236
00:13:42,070 --> 00:13:45,100
My LinkedIn is shown here
and again, have a great day.

237
00:13:45,550 --> 00:13:45,790
Thank you.

