1
00:00:00,500 --> 00:00:01,310
Hello everyone.

2
00:00:01,810 --> 00:00:07,060
I'm Amish Sahu, vice President of
Pricing and Data Analytics and xometry.

3
00:00:07,720 --> 00:00:15,010
Today we're going to talk about building
resilient AI pricing platforms and how we

4
00:00:15,010 --> 00:00:18,709
can make real time decisioning at scale.

5
00:00:19,209 --> 00:00:23,839
As we know the modern retail
landscape has changed dramatically.

6
00:00:24,349 --> 00:00:28,509
And these days pricing decisions
are becoming becoming increasingly

7
00:00:28,509 --> 00:00:30,579
complex and time sensitive.

8
00:00:31,079 --> 00:00:35,369
And today we are going to talk
about how we can build sophisticated

9
00:00:35,369 --> 00:00:38,329
AI powered systems that are
just price in real time basis.

10
00:00:39,124 --> 00:00:44,274
Based on market conditions
competitor data or competitor trends

11
00:00:44,754 --> 00:00:46,584
and customer behavior patterns.

12
00:00:47,034 --> 00:00:50,344
These dynamic pricing platforms
are represent some of the more

13
00:00:50,344 --> 00:00:54,984
complex challenging architecture
are technology ecosystems today.

14
00:00:55,464 --> 00:00:59,824
So we'll briefly discuss that and cover
some of the aspects around it as we know.

15
00:01:00,584 --> 00:01:02,954
With pricing, the stakes are high.

16
00:01:03,374 --> 00:01:05,954
You can make a direct impact on revenue.

17
00:01:06,414 --> 00:01:11,894
The requirement requirements are extremely
complex and we are dealing with massive

18
00:01:11,894 --> 00:01:15,444
data volumes from different data sources.

19
00:01:15,504 --> 00:01:19,735
We have to watch out the
performance and the latency to

20
00:01:19,735 --> 00:01:21,325
maintain consistent performance.

21
00:01:21,865 --> 00:01:24,355
Reliability is another key factor here.

22
00:01:24,845 --> 00:01:30,845
You have to make sure the systems are
reliable across geos, geographies and

23
00:01:30,845 --> 00:01:38,035
also we are maintaining the regulatory
requirements to ensure that we are

24
00:01:38,035 --> 00:01:43,855
balancing the revenue impact the
complexity of the system, and with

25
00:01:43,855 --> 00:01:46,165
the reliability across geographies.

26
00:01:46,665 --> 00:01:52,545
So a little bit about the infrastructure
architecture for low latency pricing.

27
00:01:52,795 --> 00:01:54,715
As there are few aspects we'll cover here.

28
00:01:54,805 --> 00:02:00,085
One is the edge computing, which
is essentially making sure you are

29
00:02:00,115 --> 00:02:04,875
distributing a computing resources across
different regions across pricing systems.

30
00:02:05,325 --> 00:02:09,015
So that you can reduce response
time while maintaining consistency

31
00:02:09,015 --> 00:02:10,185
across different markets.

32
00:02:10,425 --> 00:02:13,665
You have to make sure when customers
are on your site, you're not taking

33
00:02:13,665 --> 00:02:18,765
too long to show them pricing through
instant coating you're making sure that

34
00:02:18,765 --> 00:02:24,375
you are pulling the information from
different sources or systems in a way

35
00:02:24,385 --> 00:02:26,785
that is fast and also that is accurate.

36
00:02:27,285 --> 00:02:32,545
You need to have a container orchestration
where we want to make sure there is

37
00:02:32,545 --> 00:02:36,165
automatic scaling based on the demand.

38
00:02:36,315 --> 00:02:42,255
And as the demand, as the volume goes
up, your system should scale seamlessly

39
00:02:42,624 --> 00:02:48,264
to provide the right information as
we talked about the complexity across,

40
00:02:48,264 --> 00:02:49,854
dealing with different data systems.

41
00:02:50,349 --> 00:02:50,979
Consistency.

42
00:02:50,979 --> 00:02:52,929
Data consistency is another challenge.

43
00:02:53,269 --> 00:02:57,289
You need to have the real time
inventory or sourcing information.

44
00:02:57,289 --> 00:03:00,649
You need to have the
competitor pricing data.

45
00:03:00,649 --> 00:03:02,989
You need to have customer
behavior, PA patterns.

46
00:03:03,439 --> 00:03:06,619
All those things end up getting together.

47
00:03:06,739 --> 00:03:09,319
So we have to make sure
the data is consistent.

48
00:03:10,219 --> 00:03:14,809
And last but not the least, you have
to think about network optimization.

49
00:03:15,319 --> 00:03:21,459
The content delivery networks that
optimize for API responses dedicated

50
00:03:21,459 --> 00:03:27,499
network connections between data centers
and how we can make have intelligent

51
00:03:27,499 --> 00:03:31,999
routing behind it to make sure we
are minimizing the latency here.

52
00:03:32,499 --> 00:03:36,429
When we talk about the architecture,
we we need to discuss about

53
00:03:36,429 --> 00:03:38,139
data pipeline engineering.

54
00:03:38,419 --> 00:03:42,609
As we talked about the complexity of the
data and accessing data or different types

55
00:03:42,609 --> 00:03:44,979
of data from diverse kind of systems.

56
00:03:45,469 --> 00:03:49,219
You need a constant stream
processing where you're continuously

57
00:03:49,429 --> 00:03:52,159
ingesting and transforming the data.

58
00:03:52,699 --> 00:03:56,849
Across the systems as I say, whether
it's competitor data or inventory data

59
00:03:56,849 --> 00:04:01,089
or supply data or customer behavior
interactions, all these things needs

60
00:04:01,089 --> 00:04:03,359
to be processed in the right way.

61
00:04:03,449 --> 00:04:06,749
And you need to have real
time validation for that.

62
00:04:06,909 --> 00:04:09,424
So implementing real
time data quality checks.

63
00:04:10,249 --> 00:04:14,209
Of course you cannot add more
latency or processing delays.

64
00:04:14,609 --> 00:04:17,729
You need to be smart about
how to detect anomaly.

65
00:04:18,009 --> 00:04:22,059
How you make sure that you are doing the
real time validation without compromising

66
00:04:22,059 --> 00:04:23,559
on the performance or the speed.

67
00:04:24,189 --> 00:04:28,419
Of course you have to think about
time-based features that can pull from

68
00:04:28,569 --> 00:04:31,249
historical data and in a way that.

69
00:04:31,819 --> 00:04:37,829
You are whatever net new or incremental
data you're getting, you are basing your

70
00:04:37,829 --> 00:04:42,029
processing or calculation based on the
incremental data in a way that you're

71
00:04:42,029 --> 00:04:44,069
not taking too long to process it.

72
00:04:44,579 --> 00:04:49,139
So building key here is that you need
to build the robust data pipelines

73
00:04:49,139 --> 00:04:53,799
that can handle this complexity while
maintaining real time performance.

74
00:04:54,219 --> 00:04:58,069
A lot of, so robustness in the
technical architecture and operational

75
00:04:58,069 --> 00:05:00,049
processes go a long way here.

76
00:05:00,549 --> 00:05:02,769
The other thing we talk
about is in pricing.

77
00:05:02,799 --> 00:05:06,579
This is most of, as we think
about pricing in today's world,

78
00:05:06,729 --> 00:05:08,679
most of it is AI driven pricing.

79
00:05:09,039 --> 00:05:14,009
So how do you make sure that, you are
deploying your machine learning models

80
00:05:14,009 --> 00:05:20,109
in a way that the models are don't have
latency issues, but at the same time,

81
00:05:20,109 --> 00:05:25,949
you're providing the high accuracy across
different type of market conditions or,

82
00:05:25,949 --> 00:05:30,329
across all kind of the data aggregation
or data processing we are doing.

83
00:05:31,229 --> 00:05:32,249
So we have to.

84
00:05:32,804 --> 00:05:38,594
Make sure you are allocating the
memory correctly to all the, all

85
00:05:38,594 --> 00:05:41,024
these models for a fast response time.

86
00:05:41,684 --> 00:05:46,644
How we can be strategic about
where you can cache the prediction

87
00:05:47,194 --> 00:05:51,934
or where you have to make it real
time inferences for edge cases.

88
00:05:51,934 --> 00:05:55,679
So essentially as you say,
compartmentalizing the modeling with that.

89
00:05:55,989 --> 00:06:00,099
Some of the common scenarios, you are
caching the prediction, but for some of

90
00:06:00,099 --> 00:06:05,149
the edge cases, you have the intelligence
or you have you, you can run the models

91
00:06:05,149 --> 00:06:06,889
to provide the right information.

92
00:06:07,549 --> 00:06:11,509
When you think about pricing, you
have to continuously experiment.

93
00:06:11,929 --> 00:06:16,359
So how we have the right experimentation
set up, whether it's AB testing or multi

94
00:06:16,539 --> 00:06:21,939
bandit or contextual bandits, how we can
be smart about experimentation and how

95
00:06:21,939 --> 00:06:25,749
we can have the infrastructure to support
the experimentation to provide the right

96
00:06:25,959 --> 00:06:28,049
customer outcome and financial outcome.

97
00:06:28,829 --> 00:06:29,969
And as we've.

98
00:06:30,469 --> 00:06:33,829
See most of the cases, these
decisions on pricing, are

99
00:06:34,079 --> 00:06:35,819
they need to evolve over time.

100
00:06:36,269 --> 00:06:41,079
There will be cases where you we
may end up implementing something

101
00:06:41,079 --> 00:06:42,429
that doesn't work out as planned.

102
00:06:42,429 --> 00:06:45,039
So we need to have, or at
least to a system issue.

103
00:06:45,399 --> 00:06:51,559
In those cases, we have to have automated
rollback triggers based on KPIs or

104
00:06:51,559 --> 00:06:53,719
some of the guardrails we have set up.

105
00:06:54,289 --> 00:06:59,049
So in a way, we the systems we have
or architecture needs to be robust

106
00:06:59,049 --> 00:07:07,159
enough to a sup to get the right data
b, persist the data correctly and see

107
00:07:07,159 --> 00:07:11,089
support advanced models and machine
learning models during the process.

108
00:07:11,589 --> 00:07:15,669
When you think about machine
learning, model management we always

109
00:07:15,669 --> 00:07:20,139
have to think about how we can make
them more effective and efficient.

110
00:07:20,739 --> 00:07:26,619
As we know, most of these models
are combination of multiple models.

111
00:07:26,619 --> 00:07:27,939
There are models behind models.

112
00:07:28,249 --> 00:07:33,229
We have to continuously
evaluate how efficiently we can

113
00:07:33,229 --> 00:07:34,699
combine predictions from this.

114
00:07:35,299 --> 00:07:40,870
Different models how we can use
them selectively depending on their

115
00:07:40,870 --> 00:07:46,550
strengths how we control for the
biases or late and any shortcomings

116
00:07:46,550 --> 00:07:51,110
to the model to make sure that at an
overall level we are providing the.

117
00:07:51,874 --> 00:07:54,154
Right information with right accuracy.

118
00:07:54,694 --> 00:08:00,375
Version control is key as we are evolving
these models in and continuously,

119
00:08:00,715 --> 00:08:05,044
improving our predictions, improving
the way we provide price informations.

120
00:08:05,544 --> 00:08:07,465
We have to make sure we are versioning.

121
00:08:07,495 --> 00:08:12,655
We have version control so that you can
roll back if needed, or you can refer

122
00:08:12,655 --> 00:08:17,065
back if you want to see how the new model
is performing compared to the old model.

123
00:08:17,935 --> 00:08:20,695
Continuous performance monitoring is key.

124
00:08:20,845 --> 00:08:21,355
As.

125
00:08:21,855 --> 00:08:25,544
We evolve the models as pricing
has to be nimble and agile.

126
00:08:25,905 --> 00:08:27,824
We have to make sure you're
continuously monitoring the

127
00:08:27,824 --> 00:08:29,324
performance in a holistic way.

128
00:08:29,424 --> 00:08:32,064
Which when I say holistic way,
we have to think about customer

129
00:08:32,064 --> 00:08:33,834
outcomes, financial outcomes.

130
00:08:34,210 --> 00:08:36,579
All those things need to be
looked at together and all those

131
00:08:36,579 --> 00:08:40,090
performance monitoring need to
happen in real time accounting for

132
00:08:40,090 --> 00:08:41,439
all the different data sources.

133
00:08:41,949 --> 00:08:46,060
Last but not the least here is with this
models, we need continuous training.

134
00:08:46,060 --> 00:08:51,530
So how we can make our infrastructure
robust enough to ensure that the

135
00:08:51,530 --> 00:08:56,630
models are getting the right feedback
and trained on a regular basis so

136
00:08:56,630 --> 00:09:00,640
that we are making these predictions
better and better over time.

137
00:09:01,140 --> 00:09:06,359
With this models and the complex data
architecture, we have to keep in mind

138
00:09:06,359 --> 00:09:09,120
scalability and performance optimization.

139
00:09:09,780 --> 00:09:16,140
As we've discussed with the demand
volume or as the volume of data grows,

140
00:09:16,140 --> 00:09:22,750
we need autoscaling so that we can
capture the right input for the models.

141
00:09:23,140 --> 00:09:28,540
You have to balance the the volume,
incoming volume and the competition need.

142
00:09:29,040 --> 00:09:32,100
Additionally, you have to measure
where in the databases you can

143
00:09:32,100 --> 00:09:40,020
optimize to make sure that we are
able to manage heavy workloads all the

144
00:09:40,020 --> 00:09:45,060
complex queries or complex calls, we
are able to drive them efficiently.

145
00:09:45,770 --> 00:09:49,430
Just so it goes long way in
terms of you, you not only just

146
00:09:49,430 --> 00:09:51,080
need the right and accurate.

147
00:09:51,500 --> 00:09:52,100
Predictions.

148
00:09:52,100 --> 00:09:57,800
You also have to make sure that
you, we have the ability to scale

149
00:09:57,950 --> 00:09:59,660
and optimize our performance.

150
00:10:00,160 --> 00:10:03,369
The other areas will be caching
and resource management.

151
00:10:03,620 --> 00:10:07,970
Again multi-layered caching
with aggressive caching can

152
00:10:07,970 --> 00:10:09,470
improve your response times.

153
00:10:09,860 --> 00:10:13,520
As we discussed a couple
of slides ago, where, what.

154
00:10:13,910 --> 00:10:18,710
Common scenarios we can cache so
that you are not going through the

155
00:10:19,310 --> 00:10:20,780
rigorous prediction every time.

156
00:10:21,260 --> 00:10:27,400
So how do we make sure not just the
prediction and also input date has a is

157
00:10:27,400 --> 00:10:31,670
fresh and how we can cache effectively
to make sure that we are using the

158
00:10:31,670 --> 00:10:35,990
right combination of streamlining
and also edge case optimization

159
00:10:35,990 --> 00:10:37,340
to drive the right performance.

160
00:10:37,940 --> 00:10:43,030
Some of the scaling patterns here will
be non-linear depending on product

161
00:10:43,030 --> 00:10:47,170
catalog size, market complexity,
and algorithm sophistication.

162
00:10:47,590 --> 00:10:49,180
So we have to account for that as well.

163
00:10:49,680 --> 00:10:53,820
And additionally, as we say,
the performance monitoring.

164
00:10:53,860 --> 00:10:56,710
Traditional performance application
performance monitoring tools

165
00:10:56,710 --> 00:11:02,020
may not capture the unique
characteristics of pricing systems.

166
00:11:02,410 --> 00:11:07,720
So we have to think about right
customization that can track prediction,

167
00:11:07,795 --> 00:11:12,930
latency, model performance, and business
impact to provide better insights.

168
00:11:13,430 --> 00:11:17,540
Then we can talk about different
reliability and fault tolerances.

169
00:11:17,540 --> 00:11:20,710
So there are different approaches here.

170
00:11:20,810 --> 00:11:26,840
The circuit breaker patterns when
external data become una unavailable or

171
00:11:26,840 --> 00:11:31,610
internal services experience, degraded
performance circuit breakers can prevent

172
00:11:31,850 --> 00:11:35,190
by isolating the problematic areas.

173
00:11:36,180 --> 00:11:38,550
We can think about graceful
degradation as well.

174
00:11:38,610 --> 00:11:43,230
Strategy might involve serving
cash prices using simplified price

175
00:11:43,230 --> 00:11:47,640
ang pricing algorithms or falling
back to default pricing rules.

176
00:11:48,070 --> 00:11:55,550
When we have issues with the accessing
the AI part, pricing services similar

177
00:11:55,550 --> 00:11:59,970
data application is key because,
synchronous replication for critical

178
00:11:59,970 --> 00:12:04,500
data while using asynchronous
replication for less time sensitive

179
00:12:04,500 --> 00:12:09,040
information can balance performance
and reliability requirements here.

180
00:12:09,380 --> 00:12:14,035
So data replication is key in case
we have accessibility issues and

181
00:12:14,035 --> 00:12:17,510
we want to make sure we have a
fallback fail safe option here.

182
00:12:18,010 --> 00:12:21,430
As we talk about system
architecture, disaster recovery

183
00:12:21,430 --> 00:12:23,180
and health monitoring are key.

184
00:12:23,580 --> 00:12:30,600
Again we should have the ability to
recover if there are issues in one

185
00:12:30,600 --> 00:12:33,780
geography or in one of the systems.

186
00:12:33,840 --> 00:12:35,170
So how we can.

187
00:12:35,670 --> 00:12:41,040
Consider both data restoration and
model state reconstruction, as well

188
00:12:41,040 --> 00:12:45,270
as the time required to rebuild caches
and restore full system performance,

189
00:12:46,200 --> 00:12:47,520
comprehensive health checks.

190
00:12:48,045 --> 00:12:52,095
Health checks must go beyond
simple connectivity tests.

191
00:12:52,665 --> 00:12:56,775
We have to make sure the pricing
system is working as a whole.

192
00:12:57,195 --> 00:13:02,055
So comprehensive checks that not
just look at the connectivity, but

193
00:13:02,055 --> 00:13:08,415
also verify model loading prediction
quality, and also provide real time

194
00:13:08,415 --> 00:13:11,145
insight to into the system health.

195
00:13:11,775 --> 00:13:13,095
And system performance.

196
00:13:13,095 --> 00:13:14,415
I think that's the key here.

197
00:13:14,415 --> 00:13:16,155
So it has to be comprehensive.

198
00:13:16,655 --> 00:13:21,085
Additionally because we're across
geographies, across different systems,

199
00:13:21,085 --> 00:13:27,305
we have customer data that we, we
need to use for pricing, predictions,

200
00:13:27,665 --> 00:13:30,245
security and compliance are key here.

201
00:13:30,575 --> 00:13:32,675
How we are ensuring data protection.

202
00:13:33,185 --> 00:13:39,285
How we are training the models
on the data which essentially

203
00:13:39,285 --> 00:13:44,205
talks about federated learning,
how we ensure regional compliance

204
00:13:44,205 --> 00:13:46,425
when you are across geographies.

205
00:13:46,525 --> 00:13:51,025
Dealing with data for Europe, European
customers, or dealing with data for

206
00:13:51,605 --> 00:13:54,875
north American or Asian customers
every, depending on the region.

207
00:13:54,875 --> 00:13:56,705
We have compliance requirements.

208
00:13:56,705 --> 00:13:59,675
We have to make sure we are
following the regulations.

209
00:14:00,320 --> 00:14:03,680
And with vast amount of data
comes a lot of responsibility.

210
00:14:03,680 --> 00:14:08,090
How we are making sure we have the
right access for the right people and

211
00:14:08,210 --> 00:14:13,410
making sure that we are going with
the role-based access that provides

212
00:14:13,410 --> 00:14:17,040
the right level of granularity
for the right, right stakeholders.

213
00:14:17,100 --> 00:14:18,360
That goes a long way.

214
00:14:18,420 --> 00:14:21,300
And having the right authorization
framework will also go a long way.

215
00:14:21,800 --> 00:14:25,490
With this we talk a little bit about the
operational excellence and monitoring.

216
00:14:25,490 --> 00:14:29,540
So again, we are, for operational
excellence, we need to have

217
00:14:29,600 --> 00:14:32,030
multidimensional monitoring,
which needs to be comprehensive.

218
00:14:32,680 --> 00:14:37,250
Whether it's technical metrics, model
performance, or financial metrics,

219
00:14:37,640 --> 00:14:39,230
we need to monitor all of them.

220
00:14:39,730 --> 00:14:41,170
Incident responses.

221
00:14:41,830 --> 00:14:44,130
What are the automated
mitigation strategies?

222
00:14:44,580 --> 00:14:46,920
What are the escalation procedures?

223
00:14:46,920 --> 00:14:49,260
What are the cross-functional
response teams?

224
00:14:49,890 --> 00:14:52,170
How we do retro and
post incident analysis.

225
00:14:52,170 --> 00:14:53,940
All those things we need to account for.

226
00:14:54,440 --> 00:14:59,830
With that, we talked to a bit
about how the architecture or how

227
00:14:59,830 --> 00:15:02,410
we can build a AI pricing system.

228
00:15:03,070 --> 00:15:06,550
As we know in the world of
ai in pricing, things are

229
00:15:06,550 --> 00:15:09,260
continually continuously evolving.

230
00:15:09,680 --> 00:15:13,820
So there are future trends that
we need to prepare for and we need

231
00:15:13,820 --> 00:15:15,680
to account for as things evolve.

232
00:15:16,180 --> 00:15:20,910
Edge AI capabilities, quantum computing
or real time personalization are the

233
00:15:20,910 --> 00:15:23,165
ones where things are moving very fast.

234
00:15:23,855 --> 00:15:28,855
We have to make sure we are evolving
our architecture and systems and

235
00:15:28,955 --> 00:15:33,415
to handle all those complexity that
get introduced as we make progress

236
00:15:33,415 --> 00:15:34,975
in all those different aspects.

237
00:15:35,475 --> 00:15:41,815
So finally building, as we talked about
it, building a robust, resilient AI

238
00:15:41,845 --> 00:15:47,325
pricing platform is one of the most
challenging engineering problems today.

239
00:15:47,865 --> 00:15:53,225
As we talked about, its direct revenue
impact, how decision is made by

240
00:15:53,225 --> 00:15:57,485
considering data from different systems.

241
00:15:57,585 --> 00:16:01,440
Whether customer data or financial
data or competitor data or market data.

242
00:16:01,940 --> 00:16:05,210
All those things lead to
very nuanced decision making.

243
00:16:05,630 --> 00:16:10,330
That's where our systems, our
architecture they need to balance the

244
00:16:10,330 --> 00:16:14,800
competing demands for performance,
reliability, scalability, and security,

245
00:16:15,340 --> 00:16:19,930
while making sure we are adapting to
the changing business requirements.

246
00:16:20,530 --> 00:16:26,660
As the retail landscape or ma
marketplace landscape evolve the AI

247
00:16:26,690 --> 00:16:31,250
pricing platforms will play a free
role here and they need to evolve

248
00:16:31,400 --> 00:16:35,890
to address some of the challenges we
discussed during this presentation.

249
00:16:36,390 --> 00:16:37,170
Thank you so much.

250
00:16:37,170 --> 00:16:42,520
Appreciate your time and it is a pleasure
sharing some of the thoughts around this

251
00:16:42,520 --> 00:16:44,560
topic that I'm deeply passionate about.

252
00:16:44,680 --> 00:16:45,130
Thank you.

