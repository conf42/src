1
00:00:02,200 --> 00:00:04,560
Hi everyone, and thanks
for joining us today.

2
00:00:04,560 --> 00:00:08,340
I'm excited to talk about a powerful
safety in machine learning operations,

3
00:00:08,820 --> 00:00:13,980
and one that's making a real impact across
the industry as wireless architecture.

4
00:00:14,460 --> 00:00:18,630
Over the next few minutes, I will
show you how this modern approach to

5
00:00:18,630 --> 00:00:22,860
infrastructure is not just a buzzword,
it's delivering serious results.

6
00:00:23,250 --> 00:00:26,549
Organizations are stressing
operational cost while doubling

7
00:00:26,549 --> 00:00:29,769
the speed at which they'll deploy
the machine learning models.

8
00:00:30,309 --> 00:00:34,565
We'll work you through the core
principles of wireless AI share

9
00:00:34,565 --> 00:00:40,624
findings from or cost industry research
and give you the practical framework

10
00:00:40,934 --> 00:00:44,444
that has been like proven in real
order, real world implementation.

11
00:00:44,444 --> 00:00:49,104
So you can take these ideas and apply
them right away in your organizations.

12
00:00:50,104 --> 00:00:51,324
Before we dive in.

13
00:00:51,444 --> 00:00:52,524
Let's have a quick intro.

14
00:00:52,554 --> 00:00:59,504
I'm KU and I have spent past few years
working at intersections of ai, cloud

15
00:00:59,504 --> 00:01:02,834
architecture, enterprise transformations,
machine learning, et cetera.

16
00:01:03,404 --> 00:01:06,644
You can find my contact details
and LinkedIn here on the slide.

17
00:01:07,184 --> 00:01:11,164
So I am always open to connecting and
answering the questions and continuing

18
00:01:11,534 --> 00:01:13,394
the conversations after the sessions.

19
00:01:13,694 --> 00:01:15,419
So feel free to reach out to me.

20
00:01:16,419 --> 00:01:18,189
Let's look at the real impact.

21
00:01:18,289 --> 00:01:21,359
Serverless machine learning is
having organizations ing serverless

22
00:01:21,359 --> 00:01:26,379
architecture are seeing a huge improvement
starting with a 65% reduction in

23
00:01:26,379 --> 00:01:27,999
infrastructure management over it.

24
00:01:28,359 --> 00:01:33,439
That means less time spent on maintenance
and more time focused on innovations.

25
00:01:33,979 --> 00:01:37,699
On average, they're also seeing
like a 40% in cost savings compared

26
00:01:37,699 --> 00:01:39,229
to traditional deployment methods.

27
00:01:39,619 --> 00:01:43,899
But perhaps most exciting models,
deployments has jumped three and put times

28
00:01:44,289 --> 00:01:48,939
annually, and teams are able to iterate
and see models faster than ever before.

29
00:01:49,359 --> 00:01:51,949
And it is not just a,
backend improvements.

30
00:01:52,249 --> 00:01:57,009
Users engagement is up to 28% since
in products that have implemented

31
00:01:57,419 --> 00:02:01,829
serverless AI and showing a get link
between the architecture and end user

32
00:02:01,829 --> 00:02:07,129
impact what this tells us is simple
serverless doesn't just make these,

33
00:02:07,129 --> 00:02:08,619
make the things more efficient.

34
00:02:08,649 --> 00:02:12,150
It unlocks scales and speed
strategic focus for data teams.

35
00:02:13,150 --> 00:02:17,340
These slides really highlights one
of the most dramatic benefits of

36
00:02:17,340 --> 00:02:19,140
going serverless deployment speed.

37
00:02:19,440 --> 00:02:22,860
Traditionally deploying a machine
learning models could take around two to

38
00:02:22,860 --> 00:02:26,810
three weeks with the team stacks in the
cycles of provisioning infrastructure.

39
00:02:27,420 --> 00:02:31,550
And configuring the environments and
setting up the manual, scaling with

40
00:02:31,550 --> 00:02:35,840
a serverless transitions, those steps
has rings to about three to five days.

41
00:02:35,840 --> 00:02:39,140
And team focus on the things like
the configuring the API gateway,

42
00:02:39,140 --> 00:02:42,260
containerizing functions and
integrating with the cloud provider.

43
00:02:42,560 --> 00:02:46,860
But the real magic happens once
you, you are really serverless and

44
00:02:46,910 --> 00:02:49,790
deployments are dropped to just
two to four hours on an average.

45
00:02:50,155 --> 00:02:51,655
So everything is automated.

46
00:02:51,685 --> 00:02:55,255
There's no infrastructure to manage
and scaling happens in Stanley.

47
00:02:55,765 --> 00:02:59,045
So this kind of speeds
is not just nice to have.

48
00:02:59,045 --> 00:03:04,265
It's a really competitive age and in
industry where rapid iterations and AI

49
00:03:04,265 --> 00:03:06,905
driven features define the market leaders.

50
00:03:07,355 --> 00:03:11,225
So the ability to see models in hours
instead of weeks is a game changer.

51
00:03:12,225 --> 00:03:15,045
These slides focus on the financial side.

52
00:03:15,075 --> 00:03:19,515
This bar chart breaks down exactly
where server list machine learning

53
00:03:19,905 --> 00:03:21,525
earn its repetitions for cost savings.

54
00:03:21,825 --> 00:03:26,025
On average, organizations are seeing
like a 40% reductions in cost compared

55
00:03:26,025 --> 00:03:30,915
to traditional machine learning
deployments, and it's not just a one area.

56
00:03:31,155 --> 00:03:34,835
The savings came from poor
key fronts like infrastructure

57
00:03:35,175 --> 00:03:37,095
maintenance scalings, and DevOps.

58
00:03:37,365 --> 00:03:41,115
With serverless, you would not need to
verbal poisoning Hardware maintenance

59
00:03:41,115 --> 00:03:45,815
is minimum and scaling is automatic,
and DevOps efforts are dropped like

60
00:03:46,085 --> 00:03:48,875
dramatically, and by using the tool.

61
00:03:49,650 --> 00:03:53,310
What really stand out here
is the paper use model.

62
00:03:53,700 --> 00:03:57,920
So it's a perfect fit for the
machine learning where the workloads

63
00:03:57,920 --> 00:04:01,880
often spikes around training or
deployment, but remain ideal.

64
00:04:01,880 --> 00:04:06,380
In between serverless ensures that you
are only paying for what you use, which

65
00:04:06,380 --> 00:04:10,730
means no wasted spend during during the
downtime and full powers when you need it.

66
00:04:11,730 --> 00:04:11,940
Great.

67
00:04:12,090 --> 00:04:16,400
And these slides really showcases
like one of the core strengths of

68
00:04:16,850 --> 00:04:18,130
serverless for machine learning.

69
00:04:18,520 --> 00:04:22,440
One of the most powerful features of the
serverless machine learning is elastic

70
00:04:22,440 --> 00:04:24,685
scaling, and the pyramids is break down.

71
00:04:24,735 --> 00:04:25,215
Break it down.

72
00:04:25,615 --> 00:04:28,115
I. And the top, you have
the peak performance.

73
00:04:28,145 --> 00:04:31,145
Serverless systems can automatically
handle thousands of concurrent

74
00:04:31,145 --> 00:04:36,255
predictions request without skipping
a bit and be of that like a dynamic

75
00:04:36,255 --> 00:04:40,605
scalings and the ability to instantly
adjust to realtime traffic changes.

76
00:04:40,605 --> 00:04:44,215
So there is no mini manual
tunings or the planning needed.

77
00:04:44,575 --> 00:04:48,955
Then we have the predictive capacity, some
systems, even the village machine learning

78
00:04:49,495 --> 00:04:53,604
themselves to anticipate usage pattern
and allocate resources ahead of demand.

79
00:04:54,205 --> 00:04:56,335
Finally, it's all sits on a cloud.

80
00:04:56,335 --> 00:04:59,755
Foundations distributed across the
multiple availability zones for

81
00:04:59,755 --> 00:05:01,015
resilience and the performance.

82
00:05:01,825 --> 00:05:06,025
What that means, like in practice,
it's simple and organizations no longer

83
00:05:06,025 --> 00:05:10,515
have to over poison infrastructure
just in case of a traffic spike.

84
00:05:10,995 --> 00:05:16,229
And during real world like 10 time
traffic search serverless machine

85
00:05:16,229 --> 00:05:20,060
learning systems maintained stable
and low latency responses and

86
00:05:20,060 --> 00:05:23,224
delivering consistent consistent AI
performance when it matters most.

87
00:05:24,224 --> 00:05:28,014
These slides connect the technical
improvements to real business outcomes.

88
00:05:28,284 --> 00:05:30,804
Now let's talk about the
operational efficiencies.

89
00:05:30,804 --> 00:05:35,605
Because serverless is not just about
the savings times or money, it's also

90
00:05:35,995 --> 00:05:38,094
about doing more with the same team.

91
00:05:38,485 --> 00:05:40,675
Organizations are moved to the serverless.

92
00:05:40,675 --> 00:05:44,395
Were able to deploy 3.4
times more models annually.

93
00:05:44,730 --> 00:05:49,590
That's a massive leap in, in output and
it changed how fast team can respond

94
00:05:49,830 --> 00:05:51,690
to new opportunity and challenges.

95
00:05:51,960 --> 00:05:55,710
So looking at the pie chart here,
deploying velocity improved by 72%,

96
00:05:55,740 --> 00:05:59,640
giving team the ability to seep
updates and improvements faster.

97
00:06:00,000 --> 00:06:03,800
Model diversity increased to build
in support for multiple frameworks

98
00:06:03,800 --> 00:06:06,110
like a Inflow, py Tots, and others.

99
00:06:07,035 --> 00:06:10,965
The continuous deployment has become the
norm with the automated CI I CT pipelines,

100
00:06:11,115 --> 00:06:14,865
reducing the friction from experimentation
and through the protections.

101
00:06:15,405 --> 00:06:16,815
And then finally, more rapid.

102
00:06:17,355 --> 00:06:22,185
It since unlocked the new innovation
potentials leading to smarter and more

103
00:06:22,305 --> 00:06:28,275
adaptive PI features, and it's pay
off organizations saw like a 28% boost

104
00:06:28,275 --> 00:06:31,995
in user engagement after implementing
these serverless powered AI features.

105
00:06:31,995 --> 00:06:35,655
And that's a direct line from
architecture to business impact.

106
00:06:36,655 --> 00:06:39,385
This is a great slide actually
for grounding the strategy

107
00:06:39,835 --> 00:06:41,425
in a real world architecture.

108
00:06:41,875 --> 00:06:46,445
So here we are looking at a layered
architectural pattern that emerged

109
00:06:46,445 --> 00:06:49,115
as a best practice for serverless
machine learning deployments.

110
00:06:49,685 --> 00:06:53,765
Starting with the data ions layer,
everything is the event driven from the

111
00:06:53,765 --> 00:06:57,424
streaming data to automatic features
extraction and optimized storage.

112
00:06:57,695 --> 00:07:00,844
These NCOs raw data is immediately
usable for the machine learning.

113
00:07:01,114 --> 00:07:06,570
Next, the model training layers use
really uses like a thermal compute

114
00:07:06,640 --> 00:07:11,550
meaning compute resource spin up, like
only when it need and, we can get on

115
00:07:11,550 --> 00:07:16,170
demand, GPU, access and hyper parameter
during functions and ability to scale

116
00:07:16,220 --> 00:07:19,570
scale out the distributed training jobs
without managing the infrastructure.

117
00:07:19,900 --> 00:07:21,970
Then we move to the in finance layer.

118
00:07:23,260 --> 00:07:27,150
So where we train models are
containerized and start behind

119
00:07:27,150 --> 00:07:28,560
the behind an API gateway.

120
00:07:29,310 --> 00:07:32,760
We can have automatic scaling in
points and model problem worsening

121
00:07:33,090 --> 00:07:36,830
and testing, casting for high
frequency queries, all fully managed.

122
00:07:37,159 --> 00:07:41,340
Finally, the monitoring layer
and the ties it all together with

123
00:07:41,340 --> 00:07:46,200
performance in ES and model drifting
detections and even automated

124
00:07:46,205 --> 00:07:51,345
returning triggers so your models stay
accurate and relevant over the time.

125
00:07:51,780 --> 00:07:55,860
Structure allows teams to scale and
optimize each part of the machine learning

126
00:07:55,920 --> 00:08:00,180
lifecycles independently, while still
benefiting from the flexibility and

127
00:08:00,180 --> 00:08:02,130
the simplicity of serverless computing.

128
00:08:03,130 --> 00:08:06,160
This slide ties everything
together by showing the real

129
00:08:06,160 --> 00:08:08,290
world impacts across the sector.

130
00:08:08,290 --> 00:08:09,070
Let's wrap up.

131
00:08:09,655 --> 00:08:13,435
The core content by looking at how
these serverless machine learning

132
00:08:13,435 --> 00:08:17,605
strategies are being applied across
the different industries, each with

133
00:08:17,655 --> 00:08:19,305
their own unique challenges and goals.

134
00:08:20,115 --> 00:08:24,105
So in financial services, like
serverless, machine learning is a power

135
00:08:24,155 --> 00:08:30,035
is powering like a four detection system
that reduce pulse positive by 34%.

136
00:08:30,035 --> 00:08:32,995
Even as transactions
volumes increase five times.

137
00:08:33,610 --> 00:08:38,020
These models runs in real time and
continuously adapting to new for better,

138
00:08:38,020 --> 00:08:40,210
no time, downtime, and no batch deal.

139
00:08:41,020 --> 00:08:45,840
So in healthcare, serverless functions
are being used for medical imaging

140
00:08:45,940 --> 00:08:48,400
imaging analysis, what used to take days.

141
00:08:48,500 --> 00:08:50,330
Can now be done in a minute.

142
00:08:50,780 --> 00:08:55,010
So these systems scales automatically
to meet the patient's volume and

143
00:08:55,010 --> 00:08:58,350
the remain remain hipaa compliant,
which is like health insurance.

144
00:08:58,350 --> 00:09:02,300
Portability and accountability Act
compliant even with the massive data

145
00:09:02,300 --> 00:09:04,230
sets and distributed processing.

146
00:09:04,770 --> 00:09:08,700
And in a rural companies are using like
a serverless machine learning to deliver

147
00:09:09,000 --> 00:09:11,270
hyper hyper-personalized recommendations.

148
00:09:12,365 --> 00:09:15,785
And these have been like a 23%
boost in average order values.

149
00:09:15,785 --> 00:09:19,325
Thanks to the model that updates
continuously in real time.

150
00:09:19,775 --> 00:09:22,665
This also supports season
seasonal forecastings and

151
00:09:22,725 --> 00:09:23,985
the inventory optimization.

152
00:09:23,985 --> 00:09:29,350
So the key takeaway here is while the
underling server serverless principles

153
00:09:29,350 --> 00:09:32,950
are the same, implementing the
strategies must align with the industry

154
00:09:32,950 --> 00:09:35,180
specific needs whether it is compliant.

155
00:09:35,825 --> 00:09:38,165
And the speed and the customer experience.

156
00:09:39,165 --> 00:09:42,255
These slides focus on how
to refine the performance.

157
00:09:42,255 --> 00:09:46,485
So performance optimizations is a
key of getting like the most out

158
00:09:46,485 --> 00:09:49,725
of serverless machine learning,
especially as the workload skills.

159
00:09:49,950 --> 00:09:53,530
So let's dive into some technicals
some techniques that have been

160
00:09:53,530 --> 00:09:57,750
proven to make the big difference
and faster the model compresses.

161
00:09:57,750 --> 00:10:01,385
So by using this technique like
quantization pounding and knowledge

162
00:10:01,455 --> 00:10:05,965
distillations, so you can reduce
like the model size up to 60 to 80%.

163
00:10:05,995 --> 00:10:09,955
This helps you to fit your models within
the serverless deployment constant

164
00:10:09,955 --> 00:10:12,095
without sacrificing the performance.

165
00:10:12,440 --> 00:10:14,750
Then we have the cold start mitigation.

166
00:10:14,750 --> 00:10:19,310
So serverless environments often faced
like latency users where when functions

167
00:10:19,310 --> 00:10:25,000
have to warm up and to solve this you can
implement the warm pooling strategies and

168
00:10:25,120 --> 00:10:29,840
preload carbon models and manage functions
concurrency to minimize these impacts.

169
00:10:30,350 --> 00:10:32,330
Memory optimizations is another big win.

170
00:10:32,685 --> 00:10:35,775
Right sizing, memory allocations
based on the model needs to ensure

171
00:10:36,135 --> 00:10:39,135
that you are not over poisoning
or underutilizing resources.

172
00:10:39,135 --> 00:10:44,285
So pr that with adaptive batch, adaptive
batching to maximize throughputs.

173
00:10:44,285 --> 00:10:46,215
And you have what a lean
and efficient setup.

174
00:10:46,515 --> 00:10:50,715
Finally casting strategy by using
like a multilevel casting at the API

175
00:10:50,745 --> 00:10:53,985
gateway functions and the database
layer, he would reduce redundant

176
00:10:54,255 --> 00:10:58,425
computations and is spliting up the
inference times and the lowering loads.

177
00:10:58,980 --> 00:11:02,600
So now what the, is like companies
use using these strategies reported

178
00:11:02,600 --> 00:11:06,770
as 65% improvement in response type
and additional 25% cost deductions

179
00:11:07,190 --> 00:11:09,780
beyond the initial serverless savings.

180
00:11:09,870 --> 00:11:14,140
The base results comes when you
combine several of this techniques

181
00:11:14,140 --> 00:11:17,890
and tailored to the specific models
and usage pattern in your environment.

182
00:11:18,890 --> 00:11:21,410
These slides provide a
step by step roadmap.

183
00:11:21,510 --> 00:11:26,280
So our deliveries would be clear
and structures and successful server

184
00:11:26,280 --> 00:11:29,990
list lesson learning adoption doesn't
mean starting from the scratch.

185
00:11:30,650 --> 00:11:34,940
So the key smooth migrations is
integrating serverless capabilities with

186
00:11:34,940 --> 00:11:36,980
your existing machine learning workflows.

187
00:11:37,400 --> 00:11:39,820
And it can be done in three main phases.

188
00:11:40,090 --> 00:11:42,130
The faster is the assessment phase.

189
00:11:42,400 --> 00:11:47,635
This is where you evaluate your current
machine learning workloads to identify

190
00:11:47,635 --> 00:11:50,515
the candidates for serverless migrations.

191
00:11:51,115 --> 00:11:55,395
Focus on models with variable
inference pattern or those that

192
00:11:55,395 --> 00:11:56,865
require the frequent updates.

193
00:11:56,865 --> 00:12:01,095
So you will want to perform like cos
benefit analysis to determine the best

194
00:12:01,545 --> 00:12:06,005
workloads for migrations taking into
the account usage pattern and scaling

195
00:12:06,005 --> 00:12:07,745
needs and any technical constant.

196
00:12:08,315 --> 00:12:12,185
Once you have assessed and it's the
time to start the pilot implementation.

197
00:12:12,185 --> 00:12:15,835
So begin by migrating the non-critical
models to minimize the risk.

198
00:12:16,165 --> 00:12:19,855
During this phase, you will refactor
the model for the serverless deployments

199
00:12:20,245 --> 00:12:23,995
and establish the performance baseline
and implement the CICD pipelines

200
00:12:23,995 --> 00:12:25,735
for the automated deployment.

201
00:12:25,960 --> 00:12:29,690
Key task here is to include like
the containerizing, your models

202
00:12:30,080 --> 00:12:33,500
and configuring like cloud services
and setting up the monitoring

203
00:12:33,500 --> 00:12:34,580
to track the performance.

204
00:12:34,910 --> 00:12:38,010
The scale and optimize
phase comes after the pilot.

205
00:12:38,370 --> 00:12:41,520
Once you have seen the success
with the initial model, expand

206
00:12:41,820 --> 00:12:43,020
to additional workloads.

207
00:12:43,350 --> 00:12:47,760
This phase is all about like fine tuning,
optimizing the performance, and creating

208
00:12:47,760 --> 00:12:52,560
the inter internal based practices as
you move like higher value models into

209
00:12:52,560 --> 00:12:56,220
the product sense and document everything
to yeah, across the team and ensure

210
00:12:56,220 --> 00:12:58,010
those smooth transit smooth transitions.

211
00:12:59,765 --> 00:13:03,485
And our research source like that
following this phased approach,

212
00:13:03,485 --> 00:13:08,155
reduce like migrations risk and
after it's time to value in fact 87%

213
00:13:08,155 --> 00:13:11,540
of pilot project made into the full
production within just three months.

214
00:13:12,540 --> 00:13:16,135
To wrap it up, let's go over the
key takeaway and the next steps.

215
00:13:16,435 --> 00:13:20,675
So first, when we are starting like your
our server list machine learning journey

216
00:13:21,005 --> 00:13:25,035
focus on the interference workload with
the variable traffic pattern, these

217
00:13:25,035 --> 00:13:28,875
are often like the best candidates to
see immediate 20 feed, such as improved

218
00:13:28,875 --> 00:13:30,435
cost efficiency and the scalability.

219
00:13:30,795 --> 00:13:36,145
Next make your the implementation focus
specific to your models, prioritizing,

220
00:13:36,205 --> 00:13:39,865
like the optimizations techniques
that align with the characteristics

221
00:13:39,910 --> 00:13:44,565
of the, of your workloads, whether
it's model compressions cold

222
00:13:44,565 --> 00:13:46,605
start mitigations, or the casting.

223
00:13:47,455 --> 00:13:50,655
Lastly for the long-term success,
develop a comprehensive serverless

224
00:13:50,655 --> 00:13:51,615
machine learning roadmap.

225
00:13:51,615 --> 00:13:54,155
This will guide your migrations and NCO.

226
00:13:54,155 --> 00:13:59,265
The serverless principles are open into
your long-term, long-term AI strategy.

227
00:13:59,535 --> 00:14:04,755
In summary, serverless architecture
are is levelizing like how

228
00:14:04,755 --> 00:14:06,885
organizations deploy and skills ai.

229
00:14:07,215 --> 00:14:11,315
It can, it can reduce the cost by
40%, and organizations are deploying

230
00:14:11,315 --> 00:14:13,945
3.4 times more models annually.

231
00:14:14,215 --> 00:14:17,785
The elastic scaling handles the
unpredictable traffic and empowers

232
00:14:18,115 --> 00:14:22,580
data science teams to focus on what
they do based on the innovations.

233
00:14:23,510 --> 00:14:28,960
So to get started, identify a few high
impact interv interference workload from

234
00:14:28,960 --> 00:14:33,590
a small cross-functional team, and develop
proof of concept using the architectural

235
00:14:33,590 --> 00:14:35,090
pattern we have discussed today.

236
00:14:35,390 --> 00:14:39,320
And measure your result against the
established baseline and use those

237
00:14:39,320 --> 00:14:42,790
inside to build your comprehensive
serverless machine learning roadmap.

238
00:14:43,790 --> 00:14:48,900
Thank you all for your time and
at today, and I hope you found the

239
00:14:49,320 --> 00:14:52,470
insights on several latest machine
learning valuable and that you are

240
00:14:52,470 --> 00:14:56,300
excited to explore how this approach
can transform your organizations.

241
00:14:56,330 --> 00:14:59,450
If you have any questions
or you would like to discuss

242
00:14:59,450 --> 00:15:00,890
further, feel free to reach out.

243
00:15:00,940 --> 00:15:02,230
To me after the presentation.

244
00:15:02,230 --> 00:15:05,530
I am happy to connect and my
LinkedIn details are already in

245
00:15:05,530 --> 00:15:09,810
the very beginning of the slides
so you can, and thanks again.

246
00:15:09,900 --> 00:15:14,200
I look forward to hearing you about
your serverless journeys, and thank you.

