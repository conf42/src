1
00:00:00,500 --> 00:00:01,850
Speaker 24: Hi, my name's Rohan Mitra.

2
00:00:01,940 --> 00:00:04,550
I'm a product manager at
Phonepay, a Walmart company.

3
00:00:05,359 --> 00:00:09,000
Today I am here to talk about
how the 10 page PRD is dead.

4
00:00:09,150 --> 00:00:12,510
But by coding your way into
production is a recipe for kiosk.

5
00:00:12,960 --> 00:00:16,470
Today we are defining the modern
AI spec, a decision engine designed

6
00:00:16,470 --> 00:00:20,190
to turn on technical ambiguity
into high performing AI products.

7
00:00:20,689 --> 00:00:21,589
Good morning everyone.

8
00:00:21,859 --> 00:00:22,909
It's great to be here.

9
00:00:23,509 --> 00:00:24,529
Let's dive right in.

10
00:00:25,264 --> 00:00:28,354
So let's start with the big question
that's been all over our feeds lately

11
00:00:28,804 --> 00:00:33,485
is the humble, but my TPRD dead, you've
probably seen the debates kicked off

12
00:00:33,485 --> 00:00:35,224
by Ditas like mother guru at Google.

13
00:00:35,854 --> 00:00:39,364
He tweeted recently that they're moving
from writing first culture to a building.

14
00:00:39,364 --> 00:00:39,935
First one.

15
00:00:40,684 --> 00:00:44,884
He made a great point really writing
used to be a proxy for clear thinking

16
00:00:44,884 --> 00:00:46,474
when development cycles belong.

17
00:00:46,985 --> 00:00:50,194
But now when you can white code
a prototype in the same time it

18
00:00:50,194 --> 00:00:52,354
takes to write a doc by write.

19
00:00:53,164 --> 00:00:55,715
And honestly, at some
level we can all feel this.

20
00:00:56,134 --> 00:01:00,425
She hold 40 page VRD that sits unread
in a folder after that first email.

21
00:01:00,664 --> 00:01:02,194
And at best, a handoff call.

22
00:01:02,794 --> 00:01:06,634
That's probably a thing of the
past, but this new build first

23
00:01:06,634 --> 00:01:08,375
world has its own set of problems.

24
00:01:08,854 --> 00:01:09,815
It can be chaotic.

25
00:01:10,535 --> 00:01:14,524
It's easy to fall into the feature
factory trap, build things fast,

26
00:01:15,065 --> 00:01:19,384
but not building the right things or
building things that we can't measure.

27
00:01:19,744 --> 00:01:22,384
And what you can't measure, can't succeed.

28
00:01:23,255 --> 00:01:26,705
I am someone who identifies as a
vibe coder myself, and hence, I also

29
00:01:26,705 --> 00:01:31,234
know firsthand that having the right
documentation and specs for both human

30
00:01:31,294 --> 00:01:35,464
as well as agentic coding is more
important today than ever before.

31
00:01:35,964 --> 00:01:39,115
So if the old PD is too slow
and vibe coding alone is too

32
00:01:39,115 --> 00:01:40,705
risky, what's the answer?

33
00:01:41,455 --> 00:01:44,845
I believe it's a new kind of
document, and it's not a manuscript,

34
00:01:45,145 --> 00:01:46,494
it's a decision making tool.

35
00:01:47,095 --> 00:01:49,914
It's something I call the modern AI spec.

36
00:01:50,414 --> 00:01:54,854
So while the PRD dying, it's
because we've seen all seen ex doc

37
00:01:54,884 --> 00:01:56,534
examples of documents like these.

38
00:01:57,074 --> 00:02:01,004
This got out bo, what I call
the wide space spec, is to

39
00:02:01,004 --> 00:02:02,114
look at the first example.

40
00:02:02,614 --> 00:02:06,184
The problem statement has been defined
as the returns are a big problem.

41
00:02:06,845 --> 00:02:10,114
Goal is to improve customer's
experience with returns.

42
00:02:10,684 --> 00:02:12,905
These aren't decisions, they're wishes.

43
00:02:13,405 --> 00:02:15,265
Returns are a big
problem for our business.

44
00:02:15,475 --> 00:02:19,845
How big improve customer experience
By how much compared to what

45
00:02:19,845 --> 00:02:22,185
Baseline decreased refund rates.

46
00:02:22,635 --> 00:02:24,015
Are there any guardrails around?

47
00:02:24,015 --> 00:02:25,425
It Doesn't look like it.

48
00:02:25,925 --> 00:02:29,135
Let's look at the other example
on which is probably even better.

49
00:02:29,615 --> 00:02:33,220
The AI behavior spec is
generate helpful replies.

50
00:02:33,720 --> 00:02:35,070
Generate helpful replies.

51
00:02:35,350 --> 00:02:36,400
What does that even mean?

52
00:02:36,610 --> 00:02:40,630
What's helpful for one may not be
helpful for another and my personal

53
00:02:40,630 --> 00:02:43,120
favorite, start small, then run.

54
00:02:43,620 --> 00:02:45,270
There's a masterclass in saying nothing.

55
00:02:45,660 --> 00:02:49,325
These documents are full of
words, but they're of decisions.

56
00:02:49,825 --> 00:02:52,915
The ambiguity is the single
biggest source of wasted sprints

57
00:02:52,915 --> 00:02:54,835
and confused data science teams.

58
00:02:55,405 --> 00:02:57,115
The antidote isn't no document.

59
00:02:57,715 --> 00:03:01,375
It's a document that forces clarity,
and that's what we are here to build.

60
00:03:01,875 --> 00:03:03,135
So this is the framework.

61
00:03:03,434 --> 00:03:04,934
This is our modern AI spec.

62
00:03:05,565 --> 00:03:10,274
It's adapted from the best practices
at teams, from companies like mop,

63
00:03:10,575 --> 00:03:14,475
ai, meta, and Google, as well as
what I use every day at my work.

64
00:03:15,210 --> 00:03:20,100
It moves us away from generic requirements
and focuses on the five specific things

65
00:03:20,100 --> 00:03:22,800
that actually make or break AI projects.

66
00:03:23,640 --> 00:03:25,620
Number one, opportunity framing.

67
00:03:26,280 --> 00:03:28,230
Why are we even doing
this in the first place?

68
00:03:28,800 --> 00:03:30,630
Number two, behavior contract.

69
00:03:31,080 --> 00:03:33,000
What does good actually look like?

70
00:03:33,480 --> 00:03:35,100
Number three, evaluation.

71
00:03:35,670 --> 00:03:38,490
How do we prove it works
before even before we ship?

72
00:03:39,150 --> 00:03:41,310
Number four, boundaries and scope.

73
00:03:41,894 --> 00:03:43,635
What are the trade-offs we are accepting?

74
00:03:43,695 --> 00:03:46,274
What are some non goals that
are out of scope for this?

75
00:03:46,935 --> 00:03:49,125
And number five, risks and recovery.

76
00:03:49,695 --> 00:03:50,834
What are the risks?

77
00:03:51,034 --> 00:03:52,684
What is our contingency plan?

78
00:03:52,954 --> 00:03:54,274
What is our code switch?

79
00:03:54,774 --> 00:03:58,609
We're going to deep dive and demo all of
these in a moment, but I want to zoom in

80
00:03:58,609 --> 00:04:03,114
on the two pillars that are completely
unique to AI products, the behavior

81
00:04:03,114 --> 00:04:05,664
contract, and their evaluation plan.

82
00:04:06,164 --> 00:04:08,024
So let's look at the second pillar.

83
00:04:08,024 --> 00:04:09,884
Number two, the behavior contract.

84
00:04:10,694 --> 00:04:12,524
In traditional software, you write logic.

85
00:04:12,944 --> 00:04:15,044
If user clicks button open model.

86
00:04:15,584 --> 00:04:17,714
In ai, you can't really write logic.

87
00:04:17,924 --> 00:04:19,724
You have to describe a personality.

88
00:04:20,384 --> 00:04:23,864
If you just write, generate
helpful replies, you have failed.

89
00:04:24,614 --> 00:04:26,444
Your engineer doesn't
know what that means.

90
00:04:26,624 --> 00:04:28,484
He doesn't know what to prompt to the ai.

91
00:04:29,265 --> 00:04:31,724
The behavior contract
solves this with examples.

92
00:04:32,234 --> 00:04:35,054
Look at this real example
from a smart reply spec.

93
00:04:35,324 --> 00:04:35,744
Good?

94
00:04:35,954 --> 00:04:36,254
Yes.

95
00:04:36,254 --> 00:04:39,734
Sending by 4:00 PM brief
and actionable bad.

96
00:04:40,184 --> 00:04:42,104
I will send you the things you asked for.

97
00:04:42,434 --> 00:04:46,544
It sounds robotic, probably
vague and reject any mention

98
00:04:46,544 --> 00:04:48,044
of confidential project names.

99
00:04:48,944 --> 00:04:50,444
This isn't just documentation.

100
00:04:50,714 --> 00:04:54,584
This is you, the product manager, defining
the soul of the product so that the

101
00:04:54,584 --> 00:04:56,474
engineer can tune the model to match it.

102
00:04:56,974 --> 00:04:58,384
Next is the big.

103
00:04:58,684 --> 00:05:00,304
Next is the evaluation plan.

104
00:05:00,994 --> 00:05:04,684
This is the part that usually gets kept
in white coding, and it's one of the

105
00:05:04,684 --> 00:05:07,414
biggest reasons that products fail in ai.

106
00:05:07,414 --> 00:05:09,274
It works on my laptop, means nothing.

107
00:05:09,754 --> 00:05:12,184
You need a rigorous way to
graduate, a feature from an

108
00:05:12,184 --> 00:05:14,674
idea to production in what?

109
00:05:14,674 --> 00:05:19,594
I make it more, less
probabilistic and more objective.

110
00:05:20,434 --> 00:05:21,364
Deterministic.

111
00:05:22,099 --> 00:05:24,019
We call this the evaluation ladder.

112
00:05:24,859 --> 00:05:26,239
Step one, offline.

113
00:05:26,719 --> 00:05:31,579
Before we show a single user, we test
against a golden set, 500 perfect examples

114
00:05:31,579 --> 00:05:34,459
that we align and agree on human review.

115
00:05:34,639 --> 00:05:36,349
Then we look at the output.

116
00:05:36,679 --> 00:05:37,609
Does it feel right?

117
00:05:37,909 --> 00:05:39,049
Is it hallucinating?

118
00:05:39,409 --> 00:05:40,579
We sort of eyeball it.

119
00:05:41,269 --> 00:05:42,919
Step three is online guardrails.

120
00:05:42,969 --> 00:05:44,889
When we go live, we set guardrails.

121
00:05:45,219 --> 00:05:45,699
For example.

122
00:05:45,699 --> 00:05:47,589
It doesn't matter how
fast the rep applies, are.

123
00:05:47,979 --> 00:05:52,089
If the block message rate goes up
by even 0.3%, we kill the feature.

124
00:05:52,689 --> 00:05:55,749
And this is really what the difference
is between a prototype and a product.

125
00:05:56,259 --> 00:05:59,439
A prototype has vibes, a
product has a passing bar.

126
00:05:59,939 --> 00:06:00,929
Alright, enough talk.

127
00:06:01,199 --> 00:06:02,579
Let's put this into practice.

128
00:06:03,209 --> 00:06:05,189
Instead of talking about it, let's do it.

129
00:06:05,189 --> 00:06:08,369
Remember that smart reply
spec that we laughed at?

130
00:06:08,869 --> 00:06:11,029
Remember that smart reply
spec that we laughed at?

131
00:06:11,899 --> 00:06:12,139
Let's.

132
00:06:12,639 --> 00:06:14,979
The one where the goal was
to just improve engagement.

133
00:06:15,249 --> 00:06:16,809
We are going to rescue that project.

134
00:06:17,199 --> 00:06:20,919
We are going to rewrite that spec right
now, using our five pillar framework.

135
00:06:21,419 --> 00:06:22,590
We open a new doc.

136
00:06:23,090 --> 00:06:27,664
Smart replies, but better respect.

137
00:06:28,164 --> 00:06:31,614
All right, so let's fix that broken
smart reply spec that we saw earlier.

138
00:06:31,944 --> 00:06:34,164
I'm going to start with a
blank five pillar template.

139
00:06:34,664 --> 00:06:37,864
The first step was opportunity framing.

140
00:06:38,364 --> 00:06:44,234
So here we clearly call out the
user problem first PM response

141
00:06:44,234 --> 00:06:48,674
times average, whatever, eight.

142
00:06:49,439 --> 00:06:55,979
Point three minutes creating,
lemme just get this communication.

143
00:06:56,479 --> 00:06:59,059
Communication friction.

144
00:06:59,559 --> 00:07:00,719
Alright, so what are we saying?

145
00:07:00,770 --> 00:07:02,239
What will happen if we do this?

146
00:07:02,989 --> 00:07:04,099
If we solve this problem?

147
00:07:04,369 --> 00:07:04,909
Hypothesis.

148
00:07:05,409 --> 00:07:11,440
If we offer three context,
sorry, aware suggestions.

149
00:07:11,940 --> 00:07:15,840
P 50 reply times drop by.

150
00:07:16,739 --> 00:07:18,569
Greater than or equal to 10%.

151
00:07:19,289 --> 00:07:21,469
So 10% see the difference.

152
00:07:21,469 --> 00:07:25,429
Now we have a baseline and a
target that we can aim for.

153
00:07:25,929 --> 00:07:27,609
Next is the behavior.

154
00:07:28,109 --> 00:07:29,650
Behavior contract.

155
00:07:30,150 --> 00:07:32,785
This is where we kill the
ambiguity first, the numbers.

156
00:07:33,765 --> 00:07:37,415
Proxy metric, smart reply.

157
00:07:38,165 --> 00:07:39,185
Adoption

158
00:07:39,685 --> 00:07:46,765
rates greater than or equal
to 25% guardrail metric.

159
00:07:47,265 --> 00:07:48,945
These are based, these are hygiene.

160
00:07:49,095 --> 00:07:50,145
There's nothing new.

161
00:07:51,015 --> 00:07:55,905
But we are explicitly saying we want
adoption, but not at the care cost of.

162
00:07:56,405 --> 00:07:58,205
Let's define what that cost is.

163
00:07:58,705 --> 00:08:02,365
Point three, percentage
points versus control.

164
00:08:02,865 --> 00:08:06,405
So we are saying that we want adoption,
but not at the cost of annoying users to

165
00:08:06,405 --> 00:08:07,935
the point that they actually block people.

166
00:08:08,625 --> 00:08:12,635
Another example then this
is crucial, a good response.

167
00:08:13,135 --> 00:08:13,915
Yes.

168
00:08:13,975 --> 00:08:18,505
Sending it by 4:00 PM for a Pacific time.

169
00:08:19,005 --> 00:08:20,835
Actionable, specific.

170
00:08:21,335 --> 00:08:23,645
Let's do a bad response next.

171
00:08:23,645 --> 00:08:25,055
Bad response.

172
00:08:25,555 --> 00:08:26,875
That's a bad response.

173
00:08:27,115 --> 00:08:29,815
It's something that's
technically correct but useless.

174
00:08:30,415 --> 00:08:36,195
I will send you the things
you asked for is robotic and

175
00:08:36,195 --> 00:08:38,445
vague and frankly unnecessary.

176
00:08:38,595 --> 00:08:43,420
You can just send things and
reject something that's forbidden.

177
00:08:43,920 --> 00:08:44,860
Any response.

178
00:08:45,360 --> 00:08:51,241
Mentioning confidential projects or PII.

179
00:08:51,741 --> 00:08:56,571
Now let's make the V plan,
as I like to call it.

180
00:08:57,201 --> 00:08:57,891
What's a V zero?

181
00:08:58,251 --> 00:08:59,541
How do we be scrappy?

182
00:09:00,471 --> 00:09:02,361
Do we need a massive LLM for V zero?

183
00:09:02,421 --> 00:09:03,141
Probably not.

184
00:09:03,651 --> 00:09:06,371
V zero hard code.

185
00:09:06,871 --> 00:09:07,446
The top.

186
00:09:08,341 --> 00:09:14,561
10 most common replies,
stuff like, thank you.

187
00:09:15,161 --> 00:09:16,181
Thanks.

188
00:09:16,681 --> 00:09:17,221
Got it.

189
00:09:17,721 --> 00:09:24,401
You get the drift as buttons test
if people even click buttons.

190
00:09:24,901 --> 00:09:27,991
We can build this day's V zero in
a day without even touching A GPU.

191
00:09:28,491 --> 00:09:30,681
Finally, no, sorry, not finally.

192
00:09:31,181 --> 00:09:31,541
Second.

193
00:09:31,541 --> 00:09:34,901
From last, boundaries trade offs.

194
00:09:35,401 --> 00:09:41,636
Accepted V will accept plus
300 millisecond latency to

195
00:09:41,636 --> 00:09:44,606
generate better suggestions.

196
00:09:45,106 --> 00:09:48,196
So we are telling engineering
right now it's okay to be slightly

197
00:09:48,196 --> 00:09:49,936
slower if the quality is higher.

198
00:09:50,436 --> 00:09:53,106
That's a leadership decision,
that's a strategic decision.

199
00:09:53,346 --> 00:09:57,396
And then finally, risks,
or rather a risk avoidance.

200
00:09:57,966 --> 00:10:00,026
Let's call it kill switch.

201
00:10:00,526 --> 00:10:04,246
Feature toggle in admin panel.

202
00:10:04,746 --> 00:10:04,986
No.

203
00:10:05,106 --> 00:10:09,516
And accessible to On Call Engineers.

204
00:10:10,476 --> 00:10:14,286
If the model starts hallucinating
inserts, we call it in five seconds.

205
00:10:14,786 --> 00:10:19,046
And there you have it with, in about five
minutes, we've turned helpful replies into

206
00:10:19,046 --> 00:10:21,416
a specific, measurable safe product plan.

207
00:10:21,896 --> 00:10:25,376
This document is now a decision
engine with an opportunity framed.

208
00:10:25,916 --> 00:10:29,876
A behavior contract signed,
sealed, and delivered a V plan.

209
00:10:30,326 --> 00:10:32,546
Boundaries and risk avoidance.

210
00:10:33,046 --> 00:10:34,516
Look at what we just created.

211
00:10:35,116 --> 00:10:39,496
We took that generic and goalless document
from slide two and we turned it into this.

212
00:10:39,856 --> 00:10:42,766
We have a proxy metric that
defines success, a guardrail that

213
00:10:42,766 --> 00:10:44,206
protects the user experience.

214
00:10:44,626 --> 00:10:49,066
We have an explicit trade off on latency,
and most importantly, we have a clear

215
00:10:49,126 --> 00:10:52,666
trade behavior contract that tells
engineering exactly what helpful means.

216
00:10:53,311 --> 00:10:56,071
This document is no longer a
masterclass in saying nothing.

217
00:10:56,521 --> 00:10:57,721
It is a decision log.

218
00:10:58,141 --> 00:10:59,791
It is a shield against wasted work.

219
00:11:00,121 --> 00:11:01,381
This is how you lead.

220
00:11:01,881 --> 00:11:02,901
Let's bring it all home.

221
00:11:03,141 --> 00:11:05,901
We've covered a lot, but
it all comes down to this.

222
00:11:06,531 --> 00:11:08,661
The modern AI spec isn't
just another template.

223
00:11:09,021 --> 00:11:12,501
It's actually a single most powerful
tool for leadership in the AI era.

224
00:11:13,251 --> 00:11:15,441
First, it's how you navigate the politics.

225
00:11:16,041 --> 00:11:19,851
You, when a stakeholder uses
first principles as a rhetorical

226
00:11:19,851 --> 00:11:20,991
tool, you don't have to argue.

227
00:11:21,381 --> 00:11:23,271
Use the spec to make
the tradeoffs explicit.

228
00:11:24,111 --> 00:11:26,121
Second, it's how you clarify the kiosk.

229
00:11:26,541 --> 00:11:29,091
Pipe coding is fun, but
it can be unfocused.

230
00:11:29,511 --> 00:11:32,751
This spec is the insurance policy
that gives your billion team the

231
00:11:32,751 --> 00:11:34,311
alignment to build with confidence.

232
00:11:34,851 --> 00:11:36,711
And finally, it's how
you build your skills.

233
00:11:37,281 --> 00:11:38,571
The framework is the job.

234
00:11:38,991 --> 00:11:42,711
It's how you practice scrappiness,
clear communication and low ego.

235
00:11:43,371 --> 00:11:46,251
This is how you stop just being
a manager of features and being a

236
00:11:46,251 --> 00:11:48,171
leader of a high performing AI team.

237
00:11:48,671 --> 00:11:49,691
Thank you very much.

238
00:11:49,721 --> 00:11:53,081
My goal today was to give you a practical
framework that doesn't just help you

239
00:11:53,081 --> 00:11:57,881
write better docs, but to navigate the
complex realities of our jobs and build

240
00:11:57,881 --> 00:12:00,221
the essential skills for this new AI era.

241
00:12:00,911 --> 00:12:02,711
Please feel free to connect
with me on LinkedIn.

242
00:12:02,951 --> 00:12:03,971
Thank you very much.

