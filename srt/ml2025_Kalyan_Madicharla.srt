1
00:00:02,790 --> 00:00:06,090
Good morning and good afternoon to
those joining from around the world.

2
00:00:06,720 --> 00:00:12,660
I'm Kian Kumar, a senior cloud architect,
architecture leader, focused on

3
00:00:12,660 --> 00:00:14,610
enterprise scale digital transformation.

4
00:00:15,180 --> 00:00:20,490
My work centers on building resilient,
scalable, and secure cloud infrastructure,

5
00:00:21,000 --> 00:00:25,320
and increasingly, that includes
enabling safe and responsible adoption

6
00:00:25,320 --> 00:00:27,720
of machine learning and ative ai.

7
00:00:28,380 --> 00:00:33,030
I'm thrilled to be here at Conference
42, machine Learning 2025 to share

8
00:00:33,030 --> 00:00:34,860
some of those learnings with you today.

9
00:00:35,520 --> 00:00:39,570
Generative AI is accelerating
innovation at incredible pace.

10
00:00:39,930 --> 00:00:44,700
The market is projected to
grow from 13.8 billion in 2023

11
00:00:44,820 --> 00:00:47,730
to over 118 billion by 2032.

12
00:00:48,390 --> 00:00:52,080
But risk growth comes with
new and complex challenges.

13
00:00:52,485 --> 00:00:57,135
Security threats, privacy concerns,
and ethical risks that existing

14
00:00:57,135 --> 00:00:59,295
cloud frameworks don't fully address.

15
00:01:00,225 --> 00:01:05,144
In this session, I'll introduce a five
pillar framework designed specifically

16
00:01:05,144 --> 00:01:10,125
for secur and generative AI workloads,
a model that balances innovation with

17
00:01:10,125 --> 00:01:13,875
security and agility with accountability.

18
00:01:14,355 --> 00:01:19,875
My goal is to help you scale
gen AI confidently and securely.

19
00:01:20,265 --> 00:01:23,895
Especially enterprise environments
where risk and regulation

20
00:01:23,895 --> 00:01:25,215
can be an afterthought.

21
00:01:26,445 --> 00:01:27,255
Let's jump in.

22
00:01:28,255 --> 00:01:33,085
Our framework is structured around file
code domains, infrastructure, security,

23
00:01:33,294 --> 00:01:39,234
data protection, application security,
responsible AI and regulatory compliance.

24
00:01:39,714 --> 00:01:41,514
These are not just checklists.

25
00:01:41,874 --> 00:01:46,554
They are interdependent layers of a
security posture designed to protect

26
00:01:46,554 --> 00:01:52,195
gene systems from external threats,
internal misuse, and reputational harm.

27
00:01:53,004 --> 00:01:57,324
Each pillar corresponds to real world
challenges we have encountered in

28
00:01:57,324 --> 00:02:02,814
field deployments from access control
breaches to unmonitored AI outputs.

29
00:02:03,624 --> 00:02:05,424
Let's look at it one step at a time.

30
00:02:06,424 --> 00:02:07,714
Infrastructure security.

31
00:02:09,064 --> 00:02:13,594
Let's begin with identity and
access management as this is

32
00:02:13,594 --> 00:02:15,124
the number one attack vector.

33
00:02:15,604 --> 00:02:20,374
67% of organizations report
unauthorized AI access attempt,

34
00:02:21,004 --> 00:02:25,054
so least privilege and multifactor
authentication are foundational.

35
00:02:26,539 --> 00:02:31,919
During data transmission, all
model endpoints and inter component

36
00:02:31,949 --> 00:02:37,979
APIs must be encrypted end to
end using TLS 1.3 or higher.

37
00:02:38,819 --> 00:02:43,949
You can also use additionally, HSM based
key storage, which could help further

38
00:02:43,999 --> 00:02:50,539
protection, use infrastructure as a code
commonly called as IAC in the industry

39
00:02:50,839 --> 00:02:53,389
with embedded guardrails to prevent drift.

40
00:02:54,484 --> 00:02:58,024
Automate security poster
assessments quarterly gene.

41
00:02:58,024 --> 00:03:02,614
A infrastructure must be designed
with defense in depth and

42
00:03:02,614 --> 00:03:04,874
not just security perimeter.

43
00:03:05,874 --> 00:03:08,424
Next, let's talk about
data protection strategies.

44
00:03:08,934 --> 00:03:12,684
As data is a fuel and the
vulnerability of gene ai.

45
00:03:13,524 --> 00:03:16,704
Poor data governance can
leak intellectual property.

46
00:03:17,605 --> 00:03:19,945
Ate privacy, or introduce bias.

47
00:03:20,424 --> 00:03:24,954
Enterprises should classify training
and inference data by sensitivity.

48
00:03:25,765 --> 00:03:32,065
Use data minimization to limit what
the model can access to protect

49
00:03:32,065 --> 00:03:36,984
intellectual property, implement
watermarking, provenance tracking,

50
00:03:37,165 --> 00:03:42,655
and legal frameworks for AI
generated outputs for personal data.

51
00:03:43,314 --> 00:03:49,075
Lean into synthetic data and federated
learning and differential privacy.

52
00:03:51,204 --> 00:03:53,394
Let's move on to application security.

53
00:03:54,414 --> 00:03:57,474
Gene systems aren't traditional apps.

54
00:03:58,134 --> 00:04:01,765
Input and output security
is an entirely new surface.

55
00:04:02,694 --> 00:04:06,829
We are seeing prompt injection
tanks where users manipulate model

56
00:04:07,189 --> 00:04:10,069
behavior via cleverly crafted inputs.

57
00:04:10,765 --> 00:04:15,145
These require input, sanitization,
and context of validation.

58
00:04:16,135 --> 00:04:20,695
Equally important is out output
scanning, real-time toxicity

59
00:04:20,695 --> 00:04:25,645
detection, context filtering, and
safety classifiers are essential.

60
00:04:26,335 --> 00:04:31,825
A study conducted by MIT technology
reveal 72% of gene a adopters

61
00:04:31,825 --> 00:04:36,625
have already experienced at
least one unsafe output incident.

62
00:04:38,934 --> 00:04:41,064
Let's move on to responsible AI.

63
00:04:43,074 --> 00:04:44,934
Security is not just technical.

64
00:04:44,934 --> 00:04:46,944
You all are aware it's ethical too.

65
00:04:47,424 --> 00:04:53,515
Enterprise needs clear AI usage policies
and risk categorization for use cases.

66
00:04:54,114 --> 00:04:59,359
Red teaming should become a routine
practice simulate adversary use cases

67
00:04:59,544 --> 00:05:04,284
to expose weakness, combine automated
bias detection with human review.

68
00:05:05,184 --> 00:05:07,434
Also critical prompt engineering.

69
00:05:07,855 --> 00:05:09,205
Sorry, prompt security.

70
00:05:09,205 --> 00:05:09,895
Threat modeling.

71
00:05:10,615 --> 00:05:15,595
Understand attack vectors like
instructional leakage and defend with

72
00:05:15,684 --> 00:05:21,235
boundary enforcement, prompt chaining,
control and input context filtering.

73
00:05:23,740 --> 00:05:25,870
Let's move on to regulatory compliance.

74
00:05:27,010 --> 00:05:27,640
Regulatory.

75
00:05:28,000 --> 00:05:29,830
As regulation is moving fast.

76
00:05:30,130 --> 00:05:35,470
The EU AI Act creates gene AI
in critical sectors as high risk

77
00:05:35,830 --> 00:05:40,450
requiring explainability, risk
control, and human oversight.

78
00:05:41,485 --> 00:05:48,145
In the US agencies like the
F-D-A-F-T-C and NIST offer segment

79
00:05:48,355 --> 00:05:50,395
or sector specific guidance.

80
00:05:50,844 --> 00:05:54,505
This makes multi
jurisdiction com compliance.

81
00:05:54,505 --> 00:05:55,195
Complex.

82
00:05:55,735 --> 00:05:59,094
Enterprise must develop
adaptable governance models.

83
00:06:00,310 --> 00:06:05,740
Maintain audit trails for every
generative AI interaction, input output.

84
00:06:05,800 --> 00:06:10,420
User identities and system responses
ensure they are stored in a

85
00:06:10,420 --> 00:06:12,960
tamper evidence storage system.

86
00:06:14,280 --> 00:06:18,090
So let's look at some practical
implementation strategies.

87
00:06:19,124 --> 00:06:21,734
This framework is not just theoretical.

88
00:06:22,004 --> 00:06:24,044
Here is how you can make it real.

89
00:06:24,405 --> 00:06:27,650
Step one, like I mentioned
before, conduct a generative,

90
00:06:27,729 --> 00:06:29,904
a specific security assessment.

91
00:06:30,264 --> 00:06:34,854
The things that you need to be aware
in this assessment are map your

92
00:06:34,854 --> 00:06:38,964
models, APIs, data sets and endpoints.

93
00:06:39,264 --> 00:06:42,564
So these all should be part of
the assessment so that you'll

94
00:06:42,564 --> 00:06:44,364
understand where the loopholes are.

95
00:06:45,264 --> 00:06:47,784
Then develop policies with
cross-functional ownership.

96
00:06:48,429 --> 00:06:53,229
As you are aware, business legal and
technical teams must collaborate.

97
00:06:54,669 --> 00:07:02,080
Like I mentioned before, secure your APIs
with auth 2.0 and PKC, which protects

98
00:07:02,080 --> 00:07:06,759
against token interception, especially in
the client side and mobile app scenarios

99
00:07:06,759 --> 00:07:13,989
or 2.0 with PKC adds an extra layer
by requiring a dynamic verification,

100
00:07:13,989 --> 00:07:16,179
which cannot be reused by the attackers.

101
00:07:17,244 --> 00:07:21,655
Finally deploy rate limiting
and usage monitoring to identify

102
00:07:21,655 --> 00:07:24,294
suspicious patterns and prevent abuse.

103
00:07:25,554 --> 00:07:28,135
Now let's look at some
future considerations.

104
00:07:28,914 --> 00:07:34,614
Looking ahead, the JI threat
landscape will evolve, expect

105
00:07:34,614 --> 00:07:39,684
adversary prompts, data poisoning
and modeling evasion attacks.

106
00:07:41,109 --> 00:07:45,460
Resilience depends on governance,
integration linking human

107
00:07:45,460 --> 00:07:49,390
oversight policy, and automation
into one unique posture.

108
00:07:50,319 --> 00:07:54,039
Enterprises that succeed here
won't just secure models.

109
00:07:54,309 --> 00:07:58,354
They will build customer trust
and regulatory readiness as

110
00:07:58,794 --> 00:07:59,554
strategic differentiators.

111
00:08:01,194 --> 00:08:06,384
As generative AI matures, security
strategies must evolve to address

112
00:08:06,384 --> 00:08:09,294
emerging threats and governance demands.

113
00:08:09,564 --> 00:08:14,664
We are beginning to see sophisticated
risks like data poisoning, prompt

114
00:08:14,664 --> 00:08:19,284
injection chaining, and model
inversion attacks that target the

115
00:08:19,284 --> 00:08:21,085
behavior of the model themself.

116
00:08:21,804 --> 00:08:26,994
So this requires moving beyond static
controls to adapt security approaches

117
00:08:26,994 --> 00:08:29,574
such as real time prompt inspection.

118
00:08:29,949 --> 00:08:34,359
Output monitoring and retraining
aware threat modeling.

119
00:08:34,990 --> 00:08:41,169
At the same time, innovation in areas like
explainable gene ai privacy, preserving

120
00:08:42,099 --> 00:08:46,875
machine learning, and secure synthetic
data generation will become essential.

121
00:08:48,085 --> 00:08:53,035
Equally importance is the integration
of governance, aligning security with

122
00:08:53,035 --> 00:08:55,694
legal, ethical and policy frameworks.

123
00:08:56,564 --> 00:09:01,214
The enterprises that invest early
in both technical defenses and

124
00:09:01,214 --> 00:09:06,944
responsible governance will be best
positioned to lead securely and

125
00:09:06,944 --> 00:09:08,474
sustainably in the gene AI era.

126
00:09:09,474 --> 00:09:11,574
Finally, thank you for your attention.

127
00:09:11,754 --> 00:09:15,354
This framework is designed to
help enterprises embrace gen

128
00:09:15,354 --> 00:09:17,364
AI securely and responsibly.

129
00:09:18,414 --> 00:09:21,474
Thanks again for the opportunity
to speak for speaking here.

