1
00:00:00,180 --> 00:00:01,110
Hello everyone.

2
00:00:01,470 --> 00:00:06,810
My name is Gary Wan, and I have over
a decade of experience in backend

3
00:00:06,810 --> 00:00:08,760
development and database management.

4
00:00:09,270 --> 00:00:12,810
Throughout my career, I have
worked with companies like Journal

5
00:00:12,810 --> 00:00:17,640
Electronics, TCS, Wipro, Nike, NMI.

6
00:00:17,910 --> 00:00:22,140
Presently, I'm working with Bank of
America as an application programmer,

7
00:00:22,200 --> 00:00:26,820
we focusing on building scalable
and high performance backend system.

8
00:00:27,750 --> 00:00:32,160
Today I will be talking about
optimizing backend API performance

9
00:00:32,880 --> 00:00:35,880
user demands fast response from APIs.

10
00:00:36,420 --> 00:00:41,730
A slow API can lead to poor user
experience, reduce retention, and

11
00:00:41,730 --> 00:00:43,410
a negative impact on your brand.

12
00:00:43,890 --> 00:00:48,210
Today we are going to explore
the best practices for improving

13
00:00:48,240 --> 00:00:50,490
API speed and efficiency.

14
00:00:51,040 --> 00:00:56,740
I will be talking about caching
connection, pooling pagination, payload

15
00:00:56,740 --> 00:00:59,200
compression, and asynchronous processing.

16
00:00:59,980 --> 00:01:03,760
By the end of this session, you
will have a clear understanding

17
00:01:03,850 --> 00:01:09,640
of how to optimize APIs for better
scalability and responsiveness.

18
00:01:10,140 --> 00:01:15,060
Our agenda will be, I will be talking
about why API performance matter.

19
00:01:15,780 --> 00:01:18,480
What are the common a p
performance bottlenecks?

20
00:01:18,810 --> 00:01:22,080
Then the five techniques, which
I mentioned in the introduction.

21
00:01:22,350 --> 00:01:26,040
And lastly, what are the key
takeaways from this session?

22
00:01:26,540 --> 00:01:31,820
A P performance is very crucial in
any application for several reasons.

23
00:01:32,320 --> 00:01:34,570
User experience fast.

24
00:01:34,570 --> 00:01:39,010
API provides a smooth and
responsive user experience.

25
00:01:39,490 --> 00:01:39,850
Slow.

26
00:01:39,850 --> 00:01:46,600
API can lead to frustration and a negative
perception of the application Scalability.

27
00:01:47,180 --> 00:01:53,390
performing APIs can handle more requests
concurrently, allowing the application

28
00:01:53,450 --> 00:01:56,210
to scale efficiently under heavy load.

29
00:01:56,945 --> 00:02:00,185
Poorly performing API
can become bottleneck.

30
00:02:00,545 --> 00:02:06,054
Limiting the application's ability to
handle increased traffic, reliability,

31
00:02:06,685 --> 00:02:11,304
performance issue can sometimes
indicate underlying problems in the

32
00:02:11,304 --> 00:02:17,454
application, such as inefficient code,
database bottleneck, or a source leak.

33
00:02:17,965 --> 00:02:23,394
Addressing performance concern can
improve the overall stability and

34
00:02:23,394 --> 00:02:25,315
reliability of the application.

35
00:02:25,815 --> 00:02:31,725
Resource utilization efficient
APIs consume fewer resources like

36
00:02:31,725 --> 00:02:38,895
CPU Memory network per request,
reducing infrastructure cost, and

37
00:02:38,895 --> 00:02:41,325
improving overall system efficiency.

38
00:02:41,825 --> 00:02:46,234
Business impact in many cases,
API performance directly

39
00:02:46,234 --> 00:02:47,855
impact business metrics.

40
00:02:48,125 --> 00:02:53,915
For example, faster API can lead to
higher conversion rate, increased sales,

41
00:02:54,154 --> 00:02:56,644
and improved customer satisfaction.

42
00:02:57,144 --> 00:02:59,814
What are the common API
performance bottleneck.

43
00:03:00,294 --> 00:03:06,204
Now let's examine some common
bottlenecks that affect API performance.

44
00:03:06,704 --> 00:03:10,124
Database queries are the
operations that retrieve or

45
00:03:10,124 --> 00:03:12,075
modify data from your database.

46
00:03:12,464 --> 00:03:17,084
They are often the most time
consuming part of your API Logic.

47
00:03:17,684 --> 00:03:23,714
Poorly designed or executed database
queries can result in slow or inaccurate

48
00:03:23,714 --> 00:03:28,934
data delivery, high resource consumption
and security vulnerabilities to

49
00:03:29,434 --> 00:03:32,109
optimize your database queries You.

50
00:03:32,964 --> 00:03:39,404
You can use indexes, join filters,
pagination, and caching high latency,

51
00:03:39,524 --> 00:03:45,164
which is caused by synchronous logging
and processing, which means log

52
00:03:45,224 --> 00:03:50,894
events are recorded and processed in
a coordinated manner, which ensures

53
00:03:50,894 --> 00:03:55,604
that the logging operation is computed
before any further processing occur.

54
00:03:56,104 --> 00:04:01,354
Effectively creating a wait and see
approach where the system pauses until

55
00:04:01,354 --> 00:04:07,144
the log is fully returned before moving
onto the next step, preventing potential

56
00:04:07,144 --> 00:04:10,294
data inconsistencies or misinformation.

57
00:04:10,794 --> 00:04:16,914
Large compressed payloads leading to slow
data transmission, excessive database

58
00:04:16,914 --> 00:04:19,015
connection, causing resource contention.

59
00:04:19,515 --> 00:04:25,155
It means significant amount of time was
being spent in creating and closing a

60
00:04:25,155 --> 00:04:29,974
database connection, redundant client
request, increasing server load.

61
00:04:30,334 --> 00:04:35,974
It means a situation where a client
sends the same API requests multiple

62
00:04:35,974 --> 00:04:42,064
times, unnecessarily overloading the
server with identical data, which often.

63
00:04:42,784 --> 00:04:47,824
Cause issues like poor client
side logic, network glitch or user

64
00:04:47,824 --> 00:04:51,589
interaction that trigger repeated
requests for the same information.

65
00:04:52,089 --> 00:04:57,849
Lack of caching resulting in repeated
database hit means that the API does

66
00:04:57,849 --> 00:05:03,189
not store previously retrieved data
temporarily resulting in each request

67
00:05:03,429 --> 00:05:08,949
needing to be processed from scratch by
the server, leading to slower response

68
00:05:08,949 --> 00:05:14,889
time, increased server load, and a less
efficient user experience, especially

69
00:05:14,889 --> 00:05:17,464
when leading with frequently access data.

70
00:05:18,399 --> 00:05:22,899
Now that we have identified the
key performance issue, let's go

71
00:05:22,899 --> 00:05:25,589
over the solutions pagination.

72
00:05:26,309 --> 00:05:30,779
When dealing with large data sets,
fetching all records at words

73
00:05:31,109 --> 00:05:34,949
can lead to slow API response
and high memory consumption.

74
00:05:35,684 --> 00:05:40,424
Pagination helps by retrieving
data in smaller chunks, improving

75
00:05:40,454 --> 00:05:43,064
performance and user experience.

76
00:05:43,814 --> 00:05:45,824
I will be talking about
three techniques here.

77
00:05:45,914 --> 00:05:51,134
Offset based pagination, cursor based
pagination, and page-based pagination.

78
00:05:51,634 --> 00:05:53,524
Offset and limit pagination.

79
00:05:53,704 --> 00:05:58,174
These techniques involve using
two parameters, offset and limit.

80
00:05:58,654 --> 00:06:03,484
The offset parameter determines the
starting point or the position in the

81
00:06:03,484 --> 00:06:07,744
data set while the limit parameter
specifies the maximum number of

82
00:06:07,744 --> 00:06:09,814
records to include on each page.

83
00:06:10,314 --> 00:06:11,874
Cursor based pagination.

84
00:06:11,964 --> 00:06:16,284
Instead of relying on numeric
offset, cursor based pagination

85
00:06:16,284 --> 00:06:22,314
uses a unique identifier or token
to mark the position in the dataset.

86
00:06:22,944 --> 00:06:28,644
The API consumer includes the
cursor value in subsequent request

87
00:06:28,644 --> 00:06:31,074
to fetch the next page of data.

88
00:06:31,574 --> 00:06:33,134
Page-based pagination.

89
00:06:33,404 --> 00:06:37,364
In this technique, it involves
a page parameter to specify

90
00:06:37,724 --> 00:06:39,314
the desired page number.

91
00:06:39,734 --> 00:06:45,224
The API consumer requests a specific
page of data and the API response with

92
00:06:45,224 --> 00:06:49,514
the corresponding page along with the
metadata, such as the total number

93
00:06:49,514 --> 00:06:52,544
of pages or total records count.

94
00:06:53,044 --> 00:06:58,564
Using Spring Boot built in pagination
support ensures that only a subset

95
00:06:58,564 --> 00:07:00,634
of data is fetched per request.

96
00:07:00,634 --> 00:07:02,074
Reducing server code.

97
00:07:02,224 --> 00:07:02,854
Server load.

98
00:07:03,274 --> 00:07:08,164
I have attached a small code snippet
from the spring boot where you can

99
00:07:08,164 --> 00:07:13,444
use, where you can see that I have used
a GA mapping and a page able is sent

100
00:07:13,534 --> 00:07:16,744
as a request and page as a response.

101
00:07:17,244 --> 00:07:18,265
Asynchronous logging.

102
00:07:18,765 --> 00:07:24,914
Synchronous logging can slow down APIs
because each log entry requires input

103
00:07:24,914 --> 00:07:27,194
output operation performed on disk.

104
00:07:27,614 --> 00:07:32,054
By switching to asynchronous
logging, we can reduce blocking

105
00:07:32,294 --> 00:07:33,914
and improve response time.

106
00:07:34,604 --> 00:07:39,554
Asynchronous logging in Java involved
decoupling the logging operation

107
00:07:39,585 --> 00:07:41,354
from the main application thread.

108
00:07:41,940 --> 00:07:46,710
Which prevents performance bottleneck
caused by input output operation.

109
00:07:47,250 --> 00:07:52,560
This approach enhances application
responsiveness spatially under

110
00:07:52,560 --> 00:07:57,960
heavy load libraries like Log back,
log four J needs to offer built-in

111
00:07:57,960 --> 00:08:02,825
support for asynchronous logging to
configure asynchronous logging in.

112
00:08:02,825 --> 00:08:08,855
Log back use Async append tag in
your log back XML configuration file.

113
00:08:09,355 --> 00:08:14,664
This allow logs to be temporally stored in
memory and return to disc asynchronously,

114
00:08:14,664 --> 00:08:16,922
which improves a API efficiency.

115
00:08:17,422 --> 00:08:21,327
caching in Java involves
storing frequently access data

116
00:08:21,327 --> 00:08:23,697
in temporary storage location.

117
00:08:23,997 --> 00:08:29,817
You can call it as a cache to enable
faster retrieval in subsequent request,

118
00:08:30,177 --> 00:08:32,787
thus improving application performance.

119
00:08:33,207 --> 00:08:37,167
The cache act as an intermediate
layer between the application

120
00:08:37,197 --> 00:08:38,907
and the original data source.

121
00:08:39,657 --> 00:08:41,997
For example, database or external service.

122
00:08:42,497 --> 00:08:46,578
You can see I have attached a
small snippet where you can see

123
00:08:46,668 --> 00:08:48,738
an annotation cacheable is used.

124
00:08:48,767 --> 00:08:52,637
It is a Java annotation, which
is used in spring framework to

125
00:08:52,637 --> 00:08:55,127
enable caching for method results.

126
00:08:55,578 --> 00:09:00,708
When a method is annotated with add
cacheable, spring intercepts a method.

127
00:09:00,757 --> 00:09:05,228
Call and check if the result for the
given argument is already cached.

128
00:09:05,588 --> 00:09:10,777
If it is, the cache result is return
and the method is not executed.

129
00:09:10,897 --> 00:09:13,478
Otherwise, the method is executed.

130
00:09:13,718 --> 00:09:16,057
The result is cache, and then return.

131
00:09:16,557 --> 00:09:20,577
Caching helps in reducing the
load on the database and improves

132
00:09:20,877 --> 00:09:23,427
API response time significantly.

133
00:09:23,927 --> 00:09:28,603
Payload compression, large
responses can slow down APIs.

134
00:09:29,358 --> 00:09:33,588
By compressing payload using
techniques like Z zipp broadly,

135
00:09:33,798 --> 00:09:37,548
we can reduce the amount of data
transmitted over the network.

136
00:09:38,088 --> 00:09:42,708
Z Zipp, it's a widely used compression
algorithm that is efficient

137
00:09:42,738 --> 00:09:45,738
for text-based data, broadly.

138
00:09:45,978 --> 00:09:50,538
Generally provide higher compression
rate shows compressed to Zzi, but

139
00:09:50,538 --> 00:09:52,878
may have slower compression speeds.

140
00:09:53,378 --> 00:09:54,458
Few consideration.

141
00:09:54,608 --> 00:10:00,788
CPU usage, compression and decompression
can be CPU Intensive operation.

142
00:10:01,088 --> 00:10:05,108
It is important to balance
compression levels with performance

143
00:10:05,108 --> 00:10:11,798
requirement network overhead, while
compression, it reduces payload size.

144
00:10:12,128 --> 00:10:16,088
The overhead of compression and
decompression should be considered,

145
00:10:16,088 --> 00:10:18,008
especially for smaller payloads.

146
00:10:18,508 --> 00:10:23,248
The compatibility, which ensures that
both the client and server support

147
00:10:23,248 --> 00:10:27,828
the same compression algorithm
error handling, implement proper

148
00:10:27,858 --> 00:10:32,838
error handling for compression and
decompression failure security.

149
00:10:33,198 --> 00:10:38,208
If the payload contains sensitive
information, consider using encryption

150
00:10:38,208 --> 00:10:41,198
in addition to compression a small.

151
00:10:41,948 --> 00:10:45,848
Configuration has been attached,
which is being used in Spring Boot.

152
00:10:46,348 --> 00:10:50,998
This configuration enables response
compression, reduced bandwidth

153
00:10:50,998 --> 00:10:53,338
usage, and improving API performance.

154
00:10:53,838 --> 00:10:55,908
Connection, pooling connection.

155
00:10:55,908 --> 00:11:01,098
Pooling in Java is a technique
used to manage and reuse database

156
00:11:01,098 --> 00:11:06,108
connection, improving the performance
and efficiency of the application

157
00:11:06,108 --> 00:11:07,728
that interact with the database.

158
00:11:08,148 --> 00:11:14,478
Instead of creating a new connection every
time data access is needed, a pool of

159
00:11:14,478 --> 00:11:16,758
connection is established and maintained.

160
00:11:17,448 --> 00:11:22,308
When a connection is required, it
is borrowed from the pool used and

161
00:11:22,308 --> 00:11:27,288
then returned to the pool for reuse,
minimizing the overhead of repeatedly

162
00:11:27,288 --> 00:11:29,208
creating and closing connection.

163
00:11:29,958 --> 00:11:33,288
The benefits of connection
pooling are improved Performance.

164
00:11:33,693 --> 00:11:38,823
reduce overhead of creating and closing
connection resource management, which

165
00:11:38,823 --> 00:11:42,333
means efficiently managed database
connection, preventing resource

166
00:11:42,363 --> 00:11:47,973
exertion and scalability, which enables
application to handle a large number of

167
00:11:47,973 --> 00:11:51,123
concurrent requests, the best practices.

168
00:11:51,123 --> 00:11:56,368
We can use ARI CP for optimal
performance, or we can use tune pool

169
00:11:56,398 --> 00:11:58,088
size based on the traffic pattern.

170
00:11:58,588 --> 00:11:58,738
hi.

171
00:11:58,738 --> 00:12:01,018
Config has been attached here.

172
00:12:01,558 --> 00:12:04,888
Connection, pooling, minimize
overhead, ensuring the database

173
00:12:04,888 --> 00:12:07,708
queries execute faster and efficiently.

174
00:12:08,208 --> 00:12:10,968
Lastly, the key takeaways
from this session.

175
00:12:11,808 --> 00:12:13,728
Monitor and profile API.

176
00:12:13,728 --> 00:12:19,878
Using tools like Pros and Grafana,
implement caching and payload compression

177
00:12:19,878 --> 00:12:25,098
for faster response, optimize database
queries and use connection pooling

178
00:12:25,098 --> 00:12:30,318
to enhance performance leverage,
asynchronous processing for logging and.

179
00:12:30,818 --> 00:12:34,538
Test and scale APIs
proactively to handle P loads.

180
00:12:35,258 --> 00:12:39,428
Adopt API gateway and rate
limiting to manage high traffic.

181
00:12:40,118 --> 00:12:45,548
By following these practices, you can
build high performance APIs that scale

182
00:12:45,608 --> 00:12:48,218
efficiently in a cloud native environment.

183
00:12:49,118 --> 00:12:49,988
Thank you so much.

184
00:12:50,528 --> 00:12:55,298
Thank you all for attending this session
on optimizing backend a P performance.

185
00:12:55,628 --> 00:12:57,968
I hope you found it insightful.

186
00:12:58,238 --> 00:12:59,978
You can also connect me on LinkedIn.

187
00:12:59,978 --> 00:13:01,108
I. Thank you.

