1
00:00:00,510 --> 00:00:01,380
Hello everyone.

2
00:00:01,440 --> 00:00:02,580
Welcome to my session.

3
00:00:02,580 --> 00:00:03,930
My name is Samuel Bafi.

4
00:00:03,930 --> 00:00:06,720
I'm an in pretty simple
solutions architect with AWS.

5
00:00:07,110 --> 00:00:11,310
Today I'm gonna be presenting about
Amazon, Aurora DS L, which is a new

6
00:00:11,310 --> 00:00:14,130
relation database offering on AWS.

7
00:00:14,850 --> 00:00:18,150
So let's start talking a lot, a
little bit about some of the current

8
00:00:18,720 --> 00:00:20,814
relation database challenges, right?

9
00:00:21,235 --> 00:00:24,744
We can give an example about
running a Postgres database.

10
00:00:25,060 --> 00:00:27,220
In whatever, service or platform.

11
00:00:27,220 --> 00:00:31,240
It could be on your own EC2, it could
be on your on-premise, or potentially

12
00:00:31,240 --> 00:00:33,820
it could be on RDS as a service as well.

13
00:00:34,209 --> 00:00:36,855
Some of the challenges that
we have is scalability, right?

14
00:00:36,915 --> 00:00:40,725
Traditional databases have the
capacity limitations that you would

15
00:00:40,725 --> 00:00:44,954
have a instance, and that instance,
that server is your limitation.

16
00:00:44,954 --> 00:00:48,915
So customers would be constrained
by these capacity limits of

17
00:00:48,915 --> 00:00:50,114
this traditional database.

18
00:00:51,095 --> 00:00:57,105
And it becomes very hard to rightsize your
application for this specific server that

19
00:00:57,105 --> 00:01:01,540
you might need to configure when you're
provisioning this specific instance.

20
00:01:01,620 --> 00:01:07,050
S also availability because it's a
challenge because now if you have only

21
00:01:07,050 --> 00:01:12,669
one server and you know that server
goes down, we have lower resiliency

22
00:01:12,669 --> 00:01:15,880
that could potentially lead into
unplanned down times, and it could

23
00:01:15,880 --> 00:01:17,560
impact your database availability.

24
00:01:17,679 --> 00:01:21,749
Of course, there are ways that you
can have, read only replicas and

25
00:01:21,749 --> 00:01:25,669
you can potentially help alleviate
some of those concerns, but those

26
00:01:25,669 --> 00:01:27,469
are not very easy to manage.

27
00:01:27,679 --> 00:01:31,399
And there are a lot of pros and
cons about ab, about that, right?

28
00:01:31,399 --> 00:01:33,410
So those are the functional challenges.

29
00:01:33,830 --> 00:01:36,950
When you look at the operational
challenges, one of the things

30
00:01:36,950 --> 00:01:39,830
that is very common, and I keep
hearing from many customers, is.

31
00:01:40,335 --> 00:01:45,205
Infrastructure management, like patching,
upgrades requiring a lot of engineering

32
00:01:45,205 --> 00:01:51,735
time to, prepare potentially the database,
prepare the server, test those, and

33
00:01:51,795 --> 00:01:56,025
that is a lot of engineering effort
that goes just to keep your database

34
00:01:56,025 --> 00:01:58,205
up and running, also is the complexity.

35
00:01:58,205 --> 00:02:00,545
Right now you have a
lot of infrastructure.

36
00:02:00,545 --> 00:02:04,205
You need to make sure you're installing
the operating system, you're installing

37
00:02:04,205 --> 00:02:07,745
the database, like the Postgres, your
parts, that you're doing a lot of fine

38
00:02:07,745 --> 00:02:13,615
tuning configuration, which that only
not, that not only requires engineering

39
00:02:13,675 --> 00:02:16,375
effort, but also require expertise.

40
00:02:16,405 --> 00:02:18,175
That becomes very challenge, right?

41
00:02:18,505 --> 00:02:23,575
So with some, if not all of
these challenges in mind.

42
00:02:24,410 --> 00:02:30,410
AWS have announced in December of
2024, the reinvent Amazon, Aurora

43
00:02:30,410 --> 00:02:35,810
d sql, which is a cloud native
serverless distributed SQL database

44
00:02:36,230 --> 00:02:41,720
with virtually unlimited scalability
and the highest availability of AWS.

45
00:02:42,170 --> 00:02:45,800
We are on this talk, we're gonna
talk about how that was possible.

46
00:02:46,145 --> 00:02:51,875
All the behind the scenes important
architecture decisions that were made

47
00:02:51,875 --> 00:02:53,645
in order to make these available.

48
00:02:54,185 --> 00:02:56,645
So you have virtually unlimited scaling.

49
00:02:56,645 --> 00:03:01,865
That is one of the core concepts of
our RDS QL because you have the compute

50
00:03:01,865 --> 00:03:07,205
and multiple steps of the compute that
are independently managed and scaled.

51
00:03:07,520 --> 00:03:13,780
You can have rights and reads also
being scale separately and, both will

52
00:03:13,780 --> 00:03:15,700
be up and down as you need it, right?

53
00:03:15,940 --> 00:03:19,030
That allows you to have a
business continuity because

54
00:03:19,060 --> 00:03:21,910
you can now have a active.

55
00:03:22,235 --> 00:03:26,765
Multi-region distributed relation
database on databases that is

56
00:03:26,765 --> 00:03:28,415
completely managed for you.

57
00:03:28,535 --> 00:03:31,445
And you're gonna talk, spend a
lot of time on the talk today

58
00:03:31,725 --> 00:03:33,975
explaining how that actually works.

59
00:03:34,125 --> 00:03:34,785
How does it mean?

60
00:03:34,785 --> 00:03:38,565
Because we know with traditional
relation databases, actually all the

61
00:03:38,565 --> 00:03:42,625
relation databases there is a lot of
locking issues and how to make sure,

62
00:03:42,695 --> 00:03:45,875
the consistency across different
replicas in different regions.

63
00:03:45,995 --> 00:03:46,715
How does that work?

64
00:03:46,750 --> 00:03:46,780
Okay.

65
00:03:47,750 --> 00:03:52,250
Another aspect that has been designed
from the beginning is serverless.

66
00:03:52,250 --> 00:03:53,900
There is no server to provision.

67
00:03:54,080 --> 00:03:55,610
There is no server to patch.

68
00:03:55,610 --> 00:03:58,910
There is no software niching
style, or maintain or operate.

69
00:03:59,090 --> 00:04:00,385
It's completely serverless.

70
00:04:00,635 --> 00:04:01,850
Serverless native serverless.

71
00:04:02,850 --> 00:04:09,010
And fast and easy is the idea of RDCO is
very inspired on other, their offerings

72
00:04:09,040 --> 00:04:11,710
on the AWS ecosystem for serverless.

73
00:04:11,860 --> 00:04:14,300
So I'll give an example of
create a diamond db table.

74
00:04:14,400 --> 00:04:19,440
Just create a D DB table and you can start
querying and actually insert data on that.

75
00:04:19,490 --> 00:04:24,090
The same idea is trying to be
replicated here on our RD sql which,

76
00:04:24,150 --> 00:04:27,300
it should be very quick if you
have familiarity Postgres because.

77
00:04:27,900 --> 00:04:33,570
Our Rd CO is a Postgres compliant
database where you can run some

78
00:04:33,570 --> 00:04:35,070
of the capabilities of Postgres.

79
00:04:35,100 --> 00:04:37,410
If you are interested of some of
the capabilities and limitations,

80
00:04:37,410 --> 00:04:41,950
please check our documentation,
but let's dive into the first.

81
00:04:42,265 --> 00:04:44,365
Way you can run our RD sql.

82
00:04:44,665 --> 00:04:49,735
So the first one is you can run our RD
SQL on a single region cluster if you

83
00:04:49,735 --> 00:04:54,845
do not have the necessity to running
active multi region applications,

84
00:04:54,845 --> 00:04:58,415
because those are, those can be expensive
and not every single application

85
00:04:58,415 --> 00:05:01,145
requires you to have a active solution.

86
00:05:01,385 --> 00:05:04,075
So if you are okay, have
as you've been running.

87
00:05:04,450 --> 00:05:06,880
Potentially other traditional
databases on a single region.

88
00:05:06,940 --> 00:05:08,920
You can create the s
QL on a single region.

89
00:05:09,530 --> 00:05:14,090
By default, of course, because this
is a managed offering on AWS, when

90
00:05:14,090 --> 00:05:17,600
you create a single region cluster,
you operate it active across three

91
00:05:17,600 --> 00:05:19,160
availability zones always, right?

92
00:05:19,160 --> 00:05:22,910
So you can see you have your VPC with
your application, you're gonna receive

93
00:05:22,910 --> 00:05:25,280
an endpoint for that specific database.

94
00:05:25,280 --> 00:05:29,130
You're gonna use that endpoint both
for reads and writes the compute.

95
00:05:29,505 --> 00:05:32,805
The transaction logs, which you're
gonna talk about in the future of

96
00:05:32,805 --> 00:05:36,585
this presentation, the storage are
actually replicated independently

97
00:05:36,675 --> 00:05:38,295
across three availability zones.

98
00:05:38,345 --> 00:05:44,345
This provides a 99.99% of availability
and all the transactions are

99
00:05:44,345 --> 00:05:49,565
fast and local, and also maintain
acid properties of your database.

100
00:05:49,865 --> 00:05:53,735
The transaction commits goes across
availability zones, ensure data

101
00:05:53,735 --> 00:05:58,825
transactions are durable, isolated
anatomic, of course trying to maintain

102
00:05:58,855 --> 00:06:01,045
actually maintaining the asset property.

103
00:06:01,945 --> 00:06:05,725
So this is the single, region cluster
that I create, you'll have an option

104
00:06:05,725 --> 00:06:09,895
if you want a single region cluster or
if you want a multi region cluster if

105
00:06:09,895 --> 00:06:11,695
you're going to the multi region cluster.

106
00:06:12,085 --> 00:06:17,305
Now Aurora, the SQL delivers five nines
of availability across multiple regions.

107
00:06:17,825 --> 00:06:21,035
And the way this works, it's
very unique and very interesting.

108
00:06:21,515 --> 00:06:26,405
So multi to region clusters provide two
regional endpoints, and on this scenario

109
00:06:26,405 --> 00:06:28,415
we are talking about a linked region.

110
00:06:28,940 --> 00:06:32,750
The way it works is you go on
your AWS console or use the CLI or

111
00:06:32,750 --> 00:06:36,830
the API, you can create an neuro
DSL and you can say, I want a

112
00:06:36,830 --> 00:06:39,620
secondary region as a linked region.

113
00:06:40,040 --> 00:06:42,650
So in this example, you can
see that we have three regions

114
00:06:42,650 --> 00:06:44,390
here into this architecture.

115
00:06:44,390 --> 00:06:48,330
We have, region one, region
two, where each region it's

116
00:06:48,330 --> 00:06:50,310
gonna have its own unique.

117
00:06:50,580 --> 00:06:51,240
Endpoint.

118
00:06:51,390 --> 00:06:55,020
So we are gonna talk about how reads
and writes work, but the good thing

119
00:06:55,020 --> 00:07:00,840
about having a endpoint region is all
the reads that are gonna be done in that

120
00:07:00,960 --> 00:07:04,770
specific region, using that specific
endpoint are always gonna be locally.

121
00:07:04,770 --> 00:07:07,170
You don't need to go across
region, and that's one of

122
00:07:07,170 --> 00:07:08,790
the main benefits of the sql.

123
00:07:08,940 --> 00:07:13,720
But also rights are gonna be synchronous
getting replicated across regions.

124
00:07:14,200 --> 00:07:16,480
At the time of commit, we are
gonna explain what that means.

125
00:07:16,480 --> 00:07:18,915
In a moment, the regions are equal peers.

126
00:07:18,915 --> 00:07:22,275
There is no leader or master
node in this situation.

127
00:07:22,555 --> 00:07:25,665
And because you have the synchronous
replication between regions,

128
00:07:25,665 --> 00:07:27,655
you always have a RPO of zero.

129
00:07:28,430 --> 00:07:32,060
Which is really important for
mission critical applications.

130
00:07:32,240 --> 00:07:34,850
Now you see here that we
have also a witness region.

131
00:07:34,970 --> 00:07:37,730
So the witness region is
just replicating the journal.

132
00:07:37,760 --> 00:07:40,580
So we will call that journal,
but that is where the transaction

133
00:07:40,580 --> 00:07:41,960
logs of your database are.

134
00:07:42,020 --> 00:07:44,480
And in case of a failure, we're
gonna explain in the end of the

135
00:07:44,480 --> 00:07:46,190
presentation, in the case of failure.

136
00:07:46,565 --> 00:07:49,115
Of that, of one specific region.

137
00:07:49,275 --> 00:07:52,035
You also are gonna, you always
are gonna have a quorum because

138
00:07:52,035 --> 00:07:55,065
this third region, which is the
witness region, but on the witness

139
00:07:55,065 --> 00:07:56,685
region, you do not have an endpoint.

140
00:07:56,865 --> 00:08:01,805
It's just a witness region that is
there to actually replicate it at

141
00:08:01,805 --> 00:08:03,485
the transaction lock for the quorum.

142
00:08:03,845 --> 00:08:05,495
So you have always three up and Right.

143
00:08:05,615 --> 00:08:09,095
So let's talk a little bit
about the components of the sql.

144
00:08:09,595 --> 00:08:13,345
So if we think about the components
of the C COEs, you have the front end.

145
00:08:13,345 --> 00:08:17,195
So the front end you can think about,
the endpoint on each specific region

146
00:08:17,195 --> 00:08:18,725
that you're gonna talk to, you know of.

147
00:08:18,755 --> 00:08:21,085
Of course, that front end is being.

148
00:08:21,965 --> 00:08:25,595
Being served to you across multiple
load balancers that are replicated

149
00:08:25,595 --> 00:08:27,275
across multiple availability zones.

150
00:08:27,575 --> 00:08:30,425
But the interesting part here
comes with query processor.

151
00:08:30,815 --> 00:08:35,255
So the query processors are responsible
for executing the customer SQL,

152
00:08:35,405 --> 00:08:40,535
returning data in response to reads,
buffering data in response to rights

153
00:08:40,535 --> 00:08:42,695
and running the transaction protocol.

154
00:08:42,725 --> 00:08:47,135
So that's where Postgres will be
running, then we have ad adjudicators.

155
00:08:47,645 --> 00:08:52,685
Adjudicators are responsible for
deciding whether a transaction can be

156
00:08:52,685 --> 00:08:56,285
commit while following isolation rules.

157
00:08:56,285 --> 00:08:59,645
We're gonna explain how isolation rules
work in a moment for working with the

158
00:08:59,645 --> 00:09:05,375
journal in order for the transaction to
actually be committed into the storage.

159
00:09:05,975 --> 00:09:10,085
Everything you see here from the edge
educator to the crossbar are only gonna be

160
00:09:10,085 --> 00:09:13,385
necessary if you're doing a right, right?

161
00:09:13,385 --> 00:09:15,425
If you're doing a transaction
that requires a right.

162
00:09:16,280 --> 00:09:22,370
The journal are an order data stream that
makes transactions durable and replicated

163
00:09:22,370 --> 00:09:24,470
data between regions and availabilities.

164
00:09:25,310 --> 00:09:29,030
The crossbar is just a way
that it can replicate it.

165
00:09:29,130 --> 00:09:32,280
Your data into the storage
and of course the storage.

166
00:09:32,330 --> 00:09:36,290
Where is the data is gonna be
completely replicated across

167
00:09:36,290 --> 00:09:38,030
different storage partitions.

168
00:09:38,240 --> 00:09:42,170
And, DSL takes a very interesting
approach of, replicating the different

169
00:09:42,170 --> 00:09:43,850
pieces of data across different storage.

170
00:09:43,850 --> 00:09:47,030
So we have the replication and
the performance capability.

171
00:09:47,600 --> 00:09:49,699
Benefit given to you by default.

172
00:09:49,760 --> 00:09:53,670
You don't need to even, you don't
see any of these components here.

173
00:09:53,700 --> 00:09:55,500
We are just talking about
these components, so we have

174
00:09:55,500 --> 00:09:57,300
an idea how it actually works.

175
00:09:58,140 --> 00:10:02,970
So let's talk a little bit about how
different transactions, like a re

176
00:10:02,970 --> 00:10:08,189
transaction, a right transaction operate,
so you understand how these components.

177
00:10:08,445 --> 00:10:11,775
Which potentially by now are still
a little bit confusing, but how

178
00:10:11,775 --> 00:10:16,275
these components will be put in
place and how do they work together.

179
00:10:17,025 --> 00:10:22,005
So if we look here, let's just try
to illustrate how all works together.

180
00:10:22,315 --> 00:10:23,785
So we reduce the complexity.

181
00:10:23,965 --> 00:10:26,125
We'll follow a transaction from ra.

182
00:10:26,215 --> 00:10:30,355
We are going to start with a RET
transaction and a base select statement.

183
00:10:30,370 --> 00:10:36,890
Okay, let's imagine that a user is on a
specific region US is one, and that user

184
00:10:36,890 --> 00:10:42,540
is looking to order pizza from a local
restaurant in let's say Virginia, right?

185
00:10:42,660 --> 00:10:48,120
So what happens there is the user
decides what food he wants from the

186
00:10:48,120 --> 00:10:49,950
restaurant based on a specific rating.

187
00:10:49,950 --> 00:10:52,730
So in this case, let's select
all the restaurants where

188
00:10:52,730 --> 00:10:54,890
ratings equals to four, right?

189
00:10:54,950 --> 00:10:58,100
What happens behind the scenes at this?

190
00:10:58,400 --> 00:11:01,730
From this point because you have
select, you've done the a select

191
00:11:01,730 --> 00:11:03,290
statement, which is a read statement.

192
00:11:03,410 --> 00:11:06,470
How does this SQL manage that statement?

193
00:11:06,860 --> 00:11:07,910
So let's look into that.

194
00:11:08,900 --> 00:11:11,920
So you have the client will
connect to the front end.

195
00:11:12,130 --> 00:11:14,530
That means a specific regional endpoint.

196
00:11:14,710 --> 00:11:17,350
This could be a
multi-regional linked cluster.

197
00:11:17,350 --> 00:11:20,280
It could be a single reach for the
examples you're gonna provide today,

198
00:11:20,280 --> 00:11:22,170
let's say they are all multi reach.

199
00:11:22,800 --> 00:11:28,820
So when you do this specific request,
that request will go through a load

200
00:11:28,820 --> 00:11:32,360
balance from the front end, and then
we will create a query processor.

201
00:11:32,660 --> 00:11:35,770
It's where your, transaction
will actually happen.

202
00:11:36,280 --> 00:11:41,290
The query processor will actually
use a start time, and this is one

203
00:11:41,290 --> 00:11:47,020
of the very unique benefits and
capabilities of the SQL and AWS is.

204
00:11:47,365 --> 00:11:52,645
This time that is being retrieved from
a local clock is using what we call

205
00:11:52,645 --> 00:11:59,515
the Amazon Time Sink Service, which AWS
uses highly accurate global standard

206
00:11:59,645 --> 00:12:05,795
time by leveraging satellite GPS signals
alongside with atomic clocks references,

207
00:12:06,365 --> 00:12:08,135
which is crucial to ensuring that.

208
00:12:08,825 --> 00:12:13,205
Time in one region and time in another
region are actually are actually aligned

209
00:12:13,265 --> 00:12:16,945
because, speed of light and how clocks
are aligned can be problematically.

210
00:12:16,945 --> 00:12:20,455
If you're not using atomic clock and
you have, satellite communications

211
00:12:20,455 --> 00:12:22,405
to pinpoint that, right?

212
00:12:22,405 --> 00:12:26,875
So when a query gets processor by the
query processor, we have time at the

213
00:12:26,875 --> 00:12:29,365
start, which is a local clock, right?

214
00:12:29,395 --> 00:12:31,075
So you receive that data.

215
00:12:31,075 --> 00:12:32,845
Then the query processor, what it does is.

216
00:12:33,625 --> 00:12:39,435
In this case, because it's a read
because it's a read statement, read

217
00:12:39,435 --> 00:12:43,945
transaction, the query processor will
look for the shard map of the storage,

218
00:12:44,155 --> 00:12:49,315
where the data is being stored on the
storage layer, and you go to the read

219
00:12:49,315 --> 00:12:51,085
path, you go directly to the storage.

220
00:12:51,145 --> 00:12:53,635
It doesn't need to go through
any adjudicator, any journal.

221
00:12:53,785 --> 00:12:58,055
You go to the storage and then you
return, if you look here now you

222
00:12:58,055 --> 00:13:00,365
return the data back to the query.

223
00:13:00,980 --> 00:13:03,910
Processor and the query processor
will return the data to the front

224
00:13:03,910 --> 00:13:05,260
end, return the data to the client.

225
00:13:05,950 --> 00:13:10,550
So now these results, of
course, will be merged here when

226
00:13:10,610 --> 00:13:11,840
it'll be sent to the customer.

227
00:13:11,840 --> 00:13:12,290
There you go.

228
00:13:12,290 --> 00:13:16,490
And you see the specific the specific
pizza place that you have selected.

229
00:13:16,990 --> 00:13:19,940
Let's look at more complex query.

230
00:13:20,615 --> 00:13:25,165
Where maybe the user does not
only want to run a simple select

231
00:13:25,165 --> 00:13:29,495
transaction, but also wants to do some
interactive transaction potentially,

232
00:13:29,545 --> 00:13:30,985
inserting data into the database.

233
00:13:31,485 --> 00:13:35,715
So the query, of course, you're gonna
create a transaction, this case select

234
00:13:35,815 --> 00:13:37,345
in a restaurants with rate four.

235
00:13:37,555 --> 00:13:42,745
I actually want to see a specific,
a restaurant id, and I want

236
00:13:42,745 --> 00:13:44,395
to see specific item, right?

237
00:13:44,395 --> 00:13:47,455
You're selecting the item, then
you're saying, I want to order this

238
00:13:47,455 --> 00:13:51,785
item, which is a pizza and then,
put this pizza into my order table.

239
00:13:51,865 --> 00:13:54,505
So you selected the restaurant,
you chose the item you want,

240
00:13:54,505 --> 00:13:55,350
and you placed the order.

241
00:13:55,420 --> 00:13:55,540
Order.

242
00:13:55,960 --> 00:14:01,080
Let's look at how these actually
worked behind the scenes with this sql.

243
00:14:01,580 --> 00:14:08,110
So again, we, what we're gonna do here
is we are gonna have a transaction t

244
00:14:08,110 --> 00:14:11,290
time using Amazon time sync, right?

245
00:14:11,770 --> 00:14:15,820
What is gonna happen here
is the query processor.

246
00:14:16,390 --> 00:14:20,890
We get a snapshot of the data
from that T type that they

247
00:14:20,890 --> 00:14:22,870
start type the T star, right?

248
00:14:23,770 --> 00:14:28,750
That snapshot is gonna be load into
the query processor and then every

249
00:14:28,750 --> 00:14:33,310
single read and every single write will
only be done within that is specific.

250
00:14:33,670 --> 00:14:36,070
Query processor is not
touching the storage yet.

251
00:14:36,070 --> 00:14:40,760
He's using optimistic locking, which
allows, for concurrence concurrent.

252
00:14:41,600 --> 00:14:45,320
Rights should be done at the
same time if they're not actually

253
00:14:45,320 --> 00:14:47,120
using the same roles, right?

254
00:14:47,660 --> 00:14:52,550
So in this S ql, the care processor
acts as holding tank for all these

255
00:14:52,550 --> 00:14:58,370
statements waiting for a commit statement
before it sends the full transaction

256
00:14:58,370 --> 00:15:00,080
to adjudicators to be checked.

257
00:15:00,260 --> 00:15:03,410
We're gonna talk a little bit about what
Edge Educator does in a moment, right?

258
00:15:03,870 --> 00:15:06,810
Think about the query processes
being displaced here now.

259
00:15:07,310 --> 00:15:12,490
The cool thing about how this works
right is once you have a start of

260
00:15:12,490 --> 00:15:16,880
the transaction, you have that tee
time you have, the cross region

261
00:15:16,880 --> 00:15:20,210
transactions proceed very similar
to a single region transaction.

262
00:15:20,540 --> 00:15:23,810
The red path is barely changed, so
you can just grab the data from the

263
00:15:23,810 --> 00:15:25,520
storage nodes that have the charts.

264
00:15:26,020 --> 00:15:30,220
Now when you do the select in
insert update, no cross region

265
00:15:30,220 --> 00:15:31,960
interactions are required here.

266
00:15:32,560 --> 00:15:35,890
Because the optimistic locking
that the CCO implements.

267
00:15:36,100 --> 00:15:41,320
So the way this works is the latency
is only incurred at the commit time.

268
00:15:41,320 --> 00:15:44,080
So on the query processors you're
gonna go through, you're gonna do

269
00:15:44,080 --> 00:15:46,330
select, you're gonna do insert,
and you're gonna do update.

270
00:15:46,510 --> 00:15:51,800
And once you finally have your snapshot
with all the commitments and sorry,

271
00:15:51,800 --> 00:15:56,390
with all the data that needs to be
commit, it sends to the adjudicator.

272
00:15:56,675 --> 00:15:59,375
And we're gonna talk about the
adjudicator in a moment, but it sent

273
00:15:59,375 --> 00:16:03,965
to adjudicator and the goal of the
adjudicator is to go across both regions

274
00:16:03,965 --> 00:16:11,115
that you have and make sure that after
your t start, you know that no is,

275
00:16:11,175 --> 00:16:15,885
no other data has been transacted.

276
00:16:16,305 --> 00:16:22,065
Into your storage and your journal that
you conflict with your specific request.

277
00:16:22,335 --> 00:16:25,995
If there is only one of them is gonna
be committed and the other one's

278
00:16:25,995 --> 00:16:29,805
gonna be aborted and they need to
ry, but if not, you know the commit

279
00:16:29,895 --> 00:16:31,665
is when you incur the latency.

280
00:16:31,665 --> 00:16:36,225
So you're not gonna incurring the latency
into every single select insert an update.

281
00:16:36,315 --> 00:16:37,515
That is not how it works.

282
00:16:37,665 --> 00:16:41,175
You only get the latency when
you're doing the commit cross reach.

283
00:16:41,880 --> 00:16:46,110
So this means that reads, writes,
and updates are just as fast as they

284
00:16:46,110 --> 00:16:47,635
would be in a single region database.

285
00:16:48,060 --> 00:16:53,070
Only the commit part is where you incur
the cross region latency and the cross

286
00:16:53,070 --> 00:16:58,050
region latency could go between 15 to
a hundred plus milliseconds, depending

287
00:16:58,050 --> 00:17:01,890
how far each region that you have
linked together are from each other.

288
00:17:01,890 --> 00:17:04,320
If they're close to each other
in, into the us, they're gonna

289
00:17:04,320 --> 00:17:08,160
be a little bit faster between
20 to 30 to 40 milliseconds.

290
00:17:08,310 --> 00:17:11,430
If they're far apart, it could
be hundreds of plus milliseconds

291
00:17:11,430 --> 00:17:14,400
at the commit time because, speed
of flight is something that.

292
00:17:14,895 --> 00:17:18,165
We cannot expedite, at
least for the time being.

293
00:17:18,265 --> 00:17:22,135
So let's talk a little bit about
the query processor, because there

294
00:17:22,135 --> 00:17:27,585
is a lot of innovation that has
been created behind the scenes.

295
00:17:28,065 --> 00:17:32,865
So as you've seen, the query processor
is doing a lot of work is the HA Heart,

296
00:17:33,135 --> 00:17:35,535
or where the SQL Architecture runs.

297
00:17:35,985 --> 00:17:40,905
It runs inside what we call a fire crack
virtual machine, micro virtual machine.

298
00:17:41,745 --> 00:17:46,455
Which is where the query processor
host within a server, in this

299
00:17:46,455 --> 00:17:48,465
case, a bare metal instance, right?

300
00:17:49,035 --> 00:17:50,955
A micro firecracker.

301
00:17:50,955 --> 00:17:56,295
Micro VM was created and built for
Lambda in 2018, and this is the

302
00:17:56,295 --> 00:18:00,795
same technology that the SQL Query
processors is using behind the scenes.

303
00:18:01,515 --> 00:18:04,698
It's an open source micro
VM that AWS has open source.

304
00:18:05,010 --> 00:18:08,580
And, we've used to put a secure
box around the Postgres engine.

305
00:18:08,640 --> 00:18:13,020
So Postgres will be running on top of this
query processor, which is a micro view.

306
00:18:13,920 --> 00:18:19,230
So the cool thing about this is as
your database grows in a scale and a

307
00:18:19,230 --> 00:18:24,910
demand, this can literally scales to
little tens or one query processor at

308
00:18:24,910 --> 00:18:29,950
any given time or zero if you don't
have any requests to tens of millions

309
00:18:29,980 --> 00:18:31,970
of query processor is being created.

310
00:18:32,000 --> 00:18:36,830
Each query is gonna create a query
processor, like each transaction, sorry,

311
00:18:36,830 --> 00:18:38,450
is gonna create a query processor.

312
00:18:38,950 --> 00:18:43,430
Another good thing is the
support of I snapshot isolation.

313
00:18:43,640 --> 00:18:48,350
So in this SQL, we support an isolation
level call snapshot isolation.

314
00:18:48,470 --> 00:18:50,400
So what does act this actually mean?

315
00:18:50,970 --> 00:18:55,290
It means that each transaction
operated operates on a consistent

316
00:18:55,290 --> 00:19:01,050
snap snapshot of the database as it
exists at the start of the transaction.

317
00:19:01,080 --> 00:19:04,740
So when as you do the right from
the storage, and you see here on the

318
00:19:04,740 --> 00:19:10,320
right of the screen, the when there is
snapshot is being created into the query

319
00:19:10,320 --> 00:19:15,250
processor, that is a shot isolation
who only exists on the query processor.

320
00:19:16,225 --> 00:19:19,765
If you have any rights and
updates and inserts, then you

321
00:19:19,765 --> 00:19:21,055
will try to do the commit.

322
00:19:21,145 --> 00:19:24,805
If it's multi-region use, use the
adjudicator to make sure there is no

323
00:19:25,145 --> 00:19:29,225
there is no conflict across the commits
across different regions, right?

324
00:19:29,895 --> 00:19:34,655
So the transaction begins, proceeds
through the SQ execution phase where

325
00:19:35,045 --> 00:19:39,335
the read see the consistent snapshot
being put back into the micro view.

326
00:19:39,835 --> 00:19:46,135
So when the right operation occurs,
like an insert or update, they

327
00:19:46,135 --> 00:19:49,135
are not immediately applied to
the storage, and that is a very

328
00:19:49,135 --> 00:19:50,665
important thing to think, right?

329
00:19:51,655 --> 00:19:57,205
Very different than other databases
and how databases are architected.

330
00:19:57,565 --> 00:20:01,645
If you would do a read or an
update or an insert, it would be

331
00:20:01,645 --> 00:20:03,055
automatically done in storage.

332
00:20:03,070 --> 00:20:07,870
At this time, because we are using
Optimistic Locking, what it does is uses

333
00:20:07,870 --> 00:20:13,120
that snapshot that it got from, your read
pad, and every time it has a right, like

334
00:20:13,120 --> 00:20:16,210
an update on insert, you run that locally.

335
00:20:16,710 --> 00:20:21,750
Instead of we spo, of course, we spo
these rights locally and you create a

336
00:20:21,800 --> 00:20:24,230
private workspace for this transaction.

337
00:20:25,010 --> 00:20:29,300
What this approaches allows you
to do is read your rights so you

338
00:20:29,300 --> 00:20:31,100
don't need to subsequent read.

339
00:20:31,565 --> 00:20:35,765
Within the same transaction that can
see pending changes on the storage that

340
00:20:35,765 --> 00:20:41,315
increases performance and the scalability,
which is one of the very incredible

341
00:20:41,315 --> 00:20:43,145
things that the CQ allows you to do.

342
00:20:43,645 --> 00:20:48,385
But as you are doing these rights
locally on your a credit processors,

343
00:20:48,885 --> 00:20:50,380
there is a challenge, right?

344
00:20:50,410 --> 00:20:52,900
What happens if there is
another transaction that is

345
00:20:52,900 --> 00:20:55,340
trying to write at the same.

346
00:20:55,715 --> 00:20:58,685
A role that your existing transaction has.

347
00:20:58,685 --> 00:21:02,615
So let's say you have transaction
and transaction B, you need to have

348
00:21:02,615 --> 00:21:08,975
a capability on your database engine
that can look across these specific

349
00:21:09,075 --> 00:21:14,025
transactions and decide is there a
conflict or is there not a conflict?

350
00:21:14,145 --> 00:21:16,965
And that's what the
adjudicator allows you to do.

351
00:21:17,340 --> 00:21:22,140
The job of the dedicated should detect
and resolve conflict between transactions

352
00:21:22,260 --> 00:21:24,180
and ensure their rights are consistent.

353
00:21:24,240 --> 00:21:28,590
Because you have relation database,
they need to be asset, and by having

354
00:21:28,590 --> 00:21:30,360
that, they need to be consistent, right?

355
00:21:30,480 --> 00:21:34,410
So when you look at transaction
a, for example, when you create

356
00:21:34,410 --> 00:21:36,150
a payload, you have a T start.

357
00:21:36,360 --> 00:21:39,390
And remember, the T start is the
time when you are actually receiving

358
00:21:39,390 --> 00:21:41,220
the reads from the storage, right?

359
00:21:41,490 --> 00:21:44,310
Then you can do a write
of sets, post images.

360
00:21:44,340 --> 00:21:45,300
That is the payload.

361
00:21:46,095 --> 00:21:50,735
You send the payload to the adjudicator,
a payload will contain the right

362
00:21:50,735 --> 00:21:55,405
sets, which are the items that you
modified copies of the table, roads,

363
00:21:55,435 --> 00:21:57,565
applying effects of a transaction.

364
00:21:57,775 --> 00:22:01,945
The payload also contain, contains the
transaction start time, which is the

365
00:22:01,945 --> 00:22:06,565
T start, which is crucial element in
committing or aborting the transaction.

366
00:22:06,665 --> 00:22:08,795
So let's look at how this works.

367
00:22:09,295 --> 00:22:11,965
So coordinate once only at commit time.

368
00:22:12,535 --> 00:22:17,065
So you have your query processor once
it's ready to, once the query processors

369
00:22:17,065 --> 00:22:22,105
have done all the transactions that has
been given, what the query processor

370
00:22:22,195 --> 00:22:26,755
does is sends you the adjudicator and
pretty much says to the adjudicator, dear

371
00:22:26,755 --> 00:22:31,615
adjudicator, here are the keys I intend
to write, and here are my transaction.

372
00:22:31,615 --> 00:22:36,265
Start time if no other transactions
have been reading these key since.

373
00:22:36,685 --> 00:22:40,735
They start time that I've done my read.

374
00:22:41,305 --> 00:22:46,045
Pick a time for a commit and write
these changes to the journal.

375
00:22:46,375 --> 00:22:50,635
Your friend query processors
what the adjudicator will do.

376
00:22:50,695 --> 00:22:54,145
You'll never allow another
conflict transaction to pick

377
00:22:54,145 --> 00:22:56,965
a lower T commit, right?

378
00:22:57,055 --> 00:23:00,925
So if behind the scenes there was
another transaction that comes.

379
00:23:01,270 --> 00:23:05,710
Few seconds after this and says,
oh, I have actually a transaction

380
00:23:05,710 --> 00:23:10,080
that is started, after the T
start, but before the T commit.

381
00:23:10,650 --> 00:23:13,650
The adjudicator will be like, you
are not gonna be able to do that.

382
00:23:13,680 --> 00:23:18,270
It's gonna abort your transaction and your
application need to retry the transaction.

383
00:23:18,270 --> 00:23:22,800
That is one of the things that you need
to be aware of as building applications

384
00:23:22,800 --> 00:23:25,260
with this SQL that you need to retry.

385
00:23:25,260 --> 00:23:25,320
If.

386
00:23:26,055 --> 00:23:29,885
That transaction gets abor by the
seco because there was a conflict.

387
00:23:30,385 --> 00:23:34,695
I'm gonna show you in the multi region,
active scenario, that adjudicator is the

388
00:23:34,695 --> 00:23:37,005
piece that grows across the region, right?

389
00:23:37,005 --> 00:23:38,745
That is the piece that
goes across the region.

390
00:23:39,135 --> 00:23:42,935
And, it shards different
keys across different regions

391
00:23:43,185 --> 00:23:44,505
sorry, d those two regions.

392
00:23:44,505 --> 00:23:48,945
So it needs to send the data for, a
specific query across the regions to make

393
00:23:48,945 --> 00:23:51,885
sure it's actually able to do that now.

394
00:23:52,385 --> 00:23:59,375
So if you have two specific transactions
that are changing the same role, right?

395
00:23:59,405 --> 00:24:03,552
So if I have transaction one that
you start at 10 0 9 33, but 10 0 9

396
00:24:03,552 --> 00:24:08,075
35, if I have the two transactions,
A and B, and they start roughly at

397
00:24:08,075 --> 00:24:13,265
the same time, but transaction A
sends a commit for the transaction is

398
00:24:13,265 --> 00:24:18,565
likely before transaction B. What will
happen in this case, in this case.

399
00:24:19,065 --> 00:24:23,415
What would happen is the
adjudicator look at, are you

400
00:24:23,415 --> 00:24:25,605
trying to write at the same row?

401
00:24:25,785 --> 00:24:32,625
In this case, adjudicator discovers
inter in intersecting rights, right?

402
00:24:33,045 --> 00:24:37,845
And so you compare the payloads from the
query processor it's looking for, right?

403
00:24:37,875 --> 00:24:42,840
Any rights that have a T start time
and propose what needs to be in index.

404
00:24:43,575 --> 00:24:47,790
In this case, as you can see here,
is trying to update the same payload.

405
00:24:48,390 --> 00:24:53,250
So only transaction A is gonna be
approved because both can change

406
00:24:53,250 --> 00:24:54,660
the same role at the same time.

407
00:24:54,870 --> 00:25:00,180
So transaction A is gonna get committed
where our transaction B must be

408
00:25:00,180 --> 00:25:04,230
aborted, and your application must
retry because then when your application

409
00:25:04,230 --> 00:25:08,790
retries, you actually go to the storage
layer and retrieve the new data, the

410
00:25:08,790 --> 00:25:10,680
transaction they have just updated.

411
00:25:10,710 --> 00:25:14,400
So you don't have any loss of
data or in any inconsistency.

412
00:25:14,900 --> 00:25:20,330
Now the cool thing about adjudicator is if
the transactions do not intersect, in this

413
00:25:20,330 --> 00:25:24,770
case you can see one of the, maybe it's
too small for you to see, but transaction

414
00:25:24,770 --> 00:25:31,130
A is trying to write on item 93 and
transaction B is trying to write item 97.

415
00:25:31,530 --> 00:25:35,820
Even though some other selects are exactly
the same, both transactions are gonna be

416
00:25:35,820 --> 00:25:40,960
allowed to be committed and both commits
will proceed, which is really good.

417
00:25:41,425 --> 00:25:47,475
Another very interesting thing about the
SECO is in traditional databases, the

418
00:25:47,475 --> 00:25:49,515
durability happen at the storage layer.

419
00:25:50,015 --> 00:25:53,915
Transactions are only committed once
they are durably written in the storage

420
00:25:53,915 --> 00:25:56,645
layer that is for traditional databases.

421
00:25:57,485 --> 00:26:01,775
So the storage layer is expected
to be able to recover al committed

422
00:26:01,775 --> 00:26:04,175
transactions from storage after any phase.

423
00:26:04,675 --> 00:26:10,085
These requirements add significant
complexity to the database engines,

424
00:26:10,085 --> 00:26:14,465
including logging, coordinating systems,
APIs, and need to keep a storage

425
00:26:14,465 --> 00:26:16,985
consistent with more for recover purposes.

426
00:26:17,485 --> 00:26:18,625
On the sql.

427
00:26:19,125 --> 00:26:24,555
The durability is given to the
journal, and of course the journal,

428
00:26:24,555 --> 00:26:28,635
if you're using a multi-region,
active solution is replicated across.

429
00:26:29,370 --> 00:26:31,590
Multiple multiple regions.

430
00:26:31,650 --> 00:26:35,520
And this is where, if you remember
when I said I have the witness

431
00:26:35,520 --> 00:26:39,180
region, that witness region is
a replication of the journey.

432
00:26:39,720 --> 00:26:44,310
Journey is just where all your transaction
logs for your database are stored.

433
00:26:44,940 --> 00:26:49,980
So this CCOs manages this complexity
by making the journal response

434
00:26:50,010 --> 00:26:51,810
responsible for the short term dur.

435
00:26:51,810 --> 00:26:56,750
Both transactions are considered committed
once they are reading to the journal.

436
00:26:57,110 --> 00:27:00,890
Not once they are reading to the
storage, the journal can escape

437
00:27:00,890 --> 00:27:04,280
horizontally and transactions
can be reading to any journal.

438
00:27:04,780 --> 00:27:10,200
They coordinated to provide a totally
order stream of committed transactions.

439
00:27:10,230 --> 00:27:14,630
Remember, because now the adjudicator
makes sure that the priority and the

440
00:27:14,630 --> 00:27:16,640
order of the transactions are in place.

441
00:27:16,760 --> 00:27:19,820
The journal now have these
transaction logs that are ordered.

442
00:27:20,390 --> 00:27:25,400
And the crossbar component uses the
journals ordering to ensure that

443
00:27:25,460 --> 00:27:29,420
the updates that are applied to the
storage are in the correct sequence,

444
00:27:29,570 --> 00:27:31,670
even when there are multiple journals.

445
00:27:32,150 --> 00:27:33,800
So this is the cool thing, right?

446
00:27:33,800 --> 00:27:35,660
Because now you have this journal.

447
00:27:36,020 --> 00:27:40,340
That, can you scale horizontally and any
transaction can be written to any journal.

448
00:27:40,580 --> 00:27:44,780
But because the ordering that adjudicator
allows you to do is the crossbar

449
00:27:44,780 --> 00:27:49,460
components, we use that journal ordering
and ensure that the storage is also

450
00:27:49,710 --> 00:27:52,410
save the data into the correct order.

451
00:27:52,590 --> 00:27:54,600
And this is actually pretty cool, right?

452
00:27:55,100 --> 00:28:00,170
So the payload and the timestamp
are sent to the journal.

453
00:28:00,560 --> 00:28:02,600
Once the journal acknowledges.

454
00:28:03,100 --> 00:28:06,910
The right, the updates then
are sent to the storage nos.

455
00:28:07,150 --> 00:28:11,980
The journal sends a success code
to the query processor, which sends

456
00:28:11,980 --> 00:28:14,350
back a success code to the client.

457
00:28:14,800 --> 00:28:17,740
From the user perspective,
the transaction is done.

458
00:28:17,830 --> 00:28:21,340
And this is the interesting part
because now the journal is where

459
00:28:21,400 --> 00:28:22,960
the durability happens, right?

460
00:28:22,960 --> 00:28:25,420
And journal is the place that
says, okay, it's good to go.

461
00:28:25,570 --> 00:28:27,250
You go because it's replicated across.

462
00:28:27,500 --> 00:28:30,320
Multiple availability zones and
multiple regions, and it has the

463
00:28:30,350 --> 00:28:32,930
consistence and the order that you have.

464
00:28:33,430 --> 00:28:37,720
So we talked a lot about the S QL
so far, and I have a couple more

465
00:28:37,720 --> 00:28:40,880
slides before I am the presentation.

466
00:28:41,380 --> 00:28:44,440
Our RD SQL uses optimistic
concurrence control.

467
00:28:44,860 --> 00:28:49,360
So rather than putting a lock
when you are starting an insert

468
00:28:49,510 --> 00:28:50,710
and you need to do multiple.

469
00:28:51,160 --> 00:28:54,310
Selects and multiple, insert
multiple updates on the row.

470
00:28:54,430 --> 00:28:55,690
That is not how it works.

471
00:28:55,900 --> 00:29:03,170
Doing a pessimistic log allows you to have
a concurrence play here, which makes a

472
00:29:03,170 --> 00:29:08,840
crucial row for multiple transactions to
occur Simultaneously, we, without leading

473
00:29:08,840 --> 00:29:14,510
to inconsistency of data, you might need
to retry some of those transactions if the

474
00:29:14,510 --> 00:29:19,730
transactions are within the same period
as I explained the capability and the.

475
00:29:20,075 --> 00:29:21,575
And the row of the adjudicator.

476
00:29:21,965 --> 00:29:25,925
There are no deadlocks conflicts
will be detected at the transaction.

477
00:29:25,925 --> 00:29:27,515
Commit by the adjudicator.

478
00:29:28,355 --> 00:29:31,835
You have a multi-region concurrency
protection now because every single

479
00:29:31,835 --> 00:29:35,705
data that is committed is guaranteed
if you're using an active multi

480
00:29:35,705 --> 00:29:41,075
region architecture that they are
consistent across these regions.

481
00:29:41,615 --> 00:29:44,945
Now we have an efficient storage
layer from synchronous replication

482
00:29:44,945 --> 00:29:46,355
because of the journal capability.

483
00:29:46,370 --> 00:29:51,740
This and allows you as a developer
to really design new capabilities and

484
00:29:51,740 --> 00:29:53,870
new design patterns for developers.

485
00:29:53,970 --> 00:29:59,680
So there are multiple things here that we
could talk about it, but what I'll show

486
00:29:59,680 --> 00:30:04,990
you some of the extra documentations that
you can go and do a little bit of reading.

487
00:30:05,230 --> 00:30:09,640
There is great reinvent videos
also posted on the AWS channel.

488
00:30:10,600 --> 00:30:14,710
What I want to show you is behind
the scenes, how is the architecture

489
00:30:14,710 --> 00:30:17,830
for an active DCO database?

490
00:30:18,330 --> 00:30:23,430
So when we look at an active
architecture, you have three regions.

491
00:30:23,490 --> 00:30:28,200
Like I said, you have one region,
two regions with endpoints, region

492
00:30:28,200 --> 00:30:30,300
A and region C in this diagram.

493
00:30:30,660 --> 00:30:34,460
And region B is what we call
the witness the witness region.

494
00:30:34,960 --> 00:30:39,550
You have, one router on each of
those regions that have endpoints.

495
00:30:39,550 --> 00:30:40,690
Those are the endpoints.

496
00:30:40,870 --> 00:30:44,470
And then, even though it says one
query processor here, one box, think

497
00:30:44,470 --> 00:30:48,560
about that being, the micro VM from
firecracker, which is gonna run

498
00:30:48,560 --> 00:30:50,780
the Postgres engine there, right?

499
00:30:51,320 --> 00:30:56,200
So you can have multiple query processors
each actually transaction is a query

500
00:30:56,200 --> 00:30:58,090
processor invocation on its own.

501
00:30:58,590 --> 00:31:03,990
Thes l internally will actually host
across multiple availability zones, right?

502
00:31:04,200 --> 00:31:08,670
So realistically, ER stack would be
duplicated across three availability

503
00:31:08,670 --> 00:31:10,530
zones in each of these three regions.

504
00:31:11,190 --> 00:31:14,070
And here you have the adjudicator.

505
00:31:14,070 --> 00:31:18,450
And you can see here the adjudicator is
the only one that is responsible, the

506
00:31:18,450 --> 00:31:23,880
only one that requires you to have a
cross region communication at the right.

507
00:31:24,465 --> 00:31:27,995
At the commit of a right, and
you can see that adjudicator will

508
00:31:27,995 --> 00:31:32,945
have specific keys that are led by
specific adjudicator in this case.

509
00:31:33,075 --> 00:31:36,115
Because that's how you know,
you guaranteed the consistency

510
00:31:36,115 --> 00:31:39,835
across the transactions from
multiple places, multiple regions.

511
00:31:40,075 --> 00:31:44,245
Then you have the journal and you can see
the journal is actually replicated across.

512
00:31:44,695 --> 00:31:48,325
All the three regions because
that's where the durability happens.

513
00:31:48,325 --> 00:31:52,105
So the journal is where the transaction
logs are stored, and it's a key

514
00:31:52,105 --> 00:31:54,835
critical key component of the sql.

515
00:31:55,075 --> 00:31:58,885
Then you have the storage, of course,
that will read from the journal.

516
00:31:58,915 --> 00:32:01,585
You have a crossbar that is not
on this diagram that you read

517
00:32:01,585 --> 00:32:04,945
from the journal and actually make
those changes into the storage.

518
00:32:05,395 --> 00:32:10,375
So the journal only witness, which
is region B, ensures that if there

519
00:32:10,375 --> 00:32:12,505
is a split between those two regions.

520
00:32:13,045 --> 00:32:16,915
The available side can continue to be
available and consistent for client.

521
00:32:16,945 --> 00:32:21,075
On the other side of the partition,
for distributions that go across

522
00:32:21,075 --> 00:32:24,615
large geographies, you can put the
witness kind in the middle, right?

523
00:32:24,615 --> 00:32:28,595
So if you have, let's say, one region,
apologies, one region in the US

524
00:32:28,805 --> 00:32:30,215
and you might have another region.

525
00:32:31,100 --> 00:32:34,140
In Australia, you might wanna
put another region maybe in the

526
00:32:34,140 --> 00:32:35,700
Middle East on Europe, right?

527
00:32:35,700 --> 00:32:38,850
That is a nice sort of additional
property that you can actually

528
00:32:38,850 --> 00:32:41,250
optimize for latency as well, right?

529
00:32:41,750 --> 00:32:46,050
So let's talk about what happened
if Ency in this case goes down, not,

530
00:32:46,500 --> 00:32:49,860
let's knock on the wood here, but
let's say if there is a catastrophe or

531
00:32:49,860 --> 00:32:53,910
something happens with the region as
sea goes down, which is very uncommon

532
00:32:54,040 --> 00:32:55,780
but let's say that region goes down.

533
00:32:56,280 --> 00:33:00,390
Any adjudicator leadership that short
leave state for doing an isolation

534
00:33:00,390 --> 00:33:05,370
moves out of their region regency
and remain into the health region.

535
00:33:05,400 --> 00:33:07,740
Because remember, you need all
the keys for the adjudicators

536
00:33:07,740 --> 00:33:09,150
to make you know the control.

537
00:33:09,540 --> 00:33:13,410
Now the journal is splitted
across region A, region B, which

538
00:33:13,410 --> 00:33:14,850
is region B is the weakness.

539
00:33:14,870 --> 00:33:20,990
So you still have that durable storage in
the, in two regions and only the health

540
00:33:20,990 --> 00:33:22,610
side of the database remains available.

541
00:33:22,670 --> 00:33:27,620
Of course, the endpoint of Regency won't
work, but endpoint region will continue to

542
00:33:27,620 --> 00:33:30,380
work for reads rights at any given time.

543
00:33:31,070 --> 00:33:35,660
So you do, you then need to move traffic
to the health side, so of the partition.

544
00:33:35,970 --> 00:33:41,780
So you can, just either use that specific
endpoint or you can do a route 53.

545
00:33:42,085 --> 00:33:44,605
Lat sensitive routing with
health checks and so on.

546
00:33:44,635 --> 00:33:47,455
It's how you are using
endpoint on an application.

547
00:33:47,485 --> 00:33:48,445
It's completed for you.

548
00:33:48,685 --> 00:33:53,185
You can just have one specific endpoint
for the region, or you can actually

549
00:33:53,185 --> 00:33:57,865
potentially just create a DNS with
Route 53 that you know, will you do

550
00:33:57,975 --> 00:34:01,245
the routing with health checks for
that specific regions that is working.

551
00:34:01,745 --> 00:34:05,915
So this is what I wanted to
present to you about this S ql.

552
00:34:06,525 --> 00:34:08,835
This que is currently in public preview.

553
00:34:09,265 --> 00:34:12,565
Hopefully soon it'll be in general
available that you will be able

554
00:34:12,565 --> 00:34:14,965
to run production workloads.

555
00:34:15,325 --> 00:34:20,125
But if you have interest, please
feel free to reach out on LinkedIn.

556
00:34:20,175 --> 00:34:23,595
Again, my name is Samuel bfi,
but also you can scan this here.

557
00:34:23,595 --> 00:34:23,955
Codes.

558
00:34:23,955 --> 00:34:27,735
We have, the documentation of the
cco, some of the dsco or public

559
00:34:27,735 --> 00:34:31,525
web pages, and also the useful blog
posts that have that have we shared.

560
00:34:31,555 --> 00:34:36,175
And I've mentioned there are great
Ring van 2024 talks that are available

561
00:34:36,175 --> 00:34:41,165
for you to consume on YouTube, and I
highly recommend for you to do that.

562
00:34:42,035 --> 00:34:44,645
So let us know what
you thought about that.

563
00:34:44,695 --> 00:34:49,715
Hopefully you'll be building new,
exciting, resilient, and highly

564
00:34:49,715 --> 00:34:51,760
available applications on top of the SQL.

565
00:34:52,700 --> 00:34:55,300
And we are very excited
to see what you can do.

566
00:34:55,450 --> 00:34:59,200
So thank you so much for taking
the time to watch my session.

567
00:34:59,600 --> 00:35:00,560
And I'll see you soon.

568
00:35:01,190 --> 00:35:01,490
Bye bye.

