1
00:00:00,210 --> 00:00:01,230
My name is Max.

2
00:00:01,360 --> 00:00:04,090
So today we'll talk about
predicting and mitigating

3
00:00:04,090 --> 00:00:06,310
emergency situations, on the road.

4
00:00:06,380 --> 00:00:07,400
So we'll use.

5
00:00:07,780 --> 00:00:13,380
Not only transport market
examples, we will use specific

6
00:00:13,380 --> 00:00:15,090
examples from, railways business.

7
00:00:15,200 --> 00:00:17,950
but before we start,
let me introduce myself.

8
00:00:18,000 --> 00:00:20,829
as of today, I have over
10 years experience in, dot

9
00:00:20,830 --> 00:00:21,839
science, machine learning and AI.

10
00:00:22,339 --> 00:00:26,150
So I worked in different business
sectors, such as, telco, fintech,

11
00:00:26,460 --> 00:00:28,500
consulting and the entertainment industry.

12
00:00:29,000 --> 00:00:32,350
And recently I've worked in the warm
music group as a director of research

13
00:00:32,360 --> 00:00:36,680
and analysis, but now I'm a dot science
lead in consulting company Metis.

14
00:00:37,180 --> 00:00:38,520
So welcome on board.

15
00:00:38,640 --> 00:00:43,580
And today we will talk about
to how to save environment and

16
00:00:43,580 --> 00:00:48,910
how to make money, how to bring
additional value for our business.

17
00:00:48,960 --> 00:00:51,160
In our case, it was a transport company.

18
00:00:51,630 --> 00:00:52,110
It was a.

19
00:00:52,610 --> 00:00:56,150
This project was implemented for one
of the largest railway companies in

20
00:00:56,150 --> 00:01:00,970
Europe and had a big impact, so the
results were truly transformative.

21
00:01:01,030 --> 00:01:03,910
And of course we will
talk about it as well.

22
00:01:04,410 --> 00:01:11,225
But, let me Introduce what the
approach we used, I and my team, here's

23
00:01:11,225 --> 00:01:13,095
what we are going to cover today.

24
00:01:13,145 --> 00:01:16,205
the first, I'll introduce the
problem we'll set out to solve.

25
00:01:16,235 --> 00:01:20,345
Then I'll walk you through our
approach and the data we'll used.

26
00:01:21,265 --> 00:01:24,435
And, what kind of model
we built on this, data.

27
00:01:25,025 --> 00:01:27,175
What the problem we have,
what a challenge we faced.

28
00:01:27,675 --> 00:01:31,005
And, of course we'll
dive into the results.

29
00:01:31,635 --> 00:01:37,555
actually the problem must sounds
like, pretty simple, freight car

30
00:01:37,555 --> 00:01:39,395
derailments are happening across.

31
00:01:39,760 --> 00:01:46,880
The network of, railways companies
at the main point when, we needed

32
00:01:46,880 --> 00:01:52,990
to address the problem and, develop
and execute, the system which

33
00:01:53,120 --> 00:01:56,020
could prevent them by the events.

34
00:01:56,590 --> 00:02:01,550
we used, different data, but we
needed not only based on data

35
00:02:01,620 --> 00:02:03,570
built the predictive model.

36
00:02:04,190 --> 00:02:05,150
We needed to.

37
00:02:05,625 --> 00:02:11,125
describe and we needed to define
the patterns which could help

38
00:02:11,125 --> 00:02:14,395
us to prevent the derailment.

39
00:02:14,925 --> 00:02:17,945
This problem is not just
about avoiding accidents.

40
00:02:17,975 --> 00:02:22,895
Of course, it's about saving
lives, predicting problems and

41
00:02:23,205 --> 00:02:29,005
protecting the environment and saving
million of dollars in repair cost.

42
00:02:29,885 --> 00:02:31,675
And, but the problem solving plan.

43
00:02:32,175 --> 00:02:33,495
And, our approach.

44
00:02:34,240 --> 00:02:38,180
looks like, the first one, we
gathered historical data and

45
00:02:38,180 --> 00:02:40,020
identified, the key target.

46
00:02:40,580 --> 00:02:44,600
Of course, in our case, it
was a derailments, but overall

47
00:02:44,650 --> 00:02:46,570
it could be just a problem.

48
00:02:46,720 --> 00:02:51,850
And, Some risks and some,
emergency situations on the road.

49
00:02:52,480 --> 00:02:55,150
then we assess the quality of the data.

50
00:02:55,190 --> 00:03:00,030
Of course, we can't skip this
step and to ensure the accuracy.

51
00:03:00,030 --> 00:03:03,970
So we developed a model that could predict
the probability of right car derailments.

52
00:03:03,990 --> 00:03:06,740
And lastly, we evaluated the results.

53
00:03:07,130 --> 00:03:08,980
So we built a road map.

54
00:03:09,135 --> 00:03:14,195
Of end to end process that delivered
real value from start to finish.

55
00:03:14,635 --> 00:03:18,245
So that's, the first
challenge where we faced.

56
00:03:18,745 --> 00:03:25,865
It was the parameters and it was the
data and the variable, gathering and the

57
00:03:25,875 --> 00:03:28,525
figure out what kind of data we have.

58
00:03:29,025 --> 00:03:33,125
But we used, 78 key parameters
from various systems ranging

59
00:03:33,145 --> 00:03:37,735
from, track conditions to weather,
locomotive data and wagon details.

60
00:03:38,085 --> 00:03:42,545
But in addition to those, 78
parameters, we used also sensory

61
00:03:42,545 --> 00:03:45,275
data, which, was captured on them.

62
00:03:45,525 --> 00:03:47,035
track on the wagon.

63
00:03:47,535 --> 00:03:52,835
And based on that, not only
daily, activities, we've seen,

64
00:03:52,895 --> 00:03:56,975
we also seen, actually real
time data from, these sensors.

65
00:03:57,745 --> 00:04:01,535
And, also we engineered
30 calculated indicators.

66
00:04:01,605 --> 00:04:04,085
This include features,
average cargo weight.

67
00:04:04,290 --> 00:04:09,330
time between repairs and other factors
that gave us even deeper insights

68
00:04:09,340 --> 00:04:13,140
into their understanding of problems
and understanding of their business.

69
00:04:13,630 --> 00:04:15,990
data processing was also crucial.

70
00:04:16,010 --> 00:04:19,640
So we used standardization for
quantitative variables and one hot

71
00:04:19,700 --> 00:04:22,320
encoding for our target variables.

72
00:04:22,585 --> 00:04:27,615
derailment, ensuring that our model
could accurately interpret all of this.

73
00:04:28,385 --> 00:04:32,775
And when we figure out what kind
of parameters we have, when we

74
00:04:32,775 --> 00:04:39,645
process all data, we switch to
the next step, exactly model.

75
00:04:39,875 --> 00:04:44,345
So here is where we faced a major
challenge, class imbalance because

76
00:04:44,345 --> 00:04:46,815
of the event of derailments.

77
00:04:47,505 --> 00:04:54,055
The event of emergency, it's really
rare when we compare that to non events.

78
00:04:54,065 --> 00:04:57,675
So only 1 percent of the data
represented derailments and

79
00:04:57,675 --> 00:04:59,545
then a percent were non events.

80
00:04:59,575 --> 00:05:02,165
So we have the two options, of course.

81
00:05:02,800 --> 00:05:07,930
Obviously, under sampling or
oversampling, but, either reduce the

82
00:05:07,930 --> 00:05:13,570
number of non-events, it mean that we
could lose, valuable data or we could

83
00:05:13,570 --> 00:05:16,780
use a more than, oversampling more.

84
00:05:17,280 --> 00:05:19,130
Smart way, use a SMODE.

85
00:05:19,180 --> 00:05:23,850
So SMODE is a synthetic,
samples for minority class.

86
00:05:23,900 --> 00:05:25,670
In our case, it was a derailment.

87
00:05:25,680 --> 00:05:30,130
It was a target and, it help us
to creating more diversity and

88
00:05:30,130 --> 00:05:32,410
improving the models, performance.

89
00:05:32,550 --> 00:05:40,410
So it means that it's smarter than
just, adding a random, target, right?

90
00:05:40,910 --> 00:05:43,170
SMOAT, that's why we use it.

91
00:05:43,230 --> 00:05:46,570
So we did try building the
model without any oversampling,

92
00:05:46,650 --> 00:05:47,790
but the results were poor.

93
00:05:48,430 --> 00:05:52,260
That's why SMOAT allowed us to
improve the prediction accuracy

94
00:05:52,300 --> 00:05:54,380
without compromising data integrity.

95
00:05:55,010 --> 00:05:59,070
And, it's far better
solution than the basic.

96
00:05:59,650 --> 00:06:03,610
Some oversampling because, basic
oversampling is just a random

97
00:06:03,690 --> 00:06:10,050
oversampling, but small to use a
patterns, which, our data, which our

98
00:06:10,100 --> 00:06:14,750
parameters, not only target, which our
independent parameters consists of.

99
00:06:15,715 --> 00:06:22,185
When we implemented the SMOD, when we
figured out the problem of, proportions,

100
00:06:22,265 --> 00:06:26,705
so we needed to address the step of
what kind of model we need to use.

101
00:06:27,025 --> 00:06:29,935
So for model algorithms,
we choose a random forest.

102
00:06:30,405 --> 00:06:32,535
of course, the standard question, why?

103
00:06:33,114 --> 00:06:38,005
And, because it's a really powerful model,
that, Could help us interpret parameters

104
00:06:38,055 --> 00:06:45,325
well and mostly importantly it has less
tendency to overfitting of course the many

105
00:06:45,465 --> 00:06:53,005
models which we built had a Tendency had a
alignment to overfitting because it has a

106
00:06:53,395 --> 00:07:00,065
imbalance, but we covered that using SMOLT
and we covered that using random forest.

107
00:07:00,255 --> 00:07:04,785
So given the assumption that we have the
risk of imbalanced data, despite SMOLT,

108
00:07:05,205 --> 00:07:09,555
this was the best choice for balancing
interpretability and the performance.

109
00:07:10,135 --> 00:07:12,445
So based on metrics.

110
00:07:12,560 --> 00:07:16,910
on the left side, you could see true
positive rate and a false positive rate.

111
00:07:17,270 --> 00:07:20,030
So we get really pretty great.

112
00:07:20,435 --> 00:07:28,704
results like 80 percent of both, but now
let's talk about, ROC, AUC and, PR AUC.

113
00:07:28,984 --> 00:07:32,104
Both are crucial for us, but
they tell us, different things.

114
00:07:32,155 --> 00:07:36,855
ROC AUC show us how well the model
differentiates between events

115
00:07:36,855 --> 00:07:40,595
and non events overall, which is
great for understanding general.

116
00:07:40,815 --> 00:07:41,575
performance.

117
00:07:41,645 --> 00:07:43,585
As we can see, we had a strong score.

118
00:07:44,085 --> 00:07:45,565
It's 0.

119
00:07:46,135 --> 00:07:46,715
91.

120
00:07:47,305 --> 00:07:51,835
But with the class imbalance, which
we faced in our case, we needed to

121
00:07:51,865 --> 00:07:57,904
check that, using PR AUC because
it's even more crucial in that case.

122
00:07:58,735 --> 00:08:03,175
It focuses specifically on how well
the model predicts the minority class.

123
00:08:03,325 --> 00:08:08,460
So derailments, In our case, so we
could, we had a good results of,

124
00:08:08,510 --> 00:08:14,259
PR you see as well, meaning our
model excels at identifying events.

125
00:08:14,600 --> 00:08:19,260
So looking at both metrics gives us
a full picture of the model strings.

126
00:08:19,760 --> 00:08:24,700
And when we build the model, here's where
the real world applications comes in.

127
00:08:25,040 --> 00:08:27,250
So you can see the scroll button.

128
00:08:27,340 --> 00:08:31,350
It's probability of derailments
in a technical language.

129
00:08:31,360 --> 00:08:33,310
It's called a cutoff threshold.

130
00:08:33,790 --> 00:08:36,859
So we can manage that based
on the available resources.

131
00:08:36,909 --> 00:08:40,430
If our organization has a limited
resources for inspections,

132
00:08:40,760 --> 00:08:42,410
we can set and concentrate.

133
00:08:42,720 --> 00:08:46,840
More, on the probability on
the high value to only focus on

134
00:08:46,840 --> 00:08:48,420
the highest risk freight cars.

135
00:08:48,710 --> 00:08:54,680
This way we prioritize those that
need attention most urgently, ensuring

136
00:08:54,680 --> 00:08:57,130
that resources are used efficiently.

137
00:08:57,350 --> 00:09:03,030
So of course, if we had a infinite
resources, we could a bit decrease the

138
00:09:03,060 --> 00:09:05,380
probability, a bit decrease the threshold.

139
00:09:05,410 --> 00:09:09,499
It means that we could
check, the wagon, who.

140
00:09:10,034 --> 00:09:14,884
Could, fall, but with a
less probability than other.

141
00:09:15,384 --> 00:09:21,494
And, but the random forest we used,
not only because it's a really great

142
00:09:21,574 --> 00:09:29,104
algorithms for a lot of data we could
use, it's not only, because the, this

143
00:09:29,154 --> 00:09:31,054
kind of model, this kind of approach.

144
00:09:31,449 --> 00:09:37,069
really is working good with, imbalance,
but, one of the key reasons we use

145
00:09:37,069 --> 00:09:42,359
random forest was to understand the
Gini impurity, which helps us see how

146
00:09:42,389 --> 00:09:44,769
different variables impact, derailments.

147
00:09:45,269 --> 00:09:46,609
So simply.

148
00:09:47,324 --> 00:09:51,074
Talking, we just needed to
use a variable importance.

149
00:09:51,394 --> 00:09:54,434
So for example, winter season
shows a strong influence, but

150
00:09:54,454 --> 00:09:56,324
that's something we can't control.

151
00:09:56,614 --> 00:10:01,044
On the other hand, factors like a wagon
type or cargo weight or the material of

152
00:10:01,044 --> 00:10:06,334
the track section are things we can't
control and we needed focused on that.

153
00:10:06,754 --> 00:10:11,864
Allow the business to focus on area where
changes will have the greatest impact.

154
00:10:12,364 --> 00:10:15,124
Even though we've
identified key variables.

155
00:10:15,340 --> 00:10:17,930
These are not full risk profiles.

156
00:10:17,980 --> 00:10:23,580
It's just the importance of our variable,
which we put into the model, but we needed

157
00:10:23,580 --> 00:10:28,450
to move beyond this to understand exactly
which combination of factors lead to

158
00:10:28,510 --> 00:10:31,020
derailments to prevent this derailment.

159
00:10:31,030 --> 00:10:33,129
So we needed to get a scenarios.

160
00:10:33,129 --> 00:10:35,580
We needed to get a patterns, which could

161
00:10:36,080 --> 00:10:38,870
get to derailments of our.

162
00:10:39,370 --> 00:10:44,560
So to do that, to create the actionable
risk profiles for business units, we

163
00:10:44,570 --> 00:10:49,050
fed the probabilities from our random
forest model into the decision tree.

164
00:10:49,400 --> 00:10:55,599
So it looked like, just an ensemble
of a model, but this was a critical

165
00:10:55,659 --> 00:10:59,999
because the decision tree offers
clear interpretable results, which

166
00:11:00,259 --> 00:11:01,939
random forest does not offer.

167
00:11:02,439 --> 00:11:06,089
This showed us exactly how
variables combine to create high

168
00:11:06,089 --> 00:11:10,669
risk scenarios, allowing for
precise targeted interventions.

169
00:11:11,359 --> 00:11:16,719
Now we had a, not just the predictions,
but, insights into the why and how

170
00:11:16,719 --> 00:11:19,009
derailments were likely to happen.

171
00:11:19,329 --> 00:11:23,279
So how we can read that,
how we can interpret that.

172
00:11:23,739 --> 00:11:29,129
So from that profile, from a
random forest probability, which

173
00:11:29,129 --> 00:11:31,149
we could put in the decision tree.

174
00:11:31,604 --> 00:11:38,564
we could get the next risk profiles
that's let's consider the one example.

175
00:11:38,824 --> 00:11:42,124
So if the number of wagons is below 38.

176
00:11:42,194 --> 00:11:47,374
5, the year since
issuance are less than 51.

177
00:11:47,374 --> 00:11:51,304
5 and the speed rate on the
last section is below 1.

178
00:11:51,304 --> 00:11:51,319
0.

179
00:11:51,819 --> 00:11:57,939
There is a, that's mean that
our wagon get to fall with a 94.

180
00:11:57,939 --> 00:12:01,419
5 probability of derailment.

181
00:12:01,649 --> 00:12:05,989
So that's why we need it to get,
and this is what the company

182
00:12:05,999 --> 00:12:07,659
needs to prevent derailment.

183
00:12:07,709 --> 00:12:11,449
So not only probability, but
clear actionable patterns.

184
00:12:12,329 --> 00:12:15,249
And finally, here's the, our results.

185
00:12:15,289 --> 00:12:18,329
First, we achieved an 80 percent of.

186
00:12:18,614 --> 00:12:22,304
reduction in accidents, fewer
accidents, of course, it means

187
00:12:22,364 --> 00:12:26,404
less downtime and a safer, more
efficient transportation network.

188
00:12:27,104 --> 00:12:30,794
Secondly, we help minimize
environment risks.

189
00:12:31,554 --> 00:12:36,964
Derelements often lead to significant
environmental damage, of course, but

190
00:12:37,004 --> 00:12:41,284
by predicting, preventing them, we've
protecting both the company and the

191
00:12:42,149 --> 00:12:46,849
And, environment, of course, we, it's
really complex to translate that, into

192
00:12:46,849 --> 00:12:53,999
money it's, but we try to address not
only quantitative purposes, we try to

193
00:12:54,499 --> 00:12:56,879
reach the aim of, qualitative purposes.

194
00:12:57,379 --> 00:12:59,689
Approach and qualitative KPI as well.

195
00:13:00,189 --> 00:13:02,889
And third, we saved the
company 12 million a year.

196
00:13:02,899 --> 00:13:07,929
This savings came from reducing
the need for emergency repairs

197
00:13:08,319 --> 00:13:10,869
and ensuring insurance payout.

198
00:13:11,369 --> 00:13:14,679
So if you have any questions,
please reach me out on LinkedIn.

199
00:13:15,369 --> 00:13:23,414
And, I hope that, this Short presentation
was a bit inspiration for how IOT and

200
00:13:23,504 --> 00:13:29,244
data driven insights can not only be
buzzwords, but it helped to predict

201
00:13:29,244 --> 00:13:34,994
challenges, but actively and actively
create safer, smarter roads for everyone.

202
00:13:35,554 --> 00:13:40,584
Hopefully together we could reshape,
this industry and the future

203
00:13:40,624 --> 00:13:42,364
of, connected transportation.

204
00:13:42,744 --> 00:13:48,334
But, by the way, today we'll talk about
not only future, we talked about, the

205
00:13:48,334 --> 00:13:54,744
present where we could already implement
and execute all AI applications.

206
00:13:54,974 --> 00:13:55,414
Thank you.

