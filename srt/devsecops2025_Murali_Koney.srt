1
00:00:00,500 --> 00:00:03,204
Hello, this is Ani currently
working as a technical team at Cox.

2
00:00:03,744 --> 00:00:07,730
Today I'll be talking about securing
enterprise ai and some of the different

3
00:00:07,730 --> 00:00:10,850
concepts include including and how
do we secure our enterprise ai,

4
00:00:10,850 --> 00:00:14,130
which includes the governance risk
and economics of L Element option.

5
00:00:14,650 --> 00:00:17,320
Let's take a look into the
the enterprise AI real check.

6
00:00:17,620 --> 00:00:19,180
So what's the promise
and what's the challenge?

7
00:00:19,210 --> 00:00:21,490
So large language models are
currently transforming how

8
00:00:21,490 --> 00:00:23,480
enterprises are trying to operate.

9
00:00:23,550 --> 00:00:27,450
And it also includes like promising,
enhanced productivity, intelligence,

10
00:00:27,450 --> 00:00:29,775
automation, and competitive advantages.

11
00:00:30,120 --> 00:00:33,990
And our organizations across
industries are raising to integrate AI

12
00:00:33,990 --> 00:00:36,120
capabilities into their core systems.

13
00:00:36,390 --> 00:00:37,530
And what are some of the challenges?

14
00:00:37,530 --> 00:00:41,200
Most LMS are failing to reach
production because there's like a

15
00:00:41,200 --> 00:00:44,650
significant gap between the proof of
concept and the production deployment,

16
00:00:45,160 --> 00:00:46,570
which actually remains wide.

17
00:00:46,890 --> 00:00:49,440
So some of the different things
include that are like infrastructure

18
00:00:49,440 --> 00:00:51,530
complexities compliance governance.

19
00:00:51,860 --> 00:00:56,280
And security mis creating like far middle
variable barrier for the ops teams.

20
00:00:56,920 --> 00:00:59,950
Let's take a look at what most,
why most initiatives are failing.

21
00:01:00,010 --> 00:01:01,870
The first one is like infrastructure gaps.

22
00:01:02,200 --> 00:01:05,625
So currently there's like a lack of
scalable and secure infrastructure

23
00:01:05,925 --> 00:01:10,315
designed specifically for AI workloads
whereas the old traditional systems

24
00:01:10,315 --> 00:01:11,220
are struggling with the compute.

25
00:01:11,800 --> 00:01:14,020
And also failing to meet
these storage requirements.

26
00:01:14,300 --> 00:01:16,480
The second one is like governance vacuum.

27
00:01:16,810 --> 00:01:21,140
So there's like a absence of clear
policies of AI model selection and how

28
00:01:21,140 --> 00:01:23,920
the data should be handled and what
are the different the decision making

29
00:01:24,100 --> 00:01:28,120
accountabilities and the compliance
framework lags behind the ai qp.

30
00:01:28,120 --> 00:01:30,990
There's a not well-defined
compliance requirements that

31
00:01:31,080 --> 00:01:32,980
are defined in the AI space.

32
00:01:33,250 --> 00:01:35,235
And the third one is life
security environments.

33
00:01:35,765 --> 00:01:39,065
The security teams are basically
unprepared for AI specific threats

34
00:01:39,225 --> 00:01:43,160
which includes prompt injection model
poisoning and data exfiltration through

35
00:01:43,160 --> 00:01:44,760
exfiltration through the model outputs.

36
00:01:45,115 --> 00:01:47,310
And the last one is like cost uncertainty.

37
00:01:47,860 --> 00:01:51,885
Which includes like unpredictable expenses
and unclear written non investment

38
00:01:52,570 --> 00:01:56,510
makes it difficult to justify continued
investment in scale beyond initial pilots.

39
00:01:57,290 --> 00:02:01,280
Because with the with the AI systems,
there's a lot of uncertainty in the

40
00:02:01,280 --> 00:02:05,725
token usage and which, which drives
towards like the unpredictable expenses

41
00:02:05,965 --> 00:02:08,190
and the, and also unclear investment.

42
00:02:08,690 --> 00:02:12,795
Let's take a look at the three pillar
frameworks for secure and deployment.

43
00:02:12,915 --> 00:02:14,750
The first one is like
strategical infrastructure.

44
00:02:15,169 --> 00:02:19,239
Which is which is a pretty, one of the
major pillar for a CQ and LM deployment.

45
00:02:19,244 --> 00:02:23,664
This particular chooses choosing the
right deployment model is pretty key.

46
00:02:23,944 --> 00:02:26,104
There are like three different
deployment models, which is like

47
00:02:26,104 --> 00:02:29,994
infrastructure export software as a
service, and, platform as a service.

48
00:02:30,164 --> 00:02:34,234
Each one offers different different
capabilities and control compliance

49
00:02:34,234 --> 00:02:35,884
requirements and also speed to market.

50
00:02:36,334 --> 00:02:38,434
The second one is like
economical analysis.

51
00:02:38,524 --> 00:02:41,199
A rigorous certain total cost of
ownership models that accounts for.

52
00:02:41,589 --> 00:02:44,709
Compute costs, licensing
operation overhead and performance

53
00:02:44,709 --> 00:02:46,659
optimizations across AI lifecycle.

54
00:02:47,079 --> 00:02:50,539
And the last one is like operational
safeguards including like good practices

55
00:02:50,539 --> 00:02:54,059
and gateway architecture for for
enforcing like security, politics and

56
00:02:54,059 --> 00:02:57,649
policies, monitoring behaviors and
preventing cost of failures in production.

57
00:02:58,149 --> 00:03:01,059
So let's look at the deployment models,
starting with infrastructure service.

58
00:03:01,489 --> 00:03:04,309
So with the infrastructure as
a service, we the company has

59
00:03:04,309 --> 00:03:07,519
like full control over the model
selection, fine tuning optimizations

60
00:03:08,249 --> 00:03:11,044
infrastructure configuration, which
in which includes like provisioning

61
00:03:11,044 --> 00:03:12,639
the infrastructure training the model.

62
00:03:13,034 --> 00:03:16,184
During the model this is highly, this
is ideal for like highly regulated

63
00:03:16,184 --> 00:03:19,664
environments, which has like a really
specific compliance requirements.

64
00:03:20,124 --> 00:03:24,034
Some of the trade off of this approach
is high operation burdens long time

65
00:03:24,034 --> 00:03:27,274
to modern because the company's
responsible for maintaining the

66
00:03:27,274 --> 00:03:29,159
infrastructure of fine tuning the models.

67
00:03:29,824 --> 00:03:31,594
The entire, the operation life cycle.

68
00:03:31,864 --> 00:03:35,049
And this also requires like deep
machine learning expertise and

69
00:03:35,079 --> 00:03:36,669
a significant ops investment.

70
00:03:36,999 --> 00:03:38,889
The second one is like
platform as a service.

71
00:03:38,939 --> 00:03:43,419
This is a balance between owning like the
entire infrastructure because we are using

72
00:03:43,419 --> 00:03:46,859
like a managed infrastructure approach
with flexibility of the customization.

73
00:03:47,069 --> 00:03:50,699
So you we are relying on a specific
vendor for the infrastructure

74
00:03:50,699 --> 00:03:52,379
piece, but we still own the.

75
00:03:52,889 --> 00:03:56,189
Majority of the model development,
fine tuning and optimization

76
00:03:56,249 --> 00:03:57,759
piece, and some of the trade off.

77
00:03:58,259 --> 00:04:01,499
Include like vendor lockin unlimited
infrastructure care customizations,

78
00:04:01,499 --> 00:04:05,584
because we are relying on a vendor and
those vendors might not support our

79
00:04:05,584 --> 00:04:09,874
requirements of the infrastructure,
but this approach dramatically reduces

80
00:04:09,874 --> 00:04:11,674
the overall operation complexity.

81
00:04:11,944 --> 00:04:15,284
And the third one is like software as a
service which includes which represents

82
00:04:15,284 --> 00:04:18,799
like pre-built solutions with minimal
setup, which is essentially our best

83
00:04:18,799 --> 00:04:20,269
example is like Amazon Bit Rock.

84
00:04:21,169 --> 00:04:23,899
In a perfect pool for standard
use cases and rapid expectation

85
00:04:23,899 --> 00:04:25,399
that the minimal technical over.

86
00:04:26,029 --> 00:04:29,439
So we just use the AI
software as a service.

87
00:04:29,829 --> 00:04:32,894
And some of the trade offs includes
like least control over model behavior

88
00:04:32,924 --> 00:04:36,134
because since we are relying on the
service, we don't have much control over

89
00:04:36,134 --> 00:04:37,604
like how the model should be behaving.

90
00:04:37,964 --> 00:04:41,054
And it also has a potential
compliance concern because we'll

91
00:04:41,054 --> 00:04:41,949
be relying on the third party.

92
00:04:42,254 --> 00:04:46,629
Service large language models and which
includes like limited customizations

93
00:04:46,629 --> 00:04:49,749
for domain specific needs because
there's like very little customization

94
00:04:49,749 --> 00:04:53,099
that we can do if you are choosing
the software as a service approach.

95
00:04:53,599 --> 00:04:56,304
Let's take a look at five years
total cost of ownership analysis.

96
00:04:56,909 --> 00:04:59,469
The first one is like
infrastructure code as I mentioned.

97
00:04:59,719 --> 00:05:02,569
Compute resource storage,
networking, and scaling requirements.

98
00:05:02,629 --> 00:05:06,959
If we are using infrastructure as
a service, this is one of the major

99
00:05:07,019 --> 00:05:09,939
total cost of ownership analysis
that we have to perform because

100
00:05:10,119 --> 00:05:11,109
we'll be owning the compute.

101
00:05:11,109 --> 00:05:14,229
We own the storage and we need to
tweak the network configurations

102
00:05:14,229 --> 00:05:15,459
and the scaling requirements.

103
00:05:15,759 --> 00:05:18,099
The second one is like licensing
and model, which is common

104
00:05:18,099 --> 00:05:19,269
for all the three approaches.

105
00:05:19,359 --> 00:05:21,969
API modeling model, licensing,
and hosting increase.

106
00:05:22,399 --> 00:05:23,749
The third one is like operation overhead.

107
00:05:23,809 --> 00:05:27,924
Every, any system, any software
system, needs to do a regress analysis

108
00:05:27,924 --> 00:05:31,344
on the operation overhead, which
includes like monitoring, maintenance.

109
00:05:32,159 --> 00:05:33,299
Security and compliance.

110
00:05:33,389 --> 00:05:34,689
The third one is talent and training.

111
00:05:35,029 --> 00:05:38,184
Specialized ai, machine learning
engineering, and also needs like

112
00:05:38,189 --> 00:05:41,099
continuous improvement and ongoing
education for the entire teams.

113
00:05:41,489 --> 00:05:44,939
And the la and the last one is like
optimization outputs, which is a key

114
00:05:45,329 --> 00:05:48,589
because continuous improvement, fine
tuning and efficiency game because the

115
00:05:48,739 --> 00:05:50,509
overall AI system should be performed.

116
00:05:50,509 --> 00:05:54,794
It should be optimized and
should be continuously fine

117
00:05:54,794 --> 00:05:56,019
tuned for efficiency gains.

118
00:05:56,519 --> 00:05:58,799
Let's take a look at some of
the performance metrics that

119
00:05:58,804 --> 00:05:59,844
drives the demand investment.

120
00:06:00,129 --> 00:06:02,019
The first one is like first open latency.

121
00:06:02,429 --> 00:06:05,099
So which is nothing but the time
until the model begins responding.

122
00:06:05,099 --> 00:06:07,739
This is pretty critical for user
experience, especially in our

123
00:06:07,739 --> 00:06:11,979
interactive web application, like a
chat bot because low latency always

124
00:06:12,009 --> 00:06:14,859
drives like higher adoption and
also good customer satisfaction.

125
00:06:15,249 --> 00:06:16,779
And the second one is tokens per second.

126
00:06:17,364 --> 00:06:20,484
Throughput capacity determines how
many concurrent users you can serve.

127
00:06:20,854 --> 00:06:23,224
So the higher the throughput
reduce infrastructure needs

128
00:06:23,224 --> 00:06:24,514
and improves fast efficiency.

129
00:06:24,794 --> 00:06:27,894
So we need to provision like
infrastructure that satisfies

130
00:06:27,894 --> 00:06:28,944
like higher throughput needs.

131
00:06:29,224 --> 00:06:32,289
So that, that gives us, good
investment so that we are not spending

132
00:06:32,619 --> 00:06:36,789
a lot on infrastructure, but still
approaching a lot of user requests.

133
00:06:37,059 --> 00:06:38,829
And the last one is
like utilization rates.

134
00:06:39,259 --> 00:06:42,409
Percentage of provision capacity,
actively service request requests.

135
00:06:42,779 --> 00:06:47,339
So optimizing utilization is the fastest
path of improving the investments on

136
00:06:47,344 --> 00:06:48,989
element infrastructure investment.

137
00:06:49,489 --> 00:06:52,619
So let's take a look at the LL
Mops Operational Excellency for ai.

138
00:06:53,014 --> 00:06:55,409
So the first one is obviously
the development which includes

139
00:06:55,409 --> 00:06:57,869
prompt engineering, model
selection and fine tuning.

140
00:06:58,179 --> 00:06:59,289
And part of the prompt tuning.

141
00:06:59,289 --> 00:07:02,244
We need to define like a a well
crafted prompt, different using

142
00:07:02,244 --> 00:07:05,614
like different prompt engineering
technologies to efficiently.

143
00:07:06,229 --> 00:07:10,429
Pass the contextual data to the l and m
and the second one is model selection.

144
00:07:10,589 --> 00:07:14,739
Using the right model for the right use
cases is pretty essential because if

145
00:07:14,739 --> 00:07:16,974
the use cases, text-based communication.

146
00:07:17,204 --> 00:07:20,564
We use the right model if the use
case about generating videos or

147
00:07:20,564 --> 00:07:23,594
text and we need to select the
right models or side the use cases.

148
00:07:23,924 --> 00:07:27,164
And the third one in the development phase
is like fine tuning our overall fine,

149
00:07:27,164 --> 00:07:30,899
tuning the system for better performance,
better output is pretty essential.

150
00:07:31,614 --> 00:07:32,694
The second one is testing.

151
00:07:33,004 --> 00:07:35,909
It's advers testing, bias testing
and performance validation.

152
00:07:36,129 --> 00:07:39,819
Since LLMs are non-deterministic,
testing is one of the key part of,

153
00:07:39,819 --> 00:07:43,029
for the operational excellence for
the ai, which includes like the

154
00:07:43,029 --> 00:07:46,214
bias detection early in the develop,
early in the phase the better.

155
00:07:46,454 --> 00:07:49,014
And we need to do a really
good performance validation

156
00:07:49,014 --> 00:07:50,004
of the overall system.

157
00:07:50,274 --> 00:07:51,834
The third one is like deployment.

158
00:07:51,834 --> 00:07:55,044
We need to do like a controlled
rollout in include like AV testing

159
00:07:55,044 --> 00:07:59,254
capabilities and can, because let's say
we are are adding like a new feature

160
00:07:59,504 --> 00:08:02,444
by doing like a controlled rollout,
we can get like feedback immediately.

161
00:08:02,694 --> 00:08:05,064
If there's like something
goes wrong, it doesn't impact

162
00:08:05,064 --> 00:08:07,084
the or the entire user group.

163
00:08:07,514 --> 00:08:10,309
And the next one is like
monitoring having like real time

164
00:08:10,759 --> 00:08:12,589
observability around the AI systems.

165
00:08:13,189 --> 00:08:14,179
Is pretty essential.

166
00:08:14,329 --> 00:08:17,899
And also having a good cost tracking
mechanism and also the quality metrics

167
00:08:17,969 --> 00:08:22,499
because we can use this cost tracking
and quality metrics data and do like

168
00:08:22,499 --> 00:08:26,540
an optimization to the system and
identify if the cost is getting overrun

169
00:08:26,790 --> 00:08:30,170
we should, we can be able to quickly
identify the places where the using

170
00:08:30,170 --> 00:08:33,955
like this cost tracking system and
if we have to improve the performance

171
00:08:33,955 --> 00:08:35,485
during the performance optimization.

172
00:08:35,695 --> 00:08:38,845
Getting this quality metrics in this
monitoring phase is pretty essential.

173
00:08:39,210 --> 00:08:42,090
For overall optimization,
performance tuning and cost

174
00:08:42,090 --> 00:08:43,700
reduction this is of our system.

175
00:08:44,200 --> 00:08:45,815
The next one is like AI, GPI Gateway.

176
00:08:46,250 --> 00:08:48,280
Our secure our security control panel.

177
00:08:48,340 --> 00:08:51,690
The first one is like authentication
authorization, which is the key security

178
00:08:51,690 --> 00:08:55,860
metric that we need to be implemented
at the AI API gateway, which includes

179
00:08:55,860 --> 00:09:00,160
like verifying the identity and enfor
enforcing, like role-based control access.

180
00:09:00,210 --> 00:09:02,190
The second one is like
great limiting in corners.

181
00:09:02,370 --> 00:09:05,430
Implementing like a token based
throttling prevents cost over

182
00:09:05,430 --> 00:09:07,350
and abuse of the AI system.

183
00:09:07,690 --> 00:09:12,810
Since the AI systems mainly use like
tokens for input and output we can

184
00:09:12,810 --> 00:09:15,925
definitely should definitely implement
like some sort of rate limiting or ing

185
00:09:15,925 --> 00:09:17,655
at the API gateway gateway level so that.

186
00:09:17,910 --> 00:09:20,115
As I mentioned, it
doesn't overrun our cost.

187
00:09:20,385 --> 00:09:23,745
The next one is input sanitization,
which includes like detecting and

188
00:09:23,865 --> 00:09:27,845
prompting blocking, like prompting
injection at the ai, a gateway level.

189
00:09:28,145 --> 00:09:31,675
And the next one is output filtering
which includes like scanning the responses

190
00:09:31,675 --> 00:09:35,584
for data and redacting this instant
data before returning to this customer.

191
00:09:35,824 --> 00:09:38,849
And the last one is like semantic
c anti caching which is one of the

192
00:09:38,954 --> 00:09:40,604
important aspect of this AI a p gateway.

193
00:09:41,604 --> 00:09:46,525
So that we don't this which reduces the
c cost by caching like similar queries.

194
00:09:46,715 --> 00:09:48,250
So we rely on this cache.

195
00:09:48,565 --> 00:09:50,655
To get answers for similar queries.

196
00:09:50,745 --> 00:09:54,445
And if if you're not able to find the
in the query, then we'll have the system

197
00:09:54,775 --> 00:09:58,675
which improves the overall optimized
optimiz optimization of the system.

198
00:09:59,175 --> 00:10:02,785
Now let's take a look at the critical
security risk in operation with prompt

199
00:10:02,785 --> 00:10:05,965
injection attack data, exfiltration,
halalization, risk and cost overall.

200
00:10:06,295 --> 00:10:09,065
Let's start with like prompt injection
attacks because every system there

201
00:10:09,065 --> 00:10:12,245
could be like malicious users that
are trying to craft and put that

202
00:10:12,365 --> 00:10:14,315
manipulates the overall model behavior.

203
00:10:14,655 --> 00:10:17,895
And also bypassing like the security
control controls and also extracting

204
00:10:17,895 --> 00:10:19,725
like the training data of our model.

205
00:10:20,155 --> 00:10:22,825
So implementing like a gateway
level filtering and input

206
00:10:22,825 --> 00:10:24,295
validations are essential.

207
00:10:24,545 --> 00:10:27,185
Now to mitigate this
prompt I detection attack.

208
00:10:27,495 --> 00:10:28,575
The second one is the data exfiltration.

209
00:10:29,455 --> 00:10:34,045
So the, some models may independently
expose instrument information from the

210
00:10:34,045 --> 00:10:36,605
training data or on the context window.

211
00:10:36,845 --> 00:10:39,605
So output filtering and access
control, limited exposure.

212
00:10:39,635 --> 00:10:43,405
So we can implement both of
these using our AI API gateway

213
00:10:43,440 --> 00:10:44,850
that we previously discussed.

214
00:10:45,150 --> 00:10:46,920
And the third one is like ization risk.

215
00:10:46,920 --> 00:10:49,880
So model generates, incorrect
information create liability

216
00:10:49,880 --> 00:10:50,810
in the high stakes demand.

217
00:10:51,030 --> 00:10:53,660
So because AI could
definitely make some mistakes.

218
00:10:53,665 --> 00:10:58,300
So considering like scoring and human in
the loop validation will will mitigate

219
00:10:58,300 --> 00:10:59,980
the risk where the stakes are high.

220
00:11:00,380 --> 00:11:01,885
The last one is like course cost overrun.

221
00:11:02,385 --> 00:11:06,995
Can rapidly escalate costs because we
can quickly get into this loop of hall

222
00:11:06,995 --> 00:11:09,680
and thinking continuously in the loop.

223
00:11:09,930 --> 00:11:12,490
And there could be like some
some malicious users who are like

224
00:11:12,580 --> 00:11:14,020
constantly hitting our system.

225
00:11:14,200 --> 00:11:17,960
So we need to implement some sort of like
a talk base rate limiting and budgeting

226
00:11:17,960 --> 00:11:21,205
alerts which prevents like financial
surprises so that the caution shouldn't

227
00:11:21,205 --> 00:11:22,765
be a surprise for the organization.

228
00:11:23,035 --> 00:11:27,245
We should have good visibility into the
cost usage and also good control over.

229
00:11:27,745 --> 00:11:30,265
Let's take a look at domain specific
models for regulatory industries.

230
00:11:30,645 --> 00:11:33,075
Let's say for example, like
financial services and healthcare.

231
00:11:33,325 --> 00:11:36,145
They are like highly regulated and
compliance regulated industries.

232
00:11:36,150 --> 00:11:40,350
So we need to have domain specific models
that specifically addresses the use

233
00:11:40,350 --> 00:11:42,270
cases in these regulatory industries.

234
00:11:42,420 --> 00:11:45,340
Especially Bloomberg, GBT and Med pal.

235
00:11:45,920 --> 00:11:48,480
So these are like the financial
services in the healthcare industries.

236
00:11:48,750 --> 00:11:52,080
So these models are specifically
trained on this financial

237
00:11:52,080 --> 00:11:53,190
data and healthcare models.

238
00:11:53,470 --> 00:11:55,010
So that these are volunt industries.

239
00:11:55,015 --> 00:11:58,465
So using domain specific models
for regulatory industry use cases

240
00:11:58,465 --> 00:11:59,965
is one, one of the key essential.

241
00:12:00,835 --> 00:12:02,335
When you're building like an AI system.

242
00:12:02,835 --> 00:12:06,225
Now let's take a look at the best
practices for production LLM deployment.

243
00:12:06,735 --> 00:12:09,865
The first one is like in implementing
ADVERS testing as we already

244
00:12:09,865 --> 00:12:13,450
discussed regular, regularly testing
models with malicious input and

245
00:12:13,450 --> 00:12:16,930
also the each cases to identify
vulnerability before attackers two.

246
00:12:17,230 --> 00:12:21,970
So consider all possible cases in the
testing scenario is one of the important,

247
00:12:22,020 --> 00:12:24,290
production production ready system.

248
00:12:24,710 --> 00:12:26,690
And the second one is like
monitoring continuously.

249
00:12:26,950 --> 00:12:29,970
We need to definitely track the
performance metrics, the cost and

250
00:12:29,970 --> 00:12:33,250
security events in the real time
with automated alerting so that

251
00:12:33,390 --> 00:12:36,640
we need to have these strict alert
conditions around the performance

252
00:12:36,640 --> 00:12:40,405
metrics cost and security events so
that we should be able to identify

253
00:12:40,405 --> 00:12:42,200
these issues sooner valuable later.

254
00:12:42,700 --> 00:12:46,180
Next one is deploying semantic caching,
as we discussed earlier, build like

255
00:12:46,180 --> 00:12:49,990
a cast responses for similar carry
queries, which has a performance

256
00:12:49,990 --> 00:12:53,905
improvement reducing the cost and
overall without sacrificing the quality.

257
00:12:54,405 --> 00:12:56,330
The next one is like motion
controlling everything.

258
00:12:56,400 --> 00:13:00,570
Trading prompt configuration policies
as a code with proper version, country

259
00:13:00,810 --> 00:13:04,525
version controlling so that we can
roll back these capabilities quickly

260
00:13:04,585 --> 00:13:06,265
instead of doing like a hard fix.

261
00:13:06,385 --> 00:13:09,095
The next one is like enforcing
focus and rate limiting.

262
00:13:09,095 --> 00:13:12,725
As we discussed earlier at the
AI API gateway level, we need

263
00:13:12,725 --> 00:13:15,345
to implement like a token based
or a quota based rate limiting.

264
00:13:15,550 --> 00:13:19,430
For cost controlling and preventing any
abusive users from hitting our system.

265
00:13:19,740 --> 00:13:24,665
So by, by implementing token lipids
per user per time period with

266
00:13:24,665 --> 00:13:26,015
intelligent court management system.

267
00:13:26,515 --> 00:13:29,090
Implement for next one is like
implement fallback strategies which

268
00:13:29,090 --> 00:13:30,740
is design graceful degradation.

269
00:13:30,740 --> 00:13:33,560
Then models are unavailable and
produce low quality outputs.

270
00:13:33,890 --> 00:13:36,815
So let's say we rely on a model
which generates like a really good

271
00:13:36,815 --> 00:13:38,345
output based on the user scenario.

272
00:13:38,375 --> 00:13:41,355
If, for example, that
specific model is unavailable.

273
00:13:41,545 --> 00:13:46,620
So we need to fall back on using a
low confidence output model so that we

274
00:13:46,620 --> 00:13:50,120
generate an output to the customer instead
of failing the entire user request.

275
00:13:50,620 --> 00:13:54,010
The next one is establishing human
in the loop workflow, which is very

276
00:13:54,040 --> 00:13:57,790
critical decision requires a human
oversight, particularly in regulated

277
00:13:57,790 --> 00:13:59,590
industries and high stakes scenarios.

278
00:13:59,590 --> 00:14:02,535
Having a human in the loop will
be very essential and critical.

279
00:14:03,435 --> 00:14:07,195
Document decision trials maintaining
quality logs for the modern

280
00:14:07,195 --> 00:14:10,195
decision for compliance, debugging,
and continuous improvements.

281
00:14:10,195 --> 00:14:13,855
We can make, we can maintain these
decision trials and capture all

282
00:14:13,855 --> 00:14:15,815
the model decision for compliance.

283
00:14:15,875 --> 00:14:19,505
All the debug information which we can
use that information for continuous

284
00:14:19,505 --> 00:14:22,180
improvement for the overall NL
system that we are trying to build.

285
00:14:22,680 --> 00:14:24,420
The future Multimodel and agent DKI.

286
00:14:24,750 --> 00:14:28,500
So the next evolution of enterprise
AI moves beyond just text only

287
00:14:28,500 --> 00:14:33,020
models but to a multimodal system
that processes images, audio, video,

288
00:14:33,020 --> 00:14:35,030
and text simulation simulations.

289
00:14:35,310 --> 00:14:39,630
Agent DKI systems are, can auto
autonomously plan, execute, task,

290
00:14:39,630 --> 00:14:41,280
and interact with the expert tools.

291
00:14:41,620 --> 00:14:43,610
So the currently we are in the text.

292
00:14:43,660 --> 00:14:44,560
These are like the different.

293
00:14:45,500 --> 00:14:46,790
Stages of this ai.

294
00:14:47,030 --> 00:14:49,400
The one, the first one
is like text only lms.

295
00:14:49,400 --> 00:14:53,070
The current generation is efficiently
using the LMS for text generation.

296
00:14:53,320 --> 00:14:57,290
The next future is like multi
models which has the capabilities

297
00:14:57,290 --> 00:14:59,120
of processing like multimedia data.

298
00:14:59,420 --> 00:15:03,870
And the last one is like building this
systems building this autonomous system,

299
00:15:03,960 --> 00:15:08,460
which has the planning, execution and
adaptable capabilities built into it.

300
00:15:09,000 --> 00:15:12,920
The overall goal, the DevOps systems
must be prepared for disadvantages by

301
00:15:12,920 --> 00:15:17,090
building flexible secure infrastructure
that can accommodate rapid AI evaluation.

302
00:15:17,480 --> 00:15:20,950
But while maintaining governance
and really good compliance standards

303
00:15:21,450 --> 00:15:23,970
from tools to the ecosystem
are the integrated integrative.

304
00:15:24,795 --> 00:15:28,455
Successful enterprises are moving
beyond the streaming LLM as an isolated

305
00:15:28,455 --> 00:15:33,315
tool, and instead integrating these LLM
tools and these governance ecosystems

306
00:15:33,315 --> 00:15:35,085
within their DevOps pipelines.

307
00:15:35,565 --> 00:15:39,795
This means embedding AI directly into
the development workflow, security

308
00:15:39,795 --> 00:15:43,605
scanning, instant response and operation
modeling with consistent governance and

309
00:15:43,605 --> 00:15:45,230
operation across all the touch points.

310
00:15:45,690 --> 00:15:47,670
So including AI in our day-to-day.

311
00:15:48,410 --> 00:15:51,035
Entire project development
type cycle is pretty essential.

312
00:15:51,300 --> 00:15:53,920
Starting from the development
phase building like a really good

313
00:15:53,920 --> 00:15:58,080
development workflow using AI for our
security scanning instant response

314
00:15:58,080 --> 00:15:59,460
and also like operation monitoring.

315
00:15:59,980 --> 00:15:59,990
But.

316
00:16:00,490 --> 00:16:04,230
Including really good consistent
governance and observability

317
00:16:04,230 --> 00:16:05,790
across all these touch points.

318
00:16:06,030 --> 00:16:09,000
And some of the key integration
points are like CICD pipeline

319
00:16:09,000 --> 00:16:10,110
for automation code review.

320
00:16:10,110 --> 00:16:13,620
We can definitely leverage AI for
automated code review, which can

321
00:16:13,620 --> 00:16:17,040
be included as part of the pipeline
and also as part of the security

322
00:16:17,040 --> 00:16:21,090
scans and instant response system
for inter ingen triage remediation.

323
00:16:21,090 --> 00:16:23,670
We can definitely train
a specific AI models.

324
00:16:23,770 --> 00:16:27,630
With some proprietary incident and
the response data so that we can build

325
00:16:27,630 --> 00:16:31,860
this instant response system that could
intelligently triage and remediate

326
00:16:31,965 --> 00:16:33,755
any instance that we are occurring.

327
00:16:34,055 --> 00:16:37,595
The next one's monitoring platforms and
anomaly detection and root cause analysis.

328
00:16:37,595 --> 00:16:41,775
We can definitely leverage ai for root
cause analysis and root cause detection.

329
00:16:42,005 --> 00:16:42,345
Which, but.

330
00:16:43,295 --> 00:16:45,515
Which we can definitely
leverage AI for faster.

331
00:16:45,515 --> 00:16:49,065
Identifying the an anomalies and
also identifying the root causes

332
00:16:49,365 --> 00:16:53,080
and documentation system or
automated knowledge base generation.

333
00:16:53,350 --> 00:16:57,230
We can definitely use ai for billing,
like really good knowledge base and

334
00:16:57,230 --> 00:17:00,710
train a specific model based off of the
appropriate knowledge based information.

335
00:17:01,000 --> 00:17:05,160
So this is like from the tools, the
ecosystem, and integrating AI in the

336
00:17:05,160 --> 00:17:06,725
entire project development lifecycle.

337
00:17:07,115 --> 00:17:11,435
From the development phase to the security
scanning, instant response and operation

338
00:17:11,435 --> 00:17:15,325
monitoring and also anomaly detection
root cause analysis, and also building

339
00:17:15,325 --> 00:17:19,905
the really good knowledge base system
and integrating automated code review,

340
00:17:19,905 --> 00:17:22,265
security scanning into our CLCD pipelines.

341
00:17:22,765 --> 00:17:23,260
Thank you so much.

