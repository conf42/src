1
00:00:00,000 --> 00:00:00,120
Art.

2
00:00:00,620 --> 00:00:01,100
Oh, hi.

3
00:00:01,250 --> 00:00:02,060
Welcome everyone.

4
00:00:02,570 --> 00:00:05,840
Today we are gonna talk about
this generation observability,

5
00:00:06,079 --> 00:00:07,880
leveraging AI and data pipeline.

6
00:00:08,170 --> 00:00:12,310
And I'm Sara, director of
Cloud Infrastructure and

7
00:00:12,310 --> 00:00:13,900
Observability Informatica.

8
00:00:14,319 --> 00:00:18,280
And I have Katie with me who is
infrastructure architect at Informatica.

9
00:00:18,780 --> 00:00:19,770
The agenda for today.

10
00:00:20,490 --> 00:00:24,965
Is establishing the problem statement,
what is the current problem we add

11
00:00:25,025 --> 00:00:31,155
at Informatica and our existing tele
telemetry pipeline and, and our futuristic

12
00:00:31,155 --> 00:00:32,995
next generation telemetry pipeline?

13
00:00:33,095 --> 00:00:37,425
How we embedded AI in each part of
the telemetry pipeline, reducing

14
00:00:37,425 --> 00:00:40,785
the cost and bringing better MTTR.

15
00:00:41,285 --> 00:00:42,965
So Informatica, right?

16
00:00:42,965 --> 00:00:45,095
Informatica infrastructure.

17
00:00:45,665 --> 00:00:48,935
We operate at four
different cloud providers.

18
00:00:49,115 --> 00:00:54,665
Hyperscalers, Amazon, Azure, GCP,
and Oracle spread across 20 different

19
00:00:54,665 --> 00:01:00,995
regions, 600 and more Kubernetes clusters
and several thousands of worker no.

20
00:01:01,205 --> 00:01:07,710
And virtual machines being just about 60
terabyte logs every day with 3.8 trillion

21
00:01:07,710 --> 00:01:09,450
Documents get ingested every month.

22
00:01:09,950 --> 00:01:15,830
And if you look at our storage, it's
of 15 petabytes on S3 and on on ECQ.

23
00:01:16,580 --> 00:01:19,610
Virtual machines is
about two, 2.5 petabytes.

24
00:01:20,110 --> 00:01:24,520
So given, given the scale we
operate and given, given that.

25
00:01:24,880 --> 00:01:27,550
We operate in different
cloud and different region.

26
00:01:28,180 --> 00:01:32,740
It brings its own challenges in
cost, compliance, and operational

27
00:01:32,890 --> 00:01:35,230
aspect of things, right?

28
00:01:35,230 --> 00:01:39,880
The source of logs come from different
region, different availability zones get

29
00:01:39,880 --> 00:01:44,380
consolidated into one centralized message
queue, which we currently use Kafka.

30
00:01:45,205 --> 00:01:49,855
And ingested into the data store
and visualized using multiple

31
00:01:49,855 --> 00:01:53,665
tools like Kibana, Grafana,
and homegrown analytics tool.

32
00:01:54,165 --> 00:02:00,405
So this in turn increased the cost,
operational expense, and slower dashboards

33
00:02:00,735 --> 00:02:02,895
with the amount of data we operate.

34
00:02:03,395 --> 00:02:07,985
So this, this problem make us to
rethink on our existing observability.

35
00:02:08,485 --> 00:02:11,995
Pipeline and come up with a new pipeline.

36
00:02:12,025 --> 00:02:17,725
Bring gen AI and ML flavor in
each stages of the pipeline.

37
00:02:18,115 --> 00:02:20,575
So we, we bring things into the source.

38
00:02:20,995 --> 00:02:26,835
So consolidated the collection using
open telemetry and bring filters.

39
00:02:27,335 --> 00:02:30,005
And ML models at the source.

40
00:02:30,035 --> 00:02:35,885
So can, so we can clutter noisy,
unwanted data and declutter

41
00:02:35,885 --> 00:02:38,225
them in the source itself.

42
00:02:38,725 --> 00:02:46,405
So we reduce right in the source, 20%
reduction and move the data to the

43
00:02:46,405 --> 00:02:51,175
centralized message queue with better
optimized pipeline producing 50%.

44
00:02:52,120 --> 00:02:53,290
Saving right there.

45
00:02:53,790 --> 00:02:56,910
Then ingested into data
storage throughout.

46
00:02:57,060 --> 00:03:01,320
By doing so, we reduce noise right
in the source, more in the left.

47
00:03:01,820 --> 00:03:08,930
And using AI and ML models, we are able to
apply better control of the data, bringing

48
00:03:09,320 --> 00:03:14,530
clean compliance result for us as the
data ingestion reduced at the source, we

49
00:03:14,530 --> 00:03:17,200
also reduced storage cost, backup cost.

50
00:03:17,530 --> 00:03:21,550
And quicker dashboard instantaneously
available to the end users.

51
00:03:22,050 --> 00:03:26,640
So with that, I would like to
have Keith join me to go a little

52
00:03:26,640 --> 00:03:30,210
deeper into the architectural
pieces of this telemetry pipeline.

53
00:03:30,210 --> 00:03:30,300
Keith.

54
00:03:30,800 --> 00:03:31,190
Hey.

55
00:03:31,190 --> 00:03:33,590
Thank you, sir for this creative overview.

56
00:03:34,090 --> 00:03:34,510
Yeah.

57
00:03:34,570 --> 00:03:36,560
So as Sarah mentioned.

58
00:03:36,700 --> 00:03:40,869
We have been dealing with HU'S
infrastructure which ingest a lot of

59
00:03:40,869 --> 00:03:45,329
telemetry data and it's actually massive.

60
00:03:45,389 --> 00:03:47,219
We have to operate at massive scale.

61
00:03:47,719 --> 00:03:53,739
So what we did is to control, to get
a control over this telemetry data.

62
00:03:54,559 --> 00:03:58,099
We have implemented something
called Telemetry Pipeline.

63
00:03:58,599 --> 00:04:03,779
So we first started with the
centralized telemetry pipeline

64
00:04:04,349 --> 00:04:08,919
because observability is very much
important to every piece of the.

65
00:04:09,384 --> 00:04:10,914
Application and infrastructure.

66
00:04:11,124 --> 00:04:15,714
It is being used by application
security for, for every purpose.

67
00:04:16,214 --> 00:04:22,764
And today's world where there is a lot of
pipe coding AI is generating your code.

68
00:04:23,064 --> 00:04:29,554
So it's very important to make sure that
your observability as in right safe so

69
00:04:29,554 --> 00:04:34,724
that in case there is a incident, you have
the right set of data to troubleshoot.

70
00:04:35,224 --> 00:04:40,484
So what we did is since our system is
getting more and more telemetry data,

71
00:04:40,984 --> 00:04:48,184
so we put this telemetry pipeline to
make sure that we are ingesting only the

72
00:04:48,604 --> 00:04:51,394
actionable data that is required for us.

73
00:04:51,474 --> 00:04:54,264
And we, we need to store
that for longer time.

74
00:04:54,764 --> 00:04:58,324
So by doing so by adding a
centralized telemetry pipeline,

75
00:04:58,324 --> 00:05:00,844
we could able to reduce our logs.

76
00:05:01,264 --> 00:05:07,414
But what we realized is the majority
of cost is coming from the A collectors

77
00:05:07,594 --> 00:05:13,204
from where we are collecting the logs
and sending it to the centralized system.

78
00:05:13,704 --> 00:05:19,434
So we started using a open telemetry
based agent where we can add filters.

79
00:05:19,794 --> 00:05:25,674
To filter out all the noise at the source
so that we don't have to send them through

80
00:05:25,674 --> 00:05:32,574
the network where we where we incur a lot
of network transfer or n gateway cost.

81
00:05:33,074 --> 00:05:37,654
And once that data comes to our
centralized telemetry pipeline, so there

82
00:05:37,684 --> 00:05:43,144
we massage the data on how we want to
send them and how we want to store them.

83
00:05:43,644 --> 00:05:48,694
S for example sometimes there are
a lot of logs people are sending

84
00:05:48,874 --> 00:05:50,584
which they're using per metrics.

85
00:05:51,184 --> 00:05:52,984
So, but logs are quite expensive.

86
00:05:53,674 --> 00:05:57,844
So with the telemetry pipeline,
we can convert them to metrics and

87
00:05:57,904 --> 00:06:01,654
store it in metrics system instead
of storing it in the logging system.

88
00:06:02,154 --> 00:06:05,854
So similarly that will be a
lot of health checks or in, or

89
00:06:05,914 --> 00:06:07,504
similar kind of things where.

90
00:06:08,004 --> 00:06:11,874
Probably we may not need all the raw
data that is coming into our system.

91
00:06:12,374 --> 00:06:17,274
So what we can do is we just need a
summarized version of the information

92
00:06:17,634 --> 00:06:19,074
which will be useful for us.

93
00:06:19,554 --> 00:06:24,824
So in that case, what we can do is
use the telemetry pipeline to down

94
00:06:24,824 --> 00:06:30,344
sample the amount of telemetry that's
coming in, and write list data to

95
00:06:30,759 --> 00:06:34,854
the the backend observability system,
which is more, which is more useful.

96
00:06:35,354 --> 00:06:42,869
So with this, what we achieved is there
is we reduced the telemetry noise and

97
00:06:42,869 --> 00:06:45,029
we got better control over the data.

98
00:06:45,029 --> 00:06:49,124
For example, if there is a lot of
logs that's that is having some

99
00:06:49,124 --> 00:06:50,594
kind of PI data or something.

100
00:06:51,434 --> 00:06:54,654
So we have a central place to manage that.

101
00:06:54,744 --> 00:06:59,440
Basically add some kind of masking
on top of it before we write in write

102
00:06:59,799 --> 00:07:01,894
it for a long long-term stories.

103
00:07:02,854 --> 00:07:08,584
So what happens with la with the
lace data coming into the system, our

104
00:07:08,584 --> 00:07:11,554
dashboards at the are running faster.

105
00:07:12,019 --> 00:07:17,869
The cardinality of the telemetry is
reducing, and also it's increasing

106
00:07:17,869 --> 00:07:22,679
our search, which is giving our which
is giving a good user experience.

107
00:07:23,179 --> 00:07:27,339
So th this is kind of give us
more control over the data, but.

108
00:07:27,839 --> 00:07:32,429
It, it also introduced more
human effort to maintain this.

109
00:07:32,429 --> 00:07:37,509
So to create the telemetry pipelines,
to maintain these pipelines and also to

110
00:07:37,539 --> 00:07:42,049
keep keep the track of all the different
patterns that's coming in into the system.

111
00:07:42,949 --> 00:07:48,289
So what we did is we
leveraged AI to solve this.

112
00:07:48,324 --> 00:07:49,224
That problem.

113
00:07:49,724 --> 00:07:55,384
So with ai adding, added to the, to our
telemetry pipeline, so we implemented one.

114
00:07:55,384 --> 00:08:01,894
AI isn't, which takes your natural
language query and it, it knows what

115
00:08:01,894 --> 00:08:07,584
are the transforms and and what are the
pipeline's pipeline query languages.

116
00:08:08,224 --> 00:08:10,924
So it can create new pipelines.

117
00:08:11,114 --> 00:08:17,714
It can manage existing pipelines, and
also based on the based based out of the

118
00:08:17,864 --> 00:08:23,144
structure of the data or the pattern of
the data, it can recommend you basically

119
00:08:23,144 --> 00:08:26,534
if there is any scope of optimizations
that you can take any action.

120
00:08:27,034 --> 00:08:30,644
And at the same time, we, we
are not completely adding AI

121
00:08:30,854 --> 00:08:32,414
agents to create our pipelines.

122
00:08:32,414 --> 00:08:38,204
We are also keeping human in loop to
review and approve on the suggestions

123
00:08:38,204 --> 00:08:39,704
that's given by the AI agent.

124
00:08:39,914 --> 00:08:45,174
So once the human reviews and approves
it, then AI isn't goes and deploys it.

125
00:08:45,354 --> 00:08:49,224
So that way there is less
resource required to maintain

126
00:08:49,224 --> 00:08:50,874
and build these pipelines.

127
00:08:51,374 --> 00:08:56,574
So with less amount of data we we
are able to get better observability

128
00:08:56,574 --> 00:08:58,434
systems built on top of it.

129
00:08:58,934 --> 00:09:01,194
So this is how we operate.

130
00:09:01,304 --> 00:09:06,704
Basically we have a single unified portal
based agent, which collects all the

131
00:09:06,704 --> 00:09:11,779
different telemetry signals, and these
agents are managed with fleet management.

132
00:09:11,779 --> 00:09:15,859
So we don't have to go through each a
location for any contribution changes.

133
00:09:16,324 --> 00:09:21,774
So that makes our contributions t
as well, and all our applications

134
00:09:21,774 --> 00:09:27,174
are basically they're they're
instrumented with, with different a PM.

135
00:09:27,834 --> 00:09:33,624
So with, with those instrumentation,
it helps us to propagate the

136
00:09:33,624 --> 00:09:37,954
context about all the, all
the all the a PA calls that's.

137
00:09:38,754 --> 00:09:41,004
That's traveling from service to service.

138
00:09:41,904 --> 00:09:46,754
And with that we are able to create
these different service maps and

139
00:09:46,754 --> 00:09:48,914
correlation between services.

140
00:09:49,334 --> 00:09:55,544
So this helps us reducing a lot of toil
during our investigation of any issues.

141
00:09:56,044 --> 00:10:01,724
And moreover, you don't need an expert
to expert to be present in all the

142
00:10:01,784 --> 00:10:06,224
investigation calls to go through
how the service is behaving and how

143
00:10:06,224 --> 00:10:11,724
each service basically correlated or
when, when is service A is calling

144
00:10:11,724 --> 00:10:13,765
service B, or it's calling service C.

145
00:10:14,265 --> 00:10:16,665
And also we have
implemented some ML models.

146
00:10:17,060 --> 00:10:19,790
To detect the animal in the system.

147
00:10:20,430 --> 00:10:24,852
So so that we can alert in case there is
some kind of let's say let's say there

148
00:10:24,852 --> 00:10:32,295
are the yeah, the a PA response is high
or maybe there is some errors errors that

149
00:10:32,295 --> 00:10:33,945
has increased in a particular service.

150
00:10:34,845 --> 00:10:35,115
So.

151
00:10:35,375 --> 00:10:40,355
With, with all these things we have it
required massive efforts from I mean,

152
00:10:40,355 --> 00:10:42,775
human efforts to maintain all this thing.

153
00:10:43,675 --> 00:10:48,085
So that is where we have
implemented our AI assistant.

154
00:10:48,265 --> 00:10:49,975
So this is, again, another AI agent.

155
00:10:50,455 --> 00:10:54,975
Where, you don't have to really understand
the different query languages that

156
00:10:54,975 --> 00:10:58,845
is required to build your dashboards
or get the required data what,

157
00:10:58,845 --> 00:11:01,675
whenever investigating any incidents.

158
00:11:02,395 --> 00:11:07,615
So you, you can just go to the a
assistant and ask what you need in

159
00:11:07,615 --> 00:11:10,535
a simple sim simple natural query.

160
00:11:11,280 --> 00:11:12,905
It'll, it'll convert that.

161
00:11:13,445 --> 00:11:18,765
To the query language that the
observability system understands it it

162
00:11:18,765 --> 00:11:20,665
goes through your observability system.

163
00:11:20,725 --> 00:11:24,755
It correlates your traces, metrics
and logs, and it, it can provide

164
00:11:24,755 --> 00:11:29,305
you basically basic visualization,
which will help you to understand

165
00:11:29,305 --> 00:11:30,985
what's going on in the system.

166
00:11:31,900 --> 00:11:37,440
And also it can help you to automate
some of the runbooks it, it can run

167
00:11:37,440 --> 00:11:43,540
some of the runbooks to do a regular
maintenance task that is also required

168
00:11:43,750 --> 00:11:45,940
whatever is required, some human efforts.

169
00:11:46,120 --> 00:11:53,140
So this is the way we have leveraged
AI in our observability to reduce the

170
00:11:53,240 --> 00:11:55,180
human efforts that is required to.

171
00:11:55,495 --> 00:11:59,445
Build and maintain these systems
and at the same time we are also.

172
00:12:00,150 --> 00:12:05,930
Making sure that the observable stack
we are running the cost is the cost

173
00:12:05,930 --> 00:12:09,670
is within the ranges, and also at the
same time, the user experience is good.

174
00:12:10,300 --> 00:12:14,255
And also whenever, during instance
and all, whenever people need.

175
00:12:14,580 --> 00:12:18,930
Some specific data, then they can
easily get that instead of depending

176
00:12:18,930 --> 00:12:23,890
on others are searching for which
dashboard or which query to run it.

177
00:12:23,950 --> 00:12:27,490
So this is also reducing
our MTTR of our incidents.

178
00:12:27,990 --> 00:12:31,030
With that, I will conclude here.

179
00:12:31,540 --> 00:12:32,470
So thank you.

180
00:12:32,470 --> 00:12:34,000
Thank you everyone for tuning in.

181
00:12:34,690 --> 00:12:35,320
Thanks everyone.

182
00:12:36,010 --> 00:12:36,310
Thank you.

183
00:12:36,310 --> 00:12:37,060
Thank you everyone.

184
00:12:37,060 --> 00:12:37,540
Thanks, Katie.

