1
00:00:00,300 --> 00:00:04,929
Hi everyone, my name is Hilik
Paz and I'm the CTO at Arato AI.

2
00:00:05,510 --> 00:00:10,049
Arato provides an end to end Gen AI
application delivery platform for AI

3
00:00:10,050 --> 00:00:15,280
builders that integrates AI technologies
like LLMs into enterprise applications.

4
00:00:15,780 --> 00:00:19,309
Today we are going to talk about a
critical security challenge that has

5
00:00:19,309 --> 00:00:24,430
emerged as LLM became part of modern
applications, prompt injection attacks.

6
00:00:25,400 --> 00:00:30,110
I'll introduce a new model based input
validation approach designed to mitigate

7
00:00:30,119 --> 00:00:34,779
such risks Drawing some parallels with
SQL injection prevention techniques

8
00:00:34,790 --> 00:00:36,680
from traditional security models.

9
00:00:37,180 --> 00:00:39,239
First of all, what is prompt injection?

10
00:00:39,739 --> 00:00:43,619
Prompt injection is a form of attack
where an adversary manipulates the

11
00:00:43,629 --> 00:00:48,049
input to a large language model in such
a way it causes the model to behave

12
00:00:48,099 --> 00:00:51,389
unexpectedly or output unintended results.

13
00:00:51,889 --> 00:00:56,079
To better understand this, let's look
at an analogy with SQL injection,

14
00:00:56,660 --> 00:00:59,539
a well known attack vector in
traditional web applications.

15
00:00:59,539 --> 00:01:03,669
SQL Injection With SQL injection,
an attacker inserts malicious SQL

16
00:01:03,669 --> 00:01:05,819
queries as part of a user input field.

17
00:01:06,789 --> 00:01:10,399
Which the system later incorrectly
treats as part of a valid query.

18
00:01:11,069 --> 00:01:15,329
This input is mixed with the coded
SQL instructions, forcing the system

19
00:01:15,329 --> 00:01:17,359
to treat it as a part of the SQL.

20
00:01:18,079 --> 00:01:21,819
It can then later lead to an
unauthorized access to a database.

21
00:01:22,319 --> 00:01:26,429
Notable SQL injection vulnerabilities
were found in major corporates

22
00:01:26,469 --> 00:01:30,239
like Cisco, Tesla, Fortnite that
recently had vulnerability that

23
00:01:30,239 --> 00:01:32,129
let attackers access user accounts.

24
00:01:32,629 --> 00:01:36,969
Similarly, in prompt injection,
user input is mixed with the coded

25
00:01:36,969 --> 00:01:39,389
instructions intended for the LLM.

26
00:01:40,319 --> 00:01:43,769
An attacker might insert hidden
instructions in the user input

27
00:01:43,769 --> 00:01:48,889
field that overrides your intended
output, leading to harmful behavior

28
00:01:48,929 --> 00:01:50,669
or leaking sensitive information.

29
00:01:51,629 --> 00:01:55,429
As LLMs are integrated into more
applications, especially critical

30
00:01:55,469 --> 00:01:59,609
ones like customer service and
automation, Preventing these attacks

31
00:01:59,639 --> 00:02:01,459
becomes increasingly important.

32
00:02:01,959 --> 00:02:03,149
Let's look at a short demo.

33
00:02:03,789 --> 00:02:06,809
In this demo, I'll show you
a simple but effective prompt

34
00:02:06,809 --> 00:02:08,739
injection attack on my demo app.

35
00:02:09,569 --> 00:02:12,859
The app is a travel planner app
that takes user input and uses

36
00:02:12,859 --> 00:02:14,929
an LLM to provide trip plans.

37
00:02:15,909 --> 00:02:20,559
Watch what happens when a user
inputs contains hidden LLM follows,

38
00:02:21,049 --> 00:02:23,039
resulting in unexpected responses.

39
00:02:23,539 --> 00:02:26,129
So this is our Trip Planner demo app.

40
00:02:26,339 --> 00:02:30,829
Let's see what happens when the user plans
a trip to Paris, let's say for three days.

41
00:02:31,329 --> 00:02:35,289
We're using here Cloud 3 Haiku,
so it should take a few seconds

42
00:02:35,289 --> 00:02:36,689
until we'll see the trip plan.

43
00:02:37,189 --> 00:02:41,069
And we've got ourselves a nice trip
plan for our next visit to Paris.

44
00:02:41,569 --> 00:02:44,269
Let's see what happens when the
user inserts harmful content.

45
00:02:44,769 --> 00:02:47,669
I've already prepared a
data set of some examples.

46
00:02:47,749 --> 00:02:48,619
We'll pick this one.

47
00:02:49,119 --> 00:02:51,429
And we'll enter it instead
of the location field.

48
00:02:51,929 --> 00:02:54,279
As you can see, we got
an unexpected result.

49
00:02:55,139 --> 00:02:59,269
But prompt injection can be much more
harmful than just outputting LOL.

50
00:02:59,769 --> 00:03:03,039
The user can get access to
our internal configuration.

51
00:03:03,249 --> 00:03:07,919
In this example, the model outputted
the entire internal prompt that we have.

52
00:03:08,419 --> 00:03:12,469
Now that we've seen how easily an
LLM can be manipulated, let's talk

53
00:03:12,479 --> 00:03:14,129
about some prevention techniques.

54
00:03:14,879 --> 00:03:19,719
One common approach is context filtering,
where the input is pre processed and

55
00:03:19,719 --> 00:03:21,769
potentially harmful segments are removed.

56
00:03:22,439 --> 00:03:26,129
Another technique is static prompt
design, where we hard code responses

57
00:03:26,129 --> 00:03:30,309
and maybe even inputs that reduces
the flexibility for dynamic inputs,

58
00:03:30,639 --> 00:03:32,689
but that limits LLM usefulness.

59
00:03:33,514 --> 00:03:37,924
These techniques often fail in complex
or adaptive scenarios, which is why we

60
00:03:37,924 --> 00:03:42,144
propose a more sophisticated approach,
a model based input validation.

61
00:03:43,044 --> 00:03:46,634
It's based on a prompt that will
be sent to an LLM, hence the model

62
00:03:46,634 --> 00:03:50,994
part, and it will focus on specific
input validity based on a set of

63
00:03:51,014 --> 00:03:52,794
parameters you will see in a minute.

64
00:03:53,294 --> 00:03:57,534
Let's start by introducing the core
of this approach, the meta prompt.

65
00:03:58,404 --> 00:04:02,124
This prompt acts as a filter
between the user input and the LLM.

66
00:04:03,084 --> 00:04:07,044
The metaprompt is designed to
examine inputs for specific context.

67
00:04:07,544 --> 00:04:13,244
In this example, the parameters for
location input might be a type location,

68
00:04:13,484 --> 00:04:18,064
samples that include city names,
country names, maybe other definitions

69
00:04:18,074 --> 00:04:22,994
of locations, and the user intent for
a specific location one can visit.

70
00:04:23,494 --> 00:04:26,784
Let's see another demo once
we've implemented our metaprompt.

71
00:04:27,284 --> 00:04:30,834
Back to our demo app,
let's activate validation.

72
00:04:31,534 --> 00:04:36,624
Validation will make sure our metaprompt
runs on each input prior to the actual

73
00:04:36,624 --> 00:04:38,834
invocation of the triplen request.

74
00:04:39,334 --> 00:04:42,424
Let's start by running the metaprompt
validation on a good input.

75
00:04:42,924 --> 00:04:45,154
And as expected, we got our triplen.

76
00:04:45,654 --> 00:04:48,194
Let's go ahead and run it
on the malicious input.

77
00:04:48,694 --> 00:04:52,324
This time our metaprompt
worked and blocked that input

78
00:04:52,344 --> 00:04:53,714
from continuing to the LLM.

79
00:04:54,214 --> 00:04:58,214
Let's take a closer look at the
different components of our prompt.

80
00:04:58,714 --> 00:05:02,034
You will probably notice that
we're using a system message

81
00:05:02,284 --> 00:05:03,974
for the general instructions.

82
00:05:04,474 --> 00:05:07,704
and a user message to hold
the actual user input.

83
00:05:08,204 --> 00:05:12,424
The system message determines what
role the AI should play and how it

84
00:05:12,424 --> 00:05:17,274
should behave generally, and at least
theoretically should play a stronger

85
00:05:17,274 --> 00:05:19,494
role in following these instructions.

86
00:05:20,094 --> 00:05:24,744
rather than giving the same set of
instructions as part of the user message.

87
00:05:25,244 --> 00:05:29,024
The actual difference of having
these messages in a separate system

88
00:05:29,024 --> 00:05:33,764
prompt rather than the being part of
a single user message depends on many

89
00:05:33,764 --> 00:05:38,209
factors including the model and the
parameters you choose, but that's a

90
00:05:38,209 --> 00:05:40,859
topic for a whole different session.

91
00:05:41,359 --> 00:05:46,459
The first section is a set of general
instructions we give to the AI.

92
00:05:46,959 --> 00:05:51,509
We set the tone, the purpose of our
prompt, and make sure that it focuses

93
00:05:51,659 --> 00:05:54,219
on the sole purpose of validating input.

94
00:05:54,479 --> 00:05:59,974
For example, We give him the task
of classifying that user input.

95
00:06:00,474 --> 00:06:04,644
We define the format it should
expect to get the user input.

96
00:06:05,144 --> 00:06:09,744
And by doing that, we are trying to
prevent interpreting the user input as

97
00:06:09,774 --> 00:06:12,094
instructions the model should follow.

98
00:06:12,594 --> 00:06:16,544
There's a very basic anti
jailbreaking message here.

99
00:06:17,044 --> 00:06:20,604
Of course, in a real production
use case, this message will

100
00:06:20,614 --> 00:06:22,624
be much more comprehensive.

101
00:06:23,124 --> 00:06:28,304
And we also tell the model never to expose
its role capabilities or limitations.

102
00:06:28,804 --> 00:06:33,154
Next is the section where we
define how the output looks like.

103
00:06:33,954 --> 00:06:35,614
We perform two operations here.

104
00:06:36,204 --> 00:06:40,624
The first one is we specify the
format, which is a JSON object with

105
00:06:40,684 --> 00:06:42,974
two keys that we expect to get.

106
00:06:43,654 --> 00:06:46,984
One key will be the actual
result, pass or fail.

107
00:06:47,874 --> 00:06:51,404
And the second key, as you can see here,
is a new variable that we introduce.

108
00:06:51,904 --> 00:06:57,244
called secret, and it will contain
a randomly generated value for each

109
00:06:57,244 --> 00:06:59,594
interaction that we will call this prompt.

110
00:07:00,094 --> 00:07:06,214
This secret doesn't have any direct role
in the actual prompt formal function.

111
00:07:06,264 --> 00:07:12,144
It doesn't serve as assisting the AI in
any way, in understanding if the input

112
00:07:12,184 --> 00:07:14,954
it is now assessing is valid or not.

113
00:07:15,594 --> 00:07:20,254
But it does act as a kind of an internal
mechanism for our own metaprompt.

114
00:07:21,094 --> 00:07:25,824
Because, as like any other prompt,
we might also be exposed to prompt

115
00:07:25,824 --> 00:07:27,734
injection attacks on our metaprompt.

116
00:07:28,234 --> 00:07:33,114
By introducing a secret value that the
prompt must return in a valid response,

117
00:07:33,959 --> 00:07:40,599
We give our code the ability to analyze
if that response has been tampered or not.

118
00:07:41,099 --> 00:07:46,149
The third section is where we introduce
the dynamic part of the metaprompt.

119
00:07:46,989 --> 00:07:50,799
It includes type, category,
intent, and example.

120
00:07:51,299 --> 00:07:55,419
The type and category are the most
basic aspects of the input that we

121
00:07:55,419 --> 00:07:57,959
expect the prompt to validate against.

122
00:07:58,249 --> 00:08:02,359
For example, it can be a string
that represents a location.

123
00:08:02,859 --> 00:08:06,289
Or a numeric value that
represents a budget dollar amount.

124
00:08:06,789 --> 00:08:12,609
The intent is where we explain what
level of flexibility we allow in

125
00:08:12,639 --> 00:08:17,729
choosing these kinds of variables
from the relevant category.

126
00:08:17,749 --> 00:08:22,359
For example, we can have a very
strict intent for a location.

127
00:08:22,894 --> 00:08:29,224
Saying must be a specific city or state
name, or we can allow a very flexible

128
00:08:29,224 --> 00:08:35,084
location choosing by saying any form or
any description that suggests a location.

129
00:08:35,714 --> 00:08:40,014
It can be abstract, it can be
even fictional, as long as you

130
00:08:40,054 --> 00:08:44,044
can interpret it as a location for
the purpose of planning a trip.

131
00:08:44,544 --> 00:08:48,134
And lastly, we provide a set of
examples that will help the model

132
00:08:48,384 --> 00:08:50,284
analyze the actual user input.

133
00:08:50,724 --> 00:08:55,814
Maybe match it to similar examples
and understand if it is indeed a

134
00:08:55,814 --> 00:08:57,764
valid and relevant input or not.

135
00:08:58,264 --> 00:09:03,784
And lastly, the user message that includes
the actual user input we should validate.

136
00:09:04,389 --> 00:09:09,999
In this example, using a JSON object will
also assist the model in understanding

137
00:09:10,339 --> 00:09:14,009
it's an input rather than a set
of instructions it should follow.

138
00:09:14,509 --> 00:09:17,329
Let's take a look under the
hood and view the monitored

139
00:09:17,329 --> 00:09:19,449
LLM calls we've just performed.

140
00:09:19,949 --> 00:09:23,179
Note that the variable type,
category, examples, and actually

141
00:09:23,189 --> 00:09:27,889
the metadata that we provide to our
metaprompt in both cases is identical.

142
00:09:28,309 --> 00:09:30,359
The only difference is the user input.

143
00:09:30,859 --> 00:09:33,579
When the user enters
Paris, validation passes.

144
00:09:34,079 --> 00:09:39,159
But when the user enters harmful content,
it fails as expected, and our code knows

145
00:09:39,189 --> 00:09:43,829
not to continue to the next step of
passing the entire prompt to the LLM.

146
00:09:44,329 --> 00:09:48,279
As we've seen, validating the input
before it reaches the LLM is crucial.

147
00:09:49,169 --> 00:09:54,139
But beyond just running individual tests
like we just did, it's important to test

148
00:09:54,159 --> 00:09:59,089
the meta prompt like any other prompt on a
diverse set of data, to ensure it works as

149
00:09:59,089 --> 00:10:00,879
expected in a wide variety of scenarios.

150
00:10:01,379 --> 00:10:02,629
Why is that so critical?

151
00:10:03,069 --> 00:10:08,399
Because user input can be highly variable,
ranging from simple, formed inputs

152
00:10:08,449 --> 00:10:10,469
to very complex and malicious ones.

153
00:10:11,369 --> 00:10:15,329
A good metaprompt needs to be
consistently distinguishing between

154
00:10:15,329 --> 00:10:20,159
valid inputs like New Jersey and harmful
or nonsense input like ignore all

155
00:10:20,289 --> 00:10:22,689
instructions across the entire range.

156
00:10:23,189 --> 00:10:28,539
Testing against a diverse dataset helps us
simulate real world usage and uncover edge

157
00:10:28,569 --> 00:10:30,469
cases where the metaprompt might fail.

158
00:10:31,459 --> 00:10:35,899
So we should test different input
types, location, language, duration,

159
00:10:35,909 --> 00:10:39,759
or any other field type that our
business application requires.

160
00:10:40,359 --> 00:10:45,799
Different user intents, we might sometimes
allow for a more flexible user intent, and

161
00:10:45,799 --> 00:10:48,999
might sometimes be very strict or rigid.

162
00:10:49,909 --> 00:10:53,669
And various structures, for example,
what happens when a user enters,

163
00:10:54,114 --> 00:10:57,484
the initials of a city he wants
to visit in a location field.

164
00:10:58,304 --> 00:11:01,584
We can assess how well the metaprompt
handles these variations and

165
00:11:01,584 --> 00:11:03,354
make improvements accordingly.

166
00:11:04,054 --> 00:11:07,874
This testing is essential to ensuring
that the prompt validation mechanism

167
00:11:07,904 --> 00:11:12,324
is both robust and adaptable,
able to catch injection attempts

168
00:11:12,334 --> 00:11:14,154
while allowing valid inputs.

169
00:11:14,654 --> 00:11:18,434
When we introduce a new category, for
example, we should also experiment

170
00:11:18,454 --> 00:11:22,704
with various category parameters, like
relevant examples, different user intents.

171
00:11:23,204 --> 00:11:27,624
This comprehensive and iterative approach
ensures that the metaprompt is not

172
00:11:27,624 --> 00:11:32,284
just effective in controlled cases that
we've just tested, but also can handle

173
00:11:32,344 --> 00:11:34,994
unpredictable nature of real world data.

174
00:11:35,494 --> 00:11:40,004
So let's take a short demo on the
concept of a dataset and how we can

175
00:11:40,004 --> 00:11:42,264
validate our metaprompt against it.

176
00:11:42,764 --> 00:11:45,214
First, let's take a look at our datasets.

177
00:11:45,214 --> 00:11:45,694
Okay.

178
00:11:46,194 --> 00:11:51,064
Depending on the use case we're
developing or optimizing for, we

179
00:11:51,064 --> 00:11:54,534
will build the relevant test data
that we want to experiment against.

180
00:11:55,034 --> 00:11:58,104
Let's assume we're optimizing
for location input fields.

181
00:11:58,604 --> 00:12:02,924
We provided several data sets, for
example, a list of valid locations,

182
00:12:03,424 --> 00:12:07,634
We can see the different user
inputs, and of course, the expected

183
00:12:07,664 --> 00:12:11,814
response, which is passed in this
example, as they are all valid.

184
00:12:12,314 --> 00:12:16,914
If we drill down to a specific line,
we can see the entire metadata that we

185
00:12:16,944 --> 00:12:22,574
pass to the meta prompt, including the
category, the intent, and the examples.

186
00:12:23,074 --> 00:12:27,844
Similarly, we've prepared a dataset
with malicious content or malicious

187
00:12:27,854 --> 00:12:30,884
user input, used as a location field.

188
00:12:31,384 --> 00:12:35,364
that we will want to experiment against,
and of course, in this case, the

189
00:12:35,364 --> 00:12:38,064
expected result is always a failure.

190
00:12:38,564 --> 00:12:42,604
Now let's see how we can use these
datasets in a real experiment in Arata.

191
00:12:43,104 --> 00:12:44,534
Let's create a new experiment.

192
00:12:45,034 --> 00:12:45,904
We will select our dataset,

193
00:12:46,404 --> 00:12:50,404
and for our initial run, we
might keep the prompt as is.

194
00:12:50,904 --> 00:12:55,094
And let's see how it behaves against
our data set, and this time we chose

195
00:12:55,094 --> 00:13:01,384
GPT 40mini, we'll click save and run,
and we'll let the experiment execute.

196
00:13:01,884 --> 00:13:03,184
And let's view the results.

197
00:13:03,684 --> 00:13:07,474
So you can see we got a very high
score matching the similarity.

198
00:13:08,294 --> 00:13:12,204
of our expected results from the
data set, although not perfect.

199
00:13:12,814 --> 00:13:15,594
Let's see the details inside.

200
00:13:16,094 --> 00:13:21,494
Here, for example, we got exactly the same
response that we expected in our data set.

201
00:13:21,994 --> 00:13:27,604
But in other cases, for example, in
this line, our data set expected a pass

202
00:13:27,604 --> 00:13:33,294
result, but the actual status we got using
our prompt with 40mini was a failure.

203
00:13:33,784 --> 00:13:35,294
Let's try to understand why.

204
00:13:35,794 --> 00:13:38,594
The user input was a romantic location.

205
00:13:39,094 --> 00:13:43,474
While the model might have been right
saying that this is not a real place or

206
00:13:43,474 --> 00:13:49,934
specific location, as we explicitly added
an intent saying it can be abstract,

207
00:13:50,434 --> 00:13:52,414
we would have expected it to pass.

208
00:13:52,914 --> 00:13:56,554
So let's try to change one of the
parameters of our experiment and

209
00:13:56,554 --> 00:13:57,934
see if we can reach better results.

210
00:13:58,434 --> 00:14:00,634
We will first try another model.

211
00:14:01,114 --> 00:14:02,474
Let's take a different vendor.

212
00:14:02,974 --> 00:14:05,984
And we will run exactly the
same experiment with the same

213
00:14:06,004 --> 00:14:08,854
prompt and data against Clode3IQ.

214
00:14:09,354 --> 00:14:10,624
Let's view the results.

215
00:14:11,124 --> 00:14:12,274
This is much better.

216
00:14:12,394 --> 00:14:16,844
We get exactly the expected results
on each one of the individual lines

217
00:14:16,894 --> 00:14:18,404
that we run the experiment with.

218
00:14:18,904 --> 00:14:22,934
At this point, we can decide if that's
good enough and we want to continue with

219
00:14:22,944 --> 00:14:27,534
the model and parameters we've just had,
Or we want to go back to the previous

220
00:14:27,534 --> 00:14:31,534
model and try to improve our prompts,
maybe play with the parameters, etc.

221
00:14:32,034 --> 00:14:36,514
Let's run another experiment with invalid
location data that we've uploaded.

222
00:14:37,014 --> 00:14:40,454
In this experiment, we will also
add an additional validation.

223
00:14:40,809 --> 00:14:43,289
to see if we can detect harmful content.

224
00:14:43,789 --> 00:14:47,859
We will select the relevant
dataset and create the experiment.

225
00:14:48,359 --> 00:14:52,289
Again, at our first run, we will
not change any parameters in the

226
00:14:52,299 --> 00:14:54,029
prompt and we'll run it against 4.

227
00:14:54,029 --> 00:14:54,629
0 Mini.

228
00:14:55,129 --> 00:14:58,389
We can run in parallel against
a different model as well.

229
00:14:58,889 --> 00:15:00,279
And let's view the results.

230
00:15:00,779 --> 00:15:02,609
First, we will look at
the results against 4.

231
00:15:02,609 --> 00:15:03,509
0 Mini,

232
00:15:04,009 --> 00:15:08,069
and we got very close to
100 percent similarity.

233
00:15:08,569 --> 00:15:11,819
We can see there's a slight difference
in the output format, but the

234
00:15:11,849 --> 00:15:13,949
content itself is what we expected.

235
00:15:14,449 --> 00:15:18,029
And looking at Claude's
results, we see very similar,

236
00:15:18,189 --> 00:15:20,609
successful run against our data.

237
00:15:21,109 --> 00:15:25,079
So we've seen how you can
experiment multiple versions of your

238
00:15:25,129 --> 00:15:27,859
prompts, models, configurations.

239
00:15:28,204 --> 00:15:32,904
and data to achieve your business
goal and to optimize your prompt.

240
00:15:33,404 --> 00:15:36,094
When experimenting, it's
important to have a baseline.

241
00:15:36,594 --> 00:15:41,104
In the recent examples we've just did,
the baseline was the data set that we've

242
00:15:41,154 --> 00:15:43,424
uploaded with the expected results.

243
00:15:43,924 --> 00:15:47,484
But of course, we can also
experiment against data we've

244
00:15:47,524 --> 00:15:52,954
collected from production and
verify it is correct and experiment

245
00:15:52,984 --> 00:15:55,414
with our next version of prompt.

246
00:15:55,914 --> 00:15:59,964
To conclude, we've seen how prompt
injection poses a significant threat

247
00:15:59,974 --> 00:16:03,944
in LLM applications, much like
SQL injection did for databases.

248
00:16:04,734 --> 00:16:09,324
While traditional techniques like static
prompting or filtering might mitigate some

249
00:16:09,324 --> 00:16:11,964
risks, they often have many limitations.

250
00:16:12,464 --> 00:16:16,754
Our model based input validation approach
offers a more adaptable solution by

251
00:16:16,784 --> 00:16:19,554
leveraging LLMs to validate inputs.

252
00:16:20,224 --> 00:16:24,374
Unlike deny listing approaches,
where the LLM is asked for the entire

253
00:16:24,384 --> 00:16:29,324
input if it is malicious or harmful,
our method uses an allow listing

254
00:16:29,324 --> 00:16:33,504
approach, where we explicitly define
what inputs are valid and expected.

255
00:16:34,004 --> 00:16:38,234
This provides a stronger defense
by limiting the range of acceptable

256
00:16:38,274 --> 00:16:42,644
inputs on one hand, but enhancing
the flexibility of the final prompt

257
00:16:42,664 --> 00:16:44,574
that we can use on the other hand.

258
00:16:45,074 --> 00:16:48,944
By focusing on allowListing, we create
a controlled environment where the

259
00:16:49,474 --> 00:16:51,414
LLM processes only valid inputs.

260
00:16:52,114 --> 00:16:56,324
This approach significantly reduces
the risk for prompt injection while

261
00:16:56,414 --> 00:16:59,954
still offering the flexibility
needed in complex data inputs.

262
00:17:00,454 --> 00:17:01,924
Thank you all for your time today.

263
00:17:02,044 --> 00:17:04,284
I hope this session has been insightful.

264
00:17:05,194 --> 00:17:08,554
If you have any questions, comments,
or would just like to keep in touch.

265
00:17:09,534 --> 00:17:13,194
Please email me, follow us on
LinkedIn or visit our website.

266
00:17:13,424 --> 00:17:14,545
Thank you very much.

