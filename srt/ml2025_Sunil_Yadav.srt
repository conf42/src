1
00:00:01,110 --> 00:00:01,920
Hello everyone.

2
00:00:02,030 --> 00:00:03,740
I am Sunil Yadav.

3
00:00:03,800 --> 00:00:12,485
I am a seasoned database administrator
with the years of experience on Oracle

4
00:00:12,635 --> 00:00:18,764
E-Business Suite, Oracle Code databases
implementation upgrades, tuning.

5
00:00:19,384 --> 00:00:27,065
Migrations maintenance, patching cloning
in different industries like telecom,

6
00:00:27,065 --> 00:00:31,155
banking retail and various other places.

7
00:00:31,615 --> 00:00:36,805
I worked on many non-oral data
databases as well, like MSSQL

8
00:00:36,805 --> 00:00:39,965
server, MySQL server MongoDB.

9
00:00:40,370 --> 00:00:47,830
Little bit of data analytics golden Gate
ODI and some other integrated software

10
00:00:47,830 --> 00:00:50,570
technologies across different continents.

11
00:00:50,570 --> 00:00:56,500
So here I am I'm going to talk
about this topic of ml, which is

12
00:00:56,500 --> 00:00:59,710
machine learning powering databases.

13
00:01:00,190 --> 00:01:06,940
Resilience via predictive
analytics for 99.98 percentage

14
00:01:06,970 --> 00:01:09,520
of Oracle Cloud availability.

15
00:01:10,120 --> 00:01:17,325
Now, as a fact, I. Database downtime,
cost any, any huge enterprise more than

16
00:01:17,325 --> 00:01:25,425
9,000 US dollars per minute, which is like
typical outage goes beyond NR when we talk

17
00:01:25,425 --> 00:01:30,425
about production databases, which are big
in size and complicated in architecture.

18
00:01:30,425 --> 00:01:36,665
So it takes about 60 minutes to fix a
problem that cost about more than 700,000.

19
00:01:37,490 --> 00:01:41,960
Dollars per incident if we
calculate the math per minute wise.

20
00:01:42,500 --> 00:01:47,390
So the, our machine learning solutions,
they transform the, the Oracle cloud

21
00:01:47,390 --> 00:01:53,370
reliability based on the implementations
across, you know, hundreds of

22
00:01:53,370 --> 00:01:55,315
enterprise throughout the globe.

23
00:01:55,375 --> 00:01:57,805
So we are going to talk about it.

24
00:01:57,805 --> 00:01:59,305
So as an introduction.

25
00:01:59,365 --> 00:01:59,755
Yeah.

26
00:02:00,595 --> 00:02:01,585
This is what it is.

27
00:02:01,585 --> 00:02:02,035
So.

28
00:02:03,760 --> 00:02:09,270
Like I said, the cost of the downtime
is more than $9,000 per minute

29
00:02:09,270 --> 00:02:13,860
for average production issues for
a database and which lasts for.

30
00:02:14,700 --> 00:02:16,200
More than 60 minutes.

31
00:02:16,600 --> 00:02:21,029
Even if it's a small problem, the,
the limitation and, you know, the

32
00:02:21,329 --> 00:02:25,379
mitigation to solve the problem,
the finally fix and implementation.

33
00:02:25,379 --> 00:02:30,359
And, you know, that takes this much
time, which costs more than $7,000

34
00:02:30,359 --> 00:02:37,689
per incident as a total finance
impact of running a database with 99,

35
00:02:37,779 --> 00:02:40,939
more than 99 percentage of uptime.

36
00:02:42,409 --> 00:02:46,759
Now what is actually machine
learning based anatomy detection?

37
00:02:47,419 --> 00:02:51,219
So there are three pillars
of this entire concept.

38
00:02:52,089 --> 00:02:54,369
First is early detection of a problem.

39
00:02:54,369 --> 00:03:02,259
So they say that more than 70% of the
problems can be identified within like 30

40
00:03:02,259 --> 00:03:04,059
minutes or before they're happening, like.

41
00:03:04,899 --> 00:03:06,219
Space getting filled.

42
00:03:06,429 --> 00:03:10,479
CPU getting choked to more than 99%.

43
00:03:10,869 --> 00:03:12,879
So there are different examples like that.

44
00:03:12,879 --> 00:03:16,539
So if we detect that early,
we can prevent that early.

45
00:03:16,719 --> 00:03:17,049
Okay.

46
00:03:17,439 --> 00:03:18,459
Preventive action.

47
00:03:18,459 --> 00:03:24,219
So, you know, it can, can that
preventive action be immediately?

48
00:03:24,269 --> 00:03:27,279
Followed and to get the fix available.

49
00:03:27,279 --> 00:03:32,279
That's the, the action to be taken now,
improved uptime is the solution, the

50
00:03:32,489 --> 00:03:34,749
outcome of pillar one and pillar two.

51
00:03:34,749 --> 00:03:40,669
So if we do one, two, we have the
improved uptime for our database.

52
00:03:42,799 --> 00:03:46,219
So for machine learning,
what we need is we need to.

53
00:03:47,224 --> 00:03:54,444
Ensure the deep learning of the
performance matrix is done by the database

54
00:03:54,444 --> 00:03:57,544
and the entire solution to, to deliver.

55
00:03:58,024 --> 00:03:59,584
So there is a pattern.

56
00:03:59,674 --> 00:04:01,594
Recognition is the first step into it.

57
00:04:01,594 --> 00:04:07,684
Like I mentioned in the few slides before,
pattern recognition, like if there is a

58
00:04:07,684 --> 00:04:10,114
month end or quarter end, or there's a.

59
00:04:10,579 --> 00:04:14,429
Peak load of application
workload going on.

60
00:04:14,429 --> 00:04:18,929
So space or, you know, gets
transaction log or archive logs

61
00:04:18,929 --> 00:04:20,459
start getting filled up quickly.

62
00:04:20,459 --> 00:04:25,289
So if there's a patent to it, like
on few days of a month or a week,

63
00:04:25,319 --> 00:04:27,029
if something like had happens.

64
00:04:27,389 --> 00:04:31,199
So recognize that patent
do the action immediately.

65
00:04:32,055 --> 00:04:36,315
Do and recognition should
not be in a delayed manner or

66
00:04:36,315 --> 00:04:37,544
like 30 minutes or one hour.

67
00:04:37,784 --> 00:04:42,375
It should be quick enough, like an
interval of five to 10 seconds so that

68
00:04:42,825 --> 00:04:48,145
the pattern recognition can be identified
and action can be taken immediately.

69
00:04:49,015 --> 00:04:53,624
There are invisible signals also, which
is called you can leverage the neural

70
00:04:53,624 --> 00:04:59,575
networks of the entire solution to
detect the correlated pattern from the

71
00:04:59,575 --> 00:05:02,155
monitoring logs to fix the problem.

72
00:05:03,155 --> 00:05:07,529
Now when we talk about the entire
database, the solution is a machine

73
00:05:07,529 --> 00:05:09,839
learning for uptime of 99.9.

74
00:05:10,109 --> 00:05:14,999
We have different technologies like
Oracle, RAC, which is real application

75
00:05:14,999 --> 00:05:21,810
clusters which provide availability
and scalability both for the entire

76
00:05:21,810 --> 00:05:27,900
database platform to be available
throughout the tough times of month and

77
00:05:27,900 --> 00:05:30,150
close and, or, you know, if there is a.

78
00:05:30,519 --> 00:05:35,529
Disaster somewhere, or one server crashes
or something happens to the network, the

79
00:05:35,529 --> 00:05:38,919
other cluster nodes are able to cater.

80
00:05:38,919 --> 00:05:45,389
So, and with that, to re informance
learning of the rack will

81
00:05:45,389 --> 00:05:47,189
optimize the entire solution.

82
00:05:47,189 --> 00:05:49,049
So basically there are four parts to it.

83
00:05:49,379 --> 00:05:54,599
One is monitoring, then
learn, optimize, and validate.

84
00:05:54,659 --> 00:05:56,939
So to begin with.

85
00:05:57,824 --> 00:06:01,304
The monitoring of the log
should be continuous performance

86
00:06:01,394 --> 00:06:03,494
tracking of each and every log.

87
00:06:03,494 --> 00:06:05,444
Like when and what happens.

88
00:06:05,894 --> 00:06:09,494
When the logs are generated, what
information is GA gathered into it?

89
00:06:10,184 --> 00:06:15,774
Learn from those information, the logs
which are generated and generate analyze

90
00:06:15,774 --> 00:06:17,634
the pattern that anomalies into it.

91
00:06:17,634 --> 00:06:19,914
Like what happens when something.

92
00:06:20,379 --> 00:06:24,419
Happens like in the log, which
can be related to a patent.

93
00:06:24,989 --> 00:06:30,389
Then third is to optimize when
you identify this happened.

94
00:06:30,449 --> 00:06:33,419
And because of this, this
was the analysis done.

95
00:06:33,419 --> 00:06:37,689
So what could be the remediation
to, to fix the problem and then.

96
00:06:38,214 --> 00:06:43,774
Once that is delivered, you validate
for the res of the database that,

97
00:06:43,774 --> 00:06:47,104
okay, because of this, we did this
and did that solve the problem.

98
00:06:47,104 --> 00:06:52,384
So it's like feedback of the
solution and, and that's how we,

99
00:06:52,384 --> 00:06:57,354
we, we reinforce the, the learning
to the entire database solution.

100
00:06:58,704 --> 00:07:02,684
Now moving on to the, one of the
points which we discussed was.

101
00:07:03,134 --> 00:07:06,374
Neural networks for data guard tuning.

102
00:07:06,524 --> 00:07:12,204
So data guard is one, like most of you
know, who are into database technologies.

103
00:07:12,204 --> 00:07:17,184
Data guard is a terminology used
by Oracle databases primarily

104
00:07:17,514 --> 00:07:19,584
with for the standby databases.

105
00:07:19,584 --> 00:07:21,294
So they basically.

106
00:07:21,774 --> 00:07:27,714
Keep a synchronous or asynchronous copy
of the primary database to a standby

107
00:07:27,714 --> 00:07:33,454
site or in the terms of replication so
that if anything happens to the primary

108
00:07:33,454 --> 00:07:37,534
side, the stand back can be activated.

109
00:07:37,994 --> 00:07:43,854
In case of failure, disasters or
crashes and also neural networks

110
00:07:43,854 --> 00:07:47,614
for data guard tuning is basically
synchronized replication like.

111
00:07:48,199 --> 00:07:54,559
Archive system should be very minimum
delay between primary and secondary, like

112
00:07:54,559 --> 00:07:59,989
in sub milliseconds for the replication
lag between primary and standby databases.

113
00:08:00,680 --> 00:08:06,200
So this will only ensure there is a net
zero data loss during fail or events.

114
00:08:06,200 --> 00:08:11,450
Like the solution is only suitable
if there's no data loss, right?

115
00:08:11,509 --> 00:08:15,649
We don't want any transaction
to be lost if there is a data.

116
00:08:16,025 --> 00:08:19,295
Failover, a database failover
between primary and secondary.

117
00:08:19,295 --> 00:08:24,245
Otherwise, the solution holds no
value if there is a lag, which

118
00:08:24,245 --> 00:08:25,955
results in transaction loss.

119
00:08:25,985 --> 00:08:30,724
So the most important thing is
there should be milliseconds of lag

120
00:08:30,784 --> 00:08:32,764
between primary and second secondary.

121
00:08:32,764 --> 00:08:37,865
So as soon as any transaction is
committed on the primary, it should be.

122
00:08:38,235 --> 00:08:42,225
Committed or, you know, rollback or
whatever happens in the primary, it should

123
00:08:42,225 --> 00:08:47,715
be image of it should be on the secondary
side within milliseconds of the gap.

124
00:08:48,795 --> 00:08:53,484
And second important factor is if you
want to achieve this data guy tuning

125
00:08:53,884 --> 00:08:59,674
like with milliseconds of gap, it
does not mean that the primary should

126
00:08:59,674 --> 00:09:05,435
be, it should take a performance hit
because of this kind of a a millisecond

127
00:09:05,494 --> 00:09:07,775
replication between primary and secondary.

128
00:09:07,775 --> 00:09:12,964
So with the minimum performance impact
on the primary, the secondary should

129
00:09:12,964 --> 00:09:15,964
be in sync without any data loss.

130
00:09:16,025 --> 00:09:20,704
That is the most important thing,
again, after a minimum data loss.

131
00:09:21,665 --> 00:09:23,224
Then of course.

132
00:09:23,655 --> 00:09:27,165
The third key point is
ultra fast recovery.

133
00:09:27,165 --> 00:09:32,215
So, like in Oracle there is
something called, called fast MMDR.

134
00:09:32,215 --> 00:09:36,815
So like, which is whenever there is
a failover happens, it, the failover

135
00:09:36,815 --> 00:09:41,985
should be quick enough that the
secondary should be available if the

136
00:09:41,985 --> 00:09:44,445
there is a failover, failover occurring.

137
00:09:45,005 --> 00:09:47,825
To keep it simple, we don't want.

138
00:09:48,440 --> 00:09:54,570
The application to be unavailable
while the failover happens.

139
00:09:54,570 --> 00:09:56,505
Now, a few seconds or a few minutes.

140
00:09:57,165 --> 00:10:03,505
Of downtime probably is agreeable to
most of the enterprise applications

141
00:10:03,505 --> 00:10:10,235
because there are very less enterprise
applications which demand a hundred

142
00:10:10,235 --> 00:10:15,075
percent uptime because there is
always a few minutes of downtime.

143
00:10:15,435 --> 00:10:20,955
So it's like 99.99 percentage
of uptime is agreeable, so.

144
00:10:21,645 --> 00:10:27,255
Like I said, so ultra fast recovery
on the standby side is going to still

145
00:10:27,255 --> 00:10:32,085
give you a few minutes of downtime, but
it should be happening quickly enough

146
00:10:32,145 --> 00:10:37,275
so that the secondary or the failover
database should be available within

147
00:10:37,685 --> 00:10:39,955
few minutes, if not less than a minute.

148
00:10:40,615 --> 00:10:43,195
So yeah, that is about
the data guard tuning.

149
00:10:44,155 --> 00:10:46,775
Now, moving on to,
another important point.

150
00:10:47,305 --> 00:10:55,135
It's called ROI, which is rate
of, sorry, return on investment of

151
00:10:55,135 --> 00:10:57,565
machine learning based resilience.

152
00:10:58,105 --> 00:10:58,525
So.

153
00:10:59,215 --> 00:11:03,995
What, what, what is the, the return on
investment for any enterprise company

154
00:11:04,275 --> 00:11:09,195
on all this kind, this kind of machine
learning and modeling and all it, there

155
00:11:09,195 --> 00:11:11,745
has to be a value to everything, right?

156
00:11:12,105 --> 00:11:18,095
So with the machine learning based
resilience of databases in cloud,

157
00:11:18,095 --> 00:11:21,125
Oracle Cloud they, they claim more than.

158
00:11:21,695 --> 00:11:27,095
To 80% of return of investment,
meaning it delivers exceptional

159
00:11:27,095 --> 00:11:33,725
financial return across enterprise
implementations over a three year period.

160
00:11:33,755 --> 00:11:41,945
So whatever investment is done to today,
it's going to give more than 280% of

161
00:11:41,945 --> 00:11:44,495
return within three years of time.

162
00:11:45,215 --> 00:11:46,115
What does it mean?

163
00:11:46,115 --> 00:11:47,195
It means the value.

164
00:11:47,915 --> 00:11:54,005
Any enterprise or any organization derive
from the investment they do on this Oracle

165
00:11:54,005 --> 00:12:00,665
Cloud infrastructure database as a service
or disaster recovery or any solution.

166
00:12:00,935 --> 00:12:04,700
So there is a pretty nice
return on investment.

167
00:12:05,915 --> 00:12:09,495
The second point is 8.4 month payback.

168
00:12:10,155 --> 00:12:14,735
What does it mean is within
like accelerated investment

169
00:12:14,795 --> 00:12:18,395
recovery with measurable costs,
saving from prevented outage.

170
00:12:18,395 --> 00:12:23,185
So like I said, 99.9
percentage availability.

171
00:12:23,185 --> 00:12:26,515
That means there are
outages which are prevented.

172
00:12:26,860 --> 00:12:31,270
By using machine learning, by doing
pattern analysis, by digging the

173
00:12:31,270 --> 00:12:36,600
logs, by making the analysis of the
outages that what can be prevented,

174
00:12:36,660 --> 00:12:41,730
what action can be taken 30 minutes
before a pattern is recognized.

175
00:12:42,270 --> 00:12:48,430
So it takes about eight months to
start paying back on this machine

176
00:12:48,430 --> 00:12:51,510
learning based Oracle Cloud solution.

177
00:12:52,620 --> 00:12:58,620
Again, 99.98 per availability is
ensures the, the, all the critical

178
00:12:58,620 --> 00:13:07,380
systems, they are operational for 8,758
hours annually, which is like only a

179
00:13:07,380 --> 00:13:10,310
few minutes of downtime is allowed.

180
00:13:10,460 --> 00:13:15,640
Across the industry wide, and there are,
there are agreeable parameters through

181
00:13:15,640 --> 00:13:21,820
SOC and all, all the compliance where how
many minutes are allowed of downtime to

182
00:13:21,820 --> 00:13:24,580
achieve that standard of availability of.

183
00:13:24,640 --> 00:13:28,100
Databases in Oracle or
any other technology.

184
00:13:28,490 --> 00:13:32,270
So it basically cost, minimizes
the cost of disruptions.

185
00:13:32,570 --> 00:13:33,830
So that's the plus point.

186
00:13:35,180 --> 00:13:40,260
So moving to the next important
point is what actually, how

187
00:13:40,260 --> 00:13:41,640
do we do machine learning?

188
00:13:42,170 --> 00:13:44,150
In, in Oracle cloud computing.

189
00:13:44,150 --> 00:13:48,080
So overall it's predictive
autoscaling benefits.

190
00:13:48,080 --> 00:13:51,680
So what, what is predictive
autoscaling benefits?

191
00:13:51,710 --> 00:13:57,020
So before going into the technical slides
and all, I'll just share one example.

192
00:13:57,020 --> 00:14:00,890
Like when, when a month end happens,
we know that there will be lot of

193
00:14:00,890 --> 00:14:05,450
transactions, there will be lot of
reports running in, so there'll be lot of.

194
00:14:06,080 --> 00:14:10,430
Hit on the CPU of a, a
database of database server.

195
00:14:10,430 --> 00:14:15,890
So autoscaling is as, as the
month had approaches and as the

196
00:14:15,890 --> 00:14:20,490
system recognizes that, okay, CPU
started getting hitting the peak.

197
00:14:21,000 --> 00:14:22,805
Autoscaling can enable add.

198
00:14:23,075 --> 00:14:25,865
Few CPUs more as the demand grows.

199
00:14:25,895 --> 00:14:30,615
So that's the predictive
auto-scaling the for a database.

200
00:14:30,615 --> 00:14:35,185
Similarly for memory similarly
for storage, if there is a store

201
00:14:35,185 --> 00:14:40,095
growth of databases happening
very high, at a very high rate.

202
00:14:40,945 --> 00:14:45,775
So the system should be autoscaled
enough to add more space or at

203
00:14:45,775 --> 00:14:51,075
least give the alerts for the system
engineer to provision more space.

204
00:14:51,075 --> 00:14:54,085
So that gives some prediction for it.

205
00:14:54,085 --> 00:14:57,710
So that actually helps
in avoiding many outages.

206
00:14:58,820 --> 00:14:59,040
So.

207
00:14:59,855 --> 00:15:05,255
Coming to the, the, what we have in
the slide is for auto-scaling benefits.

208
00:15:05,255 --> 00:15:08,855
So one is resource optimization,
second is cost reduction.

209
00:15:09,425 --> 00:15:14,135
So resource optimization is
machine learning models reduce over

210
00:15:14,135 --> 00:15:20,345
provisioning by 47% while ensuring
capacity for unexpected workloads.

211
00:15:20,915 --> 00:15:23,885
Like I said, we don't want to auto scale.

212
00:15:25,130 --> 00:15:28,100
24 by 7, 365 days, right?

213
00:15:28,100 --> 00:15:33,020
We want to auto scale only when the
peak load comes, which can be predicted.

214
00:15:33,560 --> 00:15:37,550
So by doing this, by machine
learning models, we can reduce o

215
00:15:37,550 --> 00:15:42,980
over provisioning by almost 50%,
if not LA more while ensuring the.

216
00:15:43,865 --> 00:15:46,055
Unexpected workloads can be catered.

217
00:15:46,055 --> 00:15:51,195
So not always provision higher,
CPU memory compute to the server.

218
00:15:51,465 --> 00:15:53,985
But whenever the production is
there, then it should be there.

219
00:15:53,985 --> 00:15:55,545
Otherwise it should scale down.

220
00:15:56,535 --> 00:15:58,095
Second is cost direction.

221
00:15:58,125 --> 00:16:01,395
So everything has a value, right?

222
00:16:01,425 --> 00:16:04,545
So when we do auto scaling, it's.

223
00:16:04,590 --> 00:16:12,140
Per CPU per memory any cloud organization
will charge accordingly if it is not done

224
00:16:12,170 --> 00:16:14,660
predictive auto scaling or down scaling.

225
00:16:14,660 --> 00:16:21,155
So by using machine learning,
we can reduce the cost depending

226
00:16:21,155 --> 00:16:22,745
on the predictive workload.

227
00:16:22,745 --> 00:16:29,235
So intelligent storage tier based on
access patterns decreases cost by 60%.

228
00:16:29,595 --> 00:16:33,975
So if there is no load on the servers,
there's no workload, there's no

229
00:16:33,975 --> 00:16:38,025
prediction, downscale the infrastructure.

230
00:16:38,145 --> 00:16:39,735
That's what it means.

231
00:16:40,035 --> 00:16:42,495
It helps in reducing the overall cost.

232
00:16:44,745 --> 00:16:45,765
Moving to the next.

233
00:16:46,075 --> 00:16:46,795
Slide.

234
00:16:46,855 --> 00:16:52,435
So here we are discussing about the
case studies of 99.98, availability

235
00:16:52,435 --> 00:16:58,735
of the enterprise solutions, so
finance, services, healthcare, retail.

236
00:16:58,735 --> 00:17:03,725
These are, you know, few of
the top industries where Oracle

237
00:17:04,055 --> 00:17:06,905
cloud compute is utilized and.

238
00:17:07,325 --> 00:17:13,805
There are benefits of it, like more than
99.98 availability, which helps all these

239
00:17:13,805 --> 00:17:19,295
organization meet finance, healthcare,
retail, grow their business on day-to-day

240
00:17:19,295 --> 00:17:23,815
basis because there are no outages, they
can cater to their customers around the

241
00:17:23,815 --> 00:17:30,485
clock, 24 by seven across the geographies
because Oracle provides, multi region

242
00:17:30,635 --> 00:17:35,415
cloud-based solutions where there is
no outage and things are available in

243
00:17:35,415 --> 00:17:37,985
the matter of few seconds or minutes.

244
00:17:39,605 --> 00:17:44,765
Moving to the next slide, so
scalable AI framework, so this is

245
00:17:44,765 --> 00:17:46,505
what we are talking about, right?

246
00:17:47,765 --> 00:17:50,825
So cross architecture compatibility.

247
00:17:50,825 --> 00:17:56,210
So it's not only Oracle Cloud, which
is to be, point of discussion here.

248
00:17:56,210 --> 00:18:00,980
There are multiple solutions
like Azure AWS Amazon Cloud

249
00:18:01,230 --> 00:18:04,270
GCP, Google Cloud IBM Cloud.

250
00:18:04,360 --> 00:18:10,640
So machine learning runs through, cuts
through all these scalable AI framework

251
00:18:11,210 --> 00:18:13,555
to get what information is required for.

252
00:18:14,405 --> 00:18:18,395
The enterprise solution to
work efficiently, effectively.

253
00:18:19,505 --> 00:18:22,305
Second is automated anomaly detection.

254
00:18:22,305 --> 00:18:27,055
So it's not that manually they,
these have to be analyzed by

255
00:18:27,115 --> 00:18:29,575
DBA or a engineer sitting there.

256
00:18:30,025 --> 00:18:34,745
But there are automated jobs which
can, which are, which can be scheduled

257
00:18:34,745 --> 00:18:39,005
to capture the logs and information,
and later on analysis is done.

258
00:18:39,485 --> 00:18:45,215
For, to be able to publish the reports
and boost the operational efficiency.

259
00:18:45,215 --> 00:18:47,645
Overall, it's all about efficiency, right?

260
00:18:48,875 --> 00:18:51,405
Thank the next point is
engineering productivity.

261
00:18:51,405 --> 00:18:56,130
So it frees data I. Teams
from manual process.

262
00:18:56,130 --> 00:18:58,290
Like I said, it's all automated jobs.

263
00:18:58,570 --> 00:19:02,510
Once the jobs are there, you can
customize the jobs as per your need,

264
00:19:02,960 --> 00:19:06,920
and you can enable the focus on
high priority task and innovation.

265
00:19:06,950 --> 00:19:07,310
Right?

266
00:19:07,310 --> 00:19:09,985
Other than the mundane manual jobs.

267
00:19:11,365 --> 00:19:17,345
Now coming to the last topic of
the discussion, so transforming

268
00:19:17,345 --> 00:19:19,805
data base resilience, so.

269
00:19:21,050 --> 00:19:22,280
There are four steps to it.

270
00:19:22,370 --> 00:19:28,460
You discover the problem, identify the
the pattern, you implement the solution

271
00:19:28,460 --> 00:19:31,970
using deploy machine learning driven
monitoring and optimization tool.

272
00:19:32,955 --> 00:19:37,995
Tools, then you optimize what you have
learned from, from there, and then you

273
00:19:38,055 --> 00:19:44,565
archive you, sorry, you achieve your
99.98% availability while reducing

274
00:19:44,565 --> 00:19:49,365
the overall running cost of the
entire enterprise architect solution.

275
00:19:50,365 --> 00:19:50,605
Yeah.

276
00:19:50,605 --> 00:19:54,025
So team this is about the presentation.

277
00:19:54,025 --> 00:19:57,365
I thank you for all your
time and listening to me.

278
00:19:57,675 --> 00:19:58,575
You have a good day.

279
00:19:58,635 --> 00:19:58,935
Thanks.

280
00:19:58,935 --> 00:19:59,295
Bye.

