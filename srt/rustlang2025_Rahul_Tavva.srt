1
00:00:00,500 --> 00:00:01,429
Good morning everyone.

2
00:00:01,729 --> 00:00:05,899
My name is Raul Tawa, senior Network
Cloud infrastructure engineer at Kyro

3
00:00:05,899 --> 00:00:07,790
Technologies based out of Dallas, Texas.

4
00:00:08,290 --> 00:00:12,549
Over the past decade, I have led large
scale in transformations for the global

5
00:00:12,549 --> 00:00:17,890
enterprises, including migrating more than
2000 plus sites to SD-WAN in modernizing

6
00:00:17,890 --> 00:00:22,299
manufacturing networks and implementing
AI driven routing architectures.

7
00:00:22,509 --> 00:00:23,619
Today's session is about.

8
00:00:24,460 --> 00:00:28,360
Building Next generation network
infrastructure using Rust, a language

9
00:00:28,360 --> 00:00:32,830
that has fundamentally changed how
we approach a safety performance and

10
00:00:33,250 --> 00:00:35,110
concurrency in production networks.

11
00:00:35,470 --> 00:00:41,280
We'll explore how Rust enables zero
trust packet processing AI based routing

12
00:00:41,280 --> 00:00:45,894
decisions and enterprise great security
without compromising on the performance.

13
00:00:46,394 --> 00:00:49,454
So today's we'll break down
the session into five parts.

14
00:00:49,754 --> 00:00:54,344
Why Russ, why rusts for the network
infrastructure's, real time, real world

15
00:00:54,504 --> 00:00:59,095
case studies, practical implementation
techniques, security, enterprise options,

16
00:00:59,095 --> 00:01:01,435
and key takeaways, and the next steps.

17
00:01:01,935 --> 00:01:04,665
The challenge of modern network
infrastructure, the problem

18
00:01:04,665 --> 00:01:05,835
is pretty clear these days.

19
00:01:06,075 --> 00:01:10,305
Our networks are growing faster
and more complex than our tools.

20
00:01:10,725 --> 00:01:16,335
We are moving from 10 GBPS pipes
to 400 GBPS backbones with sub

21
00:01:16,335 --> 00:01:21,275
millisecond latency requirements
for high frequency trading.

22
00:01:21,485 --> 00:01:26,980
5G core functions and real time analytics
recommendations are no longer static.

23
00:01:27,695 --> 00:01:32,554
They're being driven by ML models
that need real time interference,

24
00:01:33,054 --> 00:01:38,005
optimizing for latency, condition
jitter, and even energy efficiencies.

25
00:01:38,304 --> 00:01:42,475
Meanwhile, in the legacy stack,
in such as C and C plus PE, carry,

26
00:01:42,475 --> 00:01:47,035
dig of technical debt and security
package buffer overflows, dangling

27
00:01:47,094 --> 00:01:51,085
binders, race conditions that
attackers allowed to exploit.

28
00:01:51,910 --> 00:01:55,210
And the operational cost of
patching and hardening these systems

29
00:01:55,210 --> 00:01:57,040
is growing substantially high.

30
00:01:57,909 --> 00:02:04,059
In short, the gap between what the
network needs to do and what our current

31
00:02:04,059 --> 00:02:09,320
tools allow our current tools allow
is widening to large extent why rust

32
00:02:09,485 --> 00:02:11,810
is ideal for network infrastructures.

33
00:02:12,170 --> 00:02:16,730
Rust solves the pro this problem
without forcing us to compromise.

34
00:02:17,375 --> 00:02:23,525
The ownership model, memory safety
is enforced to compile time without

35
00:02:23,525 --> 00:02:28,565
a garbage collector, no runtime
overheads, no pauses, and no leaks.

36
00:02:29,075 --> 00:02:32,975
This matters in the networks where
dropping a packet is not an option.

37
00:02:33,515 --> 00:02:38,735
Zero cost abstractions, right
code that looks high level, but

38
00:02:38,735 --> 00:02:42,995
combines down to machine code as a
as efficient as a handwritten code.

39
00:02:43,495 --> 00:02:47,875
We can design expressive APIs for
packet parsing without adding cycles.

40
00:02:47,875 --> 00:02:53,745
Fearless concurrency, rust makes it
safe to share state between threads

41
00:02:53,895 --> 00:02:58,695
without locks, enabling parallel packet
parsing without the race conditions,

42
00:02:58,695 --> 00:02:59,685
which is a really great option.

43
00:03:00,185 --> 00:03:06,455
Memory safety by eliminating buffer
flows and use after free rust removes

44
00:03:06,455 --> 00:03:11,525
the root cause or root cause of
70% of CVEs in network software

45
00:03:12,035 --> 00:03:14,610
over the last decade in production.

46
00:03:14,610 --> 00:03:18,420
This means you can hit line rate
performance while guaranteeing

47
00:03:18,440 --> 00:03:23,635
safety properties that were once to
impossible in the system language.

48
00:03:24,135 --> 00:03:26,775
Zero copy packet processing with rust.

49
00:03:26,775 --> 00:03:31,484
In traditional stack, a single
packet might be copied five times.

50
00:03:31,575 --> 00:03:36,255
Nick to kernel user and kernel to user
base and the kernel back to the nick.

51
00:03:36,644 --> 00:03:41,234
Each copy adds a latency and
burn CPU cycles at 400 GVPS.

52
00:03:41,234 --> 00:03:45,614
Even a single extra copy can cost
millions of hardware over time.

53
00:03:46,035 --> 00:03:48,255
With rust, we can eliminate most of it.

54
00:03:48,704 --> 00:03:51,165
Map Nick Buffers directly into.

55
00:03:51,929 --> 00:03:54,119
User space with safety abstractions.

56
00:03:54,420 --> 00:03:58,499
Pass references instead of
making memory copies, use borrow.

57
00:03:58,739 --> 00:04:02,579
Borrow, checking to guarantee no
dangling pointers or double freeze.

58
00:04:03,079 --> 00:04:08,419
In integrate with this async
runtime like Tokyo for non-blocking

59
00:04:08,419 --> 00:04:13,549
packets IO in our tests, moving
from traditional copying to rust.

60
00:04:13,759 --> 00:04:18,709
Zero copy approach, reduced packet
processing latency by 40 to 65%,

61
00:04:19,099 --> 00:04:23,389
and free CPU core for additional
workloads like telemetry analysis.

62
00:04:23,889 --> 00:04:27,729
Let's do a case study, taking the
financial services industry through the

63
00:04:27,729 --> 00:04:29,559
routing in the financial service industry.

64
00:04:29,609 --> 00:04:34,049
This was a, this was for a major
US exchange with extreme latency

65
00:04:34,049 --> 00:04:37,499
sensitivity security, which
is one of the most important.

66
00:04:37,559 --> 00:04:41,489
94% of the vulner vulnerabilities
disappeared overnight simply because

67
00:04:41,489 --> 00:04:45,149
rust made them representable in code.

68
00:04:45,239 --> 00:04:46,199
No more emergency.

69
00:04:46,199 --> 00:04:48,689
Midnight patches for the
buffer overflows latency.

70
00:04:49,424 --> 00:04:53,954
Routing decisions dropped from one
20 milliseconds to 32 milliseconds.

71
00:04:53,984 --> 00:04:57,164
That's nearly four times
improvement in the HFT.

72
00:04:57,914 --> 00:05:00,614
That can be the difference between
winning and losing a trade.

73
00:05:01,114 --> 00:05:05,404
Throughput, same hardware, 3.4
more transactions per second.

74
00:05:05,404 --> 00:05:06,664
No extra networkers.

75
00:05:06,664 --> 00:05:08,374
No extra CPUs.

76
00:05:08,874 --> 00:05:11,274
AI driven routing in rust.

77
00:05:12,009 --> 00:05:17,109
With rust, we can run ML reference
directly in the forward path.

78
00:05:17,319 --> 00:05:22,929
No round trips to separate analytical
engine data collection telemetry at

79
00:05:22,929 --> 00:05:26,799
tens of thousands of samples per second,
using zero cost obstruction model

80
00:05:26,799 --> 00:05:32,319
training offline on historical routing
data with features like utilization

81
00:05:32,319 --> 00:05:34,829
jitter packet and drops interference.

82
00:05:34,829 --> 00:05:37,769
Rust based engines run these
models in microseconds.

83
00:05:38,099 --> 00:05:42,659
Selecting optical parts in real
time, hard swapping hard swap out

84
00:05:42,659 --> 00:05:44,969
models without stopping traffic.

85
00:05:44,969 --> 00:05:47,880
Enabling adaptive learning
network techniques.

86
00:05:47,969 --> 00:05:52,650
This makes it possible to have
truly self optimized network with

87
00:05:52,650 --> 00:05:58,120
decision aware decisions are dynamical
dynamic as the traffic itself.

88
00:05:58,620 --> 00:06:01,799
Practical roster techniques
for network programming.

89
00:06:02,130 --> 00:06:03,870
These are the three powerful techniques.

90
00:06:03,870 --> 00:06:06,469
Stand out efficient
protocol serialization.

91
00:06:06,890 --> 00:06:09,789
Using ER for compact zero copy.

92
00:06:09,789 --> 00:06:13,030
Serialization de serialization
of the routing, routing

93
00:06:13,030 --> 00:06:14,859
headers and telemetry data.

94
00:06:14,950 --> 00:06:20,169
Custom allocators, pre allocate buffers
with predictable latency at 400 GPS

95
00:06:20,169 --> 00:06:23,080
and nanosecond matters Ring buffers.

96
00:06:23,500 --> 00:06:26,305
LOP free packet queues with atomic index.

97
00:06:27,295 --> 00:06:32,305
For deterministic throughput,
these patterns let us match and

98
00:06:32,305 --> 00:06:38,515
often beat the performance of hand
optimized code while keeping rust

99
00:06:38,515 --> 00:06:41,034
strong safety guaranteed intact.

100
00:06:41,534 --> 00:06:43,304
Security advantage of rust.

101
00:06:43,814 --> 00:06:47,894
The majority of the network CVEs
come from memory safety issues,

102
00:06:47,894 --> 00:06:49,754
exactly what trust eliminates.

103
00:06:49,784 --> 00:06:53,264
No buffer overflows, no
use of free after free.

104
00:06:54,074 --> 00:06:55,064
No data raise.

105
00:06:55,094 --> 00:06:59,294
Strong type system prevents
logic errors in packet parsing

106
00:06:59,294 --> 00:07:02,264
and routing state machines.

107
00:07:03,134 --> 00:07:08,024
Even when we do need unsafe blocks
for hard hardware access, the

108
00:07:08,024 --> 00:07:11,744
rust forces us to isolate and
capsulate and audit that code.

109
00:07:12,134 --> 00:07:16,874
This drastically reduces the
attack surface while keeping

110
00:07:16,874 --> 00:07:19,484
performance at a bare metal levels.

111
00:07:19,984 --> 00:07:23,044
Let's do a case study of a
manufacturing network, resilience

112
00:07:23,044 --> 00:07:24,364
in a manufacturing industry.

113
00:07:24,769 --> 00:07:30,199
Fortune 500 manufacturer has had
a recurring nightmare pro in a

114
00:07:30,199 --> 00:07:34,669
production lines Hal halted by the
network outages I, and then the

115
00:07:34,669 --> 00:07:36,889
recovery time was up to 17 minutes.

116
00:07:36,889 --> 00:07:39,949
Gradually gradual performance
degradation from memory links

117
00:07:39,949 --> 00:07:41,669
was also a ma major issue.

118
00:07:41,939 --> 00:07:46,149
After implementing the rust
routing he, the manufacturer hit

119
00:07:46,149 --> 00:07:51,164
the uptime of 99.998%, and the
failover and recovery dropped.

120
00:07:51,704 --> 00:07:57,274
Under 200 microseconds milliseconds,
security patches applied without

121
00:07:57,274 --> 00:08:02,584
taking the network offline via hot
patching, and the VP of Operation

122
00:08:02,584 --> 00:08:08,254
told that rust and error handling
turn our network from a frequent

123
00:08:08,254 --> 00:08:13,339
failure point into our most reliable
system enterprise adoption strategies.

124
00:08:13,839 --> 00:08:16,509
So you don't have to rewrite
everything on one day.

125
00:08:16,749 --> 00:08:21,499
It's basically starts by by targeting the
bottlenecks per safety and performance.

126
00:08:21,499 --> 00:08:25,389
I improvement say performance
improvements will have the biggest ROI.

127
00:08:26,034 --> 00:08:32,574
Use FFI Bridges to integrate rust
models with c cc plus legacy systems run

128
00:08:32,574 --> 00:08:36,474
parallel deployments to validate trust
performance under production loads.

129
00:08:36,834 --> 00:08:41,634
Use rust testing framework for unit
integration and property based testing

130
00:08:41,905 --> 00:08:46,014
before rollouts Phase two deployments
start with non-critical parts, then

131
00:08:46,014 --> 00:08:47,754
migrate to the code routing functions.

132
00:08:48,714 --> 00:08:54,384
This approach minimizes risk while
steadily replacing fragile legacy code.

133
00:08:54,884 --> 00:08:55,904
Key takeaways.

134
00:08:56,024 --> 00:09:00,584
Rust lets us achieve safety
without sacrificing the speed.

135
00:09:00,614 --> 00:09:01,094
Zero.

136
00:09:01,094 --> 00:09:05,864
Copy processing and fearless
concurrency means fewer CPUs, low

137
00:09:05,864 --> 00:09:07,874
latency and higher throughput.

138
00:09:08,234 --> 00:09:14,084
Rust deterministic performance makes
it AI ready, enabling in the in path.

139
00:09:14,144 --> 00:09:16,274
ML interference for the smarting.

140
00:09:16,774 --> 00:09:18,664
Thank you for the opportunity.

141
00:09:19,354 --> 00:09:20,104
Have a great day.

