1
00:00:00,500 --> 00:00:01,580
Speaker 13: Good day everyone.

2
00:00:01,920 --> 00:00:06,030
My name is Marav Koff and today we
are going to talk about how to build

3
00:00:06,030 --> 00:00:08,760
secure services with AI agents.

4
00:00:09,420 --> 00:00:13,320
If you ask security engineers
about AI agents today, you

5
00:00:13,320 --> 00:00:15,060
usually get one or two reactions.

6
00:00:15,409 --> 00:00:17,000
The first one is excitement.

7
00:00:17,210 --> 00:00:19,070
The second one is terror.

8
00:00:19,580 --> 00:00:26,689
I work@booking.com where we, I built and
maintain our payment system in our world.

9
00:00:27,140 --> 00:00:30,530
Move fast and break things
isn't a motto, it's a f threatt.

10
00:00:30,710 --> 00:00:33,410
If you break things, people
don't get on flights.

11
00:00:33,500 --> 00:00:35,000
How to won't get paid.

12
00:00:35,150 --> 00:00:39,500
So naturally, the idea of letting
AI agents write new features to our

13
00:00:39,500 --> 00:00:41,630
production services sounds insane.

14
00:00:42,290 --> 00:00:44,325
A year ago I would agree with you.

15
00:00:44,825 --> 00:00:50,275
Let me tell you why I started
experiencing this agent experimenting

16
00:00:50,275 --> 00:00:53,095
with agent on my local machine.

17
00:00:53,185 --> 00:00:55,435
I gave it a very basic task.

18
00:00:55,585 --> 00:00:58,765
Updated dependencies in
this project, run the tests.

19
00:00:58,975 --> 00:00:59,905
Simple, right?

20
00:01:00,685 --> 00:01:01,915
I watched the logs.

21
00:01:01,975 --> 00:01:05,035
It filed pox ml, updated versions.

22
00:01:05,084 --> 00:01:06,374
It ran Maven test.

23
00:01:07,270 --> 00:01:12,490
But build failed, and then instead of
asking for help or try to do something

24
00:01:12,490 --> 00:01:16,779
else, it decided to fix the environment
because it fought environmental issue.

25
00:01:16,779 --> 00:01:16,839
It.

26
00:01:17,339 --> 00:01:19,169
I looked away for 30 seconds.

27
00:01:19,259 --> 00:01:23,849
When I looked back, the agent
wasn't editing the project anymore.

28
00:01:24,479 --> 00:01:29,609
It had navigated out of the project
folder to my home directory, and

29
00:01:29,609 --> 00:01:34,649
I was attempting to rewrite my
Global Maven configuration to force

30
00:01:34,649 --> 00:01:36,539
a different local repository path.

31
00:01:36,539 --> 00:01:38,399
It wasn't malicious.

32
00:01:38,609 --> 00:01:42,149
It was just super, super
helpful because this is how it.

33
00:01:42,734 --> 00:01:45,464
Trained to be aggressively helpful.

34
00:01:45,704 --> 00:01:48,554
It was trying to solve the
problem no matter what.

35
00:01:48,884 --> 00:01:52,934
I stopped it in time, but that
moment left me with a choice.

36
00:01:53,354 --> 00:01:57,014
Give up or build the system
where it doesn't matter if

37
00:01:57,014 --> 00:01:58,664
agent can make a mistake.

38
00:01:59,164 --> 00:02:04,474
My first mistake was thinking that
I could talk agent into being good.

39
00:02:04,564 --> 00:02:08,524
I thought I just need to
better skills, rules, prompts.

40
00:02:09,024 --> 00:02:11,234
I. Let's look at the first slide.

41
00:02:12,105 --> 00:02:16,334
So my first idea was I will
taught agent how to behave.

42
00:02:16,424 --> 00:02:22,695
I will taught it how to work with coso, do
not make mistakes, never hardcore secrets.

43
00:02:22,695 --> 00:02:27,325
Follow PCI requirements we trying
to talk agent into being good.

44
00:02:27,924 --> 00:02:31,619
A reality is that prompt
injections are always possible.

45
00:02:32,119 --> 00:02:33,059
Agents can act.

46
00:02:33,559 --> 00:02:35,899
Agents are not deterministic.

47
00:02:35,899 --> 00:02:40,579
They can hallucinate at any
time and bypass all the rules

48
00:02:41,089 --> 00:02:42,559
and do not make mistakes.

49
00:02:42,619 --> 00:02:44,314
Unfortunately, doesn't work.

50
00:02:44,814 --> 00:02:47,364
Prompts are guide
guidelines, not guardrails.

51
00:02:47,454 --> 00:02:51,504
If you rely on a prompt to stop
an agent from hallucinating your

52
00:02:51,504 --> 00:02:56,364
library or putting a bag into
your code, you don't have security

53
00:02:56,364 --> 00:02:58,794
strategy, you have hopes and prayers.

54
00:02:58,944 --> 00:03:00,534
Models are not deterministic.

55
00:03:00,894 --> 00:03:04,584
No amount of instructions
make it 100% reliable.

56
00:03:05,004 --> 00:03:08,214
So if we can just trust the
brain, we must contain the body.

57
00:03:08,714 --> 00:03:10,154
So we should build a playground.

58
00:03:10,654 --> 00:03:15,814
Simply Playground is a Docker
container with restricted file system

59
00:03:16,434 --> 00:03:18,114
that was one of the restrictions.

60
00:03:18,614 --> 00:03:22,099
Second restriction is command wide list.

61
00:03:22,739 --> 00:03:25,679
Here, it's up to you where to draw a line.

62
00:03:25,859 --> 00:03:30,539
I usually doesn't allow agents to
check all websites they want, so

63
00:03:30,539 --> 00:03:32,249
I have a wide list of websites.

64
00:03:32,429 --> 00:03:35,879
I do not allow them to do some
destructive commands, such

65
00:03:35,879 --> 00:03:37,169
as removing files and stuff.

66
00:03:37,169 --> 00:03:38,939
So it's up to you to decide.

67
00:03:38,969 --> 00:03:44,369
You don't want it to be very harsh,
but you don't want it to be you don't

68
00:03:44,369 --> 00:03:47,789
want this list to be too narrow.

69
00:03:47,849 --> 00:03:49,559
So your agent should.

70
00:03:49,949 --> 00:03:52,469
Be autonomous but not destructive.

71
00:03:53,099 --> 00:03:58,709
And third most important one, you should
always have a credential secret manager.

72
00:03:58,739 --> 00:04:05,209
So credentials should not leave should not
leave the secret manager and credentials

73
00:04:05,209 --> 00:04:07,889
cannot end up in the agent context.

74
00:04:08,389 --> 00:04:13,069
When you treat your environment as
hostile, the agent's intent stop matter.

75
00:04:13,459 --> 00:04:15,649
It can try to be malicious.

76
00:04:15,964 --> 00:04:17,164
Work can be stupid.

77
00:04:17,284 --> 00:04:19,324
The result, the same acts is denied.

78
00:04:19,824 --> 00:04:22,284
So we have an agent in the box.

79
00:04:22,344 --> 00:04:26,664
It cannot burn the house down, but
it still can produce buggy code.

80
00:04:27,174 --> 00:04:28,734
And this leads us to leave.

81
00:04:28,734 --> 00:04:31,614
Number two, AI will
replace security review.

82
00:04:31,794 --> 00:04:36,624
Some people think that AI is so smart,
it can do security review for me.

83
00:04:36,954 --> 00:04:40,164
Just let agent check my code and ship it.

84
00:04:40,674 --> 00:04:43,224
Othering thinks the opposite that.

85
00:04:43,599 --> 00:04:49,439
Humans cannot be replaced and only
humans should conduct a security review.

86
00:04:49,949 --> 00:04:50,909
Both are wrong.

87
00:04:51,059 --> 00:04:54,839
The answer is a cancel,
not a single authority.

88
00:04:55,289 --> 00:04:57,359
Let me explain what cancel is.

89
00:04:57,629 --> 00:05:03,839
I use multiple LMS to review important
code because one model can start reward

90
00:05:03,839 --> 00:05:05,914
Hawking without doing any review at all.

91
00:05:06,194 --> 00:05:09,794
The pattern school, the council,
you probably heard about it.

92
00:05:09,974 --> 00:05:11,894
Andre car talked about it.

93
00:05:12,104 --> 00:05:13,514
It's very interesting concept.

94
00:05:14,024 --> 00:05:16,244
Think of it as a medical consultation.

95
00:05:16,364 --> 00:05:19,814
You don't trust one doctor
for a serious diagnosis.

96
00:05:20,084 --> 00:05:22,904
You want a second or
maybe a third opinion?

97
00:05:23,834 --> 00:05:28,154
I have agents with different
roles, A PCI expert.

98
00:05:29,145 --> 00:05:31,664
That follows the Sta PCS standards.

99
00:05:31,934 --> 00:05:38,414
The reviewer, a code quality model that is
explicitly prompted to be mean an arbiter.

100
00:05:38,715 --> 00:05:43,424
The person who wa weights their
opinions of other roles and

101
00:05:43,424 --> 00:05:45,015
decides what should be done.

102
00:05:45,494 --> 00:05:49,364
Each role ran some different LLM
model, they discuss, and then

103
00:05:49,395 --> 00:05:52,664
arbiter decides what should be done.

104
00:05:53,164 --> 00:05:58,294
If they can't reach consensus on time,
they all produce reports with their takes.

105
00:05:58,634 --> 00:06:01,875
And let human to decide what we should do.

106
00:06:01,994 --> 00:06:04,215
So human makes the final call.

107
00:06:04,715 --> 00:06:07,384
Let's talk about the
whole feature workflow.

108
00:06:08,044 --> 00:06:11,494
First of all, we go to
the brainstorm session.

109
00:06:11,824 --> 00:06:15,784
We receive a feature request,
and then agents wants to know.

110
00:06:16,549 --> 00:06:19,189
What we want to build and
how we want to build it.

111
00:06:19,189 --> 00:06:22,520
So it starts asking questions,
and you as a developer should

112
00:06:22,520 --> 00:06:24,049
provide knowledge for the agent.

113
00:06:24,590 --> 00:06:27,109
When agent has nothing else to ask.

114
00:06:27,409 --> 00:06:29,749
It goes into plan, so it breaks the.

115
00:06:30,634 --> 00:06:32,525
Brainstorm session that you had.

116
00:06:32,525 --> 00:06:37,324
It breaks this design documented
to small bite-size pieces and

117
00:06:37,984 --> 00:06:39,634
creates an implementation plan.

118
00:06:39,905 --> 00:06:41,494
Now goes the most interesting part.

119
00:06:41,614 --> 00:06:44,704
The execution agents creates a subagents.

120
00:06:45,124 --> 00:06:50,134
They produ, they execute tasks one
by one until everything is done.

121
00:06:50,764 --> 00:06:54,629
Also, important step here
that after each task is done.

122
00:06:55,234 --> 00:06:59,134
The small review is concluded, no,
not the whole council review, but

123
00:06:59,134 --> 00:07:04,834
small review by one Subagent funnel,
and then the last tab, everything is

124
00:07:04,834 --> 00:07:09,924
implemented, so we should give it to
the council, and council will review it.

125
00:07:10,254 --> 00:07:16,134
But important thing is that we still in
the loop, so agents won't replace human.

126
00:07:16,809 --> 00:07:20,919
At least for now, but they
will amplify our capabilities.

127
00:07:20,919 --> 00:07:23,710
So I am present in all of those sections.

128
00:07:24,129 --> 00:07:29,519
I maybe, I don't want to be, but I have
to and it amplifies my input to it.

129
00:07:30,019 --> 00:07:33,859
But we have a playground to
contain the blast stratus.

130
00:07:33,949 --> 00:07:39,199
We have a console to check the quality
of the produced code, but I've worked

131
00:07:39,199 --> 00:07:45,109
in FinTech for 10 years and I know one
truth, something will eventually go wrong.

132
00:07:45,679 --> 00:07:47,059
We need to be ready for.

133
00:07:47,559 --> 00:07:51,939
And this leads us to like to the
most important piece that you

134
00:07:51,939 --> 00:07:54,789
should always audit everything.

135
00:07:55,210 --> 00:07:58,369
When agent make mistakes,
you cannot debug it like a.

136
00:07:58,955 --> 00:07:59,855
Regular program.

137
00:07:59,915 --> 00:08:02,045
You need to know what it was thinking.

138
00:08:02,285 --> 00:08:04,655
You need to record a chain of thoughts.

139
00:08:04,805 --> 00:08:06,635
You need to record a session.

140
00:08:06,844 --> 00:08:13,205
If agent tries to escape playground, I
want to know exactly what protocol that

141
00:08:13,535 --> 00:08:19,685
so answer is out it and log as much as
possible and all keep all those logs.

142
00:08:20,185 --> 00:08:25,645
This leads us to myth number three,
that it might be too much to implement.

143
00:08:25,795 --> 00:08:27,234
So it's all complex.

144
00:08:27,815 --> 00:08:29,125
What if I know what you think.

145
00:08:29,125 --> 00:08:34,795
Like playgrounds, councils, Audis sounds
like a massive infrastructure project

146
00:08:34,795 --> 00:08:37,315
and it's hard to invest into that.

147
00:08:37,815 --> 00:08:39,645
But you don't have to start big.

148
00:08:39,705 --> 00:08:40,755
You can start small.

149
00:08:40,965 --> 00:08:43,275
You can start with super simple task.

150
00:08:43,365 --> 00:08:46,185
It's a create agent and
describe your project.

151
00:08:46,575 --> 00:08:50,025
Most of agents has this
feature already onboarded.

152
00:08:50,085 --> 00:08:51,105
You just need it.

153
00:08:51,465 --> 00:08:52,755
But don't be lazy.

154
00:08:52,905 --> 00:08:53,445
Please review it.

155
00:08:53,945 --> 00:08:57,035
Then you can gradually
increase your automation.

156
00:08:57,035 --> 00:08:59,585
You can discover problems or not problems.

157
00:08:59,585 --> 00:09:03,965
You can discover routine tasks in your
team and create the skills for that.

158
00:09:04,325 --> 00:09:06,845
This way, you'll have
a predictable results.

159
00:09:07,355 --> 00:09:12,365
Then you move forward for
cancel, or for agents or for

160
00:09:12,725 --> 00:09:14,675
formm of agents, you name it.

161
00:09:14,795 --> 00:09:19,685
Because this is a very
rapidly changing environment.

162
00:09:20,060 --> 00:09:23,750
And you want to experiment
and we now at the stage where

163
00:09:23,750 --> 00:09:25,700
we can automate automation.

164
00:09:26,030 --> 00:09:28,550
And stage three may be unique.

165
00:09:28,640 --> 00:09:30,080
You can shape it as you want.

166
00:09:30,580 --> 00:09:33,640
And let's talk about the checklist.

167
00:09:33,730 --> 00:09:38,100
To recap everything we should
say, like no secrets should

168
00:09:38,100 --> 00:09:40,470
be present in agent's context.

169
00:09:40,970 --> 00:09:43,490
Please let me be clear about that.

170
00:09:44,210 --> 00:09:44,565
You can.

171
00:09:45,545 --> 00:09:51,755
Let agent work with secrets, but what
you cannot do to let the secrets end

172
00:09:51,755 --> 00:09:58,505
up in the context, next step is build a
playground, not just rules and prompts.

173
00:09:58,715 --> 00:10:02,855
So you want to physically
restrict agent to, to harm you.

174
00:10:03,395 --> 00:10:07,715
Doesn't matter what they thought
about, they might think that they are

175
00:10:07,715 --> 00:10:09,995
helpful, but you have to restrict that.

176
00:10:10,495 --> 00:10:11,275
And third one.

177
00:10:11,775 --> 00:10:17,765
Keep human in the loop for critical
actions because without human we still

178
00:10:17,765 --> 00:10:20,835
need humans to apply important decisions.

179
00:10:20,895 --> 00:10:24,510
You cannot blame LLM because
you as a human approved it.

180
00:10:25,010 --> 00:10:28,250
Cross validate everything
as much as possible.

181
00:10:28,760 --> 00:10:34,670
LLMs, it's an electricity for thoughts,
so you can outsource this thought process.

182
00:10:34,670 --> 00:10:39,320
You don't have to think about it,
but you can as a philosopher said

183
00:10:39,470 --> 00:10:42,805
that truth bo burn in the argument.

184
00:10:42,939 --> 00:10:47,439
So use that and let council to Bernie to.

185
00:10:47,939 --> 00:10:49,890
Bo Burn your Truth.

186
00:10:50,130 --> 00:10:55,819
So yeah, how did everything,
this will help you with possible

187
00:10:55,819 --> 00:11:00,860
incidents and with debug and with
iteration and improving your skills.

188
00:11:01,580 --> 00:11:06,830
And start simple, create
MD and that will be it.

189
00:11:07,430 --> 00:11:10,445
And don't let the Great
Escape help scare you.

190
00:11:11,165 --> 00:11:15,625
Because as every new technology at
the beginning is dangerous, but the

191
00:11:15,625 --> 00:11:20,215
more you think about it and work
without visit, the better it becomes.

192
00:11:20,715 --> 00:11:21,945
Thank you everybody.

193
00:11:22,175 --> 00:11:25,805
You can add me on my LinkedIn
if you're interested.

194
00:11:26,435 --> 00:11:27,425
Have a good day.

