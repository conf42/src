1
00:00:00,280 --> 00:00:00,800
Hey, everyone.

2
00:00:00,940 --> 00:00:02,659
I'm Shesanath Bala Venkata.

3
00:00:03,020 --> 00:00:08,060
I'm a senior manager and I build
data products and that takes care

4
00:00:08,060 --> 00:00:10,449
of data engineering with Comcast.

5
00:00:10,809 --> 00:00:15,889
So today's talk is about cloud computing
cost shutdowns, how we will save

6
00:00:15,939 --> 00:00:21,490
millions of OPEX dollars optimizing
AWS EMR and Databricks workloads.

7
00:00:22,050 --> 00:00:24,730
So let's dive into the talk.

8
00:00:24,770 --> 00:00:25,140
So

9
00:00:25,640 --> 00:00:30,865
the agenda for today's talk is We'll
dive into what is Databricks and what

10
00:00:30,865 --> 00:00:33,535
are the Databricks cost optimization.

11
00:00:34,035 --> 00:00:36,074
Then what is AWS EMR?

12
00:00:36,835 --> 00:00:41,595
What are different types of
AWS EMR features is available

13
00:00:42,114 --> 00:00:44,225
and offerings are in market.

14
00:00:44,565 --> 00:00:48,394
And we'll look at what are
the AWS EMR cost optimization.

15
00:00:48,894 --> 00:00:50,394
So what is Databricks?

16
00:00:50,404 --> 00:00:54,904
So Databricks is a cloud based
unified analytical platform, which

17
00:00:54,904 --> 00:00:57,154
is built on top of Apache Spark.

18
00:00:57,604 --> 00:01:02,744
so Databricks build, bring, ease of
use on top of Apache Spark, where it

19
00:01:02,744 --> 00:01:08,914
has like a lot of, UI capabilities
on top of it and it has, it can

20
00:01:08,914 --> 00:01:13,045
leverage for data engineering and
machine learning and huge, data, big

21
00:01:13,045 --> 00:01:16,055
data processing and the key features.

22
00:01:16,555 --> 00:01:19,975
Of the Databricks are
Apache Spark optimizing.

23
00:01:20,305 --> 00:01:24,495
So in, if you see like open
source, Apache Spark was a

24
00:01:24,495 --> 00:01:26,355
Databricks version of Apache Park.

25
00:01:26,355 --> 00:01:31,675
It's more optimized and you'll see
lesser errors running, huge workloads.

26
00:01:31,735 --> 00:01:36,285
you'll not see the workers dying in
middle when running on, Databricks.

27
00:01:36,765 --> 00:01:39,550
And it offers, one a feature
called the data Lake.

28
00:01:40,350 --> 00:01:44,220
Where it, provides ACID
compliant on your data set.

29
00:01:44,220 --> 00:01:47,970
Like it's more of a OLTP
offering from Databricks.

30
00:01:47,980 --> 00:01:51,680
So Delta is more of like, whenever
there is a change happens on your,

31
00:01:52,130 --> 00:01:56,089
system, it will capture that and it
will maintain the metadata for it.

32
00:01:56,130 --> 00:02:00,970
And you can pull the transaction
information and it supports the ACID.

33
00:02:01,710 --> 00:02:03,870
And it supports,
cellulose compute as well.

34
00:02:03,870 --> 00:02:05,600
This is a new feature,
which they launched.

35
00:02:06,040 --> 00:02:12,630
And as I said, Databricks can be,
offered on any client, cloud, provider

36
00:02:12,630 --> 00:02:17,189
like AWS or Google Cloud or Azure.

37
00:02:17,780 --> 00:02:21,979
So right now, there's three offerings
are there and this Databricks will

38
00:02:22,009 --> 00:02:24,329
provision on top of it and you
will process the data for your

39
00:02:24,329 --> 00:02:26,579
computer analytical, combinations.

40
00:02:26,979 --> 00:02:30,979
And it offers a collaborative notebooks
where you can go and write your

41
00:02:31,019 --> 00:02:32,449
notebooks and you can deploy that.

42
00:02:32,520 --> 00:02:36,719
Whether it's for data engineering
or for data science or ML workflows.

43
00:02:37,259 --> 00:02:39,829
As I said, it's a multi cloud
support, like where you can

44
00:02:39,829 --> 00:02:42,619
have AWS Azure or Google Cloud.

45
00:02:43,189 --> 00:02:44,119
that's the key features.

46
00:02:44,379 --> 00:02:47,879
if you look at the bottom there is a
picture for where it has, Databricks,

47
00:02:47,909 --> 00:02:52,409
and it will do the governance with all
these, cloud providers, and it provides

48
00:02:52,439 --> 00:02:58,039
a business intelligence, data warehousing
solutions, AI, ML, data science solutions,

49
00:02:58,339 --> 00:03:01,860
ETL, and real time data processing
and, orchestration, within their tool.

50
00:03:02,380 --> 00:03:03,750
why we will use, Databricks?

51
00:03:03,985 --> 00:03:04,285
right?

52
00:03:04,285 --> 00:03:06,145
So that's a good point.

53
00:03:06,585 --> 00:03:10,645
one of the biggest advantage with
Databricks is like cost optimization,

54
00:03:11,085 --> 00:03:14,555
where you can run your workloads
using Databricks and you don't

55
00:03:14,555 --> 00:03:18,055
have to worry about provisioning
these clusters, how, where to get

56
00:03:18,055 --> 00:03:19,195
these resources and all of that.

57
00:03:19,225 --> 00:03:21,805
You simply focus on your
business use case and Databricks.

58
00:03:21,975 --> 00:03:25,685
We'll take care of orchestration
and provisioning of these resources.

59
00:03:26,645 --> 00:03:27,705
It's a high performance.

60
00:03:27,785 --> 00:03:31,785
So one of the thing is, like I said,
it's an optimized version of Spark.

61
00:03:31,785 --> 00:03:36,855
And it has their engine called Porton
engine, where it runs a SQL and Spark

62
00:03:36,855 --> 00:03:38,645
updates for particular use cases.

63
00:03:38,645 --> 00:03:43,545
Not all use cases are supported with
Porton, but that's really extensively

64
00:03:43,715 --> 00:03:48,575
a performance compared to General
Spark and it's written in C So it,

65
00:03:48,925 --> 00:03:50,705
it optimized the memory really good.

66
00:03:51,305 --> 00:03:54,445
Then, it's a collaboration friendly
where you will write your notebooks and

67
00:03:54,445 --> 00:03:58,635
you can share across engineers and it
can, in real time you can do, real time

68
00:03:58,675 --> 00:04:02,475
development and seamless integrations
with all these cloud providers.

69
00:04:02,575 --> 00:04:05,765
So that's on a high level, like what
Databricks is offering right now.

70
00:04:06,265 --> 00:04:10,555
Then, we look at, Databricks
optimization into like multiple layers.

71
00:04:10,625 --> 00:04:15,420
It's not like one simple, Point where
you can optimize there are multiple

72
00:04:15,430 --> 00:04:21,130
ways we have to do it So the first one
is like we need to review EBS usage.

73
00:04:21,210 --> 00:04:22,860
So what is EBS, right?

74
00:04:23,330 --> 00:04:29,020
So whenever you launch your Node or
cluster the data when it processed right

75
00:04:29,190 --> 00:04:33,830
the whenever it goes out of the memory to
start writing to the disk So most of the

76
00:04:33,850 --> 00:04:36,855
nodes comes with the internal disk itself.

77
00:04:37,125 --> 00:04:41,225
If it is not there, it'll
use the AWS EBS, storage.

78
00:04:41,835 --> 00:04:46,105
So most of the time it's a default
storage available on the nodes.

79
00:04:46,755 --> 00:04:50,015
So if you look at, disk storage
is used for shuffling, as I said,

80
00:04:50,445 --> 00:04:54,275
and checking your instance type,
allocate disk is very important.

81
00:04:54,625 --> 00:04:58,064
So when you use i3, 4x
large workers has 3.

82
00:04:58,065 --> 00:04:59,735
6 TB of local storage.

83
00:04:59,735 --> 00:05:00,765
So we don't have to use.

84
00:05:01,095 --> 00:05:06,295
EBS volumes if you are using inodes, but
still people go on provision EBS volumes

85
00:05:06,375 --> 00:05:08,405
where you're paying additional cost of it.

86
00:05:08,735 --> 00:05:13,425
So EBS cost for job is like storage
cost plus IO cost and snapshot

87
00:05:13,425 --> 00:05:14,815
cost and data transfer cost.

88
00:05:15,295 --> 00:05:16,795
Everything comes into EBS.

89
00:05:17,265 --> 00:05:22,545
So it might look very small initially,
but when you're learning a huge

90
00:05:22,545 --> 00:05:27,185
amount of jobs and we are paying in
millions, this one contributes a huge.

91
00:05:27,620 --> 00:05:30,800
And when you can tweak this one,
you can save up to 50 to 80% of

92
00:05:30,800 --> 00:05:34,700
your, savings, understanding,
auto scaling pitfalls, right?

93
00:05:35,090 --> 00:05:37,820
So saving up to 28% is, is possible.

94
00:05:38,060 --> 00:05:42,340
So basically like whenever
we have fluctuation in data

95
00:05:42,430 --> 00:05:43,690
and it's seasonal, right?

96
00:05:43,900 --> 00:05:45,280
We don't like how much data we'll get in.

97
00:05:45,280 --> 00:05:48,220
So normally what we do is like
we'll go and enable autoscaling,

98
00:05:48,720 --> 00:05:53,350
but whenever job goes on Autoscale,
whether it's a upscale or downscale,

99
00:05:53,590 --> 00:05:55,630
it keep on calling the config where.

100
00:05:56,515 --> 00:06:00,435
Keep the calling for config is
a cost related thing, right?

101
00:06:00,825 --> 00:06:04,415
So don't use this auto scaling
unless it is really required.

102
00:06:04,955 --> 00:06:08,595
If it is, if you know the history
of the job, keep it simple.

103
00:06:08,915 --> 00:06:11,305
Keep the, not dynamic
and static resources.

104
00:06:11,325 --> 00:06:13,575
That way you can save on the auto scaling.

105
00:06:14,305 --> 00:06:16,015
Reduce AWS config cost.

106
00:06:16,025 --> 00:06:17,935
This is like subsection of auto scaling.

107
00:06:17,935 --> 00:06:22,885
as I said, like previously, where whenever
you keep on calling this AWS config, From

108
00:06:22,885 --> 00:06:27,764
Databricks, it, it creates a lot of cost,
recurrently for upscale or downscale of

109
00:06:27,764 --> 00:06:32,664
your resources, whether it's EBS volumes
or increasing the, adding the nodes

110
00:06:32,744 --> 00:06:34,044
or reading the nodes, anything, right?

111
00:06:34,439 --> 00:06:37,979
it's always, uses the cost and
it'll, it's a bombard to the job.

112
00:06:38,249 --> 00:06:41,299
So it's always recommended to
use, right appropriate instance.

113
00:06:41,299 --> 00:06:42,219
That's the next point.

114
00:06:42,559 --> 00:06:46,669
So most, more appropriate workloads
from M node to I nodes, if it is

115
00:06:46,799 --> 00:06:50,509
like where you can get like internal
volume, where it'll help, with the

116
00:06:50,509 --> 00:06:54,089
EBS volume on top of it, you can
know what's the cost savings or cost.

117
00:06:54,589 --> 00:06:57,299
Breakdown for M node versus I node, right?

118
00:06:57,709 --> 00:07:00,279
So choosing the right
instance is the key here.

119
00:07:00,619 --> 00:07:03,199
we miss a lot of savings by
choosing the wrong instance.

120
00:07:03,229 --> 00:07:06,829
for example, M5, 4x versus I3, 4x large.

121
00:07:07,119 --> 00:07:10,549
both has it own, you need to understand
like why we are choosing this instance

122
00:07:10,559 --> 00:07:13,769
rather than simply blinding, and
going with the, recommendation.

123
00:07:13,769 --> 00:07:18,059
So we need to have like really good
understanding of choosing instance.

124
00:07:18,679 --> 00:07:20,449
The last one is spot versus on demand.

125
00:07:20,809 --> 00:07:23,339
most of the workflows, it depends
upon if you are running a higher

126
00:07:23,339 --> 00:07:25,399
SLA job, then you can run on demand.

127
00:07:25,709 --> 00:07:28,409
If you are having a
lower SLA job, bank on.

128
00:07:28,799 --> 00:07:32,649
A cheaper, spot instance where
you will go and bid for the

129
00:07:32,649 --> 00:07:33,589
instance and you'll get it.

130
00:07:33,609 --> 00:07:37,739
But the chances AWS can terminate
if they get a bigger bid is high,

131
00:07:37,739 --> 00:07:42,739
but still you have a lower as a job,
which can be resilient if you restart.

132
00:07:42,739 --> 00:07:44,949
And if you run one more time,
still you will save money.

133
00:07:45,209 --> 00:07:47,979
So this happens very rarely
in AWS instance where someone

134
00:07:47,979 --> 00:07:49,119
comes and grab your resources.

135
00:07:49,484 --> 00:07:51,574
But still you can save
a lot of money on that.

136
00:07:52,124 --> 00:07:55,834
so there are a few other Optimization
challenge things which we can do right

137
00:07:56,184 --> 00:07:59,864
so using the right number of shuffle
partitions So the key with any of

138
00:07:59,894 --> 00:08:04,394
your workloads particularly the data
workloads is like we should not have

139
00:08:04,754 --> 00:08:09,234
The shuffle and the amount of data
written to the disk and amount of data,

140
00:08:09,634 --> 00:08:12,114
shuffle or the IO should be very minimal.

141
00:08:12,604 --> 00:08:16,914
So we need to look at like,
when you're doing huge amount of

142
00:08:16,924 --> 00:08:21,484
aggregations, like group by joints
or reduced by key, the key should

143
00:08:21,484 --> 00:08:23,544
be distributed across all the nodes.

144
00:08:24,044 --> 00:08:27,274
The power of distributed computing
can be utilized to the fullest.

145
00:08:27,604 --> 00:08:30,704
So the partitions is very important.

146
00:08:30,714 --> 00:08:34,054
How many shuffles we can
do is very important.

147
00:08:34,344 --> 00:08:36,784
Most of the engineers know
about this one, but most of the

148
00:08:36,834 --> 00:08:38,234
time they overlook this one.

149
00:08:38,584 --> 00:08:42,434
And we need to look at the UI and see
like how much data is being spilled,

150
00:08:42,434 --> 00:08:45,354
how much data is being shuffled
over the network and all of that.

151
00:08:46,354 --> 00:08:48,654
Spark has a really good UI
to showcase all of that.

152
00:08:48,914 --> 00:08:51,444
So it's always recommended to
have two types of number of cores.

153
00:08:52,359 --> 00:08:54,779
That keep it up, keep that
as your shovel partition.

154
00:08:54,779 --> 00:08:59,019
That way it's like you want to distribute
across all the nodes and caching, right?

155
00:08:59,019 --> 00:09:02,699
Like people overly use caching,
even though it's not required.

156
00:09:02,759 --> 00:09:05,629
so Spark is a DAG where
it recollects everything.

157
00:09:05,629 --> 00:09:08,409
So if you want to cache it in
middle so that it'll read, it

158
00:09:08,409 --> 00:09:09,999
will not recollect the entire DAG.

159
00:09:10,414 --> 00:09:14,874
look at the, UI to understand like how
much activity is happening with, garbage

160
00:09:14,874 --> 00:09:18,744
collector, how much cache is required
and all of that, and use cache properly.

161
00:09:19,304 --> 00:09:24,054
And, duplicate is one of the
biggest problem where, you may see

162
00:09:24,094 --> 00:09:27,184
all the data going into one node,
or maybe the key is not unique.

163
00:09:27,494 --> 00:09:31,054
So there are multiple ways you can,
reduce a duplicate before you process

164
00:09:31,054 --> 00:09:34,024
it, get all the duplicates into one
data frame, process all remaining

165
00:09:34,394 --> 00:09:35,644
everything and just union it.

166
00:09:36,134 --> 00:09:38,064
There are like multiple
ways you can do it.

167
00:09:38,094 --> 00:09:41,444
One of the technique is called
salting, where you will take the

168
00:09:41,444 --> 00:09:43,834
key, add a unique value to it.

169
00:09:43,874 --> 00:09:47,084
That way you can make sure that
the key is distributed across all

170
00:09:47,094 --> 00:09:48,504
the nodes and it can process it.

171
00:09:48,684 --> 00:09:51,834
So this kind of, there are a lot
of, ways you can eliminate the

172
00:09:51,834 --> 00:09:55,604
duplicates and reduce the cost in
running these jobs for a longer time.

173
00:09:56,499 --> 00:10:00,419
And, the last one is establish a
robust, data life cycle and cost system.

174
00:10:00,869 --> 00:10:06,509
So different life, life cycle policies
on this, data sets and how much these

175
00:10:06,509 --> 00:10:07,919
jobs need to run and all of that.

176
00:10:08,199 --> 00:10:09,159
That's very important.

177
00:10:09,159 --> 00:10:11,469
And you need to keep
monitoring these jobs.

178
00:10:11,749 --> 00:10:14,249
So sometimes like we might think
okay, this might be using this

179
00:10:14,249 --> 00:10:16,979
much if it is having enable
with auto scaling, all of that.

180
00:10:17,269 --> 00:10:18,129
We don't like all this.

181
00:10:18,379 --> 00:10:20,769
small nitty gritties of what's
happening with the job breakdown.

182
00:10:21,159 --> 00:10:24,329
So we need to look at all of that and
keep a key and that and keep an alert

183
00:10:24,329 --> 00:10:27,849
on it If it crosses that threshold
hit alert and start looking at like

184
00:10:27,849 --> 00:10:29,329
why the job is performing like that.

185
00:10:29,829 --> 00:10:33,359
So let's now Dive into what is AWS EMR.

186
00:10:33,409 --> 00:10:39,209
So AWS EMR is a cloud based
Databricks processing offering from

187
00:10:39,210 --> 00:10:45,574
AWS where you can run Spark based
or Hive based jobs on EMR, right?

188
00:10:45,964 --> 00:10:49,114
it's equivalent to, like,
when Hadoop started.

189
00:10:49,114 --> 00:10:54,954
they released this EMR Elastic
MapReduce where you can launch your

190
00:10:55,024 --> 00:10:56,574
MapReduce jobs or Hive jobs on it.

191
00:10:57,049 --> 00:11:02,329
And it'll run on EC2 instance and
it evolved over the time and a lot

192
00:11:02,329 --> 00:11:06,179
of companies and a lot of teams use
this one for different purposes.

193
00:11:06,769 --> 00:11:09,229
So there are three flavors to, AWS EMR.

194
00:11:09,229 --> 00:11:11,779
I'll talk about the difference in a
minute, but I just want to explain like

195
00:11:11,829 --> 00:11:16,509
what are the three flavors we have or
three offerings we have on, AWS EMR.

196
00:11:16,589 --> 00:11:19,889
One is like the legacy EMR on EC2.

197
00:11:19,909 --> 00:11:24,249
That's when you have a large,
large scale, workloads and you

198
00:11:24,249 --> 00:11:25,569
need to process all of that.

199
00:11:25,579 --> 00:11:29,589
You will use, EC2s, but like the
cluster management is like very tedious,

200
00:11:29,909 --> 00:11:33,029
provisioning, scaling, and monitoring
is like very hard if you want to,

201
00:11:33,039 --> 00:11:34,999
if you're doing with, EMR on, EC2.

202
00:11:35,994 --> 00:11:41,689
Then the second offering is, EMR on
EKS, where you'll launch your EKS

203
00:11:41,789 --> 00:11:46,934
on EMR, on EKS, like electric, cu
Kubernetes services, where you'll

204
00:11:46,934 --> 00:11:48,554
run all these jobs over there.

205
00:11:48,834 --> 00:11:51,624
the problem with this one is
like it's more complex to set

206
00:11:51,624 --> 00:11:53,094
up the entire, infrastructure.

207
00:11:53,444 --> 00:11:57,674
So that is a problem, but like the
scaling up and managing the workflows

208
00:11:57,734 --> 00:11:59,359
and running the workflows is like very.

209
00:12:00,069 --> 00:12:01,109
you can do it at a scale.

210
00:12:01,699 --> 00:12:03,569
The third one is EMR Ferola.

211
00:12:03,569 --> 00:12:06,199
This is a new offering which started
hitting the market from last couple

212
00:12:06,199 --> 00:12:10,069
of years where you can do on demand,
pay for the usage processing.

213
00:12:10,309 --> 00:12:13,529
The only problem with, several CM
R is you'll not have much control.

214
00:12:13,529 --> 00:12:16,769
if you want to tweak something or if
you want to change some configuration

215
00:12:17,009 --> 00:12:19,229
is little td little, complex.

216
00:12:19,469 --> 00:12:22,499
So apart from that, serverless,
CMR is a game changer as of now.

217
00:12:22,999 --> 00:12:25,289
as I said, if you look at,
the differences, right?

218
00:12:25,289 --> 00:12:26,879
The coastal, the cluster control.

219
00:12:27,394 --> 00:12:33,864
On EMR on EC2 is little high, then
EKS is medium, then serverless

220
00:12:33,914 --> 00:12:37,024
is like pretty much low, but we
don't have much control on that.

221
00:12:37,404 --> 00:12:43,124
Scaling wise, manual, you can automate on
EMR, EKS you can automate and serverless

222
00:12:43,384 --> 00:12:45,674
EMR is like completely fully automated.

223
00:12:46,294 --> 00:12:52,354
The best for large scale UTL, for EMR
workloads, AML container kind of jobs.

224
00:12:52,669 --> 00:12:57,189
Ad hoc or busty jobs where you'll
use, serverless CMR cost efficiency.

225
00:12:57,239 --> 00:13:01,789
if you look, if you are going for, this
is where the key cost savings, you can

226
00:13:01,789 --> 00:13:06,479
see most of the workloads, which we
have migrated from server EMR to, server

227
00:13:06,484 --> 00:13:11,829
serverless, sorry, EEMR on E, EMR, uneasy
to do so as EMR, because that's where

228
00:13:11,829 --> 00:13:13,214
we have seen a lot of cost savings.

229
00:13:14,034 --> 00:13:16,534
And, you'll pay for what you use, right?

230
00:13:16,894 --> 00:13:18,644
That's the same case
for other two as well.

231
00:13:18,684 --> 00:13:21,034
But like in serverless, you
don't have to worry about it.

232
00:13:21,034 --> 00:13:23,704
It's pretty much following the
model of Databricks where you

233
00:13:23,704 --> 00:13:25,684
don't have to worry about like
the provisioning and all of that.

234
00:13:26,064 --> 00:13:28,754
You just say what you want and
focus on your business use case

235
00:13:28,814 --> 00:13:30,964
and AWS will take care of it.

236
00:13:31,444 --> 00:13:33,284
As I said, ease of use, obviously.

237
00:13:33,789 --> 00:13:38,739
As always, EMR wins the game, but, EKS is
more complex, but it has if you read the

238
00:13:38,739 --> 00:13:43,509
provision it's to wonder, and, EMR on EC2
is like a traditional thing where it's

239
00:13:43,529 --> 00:13:45,679
like moderate versus hard ease of use.

240
00:13:46,189 --> 00:13:47,919
we look at how we can save.

241
00:13:48,319 --> 00:13:51,239
On, AWS EMR cost optimization.

242
00:13:51,519 --> 00:13:54,849
So the right size cluster based
upon the workload, patterns, right?

243
00:13:54,859 --> 00:13:56,099
So that's the same kind of thing.

244
00:13:56,099 --> 00:13:59,009
What we were talked previously
with, Databricks as well.

245
00:13:59,359 --> 00:14:02,944
Like you need to choose the
right, worker type, and like node.

246
00:14:03,414 --> 00:14:05,644
To provision your jobs.

247
00:14:05,694 --> 00:14:10,754
And one of the biggest thing is like the
Graviton based instance, reduced by 20%.

248
00:14:10,774 --> 00:14:11,954
That's a game changer as well.

249
00:14:11,954 --> 00:14:15,244
Because this Graviton based is a kind
of chip, which is built by Amazon.

250
00:14:15,624 --> 00:14:19,504
And we, they don't have the property
to pay anything on Intel based chips.

251
00:14:19,934 --> 00:14:25,324
that's a game changer for AWS where the
Graviton, runs much faster and they don't

252
00:14:25,324 --> 00:14:26,624
have to pay anything on top of that.

253
00:14:26,624 --> 00:14:29,334
And they give the savings
to the, customers.

254
00:14:29,834 --> 00:14:32,064
Dynamic autoscaling for
efficient resource allocation.

255
00:14:32,064 --> 00:14:35,134
As I said, the similar kind of things
what we have seen with Databricks, like

256
00:14:35,134 --> 00:14:40,524
we should be very careful with autoscaling
where your jobs are being processed.

257
00:14:40,524 --> 00:14:43,434
So we should optimistically
use the autoscaling.

258
00:14:43,754 --> 00:14:44,544
We don't have to do it.

259
00:14:44,904 --> 00:14:48,144
Keep it normal, keep it static, and
don't have to enable autoscaling.

260
00:14:48,644 --> 00:14:52,094
The third one is, optimizing spark
performance, as I said previously,

261
00:14:52,534 --> 00:14:56,404
shuffle is very important where you
will not do a lot of IO over the

262
00:14:56,404 --> 00:15:00,784
network or will not write any dis
data to the desk and where you don't

263
00:15:00,784 --> 00:15:04,984
have to read anything, that, that
kills the, importance of Apache Spark.

264
00:15:05,304 --> 00:15:06,894
So look at that one.

265
00:15:07,569 --> 00:15:13,129
Dynamic allocation of Spark executor,
ensuring optimal usage per job, need to

266
00:15:13,129 --> 00:15:17,889
be implemented and parallelism settings
need to be optimized so that your,

267
00:15:18,389 --> 00:15:21,939
Then, as I said, serverless
EMR was a CKS compute.

268
00:15:22,469 --> 00:15:26,259
we, what we have seen is like, if
you have a, based upon the job type,

269
00:15:26,579 --> 00:15:31,329
if you have a, job type, which is
like lower in SLA and don't need,

270
00:15:31,469 --> 00:15:33,979
it's fine if it fails and restarts.

271
00:15:34,259 --> 00:15:38,099
And, based upon that kind of
thing, you can select what

272
00:15:38,099 --> 00:15:40,029
kind of, EMR you can choose.

273
00:15:40,294 --> 00:15:47,314
But like we have seen serverless EMR
saves a lot when you're tweaking and

274
00:15:47,474 --> 00:15:50,194
running on it with Graviton chips.

275
00:15:50,574 --> 00:15:57,174
So we recommend trying serverless
EMR in that instance and data

276
00:15:57,174 --> 00:15:59,324
storage and access optimization.

277
00:15:59,334 --> 00:16:02,904
Like S3, when you read and write
from S3, there is a cost to it.

278
00:16:03,364 --> 00:16:06,714
And the asset, like how
Delta is offered, AWS.

279
00:16:07,214 --> 00:16:09,114
It offers who do your eyes work for?

280
00:16:09,194 --> 00:16:11,144
Asset, compliant, datasets.

281
00:16:11,954 --> 00:16:16,324
optimize that to the fullest because like
whenever we have the asset file system,

282
00:16:16,334 --> 00:16:20,144
like the files keep on growing whenever
there's a, transaction happened on it.

283
00:16:20,144 --> 00:16:21,174
So we need to vacuum it.

284
00:16:21,174 --> 00:16:22,784
We need to clean it and
we need to keep it like.

285
00:16:23,124 --> 00:16:26,484
Certain versions so that it will
not create huge amount of data.

286
00:16:26,934 --> 00:16:33,614
So that's again a game changer there
Adjusting the retentions on this s3

287
00:16:33,614 --> 00:16:39,634
objects not just leaving it alone Will
do a huge cost savings then automating

288
00:16:39,634 --> 00:16:41,114
cluster shutdowns and scheduling.

289
00:16:41,124 --> 00:16:46,359
We have seen this huge this issue
with AWS emr particularly Where the

290
00:16:46,539 --> 00:16:50,199
cluster will be up and it will never
be shut down or it'll be kept on up.

291
00:16:50,649 --> 00:16:53,079
We keep on running even though
there is no workload running.

292
00:16:53,109 --> 00:16:57,149
So we should be keep on, as I said,
like k alerts on all these workloads.

293
00:16:57,149 --> 00:17:00,479
If it crossing certain threshold,
it should be alert and we should be

294
00:17:00,749 --> 00:17:04,729
debugged and see what, what's really
going on with the SLA and what is

295
00:17:04,729 --> 00:17:06,729
going on with the, TCO reports.

296
00:17:06,969 --> 00:17:09,459
So we need to look at that to
identify what's going on there.

297
00:17:09,959 --> 00:17:12,139
So that being said, hope the talk is.

298
00:17:12,864 --> 00:17:16,804
giving some information of like how
you can optimize your cloud workloads.

299
00:17:16,944 --> 00:17:19,864
And, if you have any
questions shoot me and,

