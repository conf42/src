1
00:00:00,500 --> 00:00:03,700
Speaker 44: Hi, I'm, and I want
to talk to you about something

2
00:00:03,700 --> 00:00:05,230
that might make you uncomfortable.

3
00:00:05,730 --> 00:00:09,630
Those screen check marks we all love
to see in our CICD pipelines where

4
00:00:10,020 --> 00:00:15,719
all of the tests are passing views are
successful, everything looks perfect,

5
00:00:16,500 --> 00:00:20,010
but here's the truth, sometimes
everything can look green while

6
00:00:20,010 --> 00:00:21,930
serious problems are hiding underneath.

7
00:00:22,430 --> 00:00:26,780
I've maintained and contributed to several
open source repositories, both small and

8
00:00:26,780 --> 00:00:30,950
large, and I've seen what happens when
teams put too much trust in automation

9
00:00:31,070 --> 00:00:32,930
and not enough in human judgment.

10
00:00:33,620 --> 00:00:37,310
Today I'm going to show you
what CICD can't catch, and more

11
00:00:37,310 --> 00:00:40,010
importantly, what we can do about it.

12
00:00:40,510 --> 00:00:44,320
Now I'd like to start with a
story from March 29th, 2024.

13
00:00:45,100 --> 00:00:49,480
Andres Fre, a Microsoft engineer, was
doing routine performance testing.

14
00:00:50,425 --> 00:00:53,665
The SSH into a WN system
and noticed something odd.

15
00:00:54,625 --> 00:00:57,895
Authentication was taking a few
hundred milliseconds longer than

16
00:00:57,895 --> 00:01:01,405
it should, and CPU usage was
spiking during the handshake.

17
00:01:02,035 --> 00:01:06,775
Now that might not sound like much when
something that should nearly be nearly

18
00:01:06,775 --> 00:01:09,145
in San suddenly fail off experience.

19
00:01:09,145 --> 00:01:10,705
Engineers need to pay attention.

20
00:01:11,545 --> 00:01:15,240
When he investigated, he found
that the test were passing.

21
00:01:15,970 --> 00:01:19,480
CICD pipeline was screen, and the
code had gone through normal review.

22
00:01:20,020 --> 00:01:22,870
So from the automation's point
of view, everything looked fine,

23
00:01:23,230 --> 00:01:25,080
but something was very wrong.

24
00:01:25,830 --> 00:01:30,330
That disconnects between what our
pipelines tell us and what's actually

25
00:01:30,330 --> 00:01:32,520
happening is what this talk is about.

26
00:01:33,020 --> 00:01:36,705
But before we go further, I'd like to
establish why I'm talking about this.

27
00:01:37,565 --> 00:01:38,425
My name is Soda.

28
00:01:39,005 --> 00:01:42,345
I'm a software engineer and
program organizer at Outreachy.

29
00:01:42,845 --> 00:01:47,105
And my role has involved coordinating
code reviews across multiple

30
00:01:47,105 --> 00:01:51,635
open source projects, some with
hundreds of contributors and

31
00:01:52,265 --> 00:01:54,095
lots of pull requests to review.

32
00:01:54,725 --> 00:01:57,095
And at that scale, you
start to see patterns.

33
00:01:57,395 --> 00:02:00,275
You see your automation works
brilliantly, and you see where

34
00:02:00,275 --> 00:02:01,685
it completely falls apart.

35
00:02:02,225 --> 00:02:04,595
You watch trusted contributors emerge.

36
00:02:04,895 --> 00:02:07,985
Reviewers get overwhelmed and burnt out.

37
00:02:08,345 --> 00:02:10,955
And green marks creates a
sense of false confidence.

38
00:02:11,455 --> 00:02:13,885
That experience is what I'm
bringing to the talk today.

39
00:02:14,385 --> 00:02:16,845
But I'd like to frame
the talk in three parts.

40
00:02:17,115 --> 00:02:21,345
The why, what, and how
Now, why does this matter?

41
00:02:21,945 --> 00:02:25,275
This matters because CICD
can show green pipelines.

42
00:02:25,575 --> 00:02:30,195
While there are fragile assumptions,
risky changes, and subtle regressions,

43
00:02:30,195 --> 00:02:31,965
that can still slip into production.

44
00:02:32,445 --> 00:02:34,515
So the automation doesn't
tell the whole story.

45
00:02:34,965 --> 00:02:35,985
Now what's the problem?

46
00:02:36,705 --> 00:02:41,415
Automation forces the rules we defined,
but it can reason about intent.

47
00:02:41,715 --> 00:02:45,735
It doesn't understand context or
pick up on social dynamics or notice

48
00:02:45,735 --> 00:02:47,235
when reviewers are over loaded.

49
00:02:47,805 --> 00:02:52,035
These human factors become
critical as systems and sim scale.

50
00:02:52,755 --> 00:02:54,375
Now the question is how do we fix it?

51
00:02:55,185 --> 00:02:58,275
We are going to explore parent
automation with female safeguards,

52
00:02:58,605 --> 00:03:01,365
structured reviews, risk checklists.

53
00:03:01,695 --> 00:03:05,175
Stage rollout and a culture
that rewards slowing down when

54
00:03:05,175 --> 00:03:06,555
something feels uncertain.

55
00:03:07,335 --> 00:03:08,685
Now, let me clear this up front.

56
00:03:09,105 --> 00:03:11,085
This is not an anti automation talk.

57
00:03:11,355 --> 00:03:12,405
I love CICD.

58
00:03:12,675 --> 00:03:15,855
I know how powerful and necessary
it's, but at the same time,

59
00:03:15,855 --> 00:03:17,535
it's not sufficient on its own.

60
00:03:17,835 --> 00:03:19,275
And that's why we are here to explore.

61
00:03:19,775 --> 00:03:21,605
Now, here's a scenario you've
probably lived through.

62
00:03:22,265 --> 00:03:23,225
The tests are green.

63
00:03:23,494 --> 00:03:27,035
Your bids are successful, your
deployments complete without errors.

64
00:03:27,244 --> 00:03:30,250
Everything your automation can
measure says you are good to go.

65
00:03:31,174 --> 00:03:33,185
And then your users
start to report issues.

66
00:03:33,545 --> 00:03:35,584
Now, this is the moment that
makes us question everything.

67
00:03:35,584 --> 00:03:36,605
We followed the process.

68
00:03:36,935 --> 00:03:40,744
We did everything right according to our
tools, but something still went wrong.

69
00:03:41,434 --> 00:03:46,144
So this gap between automation,
confidence and production reality,

70
00:03:46,385 --> 00:03:48,035
that's what we need to understand.

71
00:03:48,535 --> 00:03:52,675
So let's go back to that story from March
and actually understand what happened.

72
00:03:53,410 --> 00:03:55,780
This wasn't just a performance bug.

73
00:03:56,260 --> 00:04:00,130
The exit YouTube's backdoor incident
has been widely described as one of

74
00:04:00,130 --> 00:04:04,000
the most significant and sophisticated
supply chain attacks that we've

75
00:04:04,000 --> 00:04:08,110
seen publicly discussed, and it
wasn't found by a security scanner.

76
00:04:08,620 --> 00:04:13,015
It was found during routine performance
testing because it's small anomaly

77
00:04:13,165 --> 00:04:15,190
triggered a deeper investigation.

78
00:04:15,850 --> 00:04:17,170
Let's take a look at the timeline.

79
00:04:17,665 --> 00:04:23,305
In 2021, someone who called themselves,
Han appears in the ex UTS project.

80
00:04:23,575 --> 00:04:26,695
They make helpful contributions,
nothing suspicious.

81
00:04:26,935 --> 00:04:28,765
Just another contributor trying to help.

82
00:04:29,605 --> 00:04:36,595
By 2022 and 2023, after a year of
consistent quality work, Han gets comp

83
00:04:36,595 --> 00:04:38,665
coming access and becomes a maintainer.

84
00:04:39,145 --> 00:04:41,905
This makes perfect sense because
they've proven themselves

85
00:04:41,905 --> 00:04:43,255
through legitimate contributions.

86
00:04:44,200 --> 00:04:48,550
Then in 2024, the back is
discovered completely by accident.

87
00:04:49,150 --> 00:04:51,190
Now, let take a look
at what's this bypass.

88
00:04:51,730 --> 00:04:53,170
All tests passed.

89
00:04:53,440 --> 00:04:54,880
Code was reviewed.

90
00:04:55,120 --> 00:04:56,320
CICD was greened.

91
00:04:56,820 --> 00:05:00,330
And so the question is
what's actually filled here?

92
00:05:00,869 --> 00:05:03,719
It wasn't the test, it
wasn't the automation.

93
00:05:04,229 --> 00:05:07,200
What field was trust management at scale?

94
00:05:07,739 --> 00:05:10,895
This was a social engineering attack
that understood something fundamental.

95
00:05:11,395 --> 00:05:15,625
Automation checks code quality, but
humans are supposed to check intent.

96
00:05:16,255 --> 00:05:20,365
The attacker knew that if you build
trust over years, if you become part

97
00:05:20,365 --> 00:05:24,775
of a team, eventually people will stop
scrutinizing your changes as carefully

98
00:05:25,104 --> 00:05:26,604
because you've gained their trust.

99
00:05:27,234 --> 00:05:30,925
This is the blueprint for
attacking software at scale.

100
00:05:31,425 --> 00:05:34,335
Now, lemme break down what's
actually enabled this attack, because

101
00:05:34,335 --> 00:05:35,240
it's not what you might think.

102
00:05:36,135 --> 00:05:39,585
First, the maintainer was
overloaded and stretched thing.

103
00:05:40,125 --> 00:05:41,805
Now, this is a common open source problem.

104
00:05:42,135 --> 00:05:46,185
It's one maintainer and hundreds
of contributors, thousands of lines

105
00:05:46,395 --> 00:05:50,025
of code to review, and eventually
maintainers get burnt out.

106
00:05:50,745 --> 00:05:53,895
Second, subtle changes
slip through that time.

107
00:05:54,315 --> 00:05:55,690
It wasn't one obvious factor.

108
00:05:55,910 --> 00:05:59,210
It was incremental changes that
individually looked harmless.

109
00:05:59,980 --> 00:06:00,330
Third.

110
00:06:01,185 --> 00:06:06,555
A long, trusted contributor had
gained significant influence, years of

111
00:06:06,555 --> 00:06:11,565
legitimate contributions, had built real
trust, and that trust was weaponized.

112
00:06:12,075 --> 00:06:15,645
And finally, which is the
critical point, automation did

113
00:06:15,645 --> 00:06:17,594
not see the social dynamics.

114
00:06:17,805 --> 00:06:22,034
It couldn't detect that trust was being
systematically built and then exploited.

115
00:06:22,395 --> 00:06:25,935
He couldn't notice that review
quality was degrading under pressure.

116
00:06:26,534 --> 00:06:27,630
So these are human problems.

117
00:06:28,590 --> 00:06:32,849
Cultural problems, organizational
problems, and no amount of automated

118
00:06:32,849 --> 00:06:34,830
testing catches these issues.

119
00:06:35,330 --> 00:06:37,010
So why do we fall into this trap?

120
00:06:37,700 --> 00:06:41,150
Why do green check marks give
us such false confidence?

121
00:06:41,420 --> 00:06:42,560
Therefore, main reasons.

122
00:06:43,160 --> 00:06:44,630
First, green check.

123
00:06:45,080 --> 00:06:46,670
Green checks feel like certainty.

124
00:06:47,030 --> 00:06:50,510
There's that visual feedback that
is psychologically satisfying.

125
00:06:50,870 --> 00:06:52,250
It gives us confidence.

126
00:06:52,790 --> 00:06:54,110
Sometimes modern is warranted.

127
00:06:54,610 --> 00:06:57,850
Second team scale faster
than review capacity.

128
00:06:58,180 --> 00:07:02,770
You can hire 10 engineers and they
start Monday, but building 10 experience

129
00:07:02,770 --> 00:07:07,450
reviewers that takes years review
capacity, lags behind team growth.

130
00:07:07,450 --> 00:07:09,790
So we use CI as a approach.

131
00:07:10,330 --> 00:07:13,360
Third deadlines push speed over caution.

132
00:07:14,230 --> 00:07:18,040
When the pressure is on CI person
becomes the only approval gates

133
00:07:18,040 --> 00:07:19,390
that really matters, it's green.

134
00:07:19,570 --> 00:07:21,790
So we ship it and that becomes the reflex.

135
00:07:22,345 --> 00:07:27,565
Fourth, we confus necessary with
sufficient CI passing is a necessary

136
00:07:27,565 --> 00:07:31,705
condition for shipping code, but we treat
it like it's a sufficient condition.

137
00:07:31,885 --> 00:07:35,035
It's not, and this is a logic
error that we make constantly.

138
00:07:35,535 --> 00:07:39,495
If you've ever approved a pr,
mainly because CI will scream and

139
00:07:39,495 --> 00:07:42,790
you're rushing, you'll be able to
understand this problems really well.

140
00:07:43,290 --> 00:07:46,740
But before we go, define into the
problems, let's be precise about

141
00:07:46,740 --> 00:07:50,070
what CICD actually does, because
this framing is very important.

142
00:07:50,730 --> 00:07:52,770
CICD answers one question really well.

143
00:07:53,310 --> 00:07:56,370
Does this code meet the rules we defined?

144
00:07:56,670 --> 00:07:57,750
Does it compile?

145
00:07:58,200 --> 00:08:02,760
Does the pass our test, follow our
style guide, satisfy our LinkedIn rules?

146
00:08:03,030 --> 00:08:05,520
CIC is brilliant at
answering those questions.

147
00:08:05,520 --> 00:08:10,830
It's deterministic, consistent, and
fast, but here's what it doesn't answer.

148
00:08:11,400 --> 00:08:14,010
Is this change safe in the real world?

149
00:08:14,280 --> 00:08:20,010
That's a very different question from
meeting from the question about meeting.

150
00:08:20,010 --> 00:08:25,170
The rules that have been defined requires
judgments, context and understanding

151
00:08:25,170 --> 00:08:28,620
what goes beyond the understanding
that goes beyond what we cannot admit.

152
00:08:29,430 --> 00:08:32,370
So we need to stop treating
these as the same question.

153
00:08:32,870 --> 00:08:34,160
Now lemme be absolutely clear.

154
00:08:34,700 --> 00:08:35,810
And repeat.

155
00:08:35,810 --> 00:08:36,170
Again.

156
00:08:36,260 --> 00:08:37,250
I love CICD.

157
00:08:37,250 --> 00:08:39,530
I think it's one of the best things
that has happened to software

158
00:08:39,530 --> 00:08:43,910
engineering in the last 20 years,
because look at what it gives us.

159
00:08:44,300 --> 00:08:49,130
Repeatable, reliable, build, same
input, same outputs every single time.

160
00:08:49,820 --> 00:08:54,260
Consistent checks and LinkedIn style
enforcement and basic quality checks

161
00:08:54,260 --> 00:08:59,180
are all automatic automated testing,
progression prevention at scale.

162
00:08:59,570 --> 00:09:05,090
This alone has saved countless hours
and prevented countless books, faster

163
00:09:05,090 --> 00:09:09,410
Deployments we can ship multiple
times a day instead of once a quarter.

164
00:09:09,830 --> 00:09:11,960
This is transformative.

165
00:09:12,710 --> 00:09:14,090
Reduce human error.

166
00:09:14,420 --> 00:09:19,370
No more forgetting manual steps
or skipping items on deployments.

167
00:09:19,370 --> 00:09:23,660
Checklists, this is all
revolutionary and because of

168
00:09:23,660 --> 00:09:25,490
CICD that we are able to do this.

169
00:09:26,105 --> 00:09:28,115
So CICD is very necessary.

170
00:09:28,115 --> 00:09:30,185
I cannot begin to stress that enough.

171
00:09:30,695 --> 00:09:35,045
But necessary doesn't mean sufficience,
and that's the key distinction

172
00:09:35,045 --> 00:09:36,605
that we need to internalize.

173
00:09:37,105 --> 00:09:40,195
Now, let me show you what CICD
fundamentally cannot catch.

174
00:09:40,915 --> 00:09:44,785
Not because it's poorly configured,
but because these things are outside.

175
00:09:44,785 --> 00:09:46,315
Its scope by design.

176
00:09:47,065 --> 00:09:49,375
Number one, social engineering.

177
00:09:49,930 --> 00:09:52,600
A trusted contributor changes employers.

178
00:09:52,870 --> 00:09:56,500
Their priorities and their motivations
have shifted, but their trust level in

179
00:09:56,500 --> 00:09:58,420
your repository stays exactly the same.

180
00:09:58,840 --> 00:10:00,670
CICD can detect this.

181
00:10:01,270 --> 00:10:04,240
Number two, subtle
performance regressions.

182
00:10:04,570 --> 00:10:07,420
Your query works perfectly
with clean test data.

183
00:10:07,840 --> 00:10:11,290
When production with millions of
rules, it does a table scan that

184
00:10:11,290 --> 00:10:16,720
crushes your database test pass,
or production brand number three.

185
00:10:17,305 --> 00:10:19,585
Integration behavior across system.

186
00:10:19,975 --> 00:10:22,105
Your service passes all its tests.

187
00:10:22,405 --> 00:10:26,635
It works great in isolation, but
in production, it causes timeouts

188
00:10:26,635 --> 00:10:28,345
in three downstream dependencies.

189
00:10:28,345 --> 00:10:34,045
Your test environment doesn't run about
number four, UX and workflow mismatches.

190
00:10:34,285 --> 00:10:35,335
The feature works.

191
00:10:35,485 --> 00:10:39,685
It does exactly what expect said, but
it completely breaks the user's mental

192
00:10:39,685 --> 00:10:41,665
model of how the system should work.

193
00:10:42,175 --> 00:10:45,520
Users are confused and frustrated,
but all of the tests are passing.

194
00:10:46,020 --> 00:10:48,810
Number five, risky dependency changes.

195
00:10:49,050 --> 00:10:51,420
You upgrade a library,
the upgrade is fine.

196
00:10:51,720 --> 00:10:55,590
It brings in new transited
dependencies with non vulnerabilities

197
00:10:55,590 --> 00:10:59,100
that your scanner miss because it
only checks direct dependencies.

198
00:10:59,790 --> 00:11:03,090
Number six, misconfigurations
that look harmless.

199
00:11:03,480 --> 00:11:05,010
You change one environment's very.

200
00:11:05,595 --> 00:11:06,705
This is completely fine.

201
00:11:06,705 --> 00:11:10,575
In staging, in production, under
real load, it causes memory

202
00:11:10,845 --> 00:11:12,285
leak takes hours to surface.

203
00:11:12,885 --> 00:11:17,625
Every single one of these is a predictable
systemic gap in what automation can

204
00:11:17,625 --> 00:11:19,965
detect, and these are not edge cases.

205
00:11:19,995 --> 00:11:22,005
These happen constantly.

206
00:11:22,505 --> 00:11:27,095
Now let me show you something that
explains why the XE attack worked and why

207
00:11:27,095 --> 00:11:29,195
these problems get worse as projects grow.

208
00:11:30,050 --> 00:11:32,780
Trust doesn't scale linearly.

209
00:11:33,170 --> 00:11:36,890
It breaks up predictable
points at five contributors.

210
00:11:36,890 --> 00:11:38,720
Personal trust works perfectly.

211
00:11:39,080 --> 00:11:42,080
You know everyone, you understand
their code style, their

212
00:11:42,080 --> 00:11:44,030
judgments, their motivations.

213
00:11:44,210 --> 00:11:47,840
Review is straightforward because
you have context for everything.

214
00:11:48,500 --> 00:11:51,320
At PIP c contributors,
people are semi known.

215
00:11:51,650 --> 00:11:54,355
You recognize the regulars, but
there are people you've never met.

216
00:11:55,280 --> 00:11:55,940
Friction starts.

217
00:11:55,940 --> 00:11:56,480
Okay.

218
00:11:56,780 --> 00:11:59,630
Review takes longer because
automatic trust is gone.

219
00:12:00,200 --> 00:12:03,890
At 500 contributors, your trust
model is completely broken.

220
00:12:04,280 --> 00:12:06,050
Most prayers come from strangers.

221
00:12:06,050 --> 00:12:09,380
You have no idea about their
motivations, background or skill

222
00:12:09,380 --> 00:12:13,400
level, but you still need to
review and decide whether to merge.

223
00:12:14,180 --> 00:12:16,100
This is where the exit ER was.

224
00:12:16,310 --> 00:12:20,180
They were overwhelmed dealing with
hundreds of contributors burning outs.

225
00:12:20,570 --> 00:12:23,420
That's when appeared with
the years of legitimate

226
00:12:23,420 --> 00:12:25,040
contributions and offered to help.

227
00:12:25,880 --> 00:12:27,140
So here's the paradox.

228
00:12:27,620 --> 00:12:32,540
As your project succeeds and grows the
trust model that enabled that success

229
00:12:32,540 --> 00:12:34,580
becomes your biggest vulnerability.

230
00:12:35,510 --> 00:12:38,540
So why do these problems get
worse over time instead of better?

231
00:12:39,260 --> 00:12:42,860
First, more contributors
equals more assumptions.

232
00:12:43,670 --> 00:12:46,910
Every new person brings
different standards, background

233
00:12:46,910 --> 00:12:48,920
knowledge, and risk tolerance.

234
00:12:49,340 --> 00:12:52,700
Implicit understands in stone
transfer, they don't scale.

235
00:12:53,690 --> 00:12:57,020
Second, automation
hides fragile processes.

236
00:12:57,410 --> 00:13:01,370
When CI is green, it creates false
confidence that everything is fine.

237
00:13:01,880 --> 00:13:06,920
Problems in your process, culture
and trust management become invisible

238
00:13:07,130 --> 00:13:08,780
because your automation is passing.

239
00:13:09,290 --> 00:13:12,620
So green check marks effectively
hide systemic dysfunction.

240
00:13:13,400 --> 00:13:16,310
Third review becomes robust stamping.

241
00:13:16,910 --> 00:13:17,780
Robust stamping.

242
00:13:18,230 --> 00:13:22,850
When reviewers are overloaded with ETPs
in the queue, review becomes a checkbox.

243
00:13:23,720 --> 00:13:24,560
CI passes.

244
00:13:24,740 --> 00:13:26,570
CI Pass becomes the only criteria.

245
00:13:26,840 --> 00:13:29,240
So you're not really reviewing
anymore, you're just making

246
00:13:29,240 --> 00:13:30,440
the queue number go down.

247
00:13:31,250 --> 00:13:34,280
Fourth, trust grows
faster than oversights.

248
00:13:34,580 --> 00:13:38,750
We grant access based on velocity of
contribution as not the depth of review.

249
00:13:39,230 --> 00:13:43,190
So someone makes 20 small PR that
look fine, do they get me rights?

250
00:13:43,805 --> 00:13:46,595
Did anyone actually audit
those changes deeply?

251
00:13:46,865 --> 00:13:47,465
Probably not.

252
00:13:48,035 --> 00:13:50,135
So these aren't individual failures.

253
00:13:50,135 --> 00:13:54,455
These are systemic dynamics that
emerge predictably as teams grow.

254
00:13:54,955 --> 00:13:57,145
Now let's talk about the
organizational pressures that

255
00:13:57,145 --> 00:13:59,455
make all of this worse pressure.

256
00:13:59,455 --> 00:14:02,925
What review cues are a
hundred prs are waiting.

257
00:14:03,435 --> 00:14:04,305
They are more coming.

258
00:14:04,305 --> 00:14:06,915
Daily reviewers become the bottleneck.

259
00:14:07,275 --> 00:14:09,735
Complaints starts about slow reviews.

260
00:14:10,095 --> 00:14:12,345
Quality suffers under volume.

261
00:14:13,185 --> 00:14:16,575
Pressure to approvals happen
under that time pressure.

262
00:14:16,875 --> 00:14:18,195
The deadline is tomorrow.

263
00:14:18,525 --> 00:14:20,715
The project manager is asking for updates.

264
00:14:20,715 --> 00:14:23,985
The CEO mentioned this feature to
the board, so he start to approve.

265
00:14:23,985 --> 00:14:28,155
Thankfully, understanding trust
in the test, caught any issues.

266
00:14:28,695 --> 00:14:30,300
Pressure three, just ship.

267
00:14:30,300 --> 00:14:31,300
It becomes a norm.

268
00:14:31,990 --> 00:14:33,820
Speed becomes a dominance metric.

269
00:14:34,590 --> 00:14:40,410
Velocity deployment frequency, cycle
time, these get measured and rewarded.

270
00:14:40,740 --> 00:14:45,180
Caution is not something that appears on
the dashboard, so it stops being valued.

271
00:14:46,020 --> 00:14:48,840
Pressure four, maintenance
becomes reactive.

272
00:14:48,870 --> 00:14:50,760
All energy goes to firefighting.

273
00:14:51,030 --> 00:14:54,750
There's no time for prevention,
process improvement or learning.

274
00:14:55,020 --> 00:14:59,220
You are always in crisis mode,
cutting corners and skipping steps.

275
00:14:59,730 --> 00:15:01,470
These pressures are universal.

276
00:15:01,830 --> 00:15:04,920
So the question now is, do
your safeguards still work?

277
00:15:05,190 --> 00:15:08,070
Despite these pressures, what
are the first thing that gets

278
00:15:08,070 --> 00:15:10,410
sacrificed when pressure increases?

279
00:15:10,910 --> 00:15:14,990
So let me show you specific processes
that break under pressure First

280
00:15:15,260 --> 00:15:17,495
single reviewers for critical code.

281
00:15:18,095 --> 00:15:21,095
One person approves
authentication changes.

282
00:15:21,215 --> 00:15:23,045
One person owns payment processing.

283
00:15:23,225 --> 00:15:26,975
One person handles infrastructure
when they are overwhelmed or on

284
00:15:26,975 --> 00:15:28,865
vacation or leave the company.

285
00:15:29,015 --> 00:15:30,905
All of that knowledge works out the door.

286
00:15:31,685 --> 00:15:34,265
Second, unwritten tribal knowledge.

287
00:15:34,475 --> 00:15:38,420
The rule rules and documented new
reviewers don't know which areas are

288
00:15:38,735 --> 00:15:42,515
dangerous, which patterns are banned,
which shortcuts are acceptable.

289
00:15:43,175 --> 00:15:47,075
Critical context exist only
in senior people's heads.

290
00:15:48,050 --> 00:15:50,900
Third informal rules about approvals.

291
00:15:51,260 --> 00:15:52,550
Who can approve votes?

292
00:15:52,970 --> 00:15:56,030
It depends on what, on who you ask.

293
00:15:56,570 --> 00:16:02,240
Trust is granted inconsistently, nobody
is quite sure what the actual standard is.

294
00:16:03,050 --> 00:16:05,810
Fourth, no ownership for risky areas.

295
00:16:06,170 --> 00:16:06,680
Security.

296
00:16:07,385 --> 00:16:11,375
Infrastructure, data migrations,
performance critical code.

297
00:16:11,735 --> 00:16:15,815
Everyone assumes someone else is
watching carefully, but ueah is nobody

298
00:16:15,815 --> 00:16:17,675
is because nobody was assigned to.

299
00:16:18,125 --> 00:16:21,155
Everyone just assumed someone else would.

300
00:16:21,655 --> 00:16:24,805
This tribal knowledge problem
is nearly universal and it's

301
00:16:24,805 --> 00:16:27,055
invisible until it breaks.

302
00:16:28,015 --> 00:16:30,415
So we've talked so much about problems.

303
00:16:30,715 --> 00:16:32,245
Let's talk about solutions.

304
00:16:32,755 --> 00:16:35,665
I'm going to give you a
framework built on three pillars.

305
00:16:36,145 --> 00:16:39,955
Think of these as complementary to
automation, not replacement for it.

306
00:16:40,455 --> 00:16:46,185
Pillar one, review practices how you
actually review code, who reviews

307
00:16:46,185 --> 00:16:47,895
what and what standards you apply.

308
00:16:48,645 --> 00:16:53,895
Pillar two, process the structural and
technical safeguards you put in place

309
00:16:54,165 --> 00:16:56,385
to catch what human review might miss.

310
00:16:57,165 --> 00:16:57,855
Pillar three.

311
00:16:58,335 --> 00:17:03,735
Culture, the attitudes, incentives,
and norms that determine whether

312
00:17:03,735 --> 00:17:07,125
people actually use these
practices or route around them.

313
00:17:07,365 --> 00:17:10,965
Under pressure, all three
need to work together.

314
00:17:11,565 --> 00:17:15,435
Great process without culture
creates ignored processes.

315
00:17:15,855 --> 00:17:19,725
Great culture if that process
doesn't scale, and neither works

316
00:17:19,725 --> 00:17:21,405
if your review practices are weak.

317
00:17:21,765 --> 00:17:23,675
So let's explore each one first.

318
00:17:23,675 --> 00:17:23,795
Pillar.

319
00:17:24,650 --> 00:17:26,540
Review practices are actually scale.

320
00:17:27,110 --> 00:17:29,330
Here are four things you
can implement immediately.

321
00:17:29,870 --> 00:17:32,360
Number one, second reviewer.

322
00:17:32,840 --> 00:17:38,060
For high risk areas, things like
authentication, payments, security,

323
00:17:38,060 --> 00:17:42,230
critical code, these need two
sign-offs from people with relevant

324
00:17:42,230 --> 00:17:45,860
expertise, and this should be a
non-negotiable for critical paths.

325
00:17:46,430 --> 00:17:47,120
Number two.

326
00:17:48,050 --> 00:17:50,930
We teach reviewers to
avoid power concentration.

327
00:17:51,260 --> 00:17:54,080
Don't let the same person review
the same author twice in your row.

328
00:17:54,650 --> 00:17:59,180
Fresh eyes catch patterns, and this
prevents both intentional gaming of

329
00:17:59,180 --> 00:18:04,580
trust like we saw in XC and unintentional
drift with standards gradually relax.

330
00:18:05,390 --> 00:18:10,040
Number three, use risk checklist
before merge, before clicking,

331
00:18:10,040 --> 00:18:11,960
merge, answer a series of questions.

332
00:18:12,230 --> 00:18:13,045
Does this search both?

333
00:18:13,355 --> 00:18:17,674
The new dependencies is
this is rollback simple.

334
00:18:18,214 --> 00:18:21,274
Multiple yes answers signal
you should slow down.

335
00:18:21,934 --> 00:18:26,104
Number four, separate fast
lane versus slowing peers.

336
00:18:26,584 --> 00:18:28,624
Not everything means the same scrutiny.

337
00:18:28,984 --> 00:18:33,594
Things like documentation, fixes, test
improvements, refactor full coverage.

338
00:18:33,774 --> 00:18:34,824
These can move fast.

339
00:18:35,324 --> 00:18:40,455
New things like new features, dependency
upgrades, performance optimizations.

340
00:18:40,455 --> 00:18:45,764
These can move slower, so make this
distinction explicit and systematic.

341
00:18:46,215 --> 00:18:49,154
So the key insight here
is not all code is equal.

342
00:18:49,544 --> 00:18:53,624
Not all reviewers are equal, and
not all circumstances are equal.

343
00:18:54,104 --> 00:18:55,664
You need differentiation.

344
00:18:55,995 --> 00:18:58,334
One size fits all doesn't work at scale.

345
00:18:58,834 --> 00:18:59,704
Second pillar.

346
00:19:00,229 --> 00:19:01,669
Cultural safeguards.

347
00:19:01,969 --> 00:19:03,739
This is where most organizations fail.

348
00:19:04,249 --> 00:19:07,399
We can have great processes,
but if culture doesn't support

349
00:19:07,579 --> 00:19:09,289
them, people route around them.

350
00:19:09,789 --> 00:19:15,039
First thing, normalize asking
questions make I don't understand.

351
00:19:15,279 --> 00:19:16,089
Can you explain?

352
00:19:16,089 --> 00:19:18,069
Completely acceptable in code review.

353
00:19:18,294 --> 00:19:20,379
It's not a sign of weakness or slowness.

354
00:19:20,379 --> 00:19:22,809
It is a sign that you're
doing your job properly.

355
00:19:23,469 --> 00:19:26,384
Number two, reward
caution, not just speed.

356
00:19:27,039 --> 00:19:32,319
If your metrics focus only on velocity,
if bonuses are tied only to how fast

357
00:19:32,319 --> 00:19:37,029
deployments are made, and if only the
engineers shipping the most features

358
00:19:37,029 --> 00:19:42,219
get promoted, what behavior are you
incentivizing explicitly reward people

359
00:19:42,219 --> 00:19:44,109
who catch issues before production.

360
00:19:44,889 --> 00:19:49,389
Number three, document issues openly
when you make a technical choice.

361
00:19:49,509 --> 00:19:54,909
Accept a trade off or wa a
requirement, write it down in the pr.

362
00:19:55,464 --> 00:19:59,454
Whether it's in a commit message or design
doc, make sure that reasoning is visible.

363
00:19:59,754 --> 00:20:00,624
And reviewable.

364
00:20:01,494 --> 00:20:03,804
Number four, pair review trick.

365
00:20:04,284 --> 00:20:04,794
Pair review.

366
00:20:04,794 --> 00:20:08,364
Tricky changes for
genuinely complex peers.

367
00:20:08,754 --> 00:20:14,454
Like things like major refactoring,
architectural changes, subtle

368
00:20:14,454 --> 00:20:18,204
bug fixes have to reviewers
work together synchronously.

369
00:20:18,624 --> 00:20:22,074
That way you can catch more
issues, share knowledge, and build

370
00:20:22,074 --> 00:20:23,814
common understanding of quality.

371
00:20:24,314 --> 00:20:26,924
Culture, its process every time.

372
00:20:26,924 --> 00:20:31,544
So if your culture says, just ship it,
your processes won't be able to save you.

373
00:20:32,044 --> 00:20:36,064
Now this slide is my
favorite in the entire deck.

374
00:20:36,724 --> 00:20:38,854
The risk checklist you
can start using today.

375
00:20:39,039 --> 00:20:41,739
So before merging any pier,
answer these questions.

376
00:20:42,249 --> 00:20:46,419
Does this touch sensitive areas in the
projects like off or infrastructure?

377
00:20:47,339 --> 00:20:49,534
Are any new dependencies being added?

378
00:20:50,074 --> 00:20:52,174
Are had to test code paths changed.

379
00:20:52,744 --> 00:20:53,974
Is back simple.

380
00:20:54,454 --> 00:20:56,254
Is reviewer new to this area?

381
00:20:56,644 --> 00:20:58,534
Does this rely on tribal knowledge?

382
00:20:58,864 --> 00:21:00,634
Are we merging under time pressure?

383
00:21:01,144 --> 00:21:03,454
What could go wrong if we are wrong?

384
00:21:04,084 --> 00:21:05,884
Now, here's the key, yes.

385
00:21:05,884 --> 00:21:07,624
Answers don't mean don't merge.

386
00:21:08,074 --> 00:21:09,514
They mean slow down.

387
00:21:10,204 --> 00:21:11,524
Get a second reviewer.

388
00:21:11,974 --> 00:21:13,054
Add monitoring.

389
00:21:13,474 --> 00:21:14,974
Plan the robot procedure.

390
00:21:15,334 --> 00:21:19,204
Document your assumptions,
maybe even stage deployments.

391
00:21:19,849 --> 00:21:21,979
That last question is the most important.

392
00:21:22,369 --> 00:21:25,189
What could go wrong if we are wrong?

393
00:21:25,729 --> 00:21:28,519
If you can't answer that question,
you probably don't understand the

394
00:21:28,519 --> 00:21:30,409
change well enough to approve it.

395
00:21:31,249 --> 00:21:33,739
So the goal isn't to prevent oral risks.

396
00:21:33,919 --> 00:21:39,954
It's making risks explicit and conscious
instead of implicit and invisible.

397
00:21:40,454 --> 00:21:41,044
Third pillar.

398
00:21:41,744 --> 00:21:46,874
Technical and process safeguards
that extend CICD to catch what tests.

399
00:21:46,874 --> 00:21:50,114
Count number one, canary deployments.

400
00:21:50,324 --> 00:21:54,944
So don't go, don't just go straight
from test pass to deploy to everyone.

401
00:21:55,424 --> 00:21:57,464
Deploy to 1% of traffic first.

402
00:21:57,854 --> 00:21:58,424
Monitor it.

403
00:21:59,144 --> 00:22:03,824
Watch for errors, performance issues,
user complaints, and scale up gradually.

404
00:22:04,324 --> 00:22:09,004
Two post deployment smoke checks
after deployment automatically

405
00:22:09,004 --> 00:22:10,324
run checks against production.

406
00:22:10,534 --> 00:22:11,824
Are users able to log in?

407
00:22:12,124 --> 00:22:13,985
Can they complete critical workflows?

408
00:22:14,225 --> 00:22:15,514
Our response times normal.

409
00:22:15,995 --> 00:22:18,784
These catch integration
issues that test myness.

410
00:22:19,414 --> 00:22:22,264
Number three, monitoring types releases.

411
00:22:22,715 --> 00:22:25,985
Every deployment should create
markers in your monitoring system.

412
00:22:26,254 --> 00:22:30,364
This makes it easier to see if
error speed rates spiked after that.

413
00:22:30,370 --> 00:22:30,549
Deploy.

414
00:22:31,049 --> 00:22:34,439
Number four, dependency
and normally alerts.

415
00:22:34,769 --> 00:22:38,759
When someone adds or grades a
dependency, automatically check How

416
00:22:38,759 --> 00:22:40,619
many other dependencies does this bring?

417
00:22:41,099 --> 00:22:42,104
How old are they?

418
00:22:42,509 --> 00:22:44,429
Are there any known vulnerabilities?

419
00:22:44,429 --> 00:22:47,909
How many maintainers this
catches supply chain risks before

420
00:22:47,909 --> 00:22:49,859
they become X level problems.

421
00:22:50,429 --> 00:22:53,729
Number five, error budgets
and rule back triggers.

422
00:22:54,179 --> 00:22:55,559
Define them in advance.

423
00:22:55,769 --> 00:22:58,469
If error rates exceed X
automatically rule back.

424
00:22:59,114 --> 00:22:59,954
Latency exceeds.

425
00:22:59,954 --> 00:23:05,234
Why Automatically roll back, no discussion
needed, just automatic roll back and

426
00:23:05,234 --> 00:23:07,244
then investigate apps stopping depleting.

427
00:23:08,234 --> 00:23:10,934
These aren't expensive or complicated.

428
00:23:11,204 --> 00:23:14,444
They're systematic application
of one principle, which is

429
00:23:14,864 --> 00:23:16,994
testing production or carefully.

430
00:23:17,494 --> 00:23:21,339
Now let me show you what this
looks like in practice before

431
00:23:21,759 --> 00:23:23,649
the PR arrives, tests run.

432
00:23:24,549 --> 00:23:25,209
Merge.

433
00:23:25,239 --> 00:23:28,149
Deploy four steps very fast or fragile.

434
00:23:28,509 --> 00:23:30,639
Now, this is what our
after is looking like.

435
00:23:30,999 --> 00:23:35,739
PR arrives, tests, run risk check
happens using our checklist.

436
00:23:35,979 --> 00:23:38,949
Then it goes to appropriate
reviewers based on risk level,

437
00:23:39,579 --> 00:23:43,269
then stage deployments, canary
first and gradual rollouts.

438
00:23:43,599 --> 00:23:46,724
Then monitoring during rollouts
with automatic rollback triggers.

439
00:23:47,394 --> 00:23:48,279
More steps.

440
00:23:48,489 --> 00:23:49,119
Yes.

441
00:23:49,359 --> 00:23:50,949
Slower maybe.

442
00:23:51,449 --> 00:23:56,249
But here as what matters, low risk changes
still move fast through the fast link.

443
00:23:56,729 --> 00:24:00,959
The only thing you've added is
overhead where risk justifies it.

444
00:24:01,889 --> 00:24:05,289
And critically, you've also created
multiple opportunities to catch

445
00:24:05,289 --> 00:24:06,969
issues before the cause problems.

446
00:24:07,389 --> 00:24:10,089
This is defense in depth.

447
00:24:10,539 --> 00:24:14,079
No single safeguard is perfect,
but the combination makes it much

448
00:24:14,079 --> 00:24:15,409
harder for issues to sleep through.

449
00:24:15,909 --> 00:24:17,499
You are not slowing everything down.

450
00:24:17,529 --> 00:24:20,619
You are just select, you are just being
selective about where you add rigor.

451
00:24:21,119 --> 00:24:24,449
So lemme bring this full
circle with four takeaways.

452
00:24:24,959 --> 00:24:29,459
One, CICD is necessary but not sufficient.

453
00:24:30,059 --> 00:24:34,169
Automation is powerful, essential,
but it's not the whole answer.

454
00:24:34,859 --> 00:24:35,219
Two.

455
00:24:35,699 --> 00:24:37,739
Risk grows quietly as project skill.

456
00:24:38,639 --> 00:24:41,699
What works at five
contributors fails at 500.

457
00:24:41,699 --> 00:24:48,480
So you need to be able to actively adapt
three people and process fill the gaps.

458
00:24:48,480 --> 00:24:53,909
Automation counts, intent,
context, trust, judgments.

459
00:24:54,149 --> 00:24:58,080
These require human solutions,
not just technical ones.

460
00:24:58,735 --> 00:24:59,024
Four.

461
00:24:59,945 --> 00:25:01,649
Safeguards don't need to slow delivery.

462
00:25:02,159 --> 00:25:05,100
You can maintain velocity
while improving quality.

463
00:25:05,699 --> 00:25:07,110
They are not in opposition.

464
00:25:07,610 --> 00:25:12,830
Remember Andre's front on March
29th, 2024, he noticed something

465
00:25:12,830 --> 00:25:16,280
that all of the automation risks,
not because he was smarter than

466
00:25:16,280 --> 00:25:20,240
tests, not because he had better
tools, but because he stayed curious.

467
00:25:20,480 --> 00:25:22,669
He questioned the green check marks.

468
00:25:23,270 --> 00:25:24,889
That's what saved us from Execut.

469
00:25:25,700 --> 00:25:29,419
Human curiosity, human
judgment, human caution.

470
00:25:29,840 --> 00:25:31,670
So your automation will
keep getting better.

471
00:25:32,150 --> 00:25:35,360
Your C-I-S-C-D will keep evolving,
but it'll never replace the

472
00:25:35,360 --> 00:25:38,120
human who asks, wait, why?

473
00:25:38,600 --> 00:25:44,060
When something feels off, build systems
that supports that human, that's how we

474
00:25:44,060 --> 00:25:46,940
are able to build resilience software.

475
00:25:47,440 --> 00:25:49,450
Thank you so much for watching.

476
00:25:49,659 --> 00:25:55,149
I hope this has given you concrete ideas
to try with your own teams, and if you'd

477
00:25:55,149 --> 00:26:00,220
like to discuss any of this further, you
can find me on LinkedIn and X as soda.

478
00:26:01,149 --> 00:26:02,379
Thank you so much.

