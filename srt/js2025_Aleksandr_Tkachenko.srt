1
00:00:00,500 --> 00:00:01,250
Hi everyone.

2
00:00:01,339 --> 00:00:04,640
I'm really glad to welcome everyone
to this wonderful event and to share

3
00:00:04,700 --> 00:00:06,290
something new and exciting with you.

4
00:00:06,725 --> 00:00:10,415
In my talks, I usually focus on two
things, either new, lesser known

5
00:00:10,415 --> 00:00:14,885
technologies or old but overlooked ideas
that I believe deserves more attention.

6
00:00:15,124 --> 00:00:16,595
And this topic is no exception.

7
00:00:16,655 --> 00:00:20,134
I'm going to talk about something
experimental, but with a lot of potential.

8
00:00:20,465 --> 00:00:22,775
It is a scheduler yield right now.

9
00:00:22,775 --> 00:00:26,405
This future is still in early stages,
and not all browsers supported yet.

10
00:00:26,650 --> 00:00:28,720
But there's already IL available.

11
00:00:28,810 --> 00:00:31,270
And during the talk I'll also
show some alternative ways

12
00:00:31,270 --> 00:00:32,830
to achieve similar behavior.

13
00:00:33,280 --> 00:00:37,030
These aren't perfect replacements, but
they can still be useful in the meantime.

14
00:00:37,530 --> 00:00:41,699
And before we dive into the topic, just
a few words about myself and why my

15
00:00:41,699 --> 00:00:43,500
viewers listening to what I have to say.

16
00:00:44,070 --> 00:00:48,180
I'm a fronted engineer with over six
years of experience, author of technical

17
00:00:48,180 --> 00:00:51,960
and scientific publications and
speaker at the Global Tech conferences.

18
00:00:52,260 --> 00:00:56,130
I'm a mentor and judge at international
hackathons and innovation award programs,

19
00:00:56,339 --> 00:01:00,180
and I'm also involved in the open
source community program contribution,

20
00:01:00,180 --> 00:01:03,750
including creating my own open
source C success library ton mammoth.

21
00:01:04,265 --> 00:01:07,115
I'm also a member of several
professional associations.

22
00:01:07,535 --> 00:01:10,595
Now that you know a little bit
about me, let's get to the point.

23
00:01:11,585 --> 00:01:13,655
So what is a scheduler yield?

24
00:01:13,955 --> 00:01:16,595
It is a method of the scheduler
interface from the new

25
00:01:16,595 --> 00:01:18,905
prioritized task scheduling API.

26
00:01:19,265 --> 00:01:22,445
This methods allows you as a
developer to post your JavaScript

27
00:01:22,445 --> 00:01:25,640
execution and explicitly yield
control back to the main threat.

28
00:01:26,140 --> 00:01:30,340
So it can handle other pending
important tasks like user interactions,

29
00:01:30,370 --> 00:01:31,930
clicks, typings, et cetera.

30
00:01:32,230 --> 00:01:35,835
In simple terms, when you call scheduler
youth, you are telling the browser.

31
00:01:36,565 --> 00:01:37,885
Wait, take a breath.

32
00:01:38,065 --> 00:01:42,325
Let's put the current tasks and focus on
other, no less or more important tasks.

33
00:01:42,715 --> 00:01:46,465
Once you have done, come back and
continue execution from where we left off.

34
00:01:47,155 --> 00:01:49,855
This makes your page more
responsive, especially when running

35
00:01:49,975 --> 00:01:51,775
long or heavy JavaScript tasks.

36
00:01:52,315 --> 00:01:56,245
It can also help improve metrics like
interaction to next paint called INP,

37
00:01:56,545 --> 00:01:59,785
which is all about how quickly the
browser responds to the user input.

38
00:02:00,285 --> 00:02:03,645
Before we dive deeper, let's quickly
go over a few basic terms that

39
00:02:03,645 --> 00:02:05,175
I'll be using throughout the talk.

40
00:02:05,625 --> 00:02:08,445
I'm sure many of you already
know them, but a quicker press,

41
00:02:08,445 --> 00:02:10,275
never hearts main threat.

42
00:02:10,905 --> 00:02:14,055
This is a central place where the
browser does most of its work.

43
00:02:14,265 --> 00:02:17,565
It handles rendering, layout,
and runs most of your JavaScript.

44
00:02:18,065 --> 00:02:18,845
A long task.

45
00:02:19,295 --> 00:02:22,895
This is any JavaScript task that keep
the main thread busy for too long,

46
00:02:23,195 --> 00:02:25,145
usually more than 50 milliseconds.

47
00:02:25,535 --> 00:02:28,385
When that happens, the page can
freeze or feel unresponsive.

48
00:02:28,885 --> 00:02:32,695
And the blocking task is a synchronous
separation of the main thread that

49
00:02:32,695 --> 00:02:34,315
prevents the browser from processing.

50
00:02:34,405 --> 00:02:37,674
Other important things like
responding to clicks, updating

51
00:02:37,674 --> 00:02:39,864
the ui, usually learn tasks.

52
00:02:39,924 --> 00:02:40,910
Tasks are blocking tasks.

53
00:02:41,410 --> 00:02:41,980
The problem.

54
00:02:42,490 --> 00:02:45,790
To understand the beauty of scheduler
yield, we first need to understand

55
00:02:45,790 --> 00:02:47,140
what problem's trying to solve.

56
00:02:47,410 --> 00:02:50,980
And for that, let's quickly refresh
how JavaScript purchase tasks.

57
00:02:51,220 --> 00:02:54,190
In other words, how the task
processing in the browser works.

58
00:02:55,090 --> 00:02:57,610
I'm sure many of you have seen
diagrams like this before.

59
00:02:57,670 --> 00:02:59,320
The task queue, the event loop.

60
00:02:59,350 --> 00:03:00,160
The call stack.

61
00:03:00,610 --> 00:03:03,070
This one isn't perfect, but
it gives us the big picture.

62
00:03:03,370 --> 00:03:05,410
Let's walk through the
main ideas step by step.

63
00:03:06,234 --> 00:03:09,595
So all in Crohn's code goes straight
to the cold stack and runs line

64
00:03:09,595 --> 00:03:11,005
by line, function By function.

65
00:03:11,214 --> 00:03:13,225
It follows a leaf of principle lasting.

66
00:03:13,225 --> 00:03:17,454
First out, JavaScript runs in a single
thread, which means it can do only

67
00:03:17,454 --> 00:03:21,765
one thing at a time, as in Crohn's
operations, set them out, fetch.

68
00:03:22,290 --> 00:03:28,059
Pro handled outside the ADE by the web
APIs provided by the browser environment.

69
00:03:28,299 --> 00:03:31,299
When they've done, they don't go
back directly into the call stack.

70
00:03:31,660 --> 00:03:35,170
Instead, their callbacks queue
either in the microtask queue,

71
00:03:35,469 --> 00:03:37,329
you can see it here like promise.

72
00:03:37,329 --> 00:03:41,269
Then queue microtask or tasks
queue, set them out or set inter.

73
00:03:42,170 --> 00:03:46,040
When the call stack is empty, they went
loop check the microtask queue and runs

74
00:03:46,160 --> 00:03:49,220
all microtask one by one in order only.

75
00:03:49,220 --> 00:03:52,549
After that, it takes one runable
task from the chosen task queue.

76
00:03:53,120 --> 00:03:58,160
Importantly, the task queue assets,
not strict FIFA queues, they went loop.

77
00:03:58,160 --> 00:04:01,460
Pick the first task that is
ready to run, not necessarily

78
00:04:01,520 --> 00:04:03,200
that one that was added first.

79
00:04:04,145 --> 00:04:08,165
If during the process new microt
tasks are added, they run before

80
00:04:08,165 --> 00:04:09,785
the next task from the task queue.

81
00:04:10,084 --> 00:04:12,274
So microt tasks always get priority.

82
00:04:13,024 --> 00:04:15,215
This loop keeps going All microt tasks.

83
00:04:15,274 --> 00:04:17,345
One task from task queue repeat.

84
00:04:18,065 --> 00:04:20,135
Use chrome code gets into the call stack.

85
00:04:20,135 --> 00:04:24,065
When new tasks arrive, like a user click
in a button and new script being run.

86
00:04:24,125 --> 00:04:27,185
When a microtask or task from
Task Q runs it's callback.

87
00:04:28,130 --> 00:04:31,400
This is a very brief and superficial
explanation just to remind you how it

88
00:04:31,400 --> 00:04:36,200
works, since it'll further close the
inter circuit with the topic, please note

89
00:04:36,290 --> 00:04:40,220
that Event Loop itself is not part of
the JavaScript ECMA script specification.

90
00:04:40,280 --> 00:04:42,500
If you look into the ecma
Script specification, you

91
00:04:42,500 --> 00:04:43,880
won't point it there at all.

92
00:04:44,150 --> 00:04:46,580
The event loop is defined
in the HTML standard.

93
00:04:47,080 --> 00:04:48,190
As a problem description.

94
00:04:48,790 --> 00:04:52,300
Now that we have refreshed our
understanding of how JavaScript secured

95
00:04:52,300 --> 00:04:56,260
tasks, let's take a closer look at the
real problems that comes with this model.

96
00:04:56,800 --> 00:04:57,515
The issue is simple.

97
00:04:58,150 --> 00:05:01,810
When a task takes to long on the main
thread, it blocks everything else.

98
00:05:02,200 --> 00:05:05,350
User interactions, rendering
updates, animation.

99
00:05:05,500 --> 00:05:08,230
This leads to AI freezes
and pure responsiveness.

100
00:05:08,410 --> 00:05:12,170
The obvious forethought might be, just
don't write long or heavy functions,

101
00:05:12,170 --> 00:05:13,760
and that is the problem is solved.

102
00:05:14,030 --> 00:05:15,440
And yes, that's true.

103
00:05:15,620 --> 00:05:18,650
In an ideal world, we will always
split heavy coat into smaller

104
00:05:18,650 --> 00:05:22,700
parts, optimize every sink, and
the avoid blocking the main thread.

105
00:05:23,405 --> 00:05:26,915
Let's be honest, many of us have run
through these issues even if we weren't

106
00:05:26,975 --> 00:05:28,625
that ones who regionally cause them.

107
00:05:29,045 --> 00:05:32,885
Even if you were not the culprit of
this behavior, you have to work with it.

108
00:05:33,455 --> 00:05:37,025
And to make this more concrete, let's
simulate a simple but realistic case.

109
00:05:37,805 --> 00:05:42,005
Imagine we had to process a large
array, and each element requires some

110
00:05:42,005 --> 00:05:46,895
non-trivial computation, something
that takes time and uses CPU, which

111
00:05:46,895 --> 00:05:48,425
in turns blocks the main thread.

112
00:05:48,925 --> 00:05:51,835
For this, we'll create a
function called blocking task.

113
00:05:52,660 --> 00:05:56,800
The task as a block in task for the main
threat for the specified period of time.

114
00:05:57,040 --> 00:06:01,570
The function simulate this kind of heavy
computation on each element of the array.

115
00:06:02,170 --> 00:06:04,810
There's nice and f fancy
about the function here.

116
00:06:05,050 --> 00:06:09,100
All it does, so it accepts an
argument, the number of milliseconds.

117
00:06:09,580 --> 00:06:13,480
This is the minimum time the function
will run, thus occupying the main threat.

118
00:06:14,320 --> 00:06:16,060
Then it creates an empty array.

119
00:06:16,240 --> 00:06:21,700
Then it creates a start time as a
current time, and then runs a while loop

120
00:06:21,760 --> 00:06:23,740
until the specified time has passed.

121
00:06:24,190 --> 00:06:28,270
Inside the loop, it just does random,
meaningless calculation to simulate load.

122
00:06:28,990 --> 00:06:31,510
Finally, it returned the
result of the calculation.

123
00:06:32,230 --> 00:06:35,260
The function doesn't do anything
useful, but it does simulate a

124
00:06:35,260 --> 00:06:37,000
real world scenario of heavy load.

125
00:06:37,480 --> 00:06:40,330
This function will be used
inside another simple function.

126
00:06:40,510 --> 00:06:44,530
Imagine a common situation where we need
to look through an array of data and apply

127
00:06:44,530 --> 00:06:46,660
that heavy work to each item of the array.

128
00:06:47,160 --> 00:06:51,180
To do this, we'll create a heavy work
function in which the following happens.

129
00:06:51,810 --> 00:06:56,640
On line two, it creates an array of 200
items, just numbers from zero to one.

130
00:06:56,640 --> 00:06:57,120
Nine nine.

131
00:06:57,540 --> 00:07:02,280
I want to know that 200 items are not
that many, but it'll be enough that the

132
00:07:02,400 --> 00:07:04,440
to the see the essence of the problem.

133
00:07:05,220 --> 00:07:09,210
Then a new empty result array is
created to store the processed values.

134
00:07:10,050 --> 00:07:15,090
Then on line five declares a loop that go
through the entire lens of the data array.

135
00:07:16,050 --> 00:07:20,490
Inside the loop, we run the blocking task
function, simulating only 10 milliseconds

136
00:07:20,490 --> 00:07:24,150
of work for each element, and the
result is added to the result array.

137
00:07:24,450 --> 00:07:28,260
Once again, I want to remind you that
for the demo, the blocking task function

138
00:07:28,260 --> 00:07:30,120
does not carry any semantic load.

139
00:07:30,420 --> 00:07:34,470
It is simply perform some imaginary
resource intensive work in the real world.

140
00:07:34,620 --> 00:07:36,630
It could be some labor
intensive processing.

141
00:07:36,630 --> 00:07:37,620
Cory Element.

142
00:07:38,160 --> 00:07:41,850
Finally in return, the result
in array, and that's where

143
00:07:41,850 --> 00:07:43,170
the amazing part comes in.

144
00:07:43,260 --> 00:07:47,910
Just 10 millisecond per element and only
200 elements, but together they block

145
00:07:47,910 --> 00:07:50,040
the main thread for two full seconds.

146
00:07:50,190 --> 00:07:52,560
That's enough to cause a
noticeable freeze in the ui.

147
00:07:53,100 --> 00:07:55,260
No clicks, no typing, just a frozen.

148
00:07:55,760 --> 00:07:56,930
It's a problem demonstration.

149
00:07:57,620 --> 00:08:00,830
Now it's time to look at the problem,
not just in theory but in action.

150
00:08:01,190 --> 00:08:03,140
This is not full fledged demo just yet.

151
00:08:03,200 --> 00:08:06,800
Tin of a simplified visual to
help you clearly see the issue.

152
00:08:07,370 --> 00:08:08,630
Here's what you see here.

153
00:08:09,080 --> 00:08:13,370
The left window titled configuration
lets you turn on the main thread block

154
00:08:13,490 --> 00:08:17,090
on and off, meaning whether the blocking
task function is actually running.

155
00:08:17,540 --> 00:08:20,570
You can also toggle scheduler
yield functionality.

156
00:08:20,630 --> 00:08:21,845
We will get to that part later.

157
00:08:22,670 --> 00:08:26,830
The window titled heavy task here on
the right runs the heavy work function.

158
00:08:26,920 --> 00:08:30,909
This is one that process an array
using blocking task on each element.

159
00:08:30,940 --> 00:08:34,780
If the main thread blocking is
enabled and the window typed logger

160
00:08:34,780 --> 00:08:38,260
here, just talk the current time to
the console, including milliseconds.

161
00:08:38,760 --> 00:08:41,640
Let's see what happens when the
main thread booking is turned off.

162
00:08:41,969 --> 00:08:43,319
So the tasks are very light.

163
00:08:43,439 --> 00:08:47,400
It just took over an array of 200
elements without any complex calculation.

164
00:08:47,699 --> 00:08:50,969
What we observe here, the
user click the okay button.

165
00:08:51,089 --> 00:08:53,729
The heavy work function
runs and instantly returns.

166
00:08:54,060 --> 00:08:57,780
This is indicated by the message Heavy
Task done in the console, followed by

167
00:08:57,780 --> 00:09:00,270
the result of an array of numbers here.

168
00:09:01,125 --> 00:09:03,375
Then the user clicks the
log button three times.

169
00:09:03,705 --> 00:09:07,185
They log the time to the console,
timestamps appear immediately

170
00:09:07,245 --> 00:09:08,865
with a slight difference in time.

171
00:09:09,645 --> 00:09:12,075
They run the heavy work
function again and again.

172
00:09:12,135 --> 00:09:13,095
Instant response.

173
00:09:13,515 --> 00:09:17,235
Finally, the user closes two windows,
which actually just remove those elements

174
00:09:17,235 --> 00:09:19,395
from the do no delays, no hiccup.

175
00:09:19,895 --> 00:09:22,235
In this case, everything
feels fast and responsive.

176
00:09:22,595 --> 00:09:25,235
The browser has no trouble
hand the interactions because

177
00:09:25,235 --> 00:09:26,405
the mantra stays free.

178
00:09:26,915 --> 00:09:29,735
Tasks are performed almost
instantly and consistently.

179
00:09:30,235 --> 00:09:33,955
Now let's enable the main thread blocking
so that for each element of the array,

180
00:09:33,985 --> 00:09:37,795
the blocking task function will be called
with a delay of only 10 milliseconds.

181
00:09:38,275 --> 00:09:40,705
And now you can observe that
user interaction with your

182
00:09:40,705 --> 00:09:42,175
elements has become less smooth.

183
00:09:42,175 --> 00:09:43,555
UI freeze, have a period.

184
00:09:44,125 --> 00:09:47,125
Let's break it down to what is happening
here and what we can observe from it.

185
00:09:47,425 --> 00:09:51,025
The user press okay button, thereby
launching the heavy work function.

186
00:09:51,325 --> 00:09:54,865
And the first log that occurs is that
the okay button visually stays pressed.

187
00:09:55,330 --> 00:09:55,690
Why?

188
00:09:55,840 --> 00:09:57,580
Because the browser cannot repent.

189
00:09:57,580 --> 00:10:01,180
While heavy work is still blocking
the main threat, and it is important

190
00:10:01,180 --> 00:10:04,150
to understand that we are talking
not only about the current task,

191
00:10:04,180 --> 00:10:05,800
but about the call stack as a whole.

192
00:10:06,520 --> 00:10:09,580
During this time, the user clicks
the logs button four times.

193
00:10:09,730 --> 00:10:10,570
Nothing happens.

194
00:10:11,230 --> 00:10:14,080
The clicks are registered and
they handles edit to the queue,

195
00:10:14,260 --> 00:10:15,640
but the browsers can't react.

196
00:10:15,940 --> 00:10:19,300
Only after heavy work finishes
do we see the console output

197
00:10:19,720 --> 00:10:21,070
for the heavy workers out.

198
00:10:21,190 --> 00:10:22,630
Then the four time steps.

199
00:10:23,350 --> 00:10:27,040
All printed in a batch and only
after that the okay button changed

200
00:10:27,040 --> 00:10:28,630
its state and became impressed.

201
00:10:29,380 --> 00:10:30,670
Next, the user clicks.

202
00:10:30,730 --> 00:10:33,820
Okay, button again, same
behavior, stuck button.

203
00:10:33,940 --> 00:10:37,360
Then while the heavy work task is
running, he tries to close the window

204
00:10:37,360 --> 00:10:39,490
by clicking the X icon three times.

205
00:10:39,610 --> 00:10:42,250
Again, no visual response, only one.

206
00:10:42,250 --> 00:10:44,590
The task ends do we see
the window disappear.

207
00:10:45,280 --> 00:10:48,820
And finally, one more attempt to run
heavy work and close the last window.

208
00:10:48,850 --> 00:10:49,540
Same freeze.

209
00:10:50,080 --> 00:10:53,440
So you see the press button,
you see nothing happens here.

210
00:10:54,220 --> 00:10:56,410
You see the press button
again, nothing happens.

211
00:10:56,830 --> 00:10:58,270
It's lagging, it's freeze.

212
00:10:58,770 --> 00:11:02,609
What that, this show, the simple demo,
shows how long task block the powers

213
00:11:02,609 --> 00:11:04,650
their ability to respond to user actions.

214
00:11:05,009 --> 00:11:09,270
Even though each block code takes
just 10 millisecond changing 200 of

215
00:11:09,270 --> 00:11:13,259
them to get results in a two second
freeze, the user can interact with the

216
00:11:13,259 --> 00:11:14,879
button, the interface doesn't repaint.

217
00:11:15,379 --> 00:11:18,889
Events get queued up, but not processed
until the call stack is clear.

218
00:11:19,219 --> 00:11:22,399
This is not just a performance
issue, it's a user experience

219
00:11:22,399 --> 00:11:25,519
problem, and that's exactly the
kind of issue we want to solve.

220
00:11:25,819 --> 00:11:29,734
Ideally, without having to manually
split our logic into dozen of callbacks.

221
00:11:30,234 --> 00:11:31,399
It is a problem solution.

222
00:11:32,299 --> 00:11:35,779
Now that we understand the problem,
let's talk about the possible solutions.

223
00:11:36,139 --> 00:11:40,009
Of course, the best strategies to wet loan
task in the first place by keeping code

224
00:11:40,009 --> 00:11:42,019
efficient and breaking things up early.

225
00:11:42,289 --> 00:11:47,059
But as we have seen stuff happens, whether
it's legacy code and available computation

226
00:11:47,059 --> 00:11:48,709
are just not enough time to optimize.

227
00:11:48,709 --> 00:11:50,149
Sometimes we have to deal with it.

228
00:11:50,884 --> 00:11:55,414
Over the years before the prioritized
task scheduling API appeared, various

229
00:11:55,414 --> 00:11:59,254
workaround and tweaks have been come up
is to improve the responsiveness, but the

230
00:11:59,254 --> 00:12:03,484
core idea behind all of them and behind
scheduler as well is pretty simple.

231
00:12:03,904 --> 00:12:08,044
Break a task into smaller pieces is
chunks, and once in a while, post

232
00:12:08,044 --> 00:12:09,484
to let the browser catch it breathe.

233
00:12:10,204 --> 00:12:14,344
In other words, we give the main threat
a chance to run more urgent tasks like

234
00:12:14,344 --> 00:12:18,604
user interactions, rendering updates, and
then we come back to finish our own work.

235
00:12:19,104 --> 00:12:22,494
Here's what the concept of heavy work
function looks like in the pseudo code.

236
00:12:23,034 --> 00:12:24,084
What's happening here?

237
00:12:24,834 --> 00:12:29,384
First, you run a chunk of your task, then
you post allowing the browser to handle

238
00:12:29,444 --> 00:12:31,814
other high priority tasks like UI updates.

239
00:12:32,324 --> 00:12:34,874
Put the current task and task
control that demand threat to

240
00:12:34,874 --> 00:12:38,734
handle other high priority tasks,
and then continue execution.

241
00:12:38,734 --> 00:12:40,204
The function from where it left off.

242
00:12:40,704 --> 00:12:42,264
All problem solving approach.

243
00:12:42,639 --> 00:12:45,849
Before scheduler yield came
along, the most common trick for

244
00:12:45,849 --> 00:12:48,519
dealing with the long blocking
task was to use set time out.

245
00:12:49,119 --> 00:12:53,709
By calling it with a zero delay, you add
its callback task to the end of the task

246
00:12:53,709 --> 00:12:56,349
queue, allowing other tasks to run first.

247
00:12:56,559 --> 00:13:00,999
In other words, you tell the browser,
run this bit of code later, after you

248
00:13:00,999 --> 00:13:04,559
handle everything else, and that's how
we can give the main threat a short

249
00:13:04,559 --> 00:13:06,689
bleeder between chances of heavy work.

250
00:13:06,749 --> 00:13:09,269
Here's what the updated heavy
work function might look

251
00:13:09,269 --> 00:13:10,469
like using this approach.

252
00:13:11,099 --> 00:13:11,909
Let's break it down.

253
00:13:11,909 --> 00:13:16,109
What's going on here on A
Promise is created and it's

254
00:13:16,109 --> 00:13:17,609
executor runs immediately.

255
00:13:17,879 --> 00:13:22,109
Scheduling a set time out with a
zero delay the time article back,

256
00:13:22,109 --> 00:13:25,739
which resolves the promise is
added to the end of the task queue.

257
00:13:26,069 --> 00:13:30,149
Because of a wait, the rest of the
same function is post technically

258
00:13:30,179 --> 00:13:34,424
discontinuation is added to the microtask
queue, waiting for the promise to resolve.

259
00:13:35,189 --> 00:13:37,289
The JavaScript and giant
check the call stack.

260
00:13:37,439 --> 00:13:39,719
Once it's empty, they went loop kicks in.

261
00:13:39,959 --> 00:13:44,099
First it took at the microtask queue,
but times the promise isn't resolved.

262
00:13:44,099 --> 00:13:46,199
There's nothing to run they want.

263
00:13:46,259 --> 00:13:46,949
They went loop.

264
00:13:46,949 --> 00:13:48,269
Pick the task from the queue.

265
00:13:48,569 --> 00:13:52,469
In our example, it is set
time out, called back runs it,

266
00:13:52,559 --> 00:13:53,909
and this resolve the promise.

267
00:13:54,569 --> 00:13:58,769
Now that the promise is resolved, the
Microtask contains the continuation

268
00:13:58,769 --> 00:13:59,999
of the, I think function is run.

269
00:14:00,554 --> 00:14:03,794
In simple terms, line three gives
the browser a chance to catch its

270
00:14:03,794 --> 00:14:05,624
breeze before heavy work begins.

271
00:14:05,924 --> 00:14:09,554
Therefore, by calling this method
before doing any heavy work gives a

272
00:14:09,554 --> 00:14:13,964
browser a moment to rear-end UA updates,
such as unfreezing, a click button.

273
00:14:14,774 --> 00:14:20,194
On line nine, we calculate how often we
want to yield to the main threat, roughly

274
00:14:20,224 --> 00:14:25,384
every 25% of the work, this number can
vary depending on how heavy the task is.

275
00:14:26,179 --> 00:14:31,189
On line 13 through 15 inside the
loop, if the condition for yielding

276
00:14:31,189 --> 00:14:34,159
interval is met, execution is
transferred to the main thread.

277
00:14:34,579 --> 00:14:38,629
That is the set technique is repeated,
allowing the browser process, user

278
00:14:38,629 --> 00:14:40,519
interaction, or draw the interface.

279
00:14:41,119 --> 00:14:42,589
Essentially, this approach works.

280
00:14:42,804 --> 00:14:47,094
It's relatively simple and does improve
responsiveness, but there's a tradeoffs.

281
00:14:47,214 --> 00:14:51,264
One big issue that is set them out
isn't built for precise scheduling.

282
00:14:51,684 --> 00:14:56,064
It puts tasks at the end of the task
queue, and anything already in that

283
00:14:56,064 --> 00:14:58,044
queue can delay your continuation.

284
00:14:58,544 --> 00:15:02,084
For example, let's say some
other part of the page, you set

285
00:15:02,084 --> 00:15:03,704
interval to run task regularly.

286
00:15:04,244 --> 00:15:08,534
Now your own task, the next chunk of
heavy work function might get delayed by

287
00:15:08,564 --> 00:15:10,814
one or more of these interval call bags.

288
00:15:11,294 --> 00:15:14,774
The brow just runs whatever
in is next in line it do.

289
00:15:14,804 --> 00:15:16,394
You don't control the order.

290
00:15:16,634 --> 00:15:20,144
So while set time out lets you
yield, you don't know exactly

291
00:15:20,414 --> 00:15:21,959
when you get control back.

292
00:15:22,459 --> 00:15:25,039
There are other ways to
upload this situation.

293
00:15:25,099 --> 00:15:28,879
It could be the request animation frame
function, which lets you schedule work

294
00:15:28,879 --> 00:15:33,349
right before the next repaint, often used
in conjunction with the set amount and has

295
00:15:33,349 --> 00:15:38,359
similar drawbacks or request idle callback
that runs your code during the browser.

296
00:15:38,389 --> 00:15:39,079
Idle time.

297
00:15:39,379 --> 00:15:42,739
It's not quite an alternative,
but good for background, a less

298
00:15:42,739 --> 00:15:46,519
important work that help the mantra
to be free for more critical tasks.

299
00:15:46,894 --> 00:15:49,804
In general, we could discuss
other strategies for solving

300
00:15:49,864 --> 00:15:51,364
and preventing such problems.

301
00:15:51,694 --> 00:15:55,054
However, to stay on topic, let's
move on and see what schedule

302
00:15:55,294 --> 00:15:56,614
yield brings to the table.

303
00:15:57,114 --> 00:16:01,794
So schedule yield, it's a modern
way to post execution and yield

304
00:16:01,794 --> 00:16:05,124
control to the main threat, which
allows the browser to perform any

305
00:16:05,124 --> 00:16:08,844
pending high priority work and then
continue execution from where it left.

306
00:16:09,744 --> 00:16:13,254
What actually happens under the
hood when the AWAI scheduler

307
00:16:13,254 --> 00:16:14,694
yield expression is reached?

308
00:16:14,994 --> 00:16:18,714
The execution of the current function is
in, which it was called, is suspended,

309
00:16:19,314 --> 00:16:23,034
and the yields controlled is the main
threat, thereby breaking up or posing

310
00:16:23,064 --> 00:16:27,144
the current task, the continuation of
the function, that is the execution

311
00:16:27,234 --> 00:16:31,104
of the remaining part of it from
where it left off is a separate, newly

312
00:16:31,104 --> 00:16:33,174
scheduled microtask in the event loop.

313
00:16:33,969 --> 00:16:38,079
The beauty of scheduler yield that
the continuation after scheduler yield

314
00:16:38,139 --> 00:16:43,029
remains at the front of the queue and
the scheduler to run before any other

315
00:16:43,029 --> 00:16:45,399
non-essential tasks that have been queue.

316
00:16:45,729 --> 00:16:49,509
The key difference from the set
out approach that we set them out,

317
00:16:49,869 --> 00:16:54,039
discontinuation typically run after
any new tasks that have already

318
00:16:54,039 --> 00:16:57,549
been queued, potentially causing
long delays between yielding to the

319
00:16:57,549 --> 00:16:59,079
main threat and their completion.

320
00:16:59,579 --> 00:17:03,149
The following diagram illustrates how
three approaches compare in practice.

321
00:17:03,869 --> 00:17:08,219
Let's look at them in the first example
without yielding to the main thread.

322
00:17:08,369 --> 00:17:11,339
At the first is the long
task one runs uninterrupted.

323
00:17:11,839 --> 00:17:14,119
Blocking the main trend
and UI accordingly.

324
00:17:14,239 --> 00:17:16,069
Then a user event is processed.

325
00:17:16,429 --> 00:17:19,519
A button click triggered during
the execution of task one.

326
00:17:19,759 --> 00:17:24,109
And finally task Q. Task two
is executed, set time out, call

327
00:17:24,109 --> 00:17:27,979
back, schedule it earlier during
the execution of the wrong task.

328
00:17:28,479 --> 00:17:32,529
In the second example, using set
timeout as a yield into the main

329
00:17:32,529 --> 00:17:36,699
threat, the execution use different
at first, the long task one runs.

330
00:17:37,224 --> 00:17:40,794
Then when the yield to the main
threat happens, task one passes

331
00:17:41,094 --> 00:17:43,884
to let the browser breathe and
the button click is processed.

332
00:17:44,124 --> 00:17:49,494
But after the button click is processed,
the set time article back will be executed

333
00:17:49,494 --> 00:17:53,634
first, which could have been scheduled
in advance during the execution of Task

334
00:17:53,634 --> 00:17:58,254
one, and finally only after that the
continuation of Task one will be executed.

335
00:17:58,754 --> 00:18:01,934
And in the last example, using
scheduler yield technology.

336
00:18:01,994 --> 00:18:06,794
After the long task one has been post and
the user click event has been processed.

337
00:18:06,944 --> 00:18:10,784
Then the continuation of the
task one is prioritized and runs

338
00:18:10,784 --> 00:18:12,974
before an acute set amount tasks.

339
00:18:13,364 --> 00:18:17,354
In summary, scheduler yield is a more
intelligent and predictable way to give

340
00:18:17,354 --> 00:18:18,674
the main threat breath in the room.

341
00:18:18,974 --> 00:18:22,724
It avoid the risk of your code being
pushed far too back in the queue and helps

342
00:18:22,724 --> 00:18:26,564
maintain performance and responsiveness,
especially in complex applications.

343
00:18:27,064 --> 00:18:27,725
Priorities.

344
00:18:28,324 --> 00:18:30,954
So what causes such a
difference in behavior?

345
00:18:31,104 --> 00:18:32,274
It's all about priorities.

346
00:18:33,129 --> 00:18:37,239
As developers, we don't usually think
about the order of execution of task in

347
00:18:37,239 --> 00:18:41,080
the event loop in terms of priorities
more precisely, we have a good

348
00:18:41,080 --> 00:18:45,850
understanding what microtask and task you
are and the order image which they run.

349
00:18:45,909 --> 00:18:48,340
But if you look deeper, you'll
notice that there are all

350
00:18:48,340 --> 00:18:50,169
simplicity priorities at play.

351
00:18:50,649 --> 00:18:53,604
For example, a button click
handle, fired by user action.

352
00:18:54,054 --> 00:18:56,814
Typically execute before
a set time call back.

353
00:18:56,874 --> 00:18:59,094
Even though both a task
from the task queue.

354
00:18:59,784 --> 00:19:03,774
As mentioned earlier, scheduler yield
is a part of the prioritized task,

355
00:19:03,774 --> 00:19:08,634
scheduling API and extensive and future
reach interface that deserve its own

356
00:19:08,634 --> 00:19:12,264
separate, full-fledged discussion is
clearly beyond the scope of this talk.

357
00:19:12,894 --> 00:19:15,860
Nevertheless, it's important to
mention one of its key features.

358
00:19:16,424 --> 00:19:21,824
The introduction of Clear Task priority
Model, prioritized Task Scheduling API

359
00:19:22,034 --> 00:19:26,024
simply make these priorities explicit,
making it easier to determine which

360
00:19:26,024 --> 00:19:30,014
task will run first, and enables
adjusting priorities to change the

361
00:19:30,014 --> 00:19:32,654
order of the execution if needed.

362
00:19:33,224 --> 00:19:36,254
Here's a quick look at the main
priority levels it defines.

363
00:19:36,914 --> 00:19:41,474
First, it's user blocking the highest
priority tasks that directly affect user

364
00:19:41,474 --> 00:19:45,884
interaction, such as hand and clicks,
tops, and critical UI operations.

365
00:19:46,384 --> 00:19:50,824
Then user visible tasks that affect
UI visibility or content, but are

366
00:19:50,824 --> 00:19:52,774
not critical for immediate input.

367
00:19:53,274 --> 00:19:57,504
And the SEC and the third background
tasks that are non-agent and can be

368
00:19:57,504 --> 00:20:01,435
safely postponed without affecting
the current user experience and

369
00:20:01,465 --> 00:20:02,845
are not visible to the user.

370
00:20:03,625 --> 00:20:07,135
By default, scheduler yield
has a user visible priority.

371
00:20:07,735 --> 00:20:12,415
Also prioritized task scheduling
API exposes the post task method

372
00:20:12,774 --> 00:20:16,615
designated to schedule task with a
specified priority from the above.

373
00:20:17,245 --> 00:20:20,514
While it won't go into details
about this method here, it is worth

374
00:20:20,514 --> 00:20:24,445
mentioning that if scheduler yield
was scheduled from within a post

375
00:20:24,445 --> 00:20:26,695
task, it ensures its priority.

376
00:20:27,195 --> 00:20:31,425
So how to use scheduler yield, and
once you understand how it all works,

377
00:20:31,485 --> 00:20:35,055
the types of tasks, the problem caused
by long blocking operations and the

378
00:20:35,055 --> 00:20:38,175
priorities, the use of scheduler
yield becomes straightforward,

379
00:20:38,625 --> 00:20:39,825
but it should be used wisely.

380
00:20:39,855 --> 00:20:43,685
And with due caution, here is an
updated version of the heavy work

381
00:20:43,685 --> 00:20:45,784
function using scheduler yield.

382
00:20:45,995 --> 00:20:50,165
Now, instead of set time out, you just
need to call AWAI scheduler yield.

383
00:20:50,645 --> 00:20:53,554
And the rest part ment
change here and here.

384
00:20:53,735 --> 00:20:56,585
Instead of we just call
a wait, schedule a real.

385
00:20:57,085 --> 00:21:01,044
Now when a user starts a heavy work
function using scheduler yield, the

386
00:21:01,044 --> 00:21:02,754
different is immediately noticeable.

387
00:21:03,085 --> 00:21:05,544
Firstly, the okay button does not stick.

388
00:21:05,725 --> 00:21:09,564
And secondly, user click events on the
log button as successfully purchased,

389
00:21:09,895 --> 00:21:13,675
which does not blocked the user
interaction with the page that is.

390
00:21:13,675 --> 00:21:17,034
At first, the heavy work function
was launched and the button was

391
00:21:17,034 --> 00:21:18,355
re rendered without sticking.

392
00:21:18,895 --> 00:21:22,735
While the heavier task was being
executed, the user pressed the log button.

393
00:21:23,155 --> 00:21:26,965
They went, was processed successfully
and the data was printed to the console.

394
00:21:27,475 --> 00:21:30,535
Then the heavy work function
continued and this final result

395
00:21:30,535 --> 00:21:31,675
was printed to the console.

396
00:21:32,155 --> 00:21:34,945
After the completion, the user
press the log button again.

397
00:21:35,215 --> 00:21:39,235
In short, you can give your browser
a break with just one line, so you

398
00:21:39,235 --> 00:21:41,575
can see that there no UI freezes.

399
00:21:42,075 --> 00:21:44,385
We can see the look almost immediately.

400
00:21:44,885 --> 00:21:48,304
Now that we have explored the theory,
let's move on to the practice and

401
00:21:48,304 --> 00:21:49,835
look at the real working demo.

402
00:21:49,895 --> 00:21:51,995
This is a simulated banking complication.

403
00:21:52,355 --> 00:21:55,445
Of course, it's fictional and
simplified, but it captures just

404
00:21:55,445 --> 00:21:58,595
enough of the real world complexity
to help us understand how block and

405
00:21:58,595 --> 00:22:02,195
the main threat affects interactivity
and how schedule yield can help.

406
00:22:02,695 --> 00:22:05,065
Here's what the user
sees in the interface.

407
00:22:05,565 --> 00:22:06,495
Balance section.

408
00:22:06,555 --> 00:22:10,365
By default, the account balance is hidden
behind the plus holder of faster risk.

409
00:22:10,755 --> 00:22:14,145
This is a familiar pattern in the
real banking apps where sensitive

410
00:22:14,145 --> 00:22:17,985
information is hidden unless
explicitly revealed by the user.

411
00:22:18,705 --> 00:22:21,195
A button labeled show
balance to visibility.

412
00:22:21,695 --> 00:22:26,195
Next, a bank card, a visual representation
of a bank card shown from side by

413
00:22:26,195 --> 00:22:28,745
default where some details are displayed.

414
00:22:28,804 --> 00:22:30,695
Card type in the top left corner.

415
00:22:30,695 --> 00:22:34,534
Last four digit of the card holder's
name, and the payment system is

416
00:22:34,534 --> 00:22:36,445
the bottom right of the card.

417
00:22:36,594 --> 00:22:38,124
There are two buttons to the right of the.

418
00:22:39,040 --> 00:22:41,110
Show card details, which flip the card.

419
00:22:41,110 --> 00:22:44,710
One, click the backside of the card to
view sensitive card data like its full

420
00:22:44,710 --> 00:22:46,840
number, expiration date and serial code.

421
00:22:47,380 --> 00:22:50,770
Although the card number is generally
not considered private information,

422
00:22:50,770 --> 00:22:53,890
some applications still prefer not
to show the full number by default,

423
00:22:54,220 --> 00:22:55,900
but only the user initiates it.

424
00:22:56,260 --> 00:22:59,380
However, I know and even use the banks
that generally do not allow you to

425
00:22:59,380 --> 00:23:03,450
see the bank card number even in the
application and generate reports.

426
00:23:03,950 --> 00:23:06,830
By clicking this button, the
feature supposedly generates a list

427
00:23:06,830 --> 00:23:09,830
of transactions on the card and
display them in the table below.

428
00:23:10,310 --> 00:23:13,670
This imitates the real functionality
where a user can generate reports

429
00:23:13,670 --> 00:23:15,140
on the bond card transactions.

430
00:23:15,470 --> 00:23:19,010
In reality, these reports can be
complex tables with many customer

431
00:23:19,010 --> 00:23:22,310
visible filters and the ability to
download their reports as a file.

432
00:23:22,820 --> 00:23:26,570
Such operations might involve heavy
computations process, a huge amount of

433
00:23:26,570 --> 00:23:28,125
data making them resource intensive.

434
00:23:28,625 --> 00:23:32,854
And time consuming for the sake of the
demo, it's simplified under the hood.

435
00:23:32,854 --> 00:23:36,125
The generate report button triggers
a previously discussed heavy work

436
00:23:36,125 --> 00:23:39,754
function, which simply blocked the
main threat using the blocking task

437
00:23:39,754 --> 00:23:42,004
function, which was also discussable.

438
00:23:42,514 --> 00:23:46,235
After that static mock transaction
data, simply render it into the table.

439
00:23:46,735 --> 00:23:49,705
The behavior of the application
can be customized using the various

440
00:23:49,705 --> 00:23:51,354
settings of the configuration panel.

441
00:23:51,354 --> 00:23:55,854
On the left side, you may hear notice its
simplified version in earlier screenshots.

442
00:23:56,034 --> 00:23:57,564
Now it's time to explain what it does.

443
00:23:58,225 --> 00:24:01,735
Main thread blocking determines whether
the main thread will be blocked.

444
00:24:01,824 --> 00:24:05,844
In fact, when this option is enabled,
the blocking task function is executed.

445
00:24:06,774 --> 00:24:10,374
Scheduler yield, toggles where
the scheduler yield is used.

446
00:24:11,334 --> 00:24:16,524
Data Arit controls how many elements
are iterated by the heavy work function.

447
00:24:16,854 --> 00:24:18,925
The more elements, the longer it takes.

448
00:24:19,584 --> 00:24:23,904
Blocking time, durations specifies
how many milliseconds each element

449
00:24:23,904 --> 00:24:25,080
of the race takes to process.

450
00:24:25,580 --> 00:24:30,230
And the yield interval defines how
often scheduler yield is called as a

451
00:24:30,230 --> 00:24:32,120
percentage of progress through the array.

452
00:24:32,600 --> 00:24:35,659
That is the lower this number,
the more often it'll be called.

453
00:24:35,810 --> 00:24:39,770
In earlier example, we used a 200
element array with a 10 milliseconds

454
00:24:39,770 --> 00:24:43,070
delay and the 25% interval.

455
00:24:43,190 --> 00:24:47,720
A good balance for visible impact without
excessive delay with larger data sets,

456
00:24:47,810 --> 00:24:49,700
a smaller interval is often better.

457
00:24:50,120 --> 00:24:51,530
But as always, it depends.

458
00:24:52,030 --> 00:24:54,580
Here and sorted out all the
functionality and configuration.

459
00:24:54,580 --> 00:24:58,360
Let's walk through the real use user
scenario and see how blocking the main

460
00:24:58,360 --> 00:25:00,220
threat affect the user experience.

461
00:25:00,610 --> 00:25:04,240
To start, we enable main threat
blocking and disable schedule yield.

462
00:25:04,915 --> 00:25:08,965
We also increase the array lens a bit,
so the heavy operations take longer

463
00:25:08,965 --> 00:25:10,645
given as the time absorbs the effects.

464
00:25:11,124 --> 00:25:14,304
So the user clicks the generator
port button behind the scenes.

465
00:25:14,514 --> 00:25:18,895
This triggers the heavy work function,
which processes 1000 elements, where

466
00:25:18,895 --> 00:25:20,995
each element takes 10 milliseconds.

467
00:25:21,985 --> 00:25:22,945
Watch what happens.

468
00:25:23,604 --> 00:25:25,495
The generator port button stays stuck.

469
00:25:25,554 --> 00:25:28,104
It doesn't impress, and
the UI doesn't rear render.

470
00:25:28,434 --> 00:25:32,844
While the report is being generated, the
user tries to click the show card details,

471
00:25:33,264 --> 00:25:35,364
then the show balance buttons, but nice.

472
00:25:35,364 --> 00:25:37,884
In response, the interface
is completely frozen.

473
00:25:38,244 --> 00:25:41,394
There is no animation, no
feedback, no sense of progress.

474
00:25:41,754 --> 00:25:44,364
This is a classic example
of a bad user experience.

475
00:25:44,544 --> 00:25:47,604
The app appears frozen, even though
it's technically still working.

476
00:25:47,604 --> 00:25:50,994
The user doesn't know whether
to wait or load the page.

477
00:25:51,494 --> 00:25:54,524
And let's address these short
comments using scheduler yield

478
00:25:54,614 --> 00:25:56,474
by adjusting thumb configuration.

479
00:25:56,624 --> 00:25:58,784
Here's how the configuration now looks.

480
00:25:59,084 --> 00:26:00,674
The main threat is still blocked.

481
00:26:01,154 --> 00:26:03,854
This time, the option to use
scheduler yield is enabled.

482
00:26:04,244 --> 00:26:06,704
The rail lens is slightly
increased just for clarity.

483
00:26:07,274 --> 00:26:09,584
The blocking time remain
the same 10 milliseconds.

484
00:26:10,084 --> 00:26:15,004
The scheduler Ute response is interval
reduced to 5% for tho responsiveness,

485
00:26:15,004 --> 00:26:16,439
and the relevance has been increased.

486
00:26:16,939 --> 00:26:19,639
And now with the updated
configuration, the same user

487
00:26:19,639 --> 00:26:21,109
flow looks completely different.

488
00:26:21,409 --> 00:26:24,589
The third thing that catches the
eye is that after the generator port

489
00:26:24,589 --> 00:26:28,999
button has been clicked, it'll renders
correctly, and the load animation appears

490
00:26:29,449 --> 00:26:31,099
while the report is being generated.

491
00:26:31,129 --> 00:26:33,409
The user successfully
interacts with the ui.

492
00:26:33,709 --> 00:26:35,869
They can flip the card
and toggle the balance.

493
00:26:36,109 --> 00:26:37,609
The application remains responsive.

494
00:26:37,639 --> 00:26:41,509
Even if the animation are slightly
less smooth, it's a huge step forward

495
00:26:41,509 --> 00:26:42,494
compared to the previous freeze.

496
00:26:43,414 --> 00:26:45,124
This is a much better experience.

497
00:26:45,214 --> 00:26:48,304
The user is informed in control
and not let grace in whether

498
00:26:48,304 --> 00:26:50,164
the app is working and all.

499
00:26:50,164 --> 00:26:53,164
It was one method called
just Schedule a yield.

500
00:26:53,674 --> 00:26:58,084
Of course, the actual implementation can
be further optimized, but even this simple

501
00:26:58,084 --> 00:27:00,304
form, the differ difference striking.

502
00:27:00,804 --> 00:27:04,704
And as a conclusion, I want to say that
today you learned about giving your

503
00:27:04,704 --> 00:27:08,514
browser break the importance of yielding
to the main thread that perform higher

504
00:27:08,514 --> 00:27:12,384
priority task, and the advantages and
the disadvantages of these techniques.

505
00:27:13,329 --> 00:27:17,229
There are certainly more nuances to
cover and the prioritized task schedule

506
00:27:17,229 --> 00:27:22,569
and API has other capabilities that will
not code in this talk, but my goal was

507
00:27:22,569 --> 00:27:26,229
to give you a solid foundation enough
to start experimenting and enough to

508
00:27:26,229 --> 00:27:29,889
start thinking differently about how
your code plays with the browser.

509
00:27:30,369 --> 00:27:33,489
Thanks for your attention, and give
your browser a brick once in a while.

