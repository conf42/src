1
00:00:00,810 --> 00:00:01,320
Everyone.

2
00:00:01,500 --> 00:00:05,370
I'm Lolita Lanka, currently working
as a senior, a PN developer at

3
00:00:05,370 --> 00:00:07,080
US Food and Drug Administration.

4
00:00:07,500 --> 00:00:12,030
Today I'll be talking about scaling
AI in education through ML ops.

5
00:00:12,150 --> 00:00:16,200
Unlike enterprises, schools
face unique challenges such as

6
00:00:16,290 --> 00:00:20,730
limited budgets, diverse, revised,
and educators who aren't Mr.

7
00:00:20,730 --> 00:00:21,180
Engineers.

8
00:00:21,599 --> 00:00:25,770
And that's why we need a different
approach, like low-code platforms,

9
00:00:25,919 --> 00:00:29,880
privacy first design, and offline
ready architectures that make AI

10
00:00:29,880 --> 00:00:31,919
practical and inclusive for classrooms.

11
00:00:32,310 --> 00:00:35,550
Over the next few minutes, I will
walk you through the challenges,

12
00:00:35,640 --> 00:00:39,690
strategies, and results we have seen
in bringing ML ops to education.

13
00:00:41,415 --> 00:00:44,894
Welcome to today's session on
machine learning operation strategies

14
00:00:44,894 --> 00:00:46,995
tailored for educational environments.

15
00:00:47,205 --> 00:00:51,824
As AI and ML continue to evolve, it
is crucial for schools and educational

16
00:00:51,824 --> 00:00:56,565
institutions to embrace these
technologies despite resource constraints.

17
00:00:56,834 --> 00:01:01,065
In this presentation, we will explore
strategies that empower educational

18
00:01:01,065 --> 00:01:05,205
stakeholders to effectively integrate
AI tools into their institutions.

19
00:01:05,715 --> 00:01:10,665
We'll begin by examining the educational
ML ops landscape where we will discuss

20
00:01:10,665 --> 00:01:15,045
the unique challenges faced by schools
such as limited resources and the current

21
00:01:15,045 --> 00:01:16,905
gaps in technology infrastructure.

22
00:01:17,115 --> 00:01:22,395
Next, we will explore low-code
platforms as enablers, showcasing how

23
00:01:22,395 --> 00:01:26,670
these platforms can democratize AI
deployment, allowing non-technical

24
00:01:26,670 --> 00:01:28,485
users to take part in the process.

25
00:01:28,845 --> 00:01:33,315
This is an essential part of ensuring
that AI tools are accessible to everyone.

26
00:01:33,605 --> 00:01:36,035
Not just those with deep
technical expertise.

27
00:01:36,395 --> 00:01:41,615
Well then let dive into ML ops
Architecture for Education, where

28
00:01:41,615 --> 00:01:45,695
we will discuss the balance between
rapid AI development and the need

29
00:01:45,695 --> 00:01:49,775
for robust governance, security,
and compliance, which are often

30
00:01:49,775 --> 00:01:51,485
crucial in educational settings.

31
00:01:52,500 --> 00:01:56,370
We'll also highlight implementation
strategies, focusing on practical

32
00:01:56,370 --> 00:02:00,630
approaches like containerization
and federated learning, which can

33
00:02:00,630 --> 00:02:05,370
help schools implement AI solutions
effectively, even with limited resources.

34
00:02:05,580 --> 00:02:10,920
Finally, we will provide key takeaways
and future directions outlining actionable

35
00:02:10,920 --> 00:02:16,170
strategies that can directly apply to your
educational settings, helping you navigate

36
00:02:16,230 --> 00:02:20,940
the complexities of AI deployment and
setting the stage for future innovations.

37
00:02:22,815 --> 00:02:27,015
As educational institutions begin to
integrate artificial intelligence and

38
00:02:27,015 --> 00:02:31,274
machine learning technologies into their
operations and curricula, they face a

39
00:02:31,274 --> 00:02:35,744
unique set of challenges that are distinct
from those encountered in other sections.

40
00:02:36,045 --> 00:02:39,614
These challenges are influenced
by various factors such as budget

41
00:02:39,614 --> 00:02:44,505
constraints, infrastructure disparities,
and the need for specialized expertise.

42
00:02:45,060 --> 00:02:49,530
Unlike enterprise level AI
implementations, schools and universities

43
00:02:49,680 --> 00:02:54,780
must account for additional considerations
like governance, privacy, and the

44
00:02:54,780 --> 00:02:59,745
diverse technological environments in
in which these systems will be deployed.

45
00:03:00,690 --> 00:03:05,850
This slide outlines the key obstacles
educational institutions encounter when

46
00:03:05,910 --> 00:03:08,970
adopting AI system and ML Ops practices.

47
00:03:09,330 --> 00:03:13,020
Understanding these challenges is
the first step toward identifying

48
00:03:13,200 --> 00:03:18,330
solutions that can make AI deployment
accessible, affect you, and sustainable

49
00:03:18,480 --> 00:03:20,610
in schools and educational environments.

50
00:03:21,840 --> 00:03:24,480
Let's discuss the challenges
one by one with some examples.

51
00:03:24,840 --> 00:03:26,400
Infrastructure disparity.

52
00:03:26,760 --> 00:03:30,510
The infrastructure available in
educational institutions varies

53
00:03:30,510 --> 00:03:33,900
widely, especially between
urban and rural settings.

54
00:03:34,440 --> 00:03:37,980
In urban environments, schools may
have access to high speed internet

55
00:03:38,070 --> 00:03:40,050
and advanced computational resources.

56
00:03:40,080 --> 00:03:43,950
However, schools in rural
or underprivileged areas may

57
00:03:43,950 --> 00:03:47,490
struggle with limited internet
connectivity and outdated hardware.

58
00:03:47,820 --> 00:03:52,380
Example in well connected cities, a
school can deploy machine learning tools

59
00:03:52,380 --> 00:03:54,840
and cloud-based AI platforms seamlessly.

60
00:03:54,955 --> 00:03:59,010
However, a rural school in a
remote location may face difficult

61
00:03:59,040 --> 00:04:02,760
even accessing internet making
cloud-based AI solutions challenging.

62
00:04:03,285 --> 00:04:06,795
Additionally, high performance
computing infrastructures required

63
00:04:06,795 --> 00:04:11,865
for intensive machine learning tasks
might not be bio available, which would

64
00:04:11,865 --> 00:04:13,845
limit the AI system's effectiveness.

65
00:04:15,015 --> 00:04:17,505
The second is the
technical expertise gaps.

66
00:04:17,774 --> 00:04:21,495
Most educators are not trained in
specialized fields such as DevOps

67
00:04:21,675 --> 00:04:24,105
or machine learning engineering.

68
00:04:24,375 --> 00:04:28,185
As a result, they may lack the
necessary technical skills to

69
00:04:28,185 --> 00:04:32,265
implement, maintain, or even
troubleshoot AI solutions effectively.

70
00:04:32,835 --> 00:04:37,305
This skills gap makes it difficult to
leverage AI systems without external

71
00:04:37,305 --> 00:04:39,435
support or significant training.

72
00:04:39,735 --> 00:04:44,145
Example, a school that introduces
an AI powered educational tool to

73
00:04:44,145 --> 00:04:47,594
assist with grading and personalized
learning may find it difficult to

74
00:04:47,594 --> 00:04:51,315
handle technical issues such as
training new machine learning models,

75
00:04:51,585 --> 00:04:55,635
integrating the system with existing
platforms, or maintaining it over time.

76
00:04:56,010 --> 00:05:00,479
For instance, an AI tool that helps
with automating lessons, plans or

77
00:05:00,570 --> 00:05:05,370
grading may require constant updates and
maintenance, which requires technical

78
00:05:05,370 --> 00:05:07,335
expertise that may educators do not have.

79
00:05:08,865 --> 00:05:11,205
Third is strict governance and privacy.

80
00:05:11,565 --> 00:05:16,215
Educational institutions must adhere to
strict governance frameworks, especially

81
00:05:16,365 --> 00:05:18,284
when handling sensitive student data.

82
00:05:18,435 --> 00:05:23,205
This includes ensuring compliance with
privacy laws such as Family educational

83
00:05:23,205 --> 00:05:27,165
Rights and Privacy Act called third
part in the United States, which

84
00:05:27,165 --> 00:05:29,415
protects the privacy of student records.

85
00:05:29,745 --> 00:05:34,155
A systems in schools must comply with
these privacy standards to ensure that

86
00:05:34,155 --> 00:05:35,925
they do not violate student rights.

87
00:05:36,345 --> 00:05:40,545
Example, when planning an AI
power platform that analyzes

88
00:05:40,545 --> 00:05:44,655
student performances, it's crucial
to ensure that no unauthorized

89
00:05:44,655 --> 00:05:46,150
access to student record occurs.

90
00:05:46,920 --> 00:05:48,720
And the data is used appropriately.

91
00:05:49,140 --> 00:05:54,060
Any AI tool that process students'
data must have stringent access

92
00:05:54,060 --> 00:05:58,590
controls and security measures in
place to provide reaches or misuse.

93
00:05:58,620 --> 00:06:03,000
For example, a school should could use
a machine learning model to predict

94
00:06:03,000 --> 00:06:07,770
student success, but the model must
ensure the data, like grades, behavior,

95
00:06:07,770 --> 00:06:12,690
records, and other personal details remain
confidential and are securely stored.

96
00:06:13,859 --> 00:06:15,539
Next is the resource constraints.

97
00:06:15,929 --> 00:06:20,250
Many educational institutions operate
on limited budgets, which can restrict

98
00:06:20,250 --> 00:06:24,450
their ability to invest in dedicated
infrastructure or specialized

99
00:06:24,450 --> 00:06:27,030
personal for AI de deployments.

100
00:06:27,359 --> 00:06:31,530
This makes it challenging to purchase
the high end server software or

101
00:06:31,590 --> 00:06:35,400
professional development needed to
implement AI solutions effectively.

102
00:06:35,760 --> 00:06:39,960
Example, a small school district
might struggle to fund cloud-based

103
00:06:39,960 --> 00:06:40,859
machine learning services.

104
00:06:42,870 --> 00:06:47,909
As a result, they may have to rely on
low cost or open source platforms, which

105
00:06:47,909 --> 00:06:54,000
might not have the same functionality or
support as commercial systems for instead,

106
00:06:54,240 --> 00:06:58,770
instruc using a commercial AI based tool
for personalized learning, a school may

107
00:06:58,770 --> 00:07:03,630
have to use a simpler, free alternative
that lacks robust features or scalability.

108
00:07:04,200 --> 00:07:07,140
Finally, heterogeneous device ecosystems.

109
00:07:07,440 --> 00:07:11,430
In many educational settings, there is
a mix of different devices, laptops,

110
00:07:11,430 --> 00:07:15,840
desktops, tablets, and smartphones
that students and teachers use.

111
00:07:16,110 --> 00:07:20,010
These devices often have different
operating systems and performance

112
00:07:20,010 --> 00:07:24,750
capabilities, making it difficult
to standardize AI system deployments

113
00:07:24,810 --> 00:07:26,790
across the diverse device ecosystem.

114
00:07:27,120 --> 00:07:31,200
Example, a machine learning platform
designed for students may not be

115
00:07:31,200 --> 00:07:33,330
compatible with all devices in the school.

116
00:07:33,650 --> 00:07:38,120
For example, a high-end AI-based
educational application might run

117
00:07:38,120 --> 00:07:43,160
well on modern laptops, but perform
poorly or not at all on older

118
00:07:43,160 --> 00:07:45,500
tablets or low spec computers.

119
00:07:46,700 --> 00:07:50,990
Consider a scenario where a district
deploys an AI tool to monitor

120
00:07:50,990 --> 00:07:52,370
student progress in real time.

121
00:07:53,294 --> 00:07:56,895
The tool might work on newer Windows
laptops, but failed to perform as

122
00:07:56,895 --> 00:08:01,155
expected on outdated Chromebooks or
tablets, limiting its effectiveness

123
00:08:01,155 --> 00:08:02,835
across the entire student body.

124
00:08:03,405 --> 00:08:07,185
These unique challenges faced by
educational institutions require a

125
00:08:07,425 --> 00:08:10,935
tailored approach to ML ops, which
is significantly different from the

126
00:08:10,965 --> 00:08:14,835
typical enterprise implementations
used in larger corporations.

127
00:08:15,344 --> 00:08:19,515
Solutions that work in business often
cannot be directly applied to schools

128
00:08:19,515 --> 00:08:23,294
without considering the specific needs
and constraints of the education sector.

129
00:08:25,380 --> 00:08:29,520
Education focused ML ops strategies
should consider factors like limited

130
00:08:29,520 --> 00:08:34,140
technical expertise, tight budgets,
diverse devices, and the importance

131
00:08:34,140 --> 00:08:36,300
of strict privacy and governance.

132
00:08:36,330 --> 00:08:40,470
For example, local platforms or
hybrid cloud solutions can offer

133
00:08:40,470 --> 00:08:44,875
these more accessible, cost effective
parts for schools to integrate ai.

134
00:08:45,540 --> 00:08:50,310
By understanding these challenges and
adjusting strategies accordingly, schools

135
00:08:50,310 --> 00:08:55,319
can still unlock the potential of AI while
navigating these barriers effectively.

136
00:08:57,599 --> 00:09:01,560
Having discussed the broader challenges
in deploying AI systems in educational

137
00:09:01,560 --> 00:09:05,489
institutions such as infrastructure
disparities and limited expertise,

138
00:09:05,790 --> 00:09:09,420
it is important to understand that
the nature of data in these settings

139
00:09:09,420 --> 00:09:11,459
presents its own unique complexities.

140
00:09:12,795 --> 00:09:18,285
Educational data does not behave like data
from techn typical business environments.

141
00:09:18,315 --> 00:09:22,455
Instead, it exhibits distinct
patterns and constraints that impact

142
00:09:22,455 --> 00:09:26,295
how machine learning models are
trained, monitored, and maintained.

143
00:09:26,745 --> 00:09:30,465
In this slide, we will divide into
the data distribution challenges

144
00:09:30,555 --> 00:09:34,485
specific to educational setting and
how they require specialized approaches

145
00:09:34,485 --> 00:09:36,225
for effective AI implementation.

146
00:09:37,800 --> 00:09:39,330
Seasonal behavior patterns.

147
00:09:39,570 --> 00:09:42,270
Student interactions with
educational patterns.

148
00:09:42,840 --> 00:09:47,700
Platforms follow the academic calendar,
meaning usage spikes and drops aligned.

149
00:09:47,700 --> 00:09:51,990
Its semesters, holidays, and exam
periods, for example, during summer

150
00:09:51,990 --> 00:09:56,430
breaks or holiday seasons, platform
activity significantly decreases

151
00:09:56,580 --> 00:09:58,290
without accounting for this.

152
00:09:58,965 --> 00:10:02,655
AI models might mistake these
predictable changes for a problem

153
00:10:02,805 --> 00:10:07,185
with model accuracy, triggering false
alerts of model drift when the shift

154
00:10:07,185 --> 00:10:09,375
is actually natural and expected.

155
00:10:10,035 --> 00:10:14,985
Age-based distribution shifts as students
progress through different grade levels.

156
00:10:15,324 --> 00:10:17,995
Their learning behaviors and
interaction patterns evolve.

157
00:10:18,025 --> 00:10:22,465
For instance, a sixth graders engagement
style with digital content is quite

158
00:10:22,465 --> 00:10:26,454
different from that of a 12th graders
preparing for college entrance exams.

159
00:10:27,025 --> 00:10:30,295
AI system needs to distinguish
these natural ships from

160
00:10:30,564 --> 00:10:32,335
genuine performance degradation.

161
00:10:32,665 --> 00:10:37,885
Otherwise, a model trained on younger
students data might underperform or

162
00:10:37,885 --> 00:10:41,605
flag errors when applied to older
students leading to unnecessary

163
00:10:41,605 --> 00:10:43,510
training or inaccurate predictions.

164
00:10:44,985 --> 00:10:46,065
Limited data volume.

165
00:10:46,545 --> 00:10:50,925
Many smaller or rural schools
generate far less data than large

166
00:10:50,925 --> 00:10:54,885
urban schools due to fewer students
or less frequent platform use.

167
00:10:55,275 --> 00:11:00,405
Traditional AI monitoring techniques often
require large, statistically significant

168
00:11:00,405 --> 00:11:02,745
data sets to detect meaningful changes.

169
00:11:03,190 --> 00:11:08,560
In these cases, limited data volumes poses
a challenge, making it harder to identify

170
00:11:08,980 --> 00:11:13,240
real issues like model drift, which
requires tailored methods that affect

171
00:11:13,720 --> 00:11:16,300
work effectively with smaller data sets.

172
00:11:16,890 --> 00:11:20,940
By accounting for these unique data
distribution challenges like seasonal

173
00:11:21,000 --> 00:11:25,590
patterns, evolving student demographics
and data volume disparities, we can

174
00:11:25,590 --> 00:11:31,470
develop monitoring systems that accurately
detect genuine AI performance issues while

175
00:11:31,470 --> 00:11:36,660
minimizing false alarms and unnecessary
training re uh, retraining cycles.

176
00:11:36,990 --> 00:11:41,580
This approach is crucial to building
robust adaptive AI systems tailored

177
00:11:41,670 --> 00:11:43,830
for educational environments.

178
00:11:46,425 --> 00:11:50,745
After understanding the unique challenges
and data distribution issues based

179
00:11:50,745 --> 00:11:55,245
in educational ML ops, the question
arises, how can we overcome these

180
00:11:55,245 --> 00:11:59,775
hurdles, especially when technical
expertise and resources are limited

181
00:11:59,775 --> 00:12:01,485
in many educational institutions.

182
00:12:02,310 --> 00:12:07,500
This is where low-code platforms come into
play offering a transformative solution.

183
00:12:07,890 --> 00:12:12,030
These platforms are transforming
how AI is adopted in schools by

184
00:12:12,030 --> 00:12:15,900
making the process more accessible,
scalable, and collaborative.

185
00:12:16,290 --> 00:12:20,550
This is especially important because
many educational institute lack the

186
00:12:20,550 --> 00:12:24,960
specialized ML engineering resources
that typical enterprises may have.

187
00:12:26,130 --> 00:12:30,209
Let's explore how these platforms
drive democratization and

188
00:12:30,209 --> 00:12:32,400
scalability in educational mops.

189
00:12:33,180 --> 00:12:35,130
Empowering educators
without coding expertise.

190
00:12:36,510 --> 00:12:42,390
According to 2022, survey by EdTech
Magazine, 60% of schools reported lacking

191
00:12:42,390 --> 00:12:48,240
dedicated data scientists, orl engineers,
creating a major barrier to AI adoption.

192
00:12:48,780 --> 00:12:53,700
How low-code helped these platforms
provide drag and drop interfaces and

193
00:12:53,700 --> 00:12:58,830
pre-built AI components, enabling
educators to deploy AI models like

194
00:12:58,890 --> 00:13:02,775
student risk scoring or adaptive learning
recommendations without writing code.

195
00:13:03,495 --> 00:13:08,505
Example, new term and adapt to
learning platform enables teachers

196
00:13:08,505 --> 00:13:13,425
to customize content recommendations
via in Q2, interfaces boosting

197
00:13:13,485 --> 00:13:16,965
student engagement up to 24 5%.

198
00:13:17,355 --> 00:13:22,155
In a pilot program, a school district
reported that 70% of teachers could

199
00:13:22,155 --> 00:13:25,870
configure AI models independently
within two weeks of training.

200
00:13:28,140 --> 00:13:31,230
In Q2, visual interfaces for
configuration and monitoring.

201
00:13:31,770 --> 00:13:35,850
Real time MO modeling model monitoring
is essential for maintaining

202
00:13:35,850 --> 00:13:40,199
accuracy and avoiding false
alarms, especially with seasonal or

203
00:13:40,199 --> 00:13:42,569
demographic shift in student data.

204
00:13:43,020 --> 00:13:48,569
How low-code helps platforms like
Microsoft Azure ML Studio offer dashboards

205
00:13:48,569 --> 00:13:52,439
that let users at thresholds monitor
data drift and receive alerts visually.

206
00:13:53,565 --> 00:13:59,565
Example, a school system using Azure
ML reduced false positive alerts by

207
00:13:59,565 --> 00:14:04,755
40% by adjusting monitoring thresholds
via visual interface, allowing

208
00:14:04,815 --> 00:14:07,455
counselors to focus on genuine cases.

209
00:14:07,785 --> 00:14:12,255
Educators can tweak parameters
such as alert sensitivity in under

210
00:14:12,255 --> 00:14:17,895
five minutes without IT support
automating complex ML workflows.

211
00:14:20,220 --> 00:14:24,510
Traditional level ops pipelines require
manual handling of data ingestion, model

212
00:14:24,510 --> 00:14:29,130
retraining, validation, and deployment,
often needing weeks of effort per update.

213
00:14:29,460 --> 00:14:34,890
How low-code helps platforms like
Google Vertex AI automate retraining

214
00:14:34,890 --> 00:14:37,050
and redeployment when new data arrives?

215
00:14:37,050 --> 00:14:40,195
Ensuring models stay current
without manual intervention.

216
00:14:40,915 --> 00:14:46,075
Example, a pilot with the Midwestern
school district saw retraining

217
00:14:46,075 --> 00:14:49,795
times cut from two weeks to one
day using automated pipelines.

218
00:14:50,365 --> 00:14:54,985
This automation led to a 30%
increase in model accuracy for

219
00:14:54,985 --> 00:14:57,175
predicting student dropout risk.

220
00:14:57,235 --> 00:15:00,350
As models incorporated the
latest sinister data promptly.

221
00:15:01,454 --> 00:15:05,055
Built in governance and
compliance, why it matters.

222
00:15:05,415 --> 00:15:07,395
Educational data is highly sensitive.

223
00:15:08,025 --> 00:15:13,155
Compliance with laws like ferpa, which is
Family Educational Rights and Privacy Act

224
00:15:13,155 --> 00:15:16,454
in the US or GDPR in Europe, is mandatory.

225
00:15:16,995 --> 00:15:21,915
How low code helps platform enable
compliance mechanisms like data

226
00:15:22,484 --> 00:15:27,824
anonymization, role-based access controls,
audit trails directly into the workflows.

227
00:15:28,260 --> 00:15:33,780
Example, in a consortium of a hundred
plus students, a local platform, ensure

228
00:15:33,780 --> 00:15:38,280
a hundred percent compliance with FERPA
by automatically masking students'

229
00:15:38,310 --> 00:15:40,230
personal identification information.

230
00:15:40,470 --> 00:15:46,020
During AI model training and
inferences, schools avoided costly

231
00:15:46,020 --> 00:15:51,660
fines and reputational risks, saving
an estimated 500 K dollars annually

232
00:15:51,689 --> 00:15:54,090
in complaints related overhead.

233
00:15:54,795 --> 00:15:57,345
Reducing technical barriers and costs.

234
00:15:57,885 --> 00:16:00,855
The average cost to hire a
full-time ML engineer in the US

235
00:16:00,855 --> 00:16:03,645
exceeds one 20 K dollars per year.

236
00:16:03,825 --> 00:16:07,005
A prohibitive expense for many schools.

237
00:16:07,395 --> 00:16:11,205
How low code helps By minimizing
the need for specialized staff and

238
00:16:11,205 --> 00:16:15,415
infrastructure schools can implement
AI projects at a fraction of the cost.

239
00:16:16,005 --> 00:16:20,324
Example, a rural school district
within a budget under $1 million

240
00:16:20,355 --> 00:16:24,855
implemented predict two analytics for
student retention using a low-code

241
00:16:24,855 --> 00:16:29,295
platform for less than 15 K dollars
annually compared to a traditional bill

242
00:16:29,295 --> 00:16:31,845
estimated at over one 50 K dollars.

243
00:16:32,265 --> 00:16:37,454
This cost efficiency enabled them
to identify at risk students early,

244
00:16:37,515 --> 00:16:43,215
improving retention rates by 12%
within one academic year, facilitating

245
00:16:43,215 --> 00:16:44,625
collaboration between technical.

246
00:16:45,765 --> 00:16:47,265
Teams Insights.

247
00:16:47,595 --> 00:16:53,295
A 2023 report by the E-D-U-C-A-U-S-C
Center found that successful AI

248
00:16:53,295 --> 00:16:57,165
deployments in education requires
strong collaboration between

249
00:16:57,165 --> 00:16:58,965
educators and technical staff.

250
00:16:59,355 --> 00:17:03,490
How low-code helps shared platforms
with visual tools allow teachers

251
00:17:03,590 --> 00:17:06,015
and ML engineers to work in tandem.

252
00:17:06,405 --> 00:17:10,155
Teachers provide domain knowledge
and context contextual feedback

253
00:17:10,245 --> 00:17:12,045
while engineers handle model tuning.

254
00:17:12,479 --> 00:17:16,169
Example at a major urban school
district, a low-code platform

255
00:17:16,169 --> 00:17:20,909
reduced communication gaps, speeding
up AI project cycles by 15%.

256
00:17:22,290 --> 00:17:25,800
Teachers could adjust model parameters
based on classroom observations,

257
00:17:26,189 --> 00:17:30,570
leading to 20% higher accuracy in
personalized learning recommendations.

258
00:17:33,015 --> 00:17:37,065
Local platforms are not just simplifying
the low technical side of ai.

259
00:17:37,365 --> 00:17:41,985
They are fundamentally demo, demo,
democratizing it by making AI

260
00:17:41,985 --> 00:17:44,325
accessible, governable and collaborative.

261
00:17:44,805 --> 00:17:49,125
These platforms enable educational
institutions to leverage data-driven

262
00:17:49,125 --> 00:17:51,435
insights effectively and ethically.

263
00:17:51,855 --> 00:17:53,115
The result is a scalable.

264
00:17:53,685 --> 00:17:59,565
Cost effecti and impactful AI ecosystem
that helps educators focus on what

265
00:17:59,565 --> 00:18:02,325
matters most improving student outcomes.

266
00:18:04,515 --> 00:18:09,075
Now that we have discussed how to design
scalable and modular ML ops architectures

267
00:18:09,075 --> 00:18:13,815
for education, it's time to talk about
the most, one of the most non-negotiable

268
00:18:13,815 --> 00:18:18,915
elements of deploying AI in schools,
which is the privacy in education.

269
00:18:19,125 --> 00:18:21,285
Protecting student data isn't just.

270
00:18:22,365 --> 00:18:23,085
Best practice.

271
00:18:23,085 --> 00:18:27,375
It's a legal and ethical obligation
whether you are working in a public

272
00:18:27,375 --> 00:18:31,275
school in the US under Family
Educational Rights and Privacy Act

273
00:18:31,275 --> 00:18:36,855
called FERPA in Europe, under General
Data protection Regulation called GDPR,

274
00:18:37,155 --> 00:18:40,815
or in countries like India under the
Digital Personal Data Protection Act.

275
00:18:40,845 --> 00:18:42,015
D-P-D-P-A.

276
00:18:42,375 --> 00:18:46,185
Your ML ops pipelines must be
designed with privacy at the core.

277
00:18:46,890 --> 00:18:48,240
Data mining pipelines.

278
00:18:48,270 --> 00:18:50,040
Let's begin with data minimization.

279
00:18:50,040 --> 00:18:54,090
A core principle in privacy
law, the idea is very simple.

280
00:18:54,150 --> 00:18:55,620
Only use what is essential.

281
00:18:55,890 --> 00:19:00,360
For example, if you're training a model
to predict students dropout risk, you

282
00:19:00,360 --> 00:19:04,265
might not need full names, addresses, or
even attendance logs from early years.

283
00:19:05,155 --> 00:19:09,325
Many modern ML ops tools now
include pre-built data masking

284
00:19:09,355 --> 00:19:11,215
and anonymization features.

285
00:19:11,305 --> 00:19:15,265
For instance, a development deployment
in an Australian school district

286
00:19:15,265 --> 00:19:21,205
showed that using a minimized data
reduce exposure risk by 40% with no

287
00:19:21,205 --> 00:19:23,095
measurable drop in model accuracy.

288
00:19:24,705 --> 00:19:26,625
Differential privacy implementation.

289
00:19:26,985 --> 00:19:30,555
Differential privacy takes things
further by adding statistical noise

290
00:19:30,555 --> 00:19:34,995
to the data to prevent re reverse
engineering of individual identities.

291
00:19:35,985 --> 00:19:40,185
This is especially important in small
classroom data sets where there's a

292
00:19:40,185 --> 00:19:42,044
higher chance of re-identification.

293
00:19:42,555 --> 00:19:47,774
Google's educational AI lab ran a
pilot with differential privacy, was

294
00:19:47,774 --> 00:19:49,665
applied to student writing analysis.

295
00:19:49,695 --> 00:19:49,990
The result.

296
00:19:50,700 --> 00:19:56,010
Model performance by only 3.5%,
but zero personal traces could be

297
00:19:56,010 --> 00:19:58,620
reconstructed even by red team auditors.

298
00:19:58,980 --> 00:20:02,700
This is must have for national
exams, learning diagnostics,

299
00:20:02,760 --> 00:20:04,290
and performance dashboards.

300
00:20:04,889 --> 00:20:07,050
Third is a federated
learning architectures.

301
00:20:07,350 --> 00:20:13,139
Now let's revisit federated learning, but
from a privacy first perspective, rather

302
00:20:13,139 --> 00:20:17,190
than sending a raw data to the cloud,
models are trained locally on school

303
00:20:17,190 --> 00:20:20,040
servers or, or even teacher laptops.

304
00:20:21,360 --> 00:20:25,919
Only the learn weights, not the data
are sent back to the central system.

305
00:20:26,490 --> 00:20:30,240
A real world example comes from a
Canadian province where 42 schools

306
00:20:30,240 --> 00:20:34,980
participated in a federated model to
identify learning delays post COVID.

307
00:20:35,580 --> 00:20:38,544
This strategy preserved full
compliance with local privacy laws

308
00:20:38,554 --> 00:20:44,584
while improving predictive accuracy
by 16% over a centrally 10 baseline.

309
00:20:45,600 --> 00:20:50,130
On device inference prioritization on
device inference pushes the privacy

310
00:20:50,130 --> 00:20:55,410
boundary even further here, students'
data doesn't even leave the device

311
00:20:55,410 --> 00:21:00,000
at runtime models, run predictions
locally, for example, on a school

312
00:21:00,000 --> 00:21:04,230
tablet or a server making it I for
behavioral models or assessments.

313
00:21:04,770 --> 00:21:09,899
In Brazil, a school network used raspberry
pi clusters for local inference on

314
00:21:09,899 --> 00:21:12,600
student attention monitoring tools.

315
00:21:12,840 --> 00:21:17,399
This architecture allowed predictions
to stay entirely within the classroom,

316
00:21:17,399 --> 00:21:22,590
ensuring 99% of the data locality
even in low bandwidth environments.

317
00:21:23,730 --> 00:21:29,610
Conclusion why privacy first ML
lops is non negotiable in the

318
00:21:29,610 --> 00:21:33,990
enterprise world, privacy features
are often add-ons on upgrades.

319
00:21:34,395 --> 00:21:39,105
But in education, these are baseline
requirements, not optional layers as

320
00:21:39,105 --> 00:21:43,365
we move forward, privacy preserving
techniques like these must be embedded

321
00:21:43,365 --> 00:21:48,045
from the design phase of any ML
op workflows deployed in schools.

322
00:21:48,585 --> 00:21:52,215
Not only does this protect
institutions legally, but it also

323
00:21:52,215 --> 00:21:55,995
builds the trust that's essential
when students, parents and educators

324
00:21:56,235 --> 00:21:58,545
rely on AI to shape academic futures.

325
00:22:00,870 --> 00:22:05,100
Now that we have explored how to protect
privacy in ML ops pipelines, let's

326
00:22:05,100 --> 00:22:09,600
address another critical challenge in
educational i ai, which is the bias.

327
00:22:09,990 --> 00:22:11,790
Bias in educational AI doesn't.

328
00:22:12,585 --> 00:22:13,695
Just affect accuracy.

329
00:22:13,725 --> 00:22:18,075
It can amplify existing inequalities
from understanding the potential of

330
00:22:18,075 --> 00:22:22,245
students from certain backgrounds to
misrepresenting learning challenges

331
00:22:22,245 --> 00:22:24,254
due to language or age differences.

332
00:22:24,585 --> 00:22:26,475
Unfair morals can do real harm.

333
00:22:26,805 --> 00:22:31,065
So how do we catch and fix these
biases before they impact decisions?

334
00:22:31,575 --> 00:22:35,415
Through the automated bias detection
mechanisms, which are now being

335
00:22:35,415 --> 00:22:39,610
integrated directly into modern ML
O pipelines, this can be achieved.

336
00:22:41,160 --> 00:22:44,220
Multidimensional fairness
metrics in education.

337
00:22:44,220 --> 00:22:46,200
Fairness cannot be one dimensional.

338
00:22:46,620 --> 00:22:51,000
Models must be evaluated across multiple
access, including social, economic

339
00:22:51,000 --> 00:22:56,100
status, language proficiency, disability
status, and geographic location.

340
00:22:56,430 --> 00:23:00,150
For instance, in a New York pilot
study, a dropout prediction model

341
00:23:00,150 --> 00:23:04,740
showed 12 percentage performance
drop of students from English

342
00:23:04,740 --> 00:23:06,210
as second language backgrounds.

343
00:23:06,600 --> 00:23:10,410
By adding multidimensional fairness
checks, the school district corrected

344
00:23:10,410 --> 00:23:15,480
this by adding language based
feature and retain the model age

345
00:23:15,480 --> 00:23:17,280
appropriate evaluation frameworks.

346
00:23:17,639 --> 00:23:22,230
Models must be developmentally aware, a
10 year olds learning patterns difference

347
00:23:22,230 --> 00:23:24,091
dramatically from those of a 17-year-old.

348
00:23:24,570 --> 00:23:28,139
Yet many AI tool use static benchmarks.

349
00:23:28,350 --> 00:23:33,510
A good example in Finland bias
detection tools flag that reading

350
00:23:33,510 --> 00:23:37,740
comprehension models built for older
students were misclassifying, anger,

351
00:23:38,460 --> 00:23:43,770
anger learners as underperforming due
to natural vocabulary limitations after

352
00:23:43,770 --> 00:23:46,169
adjusting for age appropriate metrics.

353
00:23:46,350 --> 00:23:48,425
False negative rates drop by 22%.

354
00:23:48,885 --> 00:23:48,915
Okay.

355
00:23:49,995 --> 00:23:51,735
Next is the cultural context.

356
00:23:51,735 --> 00:23:56,235
Awareness bias doesn't, does,
uh, just come from data.

357
00:23:56,295 --> 00:23:58,335
It also comes from cultural misalignment.

358
00:23:58,335 --> 00:24:03,585
For example, a model trained in a Western
education system might misinterpret

359
00:24:03,585 --> 00:24:07,875
student silence as disengagement,
whereas in some eastern cultures, they

360
00:24:07,875 --> 00:24:10,060
may reflect, respect or contemplation.

361
00:24:12,030 --> 00:24:17,520
In India, a sentiment analysis based
feedback system had to be retained with

362
00:24:17,520 --> 00:24:23,190
regional linguistic nuance dataset after
it misread passive positive student

363
00:24:23,190 --> 00:24:25,500
responses as disengaged behavior.

364
00:24:26,040 --> 00:24:27,900
Local collaboration is essential.

365
00:24:28,470 --> 00:24:34,920
What works in Texas might not work in
Tokyo, CICD integration for bias testing.

366
00:24:35,970 --> 00:24:40,380
Here where ML Ops becomes powerful
bias detection shouldn't be a

367
00:24:40,380 --> 00:24:44,430
manual after, though it should
be part of your ci cd pipeline.

368
00:24:45,990 --> 00:24:49,380
Every time a model is retained,
train, or pushed to protection,

369
00:24:49,680 --> 00:24:54,090
a bias gate should check metrics
across all key demographics splits.

370
00:24:54,510 --> 00:24:59,790
Microsoft's Fail, learn, and Google's
What if tool offer integrations for this?

371
00:24:59,790 --> 00:25:02,835
Allowing real time flagging
when a model begins to diverge.

372
00:25:03,480 --> 00:25:09,510
One university deployment saw violations
reduced by 48% within six months just by

373
00:25:09,510 --> 00:25:12,030
implementing CI CD based fairness checks.

374
00:25:13,350 --> 00:25:14,220
Final message.

375
00:25:14,670 --> 00:25:18,990
If you want AI to be a force of
for equity in education, we must

376
00:25:18,990 --> 00:25:22,140
hardcode fairness into the every
stage of the model lifecycle.

377
00:25:22,860 --> 00:25:27,810
And thanks to low-code ML ops
platforms, these advanced tools, once

378
00:25:27,810 --> 00:25:32,490
the domain of AI research labs can now
be used by teachers, administrators,

379
00:25:32,490 --> 00:25:36,270
and education departments without
requiring heavy ML expertise.

380
00:25:38,820 --> 00:25:44,010
We have discussed bias, privacy, and
democratization in ML ops, but how

381
00:25:44,010 --> 00:25:48,270
do we actually structure ML ops to
support millions of students across

382
00:25:48,270 --> 00:25:51,540
different schools, districts, or even
countries with drivers infrastructure?

383
00:25:52,455 --> 00:25:56,235
This is where a distributed
ML ops architecture tailored

384
00:25:56,235 --> 00:25:57,735
for education comes into play.

385
00:25:58,215 --> 00:26:02,445
Unlike traditional centralized AI
pipelines, educational environments demand

386
00:26:02,625 --> 00:26:07,335
a balance of governance, scalability,
local autonomy, and data privacy.

387
00:26:07,485 --> 00:26:11,835
So let's explore how an adaptable
architecture works in this context.

388
00:26:12,225 --> 00:26:16,905
This slide outlines a scalable and
privacy conscious ML lops architecture,

389
00:26:17,115 --> 00:26:20,865
especially designed to meet the unique
needs of educational institutions.

390
00:26:22,410 --> 00:26:26,040
We are moving from a monolithic
cloud only approach to a layered

391
00:26:26,040 --> 00:26:30,150
distributed framework that accounts
for diverse connectivity levels,

392
00:26:30,390 --> 00:26:34,350
privacy mandates, operational
flexibility and scalability needs.

393
00:26:34,680 --> 00:26:38,580
Here is a layered architecture
breakdown, central training

394
00:26:38,580 --> 00:26:40,320
infrastructure district or native.

395
00:26:41,685 --> 00:26:45,915
This is a centralized brain for of
the architecture where AI models are

396
00:26:45,915 --> 00:26:48,014
trained, tested, and governed at scale.

397
00:26:48,435 --> 00:26:53,534
It acts as a central tower, enduring
consistency, compliancy, and reliability.

398
00:26:54,225 --> 00:26:55,995
The core functions are aggregates.

399
00:26:55,995 --> 00:26:58,485
An anonymized or synthetic student.

400
00:26:58,485 --> 00:27:02,685
Data from schools handles training,
retraining and version controls.

401
00:27:03,044 --> 00:27:07,814
Ensures complaints with loss like
used in US GDPR, from Europe,

402
00:27:08,175 --> 00:27:10,185
PIP, they from Canada, et cetera.

403
00:27:10,815 --> 00:27:15,495
Integrates bio detection, privacy,
preserving training and audit

404
00:27:15,495 --> 00:27:19,095
logging here is a real world case.

405
00:27:19,665 --> 00:27:23,925
The New York City Department of
Education runs centralized AI system to

406
00:27:23,925 --> 00:27:28,395
analyze student progress and learning
gaps across 1.1 million students.

407
00:27:28,695 --> 00:27:32,895
They use a custom ML ops platform
built on Azure and Databricks to

408
00:27:32,895 --> 00:27:34,605
ensure privacy and consistency.

409
00:27:35,220 --> 00:27:38,730
Second is the regional deployment
hubs, clusters, or province level.

410
00:27:39,330 --> 00:27:43,110
These apps as distribution notes
that cache models locally and

411
00:27:43,110 --> 00:27:48,600
support rapid low latency deployment
across geographically group schools.

412
00:27:49,140 --> 00:27:53,820
Main core functions are pre-stage
updated models and assets, perform

413
00:27:53,820 --> 00:27:58,050
local validation before full
deployment, and just model slightly

414
00:27:58,050 --> 00:28:02,490
for regional content or curriculum
differences, and act as intermediate

415
00:28:02,820 --> 00:28:04,560
repositories for edge deployment.

416
00:28:05,205 --> 00:28:10,215
Benefits are like minimizes van traffic,
which is wide area network traffic,

417
00:28:10,215 --> 00:28:14,890
enables differentiated rollout, simplifies
rollback in case of deployment issues.

418
00:28:16,680 --> 00:28:21,570
Here is a real old case scenario In
India's thumb, Nado State, a government

419
00:28:21,570 --> 00:28:26,580
backed EdTech system uses regional
data centers in Chennai and HOR to

420
00:28:26,580 --> 00:28:31,260
serve over 30,000 government schools
across diverse connectivity landscapes.

421
00:28:31,650 --> 00:28:36,120
Each hub handles localized distribution,
pushing updates to schools without

422
00:28:36,120 --> 00:28:37,665
overlaying central servers.

423
00:28:38,655 --> 00:28:45,045
Finally, the school level in inference
edge, ai, local devices, AI models

424
00:28:45,045 --> 00:28:47,205
are executed on local devices.

425
00:28:47,205 --> 00:28:52,695
Example, raspberry by tablets, school
servers, minimizing data transfer, and

426
00:28:52,695 --> 00:28:54,885
improving privacy and responsiveness.

427
00:28:55,125 --> 00:28:58,305
The core functions are performed
real time inference for things

428
00:28:58,305 --> 00:29:02,715
like student engagement, adaptive
learning recommendations, real time

429
00:29:02,715 --> 00:29:07,425
alert for learning difficulties,
retain raw student data locally.

430
00:29:08,175 --> 00:29:12,044
And provide offline support, which is
crucial in local connectivity areas.

431
00:29:13,274 --> 00:29:17,594
A real world case, uh, use case
for this category is in Rwanda.

432
00:29:17,834 --> 00:29:21,465
Over 1200 rural schools use
Raspberry Pi powered local AI

433
00:29:21,465 --> 00:29:24,044
models to assess literacy skills.

434
00:29:24,375 --> 00:29:29,415
Results are processed offline and sync
weekly when internet is available.

435
00:29:29,504 --> 00:29:33,524
This has reduced data
exfiltration risk by 85%.

436
00:29:35,024 --> 00:29:39,254
This architecture reflects the future
of ML ops in education privacy.

437
00:29:39,254 --> 00:29:43,575
First, locally adaptive, scalable,
and compliant designed for

438
00:29:43,575 --> 00:29:45,645
connectivity constraint environments.

439
00:29:45,915 --> 00:29:50,475
It empowers governments and schools
network to deploy fair, safe, and

440
00:29:50,475 --> 00:29:54,620
effective AI at scale, even in
resource constraint or remote areas.

441
00:29:57,930 --> 00:30:02,730
Let's now explore a crucial component
of ML ops in education, containerizing

442
00:30:02,730 --> 00:30:05,765
models, serving specifically
designed for offline capability.

443
00:30:06,885 --> 00:30:11,115
In many educational environments,
especially in rural district, low income

444
00:30:11,115 --> 00:30:16,305
regions or even urban schools, with
aging infrastructure, reliable internet

445
00:30:16,305 --> 00:30:18,525
access cannot be taken for granted.

446
00:30:19,005 --> 00:30:24,375
This reality makes cloud T AI
solutions impractical or inconsistent.

447
00:30:24,735 --> 00:30:26,110
So how do we overcome this?

448
00:30:26,655 --> 00:30:32,024
The answer lies in containerization, a
modern software packaging strategy that

449
00:30:32,024 --> 00:30:36,645
allows us to bundle AI models, runtime
environments, and dependence into a

450
00:30:36,645 --> 00:30:41,955
self-contained unit that can run reliably
on premise even without internet access.

451
00:30:42,660 --> 00:30:47,130
In educational ML ops, containerized
AI applications allow localized,

452
00:30:47,250 --> 00:30:51,660
secure, and consistent delivery
of AI services directly on school

453
00:30:51,660 --> 00:30:56,580
infrastructure, such as teacher laptops,
school servers, or student tablets.

454
00:30:56,880 --> 00:31:00,930
Here on the key implementation
strategies, lightweight container images,

455
00:31:00,960 --> 00:31:03,000
optimize it for educational hardware.

456
00:31:03,480 --> 00:31:05,910
The first pillar is minimizing
the weight of containers.

457
00:31:07,500 --> 00:31:12,450
Many schools still run on low spec
hardware, vehicle lightweight container

458
00:31:12,450 --> 00:31:14,760
images, often under one 50 mp.

459
00:31:15,000 --> 00:31:18,300
That can still deliver high
value a functions like grading,

460
00:31:18,300 --> 00:31:20,490
tutoring, or content recommendation.

461
00:31:20,760 --> 00:31:25,795
For example, a reading assessment
model was compressed using OS and

462
00:31:25,890 --> 00:31:29,520
QUANTIZE to eight bit precision,
allowing it to run smoothly on a

463
00:31:29,520 --> 00:31:31,715
raspberry PI four with two GB ran.

464
00:31:33,855 --> 00:31:35,115
Progressive model loading.

465
00:31:35,385 --> 00:31:38,385
Not all components of an AI
model needs to load at once.

466
00:31:38,655 --> 00:31:42,225
With progressive loading, we can
prioritize loading critical model

467
00:31:42,225 --> 00:31:46,815
components first, such as coding
or classification layers, and then

468
00:31:47,025 --> 00:31:50,955
gradually load personalization
modules or visualizations if and

469
00:31:50,955 --> 00:31:52,335
when resources are available.

470
00:31:53,055 --> 00:31:57,735
Think of it like an AI that gets smarter
the longer it turns, but never blocks

471
00:31:57,735 --> 00:31:59,925
learning even with minimal capability.

472
00:32:01,740 --> 00:32:05,460
In intelligence synchronization
protocols, when connectivity does

473
00:32:05,460 --> 00:32:09,475
return, we use synchronization
protocols that are smart and secure.

474
00:32:10,125 --> 00:32:13,815
These protocols, buffer data,
locally encrypted and attempt

475
00:32:13,815 --> 00:32:18,645
transition transmission only when
stable connectivity is detected.

476
00:32:18,915 --> 00:32:22,605
This ensures no student data
is lost, even if the device

477
00:32:22,605 --> 00:32:24,345
goes offline for days or weeks.

478
00:32:24,585 --> 00:32:29,175
In Ghana's Eastern Pilot Project
schools with only four hours of internet

479
00:32:29,175 --> 00:32:34,455
per week, still managed to sync over
93% of data logs using Delta updates

480
00:32:34,695 --> 00:32:36,975
and RESUMABLE protocols like syc.

481
00:32:38,805 --> 00:32:41,565
Local data caching with
privacy, preserving encryption.

482
00:32:42,045 --> 00:32:44,985
We don't just cache
data, we do it securely.

483
00:32:45,375 --> 00:32:49,965
Every interaction, score, or submission
is stored locally in encrypted form,

484
00:32:50,205 --> 00:32:55,635
often using a ES 2 56 or lightweight
homomorphic encryption methods.

485
00:32:55,995 --> 00:32:59,685
This protects sensitive educational
data even in shared classroom devices.

486
00:33:00,900 --> 00:33:02,670
Graceful degradation pathways.

487
00:33:02,970 --> 00:33:07,380
Finally, what happens if the AI model
fails to load fully due to power issues,

488
00:33:07,440 --> 00:33:09,480
hardware crashes, or memory constraints?

489
00:33:09,930 --> 00:33:14,610
We implement graceful degradation
where the system defaults to predefined

490
00:33:14,610 --> 00:33:19,680
rules, cache outputs, or static learning
content, ensuring the students experience

491
00:33:19,680 --> 00:33:21,185
is disrupted as little as possible.

492
00:33:22,274 --> 00:33:26,564
A practical example, if you're writing
feedback model crashes, the system can

493
00:33:26,564 --> 00:33:30,735
fall back to where Rubik based scoring
guide already embedded in the app.

494
00:33:31,335 --> 00:33:36,225
To summarize containerized modeling,
serving is not just a DevOps convenience.

495
00:33:36,225 --> 00:33:40,725
It's a strategic imperative for
ensuring that AI tools in education

496
00:33:40,845 --> 00:33:44,990
are accessible, resilient, and
equitable, especially in connecting

497
00:33:44,990 --> 00:33:46,830
connectivity constraint environments.

498
00:33:48,465 --> 00:33:52,095
And as we scale AI in education,
this approach will be the backbone

499
00:33:52,095 --> 00:33:55,815
for enabling consistency, privacy,
and functionality regardless of

500
00:33:55,815 --> 00:33:57,135
a school's internet bandwidth.

501
00:34:00,600 --> 00:34:04,590
Now that we have discussed deployment
and offline capabilities, let's focus

502
00:34:04,590 --> 00:34:09,300
on a, on a critical lifestyle component
for any AI system in education.

503
00:34:09,449 --> 00:34:14,610
Automated retraining, unlike
tactic software, AI model, lean

504
00:34:14,610 --> 00:34:18,929
from learn from data, but they
also become outdated over time.

505
00:34:19,439 --> 00:34:24,029
In education model, drift can be caused
by academic calendars, curriculum changes,

506
00:34:24,029 --> 00:34:28,139
seasonal learning behaviors, or even
localized student progress PA patterns.

507
00:34:29,399 --> 00:34:33,839
So how do we ensure our AI system remain
accurate, fair, and effective over time?

508
00:34:34,409 --> 00:34:38,310
The answer lies in building automated
retraining pipelines, customized

509
00:34:38,310 --> 00:34:42,179
for the operational and ethical
demands of educational environments.

510
00:34:42,750 --> 00:34:47,759
The cyclical nature of retraining
pipelines as shown in the graphic.

511
00:34:48,779 --> 00:34:52,830
The retraining process follows a
continuous loop that allows us to refresh

512
00:34:52,830 --> 00:34:57,480
our models in a privacy preserving
context, sensitive and scalable way.

513
00:34:57,990 --> 00:35:00,120
Let me walk you through
each phase of this pipeline.

514
00:35:00,330 --> 00:35:02,730
The first phase is the
scheduled data collection.

515
00:35:02,850 --> 00:35:04,049
It all starts with.

516
00:35:04,680 --> 00:35:08,549
Schedule data collection at regular
intervals, say monthly or quarterly.

517
00:35:08,759 --> 00:35:12,870
We aggregate anonymized model performance
logs from school infrastructure.

518
00:35:13,319 --> 00:35:17,640
These logs include accuracy of
predictions, confidence levels,

519
00:35:17,730 --> 00:35:19,799
engagement metrics, edge case flags.

520
00:35:20,009 --> 00:35:23,850
Importantly, this process must be
compliant with data privacy laws

521
00:35:23,850 --> 00:35:28,325
like FE, GDPR, or India's DPDP Act,
depending on where the schools are.

522
00:35:29,115 --> 00:35:33,645
We use differential privacy or federated
integration techniques so that student

523
00:35:33,645 --> 00:35:37,095
identifies never leave local devices.

524
00:35:38,384 --> 00:35:43,665
Next comes distribution analysis where
we compare current data distribution

525
00:35:43,725 --> 00:35:45,225
to those from previous cycles.

526
00:35:45,404 --> 00:35:50,085
For instance, a model train in February
may begin underperforming in June due

527
00:35:50,085 --> 00:35:53,985
to exam stress, summer learning loss,
or changes in students' engagement.

528
00:35:54,525 --> 00:35:58,575
Drift Detection in education is
complex because you need to account for

529
00:35:58,845 --> 00:36:00,945
seasonality and economic performance.

530
00:36:01,275 --> 00:36:04,365
Separate natural learning
progression from true model drift,

531
00:36:04,755 --> 00:36:08,745
detect regional disparities in
how AI is used or interpreted.

532
00:36:09,165 --> 00:36:12,285
This is where education specific
drift detection frameworks become

533
00:36:12,285 --> 00:36:16,305
essential, not just traditional
K tests or care divergence.

534
00:36:18,195 --> 00:36:19,485
The next step in the.

535
00:36:20,535 --> 00:36:24,705
Framework is the contextual retraining,
rather than retraining the entire

536
00:36:24,705 --> 00:36:29,475
model, we use contextual retraining
approaches, which means we target only

537
00:36:29,475 --> 00:36:31,214
on the underperforming components.

538
00:36:31,214 --> 00:36:36,705
Example, feedback modules, prediction
heads focus on effective student segments.

539
00:36:36,734 --> 00:36:40,095
Example, grade five, ESL,
learnings in roller clusters.

540
00:36:40,395 --> 00:36:43,060
This saves compute, avoids over.

541
00:36:43,860 --> 00:36:47,190
Fitting and ensure more
localized and equitable updates.

542
00:36:47,340 --> 00:36:52,170
For example, in one district pilot,
only 11% of the models parameters

543
00:36:52,170 --> 00:36:56,400
had to be updated to correct bias
against neuro divergent learners.

544
00:36:57,509 --> 00:36:59,250
Multidimensional validation.

545
00:36:59,730 --> 00:37:03,390
Once retrained, the module undergoes
multidimensional validation.

546
00:37:03,720 --> 00:37:05,970
This testing isn't just about accuracy.

547
00:37:06,180 --> 00:37:10,740
We look at fairness across gender,
linguistic background, disability

548
00:37:10,740 --> 00:37:13,470
status, interpretability metrics.

549
00:37:14,550 --> 00:37:17,490
Example, it's a model's
feedback, actionable

550
00:37:19,980 --> 00:37:23,130
bias, or its using synthetic
counterfactual data.

551
00:37:23,790 --> 00:37:29,130
A retrained model that performs well
only for urban students, but degrades

552
00:37:29,130 --> 00:37:33,000
for rural schools is immediately
flagged in real world deployments.

553
00:37:33,270 --> 00:37:39,090
Models that pass five plus geo, geo,
uh, demographic, uh, validations

554
00:37:39,090 --> 00:37:44,370
were found to main gain up to 97%
Fairness, parity in public school

555
00:37:44,370 --> 00:37:46,950
settings, graduated deployment.

556
00:37:46,980 --> 00:37:50,010
Finally, we don't roll
out changes instantly.

557
00:37:50,415 --> 00:37:52,875
We use grad, graduated deployment.

558
00:37:53,174 --> 00:37:56,924
Start with pilot schools, monitor
outcomes for two, three weeks.

559
00:37:57,015 --> 00:38:00,134
Get feedback from educators and
school admins, then roll out to

560
00:38:00,134 --> 00:38:01,995
the broader district or region.

561
00:38:02,355 --> 00:38:06,044
This prevents mass failure and
ensures human oversight at each step.

562
00:38:08,235 --> 00:38:12,404
Why this matters in education,
unlike tech tech companies that can

563
00:38:12,404 --> 00:38:16,365
retain models nightly with millions
of realtime users, school operates

564
00:38:16,365 --> 00:38:18,165
on slower structural timelines.

565
00:38:18,435 --> 00:38:20,085
You must respect the economic year.

566
00:38:20,115 --> 00:38:22,545
Student stability and policy constraints.

567
00:38:22,904 --> 00:38:27,045
These retaining pipelines balance
automation with caution, ensuring that

568
00:38:27,045 --> 00:38:31,180
AI tool remains relevant and useful
updates don't introduce new bias.

569
00:38:31,860 --> 00:38:35,250
The system evolves with
students not ahead of them.

570
00:38:35,970 --> 00:38:40,350
In short, automated retraining
pipelines make educational AI systems

571
00:38:40,590 --> 00:38:42,750
adaptive, safe, and sustainable.

572
00:38:43,080 --> 00:38:48,330
They help us avoid model dk, uphold
ethical standards, and deliver consistent

573
00:38:48,330 --> 00:38:52,080
personalized support to students,
whether in a major urban school or

574
00:38:52,080 --> 00:38:54,180
a remote classroom in the mountains.

575
00:38:57,045 --> 00:39:01,095
As we move from retraining pipelines,
let's now look at how large scale

576
00:39:01,095 --> 00:39:05,415
collaboration across multiple schools
can be made, both powerful and privacy

577
00:39:05,625 --> 00:39:07,605
respecting through federated learning.

578
00:39:08,595 --> 00:39:12,165
Unlike traditional AI models that
rely on sending raw data to the cloud,

579
00:39:12,165 --> 00:39:14,385
federated learning flips the script.

580
00:39:14,625 --> 00:39:17,515
The model goes to the data instead
of the data going to the model.

581
00:39:18,495 --> 00:39:20,505
What is Federated Learning in Education?

582
00:39:20,985 --> 00:39:25,065
Federated Learning is a decentralized
machine learning approach where local

583
00:39:25,065 --> 00:39:29,295
models are trained on individual
school devices and only model

584
00:39:29,295 --> 00:39:33,134
updates, not student data, are
shared back to the central system.

585
00:39:33,945 --> 00:39:37,905
This is especially, especially crucial
in education because schools are

586
00:39:37,905 --> 00:39:41,985
spread across district with different
resources, bandwidths and IT policies.

587
00:39:43,274 --> 00:39:45,734
Students data is highly
sensitive and centralizing.

588
00:39:45,734 --> 00:39:50,234
It creates compliance risk in
rural and underserved regions.

589
00:39:50,234 --> 00:39:54,044
Connectivity is sporadic,
but learning must continue.

590
00:39:55,245 --> 00:39:56,919
Let's break down how it works in practice.

591
00:39:58,065 --> 00:40:00,194
Local model training on school devices.

592
00:40:00,524 --> 00:40:04,274
Each school trains its version on
model locally using only the student

593
00:40:04,274 --> 00:40:06,285
data available within its premises.

594
00:40:06,705 --> 00:40:10,575
We a smart tablet or a school
server or a classroom AI assistant.

595
00:40:10,754 --> 00:40:14,265
For example, a middle school in
a tier three city can train a

596
00:40:14,265 --> 00:40:18,674
reading comprehension model using
their own data on device, capturing

597
00:40:18,674 --> 00:40:22,694
local essence, reading patterns
and curriculum specific nuances.

598
00:40:23,520 --> 00:40:25,740
Encrypted parameter sharing one.

599
00:40:25,740 --> 00:40:26,880
Local training completes.

600
00:40:26,880 --> 00:40:30,990
Instead of sending raw data, each school
sends only encrypted model updates

601
00:40:30,990 --> 00:40:32,670
to the district coordination server.

602
00:40:33,330 --> 00:40:37,770
These updates could be gradient vectors,
weight, weight changes, performance

603
00:40:37,770 --> 00:40:43,785
deltas all transmissions use end-to-end
encryption, such as TLS 1.3, and a S 2

604
00:40:43,785 --> 00:40:49,080
56, and often pass through zero trust
architecture, ensuring the process

605
00:40:49,080 --> 00:40:51,570
is tamper resistant and auditable.

606
00:40:53,129 --> 00:40:56,790
Differential private receive
integration to award the risk of

607
00:40:56,790 --> 00:41:00,509
reverse engineering student information
from gradients, which is possible.

608
00:41:00,509 --> 00:41:05,490
In NA federated setups, we implement
differential privacy mechanisms.

609
00:41:05,879 --> 00:41:09,899
This involves adding calibrated noise
to model updates so that no single

610
00:41:09,899 --> 00:41:12,060
student contribution can be identified.

611
00:41:12,779 --> 00:41:16,350
Even if a malicious actor access
the updates, they would learn

612
00:41:16,350 --> 00:41:18,270
nothing individual or identifiable.

613
00:41:19,185 --> 00:41:24,765
This satisfies legal mandates in
GDPR Article 25, which is Privacy by

614
00:41:24,765 --> 00:41:29,174
Design, F-E-R-P-A, which is Student
Educational Records protection, and

615
00:41:29,174 --> 00:41:34,095
India's D-P-D-P-A 2023, which is local
storage and processing of personal data.

616
00:41:35,564 --> 00:41:38,354
Next is the adapt to AG
aggregation, strateg.

617
00:41:38,790 --> 00:41:42,150
Once updates from all the schools
are received, the central server

618
00:41:42,150 --> 00:41:43,980
does not average them equally.

619
00:41:44,520 --> 00:41:48,060
Instead, we use adapt to aggregation,
which takes into account,

620
00:41:48,060 --> 00:41:52,380
vary school sizes, demographic
diversities, update trustworthiness.

621
00:41:52,710 --> 00:41:57,330
These strategies ensure fair
representation across districts.

622
00:41:57,690 --> 00:41:59,915
Low-code in interface for simplicity.

623
00:42:01,830 --> 00:42:05,550
To make federated learning accessible
to non-technical educators, we use

624
00:42:05,550 --> 00:42:09,690
low-code platforms like automate
training, job triggers, visualize

625
00:42:09,690 --> 00:42:14,100
model performance for per school,
provide compliance ready logs require

626
00:42:14,100 --> 00:42:16,260
no advanced DevOps or ML expertise.

627
00:42:16,860 --> 00:42:19,950
This is critical for scaling
federated learning in real world

628
00:42:19,950 --> 00:42:23,610
school system, many of which lack
full-time data science staff.

629
00:42:24,375 --> 00:42:28,125
To sum up, federated learning is
not just a technical innovation,

630
00:42:28,125 --> 00:42:29,265
it's a governance breakthrough.

631
00:42:30,105 --> 00:42:34,005
It allows us to honor privacy laws,
leverage local intelligence, and

632
00:42:34,005 --> 00:42:37,125
enable district-wide learning,
progresses through collaborative

633
00:42:37,125 --> 00:42:39,075
intelligence, not centralized control.

634
00:42:41,700 --> 00:42:45,540
Up to this point, we have talked about
architectures, privacy deployment

635
00:42:45,540 --> 00:42:47,520
strategies for AI in education.

636
00:42:47,820 --> 00:42:52,440
But an equivalent important pillar of
ML Ops is monitoring, making sure our

637
00:42:52,440 --> 00:42:56,850
models and systems continue to perform as
expected once they're in real world use.

638
00:42:57,675 --> 00:43:02,205
Now in the most enterprise environments,
monitoring is somewhat easier because

639
00:43:02,205 --> 00:43:04,095
the devices are relatively standardized.

640
00:43:04,395 --> 00:43:08,565
Servers in data centers or companies
show laptops with similar configurations.

641
00:43:08,955 --> 00:43:10,575
Education is very different.

642
00:43:10,605 --> 00:43:16,485
Schools operate on on shoestring budgets,
often relying on a mix of newer devices,

643
00:43:16,485 --> 00:43:21,105
older desktop, shared lab machines,
and even students' personal devices.

644
00:43:21,435 --> 00:43:24,945
This creates what we call the
heterogeneous device ecosystem.

645
00:43:25,335 --> 00:43:26,145
Why does that matter?

646
00:43:27,450 --> 00:43:30,960
Because traditional one size fits
all, monitoring does not work here.

647
00:43:31,319 --> 00:43:36,060
If we push enterprise grade monitoring
tools onto low end machines, they

648
00:43:36,060 --> 00:43:37,620
will struggle just to keep up.

649
00:43:38,100 --> 00:43:41,549
On the other hand, if we only apply
lightweight monitoring everywhere,

650
00:43:41,610 --> 00:43:44,549
we lose the deep visibility needed
for high performance systems.

651
00:43:44,895 --> 00:43:49,185
So the real challenging is finding
a balance, designing, monitoring

652
00:43:49,185 --> 00:43:53,445
strategies that respect device diversity,
keep system relatable and remain

653
00:43:53,445 --> 00:43:57,285
accessible to non-technical stakeholders
like teachers and administrators.

654
00:43:57,705 --> 00:44:01,335
On this slide, I will walk you
through four key strategies that

655
00:44:01,335 --> 00:44:05,535
make monitoring both practical and
inclusive in educational environments.

656
00:44:06,915 --> 00:44:11,925
Resource aware metrics collection,
what it means, monitoring systems

657
00:44:11,985 --> 00:44:13,700
adapt to the capability of each device.

658
00:44:14,340 --> 00:44:15,270
And how it works.

659
00:44:15,420 --> 00:44:19,110
High-end servers can collect
detailed metrics, while older

660
00:44:19,110 --> 00:44:22,950
laptops may only track essentials
like uptime and memory usage.

661
00:44:23,370 --> 00:44:28,590
Example, in a rural school with decade
old desktops, only basic health checks

662
00:44:28,590 --> 00:44:31,020
run, so learning apps remains usable.

663
00:44:31,170 --> 00:44:35,759
Meanwhile, an urban school with newer
hardware track advanced telemetry like GP

664
00:44:35,759 --> 00:44:42,570
utilization for AI driven tutoring apps,
device specific performance baselines.

665
00:44:42,615 --> 00:44:47,115
What it means, each device type
has its own normal performance

666
00:44:47,115 --> 00:44:48,854
thresholds and how it works.

667
00:44:49,095 --> 00:44:52,995
Instead of using one benchmark across
all devices, the system knows that a

668
00:44:52,995 --> 00:44:57,134
Chromebook should not be expected to run
at the same speed as a lab workstation.

669
00:44:57,705 --> 00:45:02,354
Example, a math learning app runs slower
on a low cost tablet, but that's expected.

670
00:45:03,435 --> 00:45:06,555
The baseline is adjusted to
avoid constant false alarms.

671
00:45:06,615 --> 00:45:07,395
At the same time.

672
00:45:07,665 --> 00:45:10,904
If the same slowdown happens on
a powerful lab pc, the system

673
00:45:10,904 --> 00:45:12,314
flag, it is a real issue.

674
00:45:14,009 --> 00:45:17,130
Centralized monitoring
dashboards what it means.

675
00:45:17,550 --> 00:45:21,509
Complex monitoring data is transformed
into simple visual insights through

676
00:45:21,509 --> 00:45:23,880
low-code dashboards and how it works.

677
00:45:24,240 --> 00:45:27,240
Teachers or administrators see
color-coded health indicators,

678
00:45:27,330 --> 00:45:29,730
trend lives or alerts of roll logs.

679
00:45:30,600 --> 00:45:35,880
And an example for this, a district admin
logs into a dashboard and sees school

680
00:45:35,880 --> 00:45:40,230
is devices are healthy, but school based
hitting memory limits on older laptops.

681
00:45:40,590 --> 00:45:44,550
This empowers them to act maybe
by shifting workloads or prior

682
00:45:44,850 --> 00:45:48,029
prioritizing an upgrade without
needing deep technical expertise.

683
00:45:48,480 --> 00:45:51,060
And finally, automated intervention works.

684
00:45:51,420 --> 00:45:51,870
Flows.

685
00:45:52,350 --> 00:45:53,220
What does this mean?

686
00:45:53,490 --> 00:45:57,569
The system can respond automatically to
detect tissues, reducing downtime and

687
00:45:57,569 --> 00:46:00,450
dependency on it staff and how it works.

688
00:46:00,839 --> 00:46:05,250
Predefined rule, trigger actions like
rolling back a buggy model, reducing batch

689
00:46:05,250 --> 00:46:08,100
sizes, or switching to offline cache data.

690
00:46:08,775 --> 00:46:09,765
Example for this.

691
00:46:10,005 --> 00:46:13,695
If a school's internet drops,
the AI app automatically switches

692
00:46:13,695 --> 00:46:15,075
to offline inference mode.

693
00:46:15,405 --> 00:46:19,425
Or if a new model starts slowing
down old machines, the system auto

694
00:46:19,695 --> 00:46:22,990
automatically reverts to a previous
table version until it reviews it.

695
00:46:25,065 --> 00:46:29,295
These four strategies, adaptive metrics,
tailored baselines, educator friendly

696
00:46:29,295 --> 00:46:34,035
dashboards, and automated interventions
together ensure that monitoring isn't just

697
00:46:34,035 --> 00:46:36,375
technically effective, but also practical.

698
00:46:36,375 --> 00:46:40,185
In resource constraints schools,
the goal is resilience, keeping AI

699
00:46:40,185 --> 00:46:44,745
systems running smoothly, even in S and
unpredictable classroom environments.

700
00:46:47,330 --> 00:46:50,415
We have looked at architectures
and monitoring, but a key question

701
00:46:50,415 --> 00:46:53,595
many institutions have is, how
do we actually get started?

702
00:46:54,404 --> 00:46:58,395
Implementing ML ops in education
isn't a one step process.

703
00:46:58,395 --> 00:47:01,395
It needs to be staged carefully
because schools have limited

704
00:47:01,395 --> 00:47:05,565
resources wearing technical skills
and strict privacy requirements.

705
00:47:06,015 --> 00:47:10,335
This roadmap breaks the journey
into four clear phases, foundation.

706
00:47:11,175 --> 00:47:12,555
Scale and optimization.

707
00:47:13,065 --> 00:47:14,655
Each phase builds on the last.

708
00:47:14,745 --> 00:47:18,525
Ensuring institutions can start
small, prove value, and then

709
00:47:18,525 --> 00:47:22,395
expand sustainably without
overwhelming their teams or budgets.

710
00:47:22,665 --> 00:47:27,915
Phase one, the foundation, what it is,
setting up the initial low-code ml, lops

711
00:47:27,915 --> 00:47:30,435
platform privacy frameworks and training.

712
00:47:30,825 --> 00:47:34,335
This focuses on building a
secure foundation before scaling.

713
00:47:36,120 --> 00:47:40,380
And in the example for this, a
districts in a low-code AI platform

714
00:47:40,380 --> 00:47:45,270
that trains a small group of educators
and IT staff to manage deployments.

715
00:47:45,570 --> 00:47:48,735
Privacy measures like differential
privacy and access controls are

716
00:47:48,995 --> 00:47:50,820
ap, uh, are established upfront.

717
00:47:51,750 --> 00:47:54,150
The phase second phase
is the pilot deployment.

718
00:47:54,750 --> 00:47:58,500
What it is running small scale
pilots in selected schools with

719
00:47:58,500 --> 00:47:59,940
different resource profiles.

720
00:48:00,615 --> 00:48:05,444
This focuses on testing containerized,
model serving basic monitoring

721
00:48:05,505 --> 00:48:06,884
and governance workflows.

722
00:48:07,095 --> 00:48:09,735
And an example for this
is a rural school test.

723
00:48:09,735 --> 00:48:14,505
Offline ready AI models to handle poor
internet via an urban school test.

724
00:48:14,505 --> 00:48:18,915
Federated learning for scaling the
pilot reveals practical constraints like

725
00:48:18,975 --> 00:48:21,404
certain devices needing lighter models.

726
00:48:22,904 --> 00:48:24,404
The third is a scaled rollout.

727
00:48:25,560 --> 00:48:30,509
What it is, expanding deployment
district-wide with localized adaptations.

728
00:48:30,839 --> 00:48:34,920
This focuses on standardizing
governance, integrated federated learning

729
00:48:34,920 --> 00:48:36,569
for collaboration across schools.

730
00:48:36,690 --> 00:48:41,640
And example, once pilots succeed,
the district rolls out AI assisted

731
00:48:41,640 --> 00:48:43,259
learning apps to all schools.

732
00:48:43,589 --> 00:48:48,390
Models are turned differently
depending on bandwidth, but all share

733
00:48:48,450 --> 00:48:49,785
updates through federated learning.

734
00:48:50,285 --> 00:48:53,190
And the final stage is
the optimization phase.

735
00:48:54,705 --> 00:48:57,674
This is the continuous improvement
through retraining and education

736
00:48:57,674 --> 00:49:01,995
specific monitoring and focuses on
fine tuning, automated retraining

737
00:49:01,995 --> 00:49:03,435
pipelines and dashboards.

738
00:49:03,765 --> 00:49:07,305
Example, the system detects
that match models underperformed

739
00:49:07,305 --> 00:49:08,475
for younger students.

740
00:49:08,835 --> 00:49:12,555
A target retraining cycle is launched
and dashboards are updated to

741
00:49:12,555 --> 00:49:16,455
highlight grade level performance
differences for administrators.

742
00:49:18,690 --> 00:49:23,610
This phase roadmap ensures institutions
do not try to boil the ocean from day one.

743
00:49:23,820 --> 00:49:28,890
Instead, delay a strong foundation,
test and control pilots expand in a

744
00:49:28,890 --> 00:49:34,260
managed way, and then continuously
optimize This approach delivers immediate

745
00:49:34,320 --> 00:49:39,540
wins while building toward long-term
scalable AI adoption in education.

746
00:49:41,685 --> 00:49:46,245
Up until now, we have explored challenges,
architectures monitoring, and the roadmap

747
00:49:46,245 --> 00:49:48,375
for rolling out ML lops in schools.

748
00:49:48,675 --> 00:49:51,885
But at the end of the day, the most
important question people ask is,

749
00:49:51,885 --> 00:49:54,315
does this really work in real world?

750
00:49:55,259 --> 00:49:58,680
This slide captures the outcomes
we have seen when districts

751
00:49:58,680 --> 00:50:00,180
adopted these approaches.

752
00:50:00,600 --> 00:50:04,379
What's powerful here is that the
results span technical reliability,

753
00:50:04,680 --> 00:50:07,020
cost efficiency, and human engagement.

754
00:50:07,379 --> 00:50:11,190
In other words, it's not just about
keeping AI running, it's about

755
00:50:11,190 --> 00:50:14,790
keeping teachers and students engaged
while saving schools money and

756
00:50:14,790 --> 00:50:20,370
staying compliant and with privacy
regulations offline real reliability.

757
00:50:20,790 --> 00:50:21,990
What does this mean?

758
00:50:22,319 --> 00:50:27,450
AI tools continue functioning even during
internet disruptions and why it matters.

759
00:50:27,690 --> 00:50:30,930
Many schools, especially rural
ones, face bandwidth issues.

760
00:50:31,230 --> 00:50:36,509
An example, a literacy is assist app in
a rural district kept working seamlessly

761
00:50:36,509 --> 00:50:41,759
during outages because of contain, uh,
containerized offline inference, ensuring

762
00:50:41,759 --> 00:50:43,290
students didn't lose learning time.

763
00:50:44,564 --> 00:50:47,084
Resource utilization, what it means?

764
00:50:47,475 --> 00:50:51,104
Optimized edge deployment reduces
computing loads and costs.

765
00:50:51,165 --> 00:50:52,245
And why does it matter?

766
00:50:52,515 --> 00:50:55,604
Schools operate on tight
budgets with limited hardware.

767
00:50:56,174 --> 00:51:00,975
An example, by using lightweight
containerized models, one district reduces

768
00:51:01,484 --> 00:51:05,354
server costs and extended the usable
life of older laptops by two years.

769
00:51:06,885 --> 00:51:08,985
The next one is a
non-technical engagement.

770
00:51:09,195 --> 00:51:10,155
What does it mean?

771
00:51:10,515 --> 00:51:14,055
Educators and administrators
actively participate in AI governance

772
00:51:14,055 --> 00:51:18,345
through low-code tools and why it
matters without engaging educators.

773
00:51:18,345 --> 00:51:21,225
AI remains a black box
and risk low adoption.

774
00:51:21,615 --> 00:51:26,235
Example, teachers use a dashboard
to tweak content delivery thresholds

775
00:51:26,235 --> 00:51:28,550
without calling it directly
improving classrooms engagement.

776
00:51:30,405 --> 00:51:34,605
Implementation impact AI tools
scaled across multiple districts

777
00:51:34,605 --> 00:51:36,135
serving millions of students.

778
00:51:36,855 --> 00:51:41,025
Consistency, maintained model performance
in bandwidth constrained environments.

779
00:51:41,925 --> 00:51:46,935
Teachers adjusted AI recommendations
without coding regulatory compliance.

780
00:51:46,935 --> 00:51:50,445
Met privacy regulations across
regions using federated learning

781
00:51:50,445 --> 00:51:52,305
and differential privacy.

782
00:51:52,965 --> 00:51:56,835
Reduce the technical burden,
self-healing deployment architectures

783
00:51:56,835 --> 00:51:58,040
maintain it interventions.

784
00:51:59,325 --> 00:52:03,045
These results prove that when we
design ML lops for education with

785
00:52:03,045 --> 00:52:07,425
low-code privacy, offline capability,
and inclusivity, it's not just theory.

786
00:52:07,425 --> 00:52:11,475
It leads to a real world impact
keeping students learning, saving

787
00:52:11,475 --> 00:52:14,655
schools money, empowering teachers,
and ensuring compliance at scale.

788
00:52:17,445 --> 00:52:17,880
Now we have.

789
00:52:19,215 --> 00:52:22,305
We have now walked through the
educational ML ops landscape,

790
00:52:22,335 --> 00:52:26,175
the challenges schools face, the
architectures that can work, and even

791
00:52:26,175 --> 00:52:28,215
real world results from implementations.

792
00:52:28,545 --> 00:52:32,475
But I know that in a fast moving
conference setting like this, it's

793
00:52:32,535 --> 00:52:33,975
easy to get lost in the detail.

794
00:52:34,395 --> 00:52:38,085
So I want to step back and highlight
the three key takeaways that really

795
00:52:38,085 --> 00:52:39,615
capture the essence of the entire talk.

796
00:52:40,365 --> 00:52:43,185
These are the principles
that should guide everyone.

797
00:52:43,515 --> 00:52:47,535
Anyone trying to scale AI
responsibly in education?

798
00:52:47,955 --> 00:52:52,035
Think of them as a north star,
simple, practical, and non-negotiable.

799
00:52:52,515 --> 00:52:57,765
If schools or districts follow these,
they won't just deploy a, they'll deploy

800
00:52:57,765 --> 00:53:02,565
AI that's sustainable, equitable, and
trusted by educators and students alike.

801
00:53:03,870 --> 00:53:05,549
Low-code empowers education.

802
00:53:06,029 --> 00:53:09,000
One of the most important points
is that low-code platforms

803
00:53:09,330 --> 00:53:11,129
break down technical barriers.

804
00:53:11,580 --> 00:53:15,000
Instead of relying solely on
machine learning engineers, which

805
00:53:15,000 --> 00:53:19,020
schools rarely have teachers and
administrations can participate directly

806
00:53:19,020 --> 00:53:20,940
in AI deployment and governance.

807
00:53:21,330 --> 00:53:25,799
This democratization makes adoption
much more feasible In education.

808
00:53:26,009 --> 00:53:29,220
Example, a teacher adjusts
content delivery thresholds in

809
00:53:29,220 --> 00:53:32,310
a dashboard, improving students'
engagement without any coding.

810
00:53:33,600 --> 00:53:37,230
Privacy first by design In
education, privacy is not optional.

811
00:53:37,230 --> 00:53:41,759
It's mandatory by integrating federated
learning, differential privacy

812
00:53:41,759 --> 00:53:45,450
and data minimization, pipelines
From the very beginning, schools

813
00:53:45,450 --> 00:53:48,990
can protect sensitive student data
while still leveraging AI insight.

814
00:53:49,950 --> 00:53:54,569
Example, instead of sending raw student
data to the cloud, only encrypted model

815
00:53:54,569 --> 00:53:56,190
updates are shared across schools.

816
00:53:56,490 --> 00:53:59,430
And finally, offline Functionality is key.

817
00:53:59,910 --> 00:54:02,910
Connectivity can be taken for
granted, especially in rural

818
00:54:03,360 --> 00:54:04,890
or underserved districts.

819
00:54:05,250 --> 00:54:09,120
Containerized serving with local
inference ensures AI tools keep

820
00:54:09,120 --> 00:54:11,279
working even without reliable internet.

821
00:54:11,549 --> 00:54:14,250
This isn't just a nice to have,
it's a critical requirement

822
00:54:14,250 --> 00:54:15,299
for equity in education.

823
00:54:16,005 --> 00:54:20,775
Example, a rural schools AI tutoring
system continues guiding students

824
00:54:20,865 --> 00:54:25,065
during an internet outage, syncing
updates later when the network returns.

825
00:54:25,515 --> 00:54:29,025
So to sum it up, AI and
education must be inclusive.

826
00:54:29,265 --> 00:54:34,785
Privacy first and T local code EM empowers
educators to take part privacy, safeguard,

827
00:54:34,785 --> 00:54:38,535
build trust, and offering capabilities,
ensure no student is left behind.

828
00:54:39,195 --> 00:54:44,445
If we design with these principles, AI
can truly scale across education in a way

829
00:54:44,595 --> 00:54:47,595
that is sustainable, far and impactful.

830
00:54:49,635 --> 00:54:51,555
That brings me to the end of my talk.

831
00:54:51,795 --> 00:54:54,885
I want to sincerely thank you all
for your time and attention today.

832
00:54:55,245 --> 00:54:58,485
Educational ML Ops is not
just a technical challenge.

833
00:54:58,545 --> 00:55:03,045
It's about making AI accessible,
equitable, and sustainable for teachers

834
00:55:03,045 --> 00:55:04,845
and students who need it to the most.

835
00:55:05,265 --> 00:55:09,645
My hope is that you leave here with
a few ideas on how local platforms,

836
00:55:10,125 --> 00:55:13,755
privacy first design, and often
functionality can come together to

837
00:55:13,760 --> 00:55:16,125
truly, truly democratize AI in education.

838
00:55:16,725 --> 00:55:20,625
I would also like to thank conference
42 for creating this platform to

839
00:55:20,625 --> 00:55:24,795
share ideas and all of you for
thoughtful discussion and innovations

840
00:55:25,005 --> 00:55:26,445
you will take forward from here.

841
00:55:26,715 --> 00:55:29,110
Thank you, and I would be
happy to take any questions.

