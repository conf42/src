1
00:00:00,000 --> 00:00:00,600
Hello.

2
00:00:00,700 --> 00:00:01,569
my name is Prashant.

3
00:00:01,670 --> 00:00:04,280
I work as a principal member of
technical staff at Salesforce.

4
00:00:04,580 --> 00:00:08,540
and I'm going to talk about how to
use Kubernetes for machine learning.

5
00:00:09,050 --> 00:00:10,580
so let's get started with it.

6
00:00:11,009 --> 00:00:12,899
so this is, this will be
the agenda of our session.

7
00:00:12,930 --> 00:00:15,110
We'll be talking about, the introduction.

8
00:00:15,629 --> 00:00:19,349
Then we'll be talking about why water is
Kubernetes and why we need Kubernetes.

9
00:00:19,709 --> 00:00:22,740
We'll also touch upon the concepts
of the machine learning lifecycle

10
00:00:22,740 --> 00:00:25,410
and the benefits of using
Kubernetes for machine learning.

11
00:00:26,040 --> 00:00:30,440
And then we'll try to discuss some of the
core concepts of, Kubernetes, especially

12
00:00:30,440 --> 00:00:31,880
from a machine learning point of view.

13
00:00:32,450 --> 00:00:36,080
we'll also try to understand some of
the core platform tools that have been

14
00:00:36,080 --> 00:00:39,800
developed on Kubernetes, which are
very specific to machine learning or

15
00:00:39,800 --> 00:00:43,160
deep learning, where we'll be talking
about cube flow to be very specific.

16
00:00:43,425 --> 00:00:45,555
Cube Flow is just not a framework.

17
00:00:45,555 --> 00:00:48,615
It's a platform combining
multiple different tools together.

18
00:00:49,185 --> 00:00:52,755
We'll just look at, a simple
training example that, we can

19
00:00:52,755 --> 00:00:54,545
use, on Kubernetes with cube flow.

20
00:00:54,945 --> 00:00:57,645
then we'll be talking about some of
the best practices and real world

21
00:00:57,645 --> 00:01:00,345
use cases, and we'll be ending
the session with future trends.

22
00:01:00,675 --> 00:01:01,995
it's going to be a little bigger session.

23
00:01:02,025 --> 00:01:04,635
I'm going to concentrate on a
lot of theoretical concepts.

24
00:01:04,770 --> 00:01:08,830
hopefully one day I'll get a chance
to, present my workshop with Con 42.

25
00:01:09,260 --> 00:01:10,910
and having said that, let's move on.

26
00:01:11,330 --> 00:01:15,900
as most of I think by now, with all the
chat Gpt, Claudes and other Lums out

27
00:01:15,900 --> 00:01:20,490
there, there is an AI revolution going
on and with this create AI revolution.

28
00:01:20,695 --> 00:01:24,265
there comes the need of great
infrastructure too, and the

29
00:01:24,295 --> 00:01:26,125
optimal usage of infrastructure.

30
00:01:26,405 --> 00:01:30,245
saving the costs at the same time,
saving the energy at the same time,

31
00:01:30,245 --> 00:01:31,865
and doing things more ethically.

32
00:01:32,345 --> 00:01:37,005
And, we will talk about, how we can
do this with Kubernetes, how we can do

33
00:01:37,005 --> 00:01:41,085
all these things that I've been talking
about with Kubernetes and why Kubernetes

34
00:01:41,085 --> 00:01:44,925
is a pivotal concept or a pivotal
framework, or a pivotal platform for

35
00:01:44,925 --> 00:01:46,605
doing machine learning or deep learning.

36
00:01:47,235 --> 00:01:50,805
just to revise a lot of bottlenecks
that happen with machine

37
00:01:50,805 --> 00:01:51,825
learning and deep learning.

38
00:01:52,095 --> 00:01:55,455
The traditional infrastructures
that a lot of these organizations

39
00:01:55,455 --> 00:02:00,075
have are, face, a lot of issue when
they need to scale up or scale down.

40
00:02:00,465 --> 00:02:03,585
especially in scenarios where there's
a huge traffic that is coming to them.

41
00:02:04,155 --> 00:02:06,795
now how to handle this and
all is what we are gonna talk

42
00:02:06,795 --> 00:02:08,175
about this se in this session.

43
00:02:08,275 --> 00:02:09,565
let's move on to the next slide.

44
00:02:09,875 --> 00:02:13,325
what does Kubernetes, I think most of
you who are listening to this session

45
00:02:13,415 --> 00:02:16,565
might have already worked on Kubernetes,
or you might be new to Kubernetes.

46
00:02:16,730 --> 00:02:20,930
But yeah, for someone who is really new
to Kubernetes, Kubernetes is an open

47
00:02:20,930 --> 00:02:23,360
source container orchestration platform.

48
00:02:23,760 --> 00:02:26,790
that's a bigger word, but if anyone of
you have already worked with Docker,

49
00:02:26,850 --> 00:02:30,270
you already know about containers,
but Kubernetes allows you to take

50
00:02:30,270 --> 00:02:34,170
the concept of the containers to next
level by automating a lot of things.

51
00:02:34,410 --> 00:02:37,140
It introduced the concepts of,
it introduces the concepts of

52
00:02:37,170 --> 00:02:40,170
deployments, rollbacks services.

53
00:02:40,565 --> 00:02:44,475
Stateful sets, demon sets and other
thing, a lot of other things into it.

54
00:02:44,525 --> 00:02:46,655
but what does Kubernetes
bring to the table?

55
00:02:46,660 --> 00:02:50,465
By, by orchestrating this containers, the
first thing is it simplifies the process

56
00:02:50,465 --> 00:02:51,725
of running your applications right?

57
00:02:51,755 --> 00:02:55,175
You can simply run your application
by packaging it as a docker image

58
00:02:55,235 --> 00:02:57,155
and writing a couple of VL files.

59
00:02:57,785 --> 00:03:01,830
It is also very reliable in the sense
that when you deploy your application to

60
00:03:01,920 --> 00:03:06,390
Kubernetes, it takes care of it, it does
the autoscaling, it does the horizontal

61
00:03:06,390 --> 00:03:08,130
autoscaling, the vertical autoscaling.

62
00:03:08,370 --> 00:03:12,680
it takes, it makes sure that, it tries
to keep your application as much as

63
00:03:12,680 --> 00:03:15,440
possible and scale it appropriately.

64
00:03:15,620 --> 00:03:19,970
It has, it does container rollbacks,
container restarts, container, crash.

65
00:03:19,970 --> 00:03:22,310
Look bags when a crash look back
is happening when you're coming.

66
00:03:22,370 --> 00:03:25,250
What I mean by crash look back is when
your container is failing for some reason,

67
00:03:25,490 --> 00:03:27,230
it tries to bring back the containers.

68
00:03:27,800 --> 00:03:30,530
So the key features of Kubernetes,
although I'm not trying to list

69
00:03:30,530 --> 00:03:34,030
all of them here, given the space
constraints and everything else, is it.

70
00:03:34,350 --> 00:03:36,570
It supports automated deployments.

71
00:03:36,570 --> 00:03:40,170
You, there are several tools out there
like Helm, customize several other things

72
00:03:40,170 --> 00:03:44,620
that allow you to package your, package
your deployment, and allow you to do

73
00:03:44,620 --> 00:03:46,630
different kinds of automated deployments.

74
00:03:47,050 --> 00:03:49,450
It allows service discovery
through its services.

75
00:03:49,450 --> 00:03:51,670
It has a built in load
balancer that is service.

76
00:03:51,670 --> 00:03:55,600
It comes in the form of a service, as
it spoke about, it has self-healing

77
00:03:55,600 --> 00:03:58,900
and fall tolerance, so it does, it
make, makes sure that it maintains

78
00:03:58,900 --> 00:04:00,490
a minimum number of replicas.

79
00:04:00,770 --> 00:04:03,740
and it also brings up the new
number of containers required.

80
00:04:03,740 --> 00:04:05,390
Minimum number of pods required.

81
00:04:05,390 --> 00:04:08,720
POD is the basic unit
of operation Kubernetes.

82
00:04:09,080 --> 00:04:11,570
and finally it takes care of
resource management and scaling.

83
00:04:12,070 --> 00:04:15,864
I. Before we go and talk about why
machine learning has to be done on

84
00:04:15,864 --> 00:04:19,794
Kubernetes, or what are the benefits of
doing machine learning or deep learning?

85
00:04:20,065 --> 00:04:22,164
When I say deep learning,
everything from neural networks

86
00:04:22,164 --> 00:04:23,934
to self attention to transformers.

87
00:04:23,934 --> 00:04:25,824
why we should be doing that on Kubernetes?

88
00:04:25,884 --> 00:04:29,454
We'll just try to quickly understand
at a very high level of how a machine

89
00:04:29,454 --> 00:04:30,714
learning lifecycle looks like.

90
00:04:31,254 --> 00:04:34,104
And machine learning lifecycle
starts with data, right?

91
00:04:34,104 --> 00:04:37,044
You get the data from your
customers or from your, from

92
00:04:37,044 --> 00:04:38,484
whatever data sources you have.

93
00:04:38,884 --> 00:04:42,064
You try to clean that data or
prepare the data for training, right?

94
00:04:42,064 --> 00:04:46,399
Preparing data is a multi-step process,
but, but at a very high level, preparing

95
00:04:46,399 --> 00:04:50,469
data involves scaling your parameters,
bringing them all to the same scale.

96
00:04:50,749 --> 00:04:55,129
converting the alpha numerics or
alphabets into numerics and so on, right?

97
00:04:55,129 --> 00:04:57,649
So that's what the data
phase is all about.

98
00:04:57,919 --> 00:05:00,229
And then you do the
training on the data, right?

99
00:05:00,229 --> 00:05:01,394
So you choose the appropriate.

100
00:05:01,914 --> 00:05:04,104
Training model to train your data.

101
00:05:04,464 --> 00:05:07,494
And there are several hundred algorithms
which are available out there.

102
00:05:07,494 --> 00:05:10,914
Platforms like hugging Face host
a ton of models that you can use.

103
00:05:11,334 --> 00:05:12,954
then you perform the
model validation, right?

104
00:05:12,954 --> 00:05:15,684
You check for the performance
accuracy, the confusion,

105
00:05:15,684 --> 00:05:17,154
metrics, everything else, right?

106
00:05:17,154 --> 00:05:19,434
You check for how well
your model is performing.

107
00:05:19,584 --> 00:05:23,464
And finally you deploy a model
into production, for deployment,

108
00:05:23,464 --> 00:05:25,144
also for model deployment also.

109
00:05:25,644 --> 00:05:28,044
There are several tools that are available
for deploying your models into production.

110
00:05:28,374 --> 00:05:31,294
and once you deploy your models
into production, you spend

111
00:05:31,294 --> 00:05:32,704
time monitoring it, right?

112
00:05:32,704 --> 00:05:36,064
You try to monitor your model, and
then you repeat the process back again.

113
00:05:36,064 --> 00:05:39,264
You keep fine tuning your models
every day with newer data or

114
00:05:39,839 --> 00:05:41,039
you have a chron schedule.

115
00:05:41,039 --> 00:05:43,949
And according to chron schedule,
you keep refining your data.

116
00:05:44,449 --> 00:05:46,129
Now let's talk about the problem, right?

117
00:05:46,129 --> 00:05:47,659
So what is the current problem?

118
00:05:47,809 --> 00:05:48,439
What is the problem?

119
00:05:48,439 --> 00:05:52,249
If you don't use Kubernetes, or if you're
trying to do machine learning on your

120
00:05:52,309 --> 00:05:56,199
own massive, massive machine learning
on your own first party clusters.

121
00:05:56,409 --> 00:05:58,239
Now first thing is data volume, right?

122
00:05:58,519 --> 00:06:03,469
as more and more data as you start saving
more and more data, obviously there's

123
00:06:03,469 --> 00:06:04,939
a lot of strain on your infrastructure.

124
00:06:04,939 --> 00:06:07,669
You have restore this data somewhere,
you transform this data somewhere.

125
00:06:08,509 --> 00:06:12,199
Now you can always provision the
entire infrastructure at once.

126
00:06:12,259 --> 00:06:14,769
Keep the infrastructure
empty and just do it.

127
00:06:14,819 --> 00:06:18,349
based on, based on the kind of,
the volume of data you receive.

128
00:06:18,859 --> 00:06:21,619
You can also end up having a very
small infrastructure and you end

129
00:06:21,619 --> 00:06:22,999
up receiving large volumes of data.

130
00:06:23,029 --> 00:06:23,959
All right.

131
00:06:23,959 --> 00:06:25,279
And how does Kubernetes solve it?

132
00:06:25,279 --> 00:06:29,299
Let's talk about it in the upcoming slides
and the computational intensity, right?

133
00:06:29,329 --> 00:06:32,799
a lot of, deep learning models on
neural networks today required a GPO.

134
00:06:32,859 --> 00:06:35,619
Having said that, would you really
buy all the GP ahead and keep it

135
00:06:35,719 --> 00:06:38,589
on your first party data centers
or anywhere, or anywhere on the

136
00:06:38,589 --> 00:06:40,629
cloud in the form of EC2 machines.

137
00:06:40,954 --> 00:06:43,414
So that, that's a lot of, lots
of cost to your company, right?

138
00:06:43,414 --> 00:06:45,904
So how do you handle this
computation industry?

139
00:06:45,904 --> 00:06:47,374
There are lows and highs.

140
00:06:47,464 --> 00:06:51,184
During the peak periods, you might
require a lot of GPU, a lot of CPU, but

141
00:06:51,184 --> 00:06:53,914
during the non-peak period, you don't
require a lot of GPU, a lot of CPU.

142
00:06:53,914 --> 00:06:54,994
You wanna save your cost.

143
00:06:55,624 --> 00:06:57,424
There's also deployment complexity, right?

144
00:06:57,424 --> 00:06:59,764
So when you deploy a machine
learning model, you need to

145
00:06:59,764 --> 00:07:01,354
have an inference endpoint.

146
00:07:01,354 --> 00:07:05,374
You need to have a proper influencing
backend where you deploy a model.

147
00:07:05,704 --> 00:07:06,634
So again, the.

148
00:07:06,999 --> 00:07:09,219
During peak periods, how do you handle it?

149
00:07:09,219 --> 00:07:12,009
You have to, everything has
to be scaled very efficiently.

150
00:07:12,059 --> 00:07:15,619
And finally, the co, the cost involved
in all these kinds of resource management

151
00:07:15,619 --> 00:07:17,059
that we have been talking about, right?

152
00:07:17,159 --> 00:07:20,549
so we have to efficiently allocate
resources to all these workloads.

153
00:07:20,575 --> 00:07:23,515
Which is very important so that you
can maximize the performance and you

154
00:07:23,515 --> 00:07:24,865
can reduce the cost at the same time.

155
00:07:25,705 --> 00:07:28,885
Now, this is a general problem with
any scaling machine learning workloads.

156
00:07:28,914 --> 00:07:29,275
It does.

157
00:07:29,275 --> 00:07:32,034
I'm not saying that Bernet is going
to solve all these problems for you,

158
00:07:32,424 --> 00:07:37,765
but Kubernetes allows you to make
right decisions and it provides you

159
00:07:37,765 --> 00:07:41,275
several avenues by which you can
easily solve all these problems.

160
00:07:41,775 --> 00:07:42,284
and then, yeah.

161
00:07:42,315 --> 00:07:45,874
now a question about why I should use
Kubernetes for machine learning, Um.

162
00:07:46,750 --> 00:07:48,400
the first thing is scalability, right?

163
00:07:48,405 --> 00:07:51,700
As you saw, as you're speaking about, you
can dynamically scale up and scale down.

164
00:07:51,720 --> 00:07:55,395
we'll have a couple of other slides which
talk about benefits, but at a, roughly, at

165
00:07:55,395 --> 00:07:59,715
a very high level, scalability, resource
management, portability and automation

166
00:07:59,715 --> 00:08:04,005
are the four biggest things, according
to me, which Kubernetes provides you.

167
00:08:04,185 --> 00:08:06,645
Now let's dive deep into
each one of those, right?

168
00:08:06,645 --> 00:08:08,145
So first is scalability, right?

169
00:08:08,425 --> 00:08:10,915
as I said, during the peak
periods, you might want to scale,

170
00:08:11,415 --> 00:08:12,705
you might want to auto scale.

171
00:08:12,975 --> 00:08:15,945
autoscale vertically, you want
to, you might want to autoscale

172
00:08:15,975 --> 00:08:19,275
horizontally or you might need
to introduce GPUs right now.

173
00:08:19,275 --> 00:08:20,715
Kubernetes with Kubernetes, right?

174
00:08:20,715 --> 00:08:24,695
You can have, for example, if you're using
E case cluster or something on, Google

175
00:08:24,725 --> 00:08:30,575
Cloud or something on Zoom, You already
have this cluster at your disposal and you

176
00:08:30,575 --> 00:08:35,085
already have this nodes at your disposal,
but depending upon your cost model, you

177
00:08:35,085 --> 00:08:37,365
will be charged only if you use them.

178
00:08:37,365 --> 00:08:39,765
So during your peak periods,
you can use the GPU.

179
00:08:40,125 --> 00:08:44,530
Kubernetes makes it very easy through its
Yamal file and a couple of annotations it.

180
00:08:44,595 --> 00:08:47,595
Easily allows you to target by
using tames and tolerations and

181
00:08:48,015 --> 00:08:50,415
Kubernetes allows you to target
the right nodes that have the GPU.

182
00:08:50,865 --> 00:08:52,755
It allows you to perform auto scaling.

183
00:08:52,755 --> 00:08:54,765
It allows you to perform
horizontal scaling.

184
00:08:54,765 --> 00:08:58,775
You can set several, you can
set several parameters, several

185
00:08:58,775 --> 00:09:01,715
attributes based on which you want
to perform the horizontal scaling.

186
00:09:01,715 --> 00:09:02,825
In fact, there are.

187
00:09:03,615 --> 00:09:05,265
Third party CNCF.

188
00:09:05,315 --> 00:09:07,505
platforms are tools like kda.

189
00:09:07,760 --> 00:09:12,455
Kda is Kubernetes event driven
autoscaling, so it allows you to autoscale

190
00:09:12,455 --> 00:09:14,825
based on, different kinds of factors.

191
00:09:15,325 --> 00:09:15,685
Okay.

192
00:09:15,955 --> 00:09:19,165
Now, from a resource management
perspective, how does Kubernetes help you?

193
00:09:19,215 --> 00:09:23,865
If your organization of your company is
already using Kubernetes, you might have

194
00:09:23,865 --> 00:09:27,735
a bunch of microservices running on your
Kubernetes already, then you are you.

195
00:09:28,065 --> 00:09:31,845
You're an apt company for running machine
learning workloads on your Kubernetes.

196
00:09:31,875 --> 00:09:36,435
Kubernetes has the concept of resource
quotas that allow you to rested the

197
00:09:36,435 --> 00:09:38,085
amount of resources you can use.

198
00:09:38,085 --> 00:09:39,220
When I say other source,
CPUs, you can use.

199
00:09:39,430 --> 00:09:40,390
Per namespace.

200
00:09:40,850 --> 00:09:43,969
if you're a large, very large
organization, you can segregate, a co.

201
00:09:44,180 --> 00:09:47,750
You can segregate the groups inside
the, into sub organizations or groups

202
00:09:47,750 --> 00:09:49,520
inside the organizations into namespace.

203
00:09:49,520 --> 00:09:52,910
For example, your finance and sales
could use different namespace.

204
00:09:53,430 --> 00:09:56,460
They can keep submitting the machine
learning workloads to their own

205
00:09:56,490 --> 00:09:58,800
namespace without encroaching the others.

206
00:09:58,860 --> 00:10:01,870
Others, others, resource quota
or others resources, right?

207
00:10:01,870 --> 00:10:05,900
For example, finance will not go and
use the, sales resources and sales

208
00:10:05,900 --> 00:10:08,660
will not go and use the finance
resources, as I said earlier.

209
00:10:09,075 --> 00:10:12,825
You also have node selectors things
and tolerations that allow you

210
00:10:12,825 --> 00:10:16,675
to target specific nodes, where,
specific nodes, where you can perform

211
00:10:16,675 --> 00:10:18,355
machine learning or deep learning.

212
00:10:18,355 --> 00:10:20,005
And when you require GPUs, right?

213
00:10:20,305 --> 00:10:21,145
that is what that is.

214
00:10:21,205 --> 00:10:23,965
That's how Kubernetes helps you from
the resource management perspective.

215
00:10:24,540 --> 00:10:26,100
from a portability perspective.

216
00:10:26,370 --> 00:10:29,970
So Kubernetes, you write all,
whatever, what Kubernetes functionality

217
00:10:29,970 --> 00:10:32,850
you're going to write, you're going
to write in terms of YAML files.

218
00:10:33,360 --> 00:10:36,450
If you're going to define your cus
own customer source definitions,

219
00:10:36,450 --> 00:10:38,010
you are going to use co files.

220
00:10:38,640 --> 00:10:40,530
Now these are pretty much.

221
00:10:40,780 --> 00:10:45,370
Independent of the cloud or wherever
you're going to deploy them, let

222
00:10:45,370 --> 00:10:47,290
it be on-premise, cloud, or hybrid.

223
00:10:47,290 --> 00:10:51,700
You'll still be working with same set
of YAML files, the same set of customer

224
00:10:51,700 --> 00:10:55,420
source definitions, which themselves are
YAML files and a combination of co files.

225
00:10:56,050 --> 00:10:59,950
So there's a huge portability if even
if you shift your cloud provider or

226
00:10:59,950 --> 00:11:02,890
if you want to move your on-premise,
on-premise Kubernetes cluster.

227
00:11:02,890 --> 00:11:06,205
There's a huge portability
when you work with Kubernetes.

228
00:11:06,705 --> 00:11:10,845
Okay, so having, we have discussed some
of the, discussed some of the basics of

229
00:11:10,845 --> 00:11:14,955
Kubernetes, but, let's try to understand,
some of the core concepts of Kubernetes.

230
00:11:15,015 --> 00:11:16,245
And these are very core.

231
00:11:16,345 --> 00:11:17,785
some of you might already know this.

232
00:11:17,815 --> 00:11:21,640
I. From a machine learning perspective,
there are four things that we

233
00:11:21,640 --> 00:11:23,430
need to do know about, Kubernetes.

234
00:11:23,460 --> 00:11:25,560
Having said that, this is not
the entire list, I'm just trying

235
00:11:25,560 --> 00:11:26,610
to put the four important.

236
00:11:26,760 --> 00:11:30,190
There are several other, built in
resources that Kubernetes provides, and

237
00:11:30,190 --> 00:11:34,180
there are several hundred projects in
cloud native compute foundation, CNCF,

238
00:11:34,600 --> 00:11:37,210
that work around the Kubernetes ecosystem.

239
00:11:37,210 --> 00:11:40,540
For example, the Orgo rollouts, which
allows you to roll out your, which

240
00:11:40,540 --> 00:11:44,050
makes it rollout deployment where the
rollouts very easy or rollbacks very easy.

241
00:11:44,290 --> 00:11:44,500
There are.

242
00:11:44,780 --> 00:11:51,150
Hundreds of, CNCF providers out there
who built a lot of, resources around

243
00:11:51,150 --> 00:11:52,590
machine learning and Kubernetes.

244
00:11:52,890 --> 00:11:55,920
But for our session today, we'll
discuss the four most important

245
00:11:55,920 --> 00:12:00,570
things, the pods, deployments, visas
and namespace POD is the smallest

246
00:12:00,570 --> 00:12:02,130
deployment unit in Kubernetes.

247
00:12:02,180 --> 00:12:06,180
as, and deployments are the ones
that bundle all your pods together.

248
00:12:06,300 --> 00:12:09,630
They allow the pods to be, they
decide the number of replicas.

249
00:12:09,635 --> 00:12:10,715
a pod can have.

250
00:12:10,715 --> 00:12:13,925
They allow the auto scaling, horizonal,
auto scaling, and vertical scaling.

251
00:12:14,485 --> 00:12:18,235
the services are the ones that expose
your deployments to the outside world.

252
00:12:18,535 --> 00:12:20,575
And obviously we spoke
about namespaces earlier.

253
00:12:20,575 --> 00:12:25,055
They allow you to logically group,
your logically group your resources,

254
00:12:25,155 --> 00:12:28,725
which just by improving the isolation
and as well as the security, it

255
00:12:28,725 --> 00:12:32,265
also allows the proper resource
management, of your Kubernetes cluster.

256
00:12:32,685 --> 00:12:36,375
So four things, pods, deployment,
services, and namespace are the

257
00:12:36,375 --> 00:12:39,645
basic things, at least what you want
to know when you're working with,

258
00:12:39,725 --> 00:12:41,155
Kubernetes, and machine learning.

259
00:12:41,655 --> 00:12:44,475
As I spoke about pods,
deployments and services.

260
00:12:44,505 --> 00:12:48,105
These three comprise the three main
things, that, Kubernetes, these are the

261
00:12:48,105 --> 00:12:51,230
fundamental things that anyone should
know when working with Kubernetes.

262
00:12:51,620 --> 00:12:54,890
And of course with the machine
learning workloads that we

263
00:12:54,890 --> 00:12:55,670
are going to discuss about.

264
00:12:56,170 --> 00:12:57,970
Now there's one more thing which
is really important, right?

265
00:12:58,030 --> 00:13:01,660
Kubernetes has this concept of
persistent volumes and persistent

266
00:13:01,660 --> 00:13:03,730
volume classes and storage classes.

267
00:13:03,940 --> 00:13:09,590
So these allow you to store
persistent data, when you're trying

268
00:13:09,590 --> 00:13:12,520
to interact, when you're trying to
interact with Kubernetes classes.

269
00:13:12,520 --> 00:13:14,530
for example, if you have
submitted a machine learning

270
00:13:14,530 --> 00:13:15,910
job to Kubernetes cluster.

271
00:13:16,165 --> 00:13:19,925
And it, you want to do some kind of
checkpointing at some time, right?

272
00:13:19,925 --> 00:13:23,795
You want to store your intermediary
model or intermediary, parameters.

273
00:13:23,925 --> 00:13:26,115
that's where the persistent
volumes, persistent volume

274
00:13:26,115 --> 00:13:28,095
claims and storage classes shine.

275
00:13:28,425 --> 00:13:31,365
And they're so easy to use that it's like.

276
00:13:31,395 --> 00:13:34,935
Like any other, sourcing Kubernetes,
it's nothing but a Yamal file.

277
00:13:35,385 --> 00:13:37,665
And of course, there's
a vendor tie up, right?

278
00:13:37,725 --> 00:13:39,585
But that is handled by annotations.

279
00:13:39,615 --> 00:13:41,925
And same goes with storage classes, right?

280
00:13:42,135 --> 00:13:45,076
These are the concepts that
allow you to store your data.

281
00:13:46,020 --> 00:13:48,870
When machine learning workload is
running, when you want a checkpoint,

282
00:13:48,870 --> 00:13:51,250
when you want to store your
parameters, when you're actually

283
00:13:51,250 --> 00:13:52,420
running your machine learning model.

284
00:13:52,750 --> 00:13:56,550
So all these, all these three
help you to maintain some kind of

285
00:13:56,760 --> 00:13:59,400
persistent state when your machine
learning workload is running.

286
00:13:59,580 --> 00:14:02,490
In fact, these three are not very
related to machine learning workload.

287
00:14:02,490 --> 00:14:03,240
They're related to.

288
00:14:03,510 --> 00:14:06,680
They're also related to any
kind of, any kind of, um.

289
00:14:07,180 --> 00:14:09,250
workload that you're trying
to run on Kubernetes.

290
00:14:09,750 --> 00:14:10,140
Okay.

291
00:14:10,260 --> 00:14:12,160
We spoke a lot about, Kubernetes.

292
00:14:12,190 --> 00:14:14,470
We try to understand what is,
what are the basics of Kubernetes.

293
00:14:14,470 --> 00:14:18,360
We try to understand what are the basics
of machine learning and, why we should

294
00:14:18,360 --> 00:14:20,040
be using Kubernetes for machine learning.

295
00:14:20,400 --> 00:14:24,090
Now you can go in and build your
own framework on Kubernetes, and

296
00:14:24,090 --> 00:14:25,590
you can run your machine learning.

297
00:14:26,175 --> 00:14:27,255
Workloads over there.

298
00:14:27,615 --> 00:14:32,055
But there are several proven, tools
out there that allow you to run your

299
00:14:32,055 --> 00:14:34,125
machine learning workloads on Kubernetes.

300
00:14:34,485 --> 00:14:36,225
They just don't allow you to run.

301
00:14:36,225 --> 00:14:41,475
They also allow you to visualize, do
an auto ml and several other things.

302
00:14:41,475 --> 00:14:42,225
Very easy.

303
00:14:42,615 --> 00:14:45,285
And now one of those very, very
famous tools that is gaining

304
00:14:45,345 --> 00:14:46,965
traction these days is Q Flow.

305
00:14:46,965 --> 00:14:50,355
It has been there for a while, but it's
gaining a lot of traction with the,

306
00:14:50,405 --> 00:14:52,115
with the new LMS and foundation models.

307
00:14:52,145 --> 00:14:52,745
Is Q Flow.

308
00:14:53,385 --> 00:14:57,385
So Q Flow is an open source machine
learning toolkit, which simplifies

309
00:14:57,385 --> 00:15:00,505
the deployment and management
of machine learning workloads.

310
00:15:00,745 --> 00:15:03,775
So it is specifically
targeted for Kubernetes.

311
00:15:03,955 --> 00:15:07,135
It has several key features, Q Flow,
and we'll be talking about each

312
00:15:07,135 --> 00:15:08,605
one of them in the upcoming slide.

313
00:15:08,635 --> 00:15:09,745
It has several key features.

314
00:15:10,535 --> 00:15:13,655
It has training operators,
built-in training operators.

315
00:15:13,835 --> 00:15:16,835
it has its own built-in serving
infrastructure called as Kerv.

316
00:15:17,015 --> 00:15:20,895
It has a Python library that allows
you to write pipelines and it

317
00:15:20,895 --> 00:15:22,455
also has a model storage model.

318
00:15:22,455 --> 00:15:25,505
It also allows you to store the models,
and several other benefits, right?

319
00:15:25,505 --> 00:15:27,455
There's several key features that
we'll be talking about in the

320
00:15:27,455 --> 00:15:30,965
upcoming slides, as I said, instead
of building your own framework.

321
00:15:31,515 --> 00:15:35,495
There's an open source initiative, that
came up from a lot of successful projects.

322
00:15:35,595 --> 00:15:39,655
and, Q Flow makes it very easy to build
and deploy and manage your machine

323
00:15:39,655 --> 00:15:44,795
learning models, and it accelerates
the AI development life cycle, Q Flow.

324
00:15:44,855 --> 00:15:45,185
Again.

325
00:15:45,185 --> 00:15:48,870
Q Flow is a game changing platform
for machine learning, on Kubernetes.

326
00:15:49,370 --> 00:15:53,370
Okay, now we'll try to talk about
each one of the components on Q Flow.

327
00:15:53,370 --> 00:15:56,190
Unfortunately, I couldn't put a
lot of examples here in the slides,

328
00:15:56,190 --> 00:15:58,820
but, definitely as I said, we'll
have workshops so in the future.

329
00:15:59,180 --> 00:16:01,310
But, what are the different
kinds of Q flow components?

330
00:16:01,360 --> 00:16:04,030
The first component of Q Flow
is training operator, right?

331
00:16:04,060 --> 00:16:06,880
There's a built in training
operator in Q Flow.

332
00:16:07,220 --> 00:16:09,110
there is, there several building.

333
00:16:09,140 --> 00:16:10,460
You can run a TensorFlow job.

334
00:16:10,460 --> 00:16:13,010
You can run a job, you can run ANet job.

335
00:16:13,125 --> 00:16:17,505
So these training operators allow
you to specify your training.

336
00:16:18,080 --> 00:16:21,290
In the form of, in the
form of a YAML file.

337
00:16:21,770 --> 00:16:26,340
Now it's a YAML file that could
run across any cloud on-premise.

338
00:16:26,390 --> 00:16:31,170
as, as long as it has, it has a
Kubernetes cluster to run on it, you

339
00:16:31,170 --> 00:16:34,322
can just interact with the training
operator since it's a YAML file that

340
00:16:34,325 --> 00:16:37,440
Kubernetes understand you can interact
it with using by your cube cuttle file.

341
00:16:38,240 --> 00:16:41,300
The training operators is one of
those things which easily makes,

342
00:16:41,330 --> 00:16:43,450
which easily makes, running your, um.

343
00:16:44,305 --> 00:16:48,155
running your training, you just need
to follow a specific contract and

344
00:16:48,155 --> 00:16:51,245
create an image out of it and create
the yamal file out of the image.

345
00:16:51,745 --> 00:16:55,375
The second important component
is the q plus serving.

346
00:16:55,375 --> 00:16:58,435
So once you have built your model
and you've trained your model and

347
00:16:58,435 --> 00:17:01,330
you've validated your model, you
want to deploy your model somewhere.

348
00:17:01,435 --> 00:17:04,015
And that's where the Q plus
serving comes into picture.

349
00:17:04,315 --> 00:17:06,325
It has a standard Python, API.

350
00:17:06,475 --> 00:17:10,275
It also has the Yamal files that you
can use to expose your Q Flow serving.

351
00:17:10,845 --> 00:17:13,275
And there's also something called
a model mesh that provides high

352
00:17:13,275 --> 00:17:16,245
performance, scalable model serving
with intelligent routing, right?

353
00:17:16,245 --> 00:17:19,665
So the it's, and it's beneath the
KF serving, but on the top you have

354
00:17:19,665 --> 00:17:23,925
q plus serving, which allows you to
serve your models very efficiently.

355
00:17:24,425 --> 00:17:26,194
so Q Flow pipelines, right?

356
00:17:26,194 --> 00:17:28,384
So this is the third most important model.

357
00:17:28,934 --> 00:17:31,784
In the Q Flow pipeline, there's
nothing but it's a Python.

358
00:17:31,784 --> 00:17:34,964
It's a Python framework that
allows you to define your machine

359
00:17:34,964 --> 00:17:38,354
learning workflow, orchestrate
it, so obviously you try to come.

360
00:17:38,594 --> 00:17:41,745
It allows you to define your
entire machine learning lifecycle

361
00:17:41,745 --> 00:17:43,784
in the form of a Python script.

362
00:17:44,444 --> 00:17:46,244
Having said that, it also has a YAML file.

363
00:17:46,244 --> 00:17:50,564
You can do it, the YAML file also, and it
allows you to track the performance also.

364
00:17:50,614 --> 00:17:54,725
But you, when we say track, you can
also actually do an auto ML by using

365
00:17:54,725 --> 00:17:57,004
something called a s CIB in Q Flow.

366
00:17:57,514 --> 00:17:59,585
And, but we'll talk about PIL later.

367
00:17:59,585 --> 00:18:03,004
But this Q Flow pipeline is a third
component, which plays a pivotal

368
00:18:03,004 --> 00:18:06,665
role in writing your entire pipelines
end-to-end pipeline in Python.

369
00:18:06,995 --> 00:18:10,955
And then you can use, you can deploy
the Python pipeline and run the Q flow.

370
00:18:11,455 --> 00:18:16,485
Okay, so what does the lifecycle of, a
machine learning workload look on Q Flow?

371
00:18:16,495 --> 00:18:18,895
We define a Q Flow job.

372
00:18:18,895 --> 00:18:22,705
In this case, I took an example of a
TensorFlow job, and you can define it

373
00:18:22,705 --> 00:18:24,775
by using a Python script or a YAML file.

374
00:18:24,965 --> 00:18:27,635
We submit the job to
the Kubernetes cluster.

375
00:18:27,845 --> 00:18:31,655
We monitor the progress by using the
Q Flow ui, and we finally deploy the

376
00:18:31,955 --> 00:18:33,485
model by using the Q Flow serving.

377
00:18:34,025 --> 00:18:35,315
And, we deploy the model.

378
00:18:35,375 --> 00:18:39,715
And of course, once you've deployed the
model, you can actually, use the model for

379
00:18:39,715 --> 00:18:41,515
inferencing by using the Q flow serving.

380
00:18:42,015 --> 00:18:44,925
So this is the data addition steps
that we have already discussed.

381
00:18:44,955 --> 00:18:47,295
it involves, working with data sources.

382
00:18:47,615 --> 00:18:49,535
Then, you fetch, you
get the, all the data.

383
00:18:49,595 --> 00:18:53,435
I'm just trying to go through step by
step guide of how you want to do the

384
00:18:53,615 --> 00:18:55,475
machine learning on your Kubernetes.

385
00:18:55,905 --> 00:18:57,105
you start with data sources.

386
00:18:57,105 --> 00:18:59,115
You fetch data from
different data sources.

387
00:18:59,385 --> 00:19:01,605
You do different kind of
data transformation on it.

388
00:19:01,605 --> 00:19:04,905
You try to clean the data, remove the
alphanumeric characters, alphabetic

389
00:19:04,905 --> 00:19:08,115
characters, scale everything to one
level, and then you finally come

390
00:19:08,115 --> 00:19:10,305
out with a set of features, right?

391
00:19:10,395 --> 00:19:12,465
That's what is called feature
engineering set of features for

392
00:19:12,465 --> 00:19:13,395
your machine learning model.

393
00:19:13,895 --> 00:19:16,565
Now then you do the machine learning,
then you do the actual training.

394
00:19:16,565 --> 00:19:19,935
You define the training job, you
specify the resources that you want

395
00:19:19,935 --> 00:19:21,765
to use for the specific, training job.

396
00:19:21,975 --> 00:19:25,425
Again, the training Q Flow has its
own training operator that you can

397
00:19:25,425 --> 00:19:26,885
use for, performing the training.

398
00:19:26,885 --> 00:19:29,765
You specify the resources and find,
you validate the model by using

399
00:19:29,765 --> 00:19:31,265
the Q Flow pipeline components.

400
00:19:31,765 --> 00:19:34,665
and at the end, once you
have the model ready, you.

401
00:19:35,165 --> 00:19:38,635
Try to serve the model
by using the KF serving.

402
00:19:38,695 --> 00:19:40,705
I just went into some
of the internal details.

403
00:19:40,705 --> 00:19:43,645
You need to create an inference,
service resource to define

404
00:19:43,645 --> 00:19:45,055
your model serving deployment.

405
00:19:45,295 --> 00:19:48,145
You specify the model, especially
where the model is located.

406
00:19:48,355 --> 00:19:52,075
And finally, you deploy the model by
using the KF serve, which provides

407
00:19:52,075 --> 00:19:55,225
your rest endpoint, or this is the
rest endpoint you can reach out to

408
00:19:55,225 --> 00:19:56,485
through your Kubernetes service.

409
00:19:56,690 --> 00:20:00,650
A gateway, which is associated with
the cloud, which with the cloud,

410
00:20:00,680 --> 00:20:01,730
with the cloud gateway, right?

411
00:20:01,730 --> 00:20:06,040
So you can reach that, reach from
an external, source to your, to your

412
00:20:06,040 --> 00:20:08,560
serving endpoint on Kubernetes cluster.

413
00:20:09,060 --> 00:20:12,000
So what are the best practices for
optimizing machine learning on Kubernetes?

414
00:20:12,000 --> 00:20:14,550
one, one thing is there's
always, you have to choose the

415
00:20:14,550 --> 00:20:15,990
right, right resources, right?

416
00:20:15,990 --> 00:20:19,170
and again, this is not something
you can come up at one shot.

417
00:20:19,200 --> 00:20:22,110
You have to experiment and play
around with it to choose the

418
00:20:22,110 --> 00:20:25,080
right kind of resources, right?

419
00:20:25,350 --> 00:20:25,980
And.

420
00:20:26,815 --> 00:20:27,915
Use the GPUs, right?

421
00:20:27,950 --> 00:20:30,290
Optimize the usage of GPUs, right?

422
00:20:30,290 --> 00:20:35,090
So having said that, don't make
all your workloads run on GPUs.

423
00:20:35,540 --> 00:20:41,100
You can optimize, the GPUs by using proper
teams tolerations on node selectors.

424
00:20:41,260 --> 00:20:45,700
and you can just run those workloads,
which really require the GPO, right?

425
00:20:45,700 --> 00:20:47,860
For example, the deep learning
with billion of parameters

426
00:20:48,280 --> 00:20:49,300
or billions of parameters.

427
00:20:50,030 --> 00:20:52,880
And finally, you need to keep
monitoring your monitoring

428
00:20:52,880 --> 00:20:54,200
the performance of your model.

429
00:20:54,470 --> 00:20:56,630
And there are several ways we can
monitor the performance, right?

430
00:20:56,630 --> 00:20:59,480
You can keep constructing the
accuracy, you can keep constructing

431
00:20:59,480 --> 00:21:03,230
the confusion matters as precisions,
recalls, et cetera, to keep, you keep

432
00:21:03,230 --> 00:21:06,620
monitoring the performance of your
application and you keep training

433
00:21:06,620 --> 00:21:08,960
your model, on a regular basis.

434
00:21:09,460 --> 00:21:12,460
Okay, so what are different
resource allocation strategies?

435
00:21:12,460 --> 00:21:15,810
I want to have a separate section
for this, especially because, we

436
00:21:15,810 --> 00:21:18,720
have to understand what are the
right resource allocation strategies.

437
00:21:18,720 --> 00:21:19,770
Now, one of the.

438
00:21:20,175 --> 00:21:23,265
One of the basic things that you can do
is you can have static resources, right?

439
00:21:23,265 --> 00:21:26,295
You can have always hard code,
your resources, but there is a

440
00:21:26,295 --> 00:21:29,895
concept called a dynamic allocation
that allows you to allocate your

441
00:21:29,895 --> 00:21:33,315
resources based on the workload and
find there is autoscaling, right?

442
00:21:33,375 --> 00:21:36,495
You can do horizontal autoscaling
or vertical autoscaling depending

443
00:21:36,495 --> 00:21:38,235
upon the number of factors, right?

444
00:21:38,535 --> 00:21:42,545
You can also use some of the resources
from CNCF that allow you to do

445
00:21:42,545 --> 00:21:46,055
the auto scaling based on external
factors like your queue sizes.

446
00:21:46,240 --> 00:21:49,150
Your database sizes, some event
that happens outside of your

447
00:21:49,150 --> 00:21:51,330
Kubernetes, Kubernetes, cluster.

448
00:21:51,810 --> 00:21:53,160
So there are three different ways.

449
00:21:53,160 --> 00:21:55,800
Basically we can do autoscaling,
the static allocation, the dynamic

450
00:21:55,800 --> 00:21:56,910
allocation, and autoscaling.

451
00:21:57,880 --> 00:22:00,300
Okay, and we already discussed about this.

452
00:22:00,570 --> 00:22:02,490
Keep having your metrics.

453
00:22:02,550 --> 00:22:04,050
Keep pumping your metrics.

454
00:22:04,110 --> 00:22:05,370
Keep looking at your metrics.

455
00:22:05,370 --> 00:22:07,770
Have proper alerts around your metrics.

456
00:22:08,250 --> 00:22:10,320
Collect and analyze your logs, right?

457
00:22:10,350 --> 00:22:13,020
Make sure that you collect and
analyze your logs so that you

458
00:22:13,020 --> 00:22:14,910
can catch any potential problems.

459
00:22:15,060 --> 00:22:18,635
have metrics or key performance indicators
that keep monitoring the health.

460
00:22:19,175 --> 00:22:22,925
Of your ML applications, and if something
degrades immediately give an alert so

461
00:22:22,925 --> 00:22:26,635
that e even before it starts degrading,
you can have warning alerts, you can have

462
00:22:26,635 --> 00:22:30,485
critical alerts so that your teams can
become, can actually have a look at it

463
00:22:30,485 --> 00:22:33,726
and, and try to resolve the issue before
it becomes a real production issue.

464
00:22:34,226 --> 00:22:35,726
what are the different
security considerations?

465
00:22:35,726 --> 00:22:38,716
I know till now we have spoken
about, the other kind of things,

466
00:22:38,746 --> 00:22:39,976
apart from security, right?

467
00:22:39,976 --> 00:22:43,726
So we have covered every other
aspect except the security now.

468
00:22:43,826 --> 00:22:46,436
Again, since you're using
Kubernetes, Kubernetes has a

469
00:22:46,436 --> 00:22:48,296
very great security mechanism.

470
00:22:48,296 --> 00:22:52,076
It has built in authorization in
the form of RBAs ABAs, and you

471
00:22:52,076 --> 00:22:53,426
can use authentication, right?

472
00:22:53,426 --> 00:22:56,486
You can securely access to your
Kubernetes, by using certificates.

473
00:22:56,666 --> 00:22:58,046
And of course you can include the data.

474
00:22:58,046 --> 00:23:00,596
So all these are really
built into Kubernetes.

475
00:23:00,816 --> 00:23:03,516
I'm not going into the fundamentals
of Kubernetes, but Kubernetes has

476
00:23:03,516 --> 00:23:08,676
several tools like CER Manager, you can
use service meshes like STO Linkerd.

477
00:23:08,801 --> 00:23:11,951
Or, or different other kinds of
service measures that allow you to

478
00:23:11,951 --> 00:23:15,071
achieve this different authentication,
authorization, encryption, because

479
00:23:15,071 --> 00:23:17,201
you're working on Kubernetes,
all that is taken care for you.

480
00:23:17,701 --> 00:23:20,341
so two real world use cases that I
really want to talk about, right?

481
00:23:20,341 --> 00:23:24,536
I'm not going to name any company over
here, but I think I. finance services and

482
00:23:24,536 --> 00:23:29,766
healthcare AI are really gaining a lot
of, are really gaining a lot, a lot from

483
00:23:29,766 --> 00:23:32,136
using Kubernetes for the machine learning.

484
00:23:32,436 --> 00:23:35,556
So financial institutions really
use Kubernetes to deploy and

485
00:23:35,556 --> 00:23:37,656
scale the fraud detection models.

486
00:23:37,896 --> 00:23:41,496
Similarly, the healthcare providers
use Kubernetes to deploy and scale

487
00:23:41,526 --> 00:23:43,476
medically image analysis models, right?

488
00:23:43,816 --> 00:23:44,686
so Kubernetes is.

489
00:23:44,711 --> 00:23:48,961
Gaining a lot of traction across
these industries, as the foundation

490
00:23:48,961 --> 00:23:51,751
for scalable and label machine
learning deployments, right?

491
00:23:51,991 --> 00:23:56,811
So these are a couple of real world
examples where in fact we do a lot of

492
00:23:56,811 --> 00:24:00,141
those things for, we build a platform
and we do a lot of those things

493
00:24:00,141 --> 00:24:03,101
for, the other platforms that are
there within our own organizations.

494
00:24:03,601 --> 00:24:06,751
As you said about there are
financial services, right?

495
00:24:06,751 --> 00:24:10,561
A lot if by the, in these days, I
think any financial organization

496
00:24:10,561 --> 00:24:12,901
or a health organization should
have a Kubernetes cluster and

497
00:24:12,901 --> 00:24:14,191
maybe having a Kubernetes cluster.

498
00:24:14,191 --> 00:24:16,831
They might be moving towards an
idea of a Kubernetes cluster to

499
00:24:17,071 --> 00:24:18,451
deploy their own microservices.

500
00:24:18,841 --> 00:24:22,381
And since they all, if they already
have a Kubernetes cluster, they can use

501
00:24:22,381 --> 00:24:25,921
the same Kubernetes cluster for, for
their machine learning work workloads.

502
00:24:26,251 --> 00:24:28,411
And it really helps a
lot of things, right?

503
00:24:28,411 --> 00:24:31,621
For fraud detection, for risk
management, for customer analytics.

504
00:24:31,801 --> 00:24:35,931
So all this is where, Kubernetes and
machine learning workloads together can

505
00:24:35,931 --> 00:24:40,561
help, in the financial services, as we
spoke about in healthcare, this medical

506
00:24:40,561 --> 00:24:44,431
imaging, drug discovery, personalized
medicine, although all these are

507
00:24:44,431 --> 00:24:46,351
not that related to Kubernetes, but.

508
00:24:46,851 --> 00:24:51,561
Kubernetes allows you to make all this
very easy, very streamlined, focusing

509
00:24:51,561 --> 00:24:53,061
on performance and minimizing the costs.

510
00:24:53,561 --> 00:24:56,371
Now, before I wrap up, there's
some future trends that we are

511
00:24:56,371 --> 00:24:57,301
going to talk about, right?

512
00:24:57,301 --> 00:24:59,341
There is serverless ML on Kubernetes.

513
00:24:59,521 --> 00:25:02,731
There is something called a scale native
that is coming up that is going to offer

514
00:25:02,791 --> 00:25:04,831
the serverless platform on Kubernetes.

515
00:25:05,131 --> 00:25:06,481
Function as a service, right?

516
00:25:06,516 --> 00:25:07,896
which is gaining a lot of traction.

517
00:25:07,896 --> 00:25:12,726
You can deploy individual ML functions
directly and even driven, architecture.

518
00:25:12,726 --> 00:25:16,126
And that's what I was talking about,
Kubernetes event driven architecture, kdi,

519
00:25:16,126 --> 00:25:18,106
you can go and look out for it on CNCF.

520
00:25:18,316 --> 00:25:19,816
So all these are really evolving.

521
00:25:19,816 --> 00:25:21,646
KDI is pretty much stabilized these days.

522
00:25:21,866 --> 00:25:25,266
all these are really evolving
and providing, a lot of benefits

523
00:25:25,266 --> 00:25:28,546
for someone who is trying to, use
Kubernetes for machine learning.

524
00:25:29,046 --> 00:25:30,366
And thank you so much.

525
00:25:30,366 --> 00:25:33,296
You can always write to me,
for any of your questions.

526
00:25:33,326 --> 00:25:36,596
I'm available@prashant.one six@gmail.com.

527
00:25:36,916 --> 00:25:38,506
please do mail me if
you have any questions.

528
00:25:38,506 --> 00:25:40,876
I'll try to reply back to
you as, as soon as possible.

529
00:25:41,446 --> 00:25:42,556
and that's what it is, right?

530
00:25:42,556 --> 00:25:44,286
So we have discussed about,
Kubernetes and how it.

531
00:25:44,786 --> 00:25:49,046
How it is the foundation, how it is
becoming the foundation of scalable ai.

532
00:25:49,416 --> 00:25:52,056
what all it does is what we've
discussed in this section.

533
00:25:52,156 --> 00:25:55,336
and, I really want to thank everyone
for listening me to this session,

534
00:25:55,336 --> 00:25:58,816
for listening to this session, and
thank you con 42 for providing me an

535
00:25:58,816 --> 00:26:00,166
opportunity to talk in this session.

536
00:26:00,316 --> 00:26:04,246
Hopefully, I'll do a great workshop
in one of the future upcoming

537
00:26:04,246 --> 00:26:06,456
Con 42, sessions if possible.

538
00:26:06,816 --> 00:26:08,886
But again, thank you so
much for listening to me.

