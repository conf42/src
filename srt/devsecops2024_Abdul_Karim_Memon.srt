1
00:00:00,140 --> 00:00:04,300
Hello, everyone, and welcome to this
session on Kubernetes networking 101.

2
00:00:05,119 --> 00:00:07,439
In this session, we'll dive
into the fascinating world

3
00:00:07,439 --> 00:00:08,620
of Kubernetes networking.

4
00:00:09,520 --> 00:00:13,109
Now, I know networking can sometimes
feel like a black box, especially when

5
00:00:13,109 --> 00:00:17,839
Kubernetes has its own complexities on top
of it, whether you are a developer or a

6
00:00:17,839 --> 00:00:19,389
DevOps engineer or somewhere in between.

7
00:00:19,900 --> 00:00:22,690
My goal today is to make this topic
approachable and practical for you.

8
00:00:23,190 --> 00:00:25,520
Networking in Kubernetes is a vast topic.

9
00:00:26,020 --> 00:00:29,020
And it's impossible to cover
everything in just 30 minutes.

10
00:00:29,429 --> 00:00:32,160
So in this session, we'll focus
on the foundational concepts and

11
00:00:32,500 --> 00:00:34,140
key areas that you can build on.

12
00:00:34,640 --> 00:00:36,400
So before we start, a quick introduction.

13
00:00:36,420 --> 00:00:37,190
My name is Abdul Kareem.

14
00:00:37,190 --> 00:00:41,400
I'm the founder and principal
architect at V Lambda.

15
00:00:41,960 --> 00:00:44,740
And I've been in DevOps SRE
space for more than a decade now.

16
00:00:45,240 --> 00:00:48,430
You can feel free to ask questions
during the Q& A at the end.

17
00:00:49,125 --> 00:00:52,475
Or you can also reach out over email
or Twitter using these coordinates.

18
00:00:52,975 --> 00:00:53,714
So here's the agenda.

19
00:00:54,394 --> 00:00:56,924
We'll start with a brief
introduction to Kubernetes to

20
00:00:56,924 --> 00:00:58,695
ensure we are all on the same page.

21
00:00:59,324 --> 00:01:00,734
Then we'll dive into the core topic.

22
00:01:01,025 --> 00:01:02,204
That is Kubernetes networking.

23
00:01:02,704 --> 00:01:06,115
First, we'll explore how pods communicate,
starting with communication within

24
00:01:06,115 --> 00:01:09,515
the same node, and then moving on to
communication across multiple nodes.

25
00:01:10,150 --> 00:01:13,460
Next, we'll talk about the
overlay networks and how they

26
00:01:13,460 --> 00:01:15,280
handle cross node communication.

27
00:01:16,010 --> 00:01:19,829
From there, we focus on services,
which are a key to abstracting and

28
00:01:19,829 --> 00:01:21,190
simplifying, port communication.

29
00:01:21,769 --> 00:01:25,890
We'll also briefly touch upon IP
tables and its role in routing the

30
00:01:25,890 --> 00:01:27,489
traffic within a Kubernetes cluster.

31
00:01:27,989 --> 00:01:32,370
So Kubernetes is the most popular
open source container orchestrator

32
00:01:32,370 --> 00:01:34,160
platform available in the market.

33
00:01:35,010 --> 00:01:39,279
It simplifies the deployment, scaling,
and management of containerized workloads.

34
00:01:39,710 --> 00:01:42,750
Making it a crucial tool
for modern infra developers.

35
00:01:43,540 --> 00:01:51,110
It was originally developed by Google and
they released it as open source in 2014.

36
00:01:52,000 --> 00:01:56,170
So it's been almost 10 years now that
Kubernetes is available in the market.

37
00:01:57,049 --> 00:02:00,970
One of the reasons Kubernetes has
become so popular is its ability

38
00:02:00,970 --> 00:02:02,550
to handle dynamic environments.

39
00:02:03,130 --> 00:02:06,700
Imagine running hundreds of
thousands of containers manually.

40
00:02:07,275 --> 00:02:10,585
It is just not feasible to automate
much of this complexity for you.

41
00:02:11,555 --> 00:02:15,355
It also stands out because it adapts
to changing demands effortlessly.

42
00:02:16,185 --> 00:02:20,175
For example, you can scale your
application as well as infrastructure up

43
00:02:20,175 --> 00:02:25,765
or down automatically, ensuring you always
have just the right amount of resources.

44
00:02:25,875 --> 00:02:27,624
Never too much and never too little.

45
00:02:28,305 --> 00:02:32,234
When something goes wrong, Kubernetes
acts like a safe healing system as well.

46
00:02:32,615 --> 00:02:35,195
detecting and replacing any
field containers to keep your

47
00:02:35,195 --> 00:02:36,425
applications running smoothly.

48
00:02:36,925 --> 00:02:41,205
All of this is made possible by Kubernetes
networking, of course, which acts as

49
00:02:41,274 --> 00:02:44,855
the highways connecting every container,
pod, and service within your cluster.

50
00:02:45,725 --> 00:02:49,105
Without a well maintained network,
traffic would slow down, applications

51
00:02:49,105 --> 00:02:51,374
would crash, and the entire
system could grind to a halt.

52
00:02:52,260 --> 00:02:54,640
So networking is a foundation
that allows Kubernetes to

53
00:02:54,640 --> 00:02:55,890
orchestrate applications at scale.

54
00:02:56,580 --> 00:02:58,310
And that's what we'll be
explaining in the session.

55
00:02:58,810 --> 00:02:59,980
Now let's talk about pods.

56
00:03:00,480 --> 00:03:03,069
Pods are the basic building
blocks of Kubernetes.

57
00:03:03,190 --> 00:03:05,840
In Kubernetes, you don't work
directly with containers.

58
00:03:06,230 --> 00:03:08,400
Instead, containers are grouped into pods.

59
00:03:09,160 --> 00:03:11,990
Think of pod as the smallest
deployable unit in Kubernetes.

60
00:03:12,170 --> 00:03:15,960
a logical wrapper around one or more
containers that need to work together.

61
00:03:16,460 --> 00:03:19,650
All containers within a pod share the
same network and storage namespace.

62
00:03:20,150 --> 00:03:23,300
which means they can communicate
with each other using localhost.

63
00:03:24,260 --> 00:03:27,780
This design simplifies, the way
containers interact within the same pod.

64
00:03:27,780 --> 00:03:31,870
For example, if you have an application
split into multiple components,

65
00:03:31,880 --> 00:03:35,969
like a web server and a monitoring
agent, they can reside in the same

66
00:03:35,970 --> 00:03:37,409
pod and communicate seamlessly.

67
00:03:37,909 --> 00:03:40,599
Pods are also designed to
be atomic and ephemeral.

68
00:03:41,099 --> 00:03:44,149
Atomic means they're
treated as a single unit.

69
00:03:44,579 --> 00:03:49,474
If something goes wrong in a pod, The
entire pod is replaced and ephemeral means

70
00:03:49,504 --> 00:03:54,304
they can be destroyed and recreated at
any time, which introduces an important

71
00:03:54,314 --> 00:03:56,794
consideration, the pods IP address.

72
00:03:57,255 --> 00:03:58,424
It's never permanent.

73
00:03:58,745 --> 00:03:59,784
It can keep on changing.

74
00:04:00,755 --> 00:04:03,074
Every new pod will have a new IP address.

75
00:04:03,634 --> 00:04:05,674
So in short, pods encapsulate containers.

76
00:04:06,174 --> 00:04:10,274
Provide them with a unique environment
and act as a foundation for all high level

77
00:04:10,274 --> 00:04:15,015
Kubernetes abstractions, like deployments,
replica sets, stateful sets, and so on.

78
00:04:15,514 --> 00:04:17,924
Next, we'll talk about the
Kubernetes networking model.

79
00:04:17,925 --> 00:04:24,700
Now that we understand what a
pod is, let's dive deep into

80
00:04:24,700 --> 00:04:26,894
how networking works for pods.

81
00:04:27,525 --> 00:04:30,274
Kubernetes operates on a
model called IP per pod.

82
00:04:31,079 --> 00:04:34,609
This means that every pod in the
cluster gets its own unique IP address.

83
00:04:35,139 --> 00:04:40,429
This is a fundamental part of
Kubernetes design and a key reason why

84
00:04:40,539 --> 00:04:42,139
its networking model is so powerful.

85
00:04:42,640 --> 00:04:46,269
With each pod having a unique IP,
Kubernetes can treat them like

86
00:04:46,269 --> 00:04:48,579
independent entities on a network, right?

87
00:04:48,589 --> 00:04:50,179
much like a device on a local network.

88
00:04:50,739 --> 00:04:55,219
This simplifies communication because
one pod can reach another directly

89
00:04:55,619 --> 00:04:59,309
without requiring NAT or any network
address translation within the cluster.

90
00:04:59,809 --> 00:05:03,509
Another key aspect of the networking
model is that all containers in a

91
00:05:03,509 --> 00:05:05,419
pod share the same network namespace.

92
00:05:05,919 --> 00:05:09,409
This means that they share
the same IP address, network

93
00:05:09,499 --> 00:05:11,319
interfaces, and boot space.

94
00:05:11,909 --> 00:05:14,784
So by sharing the network
namespace, Containers inside

95
00:05:14,784 --> 00:05:18,244
a pod can communicate directly
without using pod level networking.

96
00:05:18,744 --> 00:05:25,124
For example, if one container is running
a web server and another is running a

97
00:05:25,124 --> 00:05:29,694
monitoring agent, the agent can collect
metrics using localhost without any

98
00:05:29,694 --> 00:05:31,675
external networking configurations.

99
00:05:32,454 --> 00:05:35,364
This shared namespace is what
makes pods so efficient, for

100
00:05:35,364 --> 00:05:36,814
running tightly coupled workloads.

101
00:05:37,654 --> 00:05:41,464
While containers within a pod work
as a cohesive unit, communication

102
00:05:41,464 --> 00:05:45,414
between pods continues to rely on
Kubernetes broader networking model,

103
00:05:45,834 --> 00:05:47,324
where each pod has its unique IP.

104
00:05:48,144 --> 00:05:51,374
So this inter pod communication model
is a foundation, to how Kubernetes

105
00:05:51,374 --> 00:05:53,124
simplifies application design.

106
00:05:53,624 --> 00:05:53,864
Cool.

107
00:05:53,884 --> 00:05:56,844
Let's bring everything we've
discussed so far into this example.

108
00:05:57,419 --> 00:06:00,549
to visualize the concepts of IP per
pod and shared network instances.

109
00:06:01,009 --> 00:06:07,059
So in this diagram, we have a
virtual machine, VM1 with an 2.

110
00:06:07,369 --> 00:06:07,839
3.

111
00:06:08,359 --> 00:06:13,066
Inside this VM, there are two pods,
each with its own unique IP address.

112
00:06:13,066 --> 00:06:14,949
Pod A has address 0.

113
00:06:15,329 --> 00:06:20,429
10 and is running a Python application
on port 3000, while pod C has IP of 0.

114
00:06:20,429 --> 00:06:24,829
11 and contains two containers, one
running a Java application on port 3000.

115
00:06:25,204 --> 00:06:26,634
And the other running a data docketed.

116
00:06:27,614 --> 00:06:31,604
Now, if you have run traditional
workloads, you would realize that on a

117
00:06:31,604 --> 00:06:35,414
single VM, it is not possible to run, an
application on the same port, multiple

118
00:06:35,414 --> 00:06:36,644
applications using the same port.

119
00:06:37,184 --> 00:06:40,204
But since, we are running in
this isolation provided, using

120
00:06:40,234 --> 00:06:43,454
containers and Kubernetes, you
can have a number of applications

121
00:06:43,474 --> 00:06:44,644
all listening on the same port.

122
00:06:44,734 --> 00:06:48,404
So in this case, Python and Java, both
applications are running on the same VM.

123
00:06:48,814 --> 00:06:50,044
And I'm listening on port 3000.

124
00:06:50,544 --> 00:06:50,884
All right.

125
00:06:51,344 --> 00:06:53,732
The setup illustrates
the IP per port model.

126
00:06:53,732 --> 00:06:57,202
So each port is assigned a unique IP
address, allowing them to communicate

127
00:06:57,422 --> 00:07:00,752
directly with each other, without
requiring any translations, right?

128
00:07:00,752 --> 00:07:06,022
So for instance, port A, if port A wants
to send data to port C, it can do so by

129
00:07:06,262 --> 00:07:08,308
addressing port C's unique IP address 192.

130
00:07:08,308 --> 00:07:08,600
168.

131
00:07:08,600 --> 00:07:08,892
0.

132
00:07:08,892 --> 00:07:09,842
11.

133
00:07:10,342 --> 00:07:13,612
And within port C, the two containers
are sharing the same network namespace.

134
00:07:14,112 --> 00:07:16,972
This means, they both have
access to the same IP address.

135
00:07:17,337 --> 00:07:19,477
and can communicate with
each other using localhost.

136
00:07:20,217 --> 00:07:22,597
For example, the Datadog agent
can collect metrics from Java

137
00:07:22,597 --> 00:07:27,997
application by connecting to
localhost colon 3000 slash metrics.

138
00:07:28,717 --> 00:07:30,977
This shared namespace simplifies
the way containers within a pod

139
00:07:31,047 --> 00:07:34,107
interact, making them feel like they
are running on the same machine.

140
00:07:34,607 --> 00:07:39,547
All right, so now that we've discussed the
IP per pod model and how pods communicate,

141
00:07:40,017 --> 00:07:45,477
you might wonder how does Kubernetes
assign IP So the answer is it does not.

142
00:07:45,877 --> 00:07:49,347
Kubernetes doesn't itself get involved
in the IP address management, but

143
00:07:49,977 --> 00:07:51,387
rather it leaves it to the CNI.

144
00:07:51,827 --> 00:07:54,267
that is the Container
Networking Interface target.

145
00:07:55,167 --> 00:07:57,327
Let's look at the pod creation
lifecycle in the next slide.

146
00:07:57,827 --> 00:08:01,107
So the process of IP address
allocation for a pod involves

147
00:08:01,127 --> 00:08:02,757
several components working together.

148
00:08:02,757 --> 00:08:05,987
But I'll break it down step
by step to make it simple.

149
00:08:06,917 --> 00:08:10,047
It all starts when, the Kubernetes
schedules a pod on a specific node.

150
00:08:10,547 --> 00:08:14,247
The kubelet on that node takes over
and instructs the container runtime

151
00:08:14,247 --> 00:08:16,237
interface plugin to create the board.

152
00:08:16,897 --> 00:08:19,157
In this example, the CRI
plugin is container D.

153
00:08:19,657 --> 00:08:23,067
Container D creates a sandbox ID and
sets up the Paul's network namespace.

154
00:08:23,567 --> 00:08:26,217
Container D then hands off the
job of setting up the networking

155
00:08:26,247 --> 00:08:28,277
to, a CNI plugin, right?

156
00:08:28,327 --> 00:08:29,957
Or the Container Network Interface plugin.

157
00:08:30,527 --> 00:08:34,397
The CNI plugin works with your chosen
networking solutions such as Flannel or

158
00:08:34,467 --> 00:08:40,207
Calico or, AWS VPC CLI to assign the pod a
unique IP address from the available pool.

159
00:08:41,027 --> 00:08:44,797
Once the networking is ready, the
CRI creates something called as a

160
00:08:44,797 --> 00:08:48,427
pause container, which holds the
network setup and acts as the base

161
00:08:48,457 --> 00:08:49,747
for all containers in the pod.

162
00:08:50,747 --> 00:08:54,207
Finally, the application containers
are started sharing the same

163
00:08:54,207 --> 00:08:57,037
network setup and IP address
established by the pause container.

164
00:08:57,647 --> 00:09:00,857
Now what's key here is that
Kubernetes itself doesn't directly

165
00:09:00,887 --> 00:09:02,257
manage the networking details.

166
00:09:02,857 --> 00:09:05,267
It delegates that responsibility
to the CNI plugin.

167
00:09:06,032 --> 00:09:09,482
This allows Kubernetes to support a
wide variety of networking solutions.

168
00:09:09,982 --> 00:09:12,582
Now that we understand how pods get
their IP addresses, the next question

169
00:09:12,582 --> 00:09:16,202
is, How does one pod communicate
with another pod using these IPs?

170
00:09:16,872 --> 00:09:19,968
Kubernetes provides a flat networking
model that ensures every pod can

171
00:09:19,968 --> 00:09:23,512
communicate directly with every other
pod in the cluster as long as it knows

172
00:09:23,532 --> 00:09:25,520
the IP address of the target pod.

173
00:09:25,520 --> 00:09:28,752
So let's take a closer look at
how this communication happens.

174
00:09:29,177 --> 00:09:30,857
Starting with pods
located in the same node.

175
00:09:31,357 --> 00:09:35,847
So this example, we have two pods, pod
A and pod B running on the same node.

176
00:09:36,557 --> 00:09:38,717
Each pod has its own unique IP.

177
00:09:39,377 --> 00:09:42,477
Now, pod A wants to
communicate with pod B, right?

178
00:09:42,837 --> 00:09:46,160
We know that when Kubernetes creates
a pod, it sets up a dedicated

179
00:09:46,160 --> 00:09:47,527
network namespace for that pod.

180
00:09:48,347 --> 00:09:51,257
Each pod also has its own,
namespace, which includes its

181
00:09:51,257 --> 00:09:52,593
IP address and network stack.

182
00:09:52,593 --> 00:09:55,677
Both the pods have been assigned
their unique IP addresses.

183
00:09:56,257 --> 00:09:58,387
Now, all of these namespaces
are isolated from each other.

184
00:09:58,957 --> 00:10:03,267
But they can communicate through the root
network namespace of the node, right?

185
00:10:03,597 --> 00:10:07,817
So the root namespace acts as a bridge,
enabling traffic to flow between the pods.

186
00:10:08,317 --> 00:10:12,767
To connect the pods to the root
namespace, Kubernetes uses virtual

187
00:10:12,767 --> 00:10:15,657
Ethernet pairs, or V8 pairs.

188
00:10:16,337 --> 00:10:19,617
Each pod is connected to the root
namespace with its own V8 pair.

189
00:10:19,827 --> 00:10:26,547
So pod A, connects to V if X and pod B
connects to V if Y, these V pairs can

190
00:10:26,737 --> 00:10:30,577
act as virtual cables, bridging the
pause network namespace of the node.

191
00:10:31,257 --> 00:10:34,507
This ensures that the pods can send and
receive packets within the node, right?

192
00:10:34,577 --> 00:10:37,007
And V pairs are always
created in pairs, right?

193
00:10:37,057 --> 00:10:37,727
imagine.

194
00:10:38,397 --> 00:10:39,157
It will be a pipe.

195
00:10:39,417 --> 00:10:41,307
A pipe always has two ends, right?

196
00:10:41,467 --> 00:10:42,517
A pipe cannot have one end.

197
00:10:42,517 --> 00:10:46,901
So the virtual Ethernet pairs
are like pipes connecting your

198
00:10:46,901 --> 00:10:49,327
virtual namespaces, virtual
network namespaces within the node.

199
00:10:49,327 --> 00:10:52,797
So the journey of the packet begins
in the pod A's network namespace.

200
00:10:53,297 --> 00:10:57,227
From there, the packet exits to
the, with the interface, virtual

201
00:10:57,227 --> 00:11:00,287
ethernet interface, which connects
the port to its corresponding

202
00:11:00,527 --> 00:11:03,347
virtual ethernet pair right with xx.

203
00:11:03,987 --> 00:11:07,207
And once a packet reaches this
virtual ethernet pair, it's passed

204
00:11:07,207 --> 00:11:10,722
to the root network, namespace of
the load within the root namespace.

205
00:11:10,722 --> 00:11:13,517
The container bridge interface
plays a crucial role.

206
00:11:14,172 --> 00:11:17,792
the CBR zero acts like a virtual
switch, which connects all the

207
00:11:17,792 --> 00:11:19,372
virtual Ethernet pairs on the node.

208
00:11:19,872 --> 00:11:21,962
It looks at the destination
of the packet and knows that

209
00:11:21,962 --> 00:11:23,352
it has a routable interface.

210
00:11:23,592 --> 00:11:26,832
VETHYY available on the same
node for the destination IP.

211
00:11:27,692 --> 00:11:31,512
Once the packet reaches the VETHYY, VETH
pair, it travels into port B's namespace

212
00:11:32,022 --> 00:11:34,167
and arrives at its destination interface.

213
00:11:34,817 --> 00:11:36,277
No, it's zero for me.

214
00:11:36,277 --> 00:11:39,347
Processes the packet as it as
if it directly came from party

215
00:11:39,397 --> 00:11:41,787
without any modifications to
the source or destination.

216
00:11:42,557 --> 00:11:42,857
Right?

217
00:11:43,827 --> 00:11:44,427
that was easy.

218
00:11:44,597 --> 00:11:48,837
Now let's look at an example where
we have multiple nodes in one, right?

219
00:11:49,217 --> 00:11:52,037
we have called a and
B running on node one.

220
00:11:52,662 --> 00:11:55,652
while we have pod, C and
pod B running on node two.

221
00:11:56,332 --> 00:12:01,062
and in this case, pod A
wants to send data to pod C.

222
00:12:02,032 --> 00:12:02,382
Okay.

223
00:12:02,882 --> 00:12:06,462
pod A generates a packet
with its source IP set to 10.

224
00:12:06,602 --> 00:12:07,252
0.

225
00:12:07,252 --> 00:12:08,032
1.

226
00:12:08,032 --> 00:12:11,202
10, which is its own IP
address, and destination IP 10.

227
00:12:12,012 --> 00:12:12,332
0.

228
00:12:12,742 --> 00:12:13,062
3.

229
00:12:13,122 --> 00:12:15,272
10, which is the IP of pod C.

230
00:12:16,272 --> 00:12:18,912
This packet exits pod A
via its zero interface.

231
00:12:19,912 --> 00:12:22,562
it travels to the virtual
Ethernet pair, VEtec sets into

232
00:12:22,852 --> 00:12:23,932
node's root network namespace.

233
00:12:24,782 --> 00:12:27,622
Within node 1, the bridge device
recognizes the destination IP.

234
00:12:28,122 --> 00:12:31,392
and figures out that it is
not local to node one and

235
00:12:31,402 --> 00:12:32,522
needs to be routed externally.

236
00:12:33,022 --> 00:12:36,632
The packet is now out of the
host and on the network, right?

237
00:12:36,732 --> 00:12:38,092
And it reaches node 2.

238
00:12:38,592 --> 00:12:42,062
In this example, we are seeing only
two nodes, but in reality there could

239
00:12:42,082 --> 00:12:44,402
be hundreds of nodes in your cluster.

240
00:12:44,902 --> 00:12:48,222
It is the responsibility of the CNI plugin
to ensure that the packet reaches the

241
00:12:48,242 --> 00:12:51,012
correct node based on the destination IP.

242
00:12:51,622 --> 00:12:55,102
So if you have ever used Amazon
EKS, you must be familiar with.

243
00:12:55,582 --> 00:12:57,322
This dashboard, right?

244
00:12:57,722 --> 00:12:59,672
this is a worker node of an ES cluster.

245
00:13:00,342 --> 00:13:03,492
We can see that AWS keeps a notebook
of all the IP addresses assigned

246
00:13:03,492 --> 00:13:05,022
to the pos running on each node.

247
00:13:05,022 --> 00:13:10,832
Now a WS deploys V-V-P-C-C-N-I plugin
add-on with every EESS cluster, and it

248
00:13:10,832 --> 00:13:12,727
is the only supported CNI plugin on EKS.

249
00:13:13,512 --> 00:13:17,012
You can use other plugins like
Calico or Celium, but they

250
00:13:17,012 --> 00:13:18,032
are not officially supported.

251
00:13:18,532 --> 00:13:22,972
Coming back to our example, the packet
now reaches Node 2's network interface 8.

252
00:13:22,972 --> 00:13:23,472
0.

253
00:13:23,972 --> 00:13:27,502
From there, the bridge inspects
the destination IP, 10.

254
00:13:27,632 --> 00:13:28,482
0.

255
00:13:28,542 --> 00:13:28,812
3.

256
00:13:28,812 --> 00:13:32,082
10, and forwards the packet to
the correct virtual Ethernet

257
00:13:32,082 --> 00:13:33,619
pair, connected to port C.

258
00:13:34,149 --> 00:13:36,059
And the packet finally reaches port C.

259
00:13:36,559 --> 00:13:36,949
All right.

260
00:13:37,449 --> 00:13:41,219
In the earlier slides, we saw how
Kubernetes uses a flat networking model

261
00:13:41,339 --> 00:13:45,039
where every pod gets its own unique
IP address, but what happens when your

262
00:13:45,119 --> 00:13:50,769
cluster grows and the IP range available
for your pods starts to run out?

263
00:13:51,769 --> 00:13:53,897
This is where overlay
networks come into play.

264
00:13:53,897 --> 00:13:57,738
An overlay network is a virtual
network built on top of an

265
00:13:57,738 --> 00:13:58,581
existing physical network.

266
00:13:58,581 --> 00:14:02,898
Think of it as a way to create
a larger logical network that

267
00:14:02,898 --> 00:14:04,508
spans multiple physical machines.

268
00:14:05,008 --> 00:14:09,578
Overlay networks are particularly
useful in Kubernetes when your IP

269
00:14:09,578 --> 00:14:14,178
ranges, your IP address ranges for
pods is limited, but you need to

270
00:14:14,178 --> 00:14:16,038
scale a cluster beyond those limits.

271
00:14:16,568 --> 00:14:20,978
or if you need to isolate traffic for
security or multi tenancy purposes,

272
00:14:21,458 --> 00:14:25,178
or the underlying physical network
doesn't natively support pod to pod

273
00:14:25,178 --> 00:14:27,058
communication across nodes, right?

274
00:14:27,398 --> 00:14:28,988
So the overlay network
encapsulates pod traffic, right?

275
00:14:29,478 --> 00:14:32,668
Allowing you to traverse the physical
network as if, it were part, it were

276
00:14:32,668 --> 00:14:34,268
all part of a single logical network.

277
00:14:34,848 --> 00:14:38,248
Now this abstraction solves the problem
of limited IP space while enabling

278
00:14:38,668 --> 00:14:40,028
communication between your pods.

279
00:14:40,588 --> 00:14:43,549
the common examples of, overlay
networks, CNA plugins that support

280
00:14:43,549 --> 00:14:48,434
overlay networks are flannel,
We've, Calico, Cillian, and so on.

281
00:14:48,934 --> 00:14:51,724
So let's try to understand how all
the networks work through an example.

282
00:14:52,224 --> 00:14:56,354
Now, in this example, again, we have two
nodes, both running two parts each and

283
00:14:56,374 --> 00:14:58,474
called a wants to talk to part B or C.

284
00:14:58,974 --> 00:15:02,804
Now there's, you need to notice that
there's a flannel device created in the

285
00:15:02,824 --> 00:15:04,294
root namespace of every node, right?

286
00:15:04,344 --> 00:15:06,014
We've, shown it through flannel zero.

287
00:15:06,254 --> 00:15:07,134
So it does flannel zero.

288
00:15:07,634 --> 00:15:10,204
So the packet A leaves
pod A through Vth pep.

289
00:15:10,254 --> 00:15:15,324
the packet reaches the root namespace
of the node, and it hits the bridge,

290
00:15:15,394 --> 00:15:19,364
the bridge device, and it realizes
that the destination IP address does

291
00:15:19,364 --> 00:15:20,674
not belong to this particular node.

292
00:15:21,174 --> 00:15:22,884
In this case, something
interesting happens here.

293
00:15:23,704 --> 00:15:26,289
The packet is intercepted
by flannel device.

294
00:15:26,789 --> 00:15:30,129
Flannel maintains a mapping of all
the pod IPs and the corresponding

295
00:15:30,129 --> 00:15:31,409
nodes in the user space.

296
00:15:31,819 --> 00:15:34,939
So when Flannel device sees the
destination IP, it can easily

297
00:15:34,939 --> 00:15:39,279
look up in the map and realize
that pod C is running on node 2.

298
00:15:39,779 --> 00:15:44,384
So with this information, what it does
is it encapsulates the packet, which

299
00:15:44,384 --> 00:15:48,484
means it puts a header on top of the
packet with node 2 as the destination

300
00:15:48,484 --> 00:15:51,094
address and node 1 as the source address.

301
00:15:51,754 --> 00:15:55,494
So your entire original packet
is now encapsulated inside a new

302
00:15:55,524 --> 00:15:56,804
packet which is created by flannel.

303
00:15:57,304 --> 00:16:01,244
So flannel has now encapsulated the packet
and it is ready to leave node 1, leave

304
00:16:01,244 --> 00:16:03,444
node 1 and it eventually reaches node 2.

305
00:16:04,354 --> 00:16:08,524
When this packet reaches node two, it is
again intercepted by the flannel device.

306
00:16:09,194 --> 00:16:11,464
The magic of encapsulation is undone here.

307
00:16:11,894 --> 00:16:18,854
flannel will again look up, uh, in
this map and change the source and

308
00:16:18,854 --> 00:16:21,034
destination addresses of this packet.

309
00:16:21,154 --> 00:16:26,504
So the source becomes IP of pod A
and destination becomes IP of pod C.

310
00:16:27,084 --> 00:16:29,614
And the packet will follow
the same path in Tilt to Perth

311
00:16:30,004 --> 00:16:31,864
and eventually reach pod C.

312
00:16:32,749 --> 00:16:36,119
So this is how an overlay network would
function, in a Kubernetes cluster.

313
00:16:36,619 --> 00:16:40,469
In Kubernetes, we've seen that pods are
ephemeral, meaning they can change the,

314
00:16:40,569 --> 00:16:45,569
they can change when pods are, pod IPs are
ephemeral, which means the IPs can change

315
00:16:45,569 --> 00:16:47,589
when pods are recreated or rescheduled.

316
00:16:48,299 --> 00:16:52,289
This possesses a challenge, this poses
a challenge because communication

317
00:16:52,289 --> 00:16:56,294
between components using ephemeral
IPs for pods is not practical.

318
00:16:56,794 --> 00:17:01,134
So Kubernetes addresses this issue of
dynamic pod IPs by introducing services.

319
00:17:02,024 --> 00:17:06,084
A service acts as a stable endpoint
that abstracts and routes traffic to a

320
00:17:06,124 --> 00:17:08,104
group of pods instead of a single pod.

321
00:17:08,604 --> 00:17:11,694
So this ensures that the application
can communicate reliably even

322
00:17:11,694 --> 00:17:12,904
when the pod IPs keep on changing.

323
00:17:13,404 --> 00:17:13,624
Okay.

324
00:17:13,654 --> 00:17:16,384
This slide shows a typical YAML
configuration for a Kubernetes service.

325
00:17:16,384 --> 00:17:17,914
So let's break it down.

326
00:17:18,624 --> 00:17:20,354
There are two important
sections to notice here.

327
00:17:21,284 --> 00:17:23,704
The name in metadata is
the service identifier.

328
00:17:24,539 --> 00:17:26,449
And it is used for the service discovery.

329
00:17:26,909 --> 00:17:31,059
if your pod wants to talk to this
particular application, it can just

330
00:17:31,059 --> 00:17:36,449
say, make a gate request to Hello
Kubernetes and Kubernetes will resolve

331
00:17:36,449 --> 00:17:39,879
this name, this domain name to the
service IP address using kubernetes.

332
00:17:40,379 --> 00:17:42,939
The other thing is the
selector section in inspect.

333
00:17:43,709 --> 00:17:46,119
It is a list of labels that
are used to group pods.

334
00:17:46,779 --> 00:17:50,279
So all pods with the label Hello
Kubernetes will be part of the service.

335
00:17:50,779 --> 00:17:53,739
So how does a pod actually talk
to another pod using service IP?

336
00:17:54,109 --> 00:17:55,059
Let's look at an example.

337
00:17:55,559 --> 00:17:59,679
So just like before, pod A
creates a TCP packet and places

338
00:17:59,679 --> 00:18:01,249
it on the virtual Ethernet there.

339
00:18:01,749 --> 00:18:04,649
This time the destination is
not a pod, it is a service.

340
00:18:05,509 --> 00:18:09,659
The bridge device doesn't recognize
this destination IP and the packet is

341
00:18:09,659 --> 00:18:11,619
about to be sent to the default gateway.

342
00:18:12,374 --> 00:18:16,094
But before it leaves the node, it
gets intercepted, but before it

343
00:18:16,094 --> 00:18:19,694
leaves the node, it gets intercepted
by the IP table of the host.

344
00:18:19,854 --> 00:18:25,814
So IP table is a firewall program, and
every packet that goes in or out of

345
00:18:25,814 --> 00:18:27,664
your node has to go through IP tables.

346
00:18:27,724 --> 00:18:29,184
of course, if you have
it installed and enabled.

347
00:18:29,184 --> 00:18:35,594
Kubernetes uses IP tables to perform
something called as DNAP or destination

348
00:18:35,654 --> 00:18:36,894
network address translation.

349
00:18:37,849 --> 00:18:42,519
Which means that we are going to,
modify or alter the destination network

350
00:18:42,689 --> 00:18:44,309
address, the destination network address.

351
00:18:44,809 --> 00:18:48,418
So the destination IP in the packet
is rewritten from service IP to the

352
00:18:48,499 --> 00:18:52,489
IP address of one of the backend
pods behind the service, right?

353
00:18:52,789 --> 00:18:55,749
So there could be multiple pods
running, in service C, it would

354
00:18:55,959 --> 00:18:58,209
pick one of them at random, right?

355
00:18:58,279 --> 00:19:01,149
It does a round robin of sorts by default.

356
00:19:01,689 --> 00:19:04,689
So this translation is
managed by a contract.

357
00:19:05,474 --> 00:19:09,614
which tracks the connection and ensures
that the response packets from pod C

358
00:19:10,054 --> 00:19:11,564
are correctly routed back to pod A.

359
00:19:12,244 --> 00:19:16,294
So to pod A, it appears as though it
is communicating directly with service

360
00:19:16,464 --> 00:19:20,044
IP, while in reality, Kubernetes
is, transparently redirecting the

361
00:19:20,044 --> 00:19:21,784
traffic to one of the backend pods.

362
00:19:22,404 --> 00:19:26,144
This abstraction allows Kubernetes to
provide load balancing while hiding

363
00:19:26,144 --> 00:19:28,358
the complexity of individual pod IPs.

364
00:19:28,858 --> 00:19:31,888
So with this new information, the
packet lands on eight zero and finally

365
00:19:31,888 --> 00:19:34,518
moves out of node one on its way back.

366
00:19:34,728 --> 00:19:38,278
it again hits the IP tables, on the
node, and you can see that the source

367
00:19:38,278 --> 00:19:39,548
and destination are flipped, right?

368
00:19:39,708 --> 00:19:44,433
So now the source is called C and
destination is called A, and the IP tables

369
00:19:44,493 --> 00:19:48,973
is going to use contract information to
rewrite the source IP address, right?

370
00:19:49,013 --> 00:19:51,563
Because the original
source, of this packet.

371
00:19:51,978 --> 00:19:54,408
Is the original destination was service C.

372
00:19:54,478 --> 00:19:56,118
So the packet has to
come back from service C.

373
00:19:56,668 --> 00:20:00,368
This is known as SNAP, right?

374
00:20:00,368 --> 00:20:01,878
Source network address translation.

375
00:20:01,928 --> 00:20:05,368
So earlier, when it was going
out, we did DNAT and when it

376
00:20:05,368 --> 00:20:07,654
came back, it, it did, SNAP.

377
00:20:07,654 --> 00:20:11,941
finally reaches port A and
the journey is complete.

378
00:20:12,441 --> 00:20:13,301
So thank you so much guys.

379
00:20:13,381 --> 00:20:14,261
that was it from my end.

380
00:20:14,761 --> 00:20:18,711
And if you're interested in
reading and learning more about the

381
00:20:18,711 --> 00:20:21,641
networking concepts of Kubernetes,
here are some resources that I've

382
00:20:21,641 --> 00:20:23,761
collected, which you can refer later.

383
00:20:24,551 --> 00:20:24,851
Thank you.

