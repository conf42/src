1
00:00:00,500 --> 00:00:01,339
Speaker 26: Hello everybody.

2
00:00:01,439 --> 00:00:03,449
My name is Paul Lo Halda.

3
00:00:03,949 --> 00:00:05,839
I'm a technical architect in Cognizant.

4
00:00:06,290 --> 00:00:12,079
Today I'm going to discuss about
the AI e power CICD implementation,

5
00:00:12,329 --> 00:00:17,790
based on and with the predictive
DevOps, which is faster and release.

6
00:00:17,999 --> 00:00:19,314
So that is all about.

7
00:00:20,250 --> 00:00:26,500
The difference between the traditional
CICD deployment for the DevOps versus

8
00:00:26,619 --> 00:00:30,939
the IPO CICD implementation, which
implemented predictive analytics.

9
00:00:31,439 --> 00:00:33,680
Four, the implementation.

10
00:00:34,220 --> 00:00:38,810
So in this session today, I will
discuss about what are the advantages,

11
00:00:38,810 --> 00:00:44,860
what are the barriers, what are the
implementation of EI power, CICD, and

12
00:00:45,100 --> 00:00:50,040
how it is differ from the traditional
development implementation approach.

13
00:00:50,540 --> 00:00:55,540
So I'm going to the next
slide, which is the agenda.

14
00:00:56,365 --> 00:00:58,165
Of our today's session.

15
00:00:58,345 --> 00:01:02,294
Today's session, we'll going
to discuss about the problem

16
00:01:02,294 --> 00:01:08,395
context, predictive DevOps, concept
architecture, process flow, and impact

17
00:01:08,665 --> 00:01:11,414
for the I-C-I-C-D implementation.

18
00:01:11,414 --> 00:01:17,730
I'm going to the next step where we will
discuss about all the detail about the.

19
00:01:18,230 --> 00:01:22,420
Our today's topic, CICD,
implementation for the AI powered

20
00:01:22,420 --> 00:01:24,760
CICD deployments for the DevOps.

21
00:01:25,390 --> 00:01:29,800
Okay, so I'm going to the next one
where I will discuss about in the

22
00:01:29,800 --> 00:01:32,410
detail why there is some barrier.

23
00:01:32,480 --> 00:01:36,020
There is some problem, there is
some limitation, there is some

24
00:01:36,020 --> 00:01:41,060
failure, why traditional CICD
breaks that we need to understand?

25
00:01:41,450 --> 00:01:45,050
Okay, before we are going to
implementation, the AI implemented

26
00:01:45,050 --> 00:01:49,610
CICD deployment automation,
we need to understand why.

27
00:01:50,110 --> 00:01:54,400
The traditional CI CT breaks, so
there are different kind of thousand

28
00:01:54,520 --> 00:01:58,840
reason among which I have collected
five six reason, which are more

29
00:01:58,990 --> 00:02:02,200
vital to deployment scenarios.

30
00:02:02,260 --> 00:02:05,950
First one is the reactive
monitoring, which alerts the

31
00:02:05,950 --> 00:02:07,630
fast after the damage is done.

32
00:02:08,230 --> 00:02:10,600
Second one is the late failure detection.

33
00:02:11,100 --> 00:02:13,500
Third one is the human heavy trigger edge.

34
00:02:13,620 --> 00:02:14,990
Third one is the pin.

35
00:02:15,470 --> 00:02:20,510
So I provide all the detail and all the
steps for that in the right hand side.

36
00:02:21,140 --> 00:02:22,310
Architecture diagram.

37
00:02:22,310 --> 00:02:26,735
If you see from the rea reactive
CICD two, predictive DevOps.

38
00:02:27,235 --> 00:02:34,405
In the traditional CICD, there is some
safe build, deploy test and there is lots

39
00:02:34,405 --> 00:02:40,435
of failure that might occur for the late
detection after impact of the alert logs.

40
00:02:40,945 --> 00:02:45,655
It is a badge processing system for
most of the application and system.

41
00:02:46,075 --> 00:02:50,785
So after code there might be
possible that some error occurred

42
00:02:50,935 --> 00:02:52,615
and the L alert and logs.

43
00:02:52,975 --> 00:02:56,535
Has been triggered after impact
due to the batch running.

44
00:02:56,685 --> 00:03:03,075
So in that case, the failure occurs, but
we have a late detection that will cause

45
00:03:03,855 --> 00:03:10,425
thousands, billions of dollar impact, as
well as the money impact to the business

46
00:03:10,425 --> 00:03:15,825
organization and the business users
suffers a lot for that particular impact.

47
00:03:16,635 --> 00:03:20,850
So these are the few reasons
why traditional CICD breaks.

48
00:03:21,350 --> 00:03:26,780
So these schemes as a background,
why we'll implement the predictive

49
00:03:27,495 --> 00:03:31,010
CI DevOps using CICD automation ai.

50
00:03:31,100 --> 00:03:35,329
So that is the background
of why we'll implement this.

51
00:03:35,510 --> 00:03:37,700
Now I'm going to the next slide.

52
00:03:38,390 --> 00:03:42,650
The slide is all about what
predictive DevOps means.

53
00:03:43,150 --> 00:03:47,770
Predictive developments like if a
intelligent flow or in inte system,

54
00:03:48,160 --> 00:03:53,620
which collect the data from different
system, which has different degree of

55
00:03:53,620 --> 00:03:59,950
data, normalize it, then temperature
it and normalize properly, and

56
00:03:59,950 --> 00:04:02,410
then harmonize it cleans the data.

57
00:04:02,825 --> 00:04:06,725
To make available to the
predictive layer model.

58
00:04:07,145 --> 00:04:09,515
In the layer model, they apply AI logic.

59
00:04:10,085 --> 00:04:14,255
Then they, or they apply the machine
learning algorithm on top of that.

60
00:04:14,795 --> 00:04:18,425
Then a process data pipeline
to different kind of gates.

61
00:04:18,965 --> 00:04:23,315
This predictive DevOps is not
only intelligent flow, but it's

62
00:04:23,315 --> 00:04:27,935
actually in intelligence system or
application where risk's prediction

63
00:04:27,995 --> 00:04:32,015
before execution happened after
that EIE assisted system took.

64
00:04:32,015 --> 00:04:35,990
Picture based on the TBS system data.

65
00:04:36,880 --> 00:04:41,610
Previous step data, feedback driven
automation then took place after the i

66
00:04:41,940 --> 00:04:47,550
tion or AI logic applied to the model,
and then after the model generate the

67
00:04:47,550 --> 00:04:52,020
accurate actual result, the feedback
driven automation has happened.

68
00:04:52,440 --> 00:04:58,140
To provide that data to propagate,
reroute the data and different kind.

69
00:04:58,140 --> 00:05:03,270
And then if there is a difference
between the data or actual result and the

70
00:05:03,270 --> 00:05:08,610
forecasted result or predicted result,
then the deviation, which is the error

71
00:05:08,610 --> 00:05:15,194
co patient, is Ted to the predictive
layer again, in the Model yourself two.

72
00:05:15,779 --> 00:05:21,269
Run, learn that model so that after
running the model, similar wave,

73
00:05:21,269 --> 00:05:27,209
multiple loop, the model minimize the
air coefficient and the difference

74
00:05:27,209 --> 00:05:33,359
between the actual and the forecasted
or predictive result became very less

75
00:05:34,019 --> 00:05:36,509
difference and it's very accurate.

76
00:05:37,349 --> 00:05:40,859
So that is how the
predictive DevOps works.

77
00:05:41,129 --> 00:05:42,599
Now I'm going to.

78
00:05:43,514 --> 00:05:48,274
The high level system overview, if you
see the system overview, the signal

79
00:05:48,904 --> 00:05:54,814
after from the signal system flow goes
to signal model decision actions, okay?

80
00:05:55,264 --> 00:05:59,464
Where the signal means it's collect,
as I told already, different kind

81
00:05:59,464 --> 00:06:04,204
of temperature data, different
kind of non harmonized, different

82
00:06:04,294 --> 00:06:08,204
kind of non normalized data
from different source system.

83
00:06:08,965 --> 00:06:14,124
So sort system, like you can say,
log file metrics, test data, PR and

84
00:06:14,124 --> 00:06:17,884
intra health, which are required to
monitor the system, which are required

85
00:06:18,459 --> 00:06:21,279
to monitor the deployment production.

86
00:06:22,134 --> 00:06:27,504
Testing and other SIT testing
system, all these things as provided

87
00:06:27,504 --> 00:06:29,544
as a input data to the model.

88
00:06:29,904 --> 00:06:35,734
So in the model before implementing
the model and before implementing apply

89
00:06:35,734 --> 00:06:41,164
the logic and the algorithms, machine
landlords to those models, the data

90
00:06:41,164 --> 00:06:47,734
is need to be clean and harmonized,
and the data need to be normalized in

91
00:06:47,734 --> 00:06:49,744
the proper way so that we can have.

92
00:06:50,244 --> 00:06:53,994
Apply proper machine learning
language to that particular data.

93
00:06:54,504 --> 00:06:58,134
So one of the, kind of the scenarios
like the calibration calibrate

94
00:06:58,164 --> 00:07:02,424
the data and then the calibrated
the data to get the actual result.

95
00:07:03,024 --> 00:07:06,174
Then after applying the model
and we get that decision.

96
00:07:06,819 --> 00:07:11,529
After the power output has generated,
we got the decision and then it flow

97
00:07:11,529 --> 00:07:13,749
to the pipeline to process further.

98
00:07:13,839 --> 00:07:18,699
And as I told earlier, what is the
deviation and air coefficient that has

99
00:07:18,699 --> 00:07:23,799
been routed to the model itself for
continuous learning and improve the

100
00:07:23,829 --> 00:07:31,024
model to get the proper act forecasted
and predicted data, which should be.

101
00:07:31,914 --> 00:07:37,304
It's very similar and very nearly to
the data value of the actual data.

102
00:07:37,484 --> 00:07:37,814
Okay?

103
00:07:38,204 --> 00:07:42,644
The core principle is the system
improves continuously through a closed

104
00:07:42,644 --> 00:07:50,714
loop learning cycle where outcomes
can became more accurate and actually

105
00:07:51,074 --> 00:07:55,064
visible to the business system
based on the intelligence driving

106
00:07:55,064 --> 00:07:57,909
decision and decisions made by the.

107
00:07:58,409 --> 00:08:00,389
Logic applied to the model.

108
00:08:00,889 --> 00:08:03,049
The next one is the CIC data source.

109
00:08:03,439 --> 00:08:07,340
As I told you, that is a different kind
of data, which is, that is available

110
00:08:07,340 --> 00:08:10,939
as a input for that particular,
in this particular scenario, like

111
00:08:10,939 --> 00:08:15,789
build logs, test result, pipeline
metrics, pr, metadata level.

112
00:08:16,419 --> 00:08:19,719
So all these things
represent as a data, okay?

113
00:08:20,440 --> 00:08:21,909
The data.

114
00:08:22,409 --> 00:08:25,889
I can say one thing here that
technology must serve acuity and

115
00:08:26,190 --> 00:08:27,810
inclusion, not efficient alone.

116
00:08:28,320 --> 00:08:32,579
So that is why we, I want to tell that
all the system with different kind of

117
00:08:32,579 --> 00:08:37,595
data of different kind of, normalization
and things we need to harmonize properly

118
00:08:37,865 --> 00:08:43,925
to get the data in a equal me shape
or equal manner to serve as equity.

119
00:08:44,915 --> 00:08:52,105
So that is how the CRCD data source occur,
and serve as a proper in input level data.

120
00:08:53,035 --> 00:08:57,475
Now I'm moving to the next one, which
is the ingestion and telemetry layer.

121
00:08:57,865 --> 00:09:01,255
So in the telemetry layer,
what is the purpose of the

122
00:09:01,255 --> 00:09:02,515
ingestion of the telemetry layer?

123
00:09:02,515 --> 00:09:03,535
Anybody can ask.

124
00:09:03,835 --> 00:09:07,635
So the purpose of the initial
layer is that it act as the data

125
00:09:07,635 --> 00:09:10,580
foundation of predictive data of
continuously, I think the data from

126
00:09:11,295 --> 00:09:16,125
the input parameters and prepare
the real diamond historical signals

127
00:09:16,125 --> 00:09:18,345
from CICD system and infrastructure.

128
00:09:19,320 --> 00:09:25,130
So it'll collect, as you see in
the last log that all the data

129
00:09:25,130 --> 00:09:29,750
has been collected from different
log files, different data sources.

130
00:09:29,750 --> 00:09:33,980
For the CICD pipeline, all the
data has been act as a, the real

131
00:09:33,980 --> 00:09:37,760
time and historical signal from
CICD system and infrastructure.

132
00:09:38,360 --> 00:09:41,710
So there are different kind
of core capabilities for that.

133
00:09:41,920 --> 00:09:43,330
One is agent and collector.

134
00:09:43,830 --> 00:09:48,810
Agent, which kept, as I told earlier,
kept a log matrix events associated

135
00:09:48,810 --> 00:09:53,280
with different kind of application
and different kind of system, which

136
00:09:53,280 --> 00:09:56,790
are going to deploy in the CIC tool,
deployment and running environment.

137
00:09:56,840 --> 00:10:02,930
In incorporated in the system, different
kind of streaming and batch ingestion,

138
00:10:03,650 --> 00:10:09,370
which supports both real-time pipelines
and batch uploads, normalization.

139
00:10:09,870 --> 00:10:14,580
And transform heterogeneous data
into undefined model ready format.

140
00:10:14,580 --> 00:10:17,405
So if you see the right hand side,
I have provided all the data.

141
00:10:18,180 --> 00:10:23,340
Have provided all the step by step for the
ingestion and tele layer where it comes.

142
00:10:23,700 --> 00:10:25,770
If you see the in the emission pipeline.

143
00:10:25,775 --> 00:10:29,250
After ingestion pipeline, after
getting the data agent collect the

144
00:10:29,250 --> 00:10:34,080
data from different log system tric and
events, it is pushed to the ingestion

145
00:10:34,080 --> 00:10:35,775
pipeline, which streaming the data.

146
00:10:36,275 --> 00:10:39,245
Batch processing and
normalization enhancement.

147
00:10:39,755 --> 00:10:44,135
So this is normalization, enrichment
schema, alignment and context tagging.

148
00:10:44,495 --> 00:10:46,895
All the normalization and
enrichment done based on the

149
00:10:46,895 --> 00:10:48,995
data after ingestion pipeline.

150
00:10:48,995 --> 00:10:54,035
Then model ready telemetry layer
comes in picture, which take the

151
00:10:54,035 --> 00:10:55,745
the unified and trusted data.

152
00:10:56,245 --> 00:11:01,935
So this is the best pillar by
which we can assure that the

153
00:11:01,935 --> 00:11:03,270
data prediction will be accurate.

154
00:11:03,770 --> 00:11:07,520
With the reliable,
undefined, unified telemetry.

155
00:11:08,020 --> 00:11:11,620
Now I am moving to the next slide,
which is feature engineering.

156
00:11:11,980 --> 00:11:17,220
So feature engineering also is a step
of that DevOps, predictive DevOps

157
00:11:17,220 --> 00:11:22,500
and ai, C-D-C-I-C implementation,
which purpose is mainly to.

158
00:11:23,000 --> 00:11:26,030
Change this signal, trend,
windows, and an baseline.

159
00:11:26,030 --> 00:11:29,240
There are other purposes also,
but these three are normally,

160
00:11:29,240 --> 00:11:31,420
more impactable to the system.

161
00:11:31,930 --> 00:11:37,360
So there is other core capabilities, which
includes agents and collectors, streaming,

162
00:11:37,360 --> 00:11:40,060
band, batch, anomaly, waistlines.

163
00:11:40,540 --> 00:11:45,670
So these are all the steps and all
the objects and prostitutes of the.

164
00:11:46,170 --> 00:11:47,130
Feature engineering.

165
00:11:47,130 --> 00:11:50,190
Feature engineering plays a ATE role.

166
00:11:50,850 --> 00:11:57,030
You know how to minimize the risk,
to minimize the signal data by

167
00:11:57,030 --> 00:12:00,000
changing the signal it code call by.

168
00:12:00,000 --> 00:12:05,040
There is set process, which is
like code complexity, dependency

169
00:12:05,040 --> 00:12:07,140
analysis, component nature.

170
00:12:07,140 --> 00:12:12,815
So this kind of process helps to
get those restricted result and.

171
00:12:13,765 --> 00:12:17,700
To accurately measure the
risk and the other parameter

172
00:12:18,570 --> 00:12:19,980
to proceed to the next step.

173
00:12:20,520 --> 00:12:25,670
So this is a very vital step of
our imple, of our implementation.

174
00:12:25,880 --> 00:12:30,020
So the next one is, as I already
told, that AI analysis transform the

175
00:12:30,050 --> 00:12:31,850
raw CIC data into predictive feature.

176
00:12:32,350 --> 00:12:36,055
So in this portion, AI analysis,
it took say vital role.

177
00:12:36,555 --> 00:12:38,295
In that particular implementation?

178
00:12:38,795 --> 00:12:41,915
No, I am providing the model
later Model layer is the purpose

179
00:12:41,915 --> 00:12:42,815
of the forecasting layer.

180
00:12:43,210 --> 00:12:44,110
In the model layer.

181
00:12:44,110 --> 00:12:49,580
It'll where, as I told, we have to apply,
we'll apply the model we'll apply the

182
00:12:49,610 --> 00:12:55,040
machine learning algorithm, train the
data based on the historical data or.

183
00:12:55,535 --> 00:12:59,845
Similarly data here I can, I have
given an example of time series,

184
00:12:59,845 --> 00:13:04,875
forecast model, and other data
predicted pipeline outcomes.

185
00:13:04,875 --> 00:13:07,870
And the prioritize.

186
00:13:08,370 --> 00:13:12,310
Prioritize the, prioritize the
al layer gate and al layer.

187
00:13:12,705 --> 00:13:15,605
These are the all the
steps for the model layer.

188
00:13:15,665 --> 00:13:16,205
In model.

189
00:13:16,205 --> 00:13:20,915
Basically summarize what we will
do based on the historical data we

190
00:13:20,915 --> 00:13:25,145
upload different kind of algorithm,
different kind of AI logic on top of

191
00:13:25,145 --> 00:13:30,635
that to get the predicted data for the
particular application or deployment.

192
00:13:31,175 --> 00:13:32,705
So that is all about that.

193
00:13:32,705 --> 00:13:35,225
Now I'm moving to the
next slide, which is.

194
00:13:36,200 --> 00:13:38,780
Which is about model layer anomaly.

195
00:13:39,080 --> 00:13:43,280
An limitation means the anomaly
layer, continuously monitor, CICD, and

196
00:13:43,280 --> 00:13:48,200
runtime signals to identify abnormal
patterns are the enabling to active

197
00:13:48,200 --> 00:13:49,970
intervention before propagate failure.

198
00:13:50,300 --> 00:13:54,560
So this is all about the out outline
and abnormal data, which are not

199
00:13:54,560 --> 00:13:55,850
in different kind of pattern.

200
00:13:56,630 --> 00:14:00,980
So we use different kind of log pattern
detection, so some kind of outline.

201
00:14:01,340 --> 00:14:01,850
Outline.

202
00:14:01,940 --> 00:14:04,400
You can see in every
data, in every system.

203
00:14:04,945 --> 00:14:08,325
But what we can do using different
kind of logic, different kind of

204
00:14:08,325 --> 00:14:10,395
tactic and technique and tactics.

205
00:14:10,395 --> 00:14:16,395
We will outline those abnormal patterns
and those data, which may cause

206
00:14:16,725 --> 00:14:19,335
error and may lead to the failure.

207
00:14:19,515 --> 00:14:22,350
So that is all about the
process of anomaly detection.

208
00:14:22,530 --> 00:14:25,200
In the right hand side, I have
provided all the details slips

209
00:14:25,200 --> 00:14:28,770
of the anomaly detection, which
is a baseline behavior model.

210
00:14:29,270 --> 00:14:34,250
Anomaly detection engine, early warning
signals and vision and response layer.

211
00:14:34,940 --> 00:14:40,430
All the particular each and every step
are also subclassified into different

212
00:14:40,850 --> 00:14:47,290
processes like baseline behavior model
have two main processes, which is normal

213
00:14:47,290 --> 00:14:51,190
log patterns and expected metrics range.

214
00:14:51,640 --> 00:14:56,175
So animal detection surfaces weak
signals before they became failures.

215
00:14:56,675 --> 00:14:59,645
Now I am moving to the next slide,
which is the risk scoring engine.

216
00:14:59,645 --> 00:15:05,840
Purpose of the risk scoring engine is
it acts as a engine of the predictive

217
00:15:05,840 --> 00:15:08,200
device by synthesizing the output.

218
00:15:08,200 --> 00:15:14,470
What it do from the different model,
it produce a signal context, a this

219
00:15:15,010 --> 00:15:17,505
signal for each pipeline execution.

220
00:15:18,005 --> 00:15:22,535
And there are some different kind of core
functionality of combined model output,

221
00:15:22,595 --> 00:15:28,725
aggressive forecasting, anomaly score, and
historical signal into unified risk view.

222
00:15:28,845 --> 00:15:31,785
And there is another one core
function like context dev scoring.

223
00:15:32,325 --> 00:15:35,235
So these are all the different
tapes and different process which

224
00:15:35,235 --> 00:15:38,835
use for the risk scoring engine
and inside the risk scoring engine.

225
00:15:39,225 --> 00:15:43,620
So it used the, it, its
main activities like it.

226
00:15:43,995 --> 00:15:50,595
If it is used for multiple signal to
trust, based on the logic in the different

227
00:15:50,595 --> 00:15:55,305
kind of vision, to take the different kind
of decision and push those different kind

228
00:15:55,305 --> 00:15:57,075
of multiple signal to different model.

229
00:15:57,525 --> 00:16:03,105
And on top of that, we used to generate
the output data to get the actual output.

230
00:16:03,495 --> 00:16:07,995
So why it matters, it eliminates
fragmented signal, enables

231
00:16:07,995 --> 00:16:12,495
consistent explainable durations,
balance speed with safety.

232
00:16:12,995 --> 00:16:19,315
So engine, this is one of the
most important steps and important

233
00:16:19,345 --> 00:16:21,815
part of the predictive DevOps.

234
00:16:21,845 --> 00:16:23,805
So it's, it is role of the vision engine.

235
00:16:24,245 --> 00:16:29,190
So how did, does the particular in
Dday role in the predictive DevOps,

236
00:16:30,370 --> 00:16:34,750
in a contextual manner, it insight
into clear actionable pipeline vision,

237
00:16:34,780 --> 00:16:39,340
ensuring the right balance between
C speed, safety and reliability.

238
00:16:39,700 --> 00:16:44,080
If you see the division engine, there is
different kind of policy, different kind

239
00:16:44,080 --> 00:16:50,590
of risk threshold consists evolution by
which this maintain the different kind

240
00:16:50,590 --> 00:16:52,135
of, and monitor the different kind of.

241
00:16:53,065 --> 00:16:55,585
Metrics like speed,
safety, and reliability.

242
00:16:55,645 --> 00:16:59,455
Okay, so there is different kind
of co responsibility associated

243
00:16:59,455 --> 00:17:04,165
with the decision engine, which is
gate or hello pipeline execution.

244
00:17:04,705 --> 00:17:09,355
Determine whether the pipeline
stage should proceed, pause, or be

245
00:17:09,355 --> 00:17:11,395
blocked based on the risk threshold.

246
00:17:11,665 --> 00:17:11,995
Okay?

247
00:17:11,995 --> 00:17:14,775
There is different others
also recommended intelligent

248
00:17:15,275 --> 00:17:18,035
escalation rules, white matters.

249
00:17:18,125 --> 00:17:18,545
Okay?

250
00:17:18,900 --> 00:17:21,900
So as I told you, if you see
the right hand side, there is

251
00:17:21,900 --> 00:17:23,310
yellow pipeline gate pause.

252
00:17:23,700 --> 00:17:27,570
All the, after going to the decision
engine and the PO applying the

253
00:17:27,570 --> 00:17:30,930
rule, different kind of policies
and rule, different kind of

254
00:17:31,140 --> 00:17:35,580
parameter, like this threshold, we
applied different kind of context.

255
00:17:35,580 --> 00:17:38,280
We applied for the evolution process.

256
00:17:38,550 --> 00:17:42,960
After that, the output data go to the
pipeline and different kind of gate

257
00:17:43,020 --> 00:17:46,380
and different kind of CICD pipeline.

258
00:17:46,380 --> 00:17:47,100
Action has been.

259
00:17:48,030 --> 00:17:48,630
Taken place.

260
00:17:48,630 --> 00:17:52,290
If it is successful, all the data
accurate, then it is deployed.

261
00:17:52,290 --> 00:17:56,580
Otherwise, it is red outted
to the model to learn the

262
00:17:56,580 --> 00:17:58,680
model and get the actual data.

263
00:17:59,010 --> 00:18:00,120
So why it matters?

264
00:18:00,540 --> 00:18:03,485
So it prevent risky deployments review.

265
00:18:03,905 --> 00:18:05,140
So this is a very vital point.

266
00:18:05,405 --> 00:18:09,875
It always used to prevent risky
deployments, reduce unnecessary failure

267
00:18:09,875 --> 00:18:14,825
and details, and keep human in the
loop only when needed, otherwise not.

268
00:18:15,325 --> 00:18:19,495
The reasoning in terms the risk
intelligence into control action.

269
00:18:19,995 --> 00:18:21,405
So this here, nothing.

270
00:18:21,405 --> 00:18:23,775
But if you see, I have tried to.

271
00:18:24,205 --> 00:18:28,975
Describe the end-to-end predictive dev
of flow, purpose of the end-to-end flow

272
00:18:29,725 --> 00:18:35,245
the end-to-end flow components like
coaching, trigger, signal collect, analyze

273
00:18:35,745 --> 00:18:41,475
production, execution, and addition action
pipeline and outcome feed, landing loop.

274
00:18:42,015 --> 00:18:43,545
So why it is used?

275
00:18:43,755 --> 00:18:44,895
What is the purpose?

276
00:18:45,495 --> 00:18:47,895
So it is used.

277
00:18:48,600 --> 00:18:53,010
From code change to deployment, combining
data intelligence edition and automated

278
00:18:53,010 --> 00:18:56,700
action, there are different kind of other
action on, so other parts it is used

279
00:18:57,240 --> 00:19:02,180
the basic purpose, which it is used,
I have already mentioned in our slide.

280
00:19:03,050 --> 00:19:06,290
So there is different kind of
outcomes, which is separate releases,

281
00:19:06,295 --> 00:19:11,070
faster feedback, scalable DevOps
operation, predictive DevOps.

282
00:19:11,730 --> 00:19:16,170
Connect intelligence, automation and
learning into one continuous system.

283
00:19:16,830 --> 00:19:20,385
So in the right hand side, I
provided the detail step by step,

284
00:19:20,385 --> 00:19:23,325
like CO could commit, pull request.

285
00:19:24,135 --> 00:19:29,625
Then CICD, data and telemetry step
after that, the AI model forecasting and

286
00:19:29,955 --> 00:19:36,090
anomalies, then the cooling and addition,
then gate islet, then action layer.

287
00:19:36,340 --> 00:19:38,380
Then the deployment and
the runtime monitoring.

288
00:19:38,880 --> 00:19:40,290
There is pipeline integration.

289
00:19:40,290 --> 00:19:44,580
Also, how pipeline integration take
picture after the previous step.

290
00:19:45,210 --> 00:19:48,300
There are different kind of key
integration characteristics, which

291
00:19:48,300 --> 00:19:52,800
includes work within existing tool, like
there are different kind of tools, but.

292
00:19:53,300 --> 00:19:56,210
In different scenario, we'll
apply different kind of tools.

293
00:19:56,330 --> 00:20:00,530
This is purely based on the business
scenario and the business requirement.

294
00:20:01,130 --> 00:20:03,020
No CICD replacement.

295
00:20:03,020 --> 00:20:06,530
Existing pipeline and workflow
remain unchanged in that case.

296
00:20:07,250 --> 00:20:10,610
Lightweight integration method
here, different kind of comes

297
00:20:10,610 --> 00:20:14,360
in picture and play a vital
role in that particular process.

298
00:20:14,660 --> 00:20:15,950
Operation advantages.

299
00:20:16,715 --> 00:20:20,645
There are different kind of operation
advantages for that this step is there.

300
00:20:21,215 --> 00:20:25,625
So among them, I have noted down few
steps, like these few advantages,

301
00:20:25,625 --> 00:20:30,815
like faster rollout with minimum
risk, no returning of team,

302
00:20:31,315 --> 00:20:33,475
immediate value without disruption.

303
00:20:33,955 --> 00:20:37,705
So this is all about predictive
DevOps enhanced pipeline without

304
00:20:37,705 --> 00:20:39,745
replacing existing CICD systems.

305
00:20:40,245 --> 00:20:45,605
Predictive maintenance predict is health
cluster capacity, node failure prediction.

306
00:20:46,475 --> 00:20:48,935
These are the all the
predictive maintenance state,

307
00:20:49,085 --> 00:20:50,375
which I already provided.

308
00:20:50,675 --> 00:20:52,955
So predictive maintenance
is better than cured.

309
00:20:52,955 --> 00:20:53,825
If you see.

310
00:20:54,325 --> 00:20:55,135
Using prediction.

311
00:20:55,135 --> 00:20:57,630
If you predict that particular
system is going to down or

312
00:20:57,630 --> 00:21:00,840
particular log file is not going
to come tomorrow, then it's better.

313
00:21:01,240 --> 00:21:05,830
We can identify and fix that particular
problem before ahead of tomorrow

314
00:21:06,250 --> 00:21:09,700
to get the accurate results so that
our business will not interrupt

315
00:21:09,700 --> 00:21:11,350
and not delay, and will not stop.

316
00:21:11,850 --> 00:21:16,135
So prevent outages, it'll, if we
do use this predictive feature,

317
00:21:16,135 --> 00:21:20,155
then it'll prevent outages with
early maintenance before issue.

318
00:21:20,655 --> 00:21:21,760
So this is the end to end.

319
00:21:21,975 --> 00:21:24,765
I provided commit, predict,
act, deploy, and learn.

320
00:21:25,265 --> 00:21:29,105
This is the continuous lin loop,
which I told like it's kindly the

321
00:21:29,105 --> 00:21:30,605
enforcement lining kind of thing.

322
00:21:30,605 --> 00:21:34,325
When there is a marginal
difference between the actual

323
00:21:34,325 --> 00:21:38,465
forecasted and the predicted
data, what it does, it sends the.

324
00:21:39,050 --> 00:21:42,050
Output again to the different
error coefficient again to

325
00:21:42,050 --> 00:21:45,380
the model to tune that model.

326
00:21:45,380 --> 00:21:49,820
And similarly it loop one by
one until it'll, the result is

327
00:21:49,820 --> 00:21:51,980
very close to the actual result.

328
00:21:52,910 --> 00:21:55,130
So that is all about the
continuous learning loop.

329
00:21:55,400 --> 00:21:59,480
As you see, I put all the diagram, how
it works and order the component for

330
00:21:59,480 --> 00:22:01,280
the predictive intelligence system.

331
00:22:01,490 --> 00:22:03,800
This is predicting get
smarter with every cycle.

332
00:22:03,830 --> 00:22:08,415
That's why what I was trying to tell,
like every cycle after we push the air

333
00:22:09,345 --> 00:22:14,805
ion again to the model to learn and turn
the model, the gap between the actual

334
00:22:15,135 --> 00:22:20,850
and forecast and predictive data getting
very less and are getting very closer.

335
00:22:21,350 --> 00:22:23,540
There is some operational
benefits for that.

336
00:22:23,750 --> 00:22:29,570
One of the, which is the reduced MPTR
stable pipelines and less firefighting.

337
00:22:29,570 --> 00:22:33,710
So these are all the pillar of
a particular good system using

338
00:22:33,710 --> 00:22:35,060
predictive type of platinum.

339
00:22:35,060 --> 00:22:40,495
There are different kind of processes
and different kind of rules, logic.

340
00:22:41,060 --> 00:22:45,410
Using which we can stable the pipelines
and get the faster recovery for the

341
00:22:45,410 --> 00:22:50,810
system and application with lower,
oops noise, lower business impact.

342
00:22:51,320 --> 00:22:55,850
This is, and we get the finally
operational excellence on, based on

343
00:22:55,850 --> 00:22:57,380
the reliability and predictability to.

344
00:22:57,880 --> 00:22:59,110
Business impact business.

345
00:22:59,710 --> 00:23:04,540
Business impact is if we have some
predictive predictive DevOps on top

346
00:23:04,550 --> 00:23:09,110
instead of the traditional DevOps
and deployment environment, we can

347
00:23:09,560 --> 00:23:13,880
release the item and release the
production deployment faster, lower

348
00:23:13,940 --> 00:23:15,560
the risk, higher the confidence.

349
00:23:16,060 --> 00:23:19,690
Then the next one what I
put some kind of, you know.

350
00:23:20,190 --> 00:23:23,880
Some kind of command, which
used for the CICD actions.

351
00:23:24,240 --> 00:23:25,170
Everybody knows that.

352
00:23:25,170 --> 00:23:28,510
So nothing to, go through that
for the sample purpose I just put.

353
00:23:28,690 --> 00:23:32,560
So it is a key picture what we are
taking away from this particular.

354
00:23:32,985 --> 00:23:34,695
Presentation and particular talk.

355
00:23:34,765 --> 00:23:40,130
So the main idea is that predictive dev
representative shift from the relative

356
00:23:40,850 --> 00:23:45,770
deliver to intelligent, proactive software
operation powered by EI and automation.

357
00:23:46,130 --> 00:23:51,190
So it is far better than the
traditional system and application.

358
00:23:51,700 --> 00:23:55,885
So there is, I always say that
prediction is better than a reaction,

359
00:23:56,155 --> 00:23:59,450
which is the key tip for this
message and the AI augmented DevOps.

360
00:23:59,950 --> 00:24:01,300
Not replaces it.

361
00:24:01,600 --> 00:24:03,670
And automation must be this.

362
00:24:03,670 --> 00:24:06,940
C. These are the some key features
and key takeaway we'll be taking

363
00:24:06,940 --> 00:24:09,370
from this particular talk.

364
00:24:09,870 --> 00:24:12,990
So all this thing I have learned
provided like learning system

365
00:24:12,990 --> 00:24:14,700
outperforms static pipelines.

366
00:24:15,150 --> 00:24:19,980
Continuous feedback, ensure the
system improves with every release.

367
00:24:19,980 --> 00:24:21,330
Strategic insights.

368
00:24:21,830 --> 00:24:23,180
This is all about the predictive.

369
00:24:23,890 --> 00:24:24,550
All about that.

370
00:24:24,850 --> 00:24:28,480
DevOps with ai, CICD implementation.

371
00:24:28,980 --> 00:24:31,710
Thank you for watching
the particular session.

372
00:24:31,710 --> 00:24:32,160
Thank you.

373
00:24:32,460 --> 00:24:32,880
And thank you.

374
00:24:32,880 --> 00:24:38,420
I would like to thank you to the
organizer for this wonderful opportunity.

375
00:24:38,420 --> 00:24:39,380
Thank you

376
00:24:39,380 --> 00:24:39,400
so much.

