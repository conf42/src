1
00:00:00,900 --> 00:00:01,560
Hello everyone.

2
00:00:01,830 --> 00:00:06,270
Welcome to Con 42, prompt
Engineering, another session.

3
00:00:06,430 --> 00:00:07,840
My name is Jamis Akia.

4
00:00:07,960 --> 00:00:11,020
I'm a solution architect at Snowflake.

5
00:00:11,920 --> 00:00:17,340
Today I'm going to cover the topic for
prompt engineering for data engineering

6
00:00:17,979 --> 00:00:21,880
how we can unlock the natural language
access to cloud data platform.

7
00:00:22,380 --> 00:00:27,679
I have been working in data and
analytics field for almost 12 years now.

8
00:00:28,190 --> 00:00:31,669
I have lots of experience working
with lots of different clients on

9
00:00:32,209 --> 00:00:33,980
different data engineering projects.

10
00:00:34,069 --> 00:00:39,830
Also lots of implementation on
cloud, on-prem, cloud data platform.

11
00:00:40,250 --> 00:00:42,110
Also have done lots of migrations.

12
00:00:42,710 --> 00:00:46,230
From on-prem to cloud data
platform and then worked with all

13
00:00:46,230 --> 00:00:48,270
across different domains also.

14
00:00:48,850 --> 00:00:53,350
And I can definitely see here the
impact of how the prompt engineering

15
00:00:53,350 --> 00:00:55,540
can play in data engineering.

16
00:00:56,040 --> 00:01:01,590
So to start with how the evaluation
of data access was and now how

17
00:01:01,590 --> 00:01:03,090
it's getting evolved over the time.

18
00:01:03,930 --> 00:01:08,410
Data engineering is always, and
as of now also is more of attack.

19
00:01:09,250 --> 00:01:14,650
We consider that we need a people,
data engineers or data developers

20
00:01:14,650 --> 00:01:16,300
to do some of these things.

21
00:01:16,660 --> 00:01:20,920
They have to either write a very
complex SQL views or they have to create

22
00:01:20,920 --> 00:01:22,840
lots of different store procedures.

23
00:01:23,230 --> 00:01:28,360
They also have to do lots of scripting
and then also have to manually manage lots

24
00:01:28,360 --> 00:01:31,150
of pipelines that are coming from source.

25
00:01:31,330 --> 00:01:32,830
And then we are transforming the data.

26
00:01:33,520 --> 00:01:36,490
And then also we have to do lots
of monitoring, lots of security

27
00:01:36,490 --> 00:01:38,320
concerns, lots of data governance.

28
00:01:38,620 --> 00:01:41,200
So all of that goes into
the traditional approach.

29
00:01:42,040 --> 00:01:46,090
What we are seeing now with LRM
that there will be a revolution

30
00:01:46,480 --> 00:01:52,090
of this data engineering by using
large language models, which will

31
00:01:52,210 --> 00:01:56,510
change the paradigm using lots of
different things that can be enabled.

32
00:01:57,335 --> 00:02:00,935
And reduce some of the time
complexity and make it easy for

33
00:02:00,935 --> 00:02:04,904
everyone to use and implement data
engineering and data ecosystem

34
00:02:05,404 --> 00:02:07,375
less technical trainings required.

35
00:02:08,065 --> 00:02:12,780
And we can also de democratize the data
across the enterprise very quickly.

36
00:02:13,280 --> 00:02:16,150
So LLMs are definitely beyond chatbots.

37
00:02:16,150 --> 00:02:19,330
When initially when we
heard about chat, GPT.

38
00:02:19,750 --> 00:02:22,750
Everyone was like, okay, it looks
like this is what LLM looks like.

39
00:02:22,750 --> 00:02:26,140
If you prompt for something,
either you get a output.

40
00:02:26,140 --> 00:02:30,100
So you converse con, like it's a
conversational AI where you can talk

41
00:02:30,100 --> 00:02:33,860
with the chat bots and you can get
your answers, question questions

42
00:02:33,860 --> 00:02:35,870
answered, stuff like that very quickly.

43
00:02:36,280 --> 00:02:39,429
And also you can, content generation
is a very big application right

44
00:02:39,429 --> 00:02:41,019
now where everyone is using that.

45
00:02:41,500 --> 00:02:44,799
There is so many different things you
can do with chat, GPT and all the other

46
00:02:44,799 --> 00:02:46,210
tools that are coming in the market.

47
00:02:46,790 --> 00:02:52,660
But there is a potential for LLMs in data
engineering for making our transformations

48
00:02:53,030 --> 00:02:58,070
on how we consume our data from cloud data
platform and LLM can definitely breach

49
00:02:58,550 --> 00:03:03,109
some gap between the business users and
the technical data infrastructure that

50
00:03:03,109 --> 00:03:08,180
we always face, challenge with how fast
we can turn around things, how fast the

51
00:03:08,180 --> 00:03:10,160
data can be accessible for everyone.

52
00:03:10,609 --> 00:03:13,100
So some of the applications
that we can definitely think of.

53
00:03:13,984 --> 00:03:18,555
With LLMs in data engineering
number one is query generation.

54
00:03:19,395 --> 00:03:24,734
We can definitely convert the natural
language, respond to get a optimized sql.

55
00:03:25,234 --> 00:03:29,285
This can be done on a cloud data
platform like Snowflake using some of

56
00:03:29,285 --> 00:03:33,454
the technologies that they are offering
already, like Cortex Analyst, snowflake

57
00:03:33,454 --> 00:03:38,225
Intelligence, and we can definitely see
some of the other companies are also using

58
00:03:38,614 --> 00:03:41,010
some of this LLM data engineering tools.

59
00:03:41,385 --> 00:03:47,684
Like E-T-L-E-L-T, tools like DBT is also
already using that pipeline orchestration,

60
00:03:48,284 --> 00:03:50,054
triggering workflows through conversation.

61
00:03:50,534 --> 00:03:55,184
I want to run something that was
run last night just to fix something

62
00:03:55,184 --> 00:03:56,924
that is updated in the source side.

63
00:03:57,434 --> 00:04:03,494
I can just say run the last run last
night runs and it'll run for you.

64
00:04:04,244 --> 00:04:08,984
And that's one of the advantage you can
take from the LLM Prompt engineering.

65
00:04:09,869 --> 00:04:11,639
And definitely real time analytics.

66
00:04:11,639 --> 00:04:13,409
I want to find something about my data.

67
00:04:13,409 --> 00:04:17,459
I want to learn about where the
sales are, high orders are getting

68
00:04:17,729 --> 00:04:22,179
less, what region is impacted,
if I have any company wide issue.

69
00:04:22,389 --> 00:04:24,489
Those are the things I
can definitely talk to.

70
00:04:24,489 --> 00:04:28,809
Data on the fly with my real time
analytics using natural language.

71
00:04:29,309 --> 00:04:32,709
To implement this LRM, prompt
Engineering there are core

72
00:04:32,709 --> 00:04:34,244
components that we have to focus.

73
00:04:34,849 --> 00:04:39,839
When it comes to data engineering
number one is context optimization.

74
00:04:40,709 --> 00:04:45,419
We have to provide LLMs enough
information, business information,

75
00:04:45,839 --> 00:04:50,219
and also the relationship between the
data to ensure that the query that

76
00:04:50,219 --> 00:04:54,089
are getting generated are accurate
and we are getting the quality output.

77
00:04:54,899 --> 00:04:56,699
There are lots of different
ways you can do that.

78
00:04:56,759 --> 00:04:59,369
You can make sure that all
your data quality is good.

79
00:04:59,759 --> 00:05:02,489
You create a business
layer using semantic.

80
00:05:03,139 --> 00:05:08,389
Views or semantic models that has more
information that business users also

81
00:05:08,389 --> 00:05:13,849
have relation between different terms,
different law logics, how you calculate

82
00:05:13,849 --> 00:05:18,959
things, what is, what those type of
information can be stored in a layer.

83
00:05:19,259 --> 00:05:21,509
And it helps with the
context optimization.

84
00:05:21,959 --> 00:05:25,679
The more context you provide
to RLM more accurate and more

85
00:05:25,679 --> 00:05:27,209
fast, you get the output.

86
00:05:27,709 --> 00:05:28,819
Prompt design pattern.

87
00:05:29,599 --> 00:05:34,189
You can talk to LLMs, you can get the
answers, but if you write a particular

88
00:05:34,189 --> 00:05:39,319
thing or write questions in a particular
manner, you get a particular answers.

89
00:05:39,769 --> 00:05:42,679
So if we know that what are the
different templates that we need to

90
00:05:42,679 --> 00:05:47,539
follow, we can actually create reusable
templates, which guides the business

91
00:05:47,539 --> 00:05:51,079
users to successfully interact and also.

92
00:05:51,674 --> 00:05:54,794
Get the consistent output if
there is requirement of that.

93
00:05:55,094 --> 00:05:58,394
And then there is a doc access,
which is always there, but we

94
00:05:58,394 --> 00:06:02,144
want to make sure that there are
standardizations across, if there is

95
00:06:02,504 --> 00:06:04,574
requirement of doing that for business.

96
00:06:05,074 --> 00:06:10,774
We also have to make sure validation is
done on a data integrity and data quality.

97
00:06:11,194 --> 00:06:15,844
We have to implement lots of
implement safeguards to verify that

98
00:06:15,874 --> 00:06:17,434
the output that we are generating.

99
00:06:17,854 --> 00:06:21,214
From the existing model is as expected.

100
00:06:21,304 --> 00:06:25,754
There needs to be a rigorous testing and
lots of different validation that needs

101
00:06:25,754 --> 00:06:30,014
to happen before we allow it to get used
by the business users in production.

102
00:06:30,794 --> 00:06:35,444
And then last but not least, we have
to also have feedback loops, which is a

103
00:06:35,444 --> 00:06:40,184
human interaction, that we continuously
refine the prompts based on the user

104
00:06:40,184 --> 00:06:44,864
interaction and model con performance
to improve the accuracy over the time.

105
00:06:45,134 --> 00:06:50,354
A model can learn from itself once it
starts generating the quality outputs.

106
00:06:50,444 --> 00:06:52,604
So it's very important
to have a feedback loops.

107
00:06:53,104 --> 00:06:57,094
Now, what is the biggest advantage that
we will get with this prompt engineering?

108
00:06:57,314 --> 00:06:58,244
In data engineering?

109
00:06:58,584 --> 00:07:03,654
The most powerful outcome we can see here
is deep democratization of data access.

110
00:07:04,194 --> 00:07:06,984
Business users can ask
questions in plain language.

111
00:07:07,434 --> 00:07:10,674
They don't have to go to the IT teams
or technical experts every time.

112
00:07:11,079 --> 00:07:14,269
For some of the things that
they want to get answers from.

113
00:07:15,019 --> 00:07:19,939
They also have something that we can
build, which allows them to transfer the

114
00:07:19,939 --> 00:07:24,229
technical operations, if any, that can
be handled through the LLM interface.

115
00:07:24,559 --> 00:07:28,279
Now this can be a little complex depending
on the business requirements, like what

116
00:07:28,279 --> 00:07:32,569
type of interface that you want to build,
but you normally want to build something

117
00:07:32,569 --> 00:07:37,939
that allows technical users to also
monitor, but also business users to run.

118
00:07:38,344 --> 00:07:39,214
On the fly.

119
00:07:39,454 --> 00:07:42,274
If they have to do something, if they
need to do a data refresh, if they

120
00:07:42,274 --> 00:07:46,084
need to get additional data source,
those type of things can still be

121
00:07:46,114 --> 00:07:48,274
handled through the LLM interface.

122
00:07:48,904 --> 00:07:53,734
And then last but not list, we can have
the cloud data platform like Snowflake,

123
00:07:54,184 --> 00:07:58,234
which allows business users to execute
and return results very quickly.

124
00:07:58,624 --> 00:08:01,624
There are so many different things
you can do in the cloud data

125
00:08:01,624 --> 00:08:05,884
platform with AI enabled with
lots of features that are coming.

126
00:08:06,274 --> 00:08:09,424
That can allow business
users to feel empowered.

127
00:08:09,784 --> 00:08:14,174
It's a less it's a less work
for the analytics engineer,

128
00:08:14,234 --> 00:08:20,124
engineers to enable users and
also get things created very fast.

129
00:08:20,124 --> 00:08:25,044
The value for the data can be
get very fast, and it can be

130
00:08:25,044 --> 00:08:27,504
created and built for scalability.

131
00:08:28,004 --> 00:08:29,804
What are some of the real world examples?

132
00:08:29,864 --> 00:08:32,774
We already talked about ad aocc querying.

133
00:08:33,304 --> 00:08:37,054
We dis users can basically ask
questions on what they want to see

134
00:08:37,054 --> 00:08:41,584
from the data, if the data is created
with the high level of semantics.

135
00:08:42,154 --> 00:08:45,244
The example here we can see,
show me the customer retention

136
00:08:45,244 --> 00:08:47,554
rates by region for quarter four.

137
00:08:47,974 --> 00:08:52,774
Now, if the prompt and prompt engineering
will go back to the model, and if

138
00:08:52,774 --> 00:08:54,754
we have all the schema and data.

139
00:08:55,099 --> 00:08:56,750
Relationship define in a way.

140
00:08:57,199 --> 00:09:01,310
And then the answers we will get
either, we can ask that it creates

141
00:09:01,310 --> 00:09:04,939
a SQL query and you copy paste the
SQL query and run the SQL query or

142
00:09:04,939 --> 00:09:06,829
verify the SQL query before it runs.

143
00:09:07,430 --> 00:09:09,380
And then once it's run,
it gives you the output.

144
00:09:09,530 --> 00:09:13,040
And then output can be either in the
tabular format, chart, format, whatever

145
00:09:13,040 --> 00:09:14,300
the preference that users have.

146
00:09:14,569 --> 00:09:17,780
So you can do some of those things
where you want to add a validation

147
00:09:18,360 --> 00:09:20,430
point, and then also create the charts.

148
00:09:20,490 --> 00:09:22,920
Or sometimes if you don't want
people who are not technical.

149
00:09:23,339 --> 00:09:26,699
We can directly give them the
output pipeline management.

150
00:09:26,699 --> 00:09:29,659
This is more for the developer team
or the monitoring team or the admin

151
00:09:29,659 --> 00:09:34,249
team that can trigger things like ETL
processes, schedule jobs, monitor data

152
00:09:34,249 --> 00:09:36,349
flows through the conventional command.

153
00:09:36,799 --> 00:09:39,889
Like they can just def if I want to
run a particular nightly customer

154
00:09:39,889 --> 00:09:44,449
aggregation pipeline, I don't have
to go in the scheduling tool and

155
00:09:44,449 --> 00:09:46,069
search for the job that does that.

156
00:09:46,309 --> 00:09:51,439
I can just run the prompt and say, run
the nightly customer aggregation pipeline.

157
00:09:51,799 --> 00:09:54,739
And it should run the right job for me.

158
00:09:55,239 --> 00:09:59,889
And then data exploration, which is
a very, I will say, broad application

159
00:09:59,889 --> 00:10:04,839
right now that we can have, which allows
you to understand what's going on.

160
00:10:04,839 --> 00:10:08,019
You can run the hypothesis you
can run the marketing campaigns,

161
00:10:08,019 --> 00:10:10,989
you can run the analysis of what
type of products you can launch.

162
00:10:11,439 --> 00:10:13,029
It can give you lots of different things.

163
00:10:13,029 --> 00:10:17,819
It can be a a predictive engineering
or it can be a. Prescriptive

164
00:10:17,819 --> 00:10:21,819
engineering, whatever data that you
want to try and get the output for.

165
00:10:22,319 --> 00:10:23,709
So it's very application.

166
00:10:23,709 --> 00:10:25,959
You can see the example on the right
hand side, something like that.

167
00:10:25,959 --> 00:10:29,499
You have a natural language search on
the top, and then the things that you

168
00:10:29,499 --> 00:10:32,379
have built already can change according
to the search that you're doing.

169
00:10:32,379 --> 00:10:37,359
So it can be a very different ways of
doing prompt engineering embedded within

170
00:10:37,359 --> 00:10:40,999
BI or within your data exploration tools.

171
00:10:41,499 --> 00:10:44,709
There are challenges obviously,
to address because we do all know

172
00:10:44,759 --> 00:10:48,259
it's been lots of different topics
that people are talking about.

173
00:10:48,349 --> 00:10:50,329
One of them is accuracy and vaccination.

174
00:10:51,259 --> 00:10:56,119
How we can make sure that the accuracy
is at best, so that's one of the

175
00:10:56,299 --> 00:10:59,959
thing that we can avoid is by doing
rigorous validation and testing

176
00:10:59,959 --> 00:11:05,209
frameworks to prevent the data to be
giving anything that is not right.

177
00:11:05,709 --> 00:11:08,829
We have to also do some of the data
quality things, but also once the

178
00:11:08,829 --> 00:11:12,459
data quality checks are done and
model is using the data, we still

179
00:11:12,459 --> 00:11:13,749
need to do some of the testing.

180
00:11:14,289 --> 00:11:18,189
And then we have to define some
guide rails to avoid hallucinations

181
00:11:18,189 --> 00:11:22,599
because sometimes the LMS can think
that they are right and then they

182
00:11:22,599 --> 00:11:26,279
just go into the loop of doing the
things, which once they start doing.

183
00:11:26,759 --> 00:11:30,209
And if it's incorrect, then it always
going to give you the incorrect

184
00:11:30,359 --> 00:11:32,309
on output or incorrect answers.

185
00:11:32,714 --> 00:11:36,494
So to make sure that the guidelines
are there to say, okay, some looks

186
00:11:36,494 --> 00:11:40,634
like something is going wrong with
the model, and someone is able to make

187
00:11:40,634 --> 00:11:44,474
sure that the model is always running
in a way that it should run with the

188
00:11:44,474 --> 00:11:46,424
high accuracy and no hallucinations.

189
00:11:46,924 --> 00:11:50,494
The second big challenge is
data governance, security.

190
00:11:50,944 --> 00:11:52,654
This is independent of lms.

191
00:11:52,654 --> 00:11:56,404
We all know data governance and
security is always the critical

192
00:11:56,404 --> 00:11:57,694
part of the data ecosystem.

193
00:11:58,144 --> 00:11:59,224
We have to make sure.

194
00:11:59,629 --> 00:12:04,249
That we have all the possible data privacy
regulations, compilation compliance

195
00:12:04,249 --> 00:12:08,989
requirements, and then obviously make sure
that the permissions to models that are

196
00:12:09,019 --> 00:12:13,549
either reviewed from the security team or
we also want to make sure that the data

197
00:12:13,549 --> 00:12:19,459
that we want to pass onto these models are
gar guarded by not sharing anything that

198
00:12:19,459 --> 00:12:21,019
need, doesn't need to share to the model.

199
00:12:21,109 --> 00:12:24,199
Like any PII information,
any personal information.

200
00:12:24,619 --> 00:12:30,539
Any company data that is not,
does not qualify for using for

201
00:12:30,539 --> 00:12:33,899
ai as per the policies that are
defined at the organization level.

202
00:12:33,899 --> 00:12:37,759
You have to make sure that you
have the right data governance,

203
00:12:37,759 --> 00:12:41,449
security built on top of the
infrastructure that you're building.

204
00:12:41,449 --> 00:12:46,369
For LLMs model fine tuning, we have to
have fine tuning on the domain specific

205
00:12:46,369 --> 00:12:47,959
schemas and business terminologies.

206
00:12:48,574 --> 00:12:50,464
To improve the performance significantly.

207
00:12:50,914 --> 00:12:52,684
There are so many different
things you can do.

208
00:12:52,714 --> 00:12:56,854
You can define a layer, as I mentioned
before, which is a very good quality

209
00:12:56,854 --> 00:13:01,174
layer, which is basically business layer
that allows you to create semantics

210
00:13:01,174 --> 00:13:04,864
about what is what, how that, how
things happen, what is the business

211
00:13:04,864 --> 00:13:07,144
logic, what happens and what scenario.

212
00:13:07,144 --> 00:13:10,294
All those type of information,
other than the actual structure

213
00:13:10,294 --> 00:13:15,214
and unstructured data, helps the
context to get the model to tune.

214
00:13:15,794 --> 00:13:16,454
Much better.

215
00:13:16,454 --> 00:13:21,435
And if you want to get the model, give
more accurate answers, you can give more

216
00:13:21,435 --> 00:13:27,494
and more useful context that allows model
to tune itself or fine tune itself to

217
00:13:27,494 --> 00:13:30,435
get better output performance at scale.

218
00:13:30,674 --> 00:13:33,404
The one of the things that we
always heard about is that once

219
00:13:33,404 --> 00:13:38,114
we start using these models and
complex queries and large databases.

220
00:13:38,639 --> 00:13:42,209
The performance can be impacted
and how you can make sure of that.

221
00:13:42,239 --> 00:13:49,259
You want to make sure that you have
enough compute resources, but not always

222
00:13:49,319 --> 00:13:53,759
using all the resources, and you are
trying to do the things to make sure

223
00:13:53,759 --> 00:13:57,809
the performance is always responsive
and user experience is always better.

224
00:13:58,309 --> 00:14:03,469
And you can do that by doing optimization
strategies that can be used to make

225
00:14:03,469 --> 00:14:06,499
sure the performance is always better
when you're performing at the scale.

226
00:14:06,999 --> 00:14:09,729
As I said, governance is
the foundation of trust.

227
00:14:10,149 --> 00:14:12,549
If we can use any.

228
00:14:13,049 --> 00:14:17,219
To deploy the successful LLM, we have
to make sure we have a very robust

229
00:14:17,759 --> 00:14:20,339
governance frameworks, access control.

230
00:14:20,729 --> 00:14:24,269
We have security column masking
and force automatically.

231
00:14:24,689 --> 00:14:26,579
You can define data masking policies.

232
00:14:26,579 --> 00:14:29,060
You can have role-based access control.

233
00:14:29,600 --> 00:14:33,890
Audit trails, you want to make sure
that you have a complete logging of all

234
00:14:33,890 --> 00:14:35,780
the m generated queries and operations.

235
00:14:36,350 --> 00:14:38,810
And then you also want to make
sure that you have human before the

236
00:14:38,810 --> 00:14:40,940
execution, wherever it is required.

237
00:14:41,440 --> 00:14:45,320
So from my experience working with
so many different clients, and from

238
00:14:45,320 --> 00:14:49,670
my understanding of how things are
always going in a way that it's

239
00:14:49,670 --> 00:14:53,000
successful, is that you need to
make sure that you have a roadmap.

240
00:14:53,000 --> 00:14:56,735
You have a. You have a really good
understanding of how things are going

241
00:14:56,735 --> 00:15:01,895
to be created and used over the time
for a particular use cases or for all

242
00:15:01,895 --> 00:15:05,075
the use cases that you have for prompt
engineering in your organization,

243
00:15:05,495 --> 00:15:06,935
especially for data engineering.

244
00:15:07,775 --> 00:15:09,455
You should start with the limited scope.

245
00:15:10,025 --> 00:15:14,225
Try with one particular date, business
domain or business unit, or a particular

246
00:15:14,285 --> 00:15:18,545
data engineering process, and then
work on it and see if it works

247
00:15:18,545 --> 00:15:20,285
fine, and then go for the next one.

248
00:15:20,645 --> 00:15:25,775
Rather than trying to use everything
at once, try to minimize the scope.

249
00:15:25,955 --> 00:15:29,615
That will always help you
to define the quality and

250
00:15:29,615 --> 00:15:30,995
consistency of what you're doing.

251
00:15:31,955 --> 00:15:33,635
You can also collaborate across the team.

252
00:15:33,695 --> 00:15:38,525
We have to make sure everyone from the
business side, data engineers, security

253
00:15:38,525 --> 00:15:44,465
team, compliance team, all of them are
involved to make sure that whatever we are

254
00:15:44,465 --> 00:15:46,730
doing has covered from all the aspects.

255
00:15:47,390 --> 00:15:48,800
Is there anything we are missing?

256
00:15:49,070 --> 00:15:51,920
We have to make sure that we
are doing everything that we can

257
00:15:52,640 --> 00:15:57,020
to make sure that all the data
governance, security, business logic

258
00:15:57,050 --> 00:16:03,850
is used to implement the LLM Prompt
Engineering project text extensively.

259
00:16:03,880 --> 00:16:07,480
Again, we are coming back to the
validation because we want to make sure

260
00:16:07,990 --> 00:16:13,510
that the data quality or the results
quality or the accuracy of the model that

261
00:16:13,510 --> 00:16:15,580
is giving the output is at as the best.

262
00:16:15,910 --> 00:16:19,239
And then we are getting the
right and in and correct value

263
00:16:19,290 --> 00:16:22,350
information that is really important.

264
00:16:23,219 --> 00:16:26,729
And then we have to scale incrementally
because that also allows you to

265
00:16:26,729 --> 00:16:30,420
get feedback every time you have
something small that is implemented.

266
00:16:30,810 --> 00:16:34,949
And then gradually you are expanding your
capabilities, which also connects back to

267
00:16:34,949 --> 00:16:39,900
the performance at scalability that you
are able to scale, but also make sure that

268
00:16:39,900 --> 00:16:44,520
your performance is consistent and your
feedback that you're getting is also used.

269
00:16:45,045 --> 00:16:49,255
To do the changes for the
work that has been done before

270
00:16:49,255 --> 00:16:50,855
moving to the next project.

271
00:16:51,355 --> 00:16:54,505
So what future of data
interaction looks like?

272
00:16:55,225 --> 00:16:57,595
We all know the LLM is going to evolve.

273
00:16:57,715 --> 00:17:02,195
We are going to see lots of
different new technology every day.

274
00:17:02,195 --> 00:17:03,605
There is something new
that we are hearing.

275
00:17:03,605 --> 00:17:07,175
The models are growing, the
companies are building new things.

276
00:17:07,175 --> 00:17:07,890
The companies are coming.

277
00:17:08,540 --> 00:17:09,560
With new things.

278
00:17:09,890 --> 00:17:12,920
So there will be lots of different
things that will happen, especially

279
00:17:12,920 --> 00:17:14,630
from the data engineering perspective.

280
00:17:15,110 --> 00:17:19,550
The boundary between the business users
and the data platform will blur further.

281
00:17:20,120 --> 00:17:25,480
We will see lots of power users, lots
of business users are also doing lots

282
00:17:25,480 --> 00:17:28,690
of things which are much more technical.

283
00:17:29,140 --> 00:17:33,610
By just doing the natural language
commands and prompt engineering

284
00:17:33,610 --> 00:17:35,140
will represent a fundamental shift.

285
00:17:35,860 --> 00:17:40,990
And how organizations think about data
accessibility and technical expertise,

286
00:17:41,950 --> 00:17:45,430
it will allow them to do the faster
decision making because they have

287
00:17:46,060 --> 00:17:50,680
basically eliminated the time between
the data team or the support team because

288
00:17:50,680 --> 00:17:55,150
business users are directly talking to
the data and accelerating the decision

289
00:17:55,150 --> 00:17:59,560
cycles by getting the input and getting
the output and using that information

290
00:17:59,860 --> 00:18:01,990
to make the decisions very fast.

291
00:18:02,650 --> 00:18:05,110
And there will be a smarter
data practices across.

292
00:18:05,860 --> 00:18:09,530
How data means for getting more insights.

293
00:18:10,220 --> 00:18:13,880
I think there is a culture shift that we
have seen when we are, when there was a

294
00:18:14,090 --> 00:18:17,240
pi wave, when self-service analytics came.

295
00:18:17,510 --> 00:18:21,260
Now it's again the LLM wave with
prompt engineering that will make

296
00:18:21,260 --> 00:18:26,210
the data driven culture much more
mature and it'll be tech savvy.

297
00:18:26,545 --> 00:18:31,135
Environment where people will learn
about this new stuff and interact

298
00:18:31,135 --> 00:18:35,005
with LMS and use prompt engineering
to do most of their things.

299
00:18:35,505 --> 00:18:37,545
So what are some key takeaways
from today's session?

300
00:18:38,175 --> 00:18:41,175
Prompt engineering accents
far beyond chat bots.

301
00:18:41,475 --> 00:18:42,795
We all heard about chatbots.

302
00:18:42,795 --> 00:18:46,455
We are all about content generation,
but it is powerful tool that

303
00:18:46,455 --> 00:18:50,175
will democratize the access to
complex cloud data ecosystem.

304
00:18:50,675 --> 00:18:54,275
Success requires careful attention to
accuracy, governance, and fan tuning.

305
00:18:54,275 --> 00:18:58,415
We already saw and discussed like what
all we need to make sure that we have

306
00:18:58,415 --> 00:19:02,345
a proper framework and collaboration
across the organization to make the

307
00:19:02,345 --> 00:19:08,035
success out of this prompt engineering
applications, smart small test,

308
00:19:08,035 --> 00:19:09,835
rigorously and scale incrementally.

309
00:19:10,435 --> 00:19:15,505
That's the mantra there, which
will allow any organization.

310
00:19:15,925 --> 00:19:17,545
To build this infrastructure.

311
00:19:17,965 --> 00:19:23,365
Use LLMs, use prompt engineering
in a way that is always scaling

312
00:19:23,425 --> 00:19:25,195
and performing at it best.

313
00:19:25,765 --> 00:19:29,125
The future of data
interaction is conversational.

314
00:19:29,335 --> 00:19:31,435
It's going to be like you're
just talking with data.

315
00:19:31,435 --> 00:19:34,585
You're not really doing any
data analytics, but you're just

316
00:19:34,585 --> 00:19:37,945
trying to understand, and the
prompt engineering will allow you

317
00:19:37,945 --> 00:19:41,725
to have sort of an interaction
that will empower and accelerate

318
00:19:41,905 --> 00:19:43,795
innovation across the organizations.

319
00:19:44,295 --> 00:19:45,915
Thank you very much for listening me.

320
00:19:45,975 --> 00:19:47,535
I hope this session was useful.

321
00:19:47,905 --> 00:19:51,445
And you are learning something
new about prompt engineering, the

322
00:19:51,445 --> 00:19:54,595
application in data engineering,
which is going to grow very fast.

323
00:19:55,095 --> 00:19:59,245
And looking forward to much
more exciting times for data

324
00:19:59,245 --> 00:20:00,655
engineering and prompt engineering.

325
00:20:00,715 --> 00:20:01,195
Thank you.

