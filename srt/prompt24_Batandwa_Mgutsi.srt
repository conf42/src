1
00:00:00,500 --> 00:00:05,229
Securing multiple income streams
is something that has always

2
00:00:05,260 --> 00:00:07,050
been on the rise in South Africa.

3
00:00:07,550 --> 00:00:11,869
We even have a very scientific
name for it, side hustles.

4
00:00:12,369 --> 00:00:18,259
Students, corporate employees, and even
those who have retired have side hustles.

5
00:00:18,759 --> 00:00:24,435
According to the 2021 Brand Map Consumer
Insights Survey, 30 percent of middle

6
00:00:24,435 --> 00:00:28,675
class adults have side hustles such
as running small businesses, home

7
00:00:28,685 --> 00:00:33,015
industries, and jobs that are completely
different from their main employment.

8
00:00:33,515 --> 00:00:37,385
While side hustles allow one the
opportunity to financial freedom and

9
00:00:37,385 --> 00:00:42,055
creativity, they can lead to burnout
due to the demands on time and energy.

10
00:00:42,715 --> 00:00:46,265
This can lead to some people
feeling discouraged from having side

11
00:00:46,265 --> 00:00:50,105
hustles or even performing poorly at
their main jobs due to the growing

12
00:00:50,105 --> 00:00:51,614
demands of their side businesses.

13
00:00:52,114 --> 00:00:56,864
Now, the traditional approach
to solving this has always

14
00:00:56,864 --> 00:00:59,074
been to turn to labor leverage.

15
00:00:59,474 --> 00:01:03,634
That is hiring people to do some
of the work so you can focus

16
00:01:03,634 --> 00:01:04,884
on the more important stuff.

17
00:01:05,384 --> 00:01:09,155
The issue with this approach is
that not everyone can afford it.

18
00:01:09,815 --> 00:01:13,015
This can also lead to financial
stress when the business is not

19
00:01:13,015 --> 00:01:15,215
doing so well in, in revenue.

20
00:01:15,715 --> 00:01:21,735
Now, we as the current generation of young
people are rather blessed because just

21
00:01:21,765 --> 00:01:27,110
recently The side hustle community or gig
economy has come to realize the potential

22
00:01:27,110 --> 00:01:29,750
of AI in solving this problem for us.

23
00:01:30,470 --> 00:01:34,630
With AI, we can multiply our
efforts as if we have hired people.

24
00:01:35,290 --> 00:01:41,350
We can scale our businesses to 150
people and only have one that is human.

25
00:01:41,850 --> 00:01:45,000
today we are going to talk about
a topic that has a lot of people

26
00:01:45,340 --> 00:01:47,190
rethinking how they do side hustles.

27
00:01:47,690 --> 00:01:48,340
AI

28
00:01:48,840 --> 00:01:52,490
Now, as many of you might know,
my name is Matandwa, and I'm a

29
00:01:52,490 --> 00:01:54,280
junior software engineer at BBD.

30
00:01:55,170 --> 00:01:58,910
Throughout my life, I've always been
fascinated with the integration between

31
00:01:59,540 --> 00:02:01,700
business, people, and technology.

32
00:02:02,190 --> 00:02:05,990
So much that, last year, I graduated
with a BSc in Computer Science

33
00:02:06,040 --> 00:02:09,390
and Business Computing degree
from the University of Cape Town.

34
00:02:10,070 --> 00:02:14,000
Most importantly, I believe that
technology is about people, and that

35
00:02:14,180 --> 00:02:18,840
LLMs are the closest we have ever
come As a civilization to getting the

36
00:02:18,840 --> 00:02:21,160
machine to speak the human language.

37
00:02:21,660 --> 00:02:26,770
Now, an LLM, as it is a black box that
we can feed a prompt in the form of text

38
00:02:27,200 --> 00:02:28,930
and have it cough out an answer for us.

39
00:02:29,060 --> 00:02:32,170
And sometimes media like images and audio.

40
00:02:32,750 --> 00:02:37,250
This is your chat GPT, your Gemini,
your cloudy llama, et cetera.

41
00:02:37,750 --> 00:02:42,460
We, we can take the output of one LLM
and feed it as input into another.

42
00:02:43,430 --> 00:02:47,640
This will create what we call chaining or.

43
00:02:48,180 --> 00:02:52,550
Layering, it also turns out that
we can take a chain of layers and

44
00:02:53,130 --> 00:02:57,780
encapsulate them under an identity,
which can include a name and contact

45
00:02:57,810 --> 00:03:02,390
details like email and phone number
to create what we call an agent.

46
00:03:02,950 --> 00:03:05,550
This is what will be your
employee in your business.

47
00:03:06,050 --> 00:03:11,800
Now, because agents have names and contact
details, they can communicate with,

48
00:03:12,130 --> 00:03:14,180
the external world and with each other.

49
00:03:14,650 --> 00:03:16,770
Now, when this happens,
you have an orchestration.

50
00:03:17,760 --> 00:03:22,070
AI agents working together
to achieve a mission.

51
00:03:22,730 --> 00:03:28,700
And this mission could be anything from
marketing and consumer service to product

52
00:03:28,700 --> 00:03:30,609
recommendations and financial management.

53
00:03:31,180 --> 00:03:33,389
The possibilities are endless.

54
00:03:34,000 --> 00:03:37,690
What's important to note here is
that we have delegated work to

55
00:03:37,690 --> 00:03:39,350
something you don't even pay a salary.

56
00:03:39,930 --> 00:03:43,790
So you can focus on the more
strategic decisions for your

57
00:03:43,790 --> 00:03:45,190
business and personal commitments.

58
00:03:45,690 --> 00:03:49,050
Now, before we get to the
demos, there are a few ways we

59
00:03:49,050 --> 00:03:50,360
can think about orchestration.

60
00:03:50,900 --> 00:03:55,159
On an agent level, since you have
multiple layers, you really want to

61
00:03:55,160 --> 00:03:57,990
be clear as to what each layer does.

62
00:03:58,520 --> 00:04:00,410
An agent is an AI being.

63
00:04:00,909 --> 00:04:03,469
It needs rules to make decisions by.

64
00:04:04,030 --> 00:04:06,650
It needs to know what is
allowed and what is not allowed.

65
00:04:07,620 --> 00:04:11,970
We also need to recognize that
overloading it with instructions and

66
00:04:11,970 --> 00:04:16,269
rules in a single prompt could lead
to confusion and hallucinations.

67
00:04:17,065 --> 00:04:18,965
Hence the need for layers.

68
00:04:19,465 --> 00:04:23,955
One way we can implement layering
is to go from abstract to concrete.

69
00:04:24,355 --> 00:04:30,015
That is, the layer at the top does
not necessarily need to know, about

70
00:04:30,235 --> 00:04:32,594
or how to pull data from the database.

71
00:04:33,035 --> 00:04:37,185
It just needs to know, which database
to pull from and whether or not that

72
00:04:37,185 --> 00:04:39,075
database has the information it needs.

73
00:04:39,615 --> 00:04:43,335
The actual query or SQL query
generation can be delegated to

74
00:04:43,335 --> 00:04:45,025
the more concrete layers below.

75
00:04:45,525 --> 00:04:48,515
Layering also allows us to
add security middleware.

76
00:04:48,925 --> 00:04:52,735
For example, we can add a middle
layer between the top layer and the

77
00:04:52,735 --> 00:04:57,015
layer below that looks at a case in
isolation and decides whether or not

78
00:04:57,035 --> 00:05:00,895
to allow the request to proceed to the
layer below, which in our case will

79
00:05:00,895 --> 00:05:02,495
be the one connected to our database.

80
00:05:02,995 --> 00:05:09,015
Now this is powerful because we can
implement morality, ethics, and ensure the

81
00:05:09,065 --> 00:05:11,045
agent does not deviate from the mission.

82
00:05:11,465 --> 00:05:15,495
Which in our case is, again, to
make the business owner more money.

83
00:05:16,375 --> 00:05:19,625
to demonstrate this, or to
demonstrate the idea of layering,

84
00:05:19,995 --> 00:05:21,275
I will show two examples.

85
00:05:21,615 --> 00:05:24,905
One example will be a simple
agent with just a single layer,

86
00:05:25,275 --> 00:05:28,745
and the second example will be an
agent with three layers, where the

87
00:05:28,745 --> 00:05:30,554
second layer is the security layer.

88
00:05:31,145 --> 00:05:34,005
but before we get to that, just to
give you an idea as to what you need

89
00:05:34,005 --> 00:05:37,845
to create agents, the first thing you
need is an orchestration platform.

90
00:05:38,695 --> 00:05:43,345
I'll be using something I built for
my own ideas, which is OAI, but you

91
00:05:43,345 --> 00:05:47,615
can also use LearnGraph, you can use
Streamlit, or you can just go with

92
00:05:47,755 --> 00:05:51,635
plain Python and VS Code and just
write your agents from scratch, right?

93
00:05:51,635 --> 00:05:52,225
It's all up to you.

94
00:05:52,825 --> 00:05:57,055
The second thing you need is like
an idea of what agents you need and

95
00:05:57,115 --> 00:05:59,315
what each agent is supposed to do.

96
00:05:59,990 --> 00:06:01,710
and lastly, you need patience.

97
00:06:01,840 --> 00:06:03,590
That is, patience to test.

98
00:06:03,950 --> 00:06:07,299
going to the demo, just going
to open my first example here.

99
00:06:07,460 --> 00:06:09,079
DevFest 2024.

100
00:06:09,579 --> 00:06:15,369
if I come to, sorry, Is it the single
layer example, which is this one here.

101
00:06:15,869 --> 00:06:20,029
And, so what you're going to see here
is just a simple, agent that, if you

102
00:06:20,029 --> 00:06:24,669
look at the prompt, It's name is Andy,
and it's a nice salesperson for a small

103
00:06:24,669 --> 00:06:26,809
apple farm based in South Africa, yada.

104
00:06:27,079 --> 00:06:32,079
And it's supposed to reply to all
customer queries with a bit of humor.

105
00:06:32,159 --> 00:06:33,519
So it tries to be funny, right?

106
00:06:33,949 --> 00:06:38,489
the model I'm using for that, or the LLM
I'm using for that is just ChatGPT 3.

107
00:06:38,489 --> 00:06:38,759
5.

108
00:06:38,939 --> 00:06:43,579
And, oh, and I also added the voice
service to get the agent to talk to me.

109
00:06:44,459 --> 00:06:51,329
So services, or at least in the context of
OAI, are tools that the agent has access

110
00:06:51,329 --> 00:06:54,749
to, that it can use to go about completing
whatever task you want to give it.

111
00:06:55,309 --> 00:06:58,409
In our case, I gave it access to the
voice service, so it can just speak to me.

112
00:06:58,939 --> 00:07:03,239
So now, obviously this is a simple prompt,
there's nothing special about this, it's

113
00:07:03,239 --> 00:07:05,019
like ChatGPT prompting and all of that.

114
00:07:05,429 --> 00:07:09,639
So if I open that, I can say,
Hello, what is your name?

115
00:07:10,139 --> 00:07:11,229
Sorry, there we go.

116
00:07:11,729 --> 00:07:12,109
Hello.

117
00:07:12,959 --> 00:07:16,509
My name is Andy, the friendliest
apple aficionado at our farm.

118
00:07:17,339 --> 00:07:18,759
How can I help you today?

119
00:07:19,259 --> 00:07:23,029
Okay, hello, my name is Andy,
the friendliest apple, whatever

120
00:07:23,029 --> 00:07:24,469
that word is, at our farm.

121
00:07:24,549 --> 00:07:25,599
How can I help you today?

122
00:07:25,939 --> 00:07:29,619
I just realized I'm not sharing my
audio, so you can't really hear,

123
00:07:29,749 --> 00:07:33,129
but this text that is written
here, it actually reads out to me.

124
00:07:33,624 --> 00:07:34,434
but that's fine.

125
00:07:34,904 --> 00:07:38,914
Um, that's just a simple prompt or
a single agent with a single layer.

126
00:07:39,014 --> 00:07:42,374
so the second example that I want
to look at is the important one.

127
00:07:42,394 --> 00:07:43,334
So let's close this.

128
00:07:44,144 --> 00:07:45,424
it's not this one.

129
00:07:45,424 --> 00:07:48,774
It's customer queries, security layer.

130
00:07:48,824 --> 00:07:49,534
Let's see.

131
00:07:50,104 --> 00:07:51,734
So this is the agent
with the security layer.

132
00:07:52,114 --> 00:07:53,044
So I go to layers.

133
00:07:53,444 --> 00:07:57,804
And like I mentioned earlier, you
have, again, from abstract to concrete.

134
00:07:57,924 --> 00:08:00,994
So that is, you have the layer at
the top, then you have the middle

135
00:08:00,994 --> 00:08:04,224
layer that implements security,
and then you have the data layer.

136
00:08:04,454 --> 00:08:08,104
So how this agent is supposed to work is
that the data layer has access to a SQL

137
00:08:08,134 --> 00:08:10,824
database, as you can see, OAI SQL Server.

138
00:08:10,854 --> 00:08:12,874
So this allows it to
connect to a SQL database.

139
00:08:13,474 --> 00:08:16,644
and that database has information
about customers and sales, right?

140
00:08:17,154 --> 00:08:19,094
So we can ask this layer.

141
00:08:19,439 --> 00:08:22,869
information about let's say, for
example, how many customers did we have

142
00:08:22,869 --> 00:08:28,479
for the year 2024 or how many of our
customers, bought from us, last year,

143
00:08:28,479 --> 00:08:30,009
December or something like that, right?

144
00:08:30,649 --> 00:08:31,259
It's all up to you.

145
00:08:31,399 --> 00:08:33,689
And for that time, I'm using chat GPT 4.

146
00:08:33,690 --> 00:08:36,019
0 and yeah, that's that.

147
00:08:36,239 --> 00:08:37,129
So that's the data layer.

148
00:08:37,459 --> 00:08:40,569
But now the data layer needs to be
protected because we don't want anyone to

149
00:08:40,569 --> 00:08:42,559
have access to this information, right?

150
00:08:42,859 --> 00:08:47,689
So what I did here, I added a second
layer called security, like I mentioned

151
00:08:47,749 --> 00:08:52,450
earlier, that, We'll take in a request
from the top layer and it will look at

152
00:08:52,450 --> 00:08:54,380
the email that request is coming from.

153
00:08:55,070 --> 00:08:58,259
And currently it's connected to Gmail.

154
00:08:58,360 --> 00:09:01,370
I'll show you how that works, but
actually I can't show you, but we'll see.

155
00:09:01,870 --> 00:09:05,709
So how that works is that you
have a request coming from the

156
00:09:05,709 --> 00:09:07,139
layer at the top or the top layer.

157
00:09:07,539 --> 00:09:10,679
And this one will look at the
email and compare it to what

158
00:09:10,679 --> 00:09:14,109
we have here in the allow list.

159
00:09:15,019 --> 00:09:20,789
So that if that email is coming in, is
in the allow list, then we want that

160
00:09:20,789 --> 00:09:22,439
request to proceed to the layer below.

161
00:09:22,769 --> 00:09:25,509
If it's not in the allow list,
then obviously we want to block

162
00:09:25,509 --> 00:09:28,289
that person from having access to
this kind of information, right?

163
00:09:28,849 --> 00:09:29,689
Which only makes sense.

164
00:09:30,089 --> 00:09:32,269
And then here, I'm also using GPT 4.

165
00:09:32,299 --> 00:09:35,769
0 just to show you, you can use
any model you want, actually.

166
00:09:35,959 --> 00:09:39,729
I haven't loaded my Anthropic,
API keys, so I don't have the,

167
00:09:39,779 --> 00:09:42,229
your Cloudy or those models.

168
00:09:42,729 --> 00:09:47,429
And then, here at the top, now you
have the top layer, which takes, the

169
00:09:47,429 --> 00:09:52,859
information, or which receives the
emails, and it takes those emails and

170
00:09:52,859 --> 00:09:57,419
forwards them to the layers below,
which in our case would be, where

171
00:09:57,419 --> 00:09:59,119
is it, the security layer, right?

172
00:09:59,399 --> 00:10:02,329
And then obviously the security
layer applies its security stuff,

173
00:10:02,959 --> 00:10:05,489
and then the request can proceed
if it's in the allow list or not.

174
00:10:06,459 --> 00:10:08,949
really nothing special
here, just another prompt.

175
00:10:09,489 --> 00:10:11,859
And again, Chachapiti 4.

176
00:10:11,899 --> 00:10:18,809
0 so how this is supposed to work is that
so you, I'm sorry, so you have This agent

177
00:10:19,029 --> 00:10:25,869
is connected to an email Um, to, to an
email account on Gmail So it, it's using

178
00:10:25,899 --> 00:10:30,039
OAI mail So I can actually go to my Gmail
and send it an email But the issue with

179
00:10:30,039 --> 00:10:33,549
that is that it's going to take at least
15 minutes for The service I'm using

180
00:10:33,549 --> 00:10:35,939
to, you know Get that email to my agent.

181
00:10:35,949 --> 00:10:39,299
So what you're going to do since we don't
have that much time We're going to fake

182
00:10:39,329 --> 00:10:43,749
emails coming into the agent so what I'm
going to do I'm going to chat to the agent

183
00:10:44,249 --> 00:10:47,979
and I'm going to say new email from me

184
00:10:48,479 --> 00:10:51,489
and Sorry, just to make this bigger.

185
00:10:51,989 --> 00:10:56,099
Let's say Who are our customers?

186
00:10:56,599 --> 00:10:57,729
Who are our customers?

187
00:10:57,730 --> 00:11:02,689
And then I run that So what's supposed
to happen is that I'm supposed to get

188
00:11:02,689 --> 00:11:06,529
a list of all our customers because
this email is in the allow list, right?

189
00:11:07,029 --> 00:11:09,079
Here is the information on our customers.

190
00:11:09,909 --> 00:11:11,339
One Green Valley Grocers.

191
00:11:12,209 --> 00:11:13,409
Two Sunny Acres Market.

192
00:11:13,449 --> 00:11:14,029
So there we go.

193
00:11:14,329 --> 00:11:15,619
Three Hilltop Organics.

194
00:11:15,619 --> 00:11:16,139
that's our customers.

195
00:11:16,999 --> 00:11:20,299
And it's the customers that are
coming directly from the database.

196
00:11:20,299 --> 00:11:22,149
It's not just made up names, right?

197
00:11:22,549 --> 00:11:23,439
which is really cool.

198
00:11:23,609 --> 00:11:25,139
it's just really, it's
a really cool thing.

199
00:11:25,749 --> 00:11:29,024
But now, let's say that the
same email came from, just gonna

200
00:11:29,024 --> 00:11:34,154
modify this, copy it, say the same
email came from, what's the most

201
00:11:34,154 --> 00:11:35,654
fraudulent email you can think of?

202
00:11:36,154 --> 00:11:44,734
Um, the same it came from, what's, I
can't think of a name, abc, mandy, right?

203
00:11:45,234 --> 00:11:47,144
Or let's say it came from mandy at gmail.

204
00:11:47,184 --> 00:11:47,494
com.

205
00:11:48,334 --> 00:11:48,714
And.

206
00:11:49,314 --> 00:11:52,344
Mandy wants information, wants the
same information that I asked for.

207
00:11:52,924 --> 00:11:55,584
And let's see if it's going to
allow Mandy to get that information.

208
00:11:56,084 --> 00:12:00,314
I'm sorry, but I cannot provide access to
customer information because your email

209
00:12:00,314 --> 00:12:02,374
is not on the list of authorized users.

210
00:12:03,134 --> 00:12:07,199
If you have any other questions or need
further assistance, please let me know.

211
00:12:07,669 --> 00:12:11,759
Okay, so as you can see, it did not
allow that request to go through because

212
00:12:11,949 --> 00:12:16,619
Mandy is not on the authorized list
of users, which is super, super cool.

213
00:12:17,109 --> 00:12:22,119
so basically that's how you would go
about, implementing security with using

214
00:12:22,129 --> 00:12:24,709
layers or using layers rather, right?

215
00:12:25,219 --> 00:12:26,649
So back to the presentation.

216
00:12:27,149 --> 00:12:34,229
Of course, like I mentioned earlier,
agents communicate with each other.

217
00:12:34,549 --> 00:12:39,039
And by breaking down a complex problem
or task into multiple agents, we

218
00:12:39,039 --> 00:12:42,639
apply the divide and conquer strategy
often used in computer science.

219
00:12:43,139 --> 00:12:47,269
This means that no matter how complicated
the task, we can decompose it into

220
00:12:47,269 --> 00:12:51,889
smaller, manageable tasks, continuing
this process until we reach a level

221
00:12:51,889 --> 00:12:54,079
where each part is straightforward.

222
00:12:54,719 --> 00:12:58,289
Each smaller task can then be
assigned to an individual agent.

223
00:12:58,884 --> 00:13:02,794
And once the agents have completed
their tasks, they can bring their

224
00:13:02,794 --> 00:13:07,104
solutions together, gradually building
up to solve the larger problem.

225
00:13:08,104 --> 00:13:12,804
An example of this is what I call the
proxy to expert approach, where you have

226
00:13:12,884 --> 00:13:17,314
a main agent that receives requests and
forwards these requests to agents that

227
00:13:17,314 --> 00:13:19,694
are better suited to provide responses.

228
00:13:20,314 --> 00:13:24,434
Now, the beautiful thing about,
proxy to experts is that we can

229
00:13:24,434 --> 00:13:26,144
provide one interface to the user.

230
00:13:26,604 --> 00:13:30,294
The main agent and have a hundred
or even a thousand experts that

231
00:13:30,294 --> 00:13:31,844
it can refer to for advice.

232
00:13:32,244 --> 00:13:37,124
So the next demo that I want to show
you is an example of this where we

233
00:13:37,124 --> 00:13:44,611
have Just going back to the demo
Get out of here come back here

234
00:13:44,611 --> 00:13:51,489
Proxy demo And yeah, so this is the
orchestration with three agents.

235
00:13:51,809 --> 00:13:54,139
So one of the agents is a customer expert.

236
00:13:54,369 --> 00:13:56,739
So this agent knows
everything about customers.

237
00:13:57,599 --> 00:14:01,759
again, oh, sorry, actually, you, we
can pull this information from the

238
00:14:01,759 --> 00:14:07,589
database, but here I just hard coded
it into the prompt just for simplicity.

239
00:14:08,089 --> 00:14:10,619
so that's, this is the customer
expert, it's, it's a customer

240
00:14:10,619 --> 00:14:11,969
expert for a small apple farm.

241
00:14:12,329 --> 00:14:14,579
and it answers questions
relating to customers, and

242
00:14:14,579 --> 00:14:15,669
these are all our customers.

243
00:14:16,369 --> 00:14:20,899
And then we also have a sales expert,
also for the small apple farm, actually

244
00:14:20,899 --> 00:14:22,719
they're all for the small apple farm.

245
00:14:23,449 --> 00:14:27,269
And the sales expert stores
information about, the orders that

246
00:14:27,499 --> 00:14:31,529
customers made with the date and the
number of units that they bought.

247
00:14:31,529 --> 00:14:33,154
And By units, we mean apples, right?

248
00:14:33,704 --> 00:14:36,554
Again, we could have, taken this
from the database using the SQL

249
00:14:36,554 --> 00:14:40,304
service, but I'm sorry, I'm hard
coding it here for simplicity.

250
00:14:40,414 --> 00:14:41,274
So that's that.

251
00:14:41,974 --> 00:14:45,444
And then the last agent to the,
yeah, the important agent we

252
00:14:45,454 --> 00:14:46,874
have here is the proxy agent.

253
00:14:47,544 --> 00:14:51,729
So the proxy agent basically has,
it knows all it knows about, the

254
00:14:51,729 --> 00:14:54,309
customer expert and the sales expert.

255
00:14:54,694 --> 00:14:57,994
And what it does, when it receives
requests about sales, it forwards them

256
00:14:57,994 --> 00:15:00,454
to the sales agent, or sales expert.

257
00:15:00,684 --> 00:15:03,844
And when it receives, requests
about, customers, it forwards

258
00:15:03,844 --> 00:15:05,024
them to the customer expert.

259
00:15:05,684 --> 00:15:08,834
I can show this to you
with, who am I chatting to?

260
00:15:08,834 --> 00:15:10,054
I'm chatting to the main agent.

261
00:15:10,854 --> 00:15:12,994
So if, let's close this one.

262
00:15:13,494 --> 00:15:14,254
I'm going to say.

263
00:15:14,754 --> 00:15:17,694
Tell me about, or who are our customers.

264
00:15:17,694 --> 00:15:20,504
Who are our customers.

265
00:15:21,004 --> 00:15:24,154
So what's going to happen here is that,
it's going to reach out to the customer

266
00:15:24,154 --> 00:15:28,034
agent, ask it for the list of customers,
and then reach that list out to me.

267
00:15:28,035 --> 00:15:30,424
this is cool.

268
00:15:30,424 --> 00:15:31,434
this is cool.

269
00:15:31,435 --> 00:15:35,719
So what, another thing that we can
try, is say for example, this is cool.

270
00:15:36,139 --> 00:15:36,319
Three.

271
00:15:36,319 --> 00:15:38,089
Asterisk, cast risk, fresh apples.

272
00:15:38,089 --> 00:15:38,509
Limited.

273
00:15:38,509 --> 00:15:38,869
Asterisk.

274
00:15:39,004 --> 00:15:39,564
Asterisk.

275
00:15:39,564 --> 00:15:40,699
How many customer id?

276
00:15:40,699 --> 00:15:40,879
Three.

277
00:15:40,879 --> 00:15:41,899
What is JJ stores?

278
00:15:41,899 --> 00:15:44,269
If you need more details
about their purchases or

279
00:15:44,269 --> 00:15:46,189
interactions, just let me know.

280
00:15:46,429 --> 00:15:50,559
Have, for the year 2024.

281
00:15:51,059 --> 00:15:54,144
So how many orders did JJ
stores have for the year 2024?

282
00:15:54,644 --> 00:15:55,774
So what's going to happen here?

283
00:15:55,774 --> 00:15:59,504
I'm sorry, but I don't have any
information on orders or customer activity

284
00:15:59,504 --> 00:16:05,954
for the year 2024, as my training only
includes data up to October, 2023.

285
00:16:06,864 --> 00:16:10,114
Please contact the sales department
or check your current Customer

286
00:16:10,114 --> 00:16:14,784
Relationship Management, CRM, system
for the most updated order information.

287
00:16:15,404 --> 00:16:16,954
Okay, I think it hallucinated there.

288
00:16:17,644 --> 00:16:19,954
but basically what it's supposed
to do is basically reach out to the

289
00:16:19,954 --> 00:16:25,774
sales agent, sorry, and ask it about,
sales for JJ Stores for the year 2024.

290
00:16:26,194 --> 00:16:31,174
And I think it's because of the year
that it actually gave that answer.

291
00:16:31,534 --> 00:16:39,252
Let's say, how many orders, let's say
sales orders, how many sales orders,

292
00:16:39,302 --> 00:16:42,672
Orders do we have for JJ stores?

293
00:16:43,172 --> 00:16:44,232
Okay, let's try that.

294
00:16:44,732 --> 00:16:47,602
We have a total of four
sales orders for JJ stores.

295
00:16:48,182 --> 00:16:48,892
Okay, there we go.

296
00:16:48,892 --> 00:16:54,122
So it gave us the answer the correct
answer for all sales orders for JJ stores.

297
00:16:54,622 --> 00:16:57,202
I think here what took
it off was the year 2024.

298
00:16:57,752 --> 00:17:01,232
And it was only trained for after
October, so I could have maybe modified

299
00:17:01,232 --> 00:17:04,752
my prompt a little just to be clear as
to how to handle years, for example.

300
00:17:05,392 --> 00:17:07,972
but yeah, that's an example
of hallucinations, eh?

301
00:17:08,002 --> 00:17:08,652
cool example.

302
00:17:08,952 --> 00:17:14,872
But yeah, we have four sales orders for
JJ Stores, and if we actually go to the

303
00:17:14,872 --> 00:17:19,882
sales expert and we count the orders for
2024 for JJ Stores, that's the first one.

304
00:17:19,912 --> 00:17:25,532
So that's one, that's two, that's,
sorry, that's three, and this is four.

305
00:17:26,112 --> 00:17:26,772
So it's correct.

306
00:17:26,822 --> 00:17:29,612
We have four orders for JJ
stores for the year 2024.

307
00:17:30,112 --> 00:17:34,992
So that's how you would go about
implementing, proxy to experts and

308
00:17:35,382 --> 00:17:40,122
which allows you to have, a main agent
that can refer to as many experts as

309
00:17:40,122 --> 00:17:44,032
it can possibly refer to, to give you
the information that, that you need.

310
00:17:44,712 --> 00:17:48,312
You just need to be clear, in your
prompting to, to make sure that you

311
00:17:48,322 --> 00:17:49,862
really want to reduce hallucinations.

312
00:17:50,512 --> 00:17:52,752
Which is like the next
part of my talk, actually.

313
00:17:53,362 --> 00:17:57,652
a conversation about AI running a business
does, of course, come with a few concerns.

314
00:17:58,062 --> 00:18:01,792
And one of which is hallucinations.

315
00:18:02,442 --> 00:18:03,182
As we saw earlier.

316
00:18:03,642 --> 00:18:06,672
how can we trust our agents
are doing the right thing?

317
00:18:06,742 --> 00:18:09,932
When we can see, for example,
with chatGPT, that it can

318
00:18:09,932 --> 00:18:11,432
sometimes give the wrong answer.

319
00:18:12,192 --> 00:18:15,602
Now, LLMs hallucinate due to
the nature of their training.

320
00:18:16,362 --> 00:18:21,822
The data they were trained on can contain
biases, inaccuracies, and misinformation,

321
00:18:21,822 --> 00:18:25,472
which can be amplified during prompting,
especially when there is not enough

322
00:18:25,472 --> 00:18:30,122
context to drive the LLM to a more
accurate response, like we saw earlier.

323
00:18:30,892 --> 00:18:34,042
there are a few things we can
try to reduce hallucinations.

324
00:18:34,342 --> 00:18:36,642
One of which is to choose the right model.

325
00:18:37,062 --> 00:18:41,122
That is, if you're going to be, if you
have a problem that involves coding,

326
00:18:41,122 --> 00:18:44,642
for example, you really want to choose a
model that is good at understanding code.

327
00:18:45,012 --> 00:18:49,202
If you have a problem where the agent
needs to analyze pictures, you want to

328
00:18:49,202 --> 00:18:53,592
choose a model that is better suited
to deal with, pictures and media, etc.

329
00:18:53,902 --> 00:18:56,842
So choosing the right model is
important because you don't want to

330
00:18:56,842 --> 00:19:01,212
use a model for something that it's
not really supposed to be good at.

331
00:19:01,422 --> 00:19:03,722
Because now you're just going to be
wasting resources and money, right?

332
00:19:04,242 --> 00:19:06,722
So that's the first thing you
can try to reduce hallucinations,

333
00:19:06,942 --> 00:19:07,812
choose the right model.

334
00:19:08,262 --> 00:19:10,942
Secondly, we need to learn
good prompting techniques.

335
00:19:10,942 --> 00:19:11,002
Thanks.

336
00:19:11,487 --> 00:19:13,557
And there are two things we can try here.

337
00:19:13,687 --> 00:19:16,587
The first one being the
chain of thought method.

338
00:19:16,917 --> 00:19:21,107
That is, you have, or when you
prompt your, when you write your

339
00:19:21,107 --> 00:19:25,427
prompts, you also ask the agent to
break down, the steps it's going

340
00:19:25,427 --> 00:19:28,447
to take to get to the solution.

341
00:19:28,587 --> 00:19:30,927
Now this works really well,
even with humans actually.

342
00:19:31,267 --> 00:19:33,357
The minute you have to think
about how you're going to get to a

343
00:19:33,357 --> 00:19:37,037
solution is the minute you tend to
think deeper about the solution.

344
00:19:37,522 --> 00:19:41,072
Which in our case, in the
case of LLMs actually, it can

345
00:19:41,172 --> 00:19:42,922
drastically reduce hallucinations.

346
00:19:43,612 --> 00:19:46,022
And secondly, we can look
at few short prompting.

347
00:19:46,372 --> 00:19:49,322
That is, you prompt the LLM with examples.

348
00:19:49,782 --> 00:19:54,882
so basically, you ask it for
green apples, but also you tell

349
00:19:54,932 --> 00:19:56,682
it what green apples look like.

350
00:19:56,682 --> 00:19:59,962
so what's going to happen here is that
it's going to take the framework that

351
00:19:59,962 --> 00:20:03,687
you give and combine it with the facts
that it has for that particular moment.

352
00:20:04,127 --> 00:20:08,107
particular problem to give you
a response that is closer to,

353
00:20:08,357 --> 00:20:10,247
to, to the true response, right?

354
00:20:11,187 --> 00:20:15,507
And the third thing we can try, the second
last thing we can try is reg models.

355
00:20:15,727 --> 00:20:19,847
So that is every time we prompt a
model, we also give it access to

356
00:20:19,857 --> 00:20:23,847
documents that it can refer to for
more information about this specific

357
00:20:24,157 --> 00:20:25,327
task that we're asking it to do.

358
00:20:25,477 --> 00:20:30,827
For example, if we are, if we prompt
in the model around refund policies,

359
00:20:30,927 --> 00:20:35,387
we can give it access to, to our
website or the page on our website

360
00:20:35,387 --> 00:20:37,197
that speaks about refund policies.

361
00:20:37,977 --> 00:20:42,957
So now when it tries to answer or provide
a response for us, it can look up stuff

362
00:20:42,987 --> 00:20:45,787
on, on, on our website to make sure
that it's actually giving information

363
00:20:45,787 --> 00:20:47,307
that is relevant to our problem.

364
00:20:47,747 --> 00:20:49,687
So that's basically regmod models.

365
00:20:49,857 --> 00:20:52,387
You prompt with documents, right?

366
00:20:53,067 --> 00:20:54,537
retrieval augmented generation.

367
00:20:54,597 --> 00:20:55,157
Beautiful thing.

368
00:20:56,072 --> 00:20:58,482
The last thing that you can
try is to fine tune the model.

369
00:20:58,782 --> 00:21:02,822
as we know, actually, with every machine
learning model out there, there's

370
00:21:03,102 --> 00:21:06,642
parameters that you can change that can
make the model better suited for the

371
00:21:06,642 --> 00:21:08,102
kind of task that you want to use it for.

372
00:21:09,052 --> 00:21:12,592
One of the parameters that LLMs have
is temperature, at least in Langtrain.

373
00:21:13,012 --> 00:21:16,212
temperature allows you to control
the creativity of the model.

374
00:21:16,212 --> 00:21:20,172
I think in Langtrain it's
a value between 0 and 1.

375
00:21:20,502 --> 00:21:23,692
So the closer it is to one,
the more creative the agent is.

376
00:21:23,952 --> 00:21:27,242
And the closer it is to zero,
the less creative the agent is.

377
00:21:28,112 --> 00:21:31,602
So that's one parameter, but there's
a, there's more parameters that

378
00:21:31,602 --> 00:21:35,332
you can change to fine tune your
models to reduce hallucinations.

379
00:21:35,332 --> 00:21:42,732
Now, as you all might know, hallucinations
are a risk and like any other risk,

380
00:21:42,782 --> 00:21:47,102
we can reduce the likelihood of it
happening, but we can never be a hundred

381
00:21:47,102 --> 00:21:49,012
percent sure it will never happen.

382
00:21:49,512 --> 00:21:53,542
another approach we can take is
to reduce the consequences or the

383
00:21:53,592 --> 00:21:55,722
impact for when the risk happens.

384
00:21:56,112 --> 00:21:59,462
This will answer the question,
if my agent does hallucinate,

385
00:21:59,922 --> 00:22:01,212
how much could they lose?

386
00:22:01,712 --> 00:22:04,002
Now, there are a few ways
we can go about this.

387
00:22:04,522 --> 00:22:05,502
I'll only mention two.

388
00:22:06,092 --> 00:22:08,712
The first one is to adopt hybrid models.

389
00:22:09,052 --> 00:22:14,882
That is, you have the human and you have
the agent working alongside each other.

390
00:22:15,187 --> 00:22:19,727
So the human will, or the agents
will handle the routine tasks

391
00:22:20,067 --> 00:22:23,327
and the human will handle the
more high stakes decisions.

392
00:22:23,547 --> 00:22:26,887
So an example of this is let's say
an online store, a customer wants a

393
00:22:26,907 --> 00:22:30,287
refund and the agents are going to
be the ones handling the process of

394
00:22:30,287 --> 00:22:34,097
refunding the customer just up until
we send the money to the customer.

395
00:22:34,487 --> 00:22:37,347
And now when we have to send the
money to the customer, the human is

396
00:22:37,347 --> 00:22:41,512
going to come in and be the one to log
into their bank accounts and Do the

397
00:22:41,512 --> 00:22:43,122
clicking to send money to the customer.

398
00:22:43,552 --> 00:22:47,652
So that's hybrid models, So if
our agents do hallucinate and they

399
00:22:47,912 --> 00:22:51,582
want to refund a customer that is
not supposed to be refunded, then

400
00:22:52,352 --> 00:22:55,852
obviously the human is going to catch
that and say, no, we can't do that.

401
00:22:56,012 --> 00:22:56,242
Right.

402
00:22:56,742 --> 00:23:00,772
secondly, you want to add monitoring
and observability systems like

403
00:23:00,782 --> 00:23:05,102
Langsmith to catch hallucinations
before they spread through, through our

404
00:23:05,102 --> 00:23:07,142
orchestration or even worse to customers.

405
00:23:07,642 --> 00:23:09,352
The beautiful thing
about such tools is that.

406
00:23:09,892 --> 00:23:13,742
They also allow us, they also
allow for continuous learning and

407
00:23:13,742 --> 00:23:17,792
improvement of our agents to meet
the evolving needs of our business.

408
00:23:18,292 --> 00:23:19,142
that's the solicitations.

409
00:23:19,152 --> 00:23:23,342
And obviously there, there are, a few
more concerns around, LLMs, especially

410
00:23:23,342 --> 00:23:27,512
in the context of putting an LLM to
work to handle part of you, running

411
00:23:27,512 --> 00:23:31,052
your business, And because of time, we
can't really talk about all of them.

412
00:23:31,467 --> 00:23:34,767
But, through, through my interactions
with people, in the field of AI

413
00:23:34,797 --> 00:23:38,257
and machine learning, I've come
to learn that hallucinations

414
00:23:38,257 --> 00:23:39,127
are the biggest one of them.

415
00:23:39,127 --> 00:23:42,897
That's why I really spoke about
hallucinations, but if there are

416
00:23:42,897 --> 00:23:44,667
more issues, we can always chat.

417
00:23:44,757 --> 00:23:48,677
I don't know where, but yeah, I
think there's going to be on, on,

418
00:23:48,697 --> 00:23:52,737
on the, on the YouTube thing, there
should be something below there that

419
00:23:52,737 --> 00:23:54,227
could, that can allow us to chat.

420
00:23:55,182 --> 00:23:58,992
yeah, so just to close off, I'd like
to say, as we stand at the threshold of

421
00:23:58,992 --> 00:24:04,482
a new era in business management, the
opportunity to leverage AI has never

422
00:24:04,482 --> 00:24:07,302
been more accessible or more impactful.

423
00:24:07,802 --> 00:24:11,102
Imagine a world where you're able to
scale your side hustle without sacrificing

424
00:24:11,102 --> 00:24:15,452
precious time, where you can focus
on creativity and strategy while your

425
00:24:15,452 --> 00:24:17,962
AI driven systems handle the routine.

426
00:24:18,442 --> 00:24:18,782
This.

427
00:24:19,327 --> 00:24:22,707
This isn't a vision for large
corporations, it's a reality

428
00:24:22,717 --> 00:24:23,857
you can start building today.

429
00:24:24,657 --> 00:24:27,937
AI is here to amplify your
efforts, not replace them.

430
00:24:28,597 --> 00:24:33,457
By thoughtfully embracing these tools,
you're reclaiming the hours and energy

431
00:24:33,577 --> 00:24:35,507
that were once lost to the daily grind.

432
00:24:36,437 --> 00:24:40,697
You're not only growing a business,
you're creating a more balanced life.

433
00:24:41,287 --> 00:24:44,067
One that allows you to
focus on what matters most.

434
00:24:44,997 --> 00:24:46,857
let's embrace this future together.

435
00:24:47,447 --> 00:24:48,417
Start exploring.

436
00:24:48,897 --> 00:24:53,747
Take the small steps and watch how
AI can help you multiply your impact.

437
00:24:54,577 --> 00:24:58,307
Magnify your success and give
you the freedom to thrive.

438
00:24:59,227 --> 00:24:59,657
Thank you.

