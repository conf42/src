1
00:00:02,550 --> 00:00:03,300
Hello everyone.

2
00:00:03,510 --> 00:00:04,920
My name is Naman Goel.

3
00:00:05,370 --> 00:00:09,210
Today I want to talk about a profound
shift happening in artificial

4
00:00:09,210 --> 00:00:14,760
intelligence, a move beyond simple text
generation towards what we call agent ai,

5
00:00:15,480 --> 00:00:17,700
often powered by advanced language models.

6
00:00:19,290 --> 00:00:23,370
For a while now, we have seen
AI primarily as reactive tools.

7
00:00:23,460 --> 00:00:26,160
You give a prompt, you get
a text response, but the

8
00:00:26,160 --> 00:00:27,930
horizon is expanding rapidly.

9
00:00:28,350 --> 00:00:33,090
We are witnessing the rise of AI system
that don't just respond, but act.

10
00:00:33,360 --> 00:00:37,650
They are both product active, autonomous
agents capable of understanding complex

11
00:00:37,650 --> 00:00:41,460
goals, planning, interacting with
their environment, and solving problems

12
00:00:41,460 --> 00:00:43,440
with minimal human intervention.

13
00:00:44,760 --> 00:00:48,240
In this job, we will explore
this evolution how AI systems

14
00:00:48,240 --> 00:00:52,590
are transforming from passive
responders to active problem solvers.

15
00:00:53,010 --> 00:00:57,000
We will develop into technical foundations
enabling this change, examining

16
00:00:57,000 --> 00:01:01,140
key operational frameworks, discuss
the crucial ethical considerations.

17
00:01:01,755 --> 00:01:05,475
And look towards the exciting future
directions this research is taking.

18
00:01:05,925 --> 00:01:08,325
This isn't about just better chat bots.

19
00:01:08,385 --> 00:01:13,875
It's about redefining human AI
collaboration and opening entirely new

20
00:01:13,875 --> 00:01:16,605
frontiers of AI research and application.

21
00:01:17,605 --> 00:01:19,135
So how did we get here?

22
00:01:19,285 --> 00:01:20,185
Let's chase the journey.

23
00:01:20,935 --> 00:01:23,065
Initially we had text generators.

24
00:01:23,155 --> 00:01:26,545
Think of early LMS like GBD
three in its initial form.

25
00:01:26,905 --> 00:01:29,695
Powerful, yes, but fundamentally reactive.

26
00:01:29,995 --> 00:01:34,225
They excel at generating human length
text based on specific prompts, but are

27
00:01:34,225 --> 00:01:39,055
limited awareness of broader context
or the ability to act independently.

28
00:01:39,835 --> 00:01:43,585
The next shift involved developing
deeper contextual understanding.

29
00:01:44,605 --> 00:01:48,385
Models became better at grasping
nuances, implicit meaning with

30
00:01:48,385 --> 00:01:52,075
the then request and maintaining
contextual, longer interaction.

31
00:01:52,675 --> 00:01:56,305
This was crucial, but still largely
within the input output paradigm.

32
00:01:57,085 --> 00:02:00,415
The real transformation is the
emergence of autonomous agency.

33
00:02:01,195 --> 00:02:06,175
Modern systems, the agent ai, we are
discussing exhibit gold active behavior.

34
00:02:06,594 --> 00:02:09,894
You give them an objective and they
can figure out the steps needed.

35
00:02:10,315 --> 00:02:14,094
Often with minimal human guidance,
they transcend the limitations of

36
00:02:14,094 --> 00:02:18,175
just generating text, speech, and
pass pattern, and this agency often

37
00:02:18,175 --> 00:02:20,040
involves multi-system interaction.

38
00:02:20,530 --> 00:02:24,850
Integration Agent tech AI isn't
confined into a single interface.

39
00:02:25,180 --> 00:02:29,260
It can coordinate actions across
different platforms, tools, and APIs

40
00:02:29,260 --> 00:02:31,630
to accomplish complex multi-step tasks.

41
00:02:31,899 --> 00:02:35,050
This ability to interact with
external environments is a hallmark

42
00:02:35,050 --> 00:02:36,970
of this new generation of ai.

43
00:02:37,899 --> 00:02:41,380
This shift from reactive responses
to proactive goal-driven action

44
00:02:41,410 --> 00:02:43,570
is the core of agent revolution.

45
00:02:44,570 --> 00:02:46,760
What makes this Jump two agency possible?

46
00:02:47,029 --> 00:02:51,709
Several key technical foundations
work together, which we can visualize

47
00:02:51,709 --> 00:02:53,689
as layers, building from bottom up.

48
00:02:54,170 --> 00:02:56,269
At the base, we have
hierarchical planning.

49
00:02:56,570 --> 00:03:00,769
Instead of tackling a huge goal
at once, agent systems break it

50
00:03:00,769 --> 00:03:02,480
down into manageable sub goals.

51
00:03:02,780 --> 00:03:07,310
From high level strategic objectives to
specific actionable task, and finally

52
00:03:07,310 --> 00:03:10,040
operational execution of individual task.

53
00:03:10,940 --> 00:03:15,200
This structured approach sometimes uses
techniques like recursive refinement,

54
00:03:15,230 --> 00:03:18,950
allows them to handle complexity and
maintain coherence over extended periods.

55
00:03:19,340 --> 00:03:22,429
Research shows models using
hierarchical planning achieve

56
00:03:22,459 --> 00:03:27,325
significantly higher success rates,
sometimes around 45% than flat plane

57
00:03:27,525 --> 00:03:29,364
planning approaches on complex tasks.

58
00:03:30,979 --> 00:03:33,140
Building on planning is long-term memory.

59
00:03:33,589 --> 00:03:37,189
Traditional LMS are often limited
back their context window.

60
00:03:37,609 --> 00:03:41,599
Agent AI needs persistence,
specialized memory structures like

61
00:03:41,599 --> 00:03:43,489
episodic memory for specific events.

62
00:03:43,489 --> 00:03:47,899
Semantic knowledge, basis for conceptual
understanding and working memory for

63
00:03:47,899 --> 00:03:52,579
current context allows this agent to gain
information, learn from past interactions,

64
00:03:52,640 --> 00:03:54,230
and build understanding over time.

65
00:03:54,954 --> 00:03:57,834
Integrating explicit semantic
knowledge, for instance, has shown

66
00:03:57,834 --> 00:04:02,125
accuracy improvements of up to 37%
on certain domain specific tasks.

67
00:04:02,934 --> 00:04:06,804
Next, we have tool
interaction integration.

68
00:04:07,345 --> 00:04:12,025
This is crucial for breaking free from
the limitations of internal knowledge.

69
00:04:12,595 --> 00:04:16,314
Agent AI can leverage external
tools, APIs, and knowledge sources.

70
00:04:16,580 --> 00:04:20,240
Performing web searches for real
time information, executing code for

71
00:04:20,269 --> 00:04:23,750
calculations, analyzing documents,
or interacting with other software.

72
00:04:24,679 --> 00:04:28,460
This capability extension dramatically
expands their functional range

73
00:04:29,780 --> 00:04:32,960
implementations, using tools have
shown success rate nearly three times

74
00:04:32,960 --> 00:04:36,950
of complex information gathering tasks
compared to models without multiplexis.

75
00:04:37,669 --> 00:04:41,719
Finally at the top, these foundations
enabled decision autonomy.

76
00:04:42,110 --> 00:04:47,089
The agent can independently evaluate
situations, selects actions based on

77
00:04:47,089 --> 00:04:50,689
its goals and context, and decide how
and when it's to use its planning,

78
00:04:50,689 --> 00:04:52,309
memory and tool capabilities.

79
00:04:52,669 --> 00:04:56,914
It's this autonomy that truly
distinguish agent tech systems.

80
00:04:57,914 --> 00:05:03,945
Okay, we have the foundations, but how
do we, these agents actually operate two

81
00:05:04,034 --> 00:05:10,005
prominent frameworks, illustrate different
approaches, react and plan, and execute

82
00:05:10,455 --> 00:05:14,955
the React framework, which stands for
reasoning and action combines these two

83
00:05:14,955 --> 00:05:17,085
elements in the tight iterative cycles.

84
00:05:17,355 --> 00:05:19,995
First formalized around late 2022.

85
00:05:20,025 --> 00:05:23,805
It mirrors human cognition, observe
reason, chain of thought is often

86
00:05:23,805 --> 00:05:27,945
used here, act and then observe the
result to inform the next cycle.

87
00:05:29,700 --> 00:05:32,760
This continuous looks mix
react very effective in dynamic

88
00:05:32,760 --> 00:05:35,820
environments where conditions change
frequently and adaptation is key.

89
00:05:36,150 --> 00:05:39,150
It shows strong performance on task,
requiring information gathering,

90
00:05:39,150 --> 00:05:42,630
and a multi hub reasoning like
benchmarks, hotpot, qa, and Web

91
00:05:42,630 --> 00:05:47,010
Shop where React showed 31% higher
completion dates than some alternative.

92
00:05:47,735 --> 00:05:50,705
It also shows for better error
recovery because feedback

93
00:05:50,705 --> 00:05:52,235
is integrated immediately.

94
00:05:52,955 --> 00:05:56,974
In contrast, the Plan and Execute
framework emphasizes a clear separation

95
00:05:56,974 --> 00:05:58,445
between planning and execution.

96
00:05:59,405 --> 00:06:02,015
Inspired by classical AI planning,
the agent first generates a

97
00:06:02,015 --> 00:06:05,734
comprehensive, often data plan,
and then executes its methodically.

98
00:06:06,780 --> 00:06:08,849
Making only minor
adjustments along the way.

99
00:06:09,270 --> 00:06:13,320
Significant replanning only
happens if major obstacles arise.

100
00:06:13,650 --> 00:06:17,760
This approach excels in more structured,
predictable environments where a

101
00:06:17,760 --> 00:06:20,219
good upfront plan remains viable.

102
00:06:20,640 --> 00:06:24,840
Study shows it can lead to more coherent
solutions while stakeholder ratings,

103
00:06:24,840 --> 00:06:29,760
sometimes 24% higher on consistency
metrics in domains like urban planning.

104
00:06:31,380 --> 00:06:34,740
It can be more efficient if
the environment is stable, as

105
00:06:34,740 --> 00:06:37,980
it avoids overhead of constant
reasoning, so which is better?

106
00:06:38,580 --> 00:06:41,700
The performance comparison
shows there's no single answer.

107
00:06:41,790 --> 00:06:44,610
Specialized frameworks
excel in different contexts.

108
00:06:44,700 --> 00:06:49,890
Tax complexity, environment dynamism, and
the need for adaptability varies various

109
00:06:49,920 --> 00:06:52,260
currents, often the optimal approach.

110
00:06:52,530 --> 00:06:57,000
We are also seeing normal hybrid
models emerging through that and

111
00:06:57,000 --> 00:06:58,830
trying to get the best of both worlds.

112
00:06:59,340 --> 00:07:03,580
Context sensitive framework selection
is crucial for building agent systems.

113
00:07:04,580 --> 00:07:08,240
As these agents became more capable,
a critical question, psoriasis,

114
00:07:08,270 --> 00:07:10,280
how much autonomy they should have.

115
00:07:10,670 --> 00:07:12,830
We need a way to manage this responsibly.

116
00:07:12,890 --> 00:07:16,130
The graduated framework
provides a structured approach.

117
00:07:16,250 --> 00:07:20,150
It defines different levels of
agent's independence, human oversight.

118
00:07:20,450 --> 00:07:22,910
At the lowest level, the agent
might suggest actions, but a

119
00:07:22,910 --> 00:07:24,590
human was to approve every step.

120
00:07:24,980 --> 00:07:27,170
Direct supervision monitor.

121
00:07:27,980 --> 00:07:31,580
The agent approach operates more
independently, but requires human

122
00:07:31,580 --> 00:07:35,090
verification at key points or
from certain types of actions.

123
00:07:36,950 --> 00:07:38,120
Founded independence.

124
00:07:38,180 --> 00:07:41,270
Here, the agent has freedom to act
within predefined safety parameters.

125
00:07:41,270 --> 00:07:45,349
Constrained or rules oversight is less
direct, but the boundaries are clear.

126
00:07:45,890 --> 00:07:47,510
And lastly, full otomy.

127
00:07:47,690 --> 00:07:50,840
At the highest level, the agent
operates largely self-directed

128
00:07:51,020 --> 00:07:55,610
with minimal human interventions,
perhaps only for setting initial

129
00:07:55,610 --> 00:07:57,469
goals on handling major exceptions.

130
00:07:57,890 --> 00:07:59,540
The key idea is context.

131
00:07:59,745 --> 00:08:00,224
Sensity.

132
00:08:00,770 --> 00:08:03,909
The pre level isn't fixed.

133
00:08:04,030 --> 00:08:07,780
It should adapt based on the
task risk actions reversibility

134
00:08:07,810 --> 00:08:10,390
the agent's confidence and
the sensitivity of the domain.

135
00:08:10,990 --> 00:08:12,430
Research suggests these nuance.

136
00:08:12,430 --> 00:08:16,509
Context sensitive boundaries can
significantly reduce unnecessary human

137
00:08:16,509 --> 00:08:21,099
interventions by as much as 64% in
some studies, while maintaining safety,

138
00:08:21,369 --> 00:08:23,020
balancing efficiency with control.

139
00:08:24,020 --> 00:08:27,410
The agent paradigm doesn't
stop at single agents.

140
00:08:27,440 --> 00:08:31,070
One of the most exciting frontiers is
multi-agent systems, where multiple

141
00:08:31,460 --> 00:08:35,000
socialized agents collaborate to
tackle complex problems far beyond

142
00:08:35,030 --> 00:08:36,710
the reach of any individual agent.

143
00:08:37,309 --> 00:08:39,440
This enables collaborative
problem solving.

144
00:08:39,680 --> 00:08:41,299
Think of a team of experts.

145
00:08:41,359 --> 00:08:46,159
Frameworks like Meta GPT demonstrate this
by assigning specific roles like product

146
00:08:46,159 --> 00:08:50,060
manager, architect, programmer within
a software development process, each

147
00:08:50,060 --> 00:08:52,099
agent brings unique skills or knowledge.

148
00:08:52,609 --> 00:08:56,720
Effective collaboration requires
internal dialogue mechanisms.

149
00:08:56,960 --> 00:09:00,625
Agents need structured protocols to
communicate, share information, build

150
00:09:00,905 --> 00:09:02,305
consensus, and resolve conflicts.

151
00:09:03,274 --> 00:09:07,595
Experiments within frameworks like
Autogens show that structured direct

152
00:09:07,595 --> 00:09:12,065
agent to agent communication can improve
task completion rates by around 37%

153
00:09:12,065 --> 00:09:14,045
compared to centralized approaches.

154
00:09:15,335 --> 00:09:20,435
Often these systems exhibit hierarchical
organization mimicing supervisor

155
00:09:20,435 --> 00:09:25,234
worker relationships for efficient task
delegation and coordination, and fastly.

156
00:09:25,925 --> 00:09:30,484
We can see emergent social dynamics,
complex group behaviors and problem

157
00:09:30,484 --> 00:09:31,954
solving strategies can arrive from.

158
00:09:32,420 --> 00:09:35,630
Relatively simple interaction rules
between the agents and sometimes leading

159
00:09:35,630 --> 00:09:37,700
suppressive and innovative solutions.

160
00:09:38,180 --> 00:09:42,500
Multi-agent systems hold immense potential
for tackling multifaceted challenges

161
00:09:42,500 --> 00:09:45,890
in areas like scientific research,
complex system design, and mobile

162
00:09:45,890 --> 00:09:47,569
leveraging collective intelligence.

163
00:09:50,240 --> 00:09:54,560
Another major frontier is embodied agency
connecting the reasoning power of LLMs

164
00:09:54,560 --> 00:09:55,970
to physical worlds through robotic.

165
00:09:56,494 --> 00:09:58,744
This requires several key capabilities.

166
00:09:58,895 --> 00:10:03,274
Environmental perception, agents needs
advanced sensor vision, sound touch

167
00:10:03,365 --> 00:10:05,014
for real time situational awareness.

168
00:10:05,044 --> 00:10:08,615
This involves processing multimodal
data and understanding context

169
00:10:08,615 --> 00:10:10,954
aware scenes physical interaction.

170
00:10:11,135 --> 00:10:14,435
Moving beyond just text
requires precise manipulation.

171
00:10:14,794 --> 00:10:17,915
This includes adaptive force
control and sophisticated

172
00:10:17,944 --> 00:10:19,204
object reasoning and handling.

173
00:10:19,714 --> 00:10:23,915
Spatial navigations agent must
move autonomously through dynamic

174
00:10:23,915 --> 00:10:25,595
environments using obstacles.

175
00:10:25,909 --> 00:10:30,800
Avoidance and path optimization
algorithms, physical digital interaction,

176
00:10:31,310 --> 00:10:35,089
creating seamless bridges between
the virtual and material rooms,

177
00:10:35,300 --> 00:10:39,200
perhaps through realtime digital
twins or augmented reality interfaces.

178
00:10:40,760 --> 00:10:44,419
Research here focuses on grounding
abstract reasoning in physical reality.

179
00:10:45,079 --> 00:10:48,050
Frameworks like vision, language
action models integrate perception,

180
00:10:48,050 --> 00:10:49,129
language, and motor skills.

181
00:10:49,145 --> 00:10:54,034
System like S Spam, ERT one and RT
two are demonstrating impressive

182
00:10:54,034 --> 00:10:58,115
progress, enabling robots to perform
complex manipulation tasks based on

183
00:10:58,115 --> 00:11:01,324
natural language instructions with
success rates, sometimes comparable

184
00:11:01,385 --> 00:11:05,074
to specialized algorithms, but
offering far greater flexibility.

185
00:11:05,655 --> 00:11:09,254
Potential applications are vast
from healthcare, patient assistance

186
00:11:09,254 --> 00:11:11,504
therapy to complex industrial tasks.

187
00:11:11,504 --> 00:11:15,435
Manufacturing maintenance is
potentially hazardous environments

188
00:11:15,855 --> 00:11:20,204
Embodied agency significantly expands
the practical impact of agent ai.

189
00:11:21,204 --> 00:11:24,954
Traditional, more adults are often
chatting and training agent tech

190
00:11:24,954 --> 00:11:28,015
system, especially those interacting
with the world need to adapt.

191
00:11:28,074 --> 00:11:31,285
Continual learning focuses on
architecture that allow agents to

192
00:11:31,285 --> 00:11:33,805
improve over through ongoing experience.

193
00:11:33,925 --> 00:11:39,625
This involves several processes, often
working in a cycle experience acquisition,

194
00:11:39,715 --> 00:11:43,120
gathering diverse data from interactions
with user and the environment.

195
00:11:43,795 --> 00:11:47,484
Second, knowledge distillation,
extracting meaningful patterns,

196
00:11:47,484 --> 00:11:50,874
principles, and generalizable
knowledge from these raw experiences.

197
00:11:51,474 --> 00:11:57,084
Model adaptation, updating the agent's
internal models on neural architectures

198
00:11:57,084 --> 00:11:58,675
to incorporate this new knowledge.

199
00:11:59,244 --> 00:12:00,084
Catastrophic.

200
00:12:00,084 --> 00:12:01,314
Forgetting prevention.

201
00:12:01,645 --> 00:12:02,905
This is a critical challenge.

202
00:12:02,905 --> 00:12:06,319
This involves ensuring that learning
new things does not erase previously

203
00:12:06,479 --> 00:12:07,494
acquired knowledge or skills.

204
00:12:07,614 --> 00:12:11,334
Technical life retrieval, augmented
generation or specialized memory helps.

205
00:12:11,935 --> 00:12:17,725
Preserve critical information frameworks
like Camel and R-L-I-C-M-L illustrate

206
00:12:17,785 --> 00:12:21,415
approaches where agents refine behavior
based on outcomes and feedback.

207
00:12:21,715 --> 00:12:26,305
The goal is to create systems that become
more personalized, effective, and align

208
00:12:26,305 --> 00:12:31,045
with user preferences over time without
constantly costing retraining cycles.

209
00:12:32,594 --> 00:12:36,915
Experiments show agents using
interactive learning can achieve 24

210
00:12:36,915 --> 00:12:41,775
to 38% higher success rates on complex
tasks after multiple interaction

211
00:12:41,775 --> 00:12:43,574
cycles compared to static systems.

212
00:12:44,025 --> 00:12:47,055
This makes AI development
more sustainable and adaptive.

213
00:12:49,995 --> 00:12:54,074
Perhaps the most ambitious frontier
is meta learning or learning to learn.

214
00:12:54,629 --> 00:12:58,019
This aims to create agents that can
adapt their own learning strategies

215
00:12:58,019 --> 00:13:00,389
when facing new remains or challenges.

216
00:13:00,479 --> 00:13:05,339
Keeping capabilities include few short
adaptations, allowing agents to master

217
00:13:05,339 --> 00:13:09,300
normal tasks with minimal examples,
drastically reducing training data needs.

218
00:13:10,019 --> 00:13:13,469
Dynamic architecture modification,
enabling systems to autonomous,

219
00:13:13,649 --> 00:13:16,829
restructure their internal
processing based on the problem type.

220
00:13:17,039 --> 00:13:19,409
Optimizing for unseen challenges.

221
00:13:20,219 --> 00:13:23,369
Transferable skill acquisition
learning in one domain enhances

222
00:13:23,369 --> 00:13:26,880
performance in related ones, creating
compounding returns on learning

223
00:13:27,510 --> 00:13:32,369
hyper parameter, self-op optimization
models, tuning their own configuration

224
00:13:32,369 --> 00:13:36,930
settings, automating previously
manual resource intensive processes.

225
00:13:37,920 --> 00:13:42,749
Frameworks like Agent Verse and
I-E-L-H-E are exploring how agents

226
00:13:42,749 --> 00:13:45,810
can select learning strategies
like switching between imitation

227
00:13:45,810 --> 00:13:47,790
learning and reinforcement learning.

228
00:13:48,074 --> 00:13:50,535
Or identifying transferable
knowledge components.

229
00:13:50,805 --> 00:13:52,665
The promise here is unprecedented.

230
00:13:53,745 --> 00:13:59,234
Adaptability, research indicates meta
learning agents might require 40 to

231
00:13:59,444 --> 00:14:04,454
65% fewer examples to master new tasks
compared to fixed strategy learners.

232
00:14:04,484 --> 00:14:08,805
This represents a significant step towards
more general, versatile and efficient ai.

233
00:14:09,805 --> 00:14:13,855
While much of this is cutting edge
research, agent AI is already finding

234
00:14:13,855 --> 00:14:19,075
practical applications across industries
in healthcare can integrate patient

235
00:14:19,075 --> 00:14:23,695
history, research and imaging to a
diagnosis or coordinate complex care

236
00:14:23,695 --> 00:14:25,885
plans across specialists in finance.

237
00:14:26,574 --> 00:14:30,475
Portfolio optimization agents can
balance risk and goals independently

238
00:14:30,475 --> 00:14:35,545
executing complex trading strategies
across markets In scientific research,

239
00:14:35,635 --> 00:14:39,595
hypothesis suggesting can design
and conduct experiments, adapting

240
00:14:39,595 --> 00:14:43,135
protocols based on emerging data,
potentially accelerating discovery.

241
00:14:43,824 --> 00:14:49,314
These examples showcase the potential for
agent systems to handle complex multi-step

242
00:14:49,375 --> 00:14:53,334
tasks, requiring reasoning planning
and tool use in real world scenarios.

243
00:14:53,864 --> 00:14:56,384
With great capability
comes great responsibility.

244
00:14:56,474 --> 00:15:00,314
The rise of utmost agents introduces
significant ethical consideration

245
00:15:00,314 --> 00:15:02,295
that we must atla proactively.

246
00:15:02,685 --> 00:15:06,854
We group these into key
areas, agency alignment.

247
00:15:07,244 --> 00:15:10,694
How do we ensure agent
goals remain consistent with

248
00:15:10,694 --> 00:15:12,285
human values and intentions?

249
00:15:12,374 --> 00:15:16,004
We need mechanisms for value
drift prevention and purpose

250
00:15:16,004 --> 00:15:18,854
validation, control mechanisms.

251
00:15:19,035 --> 00:15:20,204
As agents become more.

252
00:15:21,224 --> 00:15:24,854
How we maintain reliable oversight
and the ability to intervene.

253
00:15:25,364 --> 00:15:29,895
This includes drill switches, defining
clear behavior boundaries, and designing

254
00:15:29,925 --> 00:15:32,295
effective human AI interaction protocols.

255
00:15:32,775 --> 00:15:36,555
The paper identifies control
risk at a critical category,

256
00:15:38,624 --> 00:15:39,704
societal impact.

257
00:15:40,380 --> 00:15:45,089
What are the effects of workforce
potential, job displacement and

258
00:15:45,089 --> 00:15:47,310
issues of access and equity?

259
00:15:47,760 --> 00:15:50,400
We need to consider displaced
worker transitions and ensure

260
00:15:50,400 --> 00:15:54,750
equitable access to these powerful
technologies accountability frameworks.

261
00:15:55,140 --> 00:15:58,410
Who is responsible when an
ATMOS agents makes some mistake?

262
00:15:58,620 --> 00:16:00,000
We need clear frameworks.

263
00:16:00,030 --> 00:16:03,420
Defining responsibility, including
decision audit trails and

264
00:16:03,420 --> 00:16:05,280
stakeholder recourse mechanisms.

265
00:16:06,270 --> 00:16:10,199
Yeah, so we are gonna highlight
key risk categories, misalignment,

266
00:16:10,199 --> 00:16:14,730
uninvented, consequences,
deception, and in adequate control.

267
00:16:14,760 --> 00:16:19,050
Addressing this require interdisciplinary
effort and em embedding ethical

268
00:16:19,050 --> 00:16:22,319
considerations throughout the design,
development and deployment life

269
00:16:22,319 --> 00:16:24,600
cycle, not just an afterthought.

270
00:16:24,630 --> 00:16:28,470
Frameworks like values sensitive
design are crucial here.

271
00:16:29,470 --> 00:16:34,270
This slide gives us snapshot of current
research focus on publication trends.

272
00:16:34,300 --> 00:16:38,890
As you can see, there's immense activity
in developing novel agent architectures,

273
00:16:38,890 --> 00:16:40,960
the core structures that enable agency.

274
00:16:41,575 --> 00:16:44,605
Multi-agent systems are also
a major focus reflecting the

275
00:16:44,605 --> 00:16:46,105
interest in collaborative ai.

276
00:16:46,135 --> 00:16:50,695
We are also see significant research
and avoided AI connecting these agents

277
00:16:50,695 --> 00:16:54,235
to physical world and in advanced
learning paradigms like meta learning.

278
00:16:54,685 --> 00:16:58,615
Crucially, ethics and governance
is recognized as a vital research

279
00:16:58,615 --> 00:17:01,105
area, though perhaps still
needing more adventure relative

280
00:17:01,105 --> 00:17:02,875
to capability development overall.

281
00:17:02,875 --> 00:17:06,505
This lacks clearly shows the
significant shift in AI research

282
00:17:06,505 --> 00:17:10,855
towards Atmos agency moving far
beyond traditional LLM capabilities.

283
00:17:11,855 --> 00:17:14,345
Looking ahead, where is Agent AI heading?

284
00:17:14,765 --> 00:17:19,115
We anticipate collaborative agent
ecosystems, self-organizing communities

285
00:17:19,115 --> 00:17:22,715
of specialized agents tackling complex
problems through coordinated division

286
00:17:22,715 --> 00:17:26,045
of labor human agent co-evolution.

287
00:17:26,375 --> 00:17:30,845
Deeper sym relationships will emerge where
humans and AI adapt together refining

288
00:17:30,905 --> 00:17:32,315
knowledge, work, and collaboration.

289
00:17:33,350 --> 00:17:35,300
Cognitive architecture convergence.

290
00:17:35,360 --> 00:17:39,230
AI systems may increasingly
mirror aspects of human cognition,

291
00:17:39,290 --> 00:17:43,520
potentially incorporating elements
like emotion, creativity, or intuition.

292
00:17:43,520 --> 00:17:48,320
Alongside logic embedded ethical
frameworks, agents, stem cells might

293
00:17:48,320 --> 00:17:53,480
develop more nuanced moral reason
capabilities enabling principal decision

294
00:17:53,480 --> 00:17:55,850
making even in ambiguous situations.

295
00:17:57,110 --> 00:18:01,490
In conclusion, the emergence of agentic
AI represents a fundamental expansion of

296
00:18:01,490 --> 00:18:06,380
what artificial intelligence can be and do
by booming from reactive text generation

297
00:18:06,380 --> 00:18:11,450
to proactive goal directive behavior,
these systems unlock new possibilities

298
00:18:11,450 --> 00:18:15,590
for human AI collaboration, andous
problem solving across countless domains.

299
00:18:16,250 --> 00:18:20,780
As hierarchical planning, memory, tool use
and learning continue to advance, these

300
00:18:20,780 --> 00:18:22,820
agents will become increasingly capable.

301
00:18:22,850 --> 00:18:24,410
However, this progress must be.

302
00:18:24,695 --> 00:18:28,205
Guided by thoughtful evaluation,
robust safety mechanisms and

303
00:18:28,205 --> 00:18:31,385
strong ethical frameworks to
ensure alignment with human values.

304
00:18:31,745 --> 00:18:35,585
The transition from passive respondents
to active problem solving is just

305
00:18:35,585 --> 00:18:36,995
not an incremental improvement.

306
00:18:37,205 --> 00:18:41,165
It potentially is one of the
most tion developments in AI

307
00:18:41,165 --> 00:18:44,375
evolution, fundamentally reshaping
how these systems participate and

308
00:18:44,945 --> 00:18:46,325
contribute to human endeavors.

309
00:18:46,715 --> 00:18:48,125
Thank you for attending the top.

