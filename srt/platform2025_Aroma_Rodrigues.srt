1
00:00:00,500 --> 00:00:01,400
Good morning everyone.

2
00:00:01,460 --> 00:00:02,570
Thank you for joining me today.

3
00:00:03,290 --> 00:00:06,650
My name is Aroma and I'm here to talk
about something that keeps many of

4
00:00:06,650 --> 00:00:11,330
us in FinTech awake at night burning
financial systems that actually scale.

5
00:00:12,110 --> 00:00:15,320
Today we are diving deep into
engineering Athena, a journey of

6
00:00:15,320 --> 00:00:18,710
building a scalable resilience and
compliant financial trading platform.

7
00:00:19,220 --> 00:00:20,330
Now I know what you're thinking.

8
00:00:20,689 --> 00:00:21,620
Another scaling talk.

9
00:00:22,160 --> 00:00:22,939
But here's the thing.

10
00:00:23,210 --> 00:00:25,340
Financial systems are
different beasts entirely.

11
00:00:25,880 --> 00:00:28,009
They're not your typical
e-commerce platform where you

12
00:00:28,009 --> 00:00:31,400
can eventually consistent your
way outta problems in finance.

13
00:00:31,580 --> 00:00:35,270
If your system goes down during
market hours, people lose money.

14
00:00:35,480 --> 00:00:36,080
Real money.

15
00:00:36,440 --> 00:00:39,260
If your calculations are off,
even by a few basis points,

16
00:00:39,740 --> 00:00:40,824
regulators come knocking.

17
00:00:41,085 --> 00:00:44,059
And if you cannot explain exactly
what happened to every trade

18
00:00:44,240 --> 00:00:46,790
three years ago, you might be
looking at serious legal trouble.

19
00:00:47,290 --> 00:00:51,430
So today I'm going to share the story
of how we transformed Athena from

20
00:00:51,430 --> 00:00:55,540
a system that could barely handle
thousands of trades to one processing

21
00:00:55,569 --> 00:00:57,819
millions daily across global markets.

22
00:00:58,209 --> 00:01:01,719
We'll cover the technical challenges,
the architectural solutions, and

23
00:01:01,719 --> 00:01:04,734
perhaps most importantly, the
lessons we learned the hardware.

24
00:01:05,234 --> 00:01:08,204
By the end of this talk, you'll
understand why financial systems

25
00:01:08,204 --> 00:01:11,744
require fundamentally different
approaches to scaling, and you'll

26
00:01:11,744 --> 00:01:14,475
have concrete strategies you
can apply to your own systems.

27
00:01:14,924 --> 00:01:15,615
Let's dive in.

28
00:01:16,115 --> 00:01:17,465
First, let me set the stage.

29
00:01:17,824 --> 00:01:21,244
Athena is a financial trading
platform that handles entire life

30
00:01:21,244 --> 00:01:23,044
cycling of trading operations.

31
00:01:23,615 --> 00:01:26,975
We are talking about trade execution,
risk management, profit and loss

32
00:01:26,975 --> 00:01:30,635
calculations, real time market
data processing, and massive end

33
00:01:30,635 --> 00:01:32,315
of the day batch reconciliations.

34
00:01:32,615 --> 00:01:35,375
To give you a sense of scale,
we process millions of trades

35
00:01:35,465 --> 00:01:36,995
daily across global markets.

36
00:01:37,265 --> 00:01:41,165
Each trade might be worth hundreds
of millions of dollars, and every

37
00:01:41,165 --> 00:01:44,705
single one of those trades needs to
be tracked, valued, risk assessed,

38
00:01:44,765 --> 00:01:48,485
and reported to multiple regulatory
bodies, often in real time.

39
00:01:48,985 --> 00:01:52,855
Now before we jump into the technical
architecture, I need to make sure we

40
00:01:52,855 --> 00:01:54,295
are all speaking the same language.

41
00:01:55,045 --> 00:01:58,585
Finance has its own vocabulary and
understanding these core entities

42
00:01:58,615 --> 00:02:01,195
is crucial to understanding
our scaling challenges.

43
00:02:01,735 --> 00:02:03,655
Let me walk you through a simple example.

44
00:02:04,405 --> 00:02:07,735
Imagine Trader one wants
to buy a hundred units.

45
00:02:08,530 --> 00:02:13,490
Of a corporate bond from trader
to this happens on August 5th,

46
00:02:13,490 --> 00:02:16,150
2025 at exactly 3:00 PM GMT.

47
00:02:16,750 --> 00:02:20,350
Both traders work for firms governed
by different legal entities,

48
00:02:20,380 --> 00:02:22,900
and the trade will be cleared
through a central clearinghouse.

49
00:02:23,400 --> 00:02:28,700
This single transaction creates what
we call a trade the atomic unit, of

50
00:02:28,700 --> 00:02:30,140
what actually happened at the market.

51
00:02:31,100 --> 00:02:32,420
But here's where it gets interesting.

52
00:02:33,200 --> 00:02:36,620
This one Trade creates multiple deals.

53
00:02:37,120 --> 00:02:41,950
cTrader, once book shows that they now
own a hundred units of this book, trader

54
00:02:41,950 --> 00:02:46,300
TOS book shows that they received cash
for selling these a hundred units.

55
00:02:46,800 --> 00:02:50,190
These are mirror images of the same
transaction, but they deliver in different

56
00:02:50,190 --> 00:02:52,530
books and serve different purposes.

57
00:02:53,190 --> 00:02:55,140
And that brings us two books.

58
00:02:55,640 --> 00:02:57,620
Think of them as accounted ledgers.

59
00:02:58,220 --> 00:03:01,250
A book is a collection of credits
and debits, typically grouped

60
00:03:01,250 --> 00:03:03,980
by trader desk and product type.

61
00:03:04,490 --> 00:03:08,210
So we might have a corporate bonds
book, a serious book, a European

62
00:03:08,210 --> 00:03:09,890
derivatives book, and so on.

63
00:03:10,460 --> 00:03:12,860
Now, why does this matter from
the engineering perspective?

64
00:03:13,460 --> 00:03:16,760
Because each of these entities has
different scaling characteristics.

65
00:03:17,420 --> 00:03:19,610
Trades are write ones read.

66
00:03:19,610 --> 00:03:22,550
Many deals are frequently
updated as markets move.

67
00:03:23,000 --> 00:03:25,850
Books need to be aggregated
and reported in real time.

68
00:03:26,690 --> 00:03:30,260
Understanding these patterns is
crucial to building efficient systems.

69
00:03:30,760 --> 00:03:34,530
So A trade is a single executed
transaction of a financial instrument.

70
00:03:35,040 --> 00:03:38,460
It represents the actual buying
or selling event, capturing

71
00:03:38,460 --> 00:03:39,450
what happened in the market.

72
00:03:40,050 --> 00:03:42,600
Most of the key attributes
in Athena are the instrument.

73
00:03:42,600 --> 00:03:44,100
For example, a bond, a CD.

74
00:03:45,075 --> 00:03:47,115
Which is a derivative type of instrument.

75
00:03:47,685 --> 00:03:52,185
The quantity or the notional, which
would be correspond to the size of the

76
00:03:52,185 --> 00:03:56,984
trade, the price or the premium, the
executed price counterparties, which

77
00:03:56,984 --> 00:04:02,085
are buyer and seller timestamp, trade
date, the status, whether it's spending

78
00:04:02,085 --> 00:04:04,155
settle, corrected, defaulted, et cetera.

79
00:04:04,875 --> 00:04:07,965
Typically the lifecycle in
Athena goes as created when the

80
00:04:07,965 --> 00:04:09,915
TRA transaction is executed.

81
00:04:10,245 --> 00:04:10,815
Updated.

82
00:04:11,315 --> 00:04:16,415
Rarely for twice, but usually for deals
just because of how markets move to

83
00:04:16,415 --> 00:04:21,065
correct errors or mark status changes
recorded always exist in the book forming

84
00:04:21,065 --> 00:04:23,225
the basis for positions risk and p and l.

85
00:04:23,725 --> 00:04:27,480
Let me show you how these entities flow
through a typical trading ecosystem.

86
00:04:28,165 --> 00:04:32,425
Now, this isn't just, this is the
actual architecture that every major

87
00:04:32,425 --> 00:04:34,945
investment bank uses with variations.

88
00:04:35,785 --> 00:04:37,165
First, we have the front office.

89
00:04:37,525 --> 00:04:38,695
This is where trade are born.

90
00:04:39,415 --> 00:04:43,855
Traders, salespeople, or electronic
trading platforms execute transactions.

91
00:04:44,215 --> 00:04:46,345
These get captured in systems like Athena.

92
00:04:46,945 --> 00:04:48,445
Then we move to the middle office.

93
00:04:49,105 --> 00:04:50,605
This is where the magic happens.

94
00:04:50,935 --> 00:04:53,575
Every trade gets validated
for legal compliance.

95
00:04:53,995 --> 00:04:56,335
Credit risk and regulatory requirements.

96
00:04:56,695 --> 00:04:58,855
Trades get assigned to
the appropriate books.

97
00:04:59,245 --> 00:05:01,045
Price data gets enriched.

98
00:05:01,405 --> 00:05:03,565
Risk sensitivities get calculated.

99
00:05:04,015 --> 00:05:06,414
Only clean risk approved
trades move forward.

100
00:05:07,075 --> 00:05:08,335
Next is a back office.

101
00:05:08,935 --> 00:05:10,045
This handles settlement.

102
00:05:10,974 --> 00:05:14,485
We are generating settlement
instructions, processing payment

103
00:05:14,485 --> 00:05:19,195
flows, reconciling with counterparties,
and handling corporate actions like

104
00:05:19,195 --> 00:05:21,055
bond maturities or credit events.

105
00:05:21,580 --> 00:05:25,539
Finally, we have books and piano, and
this is where all those individual

106
00:05:25,539 --> 00:05:30,219
trades get aggregated into meaningful
business information daily.

107
00:05:30,219 --> 00:05:34,299
Mark to market valuations, realized
and unrealized gains and losses,

108
00:05:34,719 --> 00:05:37,419
risk measures like value at risk.

109
00:05:37,919 --> 00:05:39,240
Now here's the critical insight.

110
00:05:39,240 --> 00:05:43,160
Each of these stages has
different preference requirements.

111
00:05:43,660 --> 00:05:47,020
Different performance requirements,
different consistency requirements,

112
00:05:47,140 --> 00:05:48,670
and different failure modes.

113
00:05:49,170 --> 00:05:52,410
A traditional monolithic approach
tries to solve all of this with

114
00:05:52,410 --> 00:05:56,400
the same architecture, and that's
where things start to break down.

115
00:05:56,900 --> 00:05:58,580
Let me give you some concrete numbers.

116
00:05:58,940 --> 00:06:00,500
In our front office, we
might see trade burst.

117
00:06:01,430 --> 00:06:06,440
Of around 10,000 transactions per second
during volatile market conditions, our

118
00:06:06,440 --> 00:06:10,670
middle office needs to validate and
enrich each of these trades within 30

119
00:06:10,670 --> 00:06:12,710
seconds to meet regulatory requirements.

120
00:06:13,190 --> 00:06:16,995
Our back office processes
settlement instructions that might

121
00:06:17,055 --> 00:06:18,225
not execute for days or weeks.

122
00:06:19,035 --> 00:06:22,875
Our books and p and l systems need
to provide realtime position data

123
00:06:23,055 --> 00:06:26,655
to traders while simultaneously
running complex risk calculations.

124
00:06:27,555 --> 00:06:31,665
Each of these has fundamentally different
patterns, burst rights, realtime

125
00:06:31,665 --> 00:06:36,105
validation, long running workflows,
and mixed read write workloads.

126
00:06:36,585 --> 00:06:40,215
Trying to hide a lot of this with a
single database, a single application

127
00:06:40,215 --> 00:06:42,225
server, and synchronous processing.

128
00:06:42,415 --> 00:06:43,765
That's a recipe for disaster.

129
00:06:44,305 --> 00:06:46,315
And that brings us to
our scaling challenge.

130
00:06:46,815 --> 00:06:49,844
Lemme paint you a picture of where
we started pictured the classic

131
00:06:49,844 --> 00:06:53,685
monolithic nightmare, but with financial
regulatory requirements layered on top.

132
00:06:54,344 --> 00:06:57,885
We had single everything, one
ingestion instance, one application

133
00:06:57,885 --> 00:07:01,455
node, one primary database with
no replicas and no sharding.

134
00:07:01,664 --> 00:07:04,844
The only way to scale was to throw
a bigger and bigger hardware at

135
00:07:04,844 --> 00:07:07,365
the Prop Classic vertical scale.

136
00:07:07,815 --> 00:07:09,974
Every single call was
synchronous and blocking.

137
00:07:10,544 --> 00:07:14,655
If a trader wanted to see their p and l,
that request would hit the same database

138
00:07:14,865 --> 00:07:19,875
that was trying to process incoming market
data feeds and run compliance reports.

139
00:07:20,175 --> 00:07:22,515
Guess what would happen
during market volatility?

140
00:07:23,015 --> 00:07:25,945
The system would grind to hos,
but here's what made it worse.

141
00:07:26,335 --> 00:07:28,135
We were running everything as bad jobs.

142
00:07:28,705 --> 00:07:32,244
Instead of processing data as it
arrived, we'd accumulate changes all

143
00:07:32,244 --> 00:07:34,765
day and then run massive recalculations.

144
00:07:35,265 --> 00:07:40,204
These jobs would take eight to 12 hours to
complete if anything fails at 3:00 AM our

145
00:07:40,204 --> 00:07:45,264
traders would start their day with stale
data and we had no back pressure handling.

146
00:07:45,804 --> 00:07:49,374
When market data feeds would spike,
which happens every single day

147
00:07:49,644 --> 00:07:53,784
during major economic announcements
such as a government change or war,

148
00:07:54,534 --> 00:07:55,944
our ingestion threats would stop.

149
00:07:56,574 --> 00:07:59,124
This would cascade to
user facing operations.

150
00:07:59,624 --> 00:08:02,264
Traders couldn't see their
position because the system

151
00:08:02,264 --> 00:08:04,394
was choking on routers feeds.

152
00:08:05,354 --> 00:08:09,314
We were a single region deployment,
which met high latency for our London

153
00:08:09,314 --> 00:08:13,874
and Hong Kong traders, and any regional
outage was a complete platform outage,

154
00:08:14,324 --> 00:08:19,064
but perhaps, first of all, our compliance
and audit data was just extra rows

155
00:08:19,064 --> 00:08:20,744
in the same operational database.

156
00:08:21,314 --> 00:08:25,454
This created noise enabler problems
and made it incredibly easy to

157
00:08:25,454 --> 00:08:27,914
accidentally break compliance in variant.

158
00:08:28,414 --> 00:08:32,135
So this is an example of what the
monolithic approach looks like.

159
00:08:32,585 --> 00:08:37,555
At the top feeds user legacy rading,
which is when you use like an

160
00:08:37,555 --> 00:08:42,385
electronic platform to execute a
trade or a CSV upload of any sort of

161
00:08:42,385 --> 00:08:45,985
trades that the trader has already
executed on their road platform.

162
00:08:46,485 --> 00:08:50,675
Which then would have an HTTP pooling
infrastructure in between, which

163
00:08:50,675 --> 00:08:55,305
would provide all of these services
to the ingestion service, which in

164
00:08:55,305 --> 00:08:58,335
the traditional monolithic approach
would be single instance and would

165
00:08:58,335 --> 00:08:59,895
have some level of sync paring.

166
00:09:00,395 --> 00:09:04,955
It would then go sit into a
single relational database,

167
00:09:05,195 --> 00:09:07,295
which would be one in one region.

168
00:09:07,715 --> 00:09:11,870
It wouldn't actually have any replicas,
and it would be mixed OLTP and OLEP.

169
00:09:12,370 --> 00:09:16,810
Which would then eventually lead to
a risk computation unit, a reporting

170
00:09:16,810 --> 00:09:18,700
dashboard, and a compliance logger.

171
00:09:19,300 --> 00:09:23,530
And all of these would run
nightly in batches via a CR job.

172
00:09:24,030 --> 00:09:24,780
Sounds simple.

173
00:09:25,470 --> 00:09:29,420
This is the appropriate architecture
if you have around a thousand traits.

174
00:09:29,920 --> 00:09:32,020
But what happens when you try to scale it?

175
00:09:32,520 --> 00:09:34,620
So core traits, why this won't scale.

176
00:09:35,010 --> 00:09:36,570
This is basically single everything.

177
00:09:36,810 --> 00:09:41,790
One ingestion instance, one op node,
one primary tb. No replica, no shouting.

178
00:09:42,510 --> 00:09:44,250
Only vertical scaling is possible.

179
00:09:44,580 --> 00:09:45,720
It's synchronous coupling.

180
00:09:45,930 --> 00:09:47,070
Every call is blocking.

181
00:09:48,000 --> 00:09:48,960
Computer and reporting.

182
00:09:48,960 --> 00:09:51,000
Sit directly on the old TP tables.

183
00:09:51,360 --> 00:09:56,250
Mixed workloads on one DB
ingestion, rights, risk analytics,

184
00:09:56,250 --> 00:09:57,720
dashboards and compliance.

185
00:09:57,720 --> 00:10:00,540
All hammered the same tables,
and the same in diocese.

186
00:10:01,040 --> 00:10:02,180
This is batch ology.

187
00:10:02,705 --> 00:10:08,765
So heavy recalculation runs which run
nightly via CR job instead of streaming or

188
00:10:08,765 --> 00:10:11,525
incremental computation, no back pressure.

189
00:10:12,245 --> 00:10:16,505
So every time there's a spike
in feed volume, it'll stall

190
00:10:16,565 --> 00:10:18,125
ingestion, threads and cascade.

191
00:10:18,155 --> 00:10:20,405
Three users, single region.

192
00:10:20,615 --> 00:10:24,695
So higher latency for global
users and any regional outage

193
00:10:24,845 --> 00:10:26,255
would equal platform outage.

194
00:10:26,755 --> 00:10:27,865
Ad compliance.

195
00:10:27,925 --> 00:10:33,325
So audit is just a few extra rows
in the same db, the schema rigidity.

196
00:10:33,415 --> 00:10:37,165
So no event versioning schema
changes require coordinated

197
00:10:37,165 --> 00:10:38,835
downtime, adventure time.

198
00:10:39,105 --> 00:10:41,805
We are going to find out what happens
when we scale this architecture.

199
00:10:42,305 --> 00:10:46,660
This it's a graphical representation
of what the Inges service feels

200
00:10:46,660 --> 00:10:49,870
like, and there's millions
of trays coming in every day.

201
00:10:50,370 --> 00:10:51,660
It probably feels like this,

202
00:10:52,160 --> 00:10:54,590
and this is probably what
the database looks like.

203
00:10:55,090 --> 00:10:59,320
So every box in this particular
database is actually the same deal.

204
00:10:59,820 --> 00:11:03,750
It probably differs from each
other by a few parameters on

205
00:11:03,750 --> 00:11:05,820
certain days by one parameter.

206
00:11:06,320 --> 00:11:08,960
Here's a simple example that
illustrates the core problem.

207
00:11:09,860 --> 00:11:12,080
Let's say we have deal one
that evolves over time.

208
00:11:12,800 --> 00:11:16,250
On day one, we are holding instrument
one worth a hundred dollars.

209
00:11:17,030 --> 00:11:20,780
On day two, the market moves,
so we are now holding $300

210
00:11:20,780 --> 00:11:24,290
worth J three $500 and so on.

211
00:11:24,790 --> 00:11:28,300
The nave approach is to store a
complete record for each day, but

212
00:11:28,300 --> 00:11:30,160
think about what it means at scale.

213
00:11:30,640 --> 00:11:34,480
We millions of deals each
potentially changing daily

214
00:11:34,540 --> 00:11:36,130
over years of trading history.

215
00:11:36,490 --> 00:11:40,650
That's terabytes of mostly redundant
data, but here's the real kicker.

216
00:11:41,520 --> 00:11:45,360
P and l needs to be calculated not
just daily, but sometimes every

217
00:11:45,360 --> 00:11:47,250
minute during wall tail markets.

218
00:11:47,820 --> 00:11:52,260
Our traders need to see real time,
profit and loss as positions change.

219
00:11:52,755 --> 00:11:57,015
So now we need to index all of
this data by date, by instrument,

220
00:11:57,255 --> 00:12:02,025
by book, by trader, and we need
these squares to be fast, even

221
00:12:02,025 --> 00:12:03,765
as our data grows exponentially.

222
00:12:04,265 --> 00:12:06,905
And that's just the beginning
of our data challenges.

223
00:12:07,405 --> 00:12:12,835
The redundancy of previous records can
be addressed by relational databases.

224
00:12:13,435 --> 00:12:17,395
Based on the dates, the normalized
table of changes cannot be guaranteed

225
00:12:17,395 --> 00:12:21,475
to function well because of what
factors in the deals change.

226
00:12:22,465 --> 00:12:25,855
The regime can change, legal
entities can change, instrument

227
00:12:25,855 --> 00:12:28,345
can change, and pricing can change.

228
00:12:28,845 --> 00:12:31,335
So how do you maintain data
that changes frequently?

229
00:12:31,835 --> 00:12:36,245
In financial markets, data is
usually dependent upon each other.

230
00:12:36,785 --> 00:12:42,305
For instance, if there is a credit
event, it leads to the evaluation of an

231
00:12:42,305 --> 00:12:46,595
instrument, which leads to the change
in the estate, which eventually leads

232
00:12:46,595 --> 00:12:51,805
to a change in p and l, and the traders
only care about the change in PL on the

233
00:12:51,805 --> 00:12:57,355
other hand, because of the magic of the
markets, which is a two layer case market.

234
00:12:57,730 --> 00:13:00,310
There could be a change in the
value of the instrument that

235
00:13:00,310 --> 00:13:02,710
cascades into a change in piano.

236
00:13:03,210 --> 00:13:09,600
What this means is all of these
calculations are basically dependent

237
00:13:09,780 --> 00:13:12,605
on each other and each other's state.

238
00:13:13,105 --> 00:13:14,780
Let me give you a concrete example.

239
00:13:15,500 --> 00:13:17,165
Here's deal one over four days.

240
00:13:18,125 --> 00:13:21,095
We are holding Instrument
one worth a hundred dollars.

241
00:13:21,845 --> 00:13:26,555
The same instrument now is worth
150 due to market movement.

242
00:13:27,515 --> 00:13:33,385
The market crashed on 30 and we are now
holding $50 worth of that instrument.

243
00:13:33,885 --> 00:13:36,795
On the fourth day, there was a
corporate action that was taken

244
00:13:37,545 --> 00:13:41,460
and instrument one gets converted
into Instrument 12, which is.

245
00:13:41,960 --> 00:13:44,510
A cashflow instrument worth $30.

246
00:13:45,010 --> 00:13:50,530
Now imagine you're a regulator asking
show me the complete audit trail of deal.

247
00:13:50,530 --> 00:13:55,600
One, you need to reconstruct not just
the value changes, but the instrument

248
00:13:55,600 --> 00:13:59,740
evolution, the corporate actions,
the legal entity changes everything.

249
00:14:00,610 --> 00:14:05,355
Traditional relational databases start
to buckle under this kind of complexity.

250
00:14:06,175 --> 00:14:08,605
Normalized tables can't handle the table.

251
00:14:08,605 --> 00:14:09,595
Schema changes.

252
00:14:10,135 --> 00:14:12,835
Full snapshots create
massive storage overheads.

253
00:14:13,525 --> 00:14:18,385
Point to time queries require increasingly
com complex joins as the data grows.

254
00:14:18,885 --> 00:14:22,005
And here's what really keeps
database administrators up

255
00:14:22,005 --> 00:14:23,535
at night lock contention.

256
00:14:24,035 --> 00:14:26,735
And during peak trading hours,
especially around market open

257
00:14:26,735 --> 00:14:31,205
and close, we are seeing massive
concurrent updates to the same records.

258
00:14:31,775 --> 00:14:35,315
Thousands of traders are updating
their position simultaneously.

259
00:14:36,185 --> 00:14:39,005
Market data feeds are
updating instrument prices.

260
00:14:39,035 --> 00:14:44,285
Every millisecond risk systems are
recalculating exposures in real time.

261
00:14:45,035 --> 00:14:49,715
All of this happening on the same set of
database tables with the same indexes.

262
00:14:50,645 --> 00:14:56,615
The result, very performance that degrades
over time, backup and restore operations

263
00:14:56,975 --> 00:14:58,665
that take longer than the business takes.

264
00:14:59,165 --> 00:15:02,555
A system that becomes
increasingly fragile as it grows.

265
00:15:03,055 --> 00:15:04,345
So that was our reality.

266
00:15:04,845 --> 00:15:07,305
A system that worked fine
for thousands of trades but

267
00:15:07,305 --> 00:15:08,955
completely fell apart at millions.

268
00:15:09,675 --> 00:15:12,645
A system where adding new
features meant risking the

269
00:15:12,645 --> 00:15:14,745
stability of existing operations.

270
00:15:15,315 --> 00:15:19,575
A system where a brilliant traders was
spending more time waiting for screens

271
00:15:19,575 --> 00:15:21,825
to refresh than actually trading.

272
00:15:22,005 --> 00:15:23,145
Something had to change.

273
00:15:23,535 --> 00:15:25,665
And that brings us to our solution.

274
00:15:26,165 --> 00:15:28,775
Our first breakthrough came
from a simple observation.

275
00:15:29,255 --> 00:15:33,485
Most of the time when data changes,
only a small subset of dependent

276
00:15:33,485 --> 00:15:35,525
calculations actually need to be updated.

277
00:15:36,025 --> 00:15:39,805
So here we are marking our functions
with dependency decorators.

278
00:15:40,285 --> 00:15:43,645
When we calculate position
value, we are dependent on

279
00:15:43,645 --> 00:15:45,355
instrument ID and market data.

280
00:15:45,855 --> 00:15:49,035
When we calculate base currency
value, we're dependent on

281
00:15:49,035 --> 00:15:50,925
position value and FX rates.

282
00:15:51,705 --> 00:15:53,835
The magic happens when something changes.

283
00:15:54,375 --> 00:15:58,755
If the price of instrument one moves,
our dependency graph automatically

284
00:15:58,755 --> 00:16:02,115
identifies every calculation
that depends on instrument one

285
00:16:02,175 --> 00:16:03,855
and triggers only those updates.

286
00:16:04,355 --> 00:16:08,015
Before this change, a single
price movement would trigger a

287
00:16:08,015 --> 00:16:11,825
full recalculation of potentially
thousands of positions.

288
00:16:12,185 --> 00:16:14,945
Now we only recalculate
what actually changed.

289
00:16:15,845 --> 00:16:19,235
This single architectural change
reduced our end of day processing

290
00:16:19,235 --> 00:16:21,875
time from eight hours to five hours.

291
00:16:22,325 --> 00:16:27,065
But more importantly, it made real
time updates feasible instead of minute

292
00:16:27,065 --> 00:16:31,955
long delays for our p and l updates, we
were getting subsequent responsiveness.

293
00:16:32,455 --> 00:16:35,880
Our second major breakthrough
was rethinking how we store data.

294
00:16:35,990 --> 00:16:37,240
That changes frequently.

295
00:16:37,740 --> 00:16:40,790
This is what a deal looks
like, evolving over days.

296
00:16:41,290 --> 00:16:44,680
In the traditional approach, we are
storing complete records, everything.

297
00:16:45,580 --> 00:16:50,800
Even when 49 out of the 50 fields
haven't changed, it's massively wasteful.

298
00:16:51,250 --> 00:16:56,610
In our Delta approach, we store the
full record once the first state, then

299
00:16:56,610 --> 00:16:58,710
we only store what actually changes.

300
00:16:59,220 --> 00:17:02,220
Obviously, you have to maintain
the head state for the day

301
00:17:02,220 --> 00:17:03,420
you're doing the processing.

302
00:17:03,920 --> 00:17:06,110
Day two might just be a price change.

303
00:17:06,830 --> 00:17:09,380
J three might just be
quantity and status change.

304
00:17:09,650 --> 00:17:10,880
And here's the clever part.

305
00:17:11,330 --> 00:17:17,600
We can reconstruct any points in time
view by applying deltas sequentially.

306
00:17:18,100 --> 00:17:23,530
Now let's talk about geographic re
distribution In finance, this isn't just

307
00:17:23,530 --> 00:17:27,850
about performance, it's about regulatory
requirements and disaster recovery.

308
00:17:28,645 --> 00:17:33,535
Our primary training hubs are in New York
and London, close to major exchanges.

309
00:17:34,135 --> 00:17:38,065
Each location has a primary
database instance with three local

310
00:17:38,065 --> 00:17:41,095
replicas for IO optimization.

311
00:17:41,595 --> 00:17:42,765
But here's the tricky part.

312
00:17:43,425 --> 00:17:47,985
We net synchronous replication within
each region for consistency, but

313
00:17:48,255 --> 00:17:52,155
asynchronous replication between
regions to handle network partitions.

314
00:17:52,545 --> 00:17:52,995
Why?

315
00:17:53,835 --> 00:17:57,495
When markets are moving fast,
traders can't wait for cross

316
00:17:57,495 --> 00:17:59,565
Atlantic network latency.

317
00:18:00,375 --> 00:18:05,115
They need local data to be consistent
and fast, but we also need to ensure

318
00:18:05,235 --> 00:18:10,035
that if London goes dark, New York has
all the data it needs to keep operating.

319
00:18:10,815 --> 00:18:13,035
This is a classic gap theorem decision.

320
00:18:13,515 --> 00:18:14,205
In finance.

321
00:18:14,265 --> 00:18:18,525
We choose consistency and partition
tolerance, accepting higher latency

322
00:18:18,525 --> 00:18:21,525
for global users during network issues.

323
00:18:22,025 --> 00:18:28,175
This diagram basically shows you
potential locations of book records

324
00:18:28,235 --> 00:18:33,725
all across the us so you can consider
each of these dolls as a book.

325
00:18:34,225 --> 00:18:38,605
These are replicated across US
geography because data loss events

326
00:18:38,695 --> 00:18:40,165
are geographically connected.

327
00:18:40,615 --> 00:18:46,615
Power outages, natural disasters, et
cetera, are usually limited by geography.

328
00:18:47,115 --> 00:18:49,875
And this is a representation
of the TB hydra.

329
00:18:50,175 --> 00:18:54,915
So as you can see, each of the
deals is replicated multiple times

330
00:18:55,245 --> 00:18:57,635
across different database instances.

331
00:18:58,135 --> 00:19:00,390
This is possibly what it
looks like across the globe.

332
00:19:01,210 --> 00:19:06,250
Usually when trading, most deals
are limited to certain regions

333
00:19:06,670 --> 00:19:08,170
because of legal entities.

334
00:19:09,160 --> 00:19:11,440
So you can see that.

335
00:19:11,690 --> 00:19:18,790
Data is replicated across the us, across
Europe, across Australia, and then there

336
00:19:18,790 --> 00:19:23,710
is a specific DB that maintains all
of the trades that are cross-regional

337
00:19:24,160 --> 00:19:25,630
are cross legal entity based.

338
00:19:26,130 --> 00:19:29,100
What this helps at is computing at scale.

339
00:19:29,670 --> 00:19:34,620
This helps us paralyzed as much
as possible because of the nature

340
00:19:34,620 --> 00:19:38,465
of markets, trading is usually
regionally legal entity based.

341
00:19:38,965 --> 00:19:42,865
Athena maintains a different instance
for across legal entity trades.

342
00:19:43,545 --> 00:19:48,315
Often using clever techniques to
add a third leg to the trade to be

343
00:19:48,315 --> 00:19:52,545
able to compute efficiently making
for some very clever corner cases.

344
00:19:53,415 --> 00:19:59,265
For instance, if there's a trade that is
cross legal entity, Athena will create a

345
00:19:59,265 --> 00:20:05,945
trade in, say, a legal entity associated
with legal entity North America and one

346
00:20:05,945 --> 00:20:08,735
associated with a legal entity in Europe.

347
00:20:09,455 --> 00:20:09,740
A deal.

348
00:20:10,240 --> 00:20:14,050
Is associated with a legal entity
in North America and a deal that is

349
00:20:14,050 --> 00:20:19,840
associated with a legal entity in Europe,
and a third deal that is associated

350
00:20:20,410 --> 00:20:26,170
with coast legal entities between
North America and Europe, which is

351
00:20:26,170 --> 00:20:27,910
stored in a completely separate entity.

352
00:20:28,690 --> 00:20:29,200
So that.

353
00:20:29,700 --> 00:20:34,680
The data that exists only in the
North American markets and the data

354
00:20:34,680 --> 00:20:38,880
that exists only in the European
markets can be computed and parallel

355
00:20:39,480 --> 00:20:41,070
independently of each other.

356
00:20:41,570 --> 00:20:45,740
Our end of day calculations used to be
a single massive monolithic process.

357
00:20:46,610 --> 00:20:49,640
If anything failed, we would have
to start over from the beginning.

358
00:20:50,150 --> 00:20:51,710
We completely redesigned this.

359
00:20:52,220 --> 00:20:54,830
As a dependency aware parallel pipeline,

360
00:20:55,330 --> 00:20:56,500
look at this architecture.

361
00:20:56,890 --> 00:21:02,140
We break down processing into independent
units, instrument a reference data

362
00:21:02,140 --> 00:21:07,990
processing runs on one compute node, for
instance, instrument B on another deal

363
00:21:07,990 --> 00:21:10,420
processing for different books runs in.

364
00:21:10,920 --> 00:21:12,120
But here's the key insight.

365
00:21:12,630 --> 00:21:14,040
We maintain dependencies.

366
00:21:14,655 --> 00:21:18,735
The p and l completion job cannot
start unless all of the book

367
00:21:18,735 --> 00:21:20,415
processing jobs are complete.

368
00:21:21,135 --> 00:21:25,455
But if Book one processing fails and
book two succeeds, we can restart

369
00:21:25,455 --> 00:21:30,335
jobs for book one using the cash
results from the reference data jobs.

370
00:21:30,835 --> 00:21:35,845
This fall tolerance approach transformed
our end of day processing instead of

371
00:21:35,905 --> 00:21:40,405
a hr, all or nothing runs, we have
resilient pipelines that can recover

372
00:21:40,525 --> 00:21:41,995
from individual component failures.

373
00:21:42,495 --> 00:21:48,165
The reason we have separated the
instrument reference data processing from

374
00:21:48,165 --> 00:21:54,315
the deal state book processing entirely
is that instrument A could exist in a

375
00:21:54,315 --> 00:21:59,835
deal that exists in both book one and
book two, which means that the instrument,

376
00:21:59,835 --> 00:22:05,115
a reference data processing needs to
be complete before Book one processing

377
00:22:05,115 --> 00:22:06,735
or book two processing can start.

378
00:22:07,235 --> 00:22:09,995
Let me show you one of our
most innovative solutions,

379
00:22:10,475 --> 00:22:12,725
compute building blocks or CBDs.

380
00:22:13,475 --> 00:22:16,685
The traditional approach pulls
all the data to a central server

381
00:22:16,955 --> 00:22:18,095
and does computation there.

382
00:22:18,845 --> 00:22:23,165
This creates memory pressure, CPU
contention and IU bottlenecks.

383
00:22:23,765 --> 00:22:28,265
Our CBB approach creates independent
compute notes and loads data

384
00:22:28,355 --> 00:22:29,825
into its own memory space.

385
00:22:30,325 --> 00:22:35,455
It executes computation independently
and returns results for aggregation.

386
00:22:35,965 --> 00:22:41,965
Think of it like AWS Lambda, but for
financial calculations, its CBB gets

387
00:22:41,965 --> 00:22:47,065
its own play fields to load data,
run computations, and return results

388
00:22:47,125 --> 00:22:48,925
without affecting the main server.

389
00:22:49,720 --> 00:22:53,650
This approach gives us horizontal
scaling for compute intensive

390
00:22:53,650 --> 00:22:58,810
operations while keeping the main
system responsive for user interactions.

391
00:22:59,310 --> 00:23:04,620
So for instance, if you consider each
of these as books all across the globe,

392
00:23:05,070 --> 00:23:10,410
and for this particular example, if
we are processing the book service

393
00:23:10,410 --> 00:23:16,650
processing for the end of day calculations
in Europe, each of these books.

394
00:23:17,190 --> 00:23:24,000
Usually a book runs on multiple CBB notes,
but for this instance, each of these books

395
00:23:24,510 --> 00:23:31,580
could be sent to a particular CBB as a
reference, and the CBB then communicates

396
00:23:31,640 --> 00:23:36,980
with the Hydro DB to load the book details
and all of the deals in one particular

397
00:23:36,980 --> 00:23:41,625
book, which are unrelated to all of
the deals in all of the other books.

398
00:23:42,560 --> 00:23:47,750
They could be related, but for the purpose
of these p and l calculations, which

399
00:23:47,750 --> 00:23:53,710
happen on book to book basis, they can be
considered independent, which means you

400
00:23:53,710 --> 00:23:58,270
have so much of parallel processing and
you will basically save a lot of time.

401
00:23:58,810 --> 00:24:04,120
This is horizontal sharding because we are
keeping data independent of each other.

402
00:24:04,620 --> 00:24:08,730
So for every computation in order to
optimize for in-memory computations

403
00:24:08,820 --> 00:24:13,620
and more parallelism, every operation
is chunked into independent computable

404
00:24:13,650 --> 00:24:17,820
chunks, which form a lambda like
function, which executes upon its own

405
00:24:17,820 --> 00:24:20,070
CVB nodes and the results are collated.

406
00:24:20,910 --> 00:24:23,970
For instance, instead of pulling
graphs from instrument one to

407
00:24:23,970 --> 00:24:28,920
compute metrics on the server itself,
another compute block is shown a

408
00:24:28,920 --> 00:24:31,020
functional hydroco to load data.

409
00:24:31,520 --> 00:24:35,450
So it loads in memory without affecting
the compute of the main server.

410
00:24:35,900 --> 00:24:40,645
Basically, each doll gets its own play
fields to beyond graves and graves.

411
00:24:41,145 --> 00:24:44,175
Before we move on, let me
touch on something critical.

412
00:24:44,865 --> 00:24:46,035
Compliance architecture.

413
00:24:46,785 --> 00:24:49,095
In finance compliance
isn't an afterthought.

414
00:24:49,635 --> 00:24:51,735
It's a core architectural requirement.

415
00:24:52,245 --> 00:24:53,475
We learned this, the Harvey.

416
00:24:54,210 --> 00:24:59,190
Our solution was to separate operational
data from compliance data physically.

417
00:24:59,850 --> 00:25:04,230
Our OLTP systems handle real-time
trading with performance optimization.

418
00:25:04,830 --> 00:25:08,490
Our OLAP systems handle regulatory
reporting with long-term

419
00:25:08,490 --> 00:25:10,560
retention and query optimization.

420
00:25:11,130 --> 00:25:15,780
This separation prevents compliance
queries from impacting trading operations

421
00:25:16,050 --> 00:25:20,280
while ensuring we can reconstruct any
historical state for audit purposes.

422
00:25:20,780 --> 00:25:23,600
We also implemented automated
compliance feed processing.

423
00:25:24,110 --> 00:25:28,370
Every trade, every price change,
every position update gets

424
00:25:28,520 --> 00:25:31,310
streamed to immutable audit logs.

425
00:25:31,640 --> 00:25:36,470
Regulators can access this data without
touching our operational systems.

426
00:25:36,970 --> 00:25:41,170
So this is the last step, but it's
possibly the most important step.

427
00:25:41,710 --> 00:25:43,180
In certain cases, it comes.

428
00:25:43,825 --> 00:25:48,625
After the deal State Book one processing
or after any deal state book processing.

429
00:25:49,125 --> 00:25:54,765
A story I have about how important this
is in financial, in the financial domain

430
00:25:55,095 --> 00:26:01,185
is that there was a time when someone was
running a Python machine learning base

431
00:26:01,185 --> 00:26:05,975
analytics script on a bunch of deals,
which ended up choking a queue and the

432
00:26:05,975 --> 00:26:08,795
deals that were supposed to be processed.

433
00:26:09,185 --> 00:26:14,195
Were left in the state of this deal
has not been processed, though it had

434
00:26:14,195 --> 00:26:18,005
been processed by the deal service, but
not by the analytical script because

435
00:26:18,005 --> 00:26:23,765
of some bucks in the script and it
choked the queue and it basically led

436
00:26:24,665 --> 00:26:31,720
to us paying a hundred thousand dollars
in fines to the regulators because we

437
00:26:31,720 --> 00:26:34,060
could not make the regulatory timeframe.

438
00:26:34,560 --> 00:26:35,310
So back to earth.

439
00:26:35,810 --> 00:26:37,425
Now let's address the
elephant in the room.

440
00:26:38,030 --> 00:26:38,780
Why Python?

441
00:26:38,840 --> 00:26:40,100
For financial systems?

442
00:26:40,670 --> 00:26:41,900
I get this question a lot.

443
00:26:42,320 --> 00:26:43,430
Python is in trust.

444
00:26:43,850 --> 00:26:45,080
Python has the GIL.

445
00:26:45,530 --> 00:26:46,340
Python is dynam.

446
00:26:46,340 --> 00:26:47,540
Clear type, all true.

447
00:26:48,050 --> 00:26:51,020
But finance, these apparent
weaknesses become strengths.

448
00:26:51,710 --> 00:26:54,020
Financial instruments
are incredibly diverse.

449
00:26:54,395 --> 00:26:58,175
Bonds derivative swaps, credit
default swaps each with different

450
00:26:58,175 --> 00:27:02,645
attributes, different valuation models,
and different risk characteristics.

451
00:27:03,005 --> 00:27:06,515
Python's duct typing and dynamic
typing lets us handle this

452
00:27:06,515 --> 00:27:08,855
diversity without Bridget Schemas.

453
00:27:09,275 --> 00:27:12,665
We can represent a bond and a seed
with the same processing logic.

454
00:27:13,385 --> 00:27:17,435
Python's dictionary structures work
beautiful beautifully with our indexing

455
00:27:17,435 --> 00:27:20,255
requirements and we need raw performance.

456
00:27:20,755 --> 00:27:24,625
When we need raw performance, we drop
down to c plus compute building blocks.

457
00:27:24,985 --> 00:27:28,705
The result is a system that's
both flexible for rapid business

458
00:27:28,705 --> 00:27:32,605
logic changes and performance
for compute intensive operations.

459
00:27:33,105 --> 00:27:37,410
Let me wrap up with the key principles
we learned building Athena Scale first.

460
00:27:37,800 --> 00:27:39,780
Embrace financial domain complexity.

461
00:27:40,470 --> 00:27:44,610
Don't try to force financial data
into simple relational models.

462
00:27:44,850 --> 00:27:48,110
The domain is inherently
complex and your architecture

463
00:27:48,110 --> 00:27:49,640
needs to reflect that reality.

464
00:27:50,150 --> 00:27:53,870
Build flexibility into your data
models from day one and plan

465
00:27:53,870 --> 00:27:55,430
for frequent schema evolution.

466
00:27:56,180 --> 00:27:58,970
Second, optimize for
change, not just scale.

467
00:27:59,470 --> 00:28:01,600
In most tech companies data.

468
00:28:02,100 --> 00:28:06,000
Data grows, but doesn't
fundamentally change In finance.

469
00:28:06,090 --> 00:28:08,820
Data mutates constantly
in unpredictable ways.

470
00:28:09,510 --> 00:28:13,950
Dependency driven updates be
it full recalculations delta

471
00:28:13,950 --> 00:28:16,170
storage beats full snapshots.

472
00:28:16,470 --> 00:28:19,590
Event driven architecture
beats batch processing.

473
00:28:20,130 --> 00:28:25,770
Third separate concerns physically don't
try to optimize operational data and

474
00:28:25,770 --> 00:28:28,170
analytical data with the same approach.

475
00:28:28,500 --> 00:28:31,770
They have fundamentally different
access patterns and requirements.

476
00:28:32,370 --> 00:28:34,050
Fourth, design for failure.

477
00:28:34,550 --> 00:28:38,750
When finance failure isn't just an
inconvenience, it's a regulatory event.

478
00:28:38,870 --> 00:28:43,510
As I mentioned before, built in
independent processing units, cash

479
00:28:43,570 --> 00:28:48,190
in intermediate results, and have
graceful degradation strategies.

480
00:28:48,690 --> 00:28:51,510
Let me share some of the pitfalls
we encountered so you don't

481
00:28:51,510 --> 00:28:52,455
have to repeat our mistakes.

482
00:28:52,955 --> 00:28:54,335
Premature optimization.

483
00:28:54,665 --> 00:28:58,595
We spent months optimizing the wrong
bottlenecks because we didn't properly

484
00:28:58,595 --> 00:29:00,965
profile our system under realistic load.

485
00:29:01,685 --> 00:29:05,555
Start with clear business requirements
profile before optimizing and

486
00:29:05,555 --> 00:29:09,155
measure the impact of every
change ignoring data lineage.

487
00:29:09,545 --> 00:29:12,515
Financial regulators don't
just want your current data.

488
00:29:13,175 --> 00:29:14,740
They want to understand how you got there.

489
00:29:15,650 --> 00:29:19,520
Built audit trails and data
lineage tracking into architecture

490
00:29:19,880 --> 00:29:23,210
from the beginning to bolt on
compliance as an afterthought.

491
00:29:23,750 --> 00:29:28,220
Third pitfall, understanding
operational complexity, multi ian

492
00:29:28,220 --> 00:29:32,690
deployments, monitoring distributed
systems, handling partial failures.

493
00:29:33,080 --> 00:29:35,000
The operational overhead is significant.

494
00:29:35,330 --> 00:29:36,710
Plan for it and budget for it.

495
00:29:37,210 --> 00:29:41,140
Looking ahead, the financial technology
landscape is evolving rapidly.

496
00:29:41,905 --> 00:29:45,055
Stream processing technologies
like Kafka are becoming the

497
00:29:45,055 --> 00:29:47,035
standard for real-time analytics.

498
00:29:47,605 --> 00:29:51,115
Even sourcing is gaining adoption
for complete audit trials.

499
00:29:51,615 --> 00:29:54,465
On the regulatory side, we
are seeing increasing demands

500
00:29:54,525 --> 00:29:55,725
for real-time reporting.

501
00:29:56,445 --> 00:29:58,185
Cloud adoption, ISS accelerating.

502
00:29:58,425 --> 00:30:02,865
Even in highly regulated industries,
data residency and sovereignty

503
00:30:02,865 --> 00:30:04,965
requirements are becoming more complex.

504
00:30:05,805 --> 00:30:10,515
Privacy regulations like GDP are
impacting how we handle financial data.

505
00:30:11,415 --> 00:30:14,625
Building scalable financial systems
is one of the most challenging

506
00:30:14,625 --> 00:30:16,245
problems in software engineer.

507
00:30:16,905 --> 00:30:20,205
You're dealing with regulatory
complexity, massive scale, real time

508
00:30:20,205 --> 00:30:24,465
requirements, and zero tolerance for
errors, but it's also incredibly reward.

509
00:30:24,965 --> 00:30:29,585
When your system processes millions of
trades flawlessly, and when traders can

510
00:30:29,585 --> 00:30:35,255
react to market S in milliseconds, when
regulators access audit trails instantly,

511
00:30:35,465 --> 00:30:39,485
you're enabling the global financial
system to function more efficiently.

512
00:30:40,235 --> 00:30:42,995
The key is to respect the
domain complexity while applying

513
00:30:42,995 --> 00:30:44,735
sound engineering principles.

514
00:30:45,235 --> 00:30:46,930
Don't try to solve everything at once.

515
00:30:47,470 --> 00:30:49,240
Start with your core Delta model.

516
00:30:49,750 --> 00:30:52,120
Build flexibility and observability.

517
00:30:52,620 --> 00:30:55,980
Observability from the beginning
and scale incrementally.

518
00:30:56,480 --> 00:30:59,930
For instance, this is what
Athena basically looks like.

519
00:31:00,320 --> 00:31:03,260
This is what any trade
model would look like.

520
00:31:03,950 --> 00:31:07,130
Any trade management platform
would look exactly like this.

521
00:31:07,610 --> 00:31:10,910
There would be the trade fees, there
would be a trade ingestion layer.

522
00:31:11,090 --> 00:31:14,570
There would be a trade end to use
service, which would eventually be

523
00:31:14,570 --> 00:31:18,445
compiled into a book service and
which would have to go to compliance.

524
00:31:18,945 --> 00:31:23,805
The trade and deal service interacts
heavily in this case with the

525
00:31:23,805 --> 00:31:30,035
distributed compute, which interacts
with the database, and also outputs

526
00:31:30,095 --> 00:31:31,985
p and l and risk computations.

527
00:31:32,485 --> 00:31:37,425
The CBBs are also associated with
event payments, which pop out alerts,

528
00:31:37,425 --> 00:31:43,515
notifications, and corporate actions, some
of which eventually come and lie into.

529
00:31:44,085 --> 00:31:48,105
The queue of the trade and deal
service, depending upon your use case.

530
00:31:49,035 --> 00:31:53,535
They also connect to monitoring
dashboards and other regulatory reports.

531
00:31:54,135 --> 00:31:57,765
Sometimes the compliance services
and the regulatory reports are

532
00:31:57,765 --> 00:32:02,175
connected based on what sort of
regulatory agency you're reporting to.

533
00:32:02,675 --> 00:32:05,765
So this is what Athena high level
scalable architecture looks like.

534
00:32:06,265 --> 00:32:10,605
We looked at the trade ingestion
layer, we looked at queues.

535
00:32:10,945 --> 00:32:16,255
We looked at the trade service, the deal
service on the book service, which is

536
00:32:16,255 --> 00:32:18,385
associated with the compliance service.

537
00:32:19,315 --> 00:32:24,835
We looked at ways to parallelize all of
these services and to share data because

538
00:32:24,835 --> 00:32:28,090
most of the data, it's high scale,
but it's independent of each other.

539
00:32:28,590 --> 00:32:33,180
As a matter of fact, it is required
for the risk and p and l calculations

540
00:32:33,810 --> 00:32:38,310
that each book be independently
weighed against the compute metrics.

541
00:32:38,810 --> 00:32:43,190
All of these services, they interact
with the distributed compute, again,

542
00:32:43,190 --> 00:32:44,660
allowing for even more parallelization.

543
00:32:45,160 --> 00:32:50,530
Which interacts with the hydro database,
which is geo distributed, which basically

544
00:32:50,530 --> 00:32:56,200
means that a trait that is executed in a
certain geo region would only be touching

545
00:32:56,530 --> 00:33:00,850
a particular geo-located service instance.

546
00:33:01,240 --> 00:33:06,010
A geo-located compute block instance
and a geo-located hydro instance.

547
00:33:06,510 --> 00:33:10,380
And hydro is replicated in
order to improve IO bottlenecks,

548
00:33:10,880 --> 00:33:12,170
which eventually leads.

549
00:33:12,935 --> 00:33:15,905
Regulatory reporting and
other monitoring services.

550
00:33:16,405 --> 00:33:20,425
If you compare these two models,
this is the monolithic approach and

551
00:33:20,425 --> 00:33:22,285
this is the highly scaled approach.

552
00:33:22,765 --> 00:33:28,275
It looks almost the same, except
this is after the SGDP polling.

553
00:33:29,235 --> 00:33:33,285
This is not an asynchronous service,
so anything that would be blocked

554
00:33:33,285 --> 00:33:35,475
in between would be a blocker.

555
00:33:36,195 --> 00:33:40,305
For any sort of other request that the
service would want to get at that time.

556
00:33:41,175 --> 00:33:45,905
On the other hand, because of our
parallelization approaches, if a node

557
00:33:45,905 --> 00:33:50,375
fails, there are other nodes that can
take over because of the replication

558
00:33:50,375 --> 00:33:55,825
of data, a lot of data is independent
of each other, geo distributed, which

559
00:33:55,825 --> 00:34:01,015
means any failures in London would
not affect anything in New York.

560
00:34:01,515 --> 00:34:06,465
On the compute node would not mean that
the service is down for every sort of

561
00:34:06,465 --> 00:34:09,075
request, which is not true in this case.

562
00:34:09,575 --> 00:34:10,505
Thank you so much.

