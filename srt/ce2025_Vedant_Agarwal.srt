1
00:00:00,190 --> 00:00:00,850
Hello everyone.

2
00:00:01,530 --> 00:00:05,880
Welcome to real time personalization
at scale, neural ranking systems

3
00:00:06,680 --> 00:00:07,799
and operational breakthroughs.

4
00:00:08,549 --> 00:00:12,270
I'm Vedant Agarwal, Senior Software
Engineer working in Search.

5
00:00:12,770 --> 00:00:17,270
Today, I will share how advanced neural
ranking systems enable personalized

6
00:00:17,460 --> 00:00:21,460
recommendations to drive both operational
efficiency and real business impact.

7
00:00:21,960 --> 00:00:27,110
In this session, our agenda is
organized on around several key topics.

8
00:00:27,610 --> 00:00:32,520
First, we will cover our breakthroughs
in ranking, which includes both candidate

9
00:00:32,540 --> 00:00:34,570
generation and precision re ranking.

10
00:00:35,550 --> 00:00:39,409
Next, we will address latency
challenges, discussing how we can

11
00:00:39,409 --> 00:00:44,309
achieve sub 50 millisecond response
times, which is a crucial factor for

12
00:00:44,319 --> 00:00:46,080
ensuring a smooth user experience.

13
00:00:46,580 --> 00:00:50,380
We will then explore the real time
constraints of processing millions

14
00:00:50,380 --> 00:00:51,980
of interactions concurrently.

15
00:00:52,480 --> 00:00:56,099
And finally, we will review the
business impact of these solutions

16
00:00:56,539 --> 00:01:00,179
and look at emerging trends that
will shape future initiatives.

17
00:01:00,679 --> 00:01:03,929
This overview is meant to
provide you with a clear roadmap

18
00:01:03,949 --> 00:01:05,220
for the presentation ahead.

19
00:01:05,720 --> 00:01:09,734
Real time personalization introduces
several technical challenges.

20
00:01:10,375 --> 00:01:16,145
First, data inconsistencies and noise
are common, as user clickstreams and

21
00:01:16,145 --> 00:01:21,445
transaction logs often contain variability
that can affect model accuracy.

22
00:01:22,375 --> 00:01:26,975
Second, scaling becomes a critical
concern when processing millions

23
00:01:26,975 --> 00:01:30,904
of concurrent interactions while
maintaining system responsiveness.

24
00:01:31,734 --> 00:01:37,790
Third, model drift poses an ongoing
issue As user behavior evolves,

25
00:01:38,580 --> 00:01:43,520
consider, for example, a sudden shift
in seasonal trends, our models must

26
00:01:43,560 --> 00:01:45,770
adapt quickly to maintain relevance.

27
00:01:46,630 --> 00:01:50,919
These challenges underscore the
need for agile and robust solutions

28
00:01:51,490 --> 00:01:54,910
capable of processing high volume,
real time data effectively.

29
00:01:55,410 --> 00:01:59,380
To overcome these challenges,
there is something as a two tier

30
00:01:59,410 --> 00:02:00,800
neural ranking architecture.

31
00:02:01,300 --> 00:02:06,700
The first tier, L1, focuses on candidate
generation using embedding based indexing.

32
00:02:07,200 --> 00:02:11,350
Here, user behaviors and item attributes
are projected into a shared high

33
00:02:11,350 --> 00:02:16,540
dimensional space, allowing for rapid
filtering of a vast number of items.

34
00:02:17,540 --> 00:02:22,019
The second tier, L2, handles
precision re ranking using advanced

35
00:02:22,020 --> 00:02:23,389
sequence modeling techniques.

36
00:02:23,900 --> 00:02:27,940
such as LSTMs or transformers
to integrate both historical

37
00:02:27,950 --> 00:02:29,520
data and real time signals.

38
00:02:30,020 --> 00:02:34,340
This decoupled approach enables
us to optimize speed in the first

39
00:02:34,350 --> 00:02:38,990
stage while ensuring that the final
recommendations are highly personalized.

40
00:02:39,010 --> 00:02:45,019
For example, while L1 may retrieve a
broad set of items from a database of

41
00:02:45,049 --> 00:02:50,889
over a million entities in a matter of
milliseconds, L2 refines this set to match

42
00:02:50,889 --> 00:02:53,239
the user's current context accurately.

43
00:02:53,739 --> 00:02:57,989
In our L1 candidate generation process,
we achieve significant performance

44
00:02:58,009 --> 00:03:00,349
gains through embedding based indexing.

45
00:03:00,849 --> 00:03:04,889
This method projects both user
behavior and item characteristics

46
00:03:04,999 --> 00:03:09,779
into a shared feature space,
allowing us to employ approximate

47
00:03:09,789 --> 00:03:11,249
nearest neighbor search technique.

48
00:03:12,239 --> 00:03:18,229
For instance, our system can retrieve a
broad set of relevant candidate items in

49
00:03:18,229 --> 00:03:23,189
under 10 milliseconds, even when querying
a corpus of more than a million items.

50
00:03:23,689 --> 00:03:29,459
This rapid pre filtering is crucial as
it reduces the computational load for

51
00:03:29,459 --> 00:03:35,234
the L2 ranking stage, ensuring that The
system remains both fast and scalable.

52
00:03:35,734 --> 00:03:40,734
The efficiency of L1 is a foundational
operational breakthrough that enables

53
00:03:40,734 --> 00:03:45,174
us to deliver highly responsive
and personalized recommendations.

54
00:03:45,674 --> 00:03:50,964
Now, we move on to L2 stage, which
focuses on precision re ranking.

55
00:03:51,464 --> 00:03:56,814
In this layer, we employ advanced sequence
modeling techniques using models such

56
00:03:56,814 --> 00:04:02,384
as transformers or LSTMs to capture the
sequential dependencies in user data.

57
00:04:02,384 --> 00:04:06,729
Music playing This approach allows
us to integrate both real time

58
00:04:06,839 --> 00:04:10,799
session information and long
term user history effectively.

59
00:04:11,759 --> 00:04:17,379
For example, by incorporating attention
mechanisms, the system can assign

60
00:04:17,389 --> 00:04:23,089
higher weight to recent clicks compared
to older ones, ensuring that the most

61
00:04:23,529 --> 00:04:25,379
relevant signals are prioritized.

62
00:04:25,879 --> 00:04:30,629
This dynamic re ranking process, which
adjusts in real time to the user's

63
00:04:30,659 --> 00:04:35,219
context, can lead to a significant
improvement in recommendation accuracy,

64
00:04:36,079 --> 00:04:39,659
with an observed increase in click
through rates by approximately

65
00:04:39,689 --> 00:04:41,539
20 percent as shown in studies.

66
00:04:42,039 --> 00:04:46,224
Next, let us discuss latency
breakthroughs, and how we can

67
00:04:46,224 --> 00:04:48,954
handle real time constraints.

68
00:04:49,824 --> 00:04:54,514
The latest systems are engineered to
achieve sub 50 millisecond end to end

69
00:04:54,564 --> 00:04:59,404
processing response times, ensuring
a fast result generation from user

70
00:04:59,524 --> 00:05:01,154
action to recommendation delivery.

71
00:05:01,654 --> 00:05:06,214
We can balance the inherent complexity
of our models with the need for

72
00:05:06,274 --> 00:05:10,329
quick inference By simplifying
certain architectural components

73
00:05:10,409 --> 00:05:15,949
without sacrificing quality, for
instance, by implementing optimized

74
00:05:15,959 --> 00:05:20,479
inference pipelines with asynchronous
processing and caching strategies,

75
00:05:20,679 --> 00:05:25,829
we can reduce latency from around 70
milliseconds down to 45 milliseconds.

76
00:05:26,329 --> 00:05:29,759
Additionally, system scales
dynamically under load.

77
00:05:30,274 --> 00:05:35,074
Thanks to auto scaling and load balancing,
which are continuously monitored in real

78
00:05:35,104 --> 00:05:37,634
time to maintain consistent performance

79
00:05:38,134 --> 00:05:42,284
at the heart of operations lies a
robust infrastructure and dynamic

80
00:05:42,284 --> 00:05:47,394
feature engineering process, we can
utilize real time data pipelines.

81
00:05:47,784 --> 00:05:52,724
Employing tools like Kafka and Apache
Flink to continuously ingest user

82
00:05:52,864 --> 00:05:58,034
clicks and purchase data, ensuring that
our models receive instant updates.

83
00:05:58,534 --> 00:06:03,504
Microservices architectures containerized
using Docker and orchestrated by

84
00:06:03,504 --> 00:06:08,854
Kubernetes can enable us to maintain
modular scalability and fault isolation.

85
00:06:09,354 --> 00:06:16,014
In parallel, feature engineering process
dynamic It generates features from

86
00:06:16,014 --> 00:06:20,274
live data, such as current session
attributes, and applies advanced

87
00:06:20,274 --> 00:06:25,434
transformations like normalization,
feature crosses, and depend meetings.

88
00:06:25,934 --> 00:06:30,374
Observability can be maintained through
tools like Prometheus and Grafana, which

89
00:06:30,474 --> 00:06:35,504
provide automated alerts to detect and
address performance anomalies promptly.

90
00:06:36,004 --> 00:06:38,934
Going on to the next slide,
deploying and updating the

91
00:06:38,934 --> 00:06:40,444
system seamlessly is critical.

92
00:06:41,064 --> 00:06:44,444
Which is why we can have
robust deployment strategies.

93
00:06:44,944 --> 00:06:50,764
We can maintain regular monitoring through
defined KPIs and automated anomaly alerts

94
00:06:51,024 --> 00:06:53,464
to catch performance deviations early.

95
00:06:53,964 --> 00:06:58,934
Automated retraining sessions can
be scheduled to address model drift,

96
00:06:59,504 --> 00:07:03,654
ensuring that our models remain up
to date with evolving user behavior.

97
00:07:04,154 --> 00:07:07,964
Our deployment processes, including
blue green deployments and rolling

98
00:07:07,994 --> 00:07:11,834
updates can help us achieve zero
done down times during rollouts.

99
00:07:12,334 --> 00:07:18,094
For example, we often can use canary
releases via Kubernetes to safely test

100
00:07:18,134 --> 00:07:20,194
new updates before a full rollout.

101
00:07:20,694 --> 00:07:24,704
Additionally, A B testing allows
us to gradually roll out features

102
00:07:25,154 --> 00:07:29,094
and assess their real time impact
with these pipelines, tightly

103
00:07:29,094 --> 00:07:31,284
integrated with our CI CD tools.

104
00:07:31,784 --> 00:07:35,254
Finally, let's consider the
business impact of these operational

105
00:07:35,254 --> 00:07:40,569
breakthroughs by refining ranking
accuracy and reducing latency.

106
00:07:41,069 --> 00:07:45,329
We can directly improve the matching
of products to user intent, which in

107
00:07:45,359 --> 00:07:47,349
turn can increase conversion rates.

108
00:07:47,849 --> 00:07:52,029
Personalized recommendations have
also led to enhanced user engagement

109
00:07:52,379 --> 00:07:55,689
reflected in longer sessions and
improved click through rates.

110
00:07:56,569 --> 00:08:01,259
In practice, we have observed
quantifiable outcomes such as 15

111
00:08:01,259 --> 00:08:05,079
percent increase in conversion
rates and a 25 percent improvement

112
00:08:05,079 --> 00:08:07,829
in CTR in these different studies.

113
00:08:08,329 --> 00:08:12,584
These metrics are tracked through
integrated analytics dashboards

114
00:08:12,954 --> 00:08:16,124
that we can continuously
monitor and adjust our business

115
00:08:16,134 --> 00:08:18,164
strategies to meet our objectives.

116
00:08:18,664 --> 00:08:21,884
This is where the technical
part of the presentation ends.

117
00:08:22,634 --> 00:08:28,014
But looking ahead, we can focus on
several emerging trends that will shape

118
00:08:28,014 --> 00:08:29,794
the next generation of personalization.

119
00:08:30,294 --> 00:08:33,504
One of these trends is multimodal
personalization, where we

120
00:08:33,504 --> 00:08:37,354
integrate text, image, and video
data to gain richer insights.

121
00:08:37,854 --> 00:08:44,024
For example, by combining visual cues
from product images with descriptive

122
00:08:44,074 --> 00:08:49,314
text, our system can be made, can
make more nuanced, Recommendations.

123
00:08:49,814 --> 00:08:54,594
We can also explore real time federated
learning, a decentralized approach

124
00:08:54,664 --> 00:08:58,964
to model training that not only
enhances privacy, but also reduces

125
00:08:58,964 --> 00:09:00,944
latency by keeping data local.

126
00:09:01,444 --> 00:09:05,984
Additionally, we can enhance our
neural ranking by adopting next

127
00:09:05,984 --> 00:09:09,764
generation deep learning models
to push accuracy even further.

128
00:09:10,264 --> 00:09:13,594
Hybrid approaches are under
investigation as well, where rule

129
00:09:13,614 --> 00:09:15,724
based systems are combined with AI.

130
00:09:16,649 --> 00:09:21,079
offering improved interpretability
without sacrificing performance.

131
00:09:21,579 --> 00:09:26,339
The long term vision should be to
continuously adapt to market trends

132
00:09:26,579 --> 00:09:32,279
and evolving user behaviors supported
by ongoing R& D aimed at integrating

133
00:09:32,279 --> 00:09:34,349
state of the art model architectures.

134
00:09:34,849 --> 00:09:38,649
In conclusion, Today, we have
reviewed operational breakthroughs

135
00:09:38,689 --> 00:09:40,149
in real time personalization.

136
00:09:41,049 --> 00:09:46,399
We discussed how ranking innovations,
both the rapid candidate generation in

137
00:09:46,399 --> 00:09:52,009
L1 and precision ranking in L2, work
together with latency optimizations

138
00:09:52,079 --> 00:09:55,689
and real time scalability to produce
a robust recommendation system.

139
00:09:56,189 --> 00:10:00,509
These technical improvements have
translated into measurable business

140
00:10:00,549 --> 00:10:05,059
outcomes such as improved conversion
rates, higher user engagement,

141
00:10:05,129 --> 00:10:06,519
and better customer retention.

142
00:10:07,019 --> 00:10:10,639
As we look to the future, emerging
trends and next generation

143
00:10:10,709 --> 00:10:15,069
personalization initiatives will
continue to drive our evolution.

144
00:10:15,569 --> 00:10:18,389
Finally, thank you for joining
me on this presentation.

145
00:10:18,929 --> 00:10:22,946
Feel free to connect with me on LinkedIn.

