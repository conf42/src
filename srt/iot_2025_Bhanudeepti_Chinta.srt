1
00:00:00,500 --> 00:00:01,040
Hello everyone.

2
00:00:01,550 --> 00:00:02,780
My name is Vanta.

3
00:00:03,620 --> 00:00:07,430
I'm a data engineering leader
working on large scale data platform

4
00:00:07,430 --> 00:00:11,480
across cloud analytics and machine
learning from over the last 14 years.

5
00:00:11,960 --> 00:00:17,840
Over the years, I worked in extensively
with very high volume, high velocity data

6
00:00:17,840 --> 00:00:23,720
systems, and one pattern I keep seeing
is organizations don't fail at iot.

7
00:00:23,814 --> 00:00:25,705
Because they can't collect the data.

8
00:00:26,095 --> 00:00:30,115
They struggle because the cost
and complexity of managing IO

9
00:00:30,115 --> 00:00:33,805
OT data grows faster than the
value they extract from it.

10
00:00:34,285 --> 00:00:39,805
Today I want to talk about how we can
rethink IOT data warehousing using

11
00:00:39,805 --> 00:00:43,795
modern Lake houses, architecture
and Snowflake feature stores.

12
00:00:43,974 --> 00:00:48,235
Not just to scale technically, but to
fundamentally change the cost equation.

13
00:00:48,735 --> 00:00:53,865
IOD data platforms today are under immense
pressure to do more than just scale.

14
00:00:54,315 --> 00:00:58,335
They need to scale economically
as connected devices continues

15
00:00:58,335 --> 00:01:02,055
to grow across industries like
manufacturing, transportation,

16
00:01:02,265 --> 00:01:04,185
utilities, and smart cities.

17
00:01:04,455 --> 00:01:08,745
Organizations are realizing that
traditional data architectures

18
00:01:08,955 --> 00:01:12,165
were not designed for continuous
telemetry at this scale.

19
00:01:12,570 --> 00:01:16,890
In this talk, I'll walk through the
architectural patterns and real world

20
00:01:16,890 --> 00:01:22,260
approaches that help teams reduce cost
while still enabling real time analytics,

21
00:01:22,560 --> 00:01:24,390
machine learning, and business insights.

22
00:01:24,890 --> 00:01:29,980
IOT Data Challenge iot ecosystem
generates data at an unprecedented

23
00:01:29,980 --> 00:01:34,840
scale and velocity sensors stream
telemetry continuously, often at

24
00:01:34,840 --> 00:01:36,460
millisecond intervals as we know.

25
00:01:36,850 --> 00:01:41,800
And within months, this data can reach
petabytes scale at the same time.

26
00:01:42,150 --> 00:01:45,570
This same data must support
very different consumers.

27
00:01:45,840 --> 00:01:48,210
Operation teams want
the real time dashboard.

28
00:01:48,480 --> 00:01:51,990
Data scientists need historical
data for modeling and business

29
00:01:51,990 --> 00:01:54,360
users want aggregated insights.

30
00:01:54,630 --> 00:01:59,040
Supporting all these workloads
simultaneously is where many

31
00:01:59,040 --> 00:02:01,110
iot platforms begin to stream.

32
00:02:01,610 --> 00:02:04,340
Coming to the unique
characteristics of iot data.

33
00:02:04,755 --> 00:02:09,615
What makes IOT data uniquely different
is that the combination of high

34
00:02:09,615 --> 00:02:15,465
velocity, massive volume, and constant
schema evolution device changes.

35
00:02:15,765 --> 00:02:21,285
Firmware updates introduces new fields
and different vendors produce consistently

36
00:02:21,675 --> 00:02:23,565
inconsistent telemetry formats.

37
00:02:24,065 --> 00:02:28,415
Any successful iot architecture
must handle continuous ingestion,

38
00:02:28,685 --> 00:02:32,945
adapt to all the schema changes
gracefully, and retain the large

39
00:02:32,945 --> 00:02:38,075
historical data sets without repeatedly
reprocessing or rewriting the data.

40
00:02:38,575 --> 00:02:42,745
So how are we gonna bridge the gap
by using the Lakehouse architecture?

41
00:02:43,285 --> 00:02:47,965
Traditional data warehouses deliver strong
performance and consistency, but they

42
00:02:47,965 --> 00:02:50,545
quickly become expensive and inflexible.

43
00:02:50,875 --> 00:02:53,365
Due to the semi-structured
data set of iot.

44
00:02:53,815 --> 00:02:58,255
Data lakes are cost effective, but
they lack reliability, governance

45
00:02:58,285 --> 00:02:59,965
and transactional guarantees.

46
00:03:00,355 --> 00:03:02,515
Lake house architecture bridges this gap.

47
00:03:02,820 --> 00:03:08,370
By combining the best of both worlds,
warehouse grade reliability on top of

48
00:03:08,370 --> 00:03:11,850
low cost cloud object storage for iot.

49
00:03:11,850 --> 00:03:15,630
This isn't just an architectural
improvement, it is a cost

50
00:03:15,630 --> 00:03:17,010
containment strategy.

51
00:03:17,510 --> 00:03:21,500
So coming to the core Lakehouse
Technologies, technologies like Delta,

52
00:03:21,500 --> 00:03:26,600
lake Apache Iceberg, and Apache Hudy
brings transactional, semantics,

53
00:03:26,840 --> 00:03:31,670
schema evolution, and efficient
metadata management to cloud storage.

54
00:03:32,060 --> 00:03:36,260
These capabilities are critical for iot
workloads where data is continuously

55
00:03:36,260 --> 00:03:40,160
dependent, occasionally updated,
and queried across long time ranges.

56
00:03:40,990 --> 00:03:45,550
Without these features, IOD platform
tend to accumulate hidden operational

57
00:03:45,670 --> 00:03:47,890
and storage cost over time.

58
00:03:48,550 --> 00:03:51,220
So what does the Lakehouse
physical architecture looks like?

59
00:03:51,720 --> 00:03:52,470
It has.

60
00:03:52,950 --> 00:03:58,050
It separates actually the storage
table formats and compute Cloud

61
00:03:58,110 --> 00:04:02,400
object storage provides virtually
unlimited low cost capacity.

62
00:04:02,820 --> 00:04:06,660
Table formats manage the metadata
and the transactional behavior.

63
00:04:07,080 --> 00:04:11,550
Compute engines like Spark or
Trium scale independently to

64
00:04:11,550 --> 00:04:13,350
process these heavy workloads.

65
00:04:13,710 --> 00:04:17,910
This operation is essential for
IT platforms because it allows

66
00:04:17,910 --> 00:04:19,590
the teams to scale compute.

67
00:04:19,835 --> 00:04:25,055
Only when needed, instead of paying
continuously for the fixed infrastructure.

68
00:04:25,555 --> 00:04:29,725
Coming to the architectural
considerations iot platform must be

69
00:04:29,725 --> 00:04:31,705
designed with streaming at the core.

70
00:04:32,095 --> 00:04:37,045
Data typically flows through Kafka,
Kinesis, or event hubs, and is processed

71
00:04:37,045 --> 00:04:39,565
in real time using Spark or Flink.

72
00:04:40,165 --> 00:04:44,935
Cost efficiency comes from decisions
like time-based partitioning

73
00:04:45,055 --> 00:04:47,485
aligned to IOT's, temporal nature.

74
00:04:48,215 --> 00:04:53,044
Lifecycle management across hot,
warm, and cold data layers for data

75
00:04:53,044 --> 00:04:56,525
storage, retention, and accommodating
the schema evolution without

76
00:04:56,525 --> 00:04:58,234
rewriting the historical data.

77
00:04:58,745 --> 00:05:04,174
In practice, many iot costs overrun
stems from poor decision in these

78
00:05:04,174 --> 00:05:05,945
architectural considerations.

79
00:05:06,445 --> 00:05:09,715
So the medallion architecture
is that place where all

80
00:05:09,715 --> 00:05:10,974
these issues gets resolved.

81
00:05:11,830 --> 00:05:16,090
The Meall architecture provides a
structured way to manage IOT data.

82
00:05:16,659 --> 00:05:21,940
Bronze stable captures the raw sensors
data exactly as received, preserving

83
00:05:21,969 --> 00:05:24,940
fidelity for auditing and replay.

84
00:05:25,495 --> 00:05:29,785
Silver tables apply the validation,
normalization, and standardization,

85
00:05:30,085 --> 00:05:34,615
and the gold table exposes the
business ready data set optimized

86
00:05:34,615 --> 00:05:36,445
for reporting and dashboards.

87
00:05:36,865 --> 00:05:41,575
This layered approach is very influential
because it reduces the redundant

88
00:05:41,575 --> 00:05:44,095
processing and ensures the higher cost.

89
00:05:44,095 --> 00:05:48,295
Compute is only applied
where business value exists.

90
00:05:48,795 --> 00:05:52,725
Coming to the integration, the
realtime and the batch integration

91
00:05:52,995 --> 00:05:55,005
iot platform must support both.

92
00:05:55,875 --> 00:06:00,885
And instead of maintaining separate
systems, modern architecture, increasingly

93
00:06:00,885 --> 00:06:06,435
adopted KAA style approach where a
single streaming pipeline serves both

94
00:06:06,435 --> 00:06:08,595
realtime and the batch use cases.

95
00:06:09,030 --> 00:06:13,320
Incremental processing and materialized
views reduce the operational

96
00:06:13,320 --> 00:06:17,790
complexity and significantly
lowers the long-term cost.

97
00:06:18,290 --> 00:06:21,980
Now the machine learning integration
is a place where we will be talking

98
00:06:21,980 --> 00:06:23,085
about the feature engineering.

99
00:06:23,870 --> 00:06:28,310
Machine learning is where iot data
delivers significant value, but it's

100
00:06:28,310 --> 00:06:30,650
also where cost quietly explored.

101
00:06:31,070 --> 00:06:35,270
Feature engineering often gets
duplicated across teams and pipelines.

102
00:06:35,570 --> 00:06:40,880
Snowflake features stores addresses
this by enabling reusable governed

103
00:06:40,880 --> 00:06:44,690
features that remain consistent
across training and inference.

104
00:06:45,545 --> 00:06:49,955
This reduces the compute cost,
improves the model reliability, and

105
00:06:49,955 --> 00:06:52,025
accelerates the experimentation.

106
00:06:52,685 --> 00:06:57,035
There are a few case studies that I have
included in here, which are directly

107
00:06:57,035 --> 00:06:59,000
ties up with the scalable architecture.

108
00:06:59,500 --> 00:07:03,820
In manufacturing environments, IO ot,
Lakehouse architecture enables the

109
00:07:03,820 --> 00:07:09,099
predictive maintenance by analyzing sensor
telemetry for early failure signals.

110
00:07:09,429 --> 00:07:13,450
Instead of reacting to equipment
breakdowns, organizations can

111
00:07:13,450 --> 00:07:15,159
plan maintenance proactively.

112
00:07:15,520 --> 00:07:19,869
This reduces the downtime, avoid
emergency repairs, and leads to

113
00:07:19,869 --> 00:07:21,580
measurable operational savings.

114
00:07:22,080 --> 00:07:26,150
Another case study which adds which
supports, this is the connected

115
00:07:26,150 --> 00:07:29,929
vehicle fleet optimization
for connected vehicle fleets.

116
00:07:30,020 --> 00:07:34,549
A real-time telemetry supports the
route optimization as we know driver

117
00:07:34,549 --> 00:07:38,330
behavior scoring, vehicle health
monitoring, and demand prediction.

118
00:07:39,234 --> 00:07:45,200
These insights directly improve safety,
efficiency and utilization while reducing

119
00:07:45,200 --> 00:07:47,689
fuel cost and unplanned downtime.

120
00:07:48,189 --> 00:07:52,659
The smart city infrastructure is
another strong case where the data

121
00:07:52,659 --> 00:07:56,979
is used to optimize the traffic flow,
monitor the environmental conditions,

122
00:07:57,249 --> 00:07:59,529
and enable the open data initiatives.

123
00:07:59,829 --> 00:08:04,569
A unified Lakehouse platform allows
governments to manage diverse data

124
00:08:04,569 --> 00:08:09,729
sources and schemas while maintaining the
governance, reliability and cost control.

125
00:08:10,229 --> 00:08:13,379
Utility meter analytics is
another beautiful case study.

126
00:08:13,799 --> 00:08:15,869
It prob, it ingests in, sorry.

127
00:08:15,899 --> 00:08:21,389
It ingests the smart meter from
data from millions of households.

128
00:08:21,389 --> 00:08:27,004
As we know, Lakehouse platforms handle
schema heterogeneity, compress the time

129
00:08:27,004 --> 00:08:33,359
series data, and enable advanced analytics
such as energy theft detection, peak

130
00:08:33,359 --> 00:08:36,179
demand forecasting, and grid optimization.

131
00:08:36,554 --> 00:08:39,464
All while keeping
infrastructure cost manageable.

132
00:08:39,964 --> 00:08:45,274
Looking ahead, iot data platforms
will evolve towards lower latency

133
00:08:45,274 --> 00:08:50,554
streaming warehouse class, time series
performance, stronger governance and

134
00:08:50,554 --> 00:08:54,604
edge analytics that reduce bandwidth
and centralized processing cost.

135
00:08:54,994 --> 00:09:00,664
The most successful platforms will be
those that are not just data aware, but

136
00:09:00,694 --> 00:09:04,084
cost aware by design as well to close.

137
00:09:04,939 --> 00:09:09,529
Iot success is not about collecting
more data, it's about designing

138
00:09:09,529 --> 00:09:14,089
systems that align cost with
value When built correctly.

139
00:09:14,419 --> 00:09:16,859
Iot data platform don't just scale.

140
00:09:17,549 --> 00:09:21,809
They become sustainable strategic
assets that power realtime

141
00:09:21,809 --> 00:09:24,059
decisions and long-term innovations.

142
00:09:24,509 --> 00:09:28,074
Thank you, and I'm open to
take any questions you have.

