1
00:00:00,500 --> 00:00:01,490
Hello everybody.

2
00:00:01,670 --> 00:00:03,689
A warm welcome to you all
to this conference 42.

3
00:00:04,189 --> 00:00:05,600
JavaScript 2025.

4
00:00:05,779 --> 00:00:08,329
It's my real pleasure to
be here with you today.

5
00:00:08,780 --> 00:00:13,759
I'm here to talk about using AI to
have a smart rate limited system,

6
00:00:13,759 --> 00:00:18,410
which is not as scalable, and it
can be cost efficient as well.

7
00:00:18,590 --> 00:00:20,810
It is going to be cost efficient as well.

8
00:00:21,439 --> 00:00:23,029
Let me ask you a question.

9
00:00:23,330 --> 00:00:28,069
How many of you were here when
building an API real reach out for rate

10
00:00:28,069 --> 00:00:30,264
limiting as your first line of defense?

11
00:00:30,765 --> 00:00:31,545
All of us, right?

12
00:00:31,545 --> 00:00:32,475
Almost all of us.

13
00:00:32,865 --> 00:00:34,785
It's a fundamental practice.

14
00:00:35,115 --> 00:00:40,275
We use it to protect our systems
from abuse, ensure stability, manage

15
00:00:40,275 --> 00:00:45,155
cost, and prevent any denial of
service attacks as anything that

16
00:00:45,365 --> 00:00:46,355
is important, attracts thieves.

17
00:00:46,855 --> 00:00:52,435
As we also know that as APIs become
more important, they attract users with

18
00:00:52,435 --> 00:00:57,775
malicious intent to either steal the
data or cut down the incoming business.

19
00:00:58,435 --> 00:01:02,935
But here's the critical challenge
we face now, is that attackers have

20
00:01:02,935 --> 00:01:07,405
become more smart and the threats
have become more, have evolved

21
00:01:07,735 --> 00:01:09,325
and become more sophisticated.

22
00:01:09,805 --> 00:01:12,835
But a primary defense mechanism has not.

23
00:01:13,660 --> 00:01:18,759
We are relying on a traditional
starting rate limited system in a

24
00:01:18,759 --> 00:01:21,400
dynamic, intelligent world of attacks.

25
00:01:21,670 --> 00:01:26,380
This isn't a failure of concept,
but rather missing evolution

26
00:01:26,470 --> 00:01:28,360
In par with the threats.

27
00:01:28,930 --> 00:01:32,200
Today we are going to explore why
these traditional methods are no

28
00:01:32,230 --> 00:01:38,050
longer sufficient, how they are
actively costing companies millions

29
00:01:38,050 --> 00:01:40,390
and still damaging user experience.

30
00:01:41,005 --> 00:01:43,345
All while creating a
false sense of security.

31
00:01:44,335 --> 00:01:48,505
Most importantly, we are going
to discuss a new path forward.

32
00:01:48,925 --> 00:01:54,575
The one that is meant to form a essential
tool rate limiting is an with artificial

33
00:01:54,575 --> 00:02:00,575
intelligence to build APIs that are
not just secure, but also remarkably

34
00:02:00,575 --> 00:02:03,515
scalable and crucially cost efficient.

35
00:02:03,905 --> 00:02:03,935
Okay.

36
00:02:04,435 --> 00:02:07,705
With that said, let me
move on to the next slide.

37
00:02:08,365 --> 00:02:11,965
Let's begin with the fundamental
truth of the current situation, right?

38
00:02:12,325 --> 00:02:16,945
The API forms the heart of the modern
web world, the, they power and touch

39
00:02:16,945 --> 00:02:22,585
multiple aspects of our life, like iot
devices, whether we use our mobile phones

40
00:02:22,585 --> 00:02:25,525
and applications shopping and much more.

41
00:02:25,825 --> 00:02:30,265
But this is critical infrastructure,
but this critical infrastructure.

42
00:02:30,865 --> 00:02:37,015
Mostly is protected by static rate
limiting a defense strategy that

43
00:02:37,015 --> 00:02:40,735
in terms of age, it might look like
an ancient fossil when compared to

44
00:02:40,825 --> 00:02:42,955
current sophisticated cyber attacks.

45
00:02:42,985 --> 00:02:50,965
Actually, the idea of static rate limiting
is by setting a fixed threshold, like

46
00:02:50,965 --> 00:02:57,715
500 requests per minute per user does not
work or prevent attacks anymore because.

47
00:02:58,120 --> 00:03:04,130
Let's be honest, people have become
smart and so have those cyber attackers.

48
00:03:04,630 --> 00:03:10,810
With that said, one of on the
one hand, it is set to limit too

49
00:03:10,810 --> 00:03:14,440
low to protect against attacks.

50
00:03:14,940 --> 00:03:17,570
Okay, let me talk about this.

51
00:03:18,070 --> 00:03:24,250
In one hand, if you set it to too low
the to protect against attacks, you

52
00:03:24,250 --> 00:03:26,590
end up blocking your best customers.

53
00:03:26,920 --> 00:03:34,790
Imagine a scenario like where loyal users
flee face a or during a flash sale face.

54
00:03:34,899 --> 00:03:37,359
Issues with being able to access the.

55
00:03:38,184 --> 00:03:41,664
Portal that they are
trying, because guess what?

56
00:03:41,694 --> 00:03:43,524
They got the error.

57
00:03:43,765 --> 00:03:46,765
4 29. Too many re requests error.

58
00:03:47,274 --> 00:03:54,624
The data shows that these instances
aren't rail on an average 41% of

59
00:03:54,774 --> 00:04:00,449
estimate traffic gets blocked by overly
aggressive static rate limiting rules.

60
00:04:00,949 --> 00:04:05,899
But on the other hand, if you set
the limit too high to avoid blocking

61
00:04:05,899 --> 00:04:11,720
users, you might be actually opening
the flood gates to abuse and misuse

62
00:04:12,170 --> 00:04:16,340
the infrastructure costs might
spiral out of budget and become more

63
00:04:16,370 --> 00:04:18,529
inefficient, and you are left with.

64
00:04:19,495 --> 00:04:24,655
Left to be with the system, which
is vulnerable to very attacks.

65
00:04:24,684 --> 00:04:26,515
You were meant to stop to begin with.

66
00:04:27,414 --> 00:04:29,005
This isn't just an inconvenience.

67
00:04:29,005 --> 00:04:34,074
This is the direct hit to the bottom
line, leading to millions in cost,

68
00:04:34,074 --> 00:04:40,615
revenue, and wasted cloud spent opening
path for sophisticated hackers to get in.

69
00:04:41,299 --> 00:04:45,110
The core of the problem is that
static thresholds are blind.

70
00:04:45,439 --> 00:04:49,520
They are not intelligent, are flexible
enough to adapt to the changing

71
00:04:49,520 --> 00:04:53,120
scenarios, or rather the changing context.

72
00:04:53,620 --> 00:04:59,080
Let's diagnose the illness in the
current context the static rate limiting.

73
00:05:00,040 --> 00:05:05,050
Why is this 30-year-old
paradigm failing us in 2025?

74
00:05:05,550 --> 00:05:08,430
It boils down to three critical flaws.

75
00:05:08,460 --> 00:05:11,070
First, the rigid thresholds.

76
00:05:11,159 --> 00:05:16,109
A fixed limit cannot distinguish
between the good attack traffic

77
00:05:16,109 --> 00:05:21,490
spike or actual attack and a good
traffic spike and a successful product

78
00:05:21,490 --> 00:05:26,980
launch going viral on Hacker News
looks identical to DDoS attacks from

79
00:05:26,980 --> 00:05:32,140
static rate, limiter point of view,
reasons being both generate a massive.

80
00:05:32,640 --> 00:05:34,140
Search in traffic.

81
00:05:34,380 --> 00:05:35,969
One in your dream.

82
00:05:35,969 --> 00:05:39,300
One is the dream scenario and
other one is your nightmare.

83
00:05:40,170 --> 00:05:41,500
Second com.

84
00:05:41,560 --> 00:05:43,780
A complete lack of context awareness.

85
00:05:43,780 --> 00:05:48,670
Static rules ignore everything
that makes a user who they are.

86
00:05:49,150 --> 00:05:53,430
They don't care if the user has
authenticated successfully from the

87
00:05:53,430 --> 00:05:57,955
past two years being able to connect
it using their office network.

88
00:05:58,320 --> 00:06:00,510
They don't care if the traffic is flowing.

89
00:06:00,510 --> 00:06:04,469
A logical sequence of APIs like
getting the products, viewing the

90
00:06:04,469 --> 00:06:05,675
products, and adding to the cart.

91
00:06:06,175 --> 00:06:10,915
Under a static, non-intelligent
system, this legitimate users looks

92
00:06:10,915 --> 00:06:15,645
like a scripted adapter from a
data center in a foreign country

93
00:06:15,795 --> 00:06:18,645
hammering your login endpoint.

94
00:06:19,425 --> 00:06:24,570
And third, the result of this
flaws which are, which is nothing

95
00:06:24,590 --> 00:06:26,715
but a sky high operational cost.

96
00:06:27,330 --> 00:06:31,410
Because companies can't trust
relate limiters to peace smartt.

97
00:06:31,890 --> 00:06:34,890
They are forced to over
provision infrastructure.

98
00:06:34,890 --> 00:06:40,710
They pay for enough servers, database
capacity, and cloud resources to

99
00:06:40,710 --> 00:06:47,520
handle worse DOS scenario, even though
99% of the times those resources.

100
00:06:47,925 --> 00:06:50,445
Sit idle burning money.

101
00:06:51,135 --> 00:06:56,025
Even if the scaling is dynamic
on the backend, it is very likely

102
00:06:56,025 --> 00:07:01,875
the system scales to cater to a
coordinated attack, not only responding

103
00:07:01,875 --> 00:07:05,770
to attack, but also adding to the
computational cost of the system.

104
00:07:06,270 --> 00:07:12,205
And these are the three traditional
rate limiting fails Now.

105
00:07:12,705 --> 00:07:20,205
I want to zoom in into most real,
potent, modern day threat that exploits

106
00:07:20,415 --> 00:07:27,320
these weaknesses, which is distributed
denial of attack or rather DDoS.

107
00:07:27,620 --> 00:07:32,870
When many of us think DDoS, we imagine
a more massive high volume nurse attack,

108
00:07:32,930 --> 00:07:39,260
which is like a tidal wave of traffic that
crashes cause failures on the servers.

109
00:07:39,260 --> 00:07:45,500
But this is, this landscape has changed
on world today, the most insidious

110
00:07:45,560 --> 00:07:51,320
and common attacks are low and slow
application layered DDoS attacks.

111
00:07:51,820 --> 00:07:55,330
These attacks, don't try to
bring down your front door with

112
00:07:55,330 --> 00:07:57,580
raw power as the name suggests.

113
00:07:57,760 --> 00:07:59,560
Denial of that is denial of service.

114
00:07:59,890 --> 00:08:02,560
Instead, they pick the
lock of the front door.

115
00:08:02,740 --> 00:08:07,100
They target your API endpoints
directly like your login,

116
00:08:07,100 --> 00:08:08,870
your search, or your checkout.

117
00:08:09,500 --> 00:08:14,270
And that is the most expensive past
part of your application to run.

118
00:08:14,870 --> 00:08:18,770
And here's the most genius and most
terrifying part of these attacks.

119
00:08:19,400 --> 00:08:21,980
They are designed to be stealth steal.

120
00:08:22,700 --> 00:08:28,520
It is not like a lock picking in, it's
like a lock picking in invisible thief.

121
00:08:29,180 --> 00:08:35,120
A botnet of thousands of compromised
devices will send few requests per minute.

122
00:08:35,120 --> 00:08:39,800
Staying carefully just below
your static rate limit, so as

123
00:08:39,800 --> 00:08:42,200
not to get caught individually.

124
00:08:42,200 --> 00:08:47,150
Each IP address looks like slightly
active, but less make user, which

125
00:08:47,150 --> 00:08:48,590
is not bombarding the setup.

126
00:08:48,985 --> 00:08:53,725
But collectively, they consume all of
your database connections, exhaust your

127
00:08:53,725 --> 00:09:01,195
server CPU, and can rake up massive
cloud compute bills all while your

128
00:09:01,195 --> 00:09:06,505
basically rate limiter gives them
a green light as they look legit.

129
00:09:07,195 --> 00:09:11,965
This is the ultimate demonstration
of why counting requests is no

130
00:09:11,965 --> 00:09:14,390
longer enough to prevent DDoS attack.

131
00:09:15,380 --> 00:09:19,520
We need to understand their behavior
and come up with a solution that

132
00:09:19,520 --> 00:09:21,620
handles such sneaky attacks.

133
00:09:22,120 --> 00:09:26,350
Let's talk about the answer for
this insidious situation, right?

134
00:09:26,740 --> 00:09:31,600
We need to replace a static
blindfolded rate limiter with

135
00:09:31,600 --> 00:09:33,610
a dynamic intelligent one.

136
00:09:33,870 --> 00:09:38,130
We need to move from simply counting
rate limiter to the one which

137
00:09:38,130 --> 00:09:43,500
truly understands the situation
and takes decisions dynamically.

138
00:09:43,500 --> 00:09:48,750
So as to who should be allowed
access to the APIs, this is where we

139
00:09:48,750 --> 00:09:53,135
introduce the AI powered framework
instead of single number, our system

140
00:09:53,335 --> 00:09:58,015
analyzes a rich mashup of 27 different.

141
00:09:58,770 --> 00:10:01,050
Behavioral features in real time.

142
00:10:01,500 --> 00:10:04,470
It just doesn't look at
the number of requests.

143
00:10:04,470 --> 00:10:07,230
It tries to understand what is
the pattern of this request?

144
00:10:07,350 --> 00:10:08,760
Who is making them?

145
00:10:08,760 --> 00:10:09,870
What is their intent?

146
00:10:09,870 --> 00:10:15,450
What is the sequence of requests
from each single user trying to do?

147
00:10:16,170 --> 00:10:20,970
By understanding these patterns, the
smart setup can dynamically adapt.

148
00:10:21,525 --> 00:10:26,535
It can confidently allow a surge
of LE legitimate users during a

149
00:10:26,535 --> 00:10:33,020
marketing campaign while identifying
and throttling a sophisticated DDoS.

150
00:10:33,735 --> 00:10:35,565
Attacks happening parallelly.

151
00:10:36,255 --> 00:10:41,865
It provides robust security without
sacrificing the user experience

152
00:10:42,285 --> 00:10:43,995
and the business's bottom line.

153
00:10:44,055 --> 00:10:50,025
All while keeping reputation, cost, and
data security intact and in and checking

154
00:10:50,145 --> 00:10:52,335
and keeping the attackers in check.

155
00:10:52,835 --> 00:10:54,215
Now, since.

156
00:10:54,715 --> 00:11:00,765
Since the smart system does so
much effectively and tactfully, you

157
00:11:00,765 --> 00:11:05,355
might be thinking, oh, this smart
system sounds complex, but the

158
00:11:05,835 --> 00:11:12,315
smarty process can be broken down
into clean four step cycle, which is

159
00:11:12,315 --> 00:11:14,630
collect, engineer, train, and deploy.

160
00:11:15,130 --> 00:11:19,470
Now, let me talk about
collecting the right data.

161
00:11:20,130 --> 00:11:21,495
It all starts with the data.

162
00:11:21,995 --> 00:11:29,015
The principle of garbage in garbage, how
out has never proven to be more true.

163
00:11:29,465 --> 00:11:33,755
We are not just collecting logs,
we are gathering the digital DNA

164
00:11:33,755 --> 00:11:36,425
markers of each API interaction.

165
00:11:37,415 --> 00:11:41,965
We instrument our API gateways
and load balancer to capture a

166
00:11:41,965 --> 00:11:49,015
rich tapestry of over 14 criteria
data points data, DNS markers.

167
00:11:49,815 --> 00:11:56,425
Which we group into several key
categories, in the category of request

168
00:11:56,455 --> 00:12:02,215
metadata and patterns, which is one of
the most important ones we capture the

169
00:12:02,215 --> 00:12:08,570
velocity and the rhythm of requests, for
example, is we, let's talk about frequency

170
00:12:08,570 --> 00:12:13,490
and burst patterns, which actually
tries to see if the traffic study.

171
00:12:14,355 --> 00:12:20,835
Stream or is actually a steady stream or
a burst of violent machine gun, like bus

172
00:12:21,105 --> 00:12:26,915
and human browsing website has natural
pauses, whereas a script does not.

173
00:12:27,415 --> 00:12:33,505
Another example of request
metadata and patterns category is

174
00:12:34,015 --> 00:12:36,865
timing and inter request delays.

175
00:12:37,225 --> 00:12:39,625
We measure the milliseconds between calls.

176
00:12:39,940 --> 00:12:44,200
Real users have variable
delays between the requests.

177
00:12:44,470 --> 00:12:50,860
However, the automated attacks often
operate with metronomic time differences,

178
00:12:50,920 --> 00:12:53,620
which are humanly impossible.

179
00:12:54,120 --> 00:13:00,570
Another category that we measure is
sequential data and behavioral intent.

180
00:13:01,230 --> 00:13:06,780
This is where we start to understand the
intent of the API call being done One.

181
00:13:07,725 --> 00:13:11,895
Parameter we use to understand
this is endpoint access sequences.

182
00:13:12,525 --> 00:13:16,515
What we do here is track the journey
and not just a single request.

183
00:13:16,545 --> 00:13:21,525
A SML users might follow a logical
path of finding the products,

184
00:13:21,525 --> 00:13:25,955
selecting the products, and actually
then viewing, continue to viewing

185
00:13:25,955 --> 00:13:27,755
the same and adding it to the cart.

186
00:13:28,415 --> 00:13:31,925
An attacker who actually does not
have intent of ordering and buying

187
00:13:31,925 --> 00:13:34,475
products might just be hammer a single.

188
00:13:34,925 --> 00:13:39,455
Endpoint like login or pro random
endpoints like search or export

189
00:13:39,455 --> 00:13:41,495
in a quick suce succession.

190
00:13:42,125 --> 00:13:47,365
This sequence of API calls and
even the missing API calls,

191
00:13:47,665 --> 00:13:50,035
tells a story about the intent.

192
00:13:50,535 --> 00:13:54,555
Another parameter that we use in
this category is action outcomes.

193
00:13:55,275 --> 00:13:58,545
In this, we just don't look at
the requests, but also look at

194
00:13:58,545 --> 00:14:00,345
what happened after the request.

195
00:14:00,765 --> 00:14:02,041
A series of HTTP.

196
00:14:02,910 --> 00:14:03,300
Four.

197
00:14:03,300 --> 00:14:04,560
Oh 4 0 4.

198
00:14:04,590 --> 00:14:05,790
Not found errors.

199
00:14:05,820 --> 00:14:11,400
Might indicate a scanner, A rapid
sequence of http 4 0 1 unauthorized,

200
00:14:11,400 --> 00:14:13,620
followed by a single 200.

201
00:14:13,620 --> 00:14:14,130
Okay.

202
00:14:14,430 --> 00:14:18,480
Could be a credential
stuffing attack in progress.

203
00:14:18,980 --> 00:14:25,660
Let's look at another category here, which
is authentication and session context.

204
00:14:26,530 --> 00:14:27,130
In this.

205
00:14:28,104 --> 00:14:31,224
This layer adds identity to the behavior.

206
00:14:31,584 --> 00:14:37,215
For example, talking about login success
and failure rates, a single, a couple of

207
00:14:37,215 --> 00:14:43,335
failures during log user login is actually
very normal, 20 failures in a minute from

208
00:14:43,335 --> 00:14:50,295
the same IP or IP subnet, even if the API
calls are below the static rate limit.

209
00:14:50,745 --> 00:14:54,615
Is a different story altogether
and is a huge red flag.

210
00:14:55,335 --> 00:15:01,635
Another example to talk about in this
category is session token usage, or

211
00:15:01,635 --> 00:15:06,135
few questions to check around session
R. How is the session being used?

212
00:15:06,495 --> 00:15:13,485
Is it a newly created token immediately
making high value transactions?

213
00:15:13,780 --> 00:15:18,375
Basically, if a newly created
token that is just generated.

214
00:15:19,080 --> 00:15:25,200
Is suddenly very active is a token
from one geographic location suddenly

215
00:15:25,200 --> 00:15:27,990
being used from another an hour later.

216
00:15:28,830 --> 00:15:33,090
These form critical trust
signals, which may point to leaked

217
00:15:33,090 --> 00:15:35,310
passwords or even bigger problems.

218
00:15:35,810 --> 00:15:40,880
The next category we'll be
talking about will be system

219
00:15:40,880 --> 00:15:42,375
health and resource consumption.

220
00:15:42,875 --> 00:15:46,805
Here we listen to what the
API itself is telling us.

221
00:15:47,015 --> 00:15:52,834
Example of example here would be like
the API response time and the error

222
00:15:52,834 --> 00:15:58,574
rates or DDoS attacks or resource
intensive scraping bot will often

223
00:15:59,265 --> 00:16:05,624
cause elevated response times and a
spike in 500 series server errors on

224
00:16:05,624 --> 00:16:07,364
the endpoints that they're targeting.

225
00:16:07,965 --> 00:16:11,654
This resource intensive
scrapping is a crucial symptom.

226
00:16:12,074 --> 00:16:17,925
Of sophisticated attack that a
static rate limit is completely miss.

227
00:16:18,885 --> 00:16:25,064
The last, but not the least category we
will talk about is the contextual signals.

228
00:16:25,965 --> 00:16:30,105
Here, what we are looking for here
would be the who and the from.

229
00:16:30,675 --> 00:16:34,275
We use the geographical location
and network resource and find

230
00:16:34,275 --> 00:16:35,535
answer to questions like.

231
00:16:36,344 --> 00:16:39,735
Is the user who not money logs
in from London, suddenly making

232
00:16:39,735 --> 00:16:43,485
requests from a data center in
different country, or it is a bot.

233
00:16:44,174 --> 00:16:50,624
We correlate with IP reputation
scores and known VPN proxy networks to

234
00:16:50,624 --> 00:16:52,755
verify the validity of the requests.

235
00:16:53,265 --> 00:16:57,674
We also use device fingerprint
and user agent to understand the

236
00:16:57,674 --> 00:17:00,015
context answers to question like.

237
00:17:00,515 --> 00:17:05,255
A request coming from standard
browser with a con with a consistent

238
00:17:05,255 --> 00:17:09,485
set of headers or a headless client
with a suspicious or a missing

239
00:17:09,485 --> 00:17:14,675
user agent helps us identify
trustworthiness of their request.

240
00:17:15,574 --> 00:17:18,244
This rich, multidimensional data.

241
00:17:18,889 --> 00:17:24,139
Forms the rich material, it forms the
foundation that our system can begin

242
00:17:24,139 --> 00:17:30,080
to extrapolate the subtle nuances
that differentiate between the real

243
00:17:30,080 --> 00:17:32,719
user and that from the Han attacker.

244
00:17:33,219 --> 00:17:38,069
Now moving on till now we have just
been talking about the data and

245
00:17:38,069 --> 00:17:39,749
which is just the list of facts.

246
00:17:40,709 --> 00:17:43,229
Now step two would be engineer in.

247
00:17:43,729 --> 00:17:49,159
Which is the art of and science of
transforming these facts into meaningful,

248
00:17:49,519 --> 00:17:52,370
insightful trends, setting signals.

249
00:17:52,429 --> 00:17:59,059
And these signals are the features
our AI model will actually understand.

250
00:17:59,929 --> 00:18:01,039
Think of it as this way.

251
00:18:01,069 --> 00:18:04,209
Roll logs are useless to a
machine learn learning model.

252
00:18:04,629 --> 00:18:09,189
We must teach it, teach the
language of behavior, understanding.

253
00:18:10,074 --> 00:18:11,034
From the loss.

254
00:18:11,514 --> 00:18:18,324
This is where we create a med layer of
27 separate behaviors, which we group

255
00:18:18,324 --> 00:18:24,324
into four powerful categories and help
analyze that, help analyze and infer the

256
00:18:24,324 --> 00:18:28,194
complete story of the actual API requests.

257
00:18:28,674 --> 00:18:33,504
Let's break down these categories with
concrete examples of what we built.

258
00:18:34,374 --> 00:18:35,814
The first category is.

259
00:18:36,324 --> 00:18:40,945
Temporal patterns that gives
us the rhythm of crust in this.

260
00:18:40,945 --> 00:18:42,834
First, we analyze time.

261
00:18:43,254 --> 00:18:47,125
We move beyond a simple count to
understand the pattern of requests.

262
00:18:47,485 --> 00:18:52,615
We create features like request per
second volatility and collect data on it.

263
00:18:53,095 --> 00:18:55,135
This is a statistical variance.

264
00:18:55,855 --> 00:19:00,145
In the customer request rate, humans
are volatile and unpredictable,

265
00:19:00,205 --> 00:19:04,615
whereas bots are often metronomically
consistent and persistent.

266
00:19:05,575 --> 00:19:11,245
We also calculate a burst score
to identify short, high intensity

267
00:19:11,245 --> 00:19:17,185
explosions of traffic that haul
marks of automated, that forms the

268
00:19:17,185 --> 00:19:19,465
hallmarks of automated scripts.

269
00:19:20,245 --> 00:19:23,605
We even look at time of the day anomalies.

270
00:19:23,664 --> 00:19:28,134
Where we identify if the requests
are happening at the rec user's,

271
00:19:28,134 --> 00:19:34,254
typical time on, on the time zone or
at 3:00 AM in a different time zone

272
00:19:34,254 --> 00:19:37,734
altogether, gather from a location
that they have never been to.

273
00:19:38,234 --> 00:19:41,204
The goal is to answer a critical question.

274
00:19:41,474 --> 00:19:46,364
Is the traffic coming in smooth,
human-like rhythm, or a throttling,

275
00:19:46,424 --> 00:19:49,784
robotic, consistent bus, even if they're.

276
00:19:50,384 --> 00:19:51,495
Smaller parts.

277
00:19:52,334 --> 00:19:57,465
Another category that we need to
talk about is access behavior.

278
00:19:57,584 --> 00:19:59,715
That gives us the narrative of intent.

279
00:20:00,195 --> 00:20:04,094
Here we analyze what is being
accessed and how this is about

280
00:20:04,094 --> 00:20:05,985
understanding the user's point of view.

281
00:20:06,614 --> 00:20:10,790
Here we calculate the endpoint entropy,
a measure of randomness in the api.

282
00:20:11,580 --> 00:20:13,229
Endpoints being accessed.

283
00:20:13,530 --> 00:20:18,570
A real user has low entropy
following a predictable path like

284
00:20:18,570 --> 00:20:23,070
home search and product page,
and possibly adding to the cart.

285
00:20:23,969 --> 00:20:29,340
Whereas a scanner has high entropy,
high disorder list like jumping randomly

286
00:20:29,340 --> 00:20:36,149
between different APIs, login, admin,
export, or even search using continuous.

287
00:20:36,569 --> 00:20:41,720
Our using continuous search APIs
with multitude of inputs and not

288
00:20:41,720 --> 00:20:47,419
using the other routine kind of
APIs, which an end user uses.

289
00:20:47,919 --> 00:20:51,579
We also create a suspicious sequence
flag that triggers that the user's

290
00:20:51,579 --> 00:20:53,949
parts matches a known malicious pattern.

291
00:20:54,489 --> 00:20:59,110
These patterns are based on industry
or sector wise, or data scan,

292
00:20:59,110 --> 00:21:03,939
realize patterns identified and
updated on a law ongoing basis.

293
00:21:04,329 --> 00:21:08,079
An example of this is accessing a
login endpoint immediately after

294
00:21:08,079 --> 00:21:13,989
trying to hit a sensitive data
export endpoint or immediately

295
00:21:13,989 --> 00:21:16,659
accessing a search endpoint after.

296
00:21:17,384 --> 00:21:21,404
Oh, search and an export
in the previous call.

297
00:21:22,094 --> 00:21:27,854
The insight we are engineering here is
to identify and realize that the user is

298
00:21:27,975 --> 00:21:33,915
browsing a diver set of endpoints like
a human, or they're laser focused on a

299
00:21:33,915 --> 00:21:39,830
simple, extensive APIs in the illogical
and unhuman like sequence and speed.

300
00:21:40,330 --> 00:21:43,010
The speed is not calculated
here, but you get the point.

301
00:21:43,699 --> 00:21:48,560
The next category we will talk
about is network signal that help us

302
00:21:48,560 --> 00:21:51,439
understand the context of connection.

303
00:21:51,860 --> 00:21:54,320
Here we look at the origin of the request.

304
00:21:54,350 --> 00:21:55,730
The network doesn't lie.

305
00:21:56,389 --> 00:22:01,040
We build a geographically impossible
score, calculating the physical

306
00:22:01,040 --> 00:22:07,100
possibility of a user moving from New York
to London between two subsequent requests.

307
00:22:07,730 --> 00:22:09,260
This is a massive red flag.

308
00:22:09,760 --> 00:22:15,429
We incorporate realtime IP reputation
scores from threat intelligence feeds and

309
00:22:15,429 --> 00:22:20,370
calculators source an anal anomaly index.

310
00:22:21,090 --> 00:22:26,100
A measure of how unusual the
user's networks source is

311
00:22:26,100 --> 00:22:30,939
compared to their history and
their general use base user base.

312
00:22:31,735 --> 00:22:36,895
This category is also incorporating
external context and looking for

313
00:22:36,895 --> 00:22:44,004
geographic and infrastructural anomalies
that static systems completely ignore.

314
00:22:44,754 --> 00:22:48,534
Last category that we have to talk
about is the user context, the

315
00:22:48,590 --> 00:22:52,465
and the, basically that highlights
the power of the baseline.

316
00:22:53,304 --> 00:22:56,450
Finally, and most powerfully, we analyze.

317
00:22:57,355 --> 00:22:58,075
Identity.

318
00:22:58,525 --> 00:23:01,255
We don't treat every user as a stranger.

319
00:23:01,585 --> 00:23:06,145
We derive a session confidence score
based on the age of the session, the

320
00:23:06,145 --> 00:23:11,725
diversity of action taken, and its
geographical geographic stability.

321
00:23:12,445 --> 00:23:16,375
We calculate fail login
velocity, but we normalize it

322
00:23:16,375 --> 00:23:18,385
by the user's historical basis.

323
00:23:18,895 --> 00:23:24,565
A user who never fails a login
certainly fails 2020 times.

324
00:23:24,955 --> 00:23:31,195
In a minute or two is a much bigger
alert than a known clumsy typist who

325
00:23:31,195 --> 00:23:36,985
might make unsuccessful attempts, or
someone like me who forgets password

326
00:23:36,985 --> 00:23:41,764
soft one and takes time to remember
and has failed logins, but that would

327
00:23:41,764 --> 00:23:46,325
be based on the historical PA pattern
that this uses, has such issues.

328
00:23:46,825 --> 00:23:50,035
This is the crown jewel of
all the features so far.

329
00:23:50,350 --> 00:23:56,290
We are continuously asking here about
if and how's this current session

330
00:23:56,290 --> 00:23:59,200
compared to the user's 90 day baseline?

331
00:23:59,710 --> 00:24:03,700
Has their behavior ly
and suspiciously changed?

332
00:24:04,200 --> 00:24:10,320
Now with the 27 powerful behavioral
features, data stats, ready, we

333
00:24:10,320 --> 00:24:13,189
move to then step three train.

334
00:24:13,669 --> 00:24:14,780
This is very.

335
00:24:15,070 --> 00:24:16,060
Important step.

336
00:24:16,090 --> 00:24:20,379
This is where we build the intelligent
brain of the entire system.

337
00:24:20,500 --> 00:24:23,560
We use a detection tree ensemble model.

338
00:24:24,070 --> 00:24:28,360
We can think this, we can think of
this as a committee of many simple

339
00:24:28,389 --> 00:24:33,189
interpretable subject matter experts,
more relevant to their own feature.

340
00:24:33,699 --> 00:24:36,669
Sit together, these experts
work together to make.

341
00:24:37,314 --> 00:24:40,135
Highly accurate and robust decision.

342
00:24:40,584 --> 00:24:45,205
We specifically use a combination of
random forest for robust generalized

343
00:24:45,205 --> 00:24:52,014
classification and gradient boosting for
precision tuning on difficult edge cases.

344
00:24:52,764 --> 00:24:55,915
Now, you might be wondering
what this terms mean.

345
00:24:55,975 --> 00:24:56,274
Don't worry.

346
00:24:56,889 --> 00:24:59,980
You don't need a data science
degree to get to the core idea.

347
00:25:00,340 --> 00:25:03,070
Let me explain them here first.

348
00:25:03,070 --> 00:25:07,040
We we ha we have what we'll call the
committee of expert or specialist.

349
00:25:07,370 --> 00:25:11,990
Imagine we had 10 different security
experts, or rather a hundred different

350
00:25:11,990 --> 00:25:16,730
security experts, and each one of them
is a specialist in a different area.

351
00:25:17,210 --> 00:25:21,200
This is our random forest, and we don't
give them all the same information.

352
00:25:21,200 --> 00:25:25,705
One expert, one expert only looks
at the timing and rhythm of request.

353
00:25:26,205 --> 00:25:30,074
List to check if it's smooth,
flow or robotic burst.

354
00:25:30,345 --> 00:25:35,085
Another expert only focuses on geographic
location, like looking at things like

355
00:25:35,445 --> 00:25:39,585
login patterns to identify that it's
a login from London just two minutes

356
00:25:39,585 --> 00:25:42,044
after logging from New York and so on.

357
00:25:42,435 --> 00:25:47,415
The third specializes in the sequence
of pages or the API visits the

358
00:25:47,415 --> 00:25:52,435
U user basically to fit whether
it's looks like a natural browsing

359
00:25:52,435 --> 00:25:54,415
journey or a random, suspicious.

360
00:25:54,730 --> 00:26:00,700
Scan another one could only analyze
the user's past behavior in this.

361
00:26:00,760 --> 00:26:05,340
Is this action normal or abnormal
for this user, we give each expert

362
00:26:05,340 --> 00:26:09,750
a slightly different view of the
request focusing or which where they

363
00:26:09,750 --> 00:26:11,520
need to focus on their specialty.

364
00:26:12,270 --> 00:26:14,645
We ask them all the same question.

365
00:26:15,064 --> 00:26:17,135
Does this look like an attack?

366
00:26:17,675 --> 00:26:21,995
Each expert makes their own decision
based on their unique lens and

367
00:26:21,995 --> 00:26:23,405
the data that is given to them.

368
00:26:23,824 --> 00:26:26,645
In the end, we just
take the majority vote.

369
00:26:27,095 --> 00:26:31,415
This method is incredibly robust and
reliable because it does not rely

370
00:26:31,415 --> 00:26:34,024
on us any single piece of evidence.

371
00:26:34,074 --> 00:26:41,145
It's hard to fool around a whole committee
of ex specialists who are all looking

372
00:26:41,145 --> 00:26:43,274
at different angles and different clues.

373
00:26:43,774 --> 00:26:47,764
But sometimes attacks can be so
clever and subtle that they can slip

374
00:26:47,764 --> 00:26:52,625
past this general vote, and that's
why a second technique comes into

375
00:26:52,625 --> 00:26:54,274
picture, which we call it ours.

376
00:26:54,274 --> 00:26:55,565
Master Investigator.

377
00:26:56,135 --> 00:26:58,625
This is our gradient boosting model.

378
00:26:59,284 --> 00:27:03,575
This detective examples, the
entire case file, learning from

379
00:27:03,575 --> 00:27:08,675
mistakes and becoming exceptionally
skilled and connecting subtle dots.

380
00:27:08,780 --> 00:27:15,699
To catch the most elusive threats,
sophisticated and sneaky threats as well.

381
00:27:16,479 --> 00:27:19,209
Now, why did we choose
this specific combination?

382
00:27:19,240 --> 00:27:22,449
There are three critical
advantages, and let us look at them.

383
00:27:23,050 --> 00:27:26,469
Firstly is that we achieve both
breadth and depth and accuracy.

384
00:27:26,860 --> 00:27:31,419
The committee provides reliable baseline
detection while the investigator

385
00:27:31,959 --> 00:27:33,909
handles sophisticated edge case.

386
00:27:33,939 --> 00:27:35,949
This hybrid approach is a key to our.

387
00:27:36,625 --> 00:27:40,014
97.5% model accuracy.

388
00:27:40,554 --> 00:27:44,365
Second is that the division of labor
enables realtime performance despite

389
00:27:44,365 --> 00:27:46,854
multiple, despite using two models.

390
00:27:46,854 --> 00:27:51,024
Our sophisticated architecture makes
predictions in microseconds, which is

391
00:27:51,024 --> 00:27:53,365
actually crucial for live API traffic.

392
00:27:53,754 --> 00:27:58,044
And third, we gain
enhanced interoperability.

393
00:27:58,854 --> 00:28:03,235
The committee ran the committee,
random forest shows us.

394
00:28:03,639 --> 00:28:07,359
Which feels like most
influential across all experts.

395
00:28:07,659 --> 00:28:12,129
While the investigator reveals the
sequential logic of complex cases,

396
00:28:12,579 --> 00:28:19,239
this multifaceted understanding
is vital for trust and debugging.

397
00:28:19,739 --> 00:28:22,649
The training process is continuous.

398
00:28:22,739 --> 00:28:27,479
We feed the model historical
traffic data labeled as estimate

399
00:28:27,509 --> 00:28:30,149
and malicious as malicious data.

400
00:28:30,659 --> 00:28:35,850
And cross verification to ensure
generalization and maintain automated

401
00:28:35,850 --> 00:28:45,029
pipelines that regularly retrain and
on new production data and basically

402
00:28:45,059 --> 00:28:47,340
become more sophisticated and up to date.

403
00:28:47,789 --> 00:28:50,759
This allows the system to
adapt to novel attacks.

404
00:28:51,299 --> 00:28:56,819
And evolving user behavior, creating
a learning system, not a static

405
00:28:56,819 --> 00:29:01,259
rule-based, which functionally overcomes
the limitations of the traditional

406
00:29:01,739 --> 00:29:04,409
rate limiting we discussed earlier.

407
00:29:04,909 --> 00:29:08,360
The final step over here is deploy.

408
00:29:08,860 --> 00:29:13,090
How do we put this intelligent brain
into production without creating a

409
00:29:13,090 --> 00:29:15,310
bottleneck or a single point of failure?

410
00:29:15,939 --> 00:29:20,080
The answer is a cloud native
serverless architecture.

411
00:29:20,620 --> 00:29:25,870
And here what it looks like in practice,
the model is packaged and deployed as

412
00:29:25,870 --> 00:29:30,520
a serverless function, for example,
in AWS Lambda or an Azure function.

413
00:29:30,879 --> 00:29:35,080
Now, why is the serverless approach,
so transf, let's me, let me explain it

414
00:29:35,080 --> 00:29:37,330
over here about its core advantages.

415
00:29:38,094 --> 00:29:43,884
For our use case, it is elastic and
event driven, basically, unlike.

416
00:29:44,770 --> 00:29:51,639
Traditional servers that you have
to provision and pay for 20 24 7

417
00:29:52,040 --> 00:29:55,010
serverless function scales to zero.

418
00:29:55,310 --> 00:29:57,409
It only wakes up when
the API request ticks.

419
00:29:57,860 --> 00:30:02,715
When you see a certain traffic spikes,
like during the product launch or

420
00:30:02,715 --> 00:30:06,344
marketing event, the cloud provider
automatically spins up thousands of

421
00:30:06,344 --> 00:30:08,834
parallel instance in milliseconds.

422
00:30:09,419 --> 00:30:13,770
There is no capacity planning
and no manual intervention.

423
00:30:14,280 --> 00:30:18,629
The system scales precisely
as the demand increases.

424
00:30:19,129 --> 00:30:24,199
Now the next advantage is
granular paper use cost model.

425
00:30:24,679 --> 00:30:27,289
This is a game changer
with cost efficiency.

426
00:30:27,769 --> 00:30:30,709
You are not built for the ideal time.

427
00:30:30,799 --> 00:30:32,779
We did see earlier how.

428
00:30:33,214 --> 00:30:38,284
The older infrastructure had extra
cost owing to the fact that we

429
00:30:38,284 --> 00:30:43,564
are maintaining the infrastructure
despite not having enough request.

430
00:30:43,894 --> 00:30:48,514
Over here, you are only charged for
the milliseconds of the time, compute

431
00:30:48,514 --> 00:30:54,724
time it takes to execute the model
inference for each request during quite,

432
00:30:54,724 --> 00:30:56,764
quite periods when there is no traffic.

433
00:30:56,794 --> 00:31:01,354
Your cost for these API
component drops to absolute zero.

434
00:31:01,999 --> 00:31:07,659
While your system remains ready to spring
in action now talking about built-in

435
00:31:07,659 --> 00:31:15,099
fault tolerance and high availability
feature Cloud provides run cloud.

436
00:31:15,249 --> 00:31:21,039
Cloud providers run serverless functions
across multiple availability zones By

437
00:31:21,039 --> 00:31:26,619
default, this means if an entire data
center is in one zone, has an outage.

438
00:31:27,474 --> 00:31:32,094
The platform automatically
routes traffic and executes the

439
00:31:32,094 --> 00:31:33,654
function in another time zone.

440
00:31:34,074 --> 00:31:38,784
You are, you get a highly
resilient system without having to

441
00:31:38,784 --> 00:31:40,704
architect the redundancy yourself.

442
00:31:41,204 --> 00:31:43,274
Second is reduce operational over it.

443
00:31:43,274 --> 00:31:43,334
We.

444
00:31:43,834 --> 00:31:47,704
Completely eliminate the need for
you to manage servers, operating

445
00:31:47,704 --> 00:31:49,744
systems, runtime environments.

446
00:31:50,104 --> 00:31:53,734
There are no patches to apply, no
servers to reboot, no clusters to

447
00:31:53,734 --> 00:31:58,924
monitor this no ops model allows your
team to focus on building features

448
00:31:59,344 --> 00:32:01,234
and not managing the infrastructure.

449
00:32:01,734 --> 00:32:06,159
This serverless function integrates
seamlessly into your existing API gateway.

450
00:32:06,659 --> 00:32:11,789
Every incoming request that
needs inspection has its features

451
00:32:11,789 --> 00:32:16,619
calculated and is then sent to this
function for real time inference.

452
00:32:16,919 --> 00:32:22,829
The gateway then enforces the decision
of allowing, delay, denying, or blocking

453
00:32:22,829 --> 00:32:25,439
based on the models confidence score.

454
00:32:25,499 --> 00:32:30,569
Now, you might wonder, what does
intelligence system not become?

455
00:32:31,009 --> 00:32:34,220
It's it's not what, how does
this intelligence system

456
00:32:34,459 --> 00:32:35,780
not become a bottleneck?

457
00:32:36,110 --> 00:32:39,979
The answer lies in the powerful
synergy between the static model

458
00:32:39,979 --> 00:32:43,429
choice and the inherited strengths
of serverless architecture.

459
00:32:43,490 --> 00:32:49,090
First, our optimized decision tree example
is purpose built for this environment.

460
00:32:49,479 --> 00:32:54,550
It delivers the high accuracy we
need with microsecond inference.

461
00:32:54,834 --> 00:33:02,695
Speed and crystal clear interpretability,
ensuring it can take lightning fast

462
00:33:02,695 --> 00:33:05,515
decisions without slowing down your API.

463
00:33:06,084 --> 00:33:09,774
Second, we deploy it using
the serverless function.

464
00:33:10,135 --> 00:33:14,544
The cloud platform provides
automatic, near infinite scaling

465
00:33:14,965 --> 00:33:17,035
and true parallel processing.

466
00:33:17,365 --> 00:33:21,504
If 10,000 requests arrive at once, it's
been sub 10,000 parallel instances.

467
00:33:22,385 --> 00:33:27,430
There's no queue because there's
no single point to queue at all.

468
00:33:27,929 --> 00:33:33,149
We complete this with a robust
and operational practices.

469
00:33:33,509 --> 00:33:39,689
We implement zero down deployments using
green blue deployment model, allowing

470
00:33:39,689 --> 00:33:44,580
us to update the AI model seamlessly
and roll back instantly if needed.

471
00:33:44,954 --> 00:33:49,334
All without users having to noticing
this powerful combination gives us

472
00:33:49,334 --> 00:33:54,764
three massive advantages of infinite
scalability, true cost, efficiency, and

473
00:33:54,764 --> 00:34:01,574
built in availability makes this rigorous
architecture that guarantees a system

474
00:34:01,574 --> 00:34:08,564
which not only is intelligent, but also
performant, reliable and cost effective.

475
00:34:09,284 --> 00:34:14,084
This four step cycle, collecting rich
data engineering intelligent features.

476
00:34:14,584 --> 00:34:19,894
Training a powerful model and deploying
with cloud native agility is how we

477
00:34:19,894 --> 00:34:26,914
transform the blunt instrument of
traditional rate limiting into a precise,

478
00:34:26,974 --> 00:34:30,154
adaptive, scalable security system.

479
00:34:30,654 --> 00:34:34,994
Now talking about advanced
strategies, or even before that.

480
00:34:35,714 --> 00:34:40,424
Let's think sometimes makes people
wonder where this actually work.

481
00:34:40,424 --> 00:34:41,924
These are not just lab result.

482
00:34:41,924 --> 00:34:45,344
The other trail work reports,
these are metrics that come from

483
00:34:45,704 --> 00:34:49,874
real world production deployment
across AWS Azure and Google Cloud.

484
00:34:50,234 --> 00:34:56,894
We see 96% product detection accuracy
for malicious threats, and we also

485
00:34:56,894 --> 00:34:59,654
see 68% reduction in false positives.

486
00:34:59,924 --> 00:35:02,829
Now, that's the number of
millions of estimate users.

487
00:35:03,479 --> 00:35:08,849
Who are no longer accidentally
blocked, which increases better, which

488
00:35:08,849 --> 00:35:14,459
increases the user experience of that
many users by throttling precise,

489
00:35:14,909 --> 00:35:17,489
precisely and only when needed.

490
00:35:17,729 --> 00:35:23,309
Companies have achieved over 27%
in infrastructure cost savings.

491
00:35:23,939 --> 00:35:28,484
This model itself operates
with 97% accuracy.

492
00:35:28,994 --> 00:35:30,924
This is an efficient and tangible.

493
00:35:31,424 --> 00:35:32,774
Bottom line improvement.

494
00:35:33,274 --> 00:35:38,104
Looking at advanced strategy like
progressive throttling, a key

495
00:35:38,104 --> 00:35:43,384
innovation that drives down false
positives, how we respond, we reject

496
00:35:43,384 --> 00:35:46,204
the binary block or allow paradigm.

497
00:35:46,324 --> 00:35:50,049
Instead, we use
progressive throttling now.

498
00:35:51,019 --> 00:35:56,119
What happens here is the AI assigns
a threat confidence score from

499
00:35:56,119 --> 00:35:58,669
zero to hundred based on the score.

500
00:35:58,669 --> 00:36:05,149
We apply a graduated response in case
of low score, which means a low threat.

501
00:36:05,179 --> 00:36:07,099
That request will be
full speed, will have.

502
00:36:07,654 --> 00:36:10,654
Full speed access, no
impact to real users.

503
00:36:10,954 --> 00:36:15,184
In case of medium score, we introduced
a slightly incremental delays.

504
00:36:15,574 --> 00:36:21,724
A script will be crippled by 500
millisecond delay, but human user might

505
00:36:21,724 --> 00:36:24,724
not even notice it in case of high.

506
00:36:24,984 --> 00:36:32,244
Medium scores can be from 31 to
70, low, zero to 30 high, 71 to 99.

507
00:36:32,244 --> 00:36:35,604
We enforce much stricter rate limits.

508
00:36:35,934 --> 00:36:41,184
In case of confirmed threat, we
will completely block the request.

509
00:36:41,694 --> 00:36:45,419
This graceful, slow down and
degradation is what allows us

510
00:36:45,504 --> 00:36:50,365
to ensure security without being
hostile and completely shutting down.

511
00:36:50,865 --> 00:36:52,814
The system doesn't stand still.

512
00:36:53,264 --> 00:36:56,144
It continues continuously segments.

513
00:36:56,144 --> 00:36:59,174
Users, monitors model
performance and incorporates

514
00:36:59,534 --> 00:37:01,934
new data to retain and improve.

515
00:37:02,684 --> 00:37:08,259
It's a living learning system that
attach to your unique traffic patterns

516
00:37:08,399 --> 00:37:10,979
and evolving tactics of attackers.

517
00:37:11,479 --> 00:37:16,039
You if you are convinced it's
time from move, from dark ages to

518
00:37:16,039 --> 00:37:20,629
rate limiting, here's a practical
phased roadmap to get you there.

519
00:37:21,499 --> 00:37:25,009
Assessment phase audit,
your current rate limiting.

520
00:37:25,519 --> 00:37:26,990
Identify pain points.

521
00:37:26,990 --> 00:37:28,849
What are your false positive rates?

522
00:37:28,879 --> 00:37:32,119
What does your attack traffic looks like?

523
00:37:32,479 --> 00:37:36,079
Establish a baseline, then
do a infrastructure setup.

524
00:37:36,439 --> 00:37:38,659
Configure the data collection.

525
00:37:38,659 --> 00:37:40,009
Pipelines set the.

526
00:37:40,669 --> 00:37:43,159
Cloud resources and monitoring dashboards.

527
00:37:43,189 --> 00:37:46,219
This is the foundation model development.

528
00:37:46,279 --> 00:37:51,019
Engineer your features and train your
initial models on historical data.

529
00:37:51,439 --> 00:37:54,049
Validate their performance
against your baseline.

530
00:37:54,549 --> 00:37:55,689
This is crucial.

531
00:37:55,719 --> 00:38:01,389
Deploy a single API or a
small percentage of traffic.

532
00:38:01,869 --> 00:38:03,069
Monitor everything.

533
00:38:03,069 --> 00:38:06,249
Closely tune the model based
on real world feedback.

534
00:38:06,749 --> 00:38:07,469
Full rollout.

535
00:38:07,499 --> 00:38:11,909
Once your confidence scale across
all your APIs, implement the

536
00:38:11,939 --> 00:38:16,259
continuous learning loop and start
optimizing the cost efficiency.

537
00:38:16,759 --> 00:38:22,399
Now, I would like to wrap up this
discussion and if you have any questions,

538
00:38:22,784 --> 00:38:29,264
you can reach me at LinkedIn that
is looking up against Rihanna Han.

539
00:38:29,784 --> 00:38:33,264
There's only one person you will get
and you can connect with me again, you

540
00:38:33,264 --> 00:38:37,104
can connect with me to discuss about
this or anything else, my friends.

541
00:38:37,314 --> 00:38:37,879
Thank you again.

542
00:38:37,879 --> 00:38:37,890
Okay.

