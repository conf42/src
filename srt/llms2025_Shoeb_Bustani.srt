1
00:00:00,210 --> 00:00:04,290
Are you looking to accelerate
well architected reviews and saved

2
00:00:04,320 --> 00:00:06,960
countless hours on manual assessments?

3
00:00:07,860 --> 00:00:08,640
Hello everyone.

4
00:00:08,730 --> 00:00:13,620
My name is Sha Bustani and I'm a
Senior Solutions Architect at AWS and

5
00:00:13,620 --> 00:00:15,510
I welcome all of you to my session.

6
00:00:15,840 --> 00:00:20,820
Accelerate AWS well architected
reviews with generative ai.

7
00:00:21,320 --> 00:00:27,560
In this session, I will talk you through
practical ways Amazon backrock can support

8
00:00:27,860 --> 00:00:30,410
your architectural assessments, right?

9
00:00:30,410 --> 00:00:33,680
From identifying potential
areas of improvement to

10
00:00:33,680 --> 00:00:36,050
streamlining your review process.

11
00:00:36,550 --> 00:00:41,230
When you are building systems at your
organization, how confident are you

12
00:00:41,470 --> 00:00:45,370
that those systems are being built
using the best practices for the cloud?

13
00:00:45,870 --> 00:00:50,309
And this is where AWS well architected
framework plays an important role.

14
00:00:50,309 --> 00:00:55,019
It'll help, it helps you understand
the pros and cons of decisions you make

15
00:00:55,260 --> 00:00:58,799
while building these systems on AWS.

16
00:00:59,299 --> 00:01:03,260
By using the framework, you learn
architecture best practices for

17
00:01:03,260 --> 00:01:09,199
designing and operating, reliable,
secure, efficient, cost-effective,

18
00:01:09,530 --> 00:01:11,495
and sustainable systems in the cloud.

19
00:01:11,995 --> 00:01:16,675
The AWS framework is based on
six pillars that helps you build,

20
00:01:17,195 --> 00:01:18,905
stable and efficient systems.

21
00:01:18,905 --> 00:01:23,855
On AWS it is a set of questions
and design principles that are

22
00:01:23,855 --> 00:01:25,595
spread across these pillars.

23
00:01:26,135 --> 00:01:32,375
Operational excellence, security,
reliability, performance efficiency,

24
00:01:32,795 --> 00:01:35,735
cost optimization, and sustainability.

25
00:01:36,665 --> 00:01:42,335
Alongside the pillars are AWS well
architected lenses, which provide

26
00:01:42,335 --> 00:01:47,315
guidance with a focus, on a specific
industry or a technology domain.

27
00:01:48,155 --> 00:01:53,705
For example, data analytics and
financial services industry lenses.

28
00:01:54,205 --> 00:01:58,704
To evaluate the health of your
workload, you essentially answer a

29
00:01:58,704 --> 00:02:04,255
set of foundational questions based
on the framework, pillar and lenses.

30
00:02:04,755 --> 00:02:09,954
In addition to align with your own
organization's, operational plans,

31
00:02:10,044 --> 00:02:15,864
internal processes, or maybe industry,
you could define and manage custom lenses.

32
00:02:16,364 --> 00:02:21,279
Creating a technology solution is a lot
like constructing a physical building.

33
00:02:22,154 --> 00:02:26,385
If the foundation is not solid,
it may lead to structural problems

34
00:02:26,684 --> 00:02:29,834
that may undermine the integrity
and function of the building.

35
00:02:30,704 --> 00:02:34,704
Similarly, if you neglect
any of these, six pillars.

36
00:02:35,109 --> 00:02:40,509
Operational excellence, security,
reliability, performance efficiency,

37
00:02:40,839 --> 00:02:43,839
cost optimization, and sustainability.

38
00:02:44,019 --> 00:02:48,669
When architecting technology solutions, it
can become a challenge to build a system

39
00:02:48,669 --> 00:02:53,200
that delivers, functional requirements
and also meet your, expectations.

40
00:02:54,039 --> 00:02:59,139
On the contrary, if you incorporate
these pillars, it'll help you produce

41
00:02:59,229 --> 00:03:04,389
stable and efficient systems, allowing
you to focus on functional requirements.

42
00:03:04,889 --> 00:03:07,619
There are three parts to wafer framework.

43
00:03:07,769 --> 00:03:13,469
First is the content, so the framework
with the design principles, pillars

44
00:03:13,469 --> 00:03:17,399
with the questions and best practices
along with the white papers that

45
00:03:17,399 --> 00:03:20,279
gets published on AWS website.

46
00:03:20,779 --> 00:03:22,429
Next is the self-service tool.

47
00:03:22,850 --> 00:03:26,610
The tool, that uses the framework to
carry out, the reviews of the workload

48
00:03:26,640 --> 00:03:29,550
in the form of question and answers.

49
00:03:29,910 --> 00:03:34,290
This is embedded within AWS Management
console, as is own dashboard.

50
00:03:34,290 --> 00:03:39,085
It allows you to generate the PDF reports,
for improvement plans, and then you

51
00:03:39,085 --> 00:03:44,665
have got the data that you have from
doing the reviews, including metadata,

52
00:03:44,915 --> 00:03:47,075
and identified improvement plans.

53
00:03:47,575 --> 00:03:53,365
As organizations expand their cloud
footprints, it brings challenges

54
00:03:53,394 --> 00:03:54,954
and opportunities to scale.

55
00:03:55,225 --> 00:04:00,025
When it comes to adhering to well
architected framework, for example,

56
00:04:00,505 --> 00:04:04,165
manual reviews may become time
consuming and resource intensive.

57
00:04:04,665 --> 00:04:09,284
Different teams may apply the
well architected principles

58
00:04:09,885 --> 00:04:14,024
inconsistently across the
applications or across the teams.

59
00:04:14,524 --> 00:04:19,175
Keeping pace with the latest
practices may get tricky, especially

60
00:04:19,355 --> 00:04:23,165
with the new services and features
being released continuously.

61
00:04:23,665 --> 00:04:26,620
And do remember V four
is a continuous activity.

62
00:04:27,120 --> 00:04:30,510
And the scaling reviews for
numerous or large architects,

63
00:04:30,610 --> 00:04:32,740
architectures can become difficult.

64
00:04:33,240 --> 00:04:38,830
To overcome these challenges, builders
like me at HWS have come up with a

65
00:04:38,830 --> 00:04:45,910
vision to accelerate AWS well architected
frame of gloss and enterprise adoption

66
00:04:46,120 --> 00:04:51,940
by leveraging the power of gen EI and
provide organizations with automated

67
00:04:51,970 --> 00:04:58,630
comprehensive analysis and recommendations
for optimizing their AWS architectures.

68
00:04:59,130 --> 00:05:05,130
The proposition here is to use the
wafer content tool and data with

69
00:05:05,130 --> 00:05:11,300
generality AI to drive well architected
assessments, and this approach brings

70
00:05:11,300 --> 00:05:13,100
multiple benefit to the enterprises.

71
00:05:13,790 --> 00:05:20,210
For example, the rapid analysis cuts the
amount of time spent on WA four reviews

72
00:05:20,540 --> 00:05:22,400
resulting in time efficiency gains.

73
00:05:22,900 --> 00:05:27,370
AI powered analysis ensures
consistent and thorough evaluations

74
00:05:27,370 --> 00:05:29,650
and reviews across workloads.

75
00:05:30,150 --> 00:05:35,100
Optimizing resource allocation and
reduced manual efforts result in

76
00:05:35,100 --> 00:05:40,780
increased, stop productivity and also
shift alert mentality, which result in

77
00:05:40,780 --> 00:05:42,640
overall cost saving for the organization.

78
00:05:43,140 --> 00:05:47,190
And you can perform more, frequent
reviews or time refining feature

79
00:05:47,190 --> 00:05:49,470
assessments and improving feedback loops.

80
00:05:50,160 --> 00:05:54,450
The other benefits too as well, so
we talked about scalability in the

81
00:05:54,450 --> 00:06:00,660
beginning, so ability to run multiple
reviews simultaneously would be a

82
00:06:00,660 --> 00:06:02,825
good thing, for the organization.

83
00:06:03,325 --> 00:06:07,675
Also taking it to the next level,
interactive exploration through

84
00:06:07,675 --> 00:06:11,995
chat interface to dive deeper into
the assessments, asking follow

85
00:06:11,995 --> 00:06:16,345
up questions and getting a better
understanding of the recommendations.

86
00:06:17,215 --> 00:06:21,415
This interactivity enhances
engagement and promotes, thorough

87
00:06:21,415 --> 00:06:22,765
comprehension of the results.

88
00:06:23,265 --> 00:06:27,085
So when it comes to building,
such a system, you would, using

89
00:06:27,085 --> 00:06:30,505
Geni, prompt driven approach,
appears as trivial choice.

90
00:06:30,845 --> 00:06:36,195
the prompt is your interface with the
model, and, crafting, the right prompt

91
00:06:36,285 --> 00:06:39,315
is crucial for the output generation.

92
00:06:40,170 --> 00:06:44,200
So prompts are similar to decision
process of, human beings by

93
00:06:44,200 --> 00:06:48,620
learning, from analogy, by tweaking
the inputs or the prompting of the

94
00:06:48,620 --> 00:06:53,520
words, you get the desired output on
completion and the slight changes,

95
00:06:53,570 --> 00:06:58,090
or tuning to the prompt can have a
significant impact, on the outcome.

96
00:06:58,810 --> 00:07:02,710
Of course, it takes trial and error,
and also an artistic FLA to it as well.

97
00:07:03,210 --> 00:07:06,545
But effectiveness also depends
on how model was framed.

98
00:07:07,045 --> 00:07:10,645
When it comes to prompt engineering,
there are multiple types.

99
00:07:10,645 --> 00:07:14,275
You have a zero short prompt,
or prompt by instruction,

100
00:07:14,425 --> 00:07:16,255
which uses, LLM out of the box.

101
00:07:16,675 --> 00:07:20,755
It allows you to, language
models to perform on the task.

102
00:07:20,965 --> 00:07:23,185
They have not been explicitly trained on.

103
00:07:23,685 --> 00:07:26,325
Then you have one shot
or a few short prompts.

104
00:07:26,715 --> 00:07:31,695
What it means in here is that you
provide one or more pairs of problem

105
00:07:31,695 --> 00:07:35,900
and solution, solution pairs, as
short, as, to the input prompt.

106
00:07:36,200 --> 00:07:38,660
And this helps to guide model performance.

107
00:07:39,160 --> 00:07:41,230
And then you have chain
of thought prompting.

108
00:07:41,830 --> 00:07:47,410
It addresses mul multi-step problem
solving challenges in arithmetic

109
00:07:47,440 --> 00:07:48,970
and common sense reasoning tasks.

110
00:07:49,470 --> 00:07:52,020
It generates intermediate reasoning steps.

111
00:07:52,230 --> 00:07:55,790
We are making human review of tho
human train of thoughts before

112
00:07:55,790 --> 00:07:57,200
it provides the actual answer.

113
00:07:57,700 --> 00:08:01,690
in principle, you would think, that,
in the way, in the current context of

114
00:08:01,690 --> 00:08:06,180
well architected framework, you could
create a series of, prompts from the

115
00:08:06,180 --> 00:08:10,410
framework, questions, and sequence
through LLM to solve the problem.

116
00:08:10,935 --> 00:08:12,105
That sounds straightforward.

117
00:08:12,495 --> 00:08:15,225
However, there are limitations,
with the prompting.

118
00:08:15,615 --> 00:08:20,485
they, they have a poor memory,
but work with very limited context

119
00:08:20,905 --> 00:08:25,075
and then accessing, and it relies
on accessing extra knowledge

120
00:08:25,315 --> 00:08:26,935
sources to complete this task.

121
00:08:27,435 --> 00:08:31,995
And this is where the retrieval,
augmented generation, or rag

122
00:08:32,175 --> 00:08:33,945
or architecture offers more.

123
00:08:34,445 --> 00:08:40,085
Retrieval, augmented, generation
or re is a process for retrieving

124
00:08:40,085 --> 00:08:45,965
facts from knowledge basis to ground
LMS with up to date, accurate and

125
00:08:45,965 --> 00:08:48,665
insightful data supplied in the prom.

126
00:08:49,165 --> 00:08:51,895
It has three stages in the retrieval.

127
00:08:52,315 --> 00:08:55,735
In the retrieval stage, the
relevant content is fetched from

128
00:08:55,735 --> 00:08:59,685
the action, knowledge base or data
sources based on the user query.

129
00:09:00,345 --> 00:09:05,205
The retrieve, context is then added to
the user prompt, which goes as an input

130
00:09:05,205 --> 00:09:10,335
to the foundation model as part of the
augmentation, and then the generation, the

131
00:09:10,335 --> 00:09:15,645
response from the Foundation Mole model
is now based on the augmented, prompt.

132
00:09:16,145 --> 00:09:20,170
Now that we know the basic,
basic functioning of rag,

133
00:09:20,470 --> 00:09:22,000
how does it actually work?

134
00:09:22,795 --> 00:09:28,145
First, you need to optimize the data,
for rack to work, and it is done as

135
00:09:28,145 --> 00:09:30,095
part of the data ingestion layer.

136
00:09:30,395 --> 00:09:34,145
First of all, the data is sourced,
from the relevant data sources.

137
00:09:34,535 --> 00:09:39,705
Then that data from the data sources
chunked, wherein the large pieces

138
00:09:39,705 --> 00:09:44,685
of text are converted into a small
segments, then stored in the vector

139
00:09:44,685 --> 00:09:46,875
database using embedding models.

140
00:09:47,375 --> 00:09:52,175
Then during text generation workflow on
receiving the user query or question,

141
00:09:52,415 --> 00:09:59,135
a semantic search is done and retrieved
passages into bracket R are ranked and

142
00:09:59,135 --> 00:10:05,885
pause as a context that is augmentation
or augmented into bracket A, into an

143
00:10:05,945 --> 00:10:11,585
A model, which in turn generates a
response complete the G aspect of it.

144
00:10:12,085 --> 00:10:16,885
So based on what we have seen so far and
learned so far as part of the session,

145
00:10:17,285 --> 00:10:22,065
we are to now talking about an improved
approach, wherein we come, we take,

146
00:10:22,095 --> 00:10:27,945
the content, data and tool and combine
it with Amazon bedrock and knowledge

147
00:10:27,945 --> 00:10:34,425
basis for Amazon Bedrock and LLM to
drive well architected assessments.

148
00:10:34,925 --> 00:10:37,925
Building on this approach,
I'm excited to share that.

149
00:10:37,975 --> 00:10:42,920
we, builders at AWS have, developed
our comprehensive one click,

150
00:10:43,085 --> 00:10:48,305
click or few click deployable
solution to facilitate and expedite

151
00:10:48,485 --> 00:10:51,305
AWS well architected, process.

152
00:10:51,805 --> 00:10:54,565
It uses workload documentation.

153
00:10:55,045 --> 00:10:59,515
It means you can upload your own solution
architecture documents or technical

154
00:10:59,515 --> 00:11:01,805
design documents, to the application.

155
00:11:02,465 --> 00:11:07,985
It uses mainstream inputs, data sets, so
it accepts a PDF file format that you can,

156
00:11:08,085 --> 00:11:13,740
convert your documents into and upload
it to the application it uses or ingests.

157
00:11:13,740 --> 00:11:18,850
AWS well architected documentation
from AWS public website, into the

158
00:11:19,090 --> 00:11:20,810
internal knowledge, knowledge base.

159
00:11:21,310 --> 00:11:22,420
And it's accessible.

160
00:11:22,480 --> 00:11:27,130
You can extend it to include
your own organization or industry

161
00:11:27,130 --> 00:11:29,500
review standards using custom lens.

162
00:11:30,000 --> 00:11:35,080
So entire stack is created, as
infrastructure as a code with, AWS cloud

163
00:11:35,080 --> 00:11:40,730
deployment kit, CDK in shop that you can
deploy with a few, one or few clicks.

164
00:11:41,315 --> 00:11:45,725
And there are a number of artifacts that
get created, or used as part of the stack.

165
00:11:45,935 --> 00:11:52,575
So we are using Amazon Bedrock with
Anthropic Cloud, LLM, for the LLM, and

166
00:11:52,575 --> 00:11:57,405
then we are using open source serverless
as the Amazon Bedrock knowledge base.

167
00:11:58,065 --> 00:12:03,235
Alongside we use, DB and which is
our, code database for storing,

168
00:12:03,595 --> 00:12:05,065
the review run information.

169
00:12:06,055 --> 00:12:11,105
In addition, we use Amazon's
SQS EC2 instance, which host the

170
00:12:11,105 --> 00:12:12,935
stream rate front-end application.

171
00:12:13,205 --> 00:12:17,695
In addition, there are other
services such as, S3 buckets, and

172
00:12:17,695 --> 00:12:19,795
Amazon Kognito for user management.

173
00:12:20,575 --> 00:12:27,145
The heart and the core of, the reviewer
is based on AWS Lambda and step functions,

174
00:12:27,445 --> 00:12:29,755
which manage the wafer analysis runs.

175
00:12:30,255 --> 00:12:35,405
In addition, we use cloud mode
distribution, with, a LB and initial

176
00:12:35,495 --> 00:12:37,865
web rules for you to improve upon.

177
00:12:38,365 --> 00:12:39,805
Let's see how it works.

178
00:12:40,000 --> 00:12:44,430
I. For the demo, I have created
a fictitious payment solution for

179
00:12:44,430 --> 00:12:48,170
a fictitious company, any comp,
any company that receives an,

180
00:12:48,450 --> 00:12:53,320
process, payment files to drive its,
downstream systems, and ML workload.

181
00:12:53,820 --> 00:12:58,230
The wafer accelerator sample
does not require the documents

182
00:12:58,230 --> 00:13:01,530
to be in any particular format
or a template where it's working.

183
00:13:02,355 --> 00:13:05,715
However, the quality of the
documentation that's uploaded for

184
00:13:05,715 --> 00:13:07,485
assessment is an important factor.

185
00:13:07,985 --> 00:13:13,175
Detailed architecture documents
will result in better influences

186
00:13:13,535 --> 00:13:15,365
and hence better assessments.

187
00:13:15,980 --> 00:13:19,260
However, in this particular
example I have, created a solution

188
00:13:19,260 --> 00:13:23,880
architecture document for the Fictious
solution that I described, earlier.

189
00:13:24,360 --> 00:13:26,610
and this is a pretty
comprehensive document.

190
00:13:26,610 --> 00:13:28,145
It's page, 37 pages long.

191
00:13:28,660 --> 00:13:30,820
which is typical with
these kind of documents.

192
00:13:31,120 --> 00:13:34,900
And we will provide this as an
input to the wafer tool, wafer

193
00:13:34,900 --> 00:13:38,770
accelerator tool, which would review
and provide, architecture assessment

194
00:13:38,770 --> 00:13:42,940
in the context of this document
and the wafer driven knowledge base

195
00:13:43,210 --> 00:13:47,780
built, from the AWS well architected
framework of build documentation.

196
00:13:48,280 --> 00:13:52,450
This is, the landing page for
the wafer accelerator sample.

197
00:13:52,950 --> 00:13:58,170
So I have already created a
fictitious user, so I'm going

198
00:13:58,170 --> 00:14:00,090
to log in using that user.

199
00:14:00,590 --> 00:14:06,200
I. Before I proceed any further,
the user, that I use to log in is

200
00:14:06,200 --> 00:14:11,270
part of the Cognito user pool that's
provisioned as part of the CDK stack.

201
00:14:11,870 --> 00:14:16,440
All you need to do is go and create, or
provision the users in that user pool.

202
00:14:16,940 --> 00:14:18,590
So this is the welcome page.

203
00:14:18,650 --> 00:14:20,780
So you have got a few options in here.

204
00:14:21,140 --> 00:14:22,880
The most important one are.

205
00:14:23,255 --> 00:14:28,475
New way for review and existing
review for review links.

206
00:14:29,045 --> 00:14:33,065
They're available here as well, so I
will start with a new way for review.

207
00:14:33,565 --> 00:14:35,305
There are two analysis types in here.

208
00:14:35,395 --> 00:14:38,665
One is a quick one and the
other one is a deep with well

209
00:14:38,665 --> 00:14:40,255
architected tool integration.

210
00:14:40,755 --> 00:14:45,645
So quick mode is, as the implies is
a quick mode wherein we club all the

211
00:14:45,645 --> 00:14:51,015
questions for a particular, pillar into a
single prompt to speed up, the inferences.

212
00:14:51,555 --> 00:14:54,855
But it's a good starting
point for the submitters.

213
00:14:54,855 --> 00:14:58,665
for example, if I am a solution
architect, if I want to submit, an

214
00:14:58,665 --> 00:15:03,145
architecture document for review to
potentially, architecture review board.

215
00:15:03,520 --> 00:15:07,760
Then I would like to mark my own homework
and I could come to this, generate a

216
00:15:07,760 --> 00:15:13,280
quick, way for assessment and see how far
I am from, or my documentation is away

217
00:15:13,280 --> 00:15:19,110
from the well architecture best practices
and the responses, or the assessment in

218
00:15:19,110 --> 00:15:23,100
this particular mode beside completely
decides completely within the application.

219
00:15:23,670 --> 00:15:27,720
And then you have got the deep with
well architected tool integration.

220
00:15:28,245 --> 00:15:32,655
This is a d as a name implies,
is a deep review wherein we, draw

221
00:15:32,655 --> 00:15:36,855
inferences for each and every question
separately from the selected pillars.

222
00:15:37,155 --> 00:15:41,235
And it's also integrated with
the AWS well architected tool.

223
00:15:41,925 --> 00:15:46,805
It means, on completion of, your
review, we do get the review output

224
00:15:46,895 --> 00:15:50,525
in the application as well as
you have got a workload that gets

225
00:15:50,525 --> 00:15:55,395
created in AWS architected tool,
and we'll see it a little bit later.

226
00:15:56,070 --> 00:16:02,050
So in the interest of time, what I'm going
to do is I'm to going to, create a sample,

227
00:16:02,050 --> 00:16:08,320
create a quick review, and I'm going to
call it wafer accelerator, quick demo two.

228
00:16:08,820 --> 00:16:09,110
Okay.

229
00:16:09,610 --> 00:16:12,905
Give it a description, then
you can select the environment.

230
00:16:13,405 --> 00:16:14,305
Industry type.

231
00:16:14,815 --> 00:16:18,295
So in this particular case, because
a payment solution, I'm gonna recall

232
00:16:18,295 --> 00:16:20,185
or mark it as financial services.

233
00:16:20,965 --> 00:16:26,785
I'll interrupt fictitious name for
the reviewer and select the lens.

234
00:16:26,785 --> 00:16:28,045
I would like it to be reviewed.

235
00:16:28,545 --> 00:16:32,385
So right now at the time of demo,
we are supporting three lenses, the

236
00:16:32,385 --> 00:16:37,445
core AWS, architected framework lens,
and then data analytics lens and

237
00:16:37,445 --> 00:16:39,365
financial services industry lens.

238
00:16:39,695 --> 00:16:44,255
So for this particular demo, I'm going
to select AWS well architected framework.

239
00:16:44,755 --> 00:16:48,495
The user is, created, biofield
is populated by the username.

240
00:16:48,495 --> 00:16:50,715
I used to log in the application.

241
00:16:51,375 --> 00:16:54,645
Now I could go and select the
pillars I would like, it to

242
00:16:54,735 --> 00:16:56,855
be, for, for it to review.

243
00:16:57,425 --> 00:16:59,715
So I have the option to
select, all the pillars.

244
00:16:59,745 --> 00:17:01,785
However, you don't have
to select all the pillars.

245
00:17:01,785 --> 00:17:03,825
You can only select the
pillars you are interested in.

246
00:17:04,125 --> 00:17:06,625
For some of the customers, if
they are, interested only in

247
00:17:06,625 --> 00:17:08,995
security and reliability, they
could select those pillars.

248
00:17:09,475 --> 00:17:12,805
But for the demo purpose, I'm
going to select all the pillars.

249
00:17:13,305 --> 00:17:17,495
And then upload the document
I mentioned earlier.

250
00:17:17,995 --> 00:17:20,725
At this point, I have
populated all the fields.

251
00:17:21,225 --> 00:17:25,415
I'm going to create a way for
review, and as the MEA says, it

252
00:17:25,415 --> 00:17:26,945
has been created successfully.

253
00:17:26,945 --> 00:17:31,460
So if I go back to this, okay,
it has commenced the processing.

254
00:17:31,960 --> 00:17:36,345
So let, I would let it complete because it
takes, a little white for it to complete.

255
00:17:36,945 --> 00:17:40,815
but in the interest of time and for
showcasing purposes, I've already

256
00:17:40,815 --> 00:17:43,435
created a few, demos, in the past.

257
00:17:43,795 --> 00:17:45,385
So let's select one of them.

258
00:17:45,885 --> 00:17:50,045
So this is the metadata that
you, that we entered, when,

259
00:17:50,105 --> 00:17:51,605
creating this particular review.

260
00:17:52,105 --> 00:17:54,535
So the first step is to
create a solution summary.

261
00:17:54,565 --> 00:17:57,595
So we use a document that has
been uploaded and use the geni

262
00:17:57,595 --> 00:17:59,345
to, create a solution summary.

263
00:17:59,405 --> 00:18:04,330
It means the reviewers don't have to
read or the entire document, or not.

264
00:18:04,330 --> 00:18:06,610
All the reviewers need to
read the entire document.

265
00:18:06,970 --> 00:18:08,290
They can read the solution summary.

266
00:18:08,290 --> 00:18:10,720
And this is, followed by, the.

267
00:18:11,710 --> 00:18:14,980
By questions for all the
pillars that have been selected.

268
00:18:14,980 --> 00:18:18,280
So for this particular one, I had
selected all the pillars, and hence you

269
00:18:18,280 --> 00:18:20,130
can see all the pillars, in the tab.

270
00:18:20,630 --> 00:18:23,920
So starting with this, you have
got the question at the, top.

271
00:18:24,430 --> 00:18:29,470
This is followed by, quick assessment
and then it tells you which best

272
00:18:29,470 --> 00:18:33,110
practices have been followed,
recommendations and examples.

273
00:18:33,845 --> 00:18:38,035
In this particular case, document,
doesn't, did not have enough information

274
00:18:38,035 --> 00:18:42,085
on this, and we have devised the
prompts in such a way that we can't

275
00:18:42,085 --> 00:18:43,555
find the relevant information.

276
00:18:43,555 --> 00:18:46,465
It calls back and says, we
don't have enough information

277
00:18:46,465 --> 00:18:47,395
to provide the assessment.

278
00:18:47,895 --> 00:18:51,915
So coming back to the recommendations,
it gives you a list of recommendations,

279
00:18:51,965 --> 00:18:57,935
to improve your architecture, followed
by risks that it, gen I has identified

280
00:18:58,295 --> 00:19:03,425
and citations from the AWS well
Architected Framework documentation.

281
00:19:04,205 --> 00:19:08,085
And it does it for all the questions,
in the pillow as you can see.

282
00:19:08,585 --> 00:19:11,525
And it does the same for
other pillars as well.

283
00:19:11,795 --> 00:19:15,375
So in this particular case, it did
identify the best practice, from

284
00:19:15,375 --> 00:19:18,645
the well architected framework
in the document, which was to use

285
00:19:18,645 --> 00:19:21,295
separate workloads using, accounts.

286
00:19:21,795 --> 00:19:26,775
And in here it gives you citations and
risks, and it does it for all the pillars

287
00:19:26,775 --> 00:19:28,365
that were selected for the review.

288
00:19:28,865 --> 00:19:31,145
Let's have a quick look
at, the Deep Review.

289
00:19:31,645 --> 00:19:34,225
The deep review works, in a
similar fashion you have called

290
00:19:34,225 --> 00:19:38,365
the summary or metadata information
followed by solution summary.

291
00:19:39,005 --> 00:19:44,965
then you, it gives, it responds with,
the same, kind of structure answering all

292
00:19:44,965 --> 00:19:47,095
the questions for the selected pillars.

293
00:19:47,905 --> 00:19:51,775
One thing that it doesn't do is
the risk because we want the well

294
00:19:51,775 --> 00:19:56,275
architected tool to reduce the risk
based on the choices that get selected.

295
00:19:56,775 --> 00:19:58,395
Otherwise, it's pretty much the same.

296
00:19:58,895 --> 00:19:59,185
Okay?

297
00:19:59,940 --> 00:20:01,560
And it does it for all the pillars.

298
00:20:02,060 --> 00:20:05,750
And let me select, the quick demo
too, which is just kicked off.

299
00:20:06,320 --> 00:20:09,560
So that's still in progress, but
as you can see, it has already

300
00:20:09,560 --> 00:20:10,820
created the solution summary.

301
00:20:11,600 --> 00:20:13,100
So it's created a summary.

302
00:20:13,100 --> 00:20:16,450
Now it's trying to answer individual
questions, and it's, take a

303
00:20:16,450 --> 00:20:17,730
little bit, time to do that.

304
00:20:17,760 --> 00:20:17,790
Okay.

305
00:20:18,290 --> 00:20:22,160
Another feature I wanted to
showcase to you, let me select,

306
00:20:22,170 --> 00:20:24,150
the deep, I can select any of them.

307
00:20:24,750 --> 00:20:25,770
Let me select the deep tab.

308
00:20:26,610 --> 00:20:31,800
Okay, so we talked about ability to
chat with the content and to understand,

309
00:20:32,060 --> 00:20:36,480
better understanding, have a deep dive,
of the review that has been carried out.

310
00:20:36,870 --> 00:20:39,870
And this is where this, chat
functionality is, super helpful.

311
00:20:40,380 --> 00:20:42,660
So let me select, the solution summary.

312
00:20:42,660 --> 00:20:45,550
So I would like to check with the
content that was, in the summary.

313
00:20:45,850 --> 00:20:52,080
So for example, I could say
which AWS regions are used.

314
00:20:52,580 --> 00:20:57,970
So as you can see, this information
isn't there already, so it should

315
00:20:57,970 --> 00:20:59,770
be able to reduce this very quickly.

316
00:21:00,130 --> 00:21:00,700
So that's fine.

317
00:21:00,700 --> 00:21:07,320
This is good, but if I say,
which AWS EC2 instances are used.

318
00:21:07,820 --> 00:21:12,110
Then of course this document, this con
this information is not then in the

319
00:21:12,110 --> 00:21:14,540
summary and ans is not able to find.

320
00:21:14,960 --> 00:21:18,650
So I could switch to the document
and ask the same question again

321
00:21:19,250 --> 00:21:20,600
and let's see what it does

322
00:21:21,100 --> 00:21:25,840
because, this is, this has been documented
in the solution architecture document

323
00:21:26,139 --> 00:21:29,469
is able to pick up that information
and provide me that, that data.

324
00:21:30,054 --> 00:21:35,595
This is quite a handy feature and this
you can do for, do it for, all, all of

325
00:21:35,595 --> 00:21:37,185
the sections that have been generated.

326
00:21:37,685 --> 00:21:38,014
Okay?

327
00:21:38,825 --> 00:21:42,944
So one of the things which I mentioned
earlier was, integration of the deep

328
00:21:42,944 --> 00:21:45,414
mode with, the well architected tool.

329
00:21:45,474 --> 00:21:50,004
So let me go to the well architected
tool in the AWS Management

330
00:21:50,004 --> 00:21:51,204
Console and show it to you.

331
00:21:51,704 --> 00:21:54,734
So this, I'm back, in the
console after sign out.

332
00:21:55,234 --> 00:22:00,804
If I go to the workloads, I can see
a workload and the name matches, with

333
00:22:00,804 --> 00:22:02,154
the review that we had carried out.

334
00:22:02,154 --> 00:22:05,474
So if I search for it, I
can see it's the, oops.

335
00:22:05,974 --> 00:22:07,564
Oh, I'll do the other way around.

336
00:22:07,624 --> 00:22:11,434
I'll select it from here
and search it there.

337
00:22:12,124 --> 00:22:13,024
Just to prove the point.

338
00:22:13,024 --> 00:22:14,614
yeah, so it's essentially the same.

339
00:22:15,114 --> 00:22:16,644
So if I click on this.

340
00:22:17,144 --> 00:22:19,994
This was purely generated
by the Vapor Accelerator.

341
00:22:20,344 --> 00:22:22,954
the sample itself, we didn't do anything.

342
00:22:22,954 --> 00:22:25,354
We just created a review
in the application.

343
00:22:25,744 --> 00:22:27,214
And this is what it has done.

344
00:22:27,604 --> 00:22:32,544
And if you see, what it does is,
it goes in and creates a workload,

345
00:22:33,024 --> 00:22:36,914
answers, all the questions or tries to
on, try to answer all the questions,

346
00:22:37,364 --> 00:22:39,944
and then it creates a milestone.

347
00:22:40,359 --> 00:22:41,229
for it as well.

348
00:22:41,360 --> 00:22:45,529
this was a baseline, version that
was created in Geni and you could

349
00:22:45,529 --> 00:22:49,399
start to build on it as part of your
human review, human review process.

350
00:22:50,060 --> 00:22:51,709
So I could go in there.

351
00:22:52,100 --> 00:22:55,879
There's an, I want to show
you a, an interesting feature.

352
00:22:55,879 --> 00:23:02,300
So I will go in there and
I'll look at the review.

353
00:23:02,800 --> 00:23:07,270
So in the very beginning, I told you that
you need to answer a set of foundational

354
00:23:07,480 --> 00:23:11,170
questions as part of the review, and
each of these questions typically

355
00:23:11,170 --> 00:23:13,210
have a number of choices underneath.

356
00:23:14,050 --> 00:23:15,850
So this is not something I've done.

357
00:23:15,909 --> 00:23:20,590
What we have done is we ask the
LM to say, Hey, when you are doing

358
00:23:20,590 --> 00:23:24,879
an assessment or trying to answer
this question, can you also answer?

359
00:23:25,269 --> 00:23:30,340
in terms of, or select the choices that
are applicable based on your assessment.

360
00:23:30,610 --> 00:23:36,059
So these, tick marks or these choices
were actually, done by the l and m itself.

361
00:23:36,659 --> 00:23:38,939
And as you can see, not all
of them have been selected,

362
00:23:39,439 --> 00:23:41,060
and it does it for all of them.

363
00:23:41,899 --> 00:23:46,489
And the good feature or another
feature is that the population notes.

364
00:23:46,820 --> 00:23:51,439
So you, you get the assessment in the
application, but at the same time, the

365
00:23:51,559 --> 00:23:56,990
generated assessment is also populated,
in the node section as you can see.

366
00:23:57,490 --> 00:23:59,620
And it does it for all the
questions for the pillars.

367
00:23:59,620 --> 00:24:02,459
So let me go back to, the review.

368
00:24:02,760 --> 00:24:04,620
So what I could do in here is.

369
00:24:05,490 --> 00:24:08,130
Go back to that and generate a report.

370
00:24:08,630 --> 00:24:11,990
Okay, so this is the report which
I've generated from console.

371
00:24:12,490 --> 00:24:19,050
So if you look at this, it has
made some choices based on the gen

372
00:24:19,050 --> 00:24:21,710
assessments and as a result of that.

373
00:24:22,429 --> 00:24:23,780
Those are all the questions.

374
00:24:24,350 --> 00:24:27,460
So going back to the console.

375
00:24:28,000 --> 00:24:34,850
So if we look, the choices have resulted
in a number of risks, in response to

376
00:24:34,850 --> 00:24:40,485
the choices that gen AI things, are
applicable or have been, implemented.

377
00:24:40,985 --> 00:24:44,755
And as a result of, ruling out the
ones which have not been selected by

378
00:24:44,755 --> 00:24:47,545
Geni, the tool has generated risks.

379
00:24:47,755 --> 00:24:52,415
So if I go and, click on that, I
can see those risks underneath,

380
00:24:52,545 --> 00:24:53,535
the individual questions.

381
00:24:54,035 --> 00:24:58,065
So just to summarize, what I
did was, I went in, I uploaded

382
00:24:58,065 --> 00:24:59,415
an architecture document.

383
00:24:59,955 --> 00:25:05,385
I carried out, a deep review, it,
and after a while it created an

384
00:25:05,385 --> 00:25:11,945
assessment, in the UI as well as it
has created a well architected workload

385
00:25:12,275 --> 00:25:18,965
with a milestone that you can use as
part of your human review process.

386
00:25:19,465 --> 00:25:20,995
Let's go back to the presentation.

387
00:25:21,495 --> 00:25:23,745
Let's see what's happening
behind the scene.

388
00:25:23,745 --> 00:25:25,125
You've seen the ui now.

389
00:25:25,625 --> 00:25:29,015
This is, the overall architecture
for Wafer Accelerator.

390
00:25:29,515 --> 00:25:35,205
So if you recall, we talked, we looked
at the basics, of, rag architecture, and

391
00:25:35,205 --> 00:25:37,785
the first step is to do a data ingestion.

392
00:25:38,370 --> 00:25:42,810
So as part of this, what we do is, we
download the files, the PDF file format

393
00:25:43,050 --> 00:25:49,540
from AWS public website, put it into
an S3 bucket, and use, a Amazon Bedrock

394
00:25:49,600 --> 00:25:52,040
knowledge base, and ingest it into that.

395
00:25:52,540 --> 00:25:56,950
And the way it works out is, the
embeddings are created and they are stored

396
00:25:56,950 --> 00:26:01,450
in Amazon open search for serverless,
which acts as the vector database.

397
00:26:01,690 --> 00:26:06,570
So the embeddings are stored within the
open search serverless, vector database.

398
00:26:07,070 --> 00:26:10,450
And this is done as part of
the CDK, deployment itself.

399
00:26:10,450 --> 00:26:12,760
So you don't have to do it
separately unless you want to

400
00:26:12,760 --> 00:26:17,310
update, to a later version, of well
architected framework, in the future.

401
00:26:17,810 --> 00:26:20,720
So the second part is, which
I just showed it to you.

402
00:26:20,720 --> 00:26:24,140
So we have developed an application
using a streamlet, which runs on

403
00:26:24,140 --> 00:26:29,800
an EC2 instance, and it's fronted
front, front-ended by, application

404
00:26:29,800 --> 00:26:32,080
load balancer and cloud front.

405
00:26:32,770 --> 00:26:36,640
We have created, we have integrated
the web with the initial set of

406
00:26:36,640 --> 00:26:39,520
rules, which you would like to
enhance based on your requirements.

407
00:26:39,890 --> 00:26:42,020
and then you have got the
Amazon cognitive user pool.

408
00:26:42,020 --> 00:26:45,770
So if you recall, I log in the
application using a fictitious user,

409
00:26:46,050 --> 00:26:47,520
but I had to provise in that user.

410
00:26:47,520 --> 00:26:51,610
So that pool is created as
part of the IEC, but, you need

411
00:26:51,610 --> 00:26:53,290
to park provision the users.

412
00:26:54,040 --> 00:26:56,080
So once the document, is, uploaded.

413
00:26:56,420 --> 00:26:58,100
or submitted for review.

414
00:26:58,580 --> 00:27:03,550
It gets uploaded to an Amazon
S3 bucket and an S3, and the

415
00:27:03,550 --> 00:27:07,510
application sends an SQS message
out to trigger the WA for review.

416
00:27:08,500 --> 00:27:12,820
This message, SQS message is received
or, received by a lambda function,

417
00:27:13,240 --> 00:27:17,260
and that in turn, invokes, the
wafer review, step functions, which

418
00:27:17,260 --> 00:27:19,030
is the heart of this, reviewer.

419
00:27:19,615 --> 00:27:24,415
And, if it happens to be a well
architected, sorry, a deep, review

420
00:27:24,655 --> 00:27:28,225
in that case, what it does is at this
point in time, it goes and creates

421
00:27:28,225 --> 00:27:30,665
an empty, workload in the tool.

422
00:27:31,165 --> 00:27:35,535
The next step, in the process is to get
the cont extract the document content.

423
00:27:35,595 --> 00:27:41,225
For this, we are using Amazon, text track,
and, Once the data has been extracted,

424
00:27:41,525 --> 00:27:47,125
it goes to step six, which is about in
working, retrieve, and in work APIs.

425
00:27:48,045 --> 00:27:52,365
So this is where, the query generation
happens, and we'll look at it in a

426
00:27:52,365 --> 00:27:53,925
little bit more detail in the next slide.

427
00:27:54,285 --> 00:27:58,825
But the idea in here is to retrieve
the relevant in buildings, based

428
00:27:58,825 --> 00:28:00,985
on the question in context.

429
00:28:01,375 --> 00:28:06,165
And then, argument the query the
prompt or say that we have developed

430
00:28:06,315 --> 00:28:10,845
with that information and the uploaded
document content, and ask the l and

431
00:28:10,845 --> 00:28:12,995
m to answer those que the question.

432
00:28:13,495 --> 00:28:17,855
So let's, take an example, of, the first
SEC question from the security pillar.

433
00:28:18,325 --> 00:28:20,780
when this is, this, is, being reviewed.

434
00:28:21,740 --> 00:28:25,240
first step in there is to find
the relevant, data from the

435
00:28:25,240 --> 00:28:28,610
data, from the knowledge base
for this particular questions.

436
00:28:29,000 --> 00:28:32,780
And all the passages that have been
found are then ranked based on the

437
00:28:32,780 --> 00:28:38,070
relevance, and then this is added, to
the context, as a context, in the query,

438
00:28:38,310 --> 00:28:40,140
which is passed on to the l and m.

439
00:28:40,640 --> 00:28:43,760
The review progresses, the staff
function keeps on updating,

440
00:28:44,010 --> 00:28:46,780
individual, questions, within the tool.

441
00:28:47,110 --> 00:28:48,780
If it's a deep, review.

442
00:28:49,050 --> 00:28:53,739
If it's not a deep review, the
information is stored purely in Dymo db.

443
00:28:54,049 --> 00:28:56,359
in case of D Deep, it's
stored in both the places.

444
00:28:57,054 --> 00:28:59,954
The next step there is
to, refresh the screen.

445
00:28:59,954 --> 00:29:04,334
as you were saying, and I was checking
the status so the UI can, user users

446
00:29:04,334 --> 00:29:08,054
can always refresh the screen and
check the progress of the reviews.

447
00:29:08,554 --> 00:29:12,514
Then I showcase you the chat
functionality wherein I went in

448
00:29:12,514 --> 00:29:15,635
and asked a few questions and it
answered for me based on the content,

449
00:29:15,884 --> 00:29:17,804
that was generated, by the review.

450
00:29:18,304 --> 00:29:22,404
And it also created a milestone
in the well architected, tool.

451
00:29:22,494 --> 00:29:26,544
I showed it to you earlier, and
that becomes a starting point.

452
00:29:26,544 --> 00:29:31,544
It could become your starting point,
for, in the human review process.

453
00:29:32,044 --> 00:29:35,519
So this is, the overall,
architecture, for, way for

454
00:29:35,519 --> 00:29:37,939
accelerator with, Numbering around it.

455
00:29:38,439 --> 00:29:40,509
Let me show you a couple of things there.

456
00:29:40,779 --> 00:29:44,724
so in terms of resources,
we have created a. in here.

457
00:29:44,784 --> 00:29:47,814
So I've co-authored a blog
with my colleagues, British

458
00:29:47,814 --> 00:29:49,804
Patti and Rohan, goosh.

459
00:29:50,259 --> 00:29:54,099
we have also released, this way for
accelerator sample under AWS samples.

460
00:29:54,429 --> 00:29:58,359
It means, if you want to explore more,
you can read through the book, which

461
00:29:58,359 --> 00:30:00,249
provides a lot more detail than the demo.

462
00:30:00,639 --> 00:30:04,449
And then, you can download
the samples and, explore that.

463
00:30:04,949 --> 00:30:07,259
So let me show you that blog very quickly.

464
00:30:07,759 --> 00:30:10,379
So this is a blog, I've
shared the link for that.

465
00:30:10,379 --> 00:30:11,219
You can have a look.

466
00:30:11,849 --> 00:30:17,349
And this is the AWS sample, which
has got lot more, and detailed

467
00:30:17,349 --> 00:30:21,339
information on how to go about
deploying and, exploring the sample.

468
00:30:21,839 --> 00:30:22,939
So this is, the block.

469
00:30:23,119 --> 00:30:24,199
I'll just show it to you.

470
00:30:24,699 --> 00:30:27,669
So before we conclude,
let's, have a quick recap.

471
00:30:28,119 --> 00:30:32,479
We started with, AWS well architected
framework, the pillars and

472
00:30:32,479 --> 00:30:36,879
lenses, scaling opportunities as
you expand your cloud footprint.

473
00:30:37,379 --> 00:30:41,429
And how generative AI could provide
answers for some of the scaling,

474
00:30:41,709 --> 00:30:43,839
opportunities for the reviews.

475
00:30:44,289 --> 00:30:48,819
And we, I showcased you the way for
accelerator, which, demonstrate,

476
00:30:48,869 --> 00:30:53,089
the art of possible, when it
comes to, reviewing using Gen ai.

477
00:30:53,589 --> 00:30:55,869
So this brings me to the
end of this presentation.

478
00:30:55,929 --> 00:30:58,419
I thank you all for, joining the session.

479
00:30:59,409 --> 00:30:59,829
Thanks.

480
00:30:59,979 --> 00:31:00,309
Bye.

