1
00:00:00,500 --> 00:00:02,690
Hello everyone, and
thank you for turning in.

2
00:00:03,260 --> 00:00:06,620
I'm m Pravin Kana, a
senior software engineer.

3
00:00:07,310 --> 00:00:11,750
In this session, I will walk you
through a simple but powerful idea.

4
00:00:12,530 --> 00:00:17,180
What if you could define and
run an entire quantum experiment

5
00:00:17,600 --> 00:00:19,100
from a single JSON file?

6
00:00:20,000 --> 00:00:21,230
No more learning notebooks.

7
00:00:21,530 --> 00:00:24,560
Updating brittle scripts or
writing pipelines by hand.

8
00:00:24,830 --> 00:00:30,620
Instead, we'll explore a schema driven
approach that helps researchers move

9
00:00:30,620 --> 00:00:35,750
faster, build repeatable processes,
and gain built-in observability.

10
00:00:36,560 --> 00:00:40,460
This is all without writing
front end or orchestration code.

11
00:00:40,960 --> 00:00:46,275
Quantum research moves fast,
new hardware circuit designs.

12
00:00:46,570 --> 00:00:52,120
Error mitigation techniques emerge
constantly, but our tooling often

13
00:00:52,180 --> 00:00:57,130
lags behind copying notebooks
create fraile dependencies.

14
00:00:57,520 --> 00:01:02,139
Document documentation drifts as
experiments evolve and auditing

15
00:01:02,139 --> 00:01:04,090
becomes nearly impossible.

16
00:01:04,750 --> 00:01:12,065
This slide captures the problem, constant
change in parameter and hardware, hidden

17
00:01:12,160 --> 00:01:15,160
dependencies and logic buried in scripts.

18
00:01:15,610 --> 00:01:21,070
Inconsistent documentation and
a series serious compliance

19
00:01:21,430 --> 00:01:23,470
headache for regular industries.

20
00:01:23,970 --> 00:01:28,350
To solve these challenges, we
built a schema driven framework.

21
00:01:29,100 --> 00:01:34,350
At its core is a single adjacent schema,
a machine readable contract that defines

22
00:01:34,590 --> 00:01:37,259
what an experiment can and cannot accept.

23
00:01:37,979 --> 00:01:41,400
From this schema, we auto
generate three things.

24
00:01:41,670 --> 00:01:42,060
First.

25
00:01:42,899 --> 00:01:44,189
React based waveform.

26
00:01:44,639 --> 00:01:48,029
So scientists never
touch HTML or JavaScript.

27
00:01:48,449 --> 00:01:52,649
Second, a step functions
workflow to execute circuits and

28
00:01:52,649 --> 00:01:55,350
post-process data, all serverless.

29
00:01:55,829 --> 00:01:57,749
Third, a lineage tracker.

30
00:01:58,350 --> 00:01:59,999
Every run is tagged.

31
00:02:00,029 --> 00:02:01,289
Versioned traceable.

32
00:02:01,979 --> 00:02:07,739
This means researchers are just a
manifest, not a monolith of scripts.

33
00:02:08,239 --> 00:02:10,879
Here is how it all fits together.

34
00:02:11,659 --> 00:02:19,339
The Chason schema is stored in AWS
S3 with object lock enabled, ensuring

35
00:02:19,489 --> 00:02:22,579
it is versioned and also immutable.

36
00:02:23,179 --> 00:02:26,119
A-C-I-C-D pipeline
triggers two generators.

37
00:02:26,569 --> 00:02:33,229
One builds the react portal, the other
compiles a step function state machine.

38
00:02:34,039 --> 00:02:36,919
The state machine calls Amazon Rocket.

39
00:02:37,744 --> 00:02:43,714
To run quantum jobs, invokes for gate
containers for post-processing and stores.

40
00:02:43,834 --> 00:02:47,394
Results in S3 observability
is handled by open Telemetry

41
00:02:47,484 --> 00:02:48,984
with the dashboards in Grafana.

42
00:02:49,484 --> 00:02:55,454
This system is modular, serverless, and
also designed for scale and traceability.

43
00:02:55,954 --> 00:02:59,014
On the right side, you can
see the architectural diagram

44
00:02:59,074 --> 00:03:00,454
and the components involved.

45
00:03:00,954 --> 00:03:05,244
Let's compare traditional workflows
with our schema driven approach.

46
00:03:05,844 --> 00:03:07,584
On the left is a notebook model.

47
00:03:07,974 --> 00:03:09,534
Everything is hand coded.

48
00:03:09,714 --> 00:03:15,384
The device on circuit chart
and output path, it works,

49
00:03:15,834 --> 00:03:18,294
but it's Frazy and error Pro.

50
00:03:19,014 --> 00:03:23,604
Also, every time some parameter
has to be changed, this notebook

51
00:03:23,664 --> 00:03:25,554
model has to be updated.

52
00:03:26,054 --> 00:03:30,194
The right is a compact J in
schema, 30 lines that describe

53
00:03:30,194 --> 00:03:31,784
the entire experiment set.

54
00:03:32,324 --> 00:03:37,814
The schema is used across the ui, the
workflow, and the validation logic.

55
00:03:38,024 --> 00:03:42,404
Instead of cloning and modifying
notebooks, research, fill out a form

56
00:03:42,404 --> 00:03:46,154
that is guaranteed to be a valid one.

57
00:03:46,654 --> 00:03:50,464
This approach unlocks
four big benefits First.

58
00:03:50,964 --> 00:03:53,934
Parameter exploration
becomes safe and structured.

59
00:03:54,264 --> 00:03:57,054
No invalid values, no runtime surprises.

60
00:03:57,554 --> 00:04:03,344
And the second one, collaboration
improves Schemas are version in git

61
00:04:03,884 --> 00:04:05,804
with pull requests and differences.

62
00:04:06,304 --> 00:04:09,964
Number three, configuration
errors go to chiro because

63
00:04:09,964 --> 00:04:12,169
schema validation runs upfront.

64
00:04:13,029 --> 00:04:13,319
Four.

65
00:04:14,060 --> 00:04:16,159
Onboarding is dramatically faster.

66
00:04:16,459 --> 00:04:21,380
New team members don't need to
learn your SDKs or internal scripts.

67
00:04:21,500 --> 00:04:24,380
They simply open a form and run.

68
00:04:25,190 --> 00:04:28,280
You get governance
without sacrificing speed

69
00:04:28,780 --> 00:04:28,999
to.

70
00:04:28,999 --> 00:04:34,634
To test this in real world, we
ran a 1 million shot VQE Sweep.

71
00:04:35,504 --> 00:04:38,775
This bar chart shows the
results across five metrics.

72
00:04:38,864 --> 00:04:39,674
Let's walk through it.

73
00:04:40,174 --> 00:04:45,604
On the far left set up time, the time
to prepare a single parametal variant

74
00:04:46,084 --> 00:04:50,764
dropped from 18 minutes with notebooks to
just three minutes with a schema portal.

75
00:04:51,424 --> 00:04:57,004
Next is wall clock time, total
runtime for the entire suite, which

76
00:04:57,004 --> 00:05:00,694
dropped from 13.4 s to 11.8 hours.

77
00:05:01,144 --> 00:05:05,405
That improvement comes from better
concurrency and simulator fallback.

78
00:05:05,905 --> 00:05:08,815
When QPU queues are logged.

79
00:05:09,534 --> 00:05:11,484
Third is a configuration errors.

80
00:05:11,844 --> 00:05:16,465
We went from seven errors in the
baseline to zero, which is a huge win.

81
00:05:17,335 --> 00:05:18,174
Then cost.

82
00:05:18,354 --> 00:05:23,424
The schema workflow saved around 200
USD largely due to more efficient

83
00:05:23,424 --> 00:05:25,614
execution and fewer retries.

84
00:05:26,125 --> 00:05:31,634
Finally, learnability researchers
rated the schema portal 4.8 out

85
00:05:31,634 --> 00:05:33,739
of five compared to 3.1 for the.

86
00:05:34,620 --> 00:05:39,999
Notebooks here, the learning is basically
straightforward for the researchers.

87
00:05:40,780 --> 00:05:43,150
These aren't synthetic benchmarks.

88
00:05:43,330 --> 00:05:48,309
They are based on real world jobs
running on a bracket with simulator file

89
00:05:48,309 --> 00:05:50,530
back and post-processing in Fargate.

90
00:05:50,784 --> 00:05:51,075
From

91
00:05:51,575 --> 00:05:55,475
an engineering standpoint, this
system is compact and maintainable.

92
00:05:56,015 --> 00:05:57,875
We use three CDK stacks.

93
00:05:58,355 --> 00:06:01,655
One for frontend portal, one
for the state machine pipeline

94
00:06:01,805 --> 00:06:03,635
and one for observability.

95
00:06:04,235 --> 00:06:08,495
The schema file itself is
tiny, about 3 75 bytes.

96
00:06:09,215 --> 00:06:13,225
The React bundle is 1.2
kb after it's jipped.

97
00:06:13,375 --> 00:06:18,285
Using the GGP, the state
machine is six KBG sn with.

98
00:06:18,675 --> 00:06:22,905
23 states fi service integrations
and no Lambda functions.

99
00:06:23,325 --> 00:06:25,215
We test locally using local stack.

100
00:06:25,635 --> 00:06:29,535
They apply with GitHub actions and
run cost effectively within AWS free

101
00:06:29,535 --> 00:06:32,265
tier for most dev and test scenarios.

102
00:06:32,765 --> 00:06:33,724
This is just the beginning.

103
00:06:34,265 --> 00:06:36,575
We are expanding in
three major directions.

104
00:06:37,145 --> 00:06:37,594
First.

105
00:06:38,450 --> 00:06:40,280
Enabling multi key MA chaining.

106
00:06:40,430 --> 00:06:44,630
So teams can compose multi-stage
pipelines where output from one

107
00:06:44,630 --> 00:06:51,860
experiment feeds into another second,
I'm adding post quantum encryption.

108
00:06:52,360 --> 00:06:56,500
The results will be automatically
encrypted with VER aligning

109
00:06:56,500 --> 00:06:58,990
with net post quantum standards.

110
00:06:59,490 --> 00:07:02,435
Third, we are making
workflow cloud portable.

111
00:07:02,935 --> 00:07:09,125
We will support backend Azure Quantum,
Google Circ using the same schema and ui.

112
00:07:09,484 --> 00:07:14,435
This will let researchers focus on
science, not the infrastructure.

113
00:07:14,935 --> 00:07:17,065
Thank you for spending time with me today.

114
00:07:17,545 --> 00:07:21,415
Schema driven experiment portals
bring structure automation

115
00:07:21,595 --> 00:07:23,425
observability to quantum research.

116
00:07:23,695 --> 00:07:27,475
Without slowing scientists down,
you gain auditability, cost

117
00:07:27,475 --> 00:07:31,915
control, and repeatability while
freeing your team from code.

118
00:07:32,395 --> 00:07:36,625
If you're working on quantum workflows,
I would love to connect and share

119
00:07:36,625 --> 00:07:38,815
con code patterns or blueprints.

120
00:07:39,315 --> 00:07:41,955
Thanks again and enjoy the rest of Con 42.

121
00:07:42,315 --> 00:07:43,849
Quantum Computing 2025.

