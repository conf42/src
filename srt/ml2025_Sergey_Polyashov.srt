1
00:00:01,410 --> 00:00:02,220
Hello everyone.

2
00:00:02,520 --> 00:00:07,170
My name is Sergey, and today I'd like to
talk about modern approach to search and

3
00:00:07,170 --> 00:00:11,190
recommendation systems and highlight some
of the scaling challenges and how they

4
00:00:11,190 --> 00:00:16,079
can be addressed based on my hands-on
experience over the years, I have led

5
00:00:16,079 --> 00:00:19,860
work on video search, personalized video
recommendations, and product search at

6
00:00:19,860 --> 00:00:21,780
companies like Yandex and Microsoft.

7
00:00:22,500 --> 00:00:26,370
This presentation is fairly short,
so I'll focus only on the most

8
00:00:26,370 --> 00:00:28,050
fundamental problems and solutions.

9
00:00:28,770 --> 00:00:32,250
Each of these topics deserves
a separate deep dive.

10
00:00:32,460 --> 00:00:35,160
If you have questions, feel
free to reach out to me.

11
00:00:36,360 --> 00:00:40,019
This talk covers the core ideas
behind machine learning, powered

12
00:00:40,019 --> 00:00:44,940
search and recommendation systems
from why they matter and how

13
00:00:44,940 --> 00:00:46,950
they are built, rank and scaled.

14
00:00:47,760 --> 00:00:52,535
We'll look at key models, system design
practices, and recent trends shaping

15
00:00:52,635 --> 00:00:54,570
the future of recommender technologies.

16
00:00:55,565 --> 00:00:59,550
Search and recommendation system are
essential for helping user navigate

17
00:00:59,550 --> 00:01:01,980
huge catalogs of content or products.

18
00:01:02,520 --> 00:01:06,360
They reduce information overload
and improve the user experience

19
00:01:06,360 --> 00:01:08,430
by surfacing and relevant items.

20
00:01:08,910 --> 00:01:13,950
They also drive key business metrics,
more clicks, purchases, and return visits,

21
00:01:14,280 --> 00:01:19,770
and help optimize for long-term value
using tech techniques like reinforcement

22
00:01:19,770 --> 00:01:22,530
learning and the impact is clear.

23
00:01:23,175 --> 00:01:29,985
30% of YouTube views, 35 of Amazon
purchases, and 80% of Netflix watches

24
00:01:30,285 --> 00:01:32,025
all come from recommendations.

25
00:01:32,414 --> 00:01:34,485
These systems are not just useful.

26
00:01:34,575 --> 00:01:37,305
They are critical to
modern digital platforms.

27
00:01:38,535 --> 00:01:42,045
When evaluating search and
recommendation systems, we often

28
00:01:42,045 --> 00:01:43,545
look at two types of goals.

29
00:01:43,635 --> 00:01:45,105
Short term and long term.

30
00:01:45,705 --> 00:01:48,675
Short term target are based
on immediate user actions.

31
00:01:48,975 --> 00:01:51,525
Things like clicks, time, or purchases.

32
00:01:52,215 --> 00:01:57,105
These are easy to track and give us
quick feedback, but if you focus only on

33
00:01:57,465 --> 00:02:02,745
them, we risk our fitting to short-term
interests and ignoring real user value.

34
00:02:03,525 --> 00:02:07,425
Long-term targets are about
user satisfaction over time.

35
00:02:08,084 --> 00:02:13,030
They are harder to measure, but they
better reflect user value, true value,

36
00:02:13,515 --> 00:02:18,345
such as retention, subscription,
continuation, or content diversity.

37
00:02:19,245 --> 00:02:24,105
These metrics encourage exploration
and help build loyal users.

38
00:02:24,645 --> 00:02:29,015
In short-term metrics are helpful,
but long-term metrics are what

39
00:02:29,015 --> 00:02:31,265
really drives sustainable success.

40
00:02:32,675 --> 00:02:34,715
Let's take a look at big picture.

41
00:02:35,255 --> 00:02:39,515
This is a high level architecture of
a typical machine learning powered

42
00:02:39,515 --> 00:02:41,135
search and recommendation system.

43
00:02:41,795 --> 00:02:47,225
At the top, we have the server layer,
which is the heart of real time response.

44
00:02:48,155 --> 00:02:53,405
It includes entity generation, which Rie
a manageable set of potentially relevant

45
00:02:53,495 --> 00:03:00,365
items, future feature generation, which
builds feature season, user query, and

46
00:03:00,365 --> 00:03:06,665
item data and models and business rules
where ranking models, score candidates,

47
00:03:07,085 --> 00:03:11,825
and business logic handles diversity,
exploration and cold start cases.

48
00:03:13,295 --> 00:03:18,065
These are the blocks we'll focus on
for the rest of the presentation.

49
00:03:18,395 --> 00:03:20,045
Any degeneration and ranking.

50
00:03:20,945 --> 00:03:26,975
Now, let's zoom out for a second and
look at the full loop and at the input we

51
00:03:26,975 --> 00:03:32,675
have user data, que items and real time
events coming through a data procession.

52
00:03:33,305 --> 00:03:38,105
That's how con, that's how context
and behavior enter the system.

53
00:03:39,020 --> 00:03:41,870
Equally important is the
login infrastructure.

54
00:03:42,410 --> 00:03:45,800
Everything users do,
clicks, scrolls, dwell.

55
00:03:45,800 --> 00:03:49,430
Time is locked and sent
into offline pipelines.

56
00:03:49,850 --> 00:03:50,810
Why is that important?

57
00:03:51,260 --> 00:03:55,430
Because we rely on this data for
training, evaluation, and experimentation.

58
00:03:56,030 --> 00:04:00,530
If you log incorrectly, we will
train on biased and broken labels,

59
00:04:00,680 --> 00:04:02,630
which directly hear systems quality.

60
00:04:03,890 --> 00:04:07,490
In the training pipeline, we
apply labeling strategies, some

61
00:04:07,490 --> 00:04:12,320
manual, some assisted by LLMs
and train our models season full.

62
00:04:12,320 --> 00:04:18,470
The training or active learning or online
updates at the bottom, we measure success.

63
00:04:19,010 --> 00:04:24,110
That includes both offline metrics,
like how, and this and d, g, and online

64
00:04:24,110 --> 00:04:26,689
metrics like CTR, time spent and revenue.

65
00:04:27,289 --> 00:04:28,770
The top the loop.

66
00:04:29,340 --> 00:04:34,020
Is closed by using these metrics to
guide further model improvements.

67
00:04:34,800 --> 00:04:38,550
So again, in this talk, we'll
go deeper into the Kennedy

68
00:04:38,550 --> 00:04:40,320
generation and ranking layers.

69
00:04:40,620 --> 00:04:44,670
But keep in mind the rest of this
architecture is equally critical to

70
00:04:44,670 --> 00:04:50,460
building a successful system to make
recommendations at scale, we use a

71
00:04:50,460 --> 00:04:52,605
multi-stage retrieval and Rankin funnel.

72
00:04:53,175 --> 00:04:54,344
The idea is simple.

73
00:04:54,735 --> 00:04:59,115
We start with millions or even billions
of items and progressively narrow

74
00:04:59,115 --> 00:05:04,305
them down to just the top 50 or so
that we actually show to the user.

75
00:05:04,785 --> 00:05:07,125
Let's walk through each stage.

76
00:05:08,025 --> 00:05:11,025
We begin with user profile
and query understanding.

77
00:05:11,595 --> 00:05:13,005
This gives us context.

78
00:05:13,575 --> 00:05:15,495
What has the user done in the past?

79
00:05:15,885 --> 00:05:17,925
What are they looking for right now?

80
00:05:18,690 --> 00:05:21,420
Then we move into candidate generation.

81
00:05:21,630 --> 00:05:24,120
This stage focuses on high recall.

82
00:05:24,480 --> 00:05:27,360
We want to gather as many
relevant items as possible.

83
00:05:27,750 --> 00:05:33,180
The goal here is to cast a wide
net and collect around 10 K items.

84
00:05:33,720 --> 00:05:37,590
We also factor in things like
diversity, freshness, and popularity.

85
00:05:39,135 --> 00:05:40,635
Next is pre ranking.

86
00:05:41,385 --> 00:05:46,815
At this point, we filter down from
10 K to roughly one K items using

87
00:05:46,815 --> 00:05:52,125
lightweight models, often gradient boosted
decision trees or fast neural networks.

88
00:05:52,605 --> 00:05:56,445
We are still optimizing for a
call and diversity here, but the

89
00:05:57,255 --> 00:05:58,965
computation needs to be fast.

90
00:05:59,925 --> 00:06:04,875
In L two and L three layers,
we do the heavy lifting.

91
00:06:05,505 --> 00:06:11,295
These stages use complex models like
deep neural networks or transformers to

92
00:06:11,295 --> 00:06:16,845
evaluate each of those one key candidates
in depth and select the top 50 or so.

93
00:06:17,745 --> 00:06:23,535
The key metrics here is NDCG, which
reflects ranking, quality and relevance.

94
00:06:24,165 --> 00:06:24,735
Finally.

95
00:06:25,635 --> 00:06:29,835
Ranking stage where we applied business
rules, for example, to increase

96
00:06:29,835 --> 00:06:34,995
category diversity or boost new items
to ensure legal and policy compliance.

97
00:06:36,255 --> 00:06:41,865
What is powerful about this funnel is that
it balance performance and efficiency.

98
00:06:42,765 --> 00:06:47,865
We use simple models early for
speed and heavy models later for

99
00:06:47,865 --> 00:06:51,044
accuracy, so the system stays fast.

100
00:06:52,065 --> 00:06:55,335
Stays fast, but delivers
high quality results.

101
00:06:57,195 --> 00:07:01,815
Once we understood the query end
user profile, the first step in the

102
00:07:01,815 --> 00:07:03,615
pipeline is candidate generation.

103
00:07:04,605 --> 00:07:08,985
The goal here is to select a small,
manageable set of that, typically

104
00:07:09,045 --> 00:07:14,445
thousands of items from a catalog
that may contain million or even

105
00:07:14,445 --> 00:07:16,305
billions or sometime trillions.

106
00:07:16,815 --> 00:07:17,325
Items.

107
00:07:18,015 --> 00:07:20,040
These steps needs to be fast.

108
00:07:20,955 --> 00:07:24,015
Provide higher goal
and maintain diversity.

109
00:07:25,215 --> 00:07:29,085
There are several approach
to do so efficiently.

110
00:07:30,315 --> 00:07:35,685
First, we have NN or approximate
nearest neighbor search, which finds

111
00:07:35,685 --> 00:07:38,025
the closest items in embedded space.

112
00:07:38,595 --> 00:07:45,675
Popular libraries include phase from meta
and scan from Google with fast algorithms

113
00:07:45,675 --> 00:07:47,985
like HNSV, which is the most popular.

114
00:07:49,635 --> 00:07:54,540
A N relies on good embeds, which we can
get from collaborative filtering like

115
00:07:54,600 --> 00:07:59,790
a LS Alterna three squares, which is
fast, but struggles with call starts and

116
00:07:59,880 --> 00:08:04,740
content based models such as two tower
architectures based on DSM or bird.

117
00:08:05,760 --> 00:08:10,890
Another method is random book,
which discovers related items

118
00:08:10,890 --> 00:08:12,330
by walking through a graph.

119
00:08:12,720 --> 00:08:15,090
It's good for diversity
and Goldstar problems.

120
00:08:15,465 --> 00:08:20,715
Though a bit outdated in modern
systems, in search-based systems,

121
00:08:20,775 --> 00:08:25,575
we often use ANOR Index, which
maps query terms to documents.

122
00:08:25,995 --> 00:08:31,395
This scales extremely well to trillions
of items thanks to techniques like term

123
00:08:31,395 --> 00:08:39,179
charting and BM 25 based stren and q.
Finally, don't underestimate heuristics.

124
00:08:39,689 --> 00:08:43,439
Simple based filters like
popularity, recency, or user

125
00:08:43,439 --> 00:08:47,490
subscriptions are still widely used,
especially when latency matters.

126
00:08:48,209 --> 00:08:52,140
The takeaway is there is no
one size fit all solution.

127
00:08:52,770 --> 00:08:58,020
Most production system combine multiple
methods and N Heuristics and angle index

128
00:08:58,199 --> 00:09:00,329
to balance performance coverage and.

129
00:09:02,535 --> 00:09:06,615
Once we generated a list of
candidates items, the next step

130
00:09:06,675 --> 00:09:12,495
is to rank them to decide what to
show and what other in what order.

131
00:09:13,485 --> 00:09:17,625
The goal of ranking is to sort the
candidates by relevance and other

132
00:09:17,625 --> 00:09:20,290
objectives like diversity or conversion.

133
00:09:21,285 --> 00:09:21,824
Conversion potential.

134
00:09:23,520 --> 00:09:28,590
There are two broad, two broad types of
optimization goals, short term metrics

135
00:09:28,590 --> 00:09:31,650
like D-C-G-M-R-R, or precision at key.

136
00:09:32,430 --> 00:09:37,080
These are widely used in industry
and are based on offline judgements

137
00:09:37,410 --> 00:09:38,910
and historical user behavior.

138
00:09:39,795 --> 00:09:43,605
And long-term metrics, which are
still an active research area.

139
00:09:44,145 --> 00:09:47,895
This includes approach like
reinforcement planning and sequence

140
00:09:47,895 --> 00:09:54,165
models that aim to optimize for
lifetime value or sustain engagement.

141
00:09:54,645 --> 00:09:55,185
Engagement.

142
00:09:57,105 --> 00:10:01,725
Let's look at the main approach
used gradient boosting decision.

143
00:10:01,725 --> 00:10:07,245
Tree models such as Boost or Lead
GBM are very popular in production.

144
00:10:07,635 --> 00:10:11,655
They're fast and Deb breathable and
work well on structured features.

145
00:10:12,165 --> 00:10:15,345
They are often used as
the final ran layout.

146
00:10:16,065 --> 00:10:20,775
On the other hand, deep neural networks
like DSM built and other transform

147
00:10:20,775 --> 00:10:26,265
based models can model more complex
interactions and are commonly used in

148
00:10:26,355 --> 00:10:31,875
upstream stages like NN, or as feature
generations for gradient boosting.

149
00:10:32,700 --> 00:10:35,100
Of course ranking isn't easy.

150
00:10:35,400 --> 00:10:38,189
It comes with several
challenges and biases.

151
00:10:38,670 --> 00:10:44,100
Biases such as label and position biases
come from implicit feedback like clicks.

152
00:10:44,640 --> 00:10:49,590
The coldstar problem when we lack
history for new user are, or items

153
00:10:50,189 --> 00:10:54,330
the classic trade between relevance
and diversity and another trade off

154
00:10:54,345 --> 00:10:56,314
exploration versus exploitation.

155
00:10:56,895 --> 00:11:01,860
Do we show what's already working or
do we help users discover new things?

156
00:11:02,565 --> 00:11:04,545
And adaptability is also a concern.

157
00:11:04,785 --> 00:11:06,945
Gradient boosting is easier to explain.

158
00:11:07,245 --> 00:11:12,135
While deep neural networks often
behave like black boxes, privacy

159
00:11:12,195 --> 00:11:13,575
is becoming more important.

160
00:11:14,055 --> 00:11:18,465
Many teams are exploring federated
learning to train models without

161
00:11:18,465 --> 00:11:19,905
centralizing sensitive data.

162
00:11:21,375 --> 00:11:22,605
And finally, latency.

163
00:11:22,995 --> 00:11:25,455
Deep models can heavy, can be heavy.

164
00:11:25,995 --> 00:11:30,255
So we need techniques like distillation
or caching to keep the system responsive.

165
00:11:31,230 --> 00:11:35,850
In practice, teams often combine
these methods using neural networks

166
00:11:35,970 --> 00:11:39,810
for representation and gradient
boosting for final scoring to

167
00:11:39,810 --> 00:11:41,490
get the best of both worlds.

168
00:11:42,870 --> 00:11:46,900
This slide shows a typical
architecture used for ranking in

169
00:11:46,900 --> 00:11:48,370
modern recommendation systems.

170
00:11:49,120 --> 00:11:52,120
We start on the left with input features.

171
00:11:52,480 --> 00:11:55,900
These include user features
like demographic or behavior

172
00:11:55,900 --> 00:11:57,940
signals, item features like.

173
00:11:58,314 --> 00:12:01,824
Price, popularity or category
interaction features.

174
00:12:01,824 --> 00:12:05,935
For example, how often the user has
interacted with similar items and

175
00:12:05,935 --> 00:12:11,665
textile signals like time of the day
or device type, and often a score

176
00:12:11,665 --> 00:12:16,074
from a lightweight to tower neural
network that helps preamp items.

177
00:12:17,395 --> 00:12:23,185
These features are then passed to a set
of gradient boosted decision three models.

178
00:12:24,295 --> 00:12:28,225
One model estimates
probability of relevance.

179
00:12:28,375 --> 00:12:32,455
Another model can predict the
probability that the user will

180
00:12:32,455 --> 00:12:34,645
click if the item is shown.

181
00:12:35,005 --> 00:12:38,125
And the third estimates
the conversion rate.

182
00:12:38,845 --> 00:12:44,965
If the user clicks, this course
can be combined into a final

183
00:12:44,965 --> 00:12:49,255
ranking score dependent on business
goals like engagement or revenue

184
00:12:50,065 --> 00:12:51,955
in more advanced appliance.

185
00:12:52,270 --> 00:12:58,090
We may also use a multitask deploy deep
neural network shown here at the bottom.

186
00:12:58,480 --> 00:13:02,440
This DNN is trained to predict the
same targets, relevant clicks and

187
00:13:02,440 --> 00:13:07,240
conversions, but it can model more
complex relationship and input.

188
00:13:08,305 --> 00:13:13,165
Finally, once we have LEAs,
we apply the ranking logic.

189
00:13:13,495 --> 00:13:17,694
This includes promotion diversity
towards showing too much of the same

190
00:13:17,694 --> 00:13:23,125
content, introducing exploration
to test new or less known items and

191
00:13:23,125 --> 00:13:27,714
applying business rules, for example,
to boost sponsor content or ensure

192
00:13:27,714 --> 00:13:30,324
policy compliance in production.

193
00:13:30,505 --> 00:13:32,245
This architecture is often hybrid.

194
00:13:33,055 --> 00:13:36,235
The DNN might be used offline or upstream.

195
00:13:36,910 --> 00:13:41,319
Gradient boosting remains the final
model for online serving due to

196
00:13:41,319 --> 00:13:43,270
its speed and interpretability.

197
00:13:45,250 --> 00:13:50,379
Let's now compare two of the most
common approach to ranking gradient

198
00:13:50,379 --> 00:13:54,639
booster decision trees and deep
neural networks, starting with

199
00:13:54,639 --> 00:13:56,109
gradient boosting on the left.

200
00:13:56,859 --> 00:14:00,129
These models are widely used
in production, especially

201
00:14:00,129 --> 00:14:01,629
for the final ranking stage.

202
00:14:02,334 --> 00:14:06,984
They work very well on structured
data and easy to interpret and

203
00:14:06,984 --> 00:14:09,084
support fast training and AB testing.

204
00:14:09,894 --> 00:14:16,644
They also grade for small and medium data
sets and have low latency, making them

205
00:14:17,185 --> 00:14:19,704
ideal for high throughput environments.

206
00:14:20,094 --> 00:14:22,915
But Gradient Boost also
has its limitations.

207
00:14:23,394 --> 00:14:28,134
It struggles to model complex and direct
and doesn't handle sequences of multimodel

208
00:14:28,184 --> 00:14:33,914
they also don't scale as effectively as
large data set compared to neural models.

209
00:14:34,874 --> 00:14:42,494
Now moving to deep neural networks on the
right side, these are seeing increased

210
00:14:42,494 --> 00:14:44,864
adoption in both research and industrial.

211
00:14:45,914 --> 00:14:49,814
DN Ns can capture both explicit
and implicit feature interactions.

212
00:14:50,144 --> 00:14:55,064
Handling billings for high cardinality
features and enable end-to-end training

213
00:14:55,214 --> 00:15:00,644
on sequences like user history, they
also support multitasking and transfer

214
00:15:00,644 --> 00:15:03,074
learning and scale better with more data.

215
00:15:03,764 --> 00:15:08,294
However, deep networks also bring
their own set of challenges.

216
00:15:08,444 --> 00:15:11,054
They are cap, potentially expensive.

217
00:15:11,489 --> 00:15:14,189
Harder to debug and less interpretable.

218
00:15:14,819 --> 00:15:19,049
They can suffer from issues
like bias, fairness, and even

219
00:15:19,049 --> 00:15:24,059
hallucinations, and they tend to
be sensitive to noise or small, ch

220
00:15:24,149 --> 00:15:27,029
small chain, small changes in input.

221
00:15:28,559 --> 00:15:32,129
Because of these trade-offs,
many real world systems adopt

222
00:15:32,129 --> 00:15:36,389
a hybrid approach using neural
network upstream for candidate

223
00:15:36,389 --> 00:15:38,579
generation or feature extraction.

224
00:15:39,359 --> 00:15:44,579
Gradient boost for final ranking to
balance performance and efficiency

225
00:15:46,469 --> 00:15:49,529
when building large scale neural
networks for recommendations.

226
00:15:49,889 --> 00:15:53,849
Performance is important, but
scalability and efficiency are critical.

227
00:15:54,659 --> 00:16:00,144
This slide outlines some of the key
design principles that help us get both.

228
00:16:00,974 --> 00:16:04,649
First, we have late fusion
and BN color architectures.

229
00:16:05,204 --> 00:16:09,944
Instead of scoring user item pairs
in real time with a single tower,

230
00:16:09,974 --> 00:16:15,494
we split them into a user tower,
which answered online and item tower,

231
00:16:15,824 --> 00:16:17,594
which we pre-com compute offline.

232
00:16:18,284 --> 00:16:25,859
This can lead to over 110 speed
up while preserving more than 80%

233
00:16:25,934 --> 00:16:27,734
of total profit in some systems.

234
00:16:28,604 --> 00:16:29,054
Next.

235
00:16:29,789 --> 00:16:30,929
Is contrastive learning.

236
00:16:31,589 --> 00:16:35,369
This trains the model to
distinguish between positive

237
00:16:35,369 --> 00:16:40,589
and hard negative examples using
the losses like in or scent.

238
00:16:41,399 --> 00:16:45,449
The goal is to produce a
billion that are compatible

239
00:16:45,719 --> 00:16:47,489
with fast dot product retrieval.

240
00:16:47,939 --> 00:16:55,889
In some cases, the teams report up to 100%
profit uplift in retrieval performance.

241
00:16:57,314 --> 00:17:01,394
A common challenge at scale
is embedding size, so we apply

242
00:17:01,394 --> 00:17:05,474
compression techniques like hashing,
quantization, or distillation to

243
00:17:05,474 --> 00:17:07,214
keep memory and latency in check.

244
00:17:07,994 --> 00:17:13,124
Another critical aspect is bias
correction, including popularity bias,

245
00:17:13,185 --> 00:17:15,164
proposition bias and feedback loops.

246
00:17:15,974 --> 00:17:19,844
One trick here is to add a context
of wear tower during training,

247
00:17:20,204 --> 00:17:22,004
but drop it at inference time.

248
00:17:22,814 --> 00:17:25,514
We also apply hard
negative mining to main.

249
00:17:25,844 --> 00:17:30,254
To make training more meaningful
instead of using random negatives

250
00:17:30,344 --> 00:17:33,614
with sample negatives that are
hard for the model to distinguish.

251
00:17:34,334 --> 00:17:37,544
This makes the learning
signal much stronger.

252
00:17:38,564 --> 00:17:41,235
Then there is multis signal learning.

253
00:17:42,134 --> 00:17:47,264
Our models often consume inputs from
multiple modalities, text, images,

254
00:17:47,324 --> 00:17:51,254
table or data, and from different
domains like search queries,

255
00:17:51,254 --> 00:17:53,379
watch history, or card activity.

256
00:17:54,614 --> 00:17:57,284
Finally, sequential model is crucial.

257
00:17:57,974 --> 00:18:01,604
We use transformer based on coders
to capture the temporal aspects

258
00:18:01,604 --> 00:18:04,664
of user behavior in recent events.

259
00:18:04,664 --> 00:18:06,914
First, to predict what comes next.

260
00:18:07,814 --> 00:18:12,554
These principles together make it possible
to run deep learning, massive scale

261
00:18:12,854 --> 00:18:17,499
in production, recommendation systems,
results, sacrifice, and speed or quality.

262
00:18:19,604 --> 00:18:22,995
Let's now talk about why scaling and
LU Commander system is much harder

263
00:18:22,995 --> 00:18:25,274
than scaling and LMS or vision models.

264
00:18:26,084 --> 00:18:29,054
On the left side, we see
that LMS and computer vision

265
00:18:29,054 --> 00:18:31,124
models scale extremely well.

266
00:18:31,874 --> 00:18:38,405
They take in long sequences like texts
or pixels, benefit from dance labels

267
00:18:38,405 --> 00:18:44,465
and strong supervision and have powerful
pre tasks like next token prediction.

268
00:18:45,589 --> 00:18:49,969
They use deep transformer architectures
and are often latency tolerant.

269
00:18:50,299 --> 00:18:56,239
We don't mind waiting a few second for
a response In these domains, scaling

270
00:18:56,329 --> 00:19:00,799
almost always improves quality and
scaling laws are well established.

271
00:19:01,879 --> 00:19:04,879
Now contrast that with
recomme command system.

272
00:19:04,939 --> 00:19:08,839
On the right we deal with
massive embedding tables.

273
00:19:09,620 --> 00:19:11,930
Billions of user and item IDs.

274
00:19:12,470 --> 00:19:16,580
Our models are often animal
to layer perceptrons, and they

275
00:19:16,580 --> 00:19:18,169
must respond in milliseconds.

276
00:19:18,740 --> 00:19:23,120
So we are under heavy latency constraints.

277
00:19:24,080 --> 00:19:27,860
Our data is based on short,
sparse behavior sequences,

278
00:19:28,250 --> 00:19:30,020
just few clicks or skips.

279
00:19:30,544 --> 00:19:34,809
Feedback is implicit and we
don't have a universal self

280
00:19:34,809 --> 00:19:37,014
supervised training task like lms.

281
00:19:37,014 --> 00:19:37,174
Do.

282
00:19:38,064 --> 00:19:41,364
Also no clear scaling law exists here.

283
00:19:42,144 --> 00:19:46,854
As we grow models, we quickly run into
bias, noise, and diminishing returns.

284
00:19:48,084 --> 00:19:53,304
The key takeaways is in the box at the
bottom, a Recomme Commander system.

285
00:19:53,634 --> 00:19:58,914
Heat, unique scaling limits, including
latency, implicit feedback, massive

286
00:19:58,974 --> 00:20:01,644
embeddings, and the main specific biases.

287
00:20:02,274 --> 00:20:06,734
These can just be solved by
making models deeper or wider.

288
00:20:07,169 --> 00:20:09,389
We need the main specific innovations.

289
00:20:11,249 --> 00:20:14,999
Let's wrap up with some of the
most important trends in neural

290
00:20:14,999 --> 00:20:18,209
networks recommended systems today.

291
00:20:19,349 --> 00:20:23,219
First, we are seeing a strong
shift from traditional ingredient

292
00:20:23,219 --> 00:20:28,379
boost models to deep learning,
what we call neural ran companies.

293
00:20:29,489 --> 00:20:34,409
Like YouTube meta Alibaba use
models in production to power

294
00:20:34,409 --> 00:20:36,389
personalized recommendations at scale.

295
00:20:37,289 --> 00:20:41,819
Multi-stage pipelines with bean quarter
for fast retrieval and deep models for

296
00:20:41,819 --> 00:20:47,894
final scoring are now fairly standard
while not new, they remain a reliable way

297
00:20:48,089 --> 00:20:50,669
to balance quality and latency at scale.

298
00:20:52,109 --> 00:20:57,479
We are also seeing LMS being used in
novel ways, not just for generating text.

299
00:20:57,794 --> 00:21:04,334
But to interpret embedding spaces and
even answer queries based on vector alone.

300
00:21:05,264 --> 00:21:10,574
In terms of architectural transformer
innovations like high performer or high

301
00:21:10,574 --> 00:21:15,434
performer from DeepMind are pushing the
envelope for recommendation specific

302
00:21:15,434 --> 00:21:18,434
models when it comes to scaling.

303
00:21:19,064 --> 00:21:23,414
Several papers have shown that scaling
laws applied recommendation in bearings

304
00:21:23,804 --> 00:21:31,904
and sequence models just like they do
in NLP Meta 2024, research on trillion

305
00:21:31,904 --> 00:21:37,514
Parameters, transducers, and the VU One
project aimed to define scaling law,

306
00:21:37,664 --> 00:21:42,554
specific to recommendations, another
growing trend in sequence modeling.

307
00:21:43,409 --> 00:21:44,969
We are moving beyond simple.

308
00:21:44,969 --> 00:21:46,949
Next item, prediction and modeling.

309
00:21:47,039 --> 00:21:50,399
Richer multi-model, time
aware user behavior.

310
00:21:51,449 --> 00:21:57,659
The area of graph neural networks models
are being used to better capture user item

311
00:21:57,659 --> 00:22:00,449
relationship, especially in the long tail.

312
00:22:01,139 --> 00:22:06,299
These use inductive and transductive
approach depending on whether the

313
00:22:06,299 --> 00:22:08,429
graph structure is fixed or dynamic.

314
00:22:09,299 --> 00:22:09,779
Finally.

315
00:22:10,319 --> 00:22:13,139
Reinforcement learning
continues to gain traction.

316
00:22:13,949 --> 00:22:18,239
It's used to optimize long-term
goals like retention or LTV.

317
00:22:18,839 --> 00:22:24,059
Reinforcement learning also helps with
exploration, which is key to avoidant

318
00:22:24,059 --> 00:22:26,639
feedback loops and filter bubbles.

319
00:22:27,449 --> 00:22:32,729
Overall, these trends show that
recommendation system are evolving rapidly

320
00:22:33,329 --> 00:22:38,849
with a growing focus on scalability,
long-term value, and deep user modeling.

321
00:22:40,589 --> 00:22:42,989
That bring us to the
end of the presentation.

322
00:22:43,829 --> 00:22:46,109
Thank you so much for your attention.

323
00:22:47,099 --> 00:22:51,269
I've covered the fundamentals of
machine learning, powered search and

324
00:22:51,269 --> 00:22:56,009
recommendation systems, explore key
architectural components, looked at

325
00:22:56,009 --> 00:23:01,234
challenges in scaling and discussed
emerging trends in this space.

326
00:23:02,144 --> 00:23:10,974
I hope this gave you a useful
foundation and maybe even sparked

327
00:23:10,974 --> 00:23:13,884
ideas you'd like to explore further.

328
00:23:14,544 --> 00:23:18,114
If you have any questions or want
to continue the conversation,

329
00:23:18,384 --> 00:23:19,374
I'd be happy to chat.

330
00:23:19,824 --> 00:23:20,784
Thanks again.

