1
00:00:00,150 --> 00:00:00,840
Hello, everybody.

2
00:00:01,390 --> 00:00:02,690
My name is Shraddha Kohli.

3
00:00:03,180 --> 00:00:08,180
And today I will be talking about
building user trust in conversational AI.

4
00:00:08,789 --> 00:00:12,399
The role of explainable AI
in chatbot transparency.

5
00:00:13,309 --> 00:00:17,370
Today's presentation explores
the application of explainable AI

6
00:00:17,430 --> 00:00:22,460
techniques to enhance transparency
and trust in chatbot decision making.

7
00:00:23,200 --> 00:00:27,259
As chatbots have become increasingly
more sophisticated and popular,

8
00:00:27,585 --> 00:00:31,965
Understanding their internal reasoning
still remains a significant challenge.

9
00:00:32,465 --> 00:00:36,975
Let's first try to understand how do
chatbot technologies actually evolve.

10
00:00:37,655 --> 00:00:40,965
The rapid advancement of chatbot
technologies have revolution,

11
00:00:40,994 --> 00:00:45,845
have revolutionized human computer
interaction, offering increasingly

12
00:00:45,845 --> 00:00:49,605
sophisticated conversational
experiences across various domains.

13
00:00:50,195 --> 00:00:54,765
However, as these AI driven
systems become more complex, they

14
00:00:54,795 --> 00:00:56,525
often operate as black boxes.

15
00:00:57,125 --> 00:01:01,405
making it challenging for users and
developers both to understand the

16
00:01:01,405 --> 00:01:03,545
rationale behind their responses.

17
00:01:04,165 --> 00:01:08,814
This opacity can lead to issues of
trust, accountability, and difficulty

18
00:01:08,814 --> 00:01:10,515
in improving the system performances.

19
00:01:11,395 --> 00:01:17,815
The early chatbots came in around the
1960s, which primarily relied on pattern

20
00:01:17,815 --> 00:01:19,815
matching and predefined responses.

21
00:01:20,805 --> 00:01:22,574
Then came the machine learning era.

22
00:01:23,360 --> 00:01:27,770
With the advent of machine learning
and NLP techniques in the 21st century,

23
00:01:28,190 --> 00:01:32,439
it led to more advanced chatbots
capable of understanding context

24
00:01:32,479 --> 00:01:34,589
and generating human like responses.

25
00:01:35,089 --> 00:01:39,739
With all these, the current
challenges such as transparency,

26
00:01:40,069 --> 00:01:44,989
leading to issues such as unexpected
responses and biased decision making.

27
00:01:45,819 --> 00:01:49,084
In order to curb these
challenges, We did a study.

28
00:01:49,584 --> 00:01:54,244
Let's first take a look at what is the
overview of explainable AI techniques.

29
00:01:54,874 --> 00:01:58,884
Explainable AI techniques aim to
demystify this decision making

30
00:01:58,884 --> 00:02:00,964
processes of complex AI systems.

31
00:02:01,484 --> 00:02:03,904
Three key methods are
explored in this study.

32
00:02:04,414 --> 00:02:09,534
The first one is called LIME, local
interpretable model agnostic explanations,

33
00:02:09,854 --> 00:02:14,694
which help to create local linear
approximations of the model's behavior.

34
00:02:15,184 --> 00:02:18,164
By perturbing inputs
and observing outputs.

35
00:02:18,764 --> 00:02:24,414
The second technique that we used was
SHAP, shapely additive explanations using

36
00:02:24,424 --> 00:02:29,454
game theory to provide a unified measure
of feature importance, offering both

37
00:02:29,494 --> 00:02:32,024
global as well as local interpretability.

38
00:02:32,954 --> 00:02:35,884
Lastly, we used
counterfactual explanations.

39
00:02:36,444 --> 00:02:41,064
Focus on providing minimal changes
to the input that would result in

40
00:02:41,064 --> 00:02:45,444
a different output, helping users
understand key decision factors.

41
00:02:45,944 --> 00:02:52,264
In our research, we, we researched around
150 users across different demographics,

42
00:02:52,914 --> 00:02:59,314
and we employed three state of the art
chatbot models, a retrieval based model,

43
00:02:59,964 --> 00:03:04,544
a generative model based on transformer
architecture, and a hybrid model.

44
00:03:05,224 --> 00:03:08,994
We applied the three techniques that
I just mentioned to these models,

45
00:03:09,284 --> 00:03:12,604
assessing their effectiveness
using metrics such as faithfulness.

46
00:03:13,374 --> 00:03:16,074
stability, as well as comprehensibility.

47
00:03:16,574 --> 00:03:21,044
The three stages were, we first did
a model selection, then we applied

48
00:03:21,044 --> 00:03:25,034
one of the explainable AI methods,
and then we evaluated the results.

49
00:03:25,534 --> 00:03:30,234
Our study revealed that each of the
explainable AI techniques offered unique

50
00:03:30,254 --> 00:03:32,574
insights into the chatbot decision making.

51
00:03:33,494 --> 00:03:37,054
LIME effectively provided local
explanations for individual

52
00:03:37,054 --> 00:03:41,044
responses, while SHAP offered
a more comprehensive view.

53
00:03:41,424 --> 00:03:44,474
of feature importance across
multiple interactions.

54
00:03:45,024 --> 00:03:49,054
Counterfactual explanations were
particularly useful in highlighting

55
00:03:49,054 --> 00:03:53,384
the sensitivity of chatbot
responses to specific input changes.

56
00:03:53,884 --> 00:03:58,374
The impact of our use on user, the
impact of our study on user trust and

57
00:03:58,394 --> 00:04:03,999
understanding was that It demonstrated
a significant improvement in the trust

58
00:04:04,039 --> 00:04:08,949
and understanding when interacting
with explainable AI enhanced chatbots.

59
00:04:09,449 --> 00:04:14,339
Participants reported that they felt more
confident in the chatbots ability and

60
00:04:14,339 --> 00:04:19,189
were more likely to forgive occasional
errors when provided with explanations.

61
00:04:19,579 --> 00:04:22,209
This whole black box sort of
became a white box to them.

62
00:04:22,864 --> 00:04:26,564
The ability to see the reasoning
behind responses led to increased

63
00:04:26,584 --> 00:04:31,164
user engagement and willingness to use
the chatbot for more complex tasks.

64
00:04:31,664 --> 00:04:35,204
Without the explainable AI, they
had very limited understanding

65
00:04:35,204 --> 00:04:36,384
of the chatbot decisions.

66
00:04:37,064 --> 00:04:39,194
And they had low forgiveness of errors.

67
00:04:39,759 --> 00:04:45,569
With explainable AI, this comprehension
improved by 48 percent, their error

68
00:04:45,569 --> 00:04:50,069
tolerance improved by 40 percent,
and their increased use of chatbots

69
00:04:50,099 --> 00:04:54,979
for complex tasks such as healthcare
or finance increased by 27 percent.

70
00:04:55,599 --> 00:05:00,019
Overall, the user trust increased
by 35 percent, and the user

71
00:05:00,049 --> 00:05:02,549
enhancement increased by 31 percent.

72
00:05:03,114 --> 00:05:04,894
These results were very promising.

73
00:05:05,394 --> 00:05:09,714
However, still, there are some challenges
in implementing these explainable AI

74
00:05:09,794 --> 00:05:14,474
techniques for chatbots, such as the
real time nature of chatbot interactions.

75
00:05:14,904 --> 00:05:18,294
You sometimes make it difficult to
generate comprehensive explanations

76
00:05:18,424 --> 00:05:20,644
without introducing significant latency.

77
00:05:21,414 --> 00:05:24,764
Additionally, balancing the level
of detail in our explanations

78
00:05:24,894 --> 00:05:29,134
with user comprehension is also
a challenge as we don't want our

79
00:05:29,134 --> 00:05:30,784
explanations to be too technical.

80
00:05:31,164 --> 00:05:35,114
Such that such as non technical
users cannot understand that model

81
00:05:35,144 --> 00:05:36,854
compatibility is another issue.

82
00:05:37,114 --> 00:05:40,854
Adapting the correct explainable
AI technique to various chatbot

83
00:05:40,864 --> 00:05:45,344
architectures and what model we want to
select is also one of the challenges.

84
00:05:45,844 --> 00:05:50,624
The integration of explainable
AI techniques in chatbot systems

85
00:05:50,634 --> 00:05:54,414
has far reaching implications for
their development and deployment.

86
00:05:54,894 --> 00:05:59,624
Developers can use the insights
gained from explainable AI to refine

87
00:05:59,624 --> 00:06:03,909
the chatbot models address biases
and improve response accuracy.

88
00:06:04,749 --> 00:06:09,079
Furthermore, the explainable AI
can facilitate easier debugging

89
00:06:09,080 --> 00:06:12,269
and maintenance of chatbot
systems, potentially reducing

90
00:06:12,269 --> 00:06:13,709
long term development costs.

91
00:06:14,179 --> 00:06:17,909
So it definitely has an
impact on the developer users.

92
00:06:18,409 --> 00:06:21,209
The ethical considerations
in transparent AI driven.

93
00:06:22,129 --> 00:06:26,369
This raises important ethical
considerations because while we want

94
00:06:26,379 --> 00:06:30,719
transparency to build trust, we also want
to make sure that we are not exposing

95
00:06:31,009 --> 00:06:35,789
any sensitive information about the
underlying models or the training data.

96
00:06:36,169 --> 00:06:40,249
So striking that balance between
transparency and privacy is crucial.

97
00:06:40,809 --> 00:06:46,089
Furthermore, there is a need to ensure
that explanations are presented unbiasedly

98
00:06:46,149 --> 00:06:51,379
and do not inadvertently reinforce
societal prejudices or stereotypes.

99
00:06:51,879 --> 00:06:56,089
Some of the future research directions
is that as our language models become

100
00:06:56,119 --> 00:07:00,439
increasingly sophisticated, there
is pressing need for a more advanced

101
00:07:00,439 --> 00:07:04,189
explainable AI techniques that can
effectively interpret and explain

102
00:07:04,189 --> 00:07:05,339
their decision making processes.

103
00:07:06,099 --> 00:07:09,629
Future research should focus more
on developing methods that can

104
00:07:09,629 --> 00:07:13,459
handle the complexity of transformer
based architecture and other

105
00:07:13,459 --> 00:07:15,209
state of the art language models.

106
00:07:15,689 --> 00:07:20,484
This may involve exploring hierarchical
explanations approaches that can

107
00:07:20,484 --> 00:07:25,034
provide insights at different levels
of abstraction, from individual

108
00:07:25,084 --> 00:07:28,414
attention weights to higher
level semantic representation.

109
00:07:28,914 --> 00:07:33,254
Overall, with this study, we were
able to demonstrate the significant

110
00:07:33,254 --> 00:07:36,764
potential of explainable AI techniques
in enhancing the transparency and

111
00:07:36,774 --> 00:07:41,704
trustworthiness of chatbot systems through
the application of methods such as LIME,

112
00:07:41,724 --> 00:07:43,804
SHAP, and counterfactual explanations.

113
00:07:44,189 --> 00:07:48,379
We have gained invaluable insights
into chatbot decision making processes.

114
00:07:49,119 --> 00:07:53,469
Our research has shown that integrating
explainable AI into chatbots

115
00:07:53,519 --> 00:07:57,639
not only improves user trust and
understanding, but also provides

116
00:07:57,639 --> 00:08:01,919
developers with powerful tools for
refining and improving these systems.

117
00:08:02,489 --> 00:08:06,129
As chatbots continue to evolve,
the need for transparency and

118
00:08:06,129 --> 00:08:08,339
accountability also becomes more crucial.

119
00:08:08,599 --> 00:08:11,189
And there is a lot of future
potential in this area.

120
00:08:11,689 --> 00:08:12,129
Thank you.

