1
00:00:00,000 --> 00:00:03,630
For being here, I'm Pril Marni,
senior DevOps professional with

2
00:00:03,630 --> 00:00:05,700
around 10 years of experience.

3
00:00:06,630 --> 00:00:09,810
Today we are going to talk
about harnessing Kubernetes for

4
00:00:09,810 --> 00:00:13,890
scalable AI ML workloads, using
insights from Tesla and open ai.

5
00:00:15,720 --> 00:00:19,980
Over the next few minutes, we'll explore
why Kubernetes has emerged as a defacto

6
00:00:19,980 --> 00:00:24,300
platform for container orchestration
in ai, and we'll dive into two real

7
00:00:24,300 --> 00:00:27,509
world implementations that leverage
Kubernetes for AI ML workloads.

8
00:00:29,250 --> 00:00:33,390
I share architecture patterns, operational
metrics, and lessons learned that you

9
00:00:33,390 --> 00:00:35,040
can apply in your own environments.

10
00:00:36,040 --> 00:00:40,210
First up, let's discuss how AI
workloads differ from traditional

11
00:00:40,210 --> 00:00:41,320
computational workloads.

12
00:00:42,505 --> 00:00:47,425
AI workloads, as are resource
intensive, require elastic scaling and

13
00:00:47,425 --> 00:00:51,325
are failure prone when thousands of
GPUs are pushing petabytes of data.

14
00:00:51,325 --> 00:00:56,845
24 7 analysts project the market
for AI platforms will search

15
00:00:56,845 --> 00:01:03,670
from five $15 billion in 2023
to over $2 trillion by 2032.

16
00:01:04,615 --> 00:01:06,205
So the stakes are huge here.

17
00:01:07,450 --> 00:01:10,030
Traditional static clusters can't keep up.

18
00:01:10,210 --> 00:01:16,690
And based on recent surveys, 61% of the
enterprises site capacity bottlenecks as

19
00:01:16,690 --> 00:01:18,910
their number one blocker to production.

20
00:01:18,970 --> 00:01:19,300
Ai.

21
00:01:20,830 --> 00:01:26,080
Considering this, Kubernetes has emerged
as a critical solution for addressing

22
00:01:26,080 --> 00:01:30,670
these challenges through dynamic resource
allocation, intelligence, scaling

23
00:01:30,905 --> 00:01:35,465
self-healing capabilities, enhanced
monitoring and workload portability.

24
00:01:36,465 --> 00:01:43,005
Coming to some of the common AI
infrastructure challenges, resource

25
00:01:43,005 --> 00:01:48,225
intensity is one of the top
challenges faced by AI infrastructure.

26
00:01:49,185 --> 00:01:52,995
Modern AI models demand extraordinary
computational resources with training

27
00:01:52,995 --> 00:01:55,395
requirements increasing exponentially

28
00:01:57,525 --> 00:02:01,695
modern AI training and inference
pipelines demand a compute.

29
00:02:02,894 --> 00:02:07,394
Driven model training can consume over
61% of the data centers total power

30
00:02:07,394 --> 00:02:12,525
budget, leaving less headroom for
networking, storage and non-AI workloads.

31
00:02:14,265 --> 00:02:21,315
Scaling complexity, data volumes and model
par parameter counts are exploding at

32
00:02:21,315 --> 00:02:25,440
around a 36% compound annual growth rate.

33
00:02:26,475 --> 00:02:30,345
This means a cluster sized for
last year's workload will be under

34
00:02:30,345 --> 00:02:32,834
provision today and obsolete tomorrow.

35
00:02:33,614 --> 00:02:37,214
Static infrastructure simply
can't keep up with the pace of

36
00:02:37,214 --> 00:02:38,804
growth that we have seen here.

37
00:02:40,665 --> 00:02:42,045
Resource inefficiency.

38
00:02:43,964 --> 00:02:47,745
Without proper orchestration,
organizations struggle to

39
00:02:47,745 --> 00:02:50,685
optimize resource allocation
across varied workloads with

40
00:02:51,109 --> 00:02:52,149
fluctuating demand patterns.

41
00:02:53,149 --> 00:02:59,644
As pipelines become more distributed,
spanning object stores messages, andous

42
00:02:59,659 --> 00:03:04,879
compute failure modes multiply and
increase potential points of failure.

43
00:03:05,879 --> 00:03:09,659
Without automated recovery,
mean time to repair can stretch

44
00:03:09,659 --> 00:03:11,219
into hours or even days.

45
00:03:11,399 --> 00:03:16,229
This is extremely concerning in large
scale distributed training environments.

46
00:03:18,509 --> 00:03:23,609
These challenges together combine to
slow down, model iteration, inflate

47
00:03:23,669 --> 00:03:25,889
costs, and undermined re reliability.

48
00:03:28,394 --> 00:03:33,134
Next, let's see how Kubernetes
directly addresses each of

49
00:03:33,134 --> 00:03:35,144
these issues as a solution.

50
00:03:36,884 --> 00:03:41,924
Alright, let's see how Kubernetes
as a solution for us here.

51
00:03:43,124 --> 00:03:47,654
According to CNCF research, 88% of
organizations are running containerized

52
00:03:47,684 --> 00:03:52,724
AI ML workloads in production with
70% leveraging Kubernetes as their

53
00:03:52,844 --> 00:03:54,825
primary orchestration platform.

54
00:03:55,724 --> 00:04:01,005
This widespread adoption is driven by
Kubernetes, is comprehensive feature

55
00:04:01,005 --> 00:04:07,664
set that directly addresses the
unique requirements of AI workloads.

56
00:04:09,734 --> 00:04:12,224
Kubernetes comes with
declarative provisioning.

57
00:04:12,839 --> 00:04:16,289
In a single yaml, you
get to describe GPU type.

58
00:04:16,889 --> 00:04:24,449
The driver, CUDA base image and Kubernetes
device plugin automates the rest.

59
00:04:25,259 --> 00:04:27,689
No more handbuilt bare metal clusters.

60
00:04:29,039 --> 00:04:32,460
It has great resource
optimization and scalability.

61
00:04:34,469 --> 00:04:38,939
It provides tools like horizontal
power autoscaler, which can combine

62
00:04:38,939 --> 00:04:40,889
with NVIDIA metrics exporter.

63
00:04:42,239 --> 00:04:48,090
Allows Kubernetes to adjust replicas
in mere seconds while vertical port

64
00:04:48,090 --> 00:04:52,799
or autoscaler right sizes, memory,
or CPU based on the requirement.

65
00:04:53,940 --> 00:05:01,409
CADA adds event driven bursts that can
help with sudden spikes in traffic.

66
00:05:03,750 --> 00:05:09,929
Kubernetes has self-healing and
rolling updates for an improved uptime.

67
00:05:10,739 --> 00:05:17,579
If A GPU node panics the scheduler,
restarts the pod on healthy hardware

68
00:05:17,699 --> 00:05:20,219
and respects pod disruption budgets.

69
00:05:20,849 --> 00:05:23,189
So training jobs keep their core.

70
00:05:25,139 --> 00:05:30,059
If any update needs to be deployed
to the model, Kubernetes control

71
00:05:30,059 --> 00:05:34,829
loop based resource management
ensures that the new changes are

72
00:05:34,829 --> 00:05:36,329
rolled out without any downtime.

73
00:05:37,329 --> 00:05:43,629
Kubernetes offers multi-tenant
isolation using namespace resource

74
00:05:43,629 --> 00:05:46,329
quotas, thas and node selectors.

75
00:05:47,109 --> 00:05:57,129
It lets you guarantee say that 40 a one
hundreds are for team A and 40 H. One

76
00:05:57,129 --> 00:05:59,139
hundreds are for production inference.

77
00:05:59,709 --> 00:06:03,159
You can divide your own GPU hardware.

78
00:06:04,584 --> 00:06:10,194
Allocate specific services, specific
workloads onto each type of hardware.

79
00:06:11,004 --> 00:06:17,184
It also enables for batch AI workloads to
be deployed onto selective infrastructure.

80
00:06:18,354 --> 00:06:23,214
So to summarize, Kubernetes provides
dynamic resource allocation, allowing

81
00:06:23,334 --> 00:06:27,984
organizations to optimize resource
utilization across variable AI workloads.

82
00:06:29,319 --> 00:06:36,279
As you can see from CNCF research, these
percentages are not a smaller percentages.

83
00:06:36,879 --> 00:06:39,069
They reflect broader industry adoption.

84
00:06:39,129 --> 00:06:44,289
Underscoring that Kubernetes
is production hardened for ai.

85
00:06:45,609 --> 00:06:50,949
Okay, let's continue our discussion about
Kubernetes capabilities for AI workloads.

86
00:06:51,249 --> 00:06:55,659
Let's dig deeper into how
each functionality helps with.

87
00:06:57,159 --> 00:07:01,089
Running AI workload dynamic
resource allocation.

88
00:07:02,229 --> 00:07:06,009
In the previous slide, we had already
covered a little bit about how Kubernetes

89
00:07:06,039 --> 00:07:12,249
allows for enhanced resource optimization
and scalability through the GPU device

90
00:07:12,249 --> 00:07:14,889
plugin and custom scheduler extensions.

91
00:07:15,729 --> 00:07:22,569
Kubernetes can share GPU devices across
parts or carve them into partitions.

92
00:07:23,484 --> 00:07:30,054
In practice, 63% of the organizations
citing resource optimization as a primary

93
00:07:30,054 --> 00:07:32,094
motivation for adopting Kubernetes

94
00:07:34,944 --> 00:07:35,994
intelligent scaling.

95
00:07:38,124 --> 00:07:42,744
Kubernetes provides multiple
scaling mechanisms that address

96
00:07:42,864 --> 00:07:44,009
variable resource requirements.

97
00:07:45,369 --> 00:07:50,559
The horizontal pod autoscaler and vertical
pod autoscaler augmented with custom

98
00:07:50,559 --> 00:07:55,989
metrics such as GPU, memory pressure
or Q Depth allow training and inference

99
00:07:56,229 --> 00:07:58,659
pods to scale up and down in real time,

100
00:08:00,999 --> 00:08:09,579
which such scaling 78% of the
organization are to adopt into ku.

101
00:08:10,579 --> 00:08:14,509
To self-healing capabilities of
Kubernetes, Kubernetes provides

102
00:08:14,509 --> 00:08:21,259
critical reliability improvements like
liveliness probes, readiness probes that

103
00:08:21,259 --> 00:08:24,739
can catch hunger or crash processes.

104
00:08:26,509 --> 00:08:32,539
Cluster autoscaler can be used to
replace unhealthy nodes automatically

105
00:08:32,749 --> 00:08:34,429
without any manual intervention.

106
00:08:37,054 --> 00:08:43,984
A 72% reduction in failed training
runs across organizations.

107
00:08:46,444 --> 00:08:48,754
Kubernetes provides enhanced monitoring.

108
00:08:49,984 --> 00:08:53,674
Kubernetes offers granular
visibility into resource

109
00:08:53,674 --> 00:08:55,504
utilization and performance metrics.

110
00:08:56,914 --> 00:08:58,204
It's out of the box.

111
00:08:58,204 --> 00:09:03,334
Integration with Prometheus and
Grafana provides dashboards for

112
00:09:03,334 --> 00:09:06,454
GPU, temperature power draw, PCIE.

113
00:09:06,454 --> 00:09:13,294
Throughput and network IO
teams achieve 76% faster.

114
00:09:14,584 --> 00:09:21,214
Mean time to recovery because anomalies
are detected and visualized immediately.

115
00:09:22,214 --> 00:09:27,525
These aren't marketing claims
that I was just showing you.

116
00:09:28,155 --> 00:09:32,234
They're aggregated from production
telemetry across hundreds of deployments.

117
00:09:33,555 --> 00:09:41,594
That said, let's continue on to our
case study of one of the prominent

118
00:09:41,625 --> 00:09:45,494
car manufacturers innovations Tesla.

119
00:09:47,400 --> 00:09:51,060
Tesla represents one of the most
sophisticated implementations of

120
00:09:51,060 --> 00:09:56,609
Kubernetes for AI ML workloads, leveraging
container orchestration to power.

121
00:09:56,609 --> 00:09:58,530
Its autonomous driving technology.

122
00:09:59,520 --> 00:10:03,930
The company's autonomous driving system
processes data from eight cameras

123
00:10:04,079 --> 00:10:12,060
that collectively capture 360 degree
video generating approximately 1.5

124
00:10:12,060 --> 00:10:15,180
terabytes of data per car annually.

125
00:10:18,029 --> 00:10:22,409
Tesla processes over a hundred
thousand video clips per day through

126
00:10:22,409 --> 00:10:23,999
its computer vision pipelines.

127
00:10:25,229 --> 00:10:30,419
With each clip requiring analysis
across multiple neural networks,

128
00:10:31,319 --> 00:10:34,889
Kubernetes orchestrates thousands
of container instance instances

129
00:10:35,489 --> 00:10:39,029
that collectively analyze these
inputs during training period.

130
00:10:40,199 --> 00:10:45,370
By contain their 360 degree camera
inference, pipeline deployment time

131
00:10:46,240 --> 00:10:48,520
from two weeks to under four hours.

132
00:10:49,520 --> 00:10:52,880
Tesla employs a hybrid cloud approach
for its training infrastructure,

133
00:10:54,440 --> 00:10:55,285
which is very important.

134
00:10:57,275 --> 00:11:01,895
Cloud brings you that reliability
and flexibility, whereas On-Prem

135
00:11:01,955 --> 00:11:08,195
gives you that high performance with
Kubernetes, managing workloads across

136
00:11:08,195 --> 00:11:12,695
both on-premise data centers and cloud
resources for from multiple providers.

137
00:11:13,385 --> 00:11:19,505
The hybrid approach did enable Tesla to
optimize for both cost and performance.

138
00:11:20,505 --> 00:11:25,935
Let's see how they have built
their Kubernetes implementation.

139
00:11:27,525 --> 00:11:33,015
Let's go through each component and see
how each component serves which purpose in

140
00:11:33,015 --> 00:11:36,885
their whole architecture, AI m pipelines.

141
00:11:37,829 --> 00:11:44,759
Tesla used PY and TensorFlow for their
AI ML pipelines to to do neural network

142
00:11:44,759 --> 00:11:50,279
training and used Triton inference
server for their realtime inference.

143
00:11:51,749 --> 00:11:58,889
And all of these were running inside
Kubernetes parts and the time inferencing

144
00:11:58,979 --> 00:12:07,260
for each camera orientation is done
using these AI ml. Infrastructure

145
00:12:07,260 --> 00:12:11,850
approach is hybrid cloud, as we
already discussed with on-prem and

146
00:12:11,850 --> 00:12:14,760
cloud to optimize cost and performance

147
00:12:16,860 --> 00:12:24,510
coming to hardware accelerators, Tesla
used Nvidia GPUs and some other custom

148
00:12:24,569 --> 00:12:27,480
AI chips built for specific use cases.

149
00:12:28,875 --> 00:12:32,505
And these are used to power
their neural network training

150
00:12:32,695 --> 00:12:35,365
model training and inferencing.

151
00:12:37,135 --> 00:12:40,814
The training technique they
adopted is data parallelism.

152
00:12:41,865 --> 00:12:47,130
And they have achieved this by
distributing workloads Kubernetes into

153
00:12:47,654 --> 00:12:52,844
Kubernetes across multiple GPUs, and
they leverage Kubernetes to achieve this.

154
00:12:53,844 --> 00:12:58,144
Deployment mechanism they have a
unique style of deployment mechanism

155
00:12:58,384 --> 00:13:01,054
compared to traditional use cases.

156
00:13:01,654 --> 00:13:06,724
Since they have a fleet of cars that
have to function and do real-time

157
00:13:06,814 --> 00:13:10,834
inferencing, they use something
called over the air updates to

158
00:13:10,834 --> 00:13:12,664
deliver their model improvements.

159
00:13:15,619 --> 00:13:18,739
Pull new container images
and rotate parts seamlessly.

160
00:13:19,039 --> 00:13:22,879
So every car pretty much runs
their latest neural net weights.

161
00:13:23,959 --> 00:13:27,379
The architecture, this architecture
that they have employed.

162
00:13:27,499 --> 00:13:31,189
Decouples model development from
infrastructure, accelerating

163
00:13:31,189 --> 00:13:32,329
Teslas iteration route.

164
00:13:33,329 --> 00:13:34,669
Now let's discuss

165
00:13:36,699 --> 00:13:39,334
the case study of one of the
cutting edge AI platform.

166
00:13:42,064 --> 00:13:47,614
That brought this whole AI
frenzy to the market open ai.

167
00:13:48,614 --> 00:13:53,924
Open AI represents a prime example of
how Kubernetes can be leveraged to manage

168
00:13:53,984 --> 00:13:59,804
extraordinary computational demands
of cutting edge AI research training.

169
00:13:59,804 --> 00:14:06,494
Modern LMS like those developed by open AI
requires massive computational resources.

170
00:14:07,844 --> 00:14:13,004
GT three featuring one 75 billion
parameters and G PT four estimated to

171
00:14:13,004 --> 00:14:15,494
have more than 1 trillion parameters.

172
00:14:16,634 --> 00:14:20,654
Kubernetes provides open AI with
the ability to define sophisticated

173
00:14:20,654 --> 00:14:25,844
scheduling rules that consider
complex variables like data locality.

174
00:14:26,459 --> 00:14:29,069
Interconnect bandwidth
and power constraints.

175
00:14:30,119 --> 00:14:35,009
The platform's native support for GP
resources allows for precise allocation

176
00:14:35,009 --> 00:14:37,979
of specialized computing resources.

177
00:14:39,089 --> 00:14:45,089
Kubernetes provides distributed training,
so open AI leverage HO Award on Q Flow,

178
00:14:45,659 --> 00:14:52,379
which runs on Kubernetes, and they used it
to orchestrate data parallelism to reduce.

179
00:14:54,224 --> 00:14:57,134
Their workloads across
hundreds of GPU parts.

180
00:14:58,334 --> 00:15:05,054
Data processing Spark on Kubernetes
was used by OpenAI to handle ETL

181
00:15:05,264 --> 00:15:10,964
of petabytes of text tokenization,
filtering, and feature extraction.

182
00:15:11,924 --> 00:15:17,594
For model serving, they used Triton
plus custom Kubernetes operators

183
00:15:18,254 --> 00:15:21,944
and use them to route thousands
of inference request per second.

184
00:15:23,339 --> 00:15:28,109
Sub 50 millisecond latency,
which is pretty low.

185
00:15:30,299 --> 00:15:34,529
And this was only possible
because of using Kubernetes.

186
00:15:35,529 --> 00:15:35,749
Now,

187
00:15:37,944 --> 00:15:44,064
let's see what other capabilities that
OpenAI has leveraged using Kubernetes.

188
00:15:46,194 --> 00:15:51,264
As you all know, as we already discussed,
the resource management is one of the key

189
00:15:51,264 --> 00:15:53,899
aspects that Kubernetes triumphs over.

190
00:15:55,194 --> 00:15:59,694
OpenAI has leveraged Kubernetes for their
GPU resource management for efficient

191
00:15:59,694 --> 00:16:03,954
allocation of hundreds of thousands
of GPUs for distributed LLM training,

192
00:16:05,694 --> 00:16:08,484
optimizing them for performance and cost.

193
00:16:10,045 --> 00:16:14,779
For example, their high priority training
jobs preempt lower priority workloads,

194
00:16:15,199 --> 00:16:18,169
ensuring SLAs for critical research runs.

195
00:16:18,499 --> 00:16:24,139
So there are high priority training
jobs run on parts that get scheduled on

196
00:16:24,739 --> 00:16:27,289
GPUs that are more powerful that way.

197
00:16:27,319 --> 00:16:31,709
Kubernetes gives you that flexibility
of resource management to ensure

198
00:16:32,009 --> 00:16:33,209
performance and efficiency.

199
00:16:35,129 --> 00:16:36,929
Swarm based ML orchestration.

200
00:16:38,459 --> 00:16:41,819
Coordination of multiple AI
agents working on different

201
00:16:41,819 --> 00:16:43,889
aspects of the MI ML pipeline.

202
00:16:44,759 --> 00:16:47,609
Breaking down the training process
into discrete containerized

203
00:16:47,609 --> 00:16:51,689
steps is key for open ai.

204
00:16:52,439 --> 00:16:56,759
Custom controllers treat hundreds
of parts as a cohesive form,

205
00:16:58,079 --> 00:17:00,479
packing GPUs to maximize efficiency.

206
00:17:01,479 --> 00:17:06,909
Dynamic scheduling is one of the
important aspects for achieving

207
00:17:06,969 --> 00:17:10,599
higher throughput with lower latency.

208
00:17:12,459 --> 00:17:16,689
Think of it, adjusting resource
allocations based on changing

209
00:17:16,749 --> 00:17:21,429
requirements across different
training phases from CPU intensive

210
00:17:21,429 --> 00:17:23,919
pre-processing to intensive training.

211
00:17:26,334 --> 00:17:32,034
Parts can migrate between CPU only ETL
stages and GPU accelerated training

212
00:17:32,034 --> 00:17:39,264
inferences stages based on demand and can
be scheduled onto specific type of node.

213
00:17:40,734 --> 00:17:45,714
This dynamic scheduling scale up and
scale down aspects of Kubernetes,

214
00:17:46,614 --> 00:17:49,884
which is automated, gives open ai.

215
00:17:51,444 --> 00:17:53,964
Edge over the other AI platforms.

216
00:17:55,614 --> 00:18:01,704
This Edge made them choose
Kubernetes over as their primary

217
00:18:02,394 --> 00:18:05,064
infrastructure platform for ai.

218
00:18:06,924 --> 00:18:11,724
Okay, now the last aspect is
monitoring and observability.

219
00:18:12,804 --> 00:18:16,314
Who doesn't need monitoring
across their workloads?

220
00:18:17,019 --> 00:18:19,449
Be it traditional
workloads or AI workloads.

221
00:18:19,449 --> 00:18:23,259
Monitoring and observability
is a key aspect for maintaining

222
00:18:24,399 --> 00:18:27,669
uptime and product efficiency.

223
00:18:28,749 --> 00:18:33,429
Tracking resource utilization, model
performance, and system health across

224
00:18:33,429 --> 00:18:38,714
distributed infrastructure to identify
bottlenecks and anon anomalies

225
00:18:39,039 --> 00:18:41,439
is key for any product lifecycle.

226
00:18:42,594 --> 00:18:49,704
They have implemented distributed
tracing of RPCs, GPU Sims, SM metrics and

227
00:18:49,704 --> 00:18:54,744
Network Telemetry triggering alerts in
under a second for anomalous patterns.

228
00:18:55,554 --> 00:19:01,689
This gives them that edge that can
help with monitoring their AI workload.

229
00:19:02,824 --> 00:19:08,074
These capabilities altogether allow
open AI to operate at a scale few

230
00:19:08,074 --> 00:19:14,344
organizations can match, and they
have achieved this high growth

231
00:19:14,794 --> 00:19:20,225
using Kubernetes while maintaining
high utilization and reliability.

232
00:19:21,225 --> 00:19:22,814
Alright, let's discuss.

233
00:19:23,814 --> 00:19:24,714
AI Ecosystem

234
00:19:27,204 --> 00:19:31,884
Q is one of the end-to-end platform
for orchestrating sophisticated

235
00:19:31,884 --> 00:19:37,044
ML pipelines provided, providing
streamlined model training and

236
00:19:37,074 --> 00:19:45,089
hyper parameter tuning using CIB and
metadata tracking with ML MD and it is.

237
00:19:45,744 --> 00:19:51,024
Very important tooling used by
many organizations for their

238
00:19:51,054 --> 00:19:52,704
production deployment workloads.

239
00:19:53,844 --> 00:19:58,254
Coming to TensorFlow operators, these
are custom Kubernetes controllers

240
00:19:58,254 --> 00:20:02,604
that auto automate TensorFlow
distributed training configuration,

241
00:20:03,324 --> 00:20:08,094
dramatically simplifying resource
allocation and internode communication.

242
00:20:09,864 --> 00:20:13,254
TensorFlow operators and
media device plugins.

243
00:20:13,764 --> 00:20:18,774
Natively expose GPUs and
multi-instance GPUs to parts

244
00:20:20,124 --> 00:20:22,284
coming to model serving production.

245
00:20:22,284 --> 00:20:27,414
Grade inferencing frameworks
like Kerv, kf serving seldom core

246
00:20:27,564 --> 00:20:33,504
and Triton deliver auto scaling,
canary rollouts and AB testing.

247
00:20:33,504 --> 00:20:34,404
For inference.

248
00:20:34,854 --> 00:20:40,224
They provide auto scaling and
deployments for seamless AI delivery.

249
00:20:41,224 --> 00:20:48,574
Importantly, Kubernetes provides
enhanced security frameworks using,

250
00:20:48,694 --> 00:20:55,084
which are S-P-I-F-F-E, SPIRE for
Workload Identity, GRPC, mutual TLS,

251
00:20:55,294 --> 00:20:57,214
and Network policies for Zero Trust.

252
00:20:58,324 --> 00:21:01,204
They also provide advanced
isolation technologies.

253
00:21:01,684 --> 00:21:06,244
Like Carta containers that create hardware
virtualized environments for high value

254
00:21:06,244 --> 00:21:12,634
AI models, protecting intellectual
property and sensitive data altogether,

255
00:21:12,784 --> 00:21:17,614
the Kubernetes ecosystem has matured
into a comprehensive AI ML platform,

256
00:21:17,764 --> 00:21:22,894
evolving from basic container management
to offering specialized tooling that

257
00:21:22,894 --> 00:21:28,924
addresses the entire machine learning
or lifecycle with enterprise adoption.

258
00:21:29,269 --> 00:21:34,429
Accelerating the global cloud
native platforms market is projected

259
00:21:34,429 --> 00:21:43,579
to reach $62.7 billion by 2034,
growing at A-C-I-G-R of 16.5%.

260
00:21:43,699 --> 00:21:47,749
As organizations increasingly
leveraged these technologies

261
00:21:47,749 --> 00:21:49,459
for competitive advantage.

262
00:21:50,459 --> 00:21:50,999
Together.

263
00:21:51,059 --> 00:21:54,869
These projects fill every stage
of the AI lifecycle from data

264
00:21:54,869 --> 00:21:59,759
ingestion to model deployment, all
taken care of within Kubernetes.

265
00:22:00,759 --> 00:22:04,749
Alright, let's look at some of
the common industry adoption

266
00:22:05,289 --> 00:22:07,389
in Kubernetes for AI workloads.

267
00:22:09,099 --> 00:22:13,509
Industries are adopting cloud native
platforms like Kubernetes at different

268
00:22:13,509 --> 00:22:18,249
kinds of rates with healthcare and
financial services leading the way.

269
00:22:19,539 --> 00:22:26,349
Healthcare is currently sitting
at 18.2 CIGR Genomic sequencing

270
00:22:26,349 --> 00:22:32,649
pipelines and MRI Ima image analysis
are running on Kubernetes clusters

271
00:22:33,879 --> 00:22:37,239
to achieve high healthcare needs.

272
00:22:38,859 --> 00:22:43,659
The healthcare sector's adoption is
particularly notable because of the

273
00:22:43,659 --> 00:22:47,289
stringent regulatory requirements
and sensitive patient data.

274
00:22:48,759 --> 00:22:56,589
Banking, financial services and insurance
are sitting at 17.9% annual growth rate.

275
00:22:57,759 --> 00:23:01,959
Growth driven by driven the need
for secure AI infrastructure with

276
00:23:01,959 --> 00:23:05,499
technologies like Carta containers
that we have already discussed about,

277
00:23:06,219 --> 00:23:10,059
has been especially valuable for
processing sensitive financial data

278
00:23:10,479 --> 00:23:12,579
and algorithmic trading strategies.

279
00:23:13,599 --> 00:23:18,609
Finance industry has seen a
rise in AI adoption for realtime

280
00:23:18,609 --> 00:23:23,169
fraud detection using streaming
inference, and Kubernetes has been.

281
00:23:24,169 --> 00:23:30,289
Telecom around 0.8 annual growth.

282
00:23:32,809 --> 00:23:36,739
It is leveraging Kubernetes to
manage complex networks and deliver

283
00:23:36,769 --> 00:23:40,339
innovative digital services at
scale with high reliability.

284
00:23:40,939 --> 00:23:45,379
For example, one of the top use cases
for telecom is to achieve superior 5G

285
00:23:45,379 --> 00:23:50,989
network analytics and edge AI in micro
data centers powered by Kubernetes.

286
00:23:52,279 --> 00:23:53,449
Coming to manufacturing.

287
00:23:53,449 --> 00:23:54,619
It's currently sitting at.

288
00:23:55,619 --> 00:24:01,739
But the experts are expecting that
this could be become one of the prime

289
00:24:01,739 --> 00:24:09,419
sector for AI adoption and that AI
adoption calls for Kubernetes adoption.

290
00:24:10,259 --> 00:24:16,109
So implementing Kubernetes to
orchestrate iot devices, optimize

291
00:24:16,109 --> 00:24:21,269
production lines, and enabling
predictive maintenance using AI systems.

292
00:24:22,349 --> 00:24:27,369
Which run on Kubernetes has been the
has been the motive for manufacturing

293
00:24:27,369 --> 00:24:33,519
growth rate, AI driven visual inspection,
and predictive maintenance via GPUA.

294
00:24:33,519 --> 00:24:37,629
Accelerated vision models that run
on Kubernetes is another top use

295
00:24:37,629 --> 00:24:41,199
case that drives this adoption.

296
00:24:42,489 --> 00:24:46,779
Alright, let's wrap up and
discuss what we have already gone

297
00:24:46,779 --> 00:24:48,309
through in the last few minutes.

298
00:24:49,309 --> 00:24:52,339
Kubernetes provides great
infrastructure foundation for

299
00:24:52,339 --> 00:24:54,979
scalable reliable AI infrastructure.

300
00:24:56,209 --> 00:25:00,379
It delivers the elasticity,
resilience and portability that

301
00:25:00,409 --> 00:25:02,359
modern AI ML workloads demand.

302
00:25:04,549 --> 00:25:09,829
Kubernetes has an expanding ecosystem
that has specialized tools for

303
00:25:09,829 --> 00:25:15,499
enhancing capabilities for AI specific
requirements, and it is ever evolving.

304
00:25:16,429 --> 00:25:20,029
C and vendor extensions
continue to evolve.

305
00:25:20,029 --> 00:25:23,989
Filling gaps in security, pipeline
orchestration and serving.

306
00:25:25,579 --> 00:25:32,299
Accelerating innovation is one of
the top drivers in Kubernetes and

307
00:25:33,319 --> 00:25:39,409
top requirements for AI organizations
gain try to gain competitive advantage

308
00:25:40,519 --> 00:25:42,559
through improved resource utilization.

309
00:25:44,104 --> 00:25:48,514
By standardizing on Kubernetes teams shift
their focus from infrastructure, plumbing,

310
00:25:48,544 --> 00:25:50,464
to model development and data science.

311
00:25:51,754 --> 00:25:56,824
As AI models grow in size and
complexity, Kubernetes will remain

312
00:25:56,884 --> 00:26:02,734
the orchestrator of choice, enabling
continuous experimentation, rapid

313
00:26:03,034 --> 00:26:05,554
ation, and cost efficient operations.

314
00:26:06,554 --> 00:26:06,974
Alright.

315
00:26:07,604 --> 00:26:09,614
Thank you for the attention.

316
00:26:09,764 --> 00:26:12,794
I hope these insights help you
architecture and operate your own

317
00:26:12,824 --> 00:26:14,774
Kubernetes based AI platforms.

318
00:26:15,494 --> 00:26:21,864
And they, I hope that they gave you a good
depth, in depth look at how Kubernetes

319
00:26:21,864 --> 00:26:24,174
can help with running AI ML workloads.

320
00:26:25,404 --> 00:26:25,884
Thank you.

321
00:26:26,544 --> 00:26:27,384
And have a.

