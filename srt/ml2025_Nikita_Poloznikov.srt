1
00:00:01,080 --> 00:00:04,320
Hi, my name is Nikita and I'm from Jos.

2
00:00:05,070 --> 00:00:10,200
I work as a head of design and as a
product designer and as a communication

3
00:00:10,200 --> 00:00:11,520
and graphic designer as well.

4
00:00:12,180 --> 00:00:16,110
Jos is a remit now, pay later
financial service and application.

5
00:00:16,710 --> 00:00:22,650
So today I want to talk with you
about AI tool, which can help a

6
00:00:22,650 --> 00:00:26,040
lot in early stage of each company.

7
00:00:26,545 --> 00:00:28,615
When you are doing a design.

8
00:00:29,435 --> 00:00:30,695
So let's start.

9
00:00:31,475 --> 00:00:36,125
When I left my last company and
joined a startup, I realized very

10
00:00:36,125 --> 00:00:40,864
quickly I was the only designer
and I had to manage everything.

11
00:00:40,915 --> 00:00:45,205
Pitch decks, marketing creatives,
user flows, even sometimes

12
00:00:45,265 --> 00:00:46,825
backend logic discussions.

13
00:00:47,295 --> 00:00:50,134
And of course user
interface for application.

14
00:00:50,285 --> 00:00:51,214
So all at once.

15
00:00:52,174 --> 00:00:58,414
It was overwhelming and I realized
that this can be done in traditional

16
00:00:58,414 --> 00:01:03,095
way anymore, and I needed to
rethink how design could scale.

17
00:01:03,454 --> 00:01:08,884
And in 2024, I knew that working
harder wasn't the solution,

18
00:01:08,884 --> 00:01:10,414
but working smarter was.

19
00:01:10,835 --> 00:01:14,404
So I started exploring how
AI could help me speed up.

20
00:01:15,109 --> 00:01:19,669
Creative production, maintain
quality, and also free my time for

21
00:01:19,669 --> 00:01:21,559
more strategic design thinking.

22
00:01:21,889 --> 00:01:26,899
And this presentation is a story
of how the journey unfolded and

23
00:01:26,899 --> 00:01:28,639
what lessons you can apply to.

24
00:01:30,259 --> 00:01:35,814
In early 2024, me Journey had yet
to develop a web-based interface.

25
00:01:36,470 --> 00:01:40,279
In other words, generating images
required users to interact through

26
00:01:40,309 --> 00:01:44,630
Discord chat, which felt stiff
link, especially for workflows that

27
00:01:44,630 --> 00:01:46,580
required a more creative touch.

28
00:01:47,119 --> 00:01:51,139
A web-based me journey did exist,
but it was in a closed be phase,

29
00:01:51,559 --> 00:01:56,879
meaning that very few users were
able to access it having come

30
00:01:56,879 --> 00:01:58,829
across plenty of other platforms.

31
00:01:59,219 --> 00:02:04,469
I settled on Dream Studio, which
operated on stable diffusion, Excel 1.0.

32
00:02:04,830 --> 00:02:08,820
This was primarily due to wanting
control over the graphical user

33
00:02:08,820 --> 00:02:10,289
interface and clean design.

34
00:02:10,680 --> 00:02:13,529
The Dream Studio had come to offer.

35
00:02:13,890 --> 00:02:18,359
Not only did the platform provide
flexibility, but it also had a very fun

36
00:02:18,359 --> 00:02:24,039
and intuitive way of allowing user to
experiment with prompts and tweak outputs.

37
00:02:24,949 --> 00:02:29,599
But it came with limits, of
course, even with negative pros.

38
00:02:30,259 --> 00:02:34,789
Getting realistic images, say a
Pakistani woman without a head

39
00:02:34,789 --> 00:02:36,799
covering was extremely difficult.

40
00:02:37,219 --> 00:02:41,239
It felt rigid, stereotypical,
and lack depth.

41
00:02:42,359 --> 00:02:46,379
Despite limitations, stable diffusion
was good enough to generate the first

42
00:02:46,379 --> 00:02:51,509
assets, images for our early pitch
decks, like an example or concept

43
00:02:51,639 --> 00:02:53,889
like our first limited payment cards.

44
00:02:54,279 --> 00:02:56,769
However, the generated output.

45
00:02:57,339 --> 00:03:03,069
Often had obvious flows, so
like broken head, hand anatomy,

46
00:03:03,129 --> 00:03:08,839
awkward details, and we had to do
significant retouching on that.

47
00:03:09,649 --> 00:03:13,459
It was a start, but it wasn't
scalable for a growing company.

48
00:03:14,239 --> 00:03:18,139
Even so stable diffusion
was extremely useful.

49
00:03:18,389 --> 00:03:23,069
During the early days of our startup,
it helped me create a working model

50
00:03:23,069 --> 00:03:25,279
of our first limited edition card.

51
00:03:25,754 --> 00:03:29,804
So this prototyping step was
pivotal in our product design.

52
00:03:30,234 --> 00:03:34,914
That added imaginative freedom in
the beginning, helped us formulate

53
00:03:34,944 --> 00:03:37,314
a brand and launched a vision.

54
00:03:39,339 --> 00:03:44,189
And then came great advancement
mid journey version 6.1.

55
00:03:44,309 --> 00:03:50,849
This release was a watershed moment,
not only in regard to features, but

56
00:03:50,849 --> 00:03:52,739
also the entire user experience.

57
00:03:52,739 --> 00:03:57,119
Mid journey migrated from a discard
only interface to a fully functional

58
00:03:57,119 --> 00:03:58,799
web application for the first time.

59
00:03:59,309 --> 00:04:04,509
Now, the tools seem to be designed for
creator rather than mere developers

60
00:04:04,539 --> 00:04:06,429
or early adopters, tech people.

61
00:04:07,074 --> 00:04:11,964
And the most striking chance in version
6.1 was a level of customization,

62
00:04:12,114 --> 00:04:18,864
aesthetic preferences, visual steadiness,
and creative directions could now be

63
00:04:18,864 --> 00:04:21,754
controlled with much greater accuracy.

64
00:04:22,174 --> 00:04:27,304
After all, the aim was not just to
produce random, stunning images, user

65
00:04:27,844 --> 00:04:33,904
strove to attain their vision seamlessly
and reliably with each refined step.

66
00:04:34,669 --> 00:04:39,079
Most importantly, it felt like
transitioning from riding a prototype to

67
00:04:39,079 --> 00:04:45,019
feeling the thrill of driving a complete
vehicle, as the image underwent a dramatic

68
00:04:45,019 --> 00:04:50,869
quality transformation, boasting clear
lines, more delicate nuances, lighting,

69
00:04:51,169 --> 00:04:53,389
and better grasp of complex prompts.

70
00:04:54,724 --> 00:05:01,804
At this stage, AI stopped feeling like a
proof of concept, a project or a whimsical

71
00:05:01,984 --> 00:05:07,024
tool For site activities, for concept art,
visual storytelling, and rapid iteration

72
00:05:07,234 --> 00:05:10,684
AI could now be relied on commenting.

73
00:05:10,744 --> 00:05:15,214
Its presents as a critical partner
in creative production pipeline.

74
00:05:16,084 --> 00:05:20,134
So in short, mid journey introduced
two powerful new concept.

75
00:05:20,314 --> 00:05:22,444
First is personalization.

76
00:05:22,834 --> 00:05:28,384
So it means rating 50 images during
onboarding, thought the model might taste.

77
00:05:28,924 --> 00:05:31,354
And the second one is aesthetic tuning.

78
00:05:31,924 --> 00:05:35,584
It's a sterilization, weirdness, variety.

79
00:05:35,584 --> 00:05:40,159
Fine tuned how creative or
unusual results would be.

80
00:05:40,984 --> 00:05:45,694
This allowed me to shape not just outputs,
but the entire feel of the brand's.

81
00:05:45,754 --> 00:05:50,434
Visual majority is
superior in numerous ways.

82
00:05:50,914 --> 00:05:55,984
When looking at issues such as the
quality of the image generated.

83
00:05:55,984 --> 00:06:01,444
Majority, often outperformed other tools
in creating beautiful images, both from

84
00:06:01,444 --> 00:06:03,004
technical and anesthetic perspective.

85
00:06:03,009 --> 00:06:05,959
It generates detailed compositions
complete with anatomy,

86
00:06:05,989 --> 00:06:07,599
sophisticated idea clusters.

87
00:06:08,674 --> 00:06:13,564
Hues that are vibrant, as well
as balanced and lower levels of

88
00:06:13,594 --> 00:06:15,874
artifacts and visual inconsistency.

89
00:06:16,384 --> 00:06:20,944
It's efficient, especially with
higher tier plans in fast, dependable

90
00:06:20,944 --> 00:06:25,424
performance, which helps create
creative, repetitive seamlessly

91
00:06:25,424 --> 00:06:27,314
and effectively with majority.

92
00:06:27,314 --> 00:06:31,604
I managed to achieve several
remarkable images in my initial trials.

93
00:06:32,159 --> 00:06:34,899
UR revealed itself to
be a helpful partner.

94
00:06:35,609 --> 00:06:40,499
When creating stories and drafting
ideas for campaigns revealing its

95
00:06:40,499 --> 00:06:45,179
full beauty in not merely providing
strong composition, but rather

96
00:06:45,179 --> 00:06:50,849
individualized, tailored AI generated
images built around focused narratives.

97
00:06:51,179 --> 00:06:54,959
I can finally state that
it clicked for a reason.

98
00:06:55,259 --> 00:07:00,119
Majority provided effortless flexibility
and thought after narrative advancements.

99
00:07:00,839 --> 00:07:04,734
I remember one image that was
particularly eye catching.

100
00:07:05,204 --> 00:07:10,004
The atmosphere and tone alongside
the composition matched perfectly

101
00:07:10,604 --> 00:07:13,294
with what I had visualized.

102
00:07:14,074 --> 00:07:18,904
That was the idea starting place for me,
a sandbox and try and different props

103
00:07:18,904 --> 00:07:24,244
become an attempt to see how far the
prompts can take the visual narratives.

104
00:07:25,674 --> 00:07:30,114
So the visuals created weren't
limited to internal trials.

105
00:07:30,264 --> 00:07:32,844
They were integrated into live campaigns.

106
00:07:33,219 --> 00:07:36,519
One of the initial images
created was incorporated into

107
00:07:36,519 --> 00:07:38,829
performance ad creative on meta.

108
00:07:39,399 --> 00:07:42,129
As expected, the ad performed quite well.

109
00:07:42,519 --> 00:07:46,689
The image captured the attention
of users fairly quickly in fields

110
00:07:46,989 --> 00:07:51,189
leading to a significant increase
in click-through rate when compared

111
00:07:51,189 --> 00:07:52,869
against our standard creatives.

112
00:07:53,629 --> 00:07:58,039
This confirmed that AI generated
visual visuals do have the

113
00:07:58,039 --> 00:08:02,449
potential for enhancing engagement
in paid media campaigns.

114
00:08:03,454 --> 00:08:08,584
The early success of this achievement
encouraged us to focus on developing a

115
00:08:08,584 --> 00:08:13,874
broader strategy that incorporate deeper
exploration of generative content.

116
00:08:15,524 --> 00:08:21,614
Just a head up, no matter which neural
image generator you use, whether it's mid

117
00:08:21,614 --> 00:08:24,044
Jordan stable effusion, or anything else.

118
00:08:24,599 --> 00:08:27,779
You'll always need to retouch the results.

119
00:08:27,839 --> 00:08:32,219
AI generated visuals often have small
flows like weird, hands, awkward,

120
00:08:32,519 --> 00:08:37,319
shes, or inconsistent textures
that need a human touch to fix.

121
00:08:37,889 --> 00:08:39,959
And here's the thing, speed matters.

122
00:08:39,959 --> 00:08:45,359
You and your marketing team are usually
working against the clock, so instead of

123
00:08:45,599 --> 00:08:50,549
firing up heavy tools like Photoshop, the
fastest and most efficient way to polish

124
00:08:50,609 --> 00:08:53,489
up images is to do it directly in Figma.

125
00:08:54,059 --> 00:08:57,419
It's lightweight, collaborative,
and way faster for quick adjustment.

126
00:08:57,749 --> 00:09:02,789
Perfect for when you are prepping
content for campaigns or social

127
00:09:02,789 --> 00:09:04,439
posts or product mockups.

128
00:09:04,979 --> 00:09:08,459
After all, it's not about spending
hours perfecting a single image.

129
00:09:08,489 --> 00:09:12,149
The real value comes from quickly
iterating on ideas and moving

130
00:09:12,539 --> 00:09:16,289
on to the next creative concept
that can make a real impact.

131
00:09:17,249 --> 00:09:21,539
Here's what a fast research workflow
in Figma look like, for example.

132
00:09:22,409 --> 00:09:26,819
So maybe the most perplexing
thing about Mid Journey was

133
00:09:26,819 --> 00:09:32,069
grappling with its tendency to
misinterpret intricate directives.

134
00:09:32,579 --> 00:09:39,209
While I appreciate the tools purpose
of artists concepts, once you try to

135
00:09:39,239 --> 00:09:41,369
impose on any specific conditions.

136
00:09:41,659 --> 00:09:42,949
Things fall apart.

137
00:09:43,669 --> 00:09:48,199
You might have a particular
mental image, say an object.

138
00:09:48,529 --> 00:09:54,499
Its relations to other elements in the
environment, texture or style, and even

139
00:09:54,499 --> 00:09:57,079
an overarching artistic aesthetics.

140
00:09:57,339 --> 00:10:01,719
Majority often works sideways,
meaning you at War Vision, an AI

141
00:10:01,749 --> 00:10:05,979
train to get in to build something
that resembles your vision.

142
00:10:06,649 --> 00:10:12,269
At one point I even juggling wondering
you know what, it might be just easier

143
00:10:12,269 --> 00:10:16,649
to hire a photographer and go looking
for a cricket balls and spend all

144
00:10:16,649 --> 00:10:21,179
the time begging me journey to make
a specific image in my imagination.

145
00:10:21,959 --> 00:10:25,289
It doesn't lack power, the
tool, but rather arbitrary.

146
00:10:25,289 --> 00:10:31,859
Novelty takes charge of structured
creativity, but then suddenly click

147
00:10:31,919 --> 00:10:35,549
and after 120 variants, here it is.

148
00:10:36,199 --> 00:10:41,249
The third in a row it's still not
perfect, but it's good to go for

149
00:10:41,249 --> 00:10:45,479
small tasks such as using it as
an illustration for the pitch deck

150
00:10:45,479 --> 00:10:48,599
again, or within an app proma section.

151
00:10:50,639 --> 00:10:55,229
So one of the features I find
really useful in my journey

152
00:10:55,259 --> 00:10:57,060
is the use of references.

153
00:10:57,569 --> 00:11:03,149
Essentially created image collections
that act like visual modifiers.

154
00:11:03,599 --> 00:11:12,719
Each references is assigned a unique
code like S Ref 6, 8, 0, et cetera, and

155
00:11:12,719 --> 00:11:15,930
you can even create your own custom one.

156
00:11:16,925 --> 00:11:19,889
It's a bit like a Pinterest,
but with superpowers.

157
00:11:20,399 --> 00:11:24,839
Think of it in a way, like instead of
browsing folders full of images and

158
00:11:24,839 --> 00:11:30,089
manual drawing inspiration, you can
feed an entire reference folder into Mid

159
00:11:30,089 --> 00:11:35,399
Journey as context and let it generate
new images based on that visual DNA.

160
00:11:36,059 --> 00:11:40,124
It's a creative shortcut and
a way to inject coherence or

161
00:11:40,154 --> 00:11:43,409
intentional style into your outputs.

162
00:11:44,159 --> 00:11:48,149
When I was working on my project, I
had a pretty clear mental image of my

163
00:11:48,149 --> 00:11:52,979
target audience, but finding the right
visual tone, that sweet spot, blending

164
00:11:52,979 --> 00:11:57,810
fashion, realism, wind touch, charm,
and hint of surrealism wasn't easy.

165
00:11:58,439 --> 00:12:03,810
I dove into the explore tap and image
journey and comped through frequent,

166
00:12:04,709 --> 00:12:06,509
frequently updated references.

167
00:12:06,814 --> 00:12:10,019
It felt a bit like a treasure
hand, but eventually I found

168
00:12:10,349 --> 00:12:12,149
the visual style that clicked.

169
00:12:13,159 --> 00:12:17,439
So it looks like this outcome.

170
00:12:18,439 --> 00:12:21,829
Okay, so now let's talk
about open AI and Sora.

171
00:12:21,949 --> 00:12:24,559
So open AI and, yeah.

172
00:12:24,559 --> 00:12:31,189
And by the way, this is all made
through Midjourney, and this is all.

173
00:12:32,104 --> 00:12:36,574
Is ready to go mockup we
used in our previous and end

174
00:12:36,574 --> 00:12:39,204
current ad campaign in meta.

175
00:12:40,854 --> 00:12:47,104
So let's talk about SOA and charge pt. So
open AI on the heels of launching Sora.

176
00:12:47,194 --> 00:12:53,254
Its new streamlined image generator
announced on March 25, the update

177
00:12:53,254 --> 00:12:55,324
of its image generator features.

178
00:12:55,699 --> 00:13:00,049
With GPT for all, so is
now fully incorporated into

179
00:13:00,049 --> 00:13:01,579
the charge GPT experience.

180
00:13:01,969 --> 00:13:05,929
This release was not only a remarkable
achievement on the technological

181
00:13:05,929 --> 00:13:10,969
front, it's also indicated a nuances,
changes of in our branding and creative

182
00:13:10,969 --> 00:13:15,199
focus, we have shifted to paying
more attention to representation,

183
00:13:15,199 --> 00:13:19,759
seeking to populate our visuals and
communications with people from as

184
00:13:19,759 --> 00:13:21,769
many different background as possible.

185
00:13:22,309 --> 00:13:24,559
So unlikely, most tools.

186
00:13:25,819 --> 00:13:31,849
Lead and with countless menus, toggles
and sliders is free from clutter while

187
00:13:31,849 --> 00:13:37,189
everything else is left to what it
would essentially call a human versus

188
00:13:37,219 --> 00:13:39,229
AI collaborative visioning process.

189
00:13:39,499 --> 00:13:42,709
User gets the opportunity to set
basic parameters such as image

190
00:13:42,709 --> 00:13:46,369
dimensions, expected outcome,
numbers, and even references.

191
00:13:46,699 --> 00:13:50,479
It's not about fine tuning controls,
it's about vision, feeling, and

192
00:13:50,479 --> 00:13:54,529
the descriptions that the company
is request the absence of clut.

193
00:13:54,964 --> 00:13:58,804
Makes the interface clean, enhancing
focus, and creating a feeling.

194
00:13:58,804 --> 00:14:02,854
Unlike most modern interfaces of
storytelling rather than technical

195
00:14:02,854 --> 00:14:08,554
configuration here's how the main page
looks like, for example, together with an

196
00:14:08,554 --> 00:14:13,864
explore section where the most ed pros and
images done by other users are displayed.

197
00:14:14,764 --> 00:14:20,444
And let's see, some first experiment
with soa when I first got access to soa.

198
00:14:21,164 --> 00:14:22,994
I was curious, but still cautious.

199
00:14:23,354 --> 00:14:28,574
I had seen impressive results online,
but I wanted to see how well it would

200
00:14:28,664 --> 00:14:31,184
respond to my own creative directions.

201
00:14:31,394 --> 00:14:35,354
So I took some of my favorite mid
journey style prompts and adapted them

202
00:14:35,624 --> 00:14:42,444
for Sora to see how it handled cinematic
language, mood, and details and result

203
00:14:42,444 --> 00:14:45,235
genuinely blew me away for the first time.

204
00:14:45,235 --> 00:14:49,975
The AI seemed to truly get what I was
imagining without endless tweaking.

205
00:14:50,319 --> 00:14:51,699
Or rear rewind prongs.

206
00:14:52,000 --> 00:14:55,120
Skin tones were quie, nuanced and natural.

207
00:14:55,360 --> 00:15:01,510
Photo angles felt intentional as it showed
by professional expressions were subtlely.

208
00:15:01,540 --> 00:15:05,860
Human emotive and believable
backgrounds weren't just feelers.

209
00:15:05,860 --> 00:15:08,230
They were crisp, coherent and detailed.

210
00:15:09,040 --> 00:15:10,210
It wasn't just impressive.

211
00:15:10,240 --> 00:15:11,560
It felt like a creative.

212
00:15:12,189 --> 00:15:13,000
Breakthrough.

213
00:15:13,360 --> 00:15:18,280
Finally, I had a tool that could translate
my mental image onto something visually

214
00:15:18,280 --> 00:15:21,130
tangible, with almost uncanny, precise.

215
00:15:22,040 --> 00:15:27,680
So every tool has its downsides
in my attempt with complex scenes

216
00:15:28,010 --> 00:15:33,199
having multiple people interact
with one another and display motion.

217
00:15:33,199 --> 00:15:34,699
Sora had some difficulties.

218
00:15:35,285 --> 00:15:39,244
Achieving this control took several
iteration, meticulous prompting, and

219
00:15:39,244 --> 00:15:45,964
most of all time that said, once control
Sora produced, Polish marketing, created

220
00:15:45,964 --> 00:15:50,085
assets with little to no ending editing.

221
00:15:52,845 --> 00:15:55,984
So like this neuro Sora also has some.

222
00:15:56,480 --> 00:16:00,390
Nifty features, for instance,
enhancing image resolution.

223
00:16:00,510 --> 00:16:04,920
It's amazing how quickly you can transform
an image to meet higher quality standards,

224
00:16:05,250 --> 00:16:09,690
making it even more versatile for
creative professionals who need polished

225
00:16:09,690 --> 00:16:15,840
visuals on the fly, and then you can
finally get a nice result for product and

226
00:16:15,840 --> 00:16:18,540
marketing purposes, like on this shots.

227
00:16:19,500 --> 00:16:22,980
Oh, when speaking of Sora, I discovered
something really interesting.

228
00:16:22,980 --> 00:16:27,120
It has the capability to remove
the background from images and

229
00:16:27,120 --> 00:16:31,640
it outputs a transparent PNG
file with an Alpha channel.

230
00:16:32,010 --> 00:16:36,660
This feature is beneficial when planning
to add graphics built, compositional

231
00:16:36,660 --> 00:16:43,410
images, or for layering elements as one
can for work freely without a background.

232
00:16:43,440 --> 00:16:45,060
If you prefer Figma, then.

233
00:16:45,465 --> 00:16:48,615
Their recent update has a
builtin background remover, so

234
00:16:48,615 --> 00:16:50,055
you are still covered to do.

235
00:16:50,455 --> 00:16:54,865
You can do everything on the platform
without switching tabs or logged out, and

236
00:16:54,865 --> 00:16:57,415
it makes the whole process effortless.

237
00:16:59,065 --> 00:17:02,215
So a few available lessons
from this journey to start.

238
00:17:02,215 --> 00:17:05,485
Remembering the evolution
of AI model is critical.

239
00:17:05,485 --> 00:17:08,905
Understanding how quickly they
are changing can be overwhelming.

240
00:17:09,385 --> 00:17:12,925
All that needs to be
addressing is remaining agile.

241
00:17:13,360 --> 00:17:18,680
In this context, once mindset should
evolve far faster than technology.

242
00:17:18,740 --> 00:17:22,910
This means that one should be open to
learn and adjust with frameworks and

243
00:17:22,910 --> 00:17:25,220
capabilities that make emerge later.

244
00:17:25,670 --> 00:17:31,370
Moving on, AI tools are not systems
that oblate designers jobs, rather,

245
00:17:31,370 --> 00:17:33,220
they are an empowerment tool.

246
00:17:33,385 --> 00:17:38,965
The argument comes down to whether or
not you will utilize the tool, or in

247
00:17:39,235 --> 00:17:44,155
essence, the manner in which you are as
a designer will be able to utilize it.

248
00:17:44,605 --> 00:17:46,225
Mechanism can assist one.

249
00:17:46,405 --> 00:17:49,825
However, the ability to use
them proficiently separates

250
00:17:50,275 --> 00:17:52,225
an expert and a doubler.

251
00:17:53,365 --> 00:17:57,415
Finally, getting to attach to
one tool or platform can reduce

252
00:17:57,415 --> 00:17:58,915
productivity drastically.

253
00:17:59,275 --> 00:18:04,555
To reframe all your available
option is in the toolkit can be

254
00:18:04,885 --> 00:18:07,165
unhelpful if your creativity is Stu.

255
00:18:08,125 --> 00:18:12,865
Equally creative intuition is
where your value lies and is more

256
00:18:12,865 --> 00:18:15,385
important than any gadgets or tool.

257
00:18:16,045 --> 00:18:20,815
That said, once mind as a tool never
goes out of style, creative empathy

258
00:18:20,815 --> 00:18:25,235
and a vision available assets,
which unlock endless possibility.

259
00:18:26,015 --> 00:18:27,215
So thank you.

260
00:18:28,220 --> 00:18:31,290
I hope you really enjoyed by this speech.

261
00:18:31,710 --> 00:18:32,130
Thank you.

