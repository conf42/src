1
00:00:00,500 --> 00:00:01,760
Hi everyone.

2
00:00:02,675 --> 00:00:07,254
My greetings to you all as this
conference can be viewed by

3
00:00:07,254 --> 00:00:09,105
across, by via the worldwide.

4
00:00:09,615 --> 00:00:11,895
I'm just giving without the time zone.

5
00:00:12,194 --> 00:00:14,685
Some maybe in good morning, good
afternoon, and good evening.

6
00:00:14,685 --> 00:00:18,825
So I just want to say my
greetings to you all and myself.

7
00:00:18,854 --> 00:00:22,755
I am seeing you as man, and I'm
currently working in Fidelity

8
00:00:22,755 --> 00:00:25,575
investment as senior manager and.

9
00:00:26,144 --> 00:00:30,130
I just want to walk you through
the observability the micro, the

10
00:00:30,134 --> 00:00:32,335
observability, micro in the microservices.

11
00:00:32,335 --> 00:00:37,675
How we really evolve from the
basic, traditional and with

12
00:00:37,735 --> 00:00:39,385
current situation where we are.

13
00:00:39,775 --> 00:00:44,815
And if we imply, if we empower that
observability with more AI enablement

14
00:00:44,815 --> 00:00:49,435
tools, how we are going to leverage
and what we can envision the future.

15
00:00:49,945 --> 00:00:51,385
Way of operation mechanism.

16
00:00:51,445 --> 00:00:54,425
That's the intent of the
whole my presentation.

17
00:00:55,325 --> 00:00:58,085
It's basically called as
AI powered observability in

18
00:00:58,085 --> 00:00:59,585
microservices architecture.

19
00:01:00,185 --> 00:01:00,394
Okay.

20
00:01:00,394 --> 00:01:03,394
It's beyond metrics where we
started from initially, but

21
00:01:03,394 --> 00:01:04,625
now where we are landing now.

22
00:01:05,225 --> 00:01:07,955
So just let us get into the presentation.

23
00:01:08,045 --> 00:01:09,935
I will go very quick on the introduction.

24
00:01:10,545 --> 00:01:14,175
As currently in the tradition we
used to have monolithic applications

25
00:01:14,445 --> 00:01:16,965
and now we are moving toward
the microservices architecture.

26
00:01:17,385 --> 00:01:21,165
We started with the monolithic
traditional monitoring approaches,

27
00:01:21,165 --> 00:01:25,735
basically like alerts, some set
of threshold alerts to give the

28
00:01:25,735 --> 00:01:27,025
infrastructure health and everything.

29
00:01:27,145 --> 00:01:30,815
That is our start of our basic
health monitoring systems.

30
00:01:30,820 --> 00:01:32,095
We call now, we are moving into more.

31
00:01:32,455 --> 00:01:34,615
Microservices distributor systems.

32
00:01:35,095 --> 00:01:39,005
So the traditional mechanism
that we applied are nowhere

33
00:01:39,605 --> 00:01:41,975
able to meet the today's needs.

34
00:01:42,245 --> 00:01:45,940
Hence, we are transformed
or transformed or evolved.

35
00:01:46,565 --> 00:01:51,005
As we move from one technical to
another involvement the same way the

36
00:01:51,005 --> 00:01:55,985
operation management has been evolving
from one decade to another time span.

37
00:01:56,465 --> 00:02:01,055
So this is basically my intent is to
say, Hey, now we are in the AI era.

38
00:02:01,830 --> 00:02:06,690
If we apply, if we enable this
observability with the AI features,

39
00:02:07,080 --> 00:02:09,270
how we can really make it more better.

40
00:02:09,510 --> 00:02:14,030
We actually, if you speak, we are already
leveraging that, but still I would really

41
00:02:14,030 --> 00:02:18,650
want to call out here basically with
my experience, how this observability

42
00:02:18,650 --> 00:02:23,540
is so important and how the AI can
really help observatory more in future.

43
00:02:23,690 --> 00:02:24,800
That's the intent of this.

44
00:02:25,645 --> 00:02:30,685
I would like to even see the framework
that we can build upon and then practice

45
00:02:30,685 --> 00:02:34,195
that observability as we go on with
new things coming up, and that will

46
00:02:34,675 --> 00:02:37,165
eventually help us a lot on ongoing.

47
00:02:37,525 --> 00:02:39,505
That's the intent of this whole exercise.

48
00:02:39,955 --> 00:02:42,925
I will just start with my first,
the evolution of observability.

49
00:02:42,925 --> 00:02:46,315
You know that we initially
started with the traditional

50
00:02:46,315 --> 00:02:47,905
monitoring where, and then.

51
00:02:48,215 --> 00:02:51,905
Monolithic application as I called
out before, we have to have an

52
00:02:51,905 --> 00:02:54,155
alerts or some sort of basic alerts.

53
00:02:54,425 --> 00:02:58,930
He's a. Database is down or it's up,
or is a basic alert system that was

54
00:02:58,930 --> 00:03:02,830
making, basically the administrator
used to get, and basically they act

55
00:03:02,830 --> 00:03:06,430
upon that alerts and work on that is
called the traditional monitoring.

56
00:03:06,880 --> 00:03:12,580
From there, we evolve into the next
set, and that is a very important,

57
00:03:12,580 --> 00:03:14,380
which I will take a little more time on.

58
00:03:14,440 --> 00:03:17,470
What is the basic observability in?

59
00:03:17,590 --> 00:03:22,600
In observability, we have three main
factors, the three pillars, the metrics.

60
00:03:22,895 --> 00:03:27,665
Logs and traces metrics, it
gives a very high level overview.

61
00:03:28,645 --> 00:03:34,864
Of the system, the CP usage, the
threshold times basically the response

62
00:03:34,864 --> 00:03:39,215
times or the error rate, the memory
usages, everything of the application

63
00:03:39,374 --> 00:03:44,384
the infrastructure, basically it's
a high level coming to the logs.

64
00:03:44,414 --> 00:03:46,064
It's a granular level of the view.

65
00:03:46,274 --> 00:03:50,524
It more tells about the events,
the basically the warning, the

66
00:03:50,524 --> 00:03:52,385
information, messages and everything.

67
00:03:52,415 --> 00:03:54,605
It's more of a granular
view of this system.

68
00:03:54,730 --> 00:03:55,179
Okay.

69
00:03:55,660 --> 00:03:59,200
Then we have the traces,
basically how a request is

70
00:03:59,200 --> 00:04:00,970
traversing within the application.

71
00:04:01,299 --> 00:04:02,859
Is there any blockers for that?

72
00:04:02,950 --> 00:04:07,339
It's basically to trace the the requests
that are incoming to the application.

73
00:04:07,339 --> 00:04:11,269
So these are the three categories
of application these categories.

74
00:04:11,644 --> 00:04:17,164
Of the data points that we used to
collect to understand, and that was

75
00:04:17,164 --> 00:04:21,034
our initial basic observability that
we, from where the other system we

76
00:04:21,034 --> 00:04:25,445
started, then we categorized into
three sectors and we started using

77
00:04:25,445 --> 00:04:27,215
them as our base for a very long term.

78
00:04:27,480 --> 00:04:29,640
The basic, these three
were very long term.

79
00:04:29,850 --> 00:04:30,840
We've been using them.

80
00:04:31,140 --> 00:04:36,840
And now the initial observability is
basically like you get an alert, you get

81
00:04:36,840 --> 00:04:40,530
a metrics or your data, you collect the
data of metrics or logs and everything.

82
00:04:40,830 --> 00:04:44,340
And then based on that, we have to
take a reactor approach basically.

83
00:04:44,340 --> 00:04:44,550
Yes.

84
00:04:44,580 --> 00:04:48,510
What needed to be done for now, that
is our trend where it used to be.

85
00:04:48,840 --> 00:04:52,850
Now given this new let us
take around five years, maybe.

86
00:04:52,910 --> 00:04:55,244
No I think I will go with 10, 7, 8 years.

87
00:04:55,744 --> 00:04:57,544
Once we started this cloud.

88
00:04:57,604 --> 00:05:03,424
S infrastructure coming up, we
really had a more better enhanced

89
00:05:03,424 --> 00:05:04,924
version of the observability.

90
00:05:04,924 --> 00:05:10,354
Where the cloud platforms are really put
a very good focus on this because they

91
00:05:10,354 --> 00:05:15,814
know that these are the very key factors
for any cloud provider that if they

92
00:05:15,814 --> 00:05:17,524
don't provide the infrastructure health.

93
00:05:17,559 --> 00:05:21,669
To the consumers, they'll not be
really being sustaining the market.

94
00:05:21,669 --> 00:05:23,559
So they really focus on the observability.

95
00:05:24,279 --> 00:05:29,589
They enhanced it in such a way that they
take a next step, not just collecting

96
00:05:29,589 --> 00:05:31,719
the data, not just collecting the data.

97
00:05:31,959 --> 00:05:36,879
They applied some sort of pattern
analysis on this to understand what

98
00:05:36,879 --> 00:05:39,099
is a peak time of a usage of a system.

99
00:05:39,369 --> 00:05:43,879
What is the low time or
what is the what is the non.

100
00:05:44,229 --> 00:05:46,508
What do you call, I can
say non-working hours.

101
00:05:46,508 --> 00:05:48,789
How, what are the maintenance
hours we can come?

102
00:05:48,938 --> 00:05:53,318
So this analysis has helped us to
come with the maintenance hours to

103
00:05:53,318 --> 00:05:56,289
know what is the peak hours, how to
manage the resources based on that.

104
00:05:56,529 --> 00:06:01,479
This is the AI enhanced observability
is I don't I, the reason why I call

105
00:06:01,479 --> 00:06:07,149
this a ns, this started using this
data, analyzing them and applying

106
00:06:07,149 --> 00:06:11,289
some thought process of what we can
take a predictive approach like, hey.

107
00:06:11,544 --> 00:06:13,944
This is a time in a day, a very high peak.

108
00:06:13,944 --> 00:06:17,724
Covers are the how we can apply
a resource optimization there.

109
00:06:18,114 --> 00:06:20,484
What are the things that I can
do in the maintenance, which

110
00:06:20,484 --> 00:06:21,714
I should not in a peak hours.

111
00:06:21,984 --> 00:06:25,194
That type of predictive analysis has
helped us to know where we need to

112
00:06:25,194 --> 00:06:28,764
do maintain hours, where we need to
increase the resource that is the

113
00:06:29,244 --> 00:06:31,044
advantage of this enhanced observative.

114
00:06:31,544 --> 00:06:33,854
The next one, which I want to call out is.

115
00:06:34,634 --> 00:06:38,564
Not just manual intervention of
increasing the resource and everything.

116
00:06:38,954 --> 00:06:43,874
Now think about if I can really
make autoscaling horizonal

117
00:06:43,874 --> 00:06:45,254
scaling or vertical scaling.

118
00:06:45,254 --> 00:06:48,764
If you remember, in cloud, we have right
now based on the peak hours or based

119
00:06:48,764 --> 00:06:52,574
on the season, like a Thanksgiving,
where Amazon has a high volume of

120
00:06:52,579 --> 00:06:57,034
data, consumers hitting the system,
they know that they need to scale out.

121
00:06:57,534 --> 00:07:02,304
At that moment of time and they need
to crunch back at the once it is done,

122
00:07:02,604 --> 00:07:05,694
so it's basically self-healing system.

123
00:07:06,084 --> 00:07:11,873
It's basically self feeling based on the
data, analyzing the predictor analysis,

124
00:07:11,873 --> 00:07:14,183
and then applying a healing system.

125
00:07:14,334 --> 00:07:18,384
And that is what is, so where we started
from just collecting the data, which

126
00:07:18,384 --> 00:07:23,484
is our traditional, now where we are is
we are taking the data, applying our AI

127
00:07:23,484 --> 00:07:28,164
enablement, and then taking a measures
without even a manual intervention.

128
00:07:28,193 --> 00:07:29,604
Hence, this is a real.

129
00:07:30,104 --> 00:07:31,304
Evolution of an Observ team.

130
00:07:31,724 --> 00:07:35,474
That's what I want to call from, where
we started from where we are now, and

131
00:07:35,474 --> 00:07:37,634
where we can go more further on this.

132
00:07:38,134 --> 00:07:39,304
Let me go to the next slide.

133
00:07:39,904 --> 00:07:40,804
The three pillars.

134
00:07:40,954 --> 00:07:45,333
These three pillars as I called
out the metrics the sorry, metrics,

135
00:07:45,333 --> 00:07:47,854
logs, and traces as I called out.

136
00:07:48,094 --> 00:07:52,234
Metrics, high level overview it
call more talks about CPU U stages

137
00:07:52,563 --> 00:07:57,304
and or the pa. Basically it has the
data related to the infrastructure.

138
00:07:57,784 --> 00:08:02,974
Then the logs is basically about a
granular level of what are the usages and.

139
00:08:03,203 --> 00:08:04,163
Sorry, my mistake.

140
00:08:04,583 --> 00:08:07,873
Granular usage of the information,
including error and everything.

141
00:08:07,873 --> 00:08:11,353
And then the other one is basically the
traces, the request flow and everything.

142
00:08:11,503 --> 00:08:11,804
Okay.

143
00:08:12,193 --> 00:08:13,093
These are the basic thing.

144
00:08:13,424 --> 00:08:13,904
No.

145
00:08:14,088 --> 00:08:19,093
If these three pillars, if we live as is,
we could have not achieved where we are.

146
00:08:19,453 --> 00:08:24,223
We have really transformed them, these
metrics and the logs and applied more.

147
00:08:24,724 --> 00:08:28,623
Frameworks or I know I can
say more technical innovations

148
00:08:28,623 --> 00:08:29,794
are done on this three.

149
00:08:30,334 --> 00:08:34,054
In order to see that, how we can
leverage, for example, metrics, CPU

150
00:08:34,054 --> 00:08:38,733
stages apply the historical data pattern
recognition so that we can know when

151
00:08:38,733 --> 00:08:45,314
to scale out, when to, not to scale out
logs, what type of errors are coming up.

152
00:08:45,614 --> 00:08:48,854
Basically to see which is,
this will help us to know.

153
00:08:49,354 --> 00:08:54,124
What is a frequent error or frequent
issues that are coming up and how we can

154
00:08:54,124 --> 00:08:55,984
really proactively take a measures on it.

155
00:08:55,984 --> 00:09:00,154
For example, database, many people are
hitting at one time and the database

156
00:09:00,154 --> 00:09:03,934
not reachable, so they can really take
a proactive measures based on the logs.

157
00:09:04,024 --> 00:09:08,554
Seeing that granular above that
information, the system traces basically

158
00:09:08,554 --> 00:09:12,904
which features are used more frequently,
how we can scale out that microservices

159
00:09:12,904 --> 00:09:15,034
more than the ones which are not used.

160
00:09:15,244 --> 00:09:18,124
So this is something an intelligence.

161
00:09:18,154 --> 00:09:22,384
Getting applied onto the tree
and making them more mature.

162
00:09:22,594 --> 00:09:26,704
So that will help us for our, take
us more life, more smoother, because

163
00:09:26,974 --> 00:09:29,854
if we have issues, we are day and
day out, we cannot burn ourselves.

164
00:09:30,124 --> 00:09:33,574
But if you apply intelligence on
this and make our life more easy,

165
00:09:33,814 --> 00:09:37,534
and that will help eventually the
operations, more simple, easy to manage.

166
00:09:38,034 --> 00:09:41,514
One of the important thing about
the observability is the SLOs.

167
00:09:41,964 --> 00:09:46,294
So I will even want to share one
of my recent experience on this

168
00:09:46,684 --> 00:09:51,064
technical methods, so we know we have
a technical, and when we know there's

169
00:09:51,064 --> 00:09:54,454
a business, unless we map this too.

170
00:09:55,114 --> 00:09:59,274
There'll never be a there'll never
be a for example a consensus.

171
00:09:59,514 --> 00:10:04,024
For example, if I want to enhance
my observability with more of with

172
00:10:04,024 --> 00:10:07,864
my, more of my knowledge with more
of my implementation, unless I get

173
00:10:07,864 --> 00:10:12,724
a business value of it out of it, I
cannot really do an investment on this.

174
00:10:12,964 --> 00:10:16,834
So basically what I really want
to sell is, unless you really.

175
00:10:17,329 --> 00:10:23,029
Correlate what your technical metrics,
data that capturing to the business KPIs.

176
00:10:23,389 --> 00:10:26,809
There will never be a buy-in for us
to really invest a lot on Observ.

177
00:10:26,868 --> 00:10:28,098
It comes with the cost.

178
00:10:28,598 --> 00:10:31,238
Observability comes with the
cost, and the cost need to be.

179
00:10:31,988 --> 00:10:35,069
Need to be approved by the
business and the business.

180
00:10:35,069 --> 00:10:36,689
Need to see the value out of it.

181
00:10:36,929 --> 00:10:37,799
What we are doing here.

182
00:10:38,128 --> 00:10:43,738
And that value can only be correlated
unless we can measure one, unless we map

183
00:10:44,069 --> 00:10:46,348
the business KPIs with what we are doing.

184
00:10:46,348 --> 00:10:48,748
For example, user customer satisfaction.

185
00:10:48,748 --> 00:10:50,368
What I'm taking, the
customer satisfaction.

186
00:10:50,669 --> 00:10:54,419
Customer satisfaction comes with
a latency, unless you have a data.

187
00:10:54,709 --> 00:10:59,299
To really capture the latency issues
in your systems, you cannot really

188
00:10:59,299 --> 00:11:01,638
assess, gauge the customer satisfaction.

189
00:11:02,268 --> 00:11:07,039
Another one is to put capacity, same
thing, then the revenue per transaction.

190
00:11:07,399 --> 00:11:11,959
Unless you know what is the cost
on revenue, cost on transaction per

191
00:11:11,959 --> 00:11:17,478
transaction, per participant, or for
the, for a customer or for a business

192
00:11:17,478 --> 00:11:20,029
order, we cannot really assess.

193
00:11:20,534 --> 00:11:22,574
How much our systems are used sometime.

194
00:11:22,574 --> 00:11:26,204
If the order takes long time,
it means we are not able to make

195
00:11:26,414 --> 00:11:28,424
within, we cannot scale up ourself.

196
00:11:28,664 --> 00:11:31,304
So this combination is very important and.

197
00:11:31,804 --> 00:11:37,144
To get, to improve, sustain our
observability and pro and to

198
00:11:37,144 --> 00:11:41,074
apply our practice on a long, we
definitely need a business approval.

199
00:11:41,223 --> 00:11:44,944
And the business can only approve
unless we show the value of what we

200
00:11:44,944 --> 00:11:49,113
are doing and how it can help the
application and how it can help them

201
00:11:49,324 --> 00:11:50,978
from their sales pitch point of view.

202
00:11:51,124 --> 00:11:53,698
What we are doing, that's
what is, for example cloud.

203
00:11:53,698 --> 00:11:57,158
When they share, they will definitely
tell, hey, how we are going how our

204
00:11:57,158 --> 00:12:00,308
observability practices are helping you.

205
00:12:00,748 --> 00:12:03,608
Unless then you'll not ever
go and make yourself as a cus

206
00:12:03,668 --> 00:12:05,308
customer to the cloud provider.

207
00:12:05,308 --> 00:12:10,618
In the same way for any application,
unless we have the metrics, data and

208
00:12:10,618 --> 00:12:14,153
observability, all this logs properly
enhanced and how we are leveraging.

209
00:12:14,843 --> 00:12:18,684
And which the customer will never
be able to come to our systems.

210
00:12:18,924 --> 00:12:20,444
That's the intent of the SLO.

211
00:12:20,654 --> 00:12:27,044
We really need to have a precise mapping
of this business, K ps, stored technical

212
00:12:27,044 --> 00:12:32,564
metrics, logs, and everything places so
that we really have a good value benefit.

213
00:12:32,863 --> 00:12:36,994
And then only we can really sustain
the practice of observability within

214
00:12:36,994 --> 00:12:41,284
our system as it'll be very, because
it comes with a cost, and cost cannot

215
00:12:41,284 --> 00:12:43,654
be done without a business approach.

216
00:12:44,154 --> 00:12:46,884
Now coming to the implementation
framework, what I really want

217
00:12:46,884 --> 00:12:51,233
to call here is building a
mature observative framework.

218
00:12:51,504 --> 00:12:55,134
It is not just an observative,
cannot be done just on one day.

219
00:12:55,464 --> 00:12:57,924
It is need to build as a building blocks.

220
00:12:58,194 --> 00:12:59,874
You need to start collecting the data.

221
00:12:59,904 --> 00:13:03,674
Then you need to apply some
set of validation checks.

222
00:13:04,154 --> 00:13:07,603
Today you are going to apply the
observability checks, like collecting

223
00:13:07,603 --> 00:13:11,084
the logs, collecting the matrix data,
collecting the tracers and everything.

224
00:13:11,353 --> 00:13:13,784
Now, think about as we go on.

225
00:13:14,639 --> 00:13:20,579
We may build new microservices, so we
need to ensure some controls to ensure

226
00:13:20,579 --> 00:13:24,479
that observability checks are being
part of that existing development.

227
00:13:24,959 --> 00:13:26,969
For example, a new microservices.

228
00:13:27,334 --> 00:13:31,439
If we don't ensure the value sanity
check on that new micro and is

229
00:13:31,439 --> 00:13:35,099
getting deployed to production, we
may ensure and end up in an issue.

230
00:13:35,279 --> 00:13:39,489
So we need to ensure that the
implementation required for

231
00:13:39,489 --> 00:13:41,589
observability is being applied.

232
00:13:41,949 --> 00:13:45,759
As part of the build, CICD
pipelines, we can apply new checks

233
00:13:45,759 --> 00:13:47,649
like sonar code coverage checks.

234
00:13:47,649 --> 00:13:51,839
That's not a basic, but logs
basically integration testing.

235
00:13:52,019 --> 00:13:56,849
There are a lot of means of testing where
we can ensure as a check list has these

236
00:13:56,849 --> 00:14:01,529
are been done that will help us to sustain
this observative practice a long term.

237
00:14:02,099 --> 00:14:06,809
Then coming to the intelligent analysis,
basically what I'm saying is applying the.

238
00:14:07,309 --> 00:14:13,489
Models, ml or machine learning models, or
you can say AI or AI algorithms to ensure

239
00:14:13,489 --> 00:14:17,449
that how we can leverage this collected
data and do the predictive analysis.

240
00:14:17,689 --> 00:14:22,939
And then finally, AI ops, basically Remi,
predictive and based on predictive, how

241
00:14:22,939 --> 00:14:25,789
we can make them self-healing system.

242
00:14:25,909 --> 00:14:29,269
That is the basic implementation
of the framework, Steve.

243
00:14:29,769 --> 00:14:30,429
Progressing.

244
00:14:30,789 --> 00:14:33,939
Each layer of the period builds
on the capabilities below it.

245
00:14:33,939 --> 00:14:37,359
Creating an observability practice that
evolves with your organization needs.

246
00:14:38,289 --> 00:14:43,449
So based on our organization needs, we
need to ensure that we do have everything

247
00:14:43,449 --> 00:14:46,299
in place and we do maintain that.

248
00:14:46,719 --> 00:14:49,959
And even though when a new application
is coming, or the new services are

249
00:14:49,959 --> 00:14:53,619
coming within the organization or
buildup, we need to ensure that we are.

250
00:14:54,119 --> 00:14:59,609
Making as a process that every
developer or every business has

251
00:14:59,609 --> 00:15:03,329
this observability checks and hence
the team at an organization level

252
00:15:03,329 --> 00:15:04,889
who maintains this operations.

253
00:15:05,219 --> 00:15:10,429
They are really having this controls and
checks so that there's no, just an example

254
00:15:10,429 --> 00:15:16,639
of penetration testing if we don't have a
proper metrics to ensure that a pen test.

255
00:15:17,029 --> 00:15:18,109
Mechanisms not there.

256
00:15:18,139 --> 00:15:20,599
Then we may be prone to a vulnerability.

257
00:15:20,809 --> 00:15:24,349
Hence, these are some of the important
things that we need to imply in our

258
00:15:24,349 --> 00:15:28,039
framework and then continue, and
that will sustain for our practice.

259
00:15:28,539 --> 00:15:30,999
Some of the open source systems
on observability is graph.

260
00:15:31,194 --> 00:15:33,414
I have, they are telemetry.

261
00:15:33,414 --> 00:15:36,744
There are a lot of tools here, which
I can list at kin and everything.

262
00:15:36,984 --> 00:15:39,504
But one of the important tools
which I like most and I've

263
00:15:39,504 --> 00:15:40,884
been personally using is graph.

264
00:15:41,544 --> 00:15:43,644
It really gives excellent.

265
00:15:44,284 --> 00:15:47,464
View visualization of the
underneath metrics locks

266
00:15:48,244 --> 00:15:50,194
place the predictor analysis.

267
00:15:50,224 --> 00:15:52,804
It even provides the suggestions.

268
00:15:53,104 --> 00:15:57,364
What we can do, and it even the, one
of the important other, the allowable

269
00:15:57,364 --> 00:16:02,884
factor that I, for me is the dashboards
based on the custom, based on the user.

270
00:16:03,279 --> 00:16:04,959
You can really build your own dashboard.

271
00:16:04,989 --> 00:16:08,229
I may be interested in metrics
analyst, the other person may

272
00:16:08,229 --> 00:16:09,639
be interested in log analysis.

273
00:16:09,639 --> 00:16:13,179
The other person may be, so you can
build your dashboards, focusing on

274
00:16:13,179 --> 00:16:16,959
where you are interested and that
really gives a visualization and even.

275
00:16:17,799 --> 00:16:21,069
Helping in you can even
build your own data.

276
00:16:21,339 --> 00:16:26,209
It has its own supporting query language
and that is really a very valuable thing

277
00:16:26,209 --> 00:16:31,489
that helps a lot for us to even query
the data that we want to assess or get

278
00:16:31,489 --> 00:16:32,989
pitch the historical data and everything.

279
00:16:32,989 --> 00:16:37,219
That's a very good, so what I really
want to say from this slide is.

280
00:16:37,719 --> 00:16:40,269
We started with this
observability concept.

281
00:16:40,329 --> 00:16:45,909
Now we are in a stage where there's a
vast amount of tools built upon, and every

282
00:16:45,909 --> 00:16:47,739
tool has been has its own capability.

283
00:16:48,069 --> 00:16:52,359
We just need to plug in that tool into
our system based on our automation

284
00:16:52,359 --> 00:16:56,919
needs, customize it, and see that we
have the complete system in place.

285
00:16:57,369 --> 00:17:01,629
So the framework that I talked about
previously, that is what you really

286
00:17:01,629 --> 00:17:05,619
want from your observability, what you
really want to capture, and how you can

287
00:17:05,619 --> 00:17:09,579
map that into a tool which is already,
like Grafana is an open source tool.

288
00:17:09,999 --> 00:17:13,719
You can apply it, customize it,
and make your system, and then you

289
00:17:13,719 --> 00:17:16,604
need to practice this, basically
sustain that observability.

290
00:17:17,104 --> 00:17:20,674
The other important thing about this
observability is a contextual alerting.

291
00:17:20,884 --> 00:17:21,154
Okay?

292
00:17:21,364 --> 00:17:24,994
Initially, we used to get in normal
alerts, Hey, this is alert and our

293
00:17:24,994 --> 00:17:27,184
production database is getting down.

294
00:17:27,574 --> 00:17:28,564
That was a basic alert.

295
00:17:28,564 --> 00:17:29,734
You used to get in emails.

296
00:17:30,124 --> 00:17:34,284
Now with this new technology
at your mobile, you can get it.

297
00:17:35,274 --> 00:17:37,044
There's something on you doesn't need.

298
00:17:37,344 --> 00:17:39,654
People used to sit in front of
the system in the traditional,

299
00:17:39,984 --> 00:17:42,394
like they were like shift wise.

300
00:17:42,424 --> 00:17:44,464
People used to sit in front
of the system watching.

301
00:17:44,469 --> 00:17:45,549
Now that's not required.

302
00:17:45,909 --> 00:17:49,899
With this new technology we are able
to get the alerts on your mobile.

303
00:17:50,169 --> 00:17:52,839
That's ideally need to create
the technology advancement,

304
00:17:53,169 --> 00:17:55,119
but not only just that one.

305
00:17:55,869 --> 00:17:59,019
Right now I can, because
I'm experiencing that.

306
00:17:59,919 --> 00:18:05,229
It'll even suggest you what is a similar
incident happened previously and what

307
00:18:05,229 --> 00:18:11,259
was the action done previously and how we
can suggest, say if a person who is on a

308
00:18:11,289 --> 00:18:15,519
on call and he got an alert saying that,
Hey, there's something happened, contact,

309
00:18:16,029 --> 00:18:22,299
he will have a provision from the alert
itself to refer to the previous incident

310
00:18:22,359 --> 00:18:26,919
that was previously done and see how we
can, it's, this is a contextual alerting.

311
00:18:26,919 --> 00:18:28,414
Basically you got an alert.

312
00:18:28,944 --> 00:18:31,554
But at the same time, it is giving
a history of the previous alerts

313
00:18:31,699 --> 00:18:37,794
for you to refer, and you can even
delegate to a right person who has

314
00:18:37,794 --> 00:18:39,534
previously worked on a similar incident.

315
00:18:39,714 --> 00:18:43,194
If he is available, you can even
delegate that incident to that person.

316
00:18:43,404 --> 00:18:46,074
So for a faster resolution,
this is all else.

317
00:18:46,574 --> 00:18:47,774
Before it was not the case.

318
00:18:47,834 --> 00:18:51,194
We don't know who worked on a similar
issue, but now we have a history

319
00:18:51,194 --> 00:18:54,854
of data and it even suggesting us,
Hey, there is a previous history.

320
00:18:55,064 --> 00:18:58,784
These other steps are executed and
this is what we can do and is the

321
00:18:58,784 --> 00:19:02,234
person available in the system, let
us go and reach the person so it's

322
00:19:02,234 --> 00:19:04,754
more of faster resolution of incident.

323
00:19:05,144 --> 00:19:07,424
This is all helps us
for faster resolution.

324
00:19:07,924 --> 00:19:11,474
I just want to take more just
take a intelligent routing

325
00:19:11,534 --> 00:19:12,644
that is also very important.

326
00:19:12,974 --> 00:19:16,424
We have many people in the system
who are monitoring the operations.

327
00:19:17,024 --> 00:19:19,844
Not everyone is dedicated
to for all the people.

328
00:19:20,144 --> 00:19:23,594
There are certain set of sector
people who are very privileged.

329
00:19:24,044 --> 00:19:24,824
Experience.

330
00:19:25,004 --> 00:19:26,714
So they will get those alerts.

331
00:19:26,774 --> 00:19:32,324
We can even delegate which alert to go
home so that we have a proper incident

332
00:19:32,324 --> 00:19:37,724
management done in the right time so
that the MT the meantime to resolution.

333
00:19:37,774 --> 00:19:38,794
It gets resolved.

334
00:19:38,854 --> 00:19:40,354
It gets reduced drastically.

335
00:19:40,774 --> 00:19:42,574
Before it was like one day, two day.

336
00:19:42,574 --> 00:19:46,439
Just an example, I'm giving now in
hours, we are able to reduce in hours.

337
00:19:47,269 --> 00:19:49,319
This is all because how.

338
00:19:49,819 --> 00:19:53,979
How we are able to apply our
intelligence on our lessons.

339
00:19:54,039 --> 00:19:56,589
It is basically lessons learned
from previous experience.

340
00:19:56,859 --> 00:19:58,209
Where are our bottlenecks?

341
00:19:58,659 --> 00:19:59,829
Where are our improvement areas?

342
00:20:00,039 --> 00:20:03,039
How we can apply this
AI models and into that.

343
00:20:03,279 --> 00:20:04,809
And so that we can make ourself.

344
00:20:04,899 --> 00:20:08,614
It's more of, as we go on, we will
improve, and I don't know, tomorrow

345
00:20:08,764 --> 00:20:09,934
it could be a mechanism where.

346
00:20:10,434 --> 00:20:14,124
With this new robots and everything,
things may be more changing, but

347
00:20:14,424 --> 00:20:18,294
contextual editing is basically
helping you to give the history

348
00:20:18,294 --> 00:20:21,774
data and even provide the people
whom you can delegate the requests.

349
00:20:22,274 --> 00:20:22,544
Yeah.

350
00:20:22,634 --> 00:20:27,004
Sorry, I just, I went ahead before my,
this is, what is the outcome of that?

351
00:20:27,814 --> 00:20:34,024
Context reduction in the fast incident,
MTR reduction, predictive accuracy.

352
00:20:34,294 --> 00:20:37,174
So based on the all alerts, you
can predict what could be the issue

353
00:20:37,174 --> 00:20:38,254
based on the previous history.

354
00:20:38,254 --> 00:20:42,874
Also, then collaboration as I just called
out, there's an improved collaboration

355
00:20:42,874 --> 00:20:46,354
between, because you know whom to
reach, you know whom to delegate.

356
00:20:46,654 --> 00:20:48,394
It's an increase and ready you are.

357
00:20:48,814 --> 00:20:52,024
Instead of just putting on one person,
you're delegating it to the right people.

358
00:20:52,204 --> 00:20:55,384
So concurrent issues can
also be resolved with this.

359
00:20:55,884 --> 00:20:59,304
Now the very important thing about
this is a next phase, which I

360
00:20:59,304 --> 00:21:03,054
thought right now we started with
traditional, then we went to this

361
00:21:03,444 --> 00:21:06,404
what you call the basic observability.

362
00:21:06,404 --> 00:21:09,374
Then we went to the enhanced
version, then the self feeling.

363
00:21:09,374 --> 00:21:10,874
Now think about the generate ai.

364
00:21:11,204 --> 00:21:12,164
Now this is a new version.

365
00:21:12,824 --> 00:21:18,059
Think about in observability Grafana,
understand if we built a chat bot.

366
00:21:18,854 --> 00:21:20,744
And which can help us.

367
00:21:21,194 --> 00:21:25,634
You can question, I got an incident and
I want to understand what can I do here?

368
00:21:26,134 --> 00:21:32,134
It is giving you based on the previous
historical data, how, what are steps to

369
00:21:32,134 --> 00:21:38,734
be done and it even shows you some set of
previous incidents so that you can really

370
00:21:38,734 --> 00:21:43,489
understand, apply so that it basically
leveraging the previous historical data.

371
00:21:43,939 --> 00:21:44,749
Just an example.

372
00:21:45,079 --> 00:21:47,029
The other one is incident.

373
00:21:47,814 --> 00:21:50,064
You get an incident,
someone locks an incident.

374
00:21:50,634 --> 00:21:53,364
But here, based on this.

375
00:21:54,009 --> 00:21:59,109
Generally if a similar incident
happened, you can really accumulatively

376
00:21:59,409 --> 00:22:03,009
build up a very good summary and it
can make the user to understand, hey,

377
00:22:03,279 --> 00:22:07,059
this could be possible, these reasons,
and this is where is a major problem.

378
00:22:07,239 --> 00:22:10,450
So most frequently when this
incident comes, this is the

379
00:22:10,455 --> 00:22:12,069
area of a fixed measure be done.

380
00:22:12,489 --> 00:22:13,959
So can you, can I check that one?

381
00:22:14,349 --> 00:22:15,609
It basically helps.

382
00:22:15,889 --> 00:22:19,669
To identify the root cause analysis
very quicker with the summary.

383
00:22:20,029 --> 00:22:24,439
Basically, it brings all the incidents of
together and gives the summary of what are

384
00:22:24,439 --> 00:22:28,489
the fixes done across and what is a common
fix mostly done so that you can really

385
00:22:28,489 --> 00:22:30,469
first go and attack that, fix that issue.

386
00:22:30,859 --> 00:22:33,524
That is basically the incident
summary, and the other one is.

387
00:22:34,024 --> 00:22:37,384
Suggestion, as I said, what are
the suggestion based on historical?

388
00:22:37,384 --> 00:22:43,359
So if we bring the generator AI
into the system, not just AI models

389
00:22:43,359 --> 00:22:46,749
and everything, even now apply the
generator on the historical data,

390
00:22:47,079 --> 00:22:48,729
you really making more better.

391
00:22:48,789 --> 00:22:53,109
Even a new person who is very new
to system, he doesn't need to really

392
00:22:53,799 --> 00:22:56,139
aware, he doesn't need to go with
the KT sessions and everything.

393
00:22:56,439 --> 00:23:00,009
We can just say, Hey, use the
chat bot, get the information,

394
00:23:00,159 --> 00:23:00,999
and you are on your own.

395
00:23:01,404 --> 00:23:08,064
That is more like you're making everyone
a new person, an independent by with

396
00:23:08,064 --> 00:23:12,354
this, all this data because no one
needs any information from a person.

397
00:23:12,354 --> 00:23:14,064
Everything information
is in the historical.

398
00:23:14,064 --> 00:23:16,914
You just need to grab it,
understand, and apply your thoughts.

399
00:23:17,414 --> 00:23:22,214
The last one is basically, as I
said, observability is basically

400
00:23:22,409 --> 00:23:23,579
a discipline you can say.

401
00:23:24,029 --> 00:23:28,079
As we, when we build a new application
within our ordination, you need

402
00:23:28,079 --> 00:23:31,019
to ensure that the discipline
is followed across in all the

403
00:23:31,019 --> 00:23:35,279
applications so that we have a proper
operation, KPS data being collected.

404
00:23:36,239 --> 00:23:40,739
And if this practice has been
applied concurrently or con, not

405
00:23:40,889 --> 00:23:44,499
concurrently or con, the right word is
ensuring that discipline is followed.

406
00:23:44,999 --> 00:23:50,879
Consistently across within, then
you are really preparing yourself

407
00:23:50,969 --> 00:23:55,129
for a better application, operation
management for your organization.

408
00:23:55,309 --> 00:23:59,449
So that your operation cost will
come down drastically because your

409
00:23:59,449 --> 00:24:02,709
incident management coming down the
turnaround your predictor analysis

410
00:24:03,009 --> 00:24:04,389
accuracy has been very good.

411
00:24:04,599 --> 00:24:05,109
Everything.

412
00:24:05,109 --> 00:24:08,379
So your operation cost, then the
cost of the quality is getting down.

413
00:24:08,739 --> 00:24:10,569
Then that will improve a lot of.

414
00:24:11,484 --> 00:24:15,684
Thing to enhance, use a breathing space
to enhance our application more further.

415
00:24:15,924 --> 00:24:20,754
So hence how an observability
can make our life more smoother.

416
00:24:21,474 --> 00:24:26,274
Because if the, if we don't have proper
operation management, hence the cost of

417
00:24:26,274 --> 00:24:29,004
quality can in, if it increases, then.

418
00:24:29,964 --> 00:24:33,414
From a budget point of view, we
may not be able to have a fund to

419
00:24:33,414 --> 00:24:34,824
improve our application features.

420
00:24:34,914 --> 00:24:38,064
Whether we need to put more
effort to retain and sustain our

421
00:24:38,064 --> 00:24:40,944
application existing, we are not
in a position to scale up our

422
00:24:40,944 --> 00:24:42,384
application for the future needs.

423
00:24:42,624 --> 00:24:44,785
Hence, that's the reason this is.

