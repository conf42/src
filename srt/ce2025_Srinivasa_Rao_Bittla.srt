1
00:00:00,160 --> 00:00:04,260
Hello everyone, this is
Srinivasa Rao Bithla.

2
00:00:04,760 --> 00:00:12,189
In today's topic, I'm going to
cover about chaos engineering in AI,

3
00:00:12,970 --> 00:00:15,540
predicting and preventing system outages.

4
00:00:16,040 --> 00:00:20,439
Before I start my presentation, I
want to make a quick disclaimer.

5
00:00:20,939 --> 00:00:25,799
All views expressed here are my
own and do not reflect the opinions

6
00:00:25,799 --> 00:00:27,829
of any affiliated organization.

7
00:00:28,329 --> 00:00:33,624
In today's agenda, I'm going to cover
about chaos What is chaos engineering?

8
00:00:34,414 --> 00:00:40,024
I'm going to give a little bit of history
on how chaos engineering started evolved.

9
00:00:40,964 --> 00:00:45,464
And I'm going to talk about the system
architecture for AI applications.

10
00:00:45,964 --> 00:00:50,754
And also I'm going to tell about
how the AI systems will fail in a

11
00:00:50,784 --> 00:00:52,464
given cloud native architecture.

12
00:00:52,964 --> 00:00:56,944
And I'm going to go in detail about
chaos engineering in a context.

13
00:00:57,444 --> 00:00:59,854
And how do you need to design experiments.

14
00:01:00,354 --> 00:01:04,754
for any chaos for AI based
applications and how you can

15
00:01:04,764 --> 00:01:11,374
make AI applications stronger by
introducing kind of vulnerabilities

16
00:01:12,014 --> 00:01:13,714
to break the AI applications.

17
00:01:14,214 --> 00:01:17,964
Then I'm going to cover about which
are the principles you may need

18
00:01:18,024 --> 00:01:23,594
to follow to make AI applications
more resilient and implementing AI.

19
00:01:24,094 --> 00:01:27,764
The chaos engineering in your
organization, which are the steps and

20
00:01:27,774 --> 00:01:32,044
remedies you may need to follow and
what is the future of chaos engineering

21
00:01:32,544 --> 00:01:36,714
or how you can actually make your
AI applications more robust in the

22
00:01:36,714 --> 00:01:41,174
future and what are the challenges
implementing chaos engineering within

23
00:01:41,174 --> 00:01:46,614
your organization and which are the tools
that you can use for chaos engineering

24
00:01:47,114 --> 00:01:51,244
and finally key take key takeaways
and we are going to close from there.

25
00:01:51,744 --> 00:01:55,664
So now let's move to what
is chaos engineering.

26
00:01:56,164 --> 00:02:03,394
So chaos engineering is about, it's a
discipline, focused on improving the

27
00:02:03,394 --> 00:02:09,444
system reliability by proactively testing
failures in a controlled environment.

28
00:02:09,944 --> 00:02:15,734
So why do we actually make a system
to fail in a controlled environment?

29
00:02:16,234 --> 00:02:20,044
So if we mean to get to that point,
I want to give a little bit of

30
00:02:20,134 --> 00:02:25,884
history, how the chaos engineering
actually, became as a practice.

31
00:02:26,090 --> 00:02:36,709
So in 2008, Netflix had an outage, it's a
prolonged outage where, Netflix was down

32
00:02:36,709 --> 00:02:41,679
and people are not able to get up and so
which was impacting the Netflix revenue

33
00:02:41,679 --> 00:02:43,469
and loyalty of the customers involved.

34
00:02:43,969 --> 00:02:48,479
So that's when they introduced,
they, they made it as an industry

35
00:02:48,479 --> 00:02:50,729
practice as a chaos engineering.

36
00:02:51,599 --> 00:02:54,669
So the main intent is
make the system to fail.

37
00:02:55,494 --> 00:02:56,674
While it is running live.

38
00:02:57,424 --> 00:03:02,694
So that way, any kind of issue
they come, they can, they should

39
00:03:02,704 --> 00:03:04,194
go and proactively fix it.

40
00:03:04,694 --> 00:03:06,594
So earlier it used to take days.

41
00:03:07,044 --> 00:03:12,424
Eventually the time started reducing
and limiting, when they're actually

42
00:03:12,454 --> 00:03:17,651
practicing these failures in a real
environment, in a controlled way,

43
00:03:17,651 --> 00:03:21,774
in a controlled environment, they
know how to revert back with you.

44
00:03:22,569 --> 00:03:24,909
So first you introduce the fault,
then you go back and fix it.

45
00:03:25,409 --> 00:03:29,569
So since they already know how and where
it is failing, they started fixing, but

46
00:03:29,719 --> 00:03:33,649
they get the real time behavior of the
application, how the system is failing.

47
00:03:34,329 --> 00:03:37,809
So this is the way the chaos
engineering, came into practice for

48
00:03:37,819 --> 00:03:43,229
most of the cloud native businesses
and cloud native applications.

49
00:03:43,729 --> 00:03:49,909
So major principles behind the chaos
engineering is you build the hypothesis,

50
00:03:50,029 --> 00:03:56,064
meaning What can go wrong and you
try to inject the failure, right?

51
00:03:56,584 --> 00:03:57,994
And then measure it.

52
00:03:58,054 --> 00:04:02,074
What is the impact, how the business
is getting impacted, how the

53
00:04:02,074 --> 00:04:04,344
user users are getting impacted.

54
00:04:05,044 --> 00:04:09,974
Then improve the system to ensure that
the system is becoming resilient when

55
00:04:10,124 --> 00:04:12,404
the real problem comes into the picture.

56
00:04:12,904 --> 00:04:15,714
So now let's get into the
AI system architecture.

57
00:04:16,214 --> 00:04:18,379
So here, the AI system architecture.

58
00:04:18,939 --> 00:04:21,239
I divided into the four layers.

59
00:04:21,739 --> 00:04:27,129
So one is the generative AI and ML
layer, where, the user, whatever

60
00:04:27,189 --> 00:04:30,929
the user interact with, the users
are going to get the information

61
00:04:30,929 --> 00:04:32,859
from the generative ML layer.

62
00:04:33,539 --> 00:04:37,539
Data layer, where the data is
going to sit predominantly, right?

63
00:04:37,549 --> 00:04:41,459
Then enterprise foundation, where
you have other infrastructure, like

64
00:04:41,459 --> 00:04:44,109
networking, identity, and other stuff.

65
00:04:45,049 --> 00:04:51,019
Then there comes the computational or
infrastructure, layer where you have

66
00:04:51,399 --> 00:04:55,519
multiple systems like Kubernetes and
all where you can, scale up your total

67
00:04:55,519 --> 00:04:57,739
environment and then set up the things.

68
00:04:58,519 --> 00:05:04,699
So why I'm introducing the architecture
is the failures can come in any

69
00:05:04,699 --> 00:05:07,089
of these deployments, right?

70
00:05:07,119 --> 00:05:10,449
So this is going to run as a
whole one single application.

71
00:05:10,949 --> 00:05:15,049
So when we do the chaos engineering,
we need to understand the layer.

72
00:05:15,964 --> 00:05:19,804
And then you may need to
inject the failures, then we'll

73
00:05:19,834 --> 00:05:21,984
try to work on, fixing that.

74
00:05:22,654 --> 00:05:26,844
So that is all about Chaos Engineering,
especially in the AI systems architecture.

75
00:05:27,794 --> 00:05:30,824
I'm going to deep dive
into these things later.

76
00:05:31,324 --> 00:05:36,134
So if you look at AI systems and follow
up with the architectural diagram.

77
00:05:36,794 --> 00:05:39,274
So where and all the failures can come.

78
00:05:40,184 --> 00:05:42,094
One is the infrastructure failures.

79
00:05:42,594 --> 00:05:44,559
It can be latency from the network.

80
00:05:44,839 --> 00:05:52,039
It can be a GPU or TPU bottleneck, and
there could be any cloud disruptions,

81
00:05:52,199 --> 00:05:56,839
like when you're hosting on any of the
cloud infrastructure, and there could

82
00:05:56,839 --> 00:06:01,449
be the data pipeline failures where
when the data is flowing, suddenly

83
00:06:01,449 --> 00:06:07,319
some network going down between the
systems or between two intranets, and

84
00:06:07,349 --> 00:06:11,762
any missing values, the data is not
ingested properly or data corrupted.

85
00:06:11,812 --> 00:06:16,492
In real time ingestion issues, any
failures from the client and validation

86
00:06:16,562 --> 00:06:19,442
side and model failures, right?

87
00:06:19,742 --> 00:06:25,672
Concept of drift in the data is a
model is trained in the wrong ways

88
00:06:25,722 --> 00:06:31,162
with wrong data and adversarial attacks
and incorrect features engineering.

89
00:06:31,852 --> 00:06:36,262
Any of these things can
cause a system to fail.

90
00:06:36,762 --> 00:06:41,532
So now we cannot prevent
most of these issues.

91
00:06:42,492 --> 00:06:46,552
Then how do we actually simulate
and how we can actually get into

92
00:06:46,562 --> 00:06:50,292
reality and how we can actually
make the system more resilient.

93
00:06:50,302 --> 00:06:52,652
That is what we are going
to cover in the future.

94
00:06:53,152 --> 00:06:55,922
So chaos engineering in AI context.

95
00:06:56,422 --> 00:07:02,482
Now looking back, chaos engineering in
AI versus traditional chaos engineering.

96
00:07:02,982 --> 00:07:07,652
In the traditional class engineering,
in any cloud native applications,

97
00:07:08,152 --> 00:07:12,752
in the whole cloud native system
architecture, the systems can

98
00:07:12,752 --> 00:07:15,442
fail in the entire architecture.

99
00:07:16,112 --> 00:07:21,622
that could be a data layer or
computational layer or the UI layer.

100
00:07:21,892 --> 00:07:23,632
So anything anywhere can fail.

101
00:07:24,182 --> 00:07:27,922
if you bring the same thing
to the A applications, it is.

102
00:07:27,967 --> 00:07:33,787
In addition to whatever the issues
that cloud native applications can

103
00:07:33,797 --> 00:07:39,977
fail, it can also add a little bit more
additional, components like pipelines

104
00:07:40,867 --> 00:07:44,197
or the data drifting part or GPUs.

105
00:07:44,517 --> 00:07:47,687
In a typical application, you
may not really see GPUs, but

106
00:07:48,427 --> 00:07:53,797
predominantly in AI applications,
GPUs context coming, more often.

107
00:07:54,297 --> 00:08:00,337
of course, as I said, in the typical cloud
native applications, whatever the failures

108
00:08:00,877 --> 00:08:03,747
can come, those can be repeated in AI.

109
00:08:03,747 --> 00:08:08,227
In addition to that, you will have model
specific issues and GPU specific issues.

110
00:08:08,277 --> 00:08:09,787
That's what I want to, highlight.

111
00:08:10,257 --> 00:08:12,327
I know I'm repeating here,
but yeah, that's what it is.

112
00:08:12,647 --> 00:08:13,517
Just to give you the clarity.

113
00:08:14,017 --> 00:08:16,807
Now, designing a. Chaos experiments.

114
00:08:17,307 --> 00:08:24,607
So how do you design a chaos experiments
when you're, trying to, the simulate,

115
00:08:25,017 --> 00:08:29,887
or even you're trying to, run in
the real environment, you need to

116
00:08:29,887 --> 00:08:31,617
follow this five step approach.

117
00:08:31,857 --> 00:08:35,477
Of course, you can also change
according to your organization needs.

118
00:08:35,977 --> 00:08:41,317
So first, what you need to do is you
need to design a hypothesis, meaning

119
00:08:41,727 --> 00:08:43,307
what experiments you want to do.

120
00:08:43,392 --> 00:08:50,282
What happens if the AI model
gets 20 percent corrupted data?

121
00:08:50,782 --> 00:08:52,322
So that is the hypothesis.

122
00:08:52,992 --> 00:08:54,792
What happens if the network goes down?

123
00:08:55,702 --> 00:08:57,972
That is another hypothesis, right?

124
00:08:58,462 --> 00:09:06,402
So now step to select the target, meaning
choose the components like which component

125
00:09:06,452 --> 00:09:08,982
might get impacted because of the change.

126
00:09:09,872 --> 00:09:12,362
Is it a data pipeline issue?

127
00:09:12,562 --> 00:09:14,412
Or is the data itself is an issue?

128
00:09:14,892 --> 00:09:19,552
Are the model inferences the issue
select like what is the target candidate,

129
00:09:19,602 --> 00:09:23,872
which layer of the architecture
is going to have the problem.

130
00:09:24,372 --> 00:09:28,342
Then you may need to, inject the failures.

131
00:09:28,842 --> 00:09:32,762
So what you do is you introduce
the synthetic faults, right?

132
00:09:32,792 --> 00:09:39,442
Such as missing data or model response
time, model responding slowly the delays.

133
00:09:40,152 --> 00:09:41,362
So that's what you're going to do it.

134
00:09:41,862 --> 00:09:42,562
Then what you do.

135
00:09:43,067 --> 00:09:49,507
You need to observe how the system is
failing and measure the impact, right?

136
00:09:49,767 --> 00:09:55,917
Is it system is degrading or is there
anything like the wrong data is coming?

137
00:09:56,507 --> 00:09:58,017
That's what you're going to observe.

138
00:09:58,517 --> 00:10:02,777
Then you work on improving
the resilience of the system.

139
00:10:03,637 --> 00:10:10,197
Meaning if any of these four steps
comes into reality, how system can

140
00:10:10,267 --> 00:10:14,067
automatically recover that and how it can.

141
00:10:14,762 --> 00:10:16,952
make it better by itself.

142
00:10:17,922 --> 00:10:22,702
That is what you actually expect
your AI system to do, right?

143
00:10:22,722 --> 00:10:27,932
So these are the things you do it in
the, these are the, five steps you follow

144
00:10:28,522 --> 00:10:32,352
to design your AI chaos experiments.

145
00:10:32,352 --> 00:10:33,542
So

146
00:10:34,042 --> 00:10:38,492
how do you make your AI
system to be stronger, right?

147
00:10:38,782 --> 00:10:39,832
So in the previous.

148
00:10:40,362 --> 00:10:46,292
Step I told like, how do you design
the whole, chaos related stuff, but

149
00:10:46,302 --> 00:10:52,452
here, what are the faults that you can
increment introduce into AI systems?

150
00:10:52,952 --> 00:10:57,582
So here I'm talking about six different
kind of, issues that you can introduce

151
00:10:57,582 --> 00:11:03,342
into the whole AI system architecture,
and then see like how the system

152
00:11:03,342 --> 00:11:09,782
behaves and come up with the solution
that How it can automatically, how it

153
00:11:09,782 --> 00:11:17,042
should automatically self-heal and then
minimize the issues that the user faces.

154
00:11:17,542 --> 00:11:22,982
So this is what we do it as part of,
breaking a to, make it stronger, right?

155
00:11:23,032 --> 00:11:28,872
so we introduce the chaos and then
we make the AI system to go stronger,

156
00:11:29,372 --> 00:11:32,752
as in AI breaking AI to make it.

157
00:11:33,252 --> 00:11:37,052
So one of the, chaos that we
can introduce in the system

158
00:11:37,052 --> 00:11:40,282
is adversarial attack testing.

159
00:11:40,782 --> 00:11:47,632
So here, how the intruder can
manipulate a system's behavior by

160
00:11:47,822 --> 00:11:50,292
injecting the external perturbations.

161
00:11:50,792 --> 00:11:55,482
So in this case, we are trying
to intrude with the existing

162
00:11:55,532 --> 00:12:00,962
image, which are the images that
are used for facial recognition.

163
00:12:00,962 --> 00:12:01,082
Recognization.

164
00:12:01,582 --> 00:12:06,012
So here you use the code, the
one which is in the red color.

165
00:12:06,132 --> 00:12:07,022
We use that code.

166
00:12:07,582 --> 00:12:14,272
We use the Fox tool to modify the
existing image and disrupt the AI

167
00:12:14,272 --> 00:12:16,532
facial recognition, images or models.

168
00:12:17,032 --> 00:12:17,742
So then.

169
00:12:18,242 --> 00:12:24,902
The expected outcome of the training
with those images, it should not have any

170
00:12:24,922 --> 00:12:28,012
impact in recognizing the person's, face.

171
00:12:28,772 --> 00:12:33,222
The reason is here, it should
still recognize the original

172
00:12:33,712 --> 00:12:35,492
of faces or original class.

173
00:12:36,152 --> 00:12:38,672
Otherwise we say it has a
vulnerability in the system.

174
00:12:39,602 --> 00:12:45,132
So when we compute that, the cosine,
factor should be close to one.

175
00:12:45,972 --> 00:12:49,462
If it recognizes the face properly,
that means there is no change.

176
00:12:49,482 --> 00:12:51,132
The system is not vulnerable.

177
00:12:51,642 --> 00:12:54,832
the intruder could not make
any changes in the model.

178
00:12:55,132 --> 00:12:57,122
It is still behaving as per expectation.

179
00:12:57,622 --> 00:13:02,492
But if the cosine factor comes close
to zero, that means The system is

180
00:13:02,492 --> 00:13:08,822
vulnerable and it is not recognizing
the faces of the respective, the person

181
00:13:08,902 --> 00:13:10,102
who is supposed to be authenticated.

182
00:13:10,942 --> 00:13:15,812
So this is how you introduce the
adversarial attack and see how

183
00:13:16,262 --> 00:13:18,162
a system is vulnerable or not.

184
00:13:18,662 --> 00:13:21,092
The expected behavior is it should not be.

185
00:13:21,122 --> 00:13:24,582
So that's where you need to work
on the, the system's resilience.

186
00:13:25,082 --> 00:13:27,472
And next is the GPU failure simulation.

187
00:13:27,972 --> 00:13:36,752
So we use, here, we try to simulate
memory leaks on a specific GPU and see

188
00:13:36,792 --> 00:13:42,832
whether the system can automatically,
prevent the failures out of memory errors,

189
00:13:42,862 --> 00:13:47,382
how it can prevent, how it can actually
transfer the respective processing thing

190
00:13:47,392 --> 00:13:52,962
to a next GPU or next CPU, and then
the system works as per expectation.

191
00:13:53,542 --> 00:13:57,902
So here with this code, when I run on
a specific GPU, here you see the out

192
00:13:57,902 --> 00:14:01,372
of memory error and system is failed.

193
00:14:02,222 --> 00:14:03,542
That means this is vulnerable.

194
00:14:04,042 --> 00:14:10,052
So now you need to write a code
in such a way that if this memory

195
00:14:10,052 --> 00:14:14,602
leak happens, how the task will be
transferred to the next GPU or CPU.

196
00:14:15,102 --> 00:14:17,582
That is what the expected outcome is.

197
00:14:17,582 --> 00:14:24,312
If it is transferring properly, that means
the GPU failure simulation worked fine.

198
00:14:24,772 --> 00:14:27,842
And the system is resilient
for any kind of outages.

199
00:14:28,342 --> 00:14:32,052
The next one is the data
pipeline latency simulation.

200
00:14:32,552 --> 00:14:37,032
So here, any kind of a delay, right?

201
00:14:37,492 --> 00:14:39,152
How do you introduce into the system?

202
00:14:39,612 --> 00:14:44,052
So let's say if you want to simulate
a network latency, so you write

203
00:14:44,052 --> 00:14:45,722
this code on the right hand side.

204
00:14:46,222 --> 00:14:51,889
Here I'm giving 15, 500 milliseconds
of, Latency and I'm repeating this

205
00:14:51,929 --> 00:14:57,119
for 60 seconds and see whether my
system is getting the response.

206
00:14:57,619 --> 00:15:03,629
So this is what the chaos you are
injecting into the AI data pipelines

207
00:15:04,459 --> 00:15:09,829
and see if the model handles the
delays or it fails gracefully or if

208
00:15:09,829 --> 00:15:11,459
it just fails without any warnings.

209
00:15:11,959 --> 00:15:16,924
So the expected outcome should be It
should see wherever the information

210
00:15:16,924 --> 00:15:20,614
that is available in any specific
cache or any kind of layer if it is

211
00:15:20,824 --> 00:15:25,704
there, it should give, or else it has
to transfer to the nearest data center

212
00:15:25,804 --> 00:15:28,294
or nearest, deployment of the systems.

213
00:15:28,944 --> 00:15:33,564
But in the given kind of current
environment, here you see the failures.

214
00:15:33,604 --> 00:15:35,954
These are the real time
failures which are captured.

215
00:15:36,514 --> 00:15:43,229
And here, if you look at it, You have,
a deep seek models failing with, the

216
00:15:43,229 --> 00:15:48,329
network issue, and here it is a charge
GPT failing with similar kind of issues.

217
00:15:49,229 --> 00:15:53,559
So this is what, it's not even
resilient, even given the kind

218
00:15:53,559 --> 00:15:57,489
of, the huge infrastructure these,
Two companies runs with right?

219
00:15:57,669 --> 00:16:04,199
So the data pipeline latency simulation
And automatic recovery is very important

220
00:16:04,299 --> 00:16:09,639
for any AI driven systems Next one
is the data corruption in AI training

221
00:16:10,139 --> 00:16:15,759
So if you are training the AI models
with the corrupted data how the system

222
00:16:15,759 --> 00:16:19,029
is actually going to Behave right?

223
00:16:19,329 --> 00:16:26,019
So in this kind of scenario, so you try
to You know, load the corrupted data

224
00:16:26,019 --> 00:16:28,009
into the system over the period of time.

225
00:16:28,529 --> 00:16:31,979
Every time you train with 10 percent
of corrupted data and then over

226
00:16:31,979 --> 00:16:35,439
the period of time, you see only
corrupted data within the system.

227
00:16:35,939 --> 00:16:39,559
So when you're training with the
corrupted data, the system should

228
00:16:39,599 --> 00:16:42,909
really understand whether it is
getting genuine data or corrupted data.

229
00:16:43,839 --> 00:16:49,624
So if the system is Unable to detect
corrupted and uncorrupted data, it will

230
00:16:49,644 --> 00:16:53,324
take the data and then the model and
the training, everything will get fumed.

231
00:16:53,824 --> 00:16:57,154
And, and then, it will give wrong out.

232
00:16:57,804 --> 00:17:03,194
For example, here, this
is the MLOps layers.

233
00:17:03,874 --> 00:17:08,114
This is, one of the chart GPT's
models I used to generate machine

234
00:17:08,114 --> 00:17:09,594
learning operations layers.

235
00:17:10,354 --> 00:17:12,014
So what I got is a sphere.

236
00:17:12,514 --> 00:17:16,534
I was laughing looking at this
image because machine learning.

237
00:17:17,144 --> 00:17:18,144
operations layers.

238
00:17:18,144 --> 00:17:19,914
It can be like multiple layers.

239
00:17:19,944 --> 00:17:22,944
It can see what is nothing, right?

240
00:17:23,424 --> 00:17:27,454
So machine learning system architecture,
that is what I wanted to generate.

241
00:17:27,744 --> 00:17:29,304
But finally I got this.

242
00:17:29,484 --> 00:17:32,834
So if you are feeding only
squares and spheres related data,

243
00:17:32,934 --> 00:17:35,884
whatever the architecture you ask,
you are giving only that input.

244
00:17:36,204 --> 00:17:37,644
Finally, you'll end up seeing this.

245
00:17:38,144 --> 00:17:40,264
So this is what the problem this is.

246
00:17:40,804 --> 00:17:43,624
If this outcome is coming, that
means the system is not resilient.

247
00:17:44,124 --> 00:17:47,644
So if the system is giving expected
output, what you're supposed to get,

248
00:17:47,804 --> 00:17:52,694
that means the system is resilient
and it is doing what is correct and

249
00:17:52,694 --> 00:17:55,424
the users can rely on it, right?

250
00:17:55,614 --> 00:17:58,704
So the data corruption
should not be there.

251
00:17:59,214 --> 00:18:04,374
Even if you do corrupted data, the
AI model should take only the valid

252
00:18:04,534 --> 00:18:07,344
data and then it should generate
the expected outcome properly.

253
00:18:07,344 --> 00:18:11,094
And then the model drift simulation.

254
00:18:11,594 --> 00:18:13,414
Let's say if your model is drifting.

255
00:18:13,914 --> 00:18:18,604
And then that means if it is biasing,
if it is going, wrong decisions over

256
00:18:18,604 --> 00:18:24,124
the period of time, if it is taking,
the models slowly, start building the

257
00:18:24,154 --> 00:18:29,454
things that are not supposed to be
the way it's supposed to look like.

258
00:18:29,674 --> 00:18:32,514
That means the accuracy level
of the model is going down.

259
00:18:33,154 --> 00:18:40,094
So every time, if in a scale, if it is
slowly started drifting down the accuracy.

260
00:18:40,649 --> 00:18:44,989
So here you see the months on the x
axis and the percentage on the y axis.

261
00:18:45,529 --> 00:18:48,529
So here you see slowly the
model started drifting.

262
00:18:48,529 --> 00:18:51,879
After some time, you see
only inaccurate information.

263
00:18:52,379 --> 00:18:56,059
So when the model is drifting, you
need to ensure that you need to train.

264
00:18:56,059 --> 00:18:59,229
You need to take the necessary
remedies to ensure that the

265
00:18:59,229 --> 00:19:00,629
model drift is not happening.

266
00:19:01,479 --> 00:19:03,799
So that's where, you need to ensure that.

267
00:19:04,299 --> 00:19:08,169
The system should have that automatic
recovery of the drifting things as well.

268
00:19:08,169 --> 00:19:11,879
Here you can use the code to
simulate the drifting thing.

269
00:19:12,379 --> 00:19:14,899
Then AI model fallback testing.

270
00:19:14,899 --> 00:19:22,579
So if the AI models are not giving
the intended outcome, right?

271
00:19:22,929 --> 00:19:27,249
So if there is a fault information
that is coming, so the model

272
00:19:27,299 --> 00:19:29,509
should not use the, the latest one.

273
00:19:29,529 --> 00:19:33,969
If the latest model is having the
issue, then it has to fall back to the.

274
00:19:34,339 --> 00:19:34,989
Table model.

275
00:19:35,789 --> 00:19:39,579
So here I have multiple
layers of decisions.

276
00:19:40,259 --> 00:19:43,949
So if there are like multiple
models are already interconnected.

277
00:19:44,509 --> 00:19:48,149
So let's say if you have five,
six versions of models, okay,

278
00:19:48,149 --> 00:19:50,349
this is your first model, right?

279
00:19:50,359 --> 00:19:51,449
This is the latest one.

280
00:19:51,999 --> 00:19:52,279
Okay.

281
00:19:52,279 --> 00:19:53,069
This is not valid.

282
00:19:53,079 --> 00:19:54,959
Then you need to go take the decision.

283
00:19:54,959 --> 00:19:58,109
Then if it is not accurate, again,
it needs to take another decision.

284
00:19:58,409 --> 00:20:00,049
So it has to go to the multiple decisions.

285
00:20:00,549 --> 00:20:04,089
to ensure that the user always
gets the accurate information.

286
00:20:04,599 --> 00:20:08,999
So this is the way you may also need
to do the model fallback testing.

287
00:20:09,409 --> 00:20:13,149
If the model is not giving accurate
results, it has to always go

288
00:20:13,159 --> 00:20:15,659
back to the latest stable model.

289
00:20:16,159 --> 00:20:19,219
Then chaos engineering
principles for AI applications.

290
00:20:19,719 --> 00:20:22,484
So how do you actually implement.

291
00:20:22,494 --> 00:20:27,614
So now we have the different methods
of chaos that you can introduce in AI.

292
00:20:27,614 --> 00:20:32,924
We have seen can we do all of these things
together in even if it is a controlled

293
00:20:32,924 --> 00:20:34,474
environment, can we implement everything?

294
00:20:35,424 --> 00:20:39,564
I say, no, you have to
start small and start slow.

295
00:20:40,234 --> 00:20:44,764
Though you do the chaos in a controlled
environment at a time, give only

296
00:20:44,764 --> 00:20:46,564
one of the aspects of the system.

297
00:20:47,174 --> 00:20:49,244
And then, and also restrict.

298
00:20:49,924 --> 00:20:53,674
The kind of impact that happens on
the system also to the smaller users,

299
00:20:53,674 --> 00:20:55,944
have smaller region of the system.

300
00:20:56,654 --> 00:20:56,984
Okay.

301
00:20:57,454 --> 00:21:03,904
And then control the radius, meaning the
nu number of users because you don't wanna

302
00:21:03,904 --> 00:21:06,934
make your business to go, bust into it.

303
00:21:06,994 --> 00:21:11,644
So you may need to control the whole
impact into very limited segment,

304
00:21:12,144 --> 00:21:14,804
and then automate the recovery.

305
00:21:15,304 --> 00:21:19,254
It should have self-healing in
place whenever the failure comes.

306
00:21:19,434 --> 00:21:26,164
The whole intent is to recover by
itself without any human interventions.

307
00:21:27,054 --> 00:21:31,004
Then you may need to
measure the impact, right?

308
00:21:31,254 --> 00:21:35,824
And then see how many, how much
of time it is taking to recover.

309
00:21:35,934 --> 00:21:38,344
And what is the business
value you are losing?

310
00:21:38,434 --> 00:21:40,964
Or what is, the kind of challenges?

311
00:21:41,004 --> 00:21:44,074
What are the challenges that
are going to face when the

312
00:21:44,084 --> 00:21:45,964
impact really happens, right?

313
00:21:46,304 --> 00:21:47,814
This is what you may need to do.

314
00:21:48,289 --> 00:21:52,669
As a principle of chaos engineering,
then you may need to find out like,

315
00:21:52,709 --> 00:21:57,199
which are the tools that you may
need to use in chaos engineering.

316
00:21:57,749 --> 00:22:01,759
So for, especially for a, and
some of the tools you may also

317
00:22:01,789 --> 00:22:06,039
see for cloud native applications,
some of them definitely for AI.

318
00:22:06,609 --> 00:22:10,729
So the first set of tools like
Gremlin, Chaos Monkey, Litmus Chaos,

319
00:22:10,769 --> 00:22:15,339
these things, you can use it in cloud
native as well as AI applications.

320
00:22:16,184 --> 00:22:17,684
But AI specific tools.

321
00:22:17,804 --> 00:22:23,284
Here you can see TensorFlow model
analysis and AI explainability tools.

322
00:22:23,344 --> 00:22:26,984
These things are specific to,
artificial intelligent, tools.

323
00:22:27,484 --> 00:22:31,324
So where you may need to, simulate
the code of these things to ensure

324
00:22:31,324 --> 00:22:36,214
that, the models are accurate and
they're giving predictable results.

325
00:22:37,214 --> 00:22:42,094
And the observability to monitor the
metrics to monitor the system's behavior.

326
00:22:42,594 --> 00:22:45,324
Processing capabilities
and usage capabilities.

327
00:22:45,684 --> 00:22:50,034
You use the observability tools
to capture the metrics like that.

328
00:22:50,034 --> 00:22:53,264
You have promote Grafana and Elk Stack.

329
00:22:53,764 --> 00:22:56,464
You can use these tools
to monitor the systems.

330
00:22:56,964 --> 00:23:01,294
So given the kind of things that we
have seen, the system reliability

331
00:23:01,354 --> 00:23:03,904
in ai, very important, right?

332
00:23:04,264 --> 00:23:10,524
The failures can come in different,
layers of your, AI systems architecture.

333
00:23:11,024 --> 00:23:15,094
So the failures can be there in
models, meaning the models may not be

334
00:23:15,524 --> 00:23:19,824
giving you the accurate information,
maybe a lot of hypothesis, right?

335
00:23:19,854 --> 00:23:22,944
And, and also the data
itself is a problem.

336
00:23:22,964 --> 00:23:26,704
What kind of data you're feeding, what
kind of data training you're doing

337
00:23:26,704 --> 00:23:28,604
and what kind of cleanup you're doing.

338
00:23:28,664 --> 00:23:29,924
All of that is very important.

339
00:23:29,924 --> 00:23:34,574
And data pipelines, like what kind
of, connect, what kind of data

340
00:23:34,574 --> 00:23:37,774
pipelines of the information is
floating and where it is coming from.

341
00:23:38,274 --> 00:23:39,084
And infrastructure.

342
00:23:39,654 --> 00:23:44,164
So these are the, main, issues in
the system's reliability, right?

343
00:23:44,284 --> 00:23:48,994
So the system always gives you
the accurate information, so you

344
00:23:48,994 --> 00:23:54,664
need to ensure that the system is
trustworthy for any given query To

345
00:23:54,664 --> 00:23:55,984
do that, you may need to do that.

346
00:23:56,554 --> 00:24:00,474
Us and, have the remedies and self
feeling things in place, right?

347
00:24:00,954 --> 00:24:03,804
So implementing ai, k, ias, engineering.

348
00:24:04,319 --> 00:24:05,339
In your organization.

349
00:24:05,639 --> 00:24:06,509
So how do you do it?

350
00:24:07,009 --> 00:24:13,979
Again, you may need to build the culture
of resilience testing, meaning, it should

351
00:24:14,019 --> 00:24:21,239
have your dev and engineering team should
have, the culture of, auto healing for any

352
00:24:21,239 --> 00:24:22,969
kind of issue that they come into picture.

353
00:24:23,519 --> 00:24:28,059
See, preventing issues is very
hard, but auto healing is the

354
00:24:28,059 --> 00:24:29,239
one which makes more sense.

355
00:24:29,819 --> 00:24:33,899
Because failures will come, it's
very difficult to avoid, but how it

356
00:24:33,949 --> 00:24:37,679
can heal by itself and how it can
actually perform better by itself,

357
00:24:37,739 --> 00:24:38,839
that is what's very important.

358
00:24:38,849 --> 00:24:40,529
That's where you need
to have that culture.

359
00:24:41,029 --> 00:24:44,329
So define the key AI failure scenarios.

360
00:24:45,019 --> 00:24:49,049
So that's where you may need to come
up with a thing, like what kind of,

361
00:24:49,149 --> 00:24:54,389
AI failures may come and then simulate
as part of your chaos engineering, and

362
00:24:54,389 --> 00:24:56,079
then have all of your remedies in place.

363
00:24:56,579 --> 00:25:01,499
Use automated kiosks, testing frameworks,
you may need to build that, that's

364
00:25:01,869 --> 00:25:05,429
where, while developing the system
itself, you need to keep all of

365
00:25:05,429 --> 00:25:07,919
those, perspectives thinking, right?

366
00:25:08,019 --> 00:25:08,419
Okay.

367
00:25:08,579 --> 00:25:10,227
If I'm developing this
specific code, okay.

368
00:25:10,227 --> 00:25:13,129
If this middleware fails,
what will happen to this?

369
00:25:13,629 --> 00:25:16,849
Or if the specific component
fails, what will happen to this?

370
00:25:16,849 --> 00:25:21,724
So all of those kinds of perspectives,
thought process should be in place and

371
00:25:21,734 --> 00:25:23,304
continuously improve the system design.

372
00:25:23,304 --> 00:25:23,334
Okay.

373
00:25:24,204 --> 00:25:26,314
This is where the, improvement
comes into the picture.

374
00:25:26,544 --> 00:25:31,744
So every API, every code, every program,
every, component that you build, you need

375
00:25:31,794 --> 00:25:34,684
to think in all these aspects, right?

376
00:25:35,184 --> 00:25:38,134
And challenges in chaos engineering.

377
00:25:38,684 --> 00:25:42,264
especially for the AI systems,
first of all, we have a lot of trust

378
00:25:42,264 --> 00:25:44,034
issues on any of the AI models.

379
00:25:44,994 --> 00:25:49,774
But if you are introducing a chaos in
the real world applications, it is going

380
00:25:49,774 --> 00:25:55,054
to be a real problem because when you
do chaos, you may, it might impact.

381
00:25:55,054 --> 00:26:00,704
Let's say if there is a specific, user
data sitting on the system and you

382
00:26:00,704 --> 00:26:06,014
introduce the chaos and it manipulated
the data and then the data is retrieved

383
00:26:06,024 --> 00:26:10,524
by a specific user from a specific
region and he may get the wrong data.

384
00:26:11,024 --> 00:26:12,554
So that's where the problem, right?

385
00:26:12,744 --> 00:26:16,544
You are intruding the data
privacy of a specific user and

386
00:26:16,544 --> 00:26:17,664
you're causing security risks.

387
00:26:18,164 --> 00:26:21,823
So this is the problem, especially
in the chaos engineering, if you are

388
00:26:21,823 --> 00:26:26,344
doing in the real world applications,
and it is very difficult to track the

389
00:26:26,634 --> 00:26:32,794
cascading failures, like the dependencies
and from one issue leading to another

390
00:26:32,794 --> 00:26:37,994
issue, to monitor and track, that is
also one of the major challenges and,

391
00:26:38,074 --> 00:26:40,064
how do you get rid of those things?

392
00:26:40,064 --> 00:26:45,084
You may need to be very conservative in
the going back to the previous slide.

393
00:26:45,134 --> 00:26:49,974
You need to ensure that these complexities
and data privacy things are taken care of.

394
00:26:50,544 --> 00:26:54,889
And you should do it in a very controlled
environment to eliminate these issues.

395
00:26:55,389 --> 00:26:57,689
And future of chaos engineering in AI.

396
00:26:58,189 --> 00:27:03,939
As I mentioned, you may need to build
robust systems by way of implementing

397
00:27:03,959 --> 00:27:05,703
self healing systems, right?

398
00:27:05,703 --> 00:27:10,589
And integrate the AI operations
for proactive failure preventions.

399
00:27:11,089 --> 00:27:15,839
So like DevOps, you need to have
artificial intelligence operations,

400
00:27:16,329 --> 00:27:20,699
any failure that comes, how we can
actually proactively, prevent it.

401
00:27:21,499 --> 00:27:25,579
so the self healing with preventive
failure protections, proactive failure

402
00:27:25,579 --> 00:27:32,339
protections, it would help the systems to
become stable and work reliably, and you

403
00:27:32,339 --> 00:27:37,059
also need to do the continuous monitoring
and adaptive learning in AI models.

404
00:27:37,559 --> 00:27:42,439
So you need to use your observability
metrics and see alerting mechanisms.

405
00:27:42,439 --> 00:27:46,199
If something goes wrong, the
respective user should be alerted

406
00:27:46,199 --> 00:27:48,129
and remedies will be, taking care.

407
00:27:48,629 --> 00:27:50,979
So from this, what are
the key takeaways, right?

408
00:27:51,439 --> 00:27:55,519
So chaos engineering is
essential for AI resilience.

409
00:27:56,019 --> 00:27:56,289
Yeah.

410
00:27:56,339 --> 00:28:01,999
See, because AI systems to become
resilient for any of these intruder thing

411
00:28:02,019 --> 00:28:04,029
that's going to happen on the system.

412
00:28:04,624 --> 00:28:10,424
You may need to, plan it, you may
need to, run it, those kiosks, you

413
00:28:10,424 --> 00:28:16,714
may need to inject those pairs in the
system and make sure that your, AI

414
00:28:16,714 --> 00:28:20,264
systems are released, resilient, okay?

415
00:28:20,674 --> 00:28:25,164
And focus on data pipelines,
model inferences, and cloud

416
00:28:25,164 --> 00:28:26,924
infrastructure, right?

417
00:28:26,984 --> 00:28:28,874
Whatever the AI components are there.

418
00:28:29,374 --> 00:28:34,924
Focus on them, ensure that, each one of
them is, tested with all of these, chaos

419
00:28:35,424 --> 00:28:40,914
and use the control failure injections
to strengthen the AI reliability, right?

420
00:28:41,284 --> 00:28:44,674
So you should not do it
in the, the whole system.

421
00:28:44,684 --> 00:28:47,914
You need to be in the controlled
environment in a specific region,

422
00:28:47,934 --> 00:28:53,314
specific user group, ensure you notify
the specific users and you notify the

423
00:28:53,314 --> 00:28:55,794
QA, everybody who is supposed to be.

424
00:28:56,234 --> 00:29:02,574
there before intruding or before your
fault injecting into the system, then

425
00:29:02,574 --> 00:29:05,034
you minimizing the impact, right?

426
00:29:05,754 --> 00:29:10,354
So you may need to leverage the automation
and improve the scalability and recovery.

427
00:29:10,884 --> 00:29:13,374
See, these things manually
doing is very difficult.

428
00:29:13,374 --> 00:29:17,114
So you need to have the automated
script to fall back or the automated

429
00:29:17,144 --> 00:29:22,264
script to heal, automated script,
automated way to, make the system to,

430
00:29:22,614 --> 00:29:27,544
Hel itself, like falling back the model
or if there is a CCP issue, moving

431
00:29:27,574 --> 00:29:32,164
issue, moving onto a different CP or
different host, the specific task.

432
00:29:32,644 --> 00:29:34,054
So all of those things should be there.

433
00:29:34,264 --> 00:29:37,014
So these things should be
automatically to be done.

434
00:29:37,014 --> 00:29:42,794
So these are the key takeaways when you
talk about I engineering in ai, world.

435
00:29:43,294 --> 00:29:44,584
So with this I'm concluding.

436
00:29:45,064 --> 00:29:47,139
Thank you very much for attending my talk.

437
00:29:47,894 --> 00:29:48,884
If you have any questions.

438
00:29:49,414 --> 00:29:52,884
You can connect with me on
LinkedIn and you can reach me

439
00:29:53,304 --> 00:29:55,164
directly, through LinkedIn itself.

440
00:29:55,664 --> 00:29:56,114
Thank you.

441
00:29:56,714 --> 00:29:57,504
Thanks for listening.

