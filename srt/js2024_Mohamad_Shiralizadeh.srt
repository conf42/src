1
00:00:00,490 --> 00:00:02,250
Hey guys, welcome to my talk.

2
00:00:02,320 --> 00:00:05,439
Unlike the future,
built in AI in browsers.

3
00:00:06,220 --> 00:00:09,110
Better start learning to
speak robot, isn't it?

4
00:00:09,610 --> 00:00:10,620
AI is rising.

5
00:00:10,810 --> 00:00:13,290
Everybody know AI is everywhere.

6
00:00:14,280 --> 00:00:19,839
AI even in our everyday life, like
virtual assistants, recommendation

7
00:00:19,839 --> 00:00:23,610
systems, autonomous vehicles, even food.

8
00:00:24,120 --> 00:00:27,470
We have Coke with AI generated flavor.

9
00:00:27,560 --> 00:00:28,260
Come on.

10
00:00:28,680 --> 00:00:31,560
AI these days is not just a buzzword.

11
00:00:32,269 --> 00:00:38,620
Everything is focusing on AI because it
is shaping the future of our industry.

12
00:00:39,120 --> 00:00:44,470
My name is Mohamed, Senior Software
Engineer in Netherlands, ING Bank.

13
00:00:44,720 --> 00:00:49,260
This is the QR to my page, so we
can connect on LinkedIn, have a

14
00:00:49,260 --> 00:00:51,309
chat, keep up with each other.

15
00:00:51,350 --> 00:00:51,839
Why not?

16
00:00:52,150 --> 00:00:57,089
I love to connect to enthusiastic
developers, and you are, since

17
00:00:57,090 --> 00:00:58,540
you are here in this conference.

18
00:00:59,040 --> 00:00:59,969
So what's the plan?

19
00:01:00,749 --> 00:01:04,269
First of all, we will focus on local LLMs.

20
00:01:05,049 --> 00:01:10,179
So and compare them to cloud LLMs
because we have two types of LLMs in this

21
00:01:10,179 --> 00:01:16,079
case, and we are focusing on built in
ones, which is some kind of local LLM.

22
00:01:16,869 --> 00:01:21,339
And then we will make everything
technical, focus on the API and

23
00:01:21,379 --> 00:01:23,829
overview what how the API works.

24
00:01:24,489 --> 00:01:29,769
Then we have some live coding guys finger
crossed for me because live coding is

25
00:01:29,819 --> 00:01:34,449
always so next step Yeah, what lies ahead?

26
00:01:34,679 --> 00:01:40,149
So what is the next step that we can take
or what's going on behind the scene later?

27
00:01:40,649 --> 00:01:42,940
So let's start with local LLMs.

28
00:01:43,440 --> 00:01:51,615
So let me um, Define LLM in a simple word
in a simple word LLM is so simple You We

29
00:01:51,625 --> 00:01:53,945
have a prompt, like, where is Amsterdam?

30
00:01:54,545 --> 00:02:00,505
It goes to LLM, and then it gives
us a response, Netherlands, right?

31
00:02:00,925 --> 00:02:06,405
converting a prompt to a response using
LLM is the one that we are going to use.

32
00:02:06,905 --> 00:02:11,185
In a more technical way, LLM
is a large language model.

33
00:02:11,685 --> 00:02:16,735
It's type of artificial intelligence
that uses deep learning techniques

34
00:02:16,785 --> 00:02:21,335
to understand, generate and
manipulate human language.

35
00:02:21,815 --> 00:02:27,845
So this kind of LLM, first of all,
focusing on human language so it can

36
00:02:27,855 --> 00:02:30,005
generate, understand, manipulate.

37
00:02:30,005 --> 00:02:33,945
So yeah, like the question that we ask,
where is Amsterdam is going to tell us.

38
00:02:34,445 --> 00:02:38,765
So let's see, differences
between local LM and cloud LLM.

39
00:02:39,265 --> 00:02:44,500
When we use local LLMs,
LLM is on our machine.

40
00:02:44,870 --> 00:02:50,310
So the whole, neural network
and the artificial intelligence,

41
00:02:50,400 --> 00:02:54,430
all the technologies that lies
behind would be on our machine.

42
00:02:54,460 --> 00:02:58,330
So we are limited to our machine as
well in terms of, the performance.

43
00:02:58,380 --> 00:03:01,060
But the thing is, there are some benefits.

44
00:03:01,150 --> 00:03:03,010
The first thing is privacy.

45
00:03:03,510 --> 00:03:04,810
Why privacy?

46
00:03:05,010 --> 00:03:10,080
Because when we are using local
LLMs, the data stays on your machine.

47
00:03:10,415 --> 00:03:12,435
It doesn't go anywhere else.

48
00:03:12,445 --> 00:03:19,735
So you shouldn't, send data through
the wire to clouds and expect, I don't

49
00:03:19,735 --> 00:03:24,545
know, as your GCP get back to you with
some results or some other services.

50
00:03:25,315 --> 00:03:28,695
So the thing is, yeah,
privacy, which matters a lot.

51
00:03:28,785 --> 00:03:31,759
It's one of the biggest
advantage of local LLMs.

52
00:03:32,259 --> 00:03:36,649
Then low latency, because everything
is on your machine, low latency,

53
00:03:36,659 --> 00:03:41,789
you shouldn't wait for network
and stuff, internet connection.

54
00:03:41,789 --> 00:03:45,199
So nothing is required in this case,
because everything is on your machine.

55
00:03:45,779 --> 00:03:51,149
And then low cost, because no
subscriptions required for this one.

56
00:03:51,209 --> 00:03:55,519
So because the LLM, it's just
imagine there's a database, the

57
00:03:55,549 --> 00:03:57,579
LLM database is on your machine.

58
00:03:57,579 --> 00:03:59,919
So everything gonna work.

59
00:04:00,020 --> 00:04:05,720
some examples I can say Misrall is
one of them and Blama from Meta.

60
00:04:06,350 --> 00:04:07,430
These are local LLMs.

61
00:04:07,930 --> 00:04:08,660
Cloud LLMs.

62
00:04:09,475 --> 00:04:15,025
Yeah, of course with cloud LLMs you have
a superpower as I mentioned So since the

63
00:04:15,055 --> 00:04:20,585
model would be on your machine in terms
of the local LLMs, but the cloud LLM

64
00:04:20,655 --> 00:04:23,065
Yeah, the model is somewhere in the cloud.

65
00:04:23,065 --> 00:04:29,525
So it could be Super big so it means
that they trained it with more data.

66
00:04:29,575 --> 00:04:36,205
They have a better superpower there
So the other one is network latency.

67
00:04:36,205 --> 00:04:39,695
Yeah, it is Up to date with a lot of data.

68
00:04:39,695 --> 00:04:43,265
It can give you better answers,
but it has latency because you

69
00:04:43,265 --> 00:04:44,885
should send the data over the wire.

70
00:04:45,155 --> 00:04:49,445
So bigger data, slower, bigger
data, it should compute more.

71
00:04:49,945 --> 00:04:51,415
And also high costs.

72
00:04:51,475 --> 00:04:56,205
So it has a cost because we are
using third party services like

73
00:04:56,235 --> 00:05:00,005
Azure or GCP, Google Cloud Services.

74
00:05:00,505 --> 00:05:01,070
That's it.

75
00:05:01,570 --> 00:05:03,230
So in this case, we reach.

76
00:05:04,160 --> 00:05:09,650
But yeah, let's have a local LLM
on our machine and thanks to the

77
00:05:09,650 --> 00:05:14,600
browsers which install on all of the
machines and web application, that the

78
00:05:14,600 --> 00:05:17,120
application that we develop lies there.

79
00:05:17,330 --> 00:05:22,640
So it means that, yeah, if we put
an LLM inside the browser, wow.

80
00:05:22,640 --> 00:05:28,030
So some kind of superpower in our
machine, we can perform some magic.

81
00:05:28,090 --> 00:05:28,840
So let's see.

82
00:05:29,380 --> 00:05:34,020
How does the API looks like behind
the scene, first of all, disclaimer.

83
00:05:34,520 --> 00:05:38,890
for the things that you are going to
see no machine learning is required

84
00:05:38,930 --> 00:05:44,440
So don't worry that you don't have any
knowledge of ml and this and other things

85
00:05:44,450 --> 00:05:52,430
so no ml No machine learning is required
No, ai Knowledge is required as well.

86
00:05:52,650 --> 00:05:54,900
So you're going to see how does it work?

87
00:05:54,900 --> 00:05:59,680
So stay tuned the api is super simple
First of all, you should create a

88
00:05:59,680 --> 00:06:04,035
session Since It is asynchronous.

89
00:06:04,035 --> 00:06:04,198
Yeah, definitely.

90
00:06:04,198 --> 00:06:04,524
We need a wait.

91
00:06:04,525 --> 00:06:07,455
So AI that assistant that create.

92
00:06:07,535 --> 00:06:14,055
So if you grab the AI object from window
that assistant that create, you're

93
00:06:14,085 --> 00:06:15,935
going to create a session for yourself.

94
00:06:15,945 --> 00:06:21,415
So in this way, you can start,
prompting asking question from LLM.

95
00:06:21,915 --> 00:06:24,235
Next step is prompting.

96
00:06:24,895 --> 00:06:27,899
As you see, with the session
that I created, Yeah, perfect.

97
00:06:28,370 --> 00:06:33,060
I called dot prompt and then the
text my question actually my prompt

98
00:06:33,480 --> 00:06:35,260
So where is amsterdam in this case?

99
00:06:35,270 --> 00:06:38,330
So do you remember that
in the other diagram?

100
00:06:38,370 --> 00:06:41,350
I showed you Yeah, the
answer is netherlands.

101
00:06:41,570 --> 00:06:48,010
Yeah Based on the data that the model
has been trained for So the answer might

102
00:06:48,010 --> 00:06:51,750
be different and also a lot of different
parameters, but generally, the data

103
00:06:51,750 --> 00:06:57,915
matters a lot so For me In the test
that I did, it gave me this sentence.

104
00:06:58,175 --> 00:07:00,785
Amsterdam is the capital
city of Netherlands.

105
00:07:01,750 --> 00:07:02,200
Nice.

106
00:07:02,300 --> 00:07:07,180
So with two lines of code,
I could ask LLM something.

107
00:07:07,330 --> 00:07:15,830
So just imagine how, creative could you
be in your applications to, interact

108
00:07:15,830 --> 00:07:19,650
with the user in a better way, gives
them better suggestions and stuff.

109
00:07:19,660 --> 00:07:21,770
So we will see some use cases later on.

110
00:07:22,270 --> 00:07:27,180
The other one, the other API that
matters a lot is prompt streaming.

111
00:07:27,680 --> 00:07:30,070
As LLMs are using generative.

112
00:07:30,470 --> 00:07:36,320
Technology, generative ai, technology,
generative ai, it's, it literally

113
00:07:36,320 --> 00:07:39,850
means generating, then you call prompt.

114
00:07:40,330 --> 00:07:46,800
So it just waits from wait
for the LLM to generate all

115
00:07:46,800 --> 00:07:48,810
the content, all the response.

116
00:07:49,250 --> 00:07:53,590
But if you use prompt
streaming, it's different.

117
00:07:54,260 --> 00:07:56,570
It's the same thing, but.

118
00:07:57,320 --> 00:08:01,950
As soon as LLM, predict the next
token, which is the next word,

119
00:08:01,960 --> 00:08:05,390
just imagine in this case, so
it's going to give you the output.

120
00:08:05,890 --> 00:08:11,140
So this is a, a standard,
stream in, in the browser.

121
00:08:11,370 --> 00:08:16,490
So you can, just await for that and
expect some chunks from the stream.

122
00:08:16,880 --> 00:08:19,480
So as you see, the output
would be something like this.

123
00:08:20,020 --> 00:08:21,250
The first answer done.

124
00:08:21,460 --> 00:08:22,260
Then is.

125
00:08:23,245 --> 00:08:28,224
Then is the capital city, is the capital
city of, is the capital city of the,

126
00:08:28,225 --> 00:08:30,325
is the capital city of the Netherlands.

127
00:08:30,425 --> 00:08:32,205
that's how it works.

128
00:08:33,055 --> 00:08:37,934
when you are dealing with prompt or prompt
streaming, just imagine how does it work.

129
00:08:38,034 --> 00:08:43,614
this is a cool API from the
prompt, from the, built in AI API.

130
00:08:44,394 --> 00:08:52,184
Yeah, no NL, expertise required, no AI
expertise required, no neural networks,

131
00:08:52,194 --> 00:08:59,104
some magics, but to be honest, prompt
engineering can make it much better.

132
00:08:59,574 --> 00:09:03,594
So there are a lot of prompt engineering
out there that you can check them out.

133
00:09:04,084 --> 00:09:10,234
First of all, how to write a better
prompt, how to ask LLMs or what

134
00:09:10,234 --> 00:09:12,244
are the tricks that you can use?

135
00:09:12,244 --> 00:09:15,964
What are you know how LLMs
can answer you better?

136
00:09:15,974 --> 00:09:18,094
So these are all the
things that you can learn.

137
00:09:18,114 --> 00:09:21,754
For instance, one of
them is Nshot prompting.

138
00:09:21,755 --> 00:09:23,994
Nshot prompting.

139
00:09:24,814 --> 00:09:31,209
It's like giving some examples to
LLM Please use these examples and

140
00:09:31,219 --> 00:09:34,479
get back to me like I asked for.

141
00:09:34,979 --> 00:09:36,179
Let's start from the top.

142
00:09:37,089 --> 00:09:41,169
I'm using again, AI
assistant that creates.

143
00:09:41,839 --> 00:09:45,769
Then I'm passing two parameters,
temperature and top k.

144
00:09:46,269 --> 00:09:50,729
So these are these two
parameter are so details.

145
00:09:50,789 --> 00:09:54,959
I recommend you to read them
in the documentation that I'm

146
00:09:54,989 --> 00:09:56,589
gonna share the link later.

147
00:09:56,799 --> 00:10:01,419
But generally the temperature, for
instance, in this case is something

148
00:10:01,429 --> 00:10:05,419
like how creative LLM could be.

149
00:10:05,919 --> 00:10:10,749
Most of the time, if you set it to zero,
it's something like it's gonna give you

150
00:10:10,779 --> 00:10:14,199
the same answer all the time somehow.

151
00:10:14,699 --> 00:10:16,709
And then I initiate prompts.

152
00:10:17,059 --> 00:10:21,909
Some system prompts, some kind of
persona, I give a persona to the

153
00:10:21,909 --> 00:10:24,149
system, pretend to be a tour guide.

154
00:10:24,979 --> 00:10:28,109
And then I give some examples.

155
00:10:28,119 --> 00:10:33,510
For instance, for Netherlands,
if user asks, the assistant

156
00:10:33,510 --> 00:10:36,660
says, let's go to Rijksmuseum.

157
00:10:37,160 --> 00:10:40,910
If I talk about Italy,
say, let's do Colosseum.

158
00:10:41,360 --> 00:10:45,510
see, these are well known
museum, tourist places.

159
00:10:45,830 --> 00:10:48,900
what if, now, I ask something new?

160
00:10:49,310 --> 00:10:50,980
tell me something about Iran.

161
00:10:51,080 --> 00:10:56,420
the thing is, since LLM just
learned that, Yeah, my user

162
00:10:56,460 --> 00:10:58,750
expects this kind of sentence.

163
00:10:58,780 --> 00:11:00,940
Let's go to somewhere!

164
00:11:00,940 --> 00:11:04,580
yeah, the answer, the response
in this case would be, Yeah,

165
00:11:04,580 --> 00:11:06,010
let's go to Grand Bazaar.

166
00:11:06,250 --> 00:11:06,720
Why not?

167
00:11:07,160 --> 00:11:07,650
So nice.

168
00:11:08,150 --> 00:11:09,230
That's how it works.

169
00:11:09,230 --> 00:11:14,390
So it's one of the, techniques to improve
your prompts, which is nshut prompting.

170
00:11:14,890 --> 00:11:18,010
So it's time for some live coding.

171
00:11:18,790 --> 00:11:19,550
Finger crossed.

172
00:11:20,050 --> 00:11:21,100
Let's see what do we have.

173
00:11:21,600 --> 00:11:24,140
I have a simple form at blog post.

174
00:11:24,930 --> 00:11:28,789
I'm gonna put my context
and tags for that blog post.

175
00:11:28,790 --> 00:11:29,900
So let's use.

176
00:11:30,365 --> 00:11:34,695
The API that we just learned, just
improve our application simply.

177
00:11:35,675 --> 00:11:37,855
So you remember what was the API, right?

178
00:11:37,855 --> 00:11:42,485
So it means that if I want to run the
API, I should run it on the text change.

179
00:11:42,495 --> 00:11:44,355
So let's see the code that I have.

180
00:11:44,855 --> 00:11:46,055
Really straightforward.

181
00:11:46,555 --> 00:11:50,115
Add event listener on the
inputs of my text element.

182
00:11:50,795 --> 00:11:51,285
Nice.

183
00:11:51,525 --> 00:11:52,415
So far so good.

184
00:11:53,415 --> 00:11:57,335
In the prompt function, I
have an asynchronous function.

185
00:11:57,845 --> 00:11:59,955
I am awaiting to create a session.

186
00:12:00,365 --> 00:12:00,905
Simple.

187
00:12:01,375 --> 00:12:01,825
Then.

188
00:12:02,525 --> 00:12:05,215
I'm prompting my LLM, my local LLM.

189
00:12:05,715 --> 00:12:08,095
So my, my prompt is something like this.

190
00:12:08,105 --> 00:12:13,215
You are an author helping people to find
the right tags for their blog posts.

191
00:12:13,935 --> 00:12:14,405
nice.

192
00:12:14,565 --> 00:12:16,315
Some kind of a persona.

193
00:12:16,815 --> 00:12:23,145
Consider the following text and
suggest tags for it in a JSON format.

194
00:12:23,315 --> 00:12:26,975
Yeah, every developer's
favorite format, right?

195
00:12:27,205 --> 00:12:27,665
Is it?

196
00:12:28,045 --> 00:12:28,905
Yeah, anyway.

197
00:12:29,525 --> 00:12:35,115
So I'm gonna put the text
inside, an html type XML type.

198
00:12:35,365 --> 00:12:36,525
It could be anything.

199
00:12:36,535 --> 00:12:40,295
It could be back tag, backpack
tick or something else.

200
00:12:40,335 --> 00:12:44,395
But to be honest, I prefer in
this format because LLMs most of

201
00:12:44,395 --> 00:12:45,855
the time understand it better.

202
00:12:46,355 --> 00:12:50,615
So I'm awaiting for the response,
getting the response and just like it.

203
00:12:50,685 --> 00:12:53,755
So let's see what do we get from the text.

204
00:12:54,350 --> 00:12:57,750
First text is AI is awesome.

205
00:12:58,430 --> 00:12:59,550
Let's see the console.

206
00:13:00,050 --> 00:13:04,530
Come on Oh, yeah, as you see it
took a little bit time and it makes

207
00:13:04,530 --> 00:13:08,740
sense because it was Computing
on my machine with all the stuff.

208
00:13:09,510 --> 00:13:16,160
Yeah, it is somehow in json format as you
see It gave me in a markdown format, which

209
00:13:16,190 --> 00:13:23,560
we are gonna trim it But yeah, we have an
object full of tags For the AI is awesome.

210
00:13:23,570 --> 00:13:25,630
It detects artificial intelligence.

211
00:13:25,940 --> 00:13:27,220
Nice, an AI tag.

212
00:13:27,480 --> 00:13:28,180
Yeah, nice.

213
00:13:28,340 --> 00:13:32,985
So we are gonna show tags
here for Our application.

214
00:13:33,455 --> 00:13:36,745
I am so happy to be here.

215
00:13:37,695 --> 00:13:38,175
Let's see.

216
00:13:38,675 --> 00:13:39,295
Okay.

217
00:13:39,345 --> 00:13:40,575
yeah, in food.

218
00:13:40,635 --> 00:13:45,435
Come on, because I'm just, typing,
it's gonna run the function

219
00:13:45,585 --> 00:13:47,715
on each of my, pure press.

220
00:13:47,725 --> 00:13:49,925
So that's why you can
see a lot of logs here.

221
00:13:50,865 --> 00:13:53,435
yeah, the last one is
this one, yeah, happiness.

222
00:13:53,535 --> 00:13:54,555
Yeah, it could be.

223
00:13:54,555 --> 00:13:54,570
Okay.

224
00:13:54,910 --> 00:13:59,760
a good tag for my blog post which
contains this text at the moment

225
00:14:00,740 --> 00:14:06,960
Or it has a lot of others as well
sentiment tone emotions nice.

226
00:14:06,960 --> 00:14:11,250
But anyway, this is the last one and
the most accurate one because right?

227
00:14:11,280 --> 00:14:14,480
Yeah at this time it had all the text.

228
00:14:15,090 --> 00:14:15,870
So let's use it.

229
00:14:16,370 --> 00:14:19,250
So I want to extract tags, right?

230
00:14:19,750 --> 00:14:26,650
so My response contains some
backtick and the JSON in the front.

231
00:14:26,650 --> 00:14:28,460
So let's replace them.

232
00:14:28,960 --> 00:14:35,590
I'm going to use regex, find all
the backticks and just move forward.

233
00:14:35,630 --> 00:14:37,930
Everything that you
found, replace it with.

234
00:14:38,400 --> 00:14:39,160
Nothing.

235
00:14:39,520 --> 00:14:40,960
So these are the tags.

236
00:14:41,510 --> 00:14:43,920
Yeah, the tags string.

237
00:14:43,940 --> 00:14:47,520
So let me parse it with json.

238
00:14:47,620 --> 00:14:52,730
parse as well to make
it a JSON, an object.

239
00:14:52,980 --> 00:14:55,600
And let's log tags for myself.

240
00:14:55,670 --> 00:14:58,540
Let's see what do we have in the browser.

241
00:14:59,040 --> 00:15:00,490
So text is happy.

242
00:15:00,990 --> 00:15:01,890
Yeah, nice.

243
00:15:02,650 --> 00:15:03,080
Thanks.

244
00:15:03,230 --> 00:15:03,780
Happiness.

245
00:15:04,670 --> 00:15:05,240
Great.

246
00:15:05,480 --> 00:15:06,560
So far so good.

247
00:15:07,380 --> 00:15:08,070
what else?

248
00:15:08,070 --> 00:15:13,090
So let's have a four loop our tags.

249
00:15:13,800 --> 00:15:14,520
Nice.

250
00:15:15,400 --> 00:15:17,370
I have a UL here.

251
00:15:17,430 --> 00:15:18,360
Name tags.

252
00:15:19,330 --> 00:15:20,380
I'm getting it by.

253
00:15:20,380 --> 00:15:22,570
Id You have tag element.

254
00:15:23,210 --> 00:15:27,080
So let's me create an li.

255
00:15:27,580 --> 00:15:28,150
Oh, nice.

256
00:15:28,150 --> 00:15:28,510
Nice.

257
00:15:28,510 --> 00:15:29,440
Thanks copilot.

258
00:15:29,490 --> 00:15:34,970
We have an li, set the text content to
the tag itself, append it to the tags.

259
00:15:35,900 --> 00:15:37,390
Let's see the result.

260
00:15:37,460 --> 00:15:38,590
Refresh.

261
00:15:38,930 --> 00:15:39,450
Happy.

262
00:15:39,950 --> 00:15:41,140
Yeah, live coding.

263
00:15:41,640 --> 00:15:44,230
You should wish me luck,
but why you didn't?

264
00:15:44,990 --> 00:15:46,530
Anyway, let's see.

265
00:15:46,570 --> 00:15:47,110
Let's see.

266
00:15:47,150 --> 00:15:47,810
Let's see.

267
00:15:48,700 --> 00:15:49,880
What's the problem?

268
00:15:49,890 --> 00:15:52,490
Let me put a log here.

269
00:15:52,990 --> 00:15:55,610
Nice tag element append.

270
00:15:56,000 --> 00:15:58,460
Okay, li create element li.

271
00:15:58,760 --> 00:16:00,480
Yeah, everything makes sense.

272
00:16:00,510 --> 00:16:05,390
I just want to make sure that we
have some content for the tags.

273
00:16:05,400 --> 00:16:05,960
So yeah.

274
00:16:06,210 --> 00:16:07,940
Oh yeah, guys, tags.

275
00:16:08,400 --> 00:16:10,160
It has the property tags.

276
00:16:10,660 --> 00:16:13,970
So yeah, so I'm gonna just put tags there.

277
00:16:13,980 --> 00:16:15,740
So right now we have tags.

278
00:16:16,420 --> 00:16:18,400
So everything makes more sense.

279
00:16:18,400 --> 00:16:19,990
Let me go for happy.

280
00:16:20,490 --> 00:16:21,070
cool, cool.

281
00:16:21,570 --> 00:16:21,980
Yeah, happy.

282
00:16:22,480 --> 00:16:25,170
Yeah, see, yeah, since I was typing.

283
00:16:25,190 --> 00:16:27,060
So yeah, music happiness.

284
00:16:27,070 --> 00:16:31,120
it's all those prompts that
it was doing during my typing.

285
00:16:31,580 --> 00:16:34,310
So I can do two things.

286
00:16:35,040 --> 00:16:39,210
Let me go for tag element
in our HTML empty.

287
00:16:39,460 --> 00:16:42,260
Yeah, because each time
I should clear the list.

288
00:16:42,760 --> 00:16:48,060
So even I can set a loading or something
which doesn't matter in this case.

289
00:16:48,110 --> 00:16:50,830
Yeah, happy So okay.

290
00:16:50,930 --> 00:16:52,330
Oh, yeah, it's working.

291
00:16:52,700 --> 00:16:53,300
It's working.

292
00:16:53,340 --> 00:16:57,240
Anyway, you can see happiness here
So if you want to create a tag, you

293
00:16:57,240 --> 00:17:03,330
can you know Use this suggestion
link to create a tag and also as

294
00:17:03,330 --> 00:17:05,310
these are just redundant, right?

295
00:17:05,370 --> 00:17:10,160
So I have already loaded the
low dash here for myself.

296
00:17:10,160 --> 00:17:18,870
So yeah easily let's use And the
bounce from low dash put it to

297
00:17:18,870 --> 00:17:24,210
200 300 millisecond something like
that to, just debounce all of them.

298
00:17:24,840 --> 00:17:25,950
So happy.

299
00:17:26,880 --> 00:17:32,250
Yeah, just one super fast because
yeah, there aren't a lot of prompt

300
00:17:32,260 --> 00:17:34,290
to my LLM, which is my computer.

301
00:17:34,320 --> 00:17:35,550
So it's going to make it slow.

302
00:17:35,870 --> 00:17:37,160
So on and so forth.

303
00:17:37,660 --> 00:17:38,310
So easy peasy.

304
00:17:38,810 --> 00:17:47,610
So as you see, with just, i dunno,
from 55 to just 85, 20, 25, 30

305
00:17:47,610 --> 00:17:49,440
lines of code, simple codes.

306
00:17:49,440 --> 00:17:55,020
So I just could to, I could prompt
LLM, get some tags for my blog

307
00:17:55,020 --> 00:18:00,380
post and just suggest them to the
user, make my user's life easier.

308
00:18:00,680 --> 00:18:02,480
So everything is great.

309
00:18:02,980 --> 00:18:05,830
Let's try it out for the last time.

310
00:18:05,950 --> 00:18:07,150
AI is.

311
00:18:07,575 --> 00:18:10,845
Awesome, I am presenting at

312
00:18:11,345 --> 00:18:11,355
conf.

313
00:18:11,855 --> 00:18:13,975
Let's see, what are the
tags that it suggests?

314
00:18:14,475 --> 00:18:15,505
Conference.

315
00:18:16,005 --> 00:18:20,515
Yeah, technology, artificial
intelligence, conference.

316
00:18:21,055 --> 00:18:21,775
Yeah, good.

317
00:18:22,035 --> 00:18:25,485
So it means our application is
working in the way that we want.

318
00:18:26,145 --> 00:18:28,035
And yeah, that's it.

319
00:18:28,705 --> 00:18:29,295
So let's move on.

320
00:18:29,795 --> 00:18:33,475
So maybe you wonder how
did I oh, I'm sorry.

321
00:18:33,785 --> 00:18:35,235
So I'm gonna start right now.

322
00:18:35,235 --> 00:18:35,605
Okay.

323
00:18:35,725 --> 00:18:39,605
So yeah after the demo So we can
cut it and right now the second part

324
00:18:40,105 --> 00:18:44,795
So maybe you wonder how did I
set up this API in my browser?

325
00:18:44,905 --> 00:18:48,085
First of all download
Chrome Canary or death.

326
00:18:48,585 --> 00:18:53,195
It doesn't matter for sure latest
version So if you go to this, url,

327
00:18:53,195 --> 00:18:59,415
these are internal urls of the Chrome
colon slash flags and if you search for

328
00:18:59,425 --> 00:19:05,375
prompt api for gemini nano Yeah, just
make it enabled and also another flag

329
00:19:05,385 --> 00:19:10,555
in the flags url optimization guide
and device model So you should enable

330
00:19:10,565 --> 00:19:15,805
that one as well enable bypass perf
requirements Who named it like that?

331
00:19:16,505 --> 00:19:20,190
Anyway, The last Thing that you
should do, and actually it is

332
00:19:20,190 --> 00:19:24,250
one of the most important one,
is downloading the model itself.

333
00:19:24,340 --> 00:19:30,150
if you go to Chrome, URL Components,
so you will find, this name,

334
00:19:30,410 --> 00:19:32,750
Optimization Guide Ion Device Model.

335
00:19:32,820 --> 00:19:37,265
just click and check for the update,
so it's gonna No check for sure.

336
00:19:37,265 --> 00:19:40,745
There is no, model on your machine,
so it's gonna start downloading.

337
00:19:40,755 --> 00:19:43,855
So we just need internal connection
for the first time to download.

338
00:19:44,355 --> 00:19:48,655
So it means that later on, if somebody
wants to use the API, the model

339
00:19:48,665 --> 00:19:50,695
has been downloaded and can use it.

340
00:19:51,195 --> 00:19:52,965
So what's the next step?

341
00:19:53,465 --> 00:19:54,365
What lies ahead?

342
00:19:54,865 --> 00:20:02,395
One of the most important thing
step after my talk after the

343
00:20:02,395 --> 00:20:04,595
thing that we just learned is you.

344
00:20:05,385 --> 00:20:07,875
So I want you to join built in A.

345
00:20:07,875 --> 00:20:08,205
I.

346
00:20:08,295 --> 00:20:09,545
Program from Google.

347
00:20:09,955 --> 00:20:10,575
This is the U.

348
00:20:10,575 --> 00:20:10,725
R.

349
00:20:10,725 --> 00:20:10,975
L.

350
00:20:10,985 --> 00:20:11,735
This is the Q.

351
00:20:11,735 --> 00:20:12,035
R.

352
00:20:12,035 --> 00:20:12,585
Two.

353
00:20:13,515 --> 00:20:19,185
that page just joined the program so we
can, help each other understand more.

354
00:20:19,375 --> 00:20:20,605
Look what's going on.

355
00:20:20,635 --> 00:20:25,765
If you face an issue, because we
are talking about the future, right?

356
00:20:26,125 --> 00:20:29,155
Since we are talking about the
future API that is coming, so for

357
00:20:29,155 --> 00:20:33,815
sure it's not, a stable even from
time to time I face issues as well.

358
00:20:33,825 --> 00:20:36,245
So keep in mind it is very important.

359
00:20:36,995 --> 00:20:42,625
So to, just make your hands dirty
with the code to experiment it.

360
00:20:42,915 --> 00:20:44,845
So this is the URL and QR.

361
00:20:44,845 --> 00:20:46,095
So thanks for joining.

362
00:20:46,595 --> 00:20:53,325
And also, From time to time people
ask me, so how do you see this AI?

363
00:20:53,325 --> 00:20:54,575
Where does it go?

364
00:20:55,195 --> 00:20:57,225
Will AI replace us?

365
00:20:57,385 --> 00:21:02,245
To be honest, I always believe
in this sentence The best way to

366
00:21:02,345 --> 00:21:04,645
predict the future is to create it.

367
00:21:04,685 --> 00:21:09,855
So Right now we have the API, we
have the AI, we have the LLMs, we

368
00:21:09,865 --> 00:21:12,425
have the APIs, everything is there.

369
00:21:12,635 --> 00:21:17,255
Come on guys, we are living in
a world full of, innovations,

370
00:21:17,295 --> 00:21:19,485
APIs, so let's keep it up.

371
00:21:19,725 --> 00:21:25,855
just try to use the latest APIs and
stuff and start learning, create

372
00:21:25,855 --> 00:21:30,515
something, it shouldn't be production
ready, something, or it could be

373
00:21:30,515 --> 00:21:32,635
even one simple page for yourself.

374
00:21:32,845 --> 00:21:33,485
yeah, why not?

375
00:21:33,495 --> 00:21:35,255
Let's start using these features.

376
00:21:35,495 --> 00:21:38,990
And in this way, You
can predict the future.

377
00:21:39,030 --> 00:21:41,790
You can see what are the
features that are coming.

378
00:21:41,810 --> 00:21:46,120
So in that way, yeah, you can
adapt yourself to the future.

379
00:21:46,140 --> 00:21:53,460
So sooner or later, if something happened
to our you, industry because of the A.

380
00:21:53,490 --> 00:21:53,890
I.

381
00:21:53,910 --> 00:21:57,370
So you are ready for that, at
least before that predict that.

382
00:21:57,870 --> 00:22:00,800
So let's see some use cases off this A.

383
00:22:00,830 --> 00:22:01,010
P.

384
00:22:01,010 --> 00:22:01,240
I.

385
00:22:01,450 --> 00:22:06,450
For instance, classification, tagging,
keyboard extraction, helping user,

386
00:22:06,520 --> 00:22:11,900
to compose text summarization,
generating titles, headlines for the

387
00:22:11,900 --> 00:22:17,210
articles, and answering some questions
based on the unstructured data.

388
00:22:17,420 --> 00:22:25,190
So you know that, the data in web pages or
PDFs and stuff are somehow unstructured.

389
00:22:25,210 --> 00:22:29,370
So you can, because LLM
understands it better than us.

390
00:22:29,380 --> 00:22:32,990
So it's not something most of
the time, it's not tangible

391
00:22:32,990 --> 00:22:35,760
to our eyes, but to LLM it is.

392
00:22:36,730 --> 00:22:43,260
Also translation between languages, it
is one of those APIs that is coming.

393
00:22:43,670 --> 00:22:48,120
So a lot of features are coming,
a lot of use cases for this API.

394
00:22:48,500 --> 00:22:53,960
So yeah, it's us that we should
think about it and start innovation.

395
00:22:53,960 --> 00:22:59,970
So if we know that this API exists, so we
can adapt ourselves to the newest changes.

396
00:23:00,470 --> 00:23:02,860
So yeah, AI is everywhere.

397
00:23:03,360 --> 00:23:05,735
Let's be part of it.

398
00:23:06,235 --> 00:23:07,265
Thanks for listening!

399
00:23:07,645 --> 00:23:12,065
If you have any questions, my email
is here, also the QR to my page,

400
00:23:12,095 --> 00:23:15,454
all my social media links are there.

401
00:23:15,844 --> 00:23:19,535
I would be super happy to
have a talk with any of you.

402
00:23:20,035 --> 00:23:21,085
Happy to see you guys!

403
00:23:21,815 --> 00:23:22,974
Hope catch up next time!

