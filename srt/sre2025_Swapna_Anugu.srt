1
00:00:00,300 --> 00:00:01,050
Hello everyone.

2
00:00:01,560 --> 00:00:01,950
I'm Sona.

3
00:00:03,090 --> 00:00:07,380
I'm here to discuss how Auto ML
is transforming enterprise site

4
00:00:07,440 --> 00:00:09,390
reliability engineering practices.

5
00:00:10,260 --> 00:00:14,160
So we will discuss in detail how
the organizations are getting

6
00:00:14,160 --> 00:00:15,990
leverage with this process.

7
00:00:16,650 --> 00:00:20,430
So when it comes to the site
reliability engineering, it's a

8
00:00:20,430 --> 00:00:26,640
fundamental transformations through
auto ml, the evaluation approaches

9
00:00:26,910 --> 00:00:29,100
redefining how organizations monitor.

10
00:00:29,640 --> 00:00:31,169
Predict and response.

11
00:00:31,919 --> 00:00:36,120
This reliability challenges, it is
applicable for across industries.

12
00:00:37,350 --> 00:00:43,110
We will explore how auto ML is
democratizing a power reliable analysis

13
00:00:43,590 --> 00:00:50,129
and predictions all the maximum services
which we can integrate with this auto

14
00:00:50,129 --> 00:00:56,910
ml. So earlier in the traditional
operations, the manual monitoring was.

15
00:00:57,300 --> 00:01:01,890
Quite challenging and it was
time taking process and it was,

16
00:01:02,099 --> 00:01:04,739
uh, giving lot of errors also.

17
00:01:05,160 --> 00:01:08,190
And sometimes the results will
go in different directions.

18
00:01:08,970 --> 00:01:14,850
So if it is the L-A-S-R-E adaptions,
the software engineering principles

19
00:01:14,880 --> 00:01:20,160
with the basic automations or log
monitoring or anomalies, these kind of

20
00:01:20,160 --> 00:01:22,860
protocols is integrated in adoption.

21
00:01:23,820 --> 00:01:24,990
But coming to the modern SRE.

22
00:01:26,895 --> 00:01:31,785
It is emphasizing on service
level objectives, how the instance

23
00:01:31,785 --> 00:01:35,804
management work and how it can
be leveraged with this process.

24
00:01:36,315 --> 00:01:42,540
We can go for the modern SRE, but
nowadays with this cloud, I. We have

25
00:01:42,540 --> 00:01:48,630
a Auto ml, enhanced sre, so with this
integrated auto ml, we have all the

26
00:01:48,630 --> 00:01:55,080
predictive analytics and alerting
mechanism and all the mutation of

27
00:01:55,170 --> 00:01:59,400
this alerts, anomalies, or errors.

28
00:01:59,670 --> 00:02:02,910
All this we can predict
in advance so that.

29
00:02:03,470 --> 00:02:08,060
We can get benefit out of this and the
projects also will run successfully.

30
00:02:08,660 --> 00:02:14,180
So this journey is from traditional
operations to SRE, how this continuous

31
00:02:14,180 --> 00:02:16,640
process, and it's a proactive process.

32
00:02:17,000 --> 00:02:21,109
So we need to check back and forth
and success system complexities and

33
00:02:21,109 --> 00:02:23,209
we can incorporate this process.

34
00:02:23,840 --> 00:02:27,709
So when it comes to the why, actually
enterprises needed this site,

35
00:02:27,769 --> 00:02:32,480
reliability engineering, because
nowadays this scalability is.

36
00:02:33,690 --> 00:02:34,080
High.

37
00:02:35,010 --> 00:02:38,910
This applications are, the
traffic of applications are high,

38
00:02:39,270 --> 00:02:42,810
and the capabilities of this
infrastructure rules has became high.

39
00:02:43,800 --> 00:02:47,490
And even the architecture's
complexities has been increased.

40
00:02:48,720 --> 00:02:53,885
And when it comes to the development, it's
a continuous, uh, processes evaluating

41
00:02:54,090 --> 00:03:01,710
and cycles, release cycles, SDLC process,
uh, all are being increased rapidly.

42
00:03:02,595 --> 00:03:06,915
And user expectations also, they
don't want to tolerate even for

43
00:03:06,915 --> 00:03:08,410
the fraction of seconds downtime.

44
00:03:08,970 --> 00:03:13,680
And even the standards that they
believe that the revenue loss, they

45
00:03:13,680 --> 00:03:20,580
cannot afford it and financial impact,
eventually these outages can impact

46
00:03:20,580 --> 00:03:25,230
the financial processes and, uh,
engineering efforts also will be more.

47
00:03:26,030 --> 00:03:28,370
So this is a brand damage.

48
00:03:28,370 --> 00:03:32,840
Also, we occur with this if we do
not identify the process in elder

49
00:03:32,840 --> 00:03:35,630
stage and we, if we don't address it.

50
00:03:36,290 --> 00:03:40,820
So here how auto ML is
transforming this SRS.

51
00:03:41,780 --> 00:03:46,220
Some use cases is kind of instant
predictions or preventions.

52
00:03:47,060 --> 00:03:51,920
If you can predict any of the
server failure in advance or

53
00:03:52,220 --> 00:03:54,650
any traffic or error spikes.

54
00:03:55,035 --> 00:04:01,485
That is, we can mitigate in advance
by predicting this one so that we

55
00:04:01,485 --> 00:04:07,095
can prevent it, and sometimes we
can go for the root cause analysis.

56
00:04:07,545 --> 00:04:09,195
Most of the time it is users.

57
00:04:09,585 --> 00:04:14,385
Because it's correlate metrics and
it identifies the pattern, how the

58
00:04:14,385 --> 00:04:18,524
logs has been, identifying how the
events are continuously occurring.

59
00:04:19,065 --> 00:04:22,094
These we can, most likely we
can go for the root causes

60
00:04:22,844 --> 00:04:24,795
and it reduces the downtime.

61
00:04:26,020 --> 00:04:31,635
For helping SREs to fix the things,
because if we know the problem, then

62
00:04:31,635 --> 00:04:35,025
we can identify the fix immediately
and we will be very preventive.

63
00:04:35,745 --> 00:04:37,995
We fix all those, these issues.

64
00:04:37,995 --> 00:04:41,115
So that's, that's the reason
root cause analysis will be easy

65
00:04:41,205 --> 00:04:42,680
and helpful to fix faster way.

66
00:04:44,895 --> 00:04:49,065
And when it comes to the capacity
planning, so when automated

67
00:04:50,385 --> 00:04:53,355
ML is focused system outages.

68
00:04:53,940 --> 00:04:59,370
So you can mention that how this
traffic searches and, uh, what

69
00:04:59,370 --> 00:05:04,620
type of overloads can occur and,
uh, if we prevent it and, uh.

70
00:05:05,745 --> 00:05:09,975
Or else if we predict it, we can
increase the size and, uh, you know,

71
00:05:10,005 --> 00:05:15,375
infrastructure allocations, all this,
uh, bandwidth so that we can save the

72
00:05:15,375 --> 00:05:20,385
money in the cloud services, it is
auto-scaling, so whenever the services

73
00:05:20,385 --> 00:05:26,325
are increasing, so it'll be in the cost
will be I, if we don't have a services

74
00:05:26,325 --> 00:05:32,355
much, I mean, if we are not leveraging
most of the time, so then we can reduce

75
00:05:32,355 --> 00:05:34,455
the compute so that we can save the time.

76
00:05:35,414 --> 00:05:40,905
Then other one is automated alert
tuning if too many alerts are coming,

77
00:05:41,325 --> 00:05:46,880
and the automated ML will identify
whether these are true or false.

78
00:05:47,895 --> 00:05:52,575
If it is false, then it'll ignore
because sometimes we don't even

79
00:05:52,575 --> 00:05:56,865
know that a spam kind of males,
like the alerts also not accurate.

80
00:05:57,435 --> 00:06:01,905
And uh, we may tend to that to
be considered and, uh, towards

81
00:06:02,025 --> 00:06:05,535
we end up the time to fix those
things, which is not even.

82
00:06:06,315 --> 00:06:12,104
Um, impact of any of the process, then
that kind of will be analyzed in the

83
00:06:12,104 --> 00:06:18,224
automated alert tuning, so then only the,
we will have a meaningful alerts, so send

84
00:06:18,224 --> 00:06:22,185
to the engineers so that they can only
concentrate on, which are really useful.

85
00:06:23,130 --> 00:06:26,760
And self failing systems, we
can define some of the process.

86
00:06:27,120 --> 00:06:32,040
If, for example, the downtime is high
in during particular time and only the

87
00:06:32,040 --> 00:06:37,410
restart required that we can tune it
if it is reaching this threshold value.

88
00:06:37,770 --> 00:06:42,570
And then, uh, we can mention that
the rules, which are, we can define

89
00:06:42,570 --> 00:06:48,240
easily and automatically it restarts
so that attention we, we need not

90
00:06:48,240 --> 00:06:50,670
to give, so it'll automatically fix.

91
00:06:51,854 --> 00:06:58,125
And, uh, eventually all these things
will, we can get implemented how

92
00:06:58,185 --> 00:07:00,674
earlier the traditional MLS was going.

93
00:07:00,674 --> 00:07:07,215
So it was a massive process where
time taking and the efforts also more.

94
00:07:07,695 --> 00:07:11,294
So when it comes to the data
acquisitions, so all the cases that,

95
00:07:11,294 --> 00:07:15,854
uh, predefined data will acquire it,
even the traditional and automated.

96
00:07:16,484 --> 00:07:22,125
But after this, when it comes to the data
exploration, two, data preparation and

97
00:07:22,125 --> 00:07:27,615
feature engineering, then model selection,
model training, and the parameters for.

98
00:07:27,825 --> 00:07:30,255
Performance tuning and model evaluations.

99
00:07:30,675 --> 00:07:35,325
These all process will in, in the
existing, in the traditional ml, but

100
00:07:35,354 --> 00:07:38,715
whereas in the ml. So all these will.

101
00:07:39,420 --> 00:07:44,340
Come up, come up with the machine
learning automated system where we

102
00:07:44,340 --> 00:07:50,400
can only in insert the data and we
can make, give some metrics and, uh,

103
00:07:50,400 --> 00:07:54,750
sometimes we can, if we are really
budget friendly, we can give the time

104
00:07:54,840 --> 00:08:00,420
and, uh, cost so that it'll consider all
these parameters which you have given.

105
00:08:00,810 --> 00:08:02,280
And this is the black box.

106
00:08:02,490 --> 00:08:05,580
And where you can also
mention if you are really.

107
00:08:05,625 --> 00:08:07,155
Sure about the process.

108
00:08:07,155 --> 00:08:11,445
Then you can mention if you
are not, then you can take the

109
00:08:11,565 --> 00:08:16,065
approaches from this automated ml
that, uh, features, algorithms.

110
00:08:16,065 --> 00:08:17,145
All these parameters.

111
00:08:17,145 --> 00:08:18,015
We can mention it.

112
00:08:18,615 --> 00:08:23,685
And then after this, it'll consider
various, uh, train and test status and

113
00:08:23,685 --> 00:08:28,545
it'll give the results and, uh, that will
give a rank and, uh, accuracy for us.

114
00:08:28,905 --> 00:08:33,975
So out of this, it's your choice to
discuss and, uh, decide among of this

115
00:08:34,304 --> 00:08:36,405
and you can get benefit out of this.

116
00:08:36,975 --> 00:08:42,044
So this is how that, um, auto ML process
is very easy and, uh, without having

117
00:08:42,044 --> 00:08:45,465
much knowledge in the data scientist
science, also we can go for it.

118
00:08:46,605 --> 00:08:52,935
So, and coming to the auto ML
transforms, uh, SRE workflows, we can.

119
00:08:53,370 --> 00:08:58,860
Do this in a better way as first we can
go for the data collections and, uh,

120
00:08:59,040 --> 00:09:02,850
the future engineering and monitoring
resources can derive from there.

121
00:09:03,390 --> 00:09:07,680
And the model selections and training
this algorithms is the models, this

122
00:09:07,890 --> 00:09:10,230
only the reliability scenarios.

123
00:09:10,760 --> 00:09:15,709
Whether it is a prediction, uh, then it'll
choose the prediction models and anomaly

124
00:09:15,709 --> 00:09:20,449
detections if it is continuous monitoring
and recognization behaviors that exist.

125
00:09:20,810 --> 00:09:24,560
So it'll, it'll identify those
and it'll monitor for it.

126
00:09:25,069 --> 00:09:28,760
And predictive responses also
automated the two actions.

127
00:09:29,150 --> 00:09:33,620
This adjustments, whatever the predict
insights it, it gives, if you can

128
00:09:33,620 --> 00:09:37,490
search, mention in that parameter so
that it'll automatically consider it.

129
00:09:38,925 --> 00:09:43,875
So this streamlined, uh, analytic
workflow, it's eliminate all the

130
00:09:43,875 --> 00:09:51,015
manual efforts and model tuning, also
improving this accuracy coming to the

131
00:09:51,015 --> 00:09:52,935
practical implementation framework.

132
00:09:53,175 --> 00:09:57,345
So whenever you wanted to implement
in your organizations, so then you can

133
00:09:57,345 --> 00:09:58,814
go for the assessments and planning.

134
00:10:00,030 --> 00:10:04,860
Then evaluate the current SRE maturity,
whether it is working fine or you

135
00:10:04,860 --> 00:10:06,300
wanted to go for the automation.

136
00:10:06,480 --> 00:10:10,650
If it is a maturity of your manual
process, then it is fine, but most of

137
00:10:10,650 --> 00:10:15,660
the cases, manual intervention is more
then, so then identify this high value

138
00:10:15,660 --> 00:10:18,630
use cases and what is the success metrics.

139
00:10:18,960 --> 00:10:21,870
Then whatever the existing
process, you can document it

140
00:10:22,319 --> 00:10:24,630
and you can see the automation.

141
00:10:24,630 --> 00:10:26,850
Then, uh, you can see the differences.

142
00:10:27,540 --> 00:10:31,170
If it has come to the data preparation
that whatever the data monitoring

143
00:10:31,170 --> 00:10:36,630
data is available, and you can
establish the quality baselines and

144
00:10:36,630 --> 00:10:41,280
uh, some labels, you can create it
and even the tips it is used for the

145
00:10:41,280 --> 00:10:44,790
supervised learning platform selections.

146
00:10:45,270 --> 00:10:47,040
There are, uh, three.

147
00:10:47,685 --> 00:10:52,395
Platforms, if you can assume it's
the most, uh, predominantly using by

148
00:10:52,395 --> 00:10:57,824
organizations is, uh, Azure to ml,
and Google also is having this feature

149
00:10:57,915 --> 00:11:03,495
and, uh, AWS also, it's up to the
organizations what services they can.

150
00:11:03,805 --> 00:11:05,155
Use it, what cloud?

151
00:11:05,485 --> 00:11:06,355
They can go for it.

152
00:11:06,355 --> 00:11:07,435
They can select it.

153
00:11:07,795 --> 00:11:13,045
And, uh, most of the cases,
every, every, uh, platform is

154
00:11:13,045 --> 00:11:14,875
working in the similar approach.

155
00:11:15,055 --> 00:11:19,315
So then that specific use cases
we can consider cloud native

156
00:11:19,315 --> 00:11:21,865
and, and vendor neutral options.

157
00:11:22,470 --> 00:11:26,760
Then pilot implementations, you can
please start with the, uh, modified

158
00:11:26,760 --> 00:11:32,520
pilot projects and assess it and
how the transition, this automated

159
00:11:32,520 --> 00:11:38,100
process, you can, uh, go for the
implementation, then scale and optimize.

160
00:11:38,105 --> 00:11:42,245
Expand this additional use cases if
you are comfortable with the model

161
00:11:42,245 --> 00:11:46,835
performance, and you can go for the
large group of things and you can go

162
00:11:46,835 --> 00:11:50,975
for the continuous implement, so that
that's how the project will go live.

163
00:11:51,005 --> 00:11:55,385
And, uh, you will be, you can compare the
results and you will, you will be good.

164
00:11:55,865 --> 00:12:02,045
Then the manual results versus automated
results and when it comes to the key

165
00:12:02,045 --> 00:12:04,775
operational metrics, implement now.

166
00:12:05,115 --> 00:12:10,155
It has been around as per the
statistics, it has been 68%.

167
00:12:11,325 --> 00:12:18,795
Uh, man, time to deductions decreased
this process and faster 42%.

168
00:12:19,275 --> 00:12:23,295
Meantime, resolution has
improved across, uh, with 42.

169
00:12:24,255 --> 00:12:29,715
That 48 percentage and alert
accuracy are very high.

170
00:12:30,105 --> 00:12:36,314
This is around 91% as per the
statisticians and the coverage expansion

171
00:12:36,314 --> 00:12:43,275
is tripled and these all, uh, key metrics
which organization considering to it.

172
00:12:46,079 --> 00:12:51,300
And if next steps, if you wanted to
go for it, then the conductor, some

173
00:12:51,300 --> 00:12:56,939
audit cases and some take of the two
to three high level use cases and

174
00:12:57,360 --> 00:13:03,120
discuss with the cross-functional teams
because all stakeholders, engineers,

175
00:13:03,510 --> 00:13:08,969
and data scientists, if they involve,
so we will have a good understanding.

176
00:13:08,969 --> 00:13:09,594
What are the.

177
00:13:10,125 --> 00:13:14,295
Major problems and how we can
address those issues and how we

178
00:13:14,295 --> 00:13:19,185
can come out of the situation by
reducing the downtime or anomalies.

179
00:13:19,425 --> 00:13:19,814
Error Pro.

180
00:13:21,074 --> 00:13:25,095
And this, you can launch the pilot
project in the auto ML later once

181
00:13:25,095 --> 00:13:29,895
you are comparing with the manual,
uh, results versus auto ML results.

182
00:13:34,064 --> 00:13:36,910
Yes, there are some implementation
challenges here too.

183
00:13:37,905 --> 00:13:41,415
For example, if you go for the
data quality issues, there is

184
00:13:41,415 --> 00:13:46,935
an inconsist and incomplete in
the monitoring data that time.

185
00:13:46,995 --> 00:13:52,520
What we can suggest in this solution,
the data validation pipelines, is.

186
00:13:54,015 --> 00:13:56,235
Input meet inputs and all.

187
00:13:56,265 --> 00:14:01,725
They should meet the standard process
because if the data is accurate and

188
00:14:01,725 --> 00:14:07,814
if incorrect data and if the relation
between the data, so then you will have a

189
00:14:08,175 --> 00:14:14,954
correct output so you can check when you
are passing this data to the model, then

190
00:14:14,954 --> 00:14:20,084
automatically the quality issues will be
resolved and the scoring also will impact

191
00:14:20,115 --> 00:14:22,755
if you do not post the data properly.

192
00:14:24,630 --> 00:14:26,790
And organization resistance.

193
00:14:26,819 --> 00:14:27,270
Yes.

194
00:14:27,329 --> 00:14:29,520
SRE teams is trusting.

195
00:14:29,520 --> 00:14:34,949
Automated process is difficult
because there are, uh, some critical

196
00:14:35,250 --> 00:14:37,949
decisions also be taken, of course.

197
00:14:37,949 --> 00:14:43,199
But what I suggest, you can go for
the non-critical systems and if

198
00:14:43,199 --> 00:14:48,359
you have a confidence and to go for
the side by side comparison, how.

199
00:14:48,750 --> 00:14:52,410
The manual results and how
the automatic decisions.

200
00:14:52,920 --> 00:14:57,960
So eventually, if you see it so
you can go for these approaches.

201
00:14:59,040 --> 00:15:00,540
Integration complexity.

202
00:15:01,199 --> 00:15:01,650
Yes.

203
00:15:01,680 --> 00:15:07,110
Connecting automate auto ML outputs
to existing this monitoring tools.

204
00:15:07,199 --> 00:15:11,595
For example, if you have a, uh,
platform specific tools and.

205
00:15:12,450 --> 00:15:17,010
It is hard to integrate at one
stretch with the auto ML process.

206
00:15:17,370 --> 00:15:23,730
So for that, we can leverage standard
APIs and some architectures to create

207
00:15:23,730 --> 00:15:26,100
some loosely coupled integration points.

208
00:15:26,460 --> 00:15:32,730
But now with the Cloud auto MLS are
providing lot of s, we can get leverage

209
00:15:32,730 --> 00:15:34,710
with those and we can go for it.

210
00:15:35,250 --> 00:15:38,970
So the successful implementations
all the way it is required.

211
00:15:39,735 --> 00:15:43,845
Thoughtful discussions and the
technical and organization challenges.

212
00:15:44,745 --> 00:15:52,065
Some domains I can, most of the domains
are using this one, but how much

213
00:15:52,125 --> 00:15:53,985
the domains are getting leveraged.

214
00:15:53,985 --> 00:15:58,785
So I just wanted to point out some
of the areas, for example, if you

215
00:15:58,785 --> 00:16:03,015
take the financial services, this
automatic predicts, the how much

216
00:16:03,015 --> 00:16:08,805
load during the market hours are
stock exchange timings, if it.

217
00:16:09,569 --> 00:16:10,260
Predicts it.

218
00:16:10,890 --> 00:16:15,240
And then during that we can
make a decision during this peak

219
00:16:15,240 --> 00:16:20,699
hours whether we can scale out
and, uh, increase the resources.

220
00:16:20,760 --> 00:16:24,870
We, we can decide in
pre preventive measures.

221
00:16:24,870 --> 00:16:26,130
Also, we can take it.

222
00:16:27,275 --> 00:16:31,830
And it can detect anomalies in
the transactions, our server

223
00:16:31,830 --> 00:16:37,380
level logs, if any fraud or system
values, that also we can detect it.

224
00:16:37,650 --> 00:16:39,870
So hence we can take a good action on it.

225
00:16:41,040 --> 00:16:45,570
And if you go for the
e-commerce, e-commerce, if it is.

226
00:16:46,215 --> 00:16:53,085
We predict the traffic spikes, how
the sales time be Black Friday or New

227
00:16:53,085 --> 00:17:00,645
Year, new Year time, are any of the,
uh, during holidays that time the, you

228
00:17:00,645 --> 00:17:05,984
know, sales services is high and we
can expect the peak covers during that.

229
00:17:06,405 --> 00:17:12,224
So it automatically predicts and we can,
it pop up to us in advance so that we can

230
00:17:12,224 --> 00:17:14,504
take a decisions to how to improve the.

231
00:17:15,015 --> 00:17:16,845
Compete engine are.

232
00:17:17,055 --> 00:17:21,735
This is also detect the anomalies and if
any revenue laws from the field, payments

233
00:17:21,735 --> 00:17:26,955
and all so that we can take care, for
example, if the one payment process is not

234
00:17:26,955 --> 00:17:31,845
going through well all the time so that we
can have a preventive measures to opt it.

235
00:17:33,030 --> 00:17:35,250
Then, uh, other healthcare.

236
00:17:36,090 --> 00:17:40,260
This healthcare monitors iot
devices and patient data as systems.

237
00:17:40,680 --> 00:17:45,660
This EMR medical reports also is the
predictive maintenance can be happen,

238
00:17:46,170 --> 00:17:48,150
and the same way telecom industries.

239
00:17:48,150 --> 00:17:53,040
Also, we can detect outages in the
real time and the failover roads.

240
00:17:53,040 --> 00:17:57,780
Also, we can identify, we can
forecast usage patterns, how

241
00:17:57,780 --> 00:18:00,540
the bandwidth allocations and
the infrastructure deployment.

242
00:18:02,115 --> 00:18:02,505
Here.

243
00:18:02,565 --> 00:18:09,465
I would like to conclude saying
ROML is not a replace of sre.

244
00:18:10,065 --> 00:18:14,925
It only enhances the tool is getting used.

245
00:18:14,925 --> 00:18:15,885
The capabilities of.

246
00:18:16,680 --> 00:18:23,460
SRE practices, how we can automatic
routine analysis, our decision makings,

247
00:18:23,520 --> 00:18:26,670
our anomalies, our fraud detections.

248
00:18:27,060 --> 00:18:31,380
These kind of scenarios are P
covers, these SRE practices, whatever

249
00:18:31,380 --> 00:18:33,090
we are doing in normal basis.

250
00:18:34,050 --> 00:18:35,340
I mean manual braces.

251
00:18:35,340 --> 00:18:40,890
So we can go for this approach and we
can think in the strategical way and

252
00:18:40,890 --> 00:18:43,320
then we can have decisions out of this.

253
00:18:44,429 --> 00:18:51,209
This allows SRE to focus on only
strategic tasks, but when this heavy

254
00:18:51,300 --> 00:18:55,919
load is there, then that time it
is hard to take your decisions with

255
00:18:55,919 --> 00:19:00,480
the specific tools and um, you know,
the tool compatibilities and all.

256
00:19:00,480 --> 00:19:03,689
But, uh, whereas if it's
ML it handles very well.

257
00:19:04,860 --> 00:19:07,050
So this is what I wanted to conclude here.

258
00:19:07,080 --> 00:19:11,416
So thank you so much for
this giving this opportunity.

