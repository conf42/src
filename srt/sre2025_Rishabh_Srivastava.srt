1
00:00:00,500 --> 00:00:01,220
Hello everyone.

2
00:00:01,580 --> 00:00:06,650
Welcome to the Con 42 Site Reliability
Engineering 2025 conference.

3
00:00:07,220 --> 00:00:12,200
My name is Ravata, and today I'm going
to talk about the alert and monitoring

4
00:00:12,230 --> 00:00:17,000
and the strategies for identifying
and resolving performance bottlenecks.

5
00:00:17,330 --> 00:00:19,040
So let's just get started.

6
00:00:19,540 --> 00:00:23,350
System failures can have
severe real world consequences.

7
00:00:23,875 --> 00:00:28,525
Impacting finances, safety, and
critical infrastructure in finance.

8
00:00:28,525 --> 00:00:32,125
Trading glitches like the 20 20
12 Night capital group trading

9
00:00:32,125 --> 00:00:38,455
algorithm failure resulted in a
loss of 440,000,045 minutes while

10
00:00:38,455 --> 00:00:41,605
banking outages disrupt transactions.

11
00:00:41,845 --> 00:00:46,495
Another example is the Amazon Web
Services outage in 2021, which caused

12
00:00:46,585 --> 00:00:51,595
major losses across multiple businesses
while banking outages, disrupt

13
00:00:51,595 --> 00:00:53,335
transactions, and customer access.

14
00:00:53,995 --> 00:00:58,555
Healthcare, failure in medical
devices or hospital regard systems

15
00:00:58,555 --> 00:01:00,864
can delay treatments and risk lives.

16
00:01:01,375 --> 00:01:04,974
Transportation failures such
as aviation software crashes or

17
00:01:04,974 --> 00:01:08,635
self-driving car malfunctions led to.

18
00:01:08,900 --> 00:01:11,539
Delays accidents and safety concerns.

19
00:01:12,020 --> 00:01:18,590
Power grid failures like the 2003 North
American blackout affect millions while

20
00:01:18,590 --> 00:01:23,959
cyber attacks on infrastructures such
as the colonial pipeline attack, disrupt

21
00:01:24,229 --> 00:01:26,479
supply chain, and fuel availability.

22
00:01:27,414 --> 00:01:28,134
Data breaches.

23
00:01:28,134 --> 00:01:33,914
Like the 2017 Equifax hack exposes
sensitive information leading

24
00:01:33,914 --> 00:01:36,315
to financial fraud and theft.

25
00:01:36,675 --> 00:01:40,484
Even defense and system space
systems failure can compromise

26
00:01:40,484 --> 00:01:45,395
national security affecting military
operations and GPS navigations system.

27
00:01:45,395 --> 00:01:48,785
Downtime in major tech platforms
can hurt businesses and

28
00:01:48,785 --> 00:01:50,494
impact global communication.

29
00:01:51,365 --> 00:01:55,384
Faulty AI decision making in areas
like fraud detection, hiring,

30
00:01:55,384 --> 00:01:59,344
and credit approvals can lead to
unfair biases and legal challenges.

31
00:01:59,824 --> 00:02:04,744
These risks highlight the need
for a robust engineering rigorous

32
00:02:04,744 --> 00:02:08,974
testing, cybersecurity measures and
resilience system designs to prevent

33
00:02:08,974 --> 00:02:14,104
the catastrophic failures and ensure
reliability in critical services.

34
00:02:14,604 --> 00:02:19,194
System failures can severely disrupt
business operations by halting

35
00:02:19,554 --> 00:02:23,184
critical services, delaying production,
and causing financial losses.

36
00:02:23,545 --> 00:02:27,179
For example, software outages can
prevent employees from accessing

37
00:02:28,134 --> 00:02:31,765
key data or applications leading to
inefficiency and missed deadlines.

38
00:02:32,349 --> 00:02:37,419
In customer facing systems, failures
can result in poor user experience,

39
00:02:37,419 --> 00:02:39,519
loss sales, and damage reputation.

40
00:02:40,149 --> 00:02:44,169
Payment processing issues can hold
transactions affecting revenues.

41
00:02:45,024 --> 00:02:49,075
Supply chain disruptions due to system
errors can delay production, delivery

42
00:02:49,135 --> 00:02:51,684
and create inventory shortages.

43
00:02:52,255 --> 00:02:56,094
Additionally, data breaches or
cybersecurity attacks can compromise

44
00:02:56,094 --> 00:03:01,225
sensitive information leading to legal
liabilities and loss of customer trust.

45
00:03:01,434 --> 00:03:05,230
Ensuring system reliability is
crucial for maintaining smooth and

46
00:03:05,230 --> 00:03:06,629
continuous business operations.

47
00:03:07,434 --> 00:03:11,874
Monitoring is essential for
maintaining uptime and system health.

48
00:03:12,114 --> 00:03:17,424
By providing realtime insights into
system performance, it helps detect

49
00:03:17,575 --> 00:03:23,154
issues early, such as slowdowns
errors or security breaches before

50
00:03:23,154 --> 00:03:24,714
they can even escalate into a major.

51
00:03:24,714 --> 00:03:25,404
Problems.

52
00:03:25,855 --> 00:03:29,784
With proactive monitoring, teams can
quickly address potential failures,

53
00:03:29,814 --> 00:03:33,924
minimizing downtime, and reducing
the impact on users and operations.

54
00:03:34,404 --> 00:03:39,174
It also allows for continuous
optimization, ensuring systems run

55
00:03:39,204 --> 00:03:44,214
efficiency and securely by tracking
key metrics like server load,

56
00:03:44,214 --> 00:03:46,584
response times, and error rates.

57
00:03:46,765 --> 00:03:52,644
Monitoring helps maintain a stable
environment, ensuring consistent C service

58
00:03:52,765 --> 00:03:54,714
delivery, and preventing disruptions.

59
00:03:55,214 --> 00:03:59,535
Alerting plays a critical role in
ensuring rapid issue resolution

60
00:03:59,535 --> 00:04:03,855
by notifying team about potential
problems as soon as they arise.

61
00:04:04,355 --> 00:04:08,585
It provides realtime alerts based
on predefined thresholds, enabling

62
00:04:08,645 --> 00:04:13,475
immediate action before issues
impact users or system performances.

63
00:04:14,299 --> 00:04:18,710
By prioritizing alerts according to
severity, teams can focus on critical

64
00:04:18,710 --> 00:04:23,600
issues first, reducing downtime and
minimizing business disruptions.

65
00:04:23,990 --> 00:04:28,669
Prompt alerts also ensures that the
right team members are informed, enabling

66
00:04:28,669 --> 00:04:33,554
faster collaboration, and quicker
resolutions in fast paced environment.

67
00:04:33,865 --> 00:04:38,155
Effective alerting helps maintain system
health, improves response times and

68
00:04:38,184 --> 00:04:40,355
ensures continuous service availability.

69
00:04:40,855 --> 00:04:45,145
Monitoring is the ongoing process
of tracking system health to ensure

70
00:04:45,205 --> 00:04:47,125
optimal performance and stability.

71
00:04:47,665 --> 00:04:51,685
It involves continuously observing
key system metrics, such as

72
00:04:52,345 --> 00:04:56,965
server load, response times, and
error rates to identify potential

73
00:04:56,965 --> 00:05:00,955
issues before they escalate by
maintaining constant visibility.

74
00:05:01,765 --> 00:05:05,425
Monitoring helps detect anomalies,
performance bottlenecks,

75
00:05:05,455 --> 00:05:06,925
and security threats early.

76
00:05:07,300 --> 00:05:09,640
Allowing teams to take proactive measures.

77
00:05:10,030 --> 00:05:15,340
This continuous oversight ensures system
remains reliable, efficient, and secure.

78
00:05:15,790 --> 00:05:17,890
Minimizing downtime and supply.

79
00:05:17,920 --> 00:05:22,810
Supporting smooth business operations
monitoring is essential for maintaining a

80
00:05:22,810 --> 00:05:25,395
healthy high performance IT environment.

81
00:05:26,025 --> 00:05:31,155
Key components of monitoring include data
collection, analysis, and visualization.

82
00:05:31,575 --> 00:05:33,765
Data collection involves gathering logs.

83
00:05:34,265 --> 00:05:34,535
Sorry.

84
00:05:34,955 --> 00:05:39,125
Log metrics and events from servers,
applications, and infrastructure

85
00:05:39,125 --> 00:05:40,595
to capture system behaviors.

86
00:05:40,985 --> 00:05:46,415
Analysis is the process of detecting
patent trends and potential issues.

87
00:05:46,535 --> 00:05:51,705
By examining this data for anomalies
or irregularities, visualization helps

88
00:05:51,965 --> 00:05:56,320
in interpret system performance through
dashboards and reports, providing

89
00:05:56,320 --> 00:05:58,810
clear insights into the system health.

90
00:05:59,200 --> 00:05:59,590
Together.

91
00:05:59,590 --> 00:06:04,780
These components enable proactive
management and ensure quick identification

92
00:06:04,780 --> 00:06:09,070
and resolution of problems leading
to improved uptime and efficiency.

93
00:06:09,570 --> 00:06:12,600
Infrastructure monitoring focuses
on tracking the health of the

94
00:06:12,600 --> 00:06:17,250
underlying hardware, such as
CPU usage and disc utilization.

95
00:06:17,700 --> 00:06:21,630
This helps ensure that the system
resources are not overburdened

96
00:06:21,720 --> 00:06:24,240
preventing slowdowns or crashes.

97
00:06:24,750 --> 00:06:26,729
Application performance monitoring.

98
00:06:26,729 --> 00:06:30,870
Also called as a PM, measures
the performance of application by

99
00:06:30,870 --> 00:06:35,219
monitoring response times and database
queries, allowing system to identify

100
00:06:35,219 --> 00:06:37,380
bottlenecks and optimize performance.

101
00:06:37,890 --> 00:06:40,289
Network monitoring focuses on latency.

102
00:06:40,440 --> 00:06:45,780
Packet loss and connectivity issues,
ensuring smooth and communication between

103
00:06:45,780 --> 00:06:47,610
systems and minimizing disruptions.

104
00:06:48,060 --> 00:06:52,980
Lastly, securing monitoring involves
tools for anomaly detection and

105
00:06:53,219 --> 00:06:57,960
intrusion detection systems, which
helps identify unusual activity

106
00:06:58,020 --> 00:06:59,640
or potential security breaches.

107
00:07:00,060 --> 00:07:04,110
These four areas together provide
a comprehensive approach to

108
00:07:04,110 --> 00:07:08,910
maintaining system health, optimizing
performance, and ensuring security.

109
00:07:09,410 --> 00:07:13,340
Effective monitoring helps identify
performance bottlenecks early,

110
00:07:14,060 --> 00:07:20,870
allowing steam to detect slowdowns,
high resource usage or inefficiencies

111
00:07:20,870 --> 00:07:22,670
before they impact operations.

112
00:07:23,360 --> 00:07:29,600
This enables proactive problem resolution,
which ensures our addressed before

113
00:07:29,600 --> 00:07:31,760
they escalate into major failures.

114
00:07:32,510 --> 00:07:37,400
Reducing downtime and minimizing
business disruptions by continuously

115
00:07:37,400 --> 00:07:39,560
tracking key system metrics.

116
00:07:39,650 --> 00:07:45,500
Monitoring help ensure system stability
and smooth user experience preventing

117
00:07:46,070 --> 00:07:49,040
unexpected crashes or performance issues.

118
00:07:49,550 --> 00:07:54,050
A well monitored system runs
efficiently, maintains reliability,

119
00:07:54,140 --> 00:07:56,540
and keeps users satisfied.

120
00:07:57,320 --> 00:08:02,300
Ultimately supporting seamless business
operations and long-term success.

121
00:08:02,800 --> 00:08:05,650
So components of alerting.

122
00:08:06,150 --> 00:08:09,715
Alerting its process of notifying
teams when an issue arises,

123
00:08:09,804 --> 00:08:16,044
ensuring that potential problems are
addressed before they are impacted.

124
00:08:16,780 --> 00:08:17,559
Users,

125
00:08:18,059 --> 00:08:19,430
it allows it.

126
00:08:19,490 --> 00:08:23,450
It works by triggering real time
alerts based on predefined thresholds,

127
00:08:23,450 --> 00:08:28,159
such as high CPU usage, slow
response times, or security threats.

128
00:08:28,490 --> 00:08:33,110
Alerting prevents unnoticed system
failures by continuously monitoring

129
00:08:33,380 --> 00:08:38,210
critical components and immediate
flagging anomalies, reducing

130
00:08:38,210 --> 00:08:40,640
the risk of prolonged downtime.

131
00:08:41,510 --> 00:08:45,380
It plays a crucial role in ensuring
quick response time to incidents,

132
00:08:45,620 --> 00:08:50,030
enabling teams to act swiftly,
resolve issues efficiently, and

133
00:08:50,030 --> 00:08:52,070
maintaining system stability.

134
00:08:52,880 --> 00:08:58,310
Effective alerting minimizes disruptions,
protects users experience, and

135
00:08:58,310 --> 00:09:00,170
helps maintain business continuity.

136
00:09:00,670 --> 00:09:04,780
Alerting consists of key
components, triggers notification

137
00:09:04,785 --> 00:09:07,245
channel and escalation policies.

138
00:09:07,745 --> 00:09:12,485
Triggers are the conditions that active
alerts such as high CPU usage, server

139
00:09:12,485 --> 00:09:18,095
downtime, or security breaches, these
predefined threshold ensures that

140
00:09:18,095 --> 00:09:20,689
teams are notified the moment an alert.

141
00:09:21,635 --> 00:09:23,375
Arises issue arises.

142
00:09:23,855 --> 00:09:28,355
Notification channels determine how
alerts are delivered, including email,

143
00:09:28,895 --> 00:09:35,285
SMS Slack or PagerDuty, ensuring that the
right people are informed instantly as

144
00:09:35,285 --> 00:09:38,525
soon as the issue is started occurring.

145
00:09:39,305 --> 00:09:43,055
Escalation policies ensures that
if an alert is not acknowledged,

146
00:09:43,235 --> 00:09:47,135
it is forwarded to the next
level, guaranteeing a response.

147
00:09:47,675 --> 00:09:52,204
Together these components create an
efficient alert ring system that helps

148
00:09:52,444 --> 00:09:57,724
teams react quickly, prevent unnoticed
failures, and maintain system stability.

149
00:09:58,224 --> 00:10:02,244
To build an effective alert system,
it's important to set clear alert

150
00:10:02,394 --> 00:10:07,279
thresholds so teams are notified
only when issue truly need attention.

151
00:10:08,049 --> 00:10:12,969
Ensuring alerts and actions are
helps prevent unnecessary noise

152
00:10:12,969 --> 00:10:17,409
by providing relevant details
and clear steps for resolution.

153
00:10:17,889 --> 00:10:22,689
Prioritizing alerts is crucial to avoid
alert fatigue, ensuring that critical

154
00:10:22,689 --> 00:10:29,179
issues are addressed first while lower
priority alerts don't overwhelm teams.

155
00:10:29,554 --> 00:10:34,504
Finally, using automation to resolve
common issues helps reduce manual

156
00:10:34,564 --> 00:10:40,054
interventions by automatically handling
repetitive problems, improve response

157
00:10:40,054 --> 00:10:42,454
times, and maintaining system stability.

158
00:10:42,694 --> 00:10:47,644
A well-structured alerting should keep
operations as smooth and teams efficient.

159
00:10:48,144 --> 00:10:51,624
An effective alerting system
can cause serious challenges.

160
00:10:52,014 --> 00:10:55,619
Too many alerts can overwhelm
teams leading to alert fatigue.

161
00:10:56,364 --> 00:10:59,515
Where critical issues may be
ignored, false positives and

162
00:10:59,515 --> 00:11:01,374
false negatives create confusion.

163
00:11:01,765 --> 00:11:05,454
False positive triggers, unnecessary
responses while false negative

164
00:11:05,454 --> 00:11:07,494
causes real issues to go unnoticed.

165
00:11:08,275 --> 00:11:11,484
Delaying action, lack
of context in alerts.

166
00:11:12,100 --> 00:11:16,030
Makes it difficult to diagnose
problem quickly as alerts

167
00:11:16,090 --> 00:11:17,680
without relevant details.

168
00:11:17,680 --> 00:11:20,350
Force teams to spend
extra time investigating.

169
00:11:20,470 --> 00:11:25,540
Finally, delayed responses can turn minor
issues into major outages, impacting

170
00:11:25,540 --> 00:11:27,850
system uptime and user experiences.

171
00:11:28,510 --> 00:11:31,814
A well tuned alerts strategy
ensures timely, accurate,

172
00:11:31,954 --> 00:11:34,295
and actionable notifications.

173
00:11:34,795 --> 00:11:39,204
To improve alerting effectiveness,
it's essential to tune alert

174
00:11:39,234 --> 00:11:44,515
thresholds, carefully balancing
sensitivity to avoid both excessive

175
00:11:44,515 --> 00:11:47,875
noise and missed issues implementing.

176
00:11:48,475 --> 00:11:52,435
Structured on-call rotations
ensures that alerts are handled

177
00:11:52,495 --> 00:11:56,905
effectively, preventing burnouts,
and ensuring 24 by seven coverage.

178
00:11:57,355 --> 00:12:02,814
Leveraging ai, ML based anomaly
detection helps identify unusual patterns

179
00:12:02,814 --> 00:12:07,704
and reduce false positives, making
alerting smarter and more precise.

180
00:12:08,005 --> 00:12:13,125
Lastly, ensuring logs and metrics
provide enough enough context allows

181
00:12:13,125 --> 00:12:17,355
teams to quickly diagnose and resolve
issues without unnecessary delays.

182
00:12:18,305 --> 00:12:22,445
Optimized alerting system enhances
the response times, reduce fatigues

183
00:12:22,715 --> 00:12:24,875
and maintains system reliability.

184
00:12:25,375 --> 00:12:28,855
An effective alerting process
follows a structured approach.

185
00:12:28,855 --> 00:12:34,525
Step one would be monitoring system
health and collecting data to track

186
00:12:34,525 --> 00:12:37,485
key performance metrics in real time.

187
00:12:37,985 --> 00:12:39,425
Analyze logs and metrics.

188
00:12:39,425 --> 00:12:39,965
Detect two.

189
00:12:40,465 --> 00:12:45,535
Detect anomalies and identify potential
issues before they actually escalate.

190
00:12:46,035 --> 00:12:52,945
Third would be a step up alerts based on
the critical thresholds, ensuring teams

191
00:12:52,945 --> 00:12:55,405
are notified only when action is needed.

192
00:12:55,905 --> 00:13:00,130
Step four would be automate responses
for faster recovery, reducing manual

193
00:13:00,490 --> 00:13:02,385
interventions, and minimizing downtime.

194
00:13:02,940 --> 00:13:06,600
Step five would be continuously
refining alert rules to improve

195
00:13:06,600 --> 00:13:11,070
efficiency, reducing false alarms,
and ensuring alert remains relevant.

196
00:13:11,700 --> 00:13:15,570
The structured approach helps
maintain system stability and

197
00:13:15,570 --> 00:13:17,430
ensures the rapid issue resolution.

198
00:13:17,930 --> 00:13:20,900
There are various tools available
for monitoring and alerting.

199
00:13:21,400 --> 00:13:25,150
Ramus and Grafana are popular
open source solutions.

200
00:13:25,465 --> 00:13:28,945
That provide powerful monitoring
and visualization capabilities.

201
00:13:29,335 --> 00:13:34,495
Datadog and New Relic are commercial
observability platforms, offering

202
00:13:34,495 --> 00:13:38,005
real-time insights, application
performance monitoring, and

203
00:13:38,095 --> 00:13:42,985
an advanced analysis for cloud
environments providers offer built-in

204
00:13:42,985 --> 00:13:45,805
solutions like AWS CloudWatch.

205
00:13:46,050 --> 00:13:51,090
Azure Monitor and Google Cloud operations,
which integrates seamlessly with

206
00:13:51,090 --> 00:13:55,980
cloud services to track performances,
detect issues, and trigger alerts.

207
00:13:56,190 --> 00:13:59,610
Choosing the right tool depends
on system requirement, scalability

208
00:13:59,610 --> 00:14:01,890
needs, and budget, ensuring.

209
00:14:02,235 --> 00:14:05,175
Efficient monitoring and
proactive issue resolutions.

210
00:14:05,595 --> 00:14:07,215
When choosing monitoring tool.

211
00:14:07,305 --> 00:14:11,295
Consider your team's expertise,
budget in budget, integration needs

212
00:14:11,325 --> 00:14:13,185
and specific monitoring requirements.

213
00:14:13,515 --> 00:14:17,745
The right tool ensures seamless
tracking, quick alerts, and

214
00:14:17,745 --> 00:14:19,130
efficient issue resolution.

215
00:14:19,630 --> 00:14:23,740
Effective incident management and
alerting, rely on the right tools.

216
00:14:24,500 --> 00:14:31,190
Page of duty and ops chiney are powerful
incident management platforms that help

217
00:14:31,190 --> 00:14:35,870
team handle alert automation workflows
and escalate critical issues to the right

218
00:14:35,870 --> 00:14:38,390
personal, ensuring quick resolution.

219
00:14:38,750 --> 00:14:43,190
Slack, VictorOps and Microsoft
Teams enhanced collaboration

220
00:14:43,190 --> 00:14:46,640
with built-in alerting, allowing
teams to receive notifications,

221
00:14:46,940 --> 00:14:50,960
discuss issues in real time, and
coordinate responses efficiently.

222
00:14:51,305 --> 00:14:56,595
Additionally built in cloud alerting
solutions like AWS CloudWatch Alarms,

223
00:14:56,685 --> 00:15:01,365
Azure Monitor Alerts, and Google
Cloud Operation Alerts provide native

224
00:15:01,365 --> 00:15:06,315
monitoring and automated notifications
within cloud environments, helping

225
00:15:06,315 --> 00:15:10,065
teams detect and address issues
before they escalate together.

226
00:15:10,065 --> 00:15:14,330
These tools enables fast response
times, streamlined communication,

227
00:15:14,775 --> 00:15:16,515
and improved system reliability.

228
00:15:17,015 --> 00:15:21,545
Imagine a scenario where an e-commerce
platform experiences a sudden surge

229
00:15:21,545 --> 00:15:27,215
in traffic during a holiday sale,
but due to a poor monitoring system,

230
00:15:27,455 --> 00:15:31,505
the system fails to detect the high
CPU usage and database overload.

231
00:15:31,655 --> 00:15:37,025
As a result, pages low started loading
slowly, transaction fails, and customer

232
00:15:37,025 --> 00:15:41,765
abandon their cards leading to lost
revenue and customer dissatisfaction.

233
00:15:42,265 --> 00:15:46,225
The issue remains unnoticed for
hours, significantly impacting

234
00:15:46,225 --> 00:15:48,445
the business operations and sales.

235
00:15:49,045 --> 00:15:53,215
After implementing proper monitoring
and alerting the company set up a

236
00:15:53,215 --> 00:15:57,775
real-time performance, tracking automated
alerts and AI driven anomaly detection.

237
00:15:58,255 --> 00:16:02,905
Now when traffic spikes alert, notify
the teams immediately allowing them to

238
00:16:02,935 --> 00:16:07,945
scale resources and optimize database
queries before user experience issues.

239
00:16:08,605 --> 00:16:11,425
As a result, downtime is reduced by 60%.

240
00:16:11,425 --> 00:16:16,315
Response time improved by 40%, and
customer satisfaction scores increases.

241
00:16:16,815 --> 00:16:21,585
This example highlights the critical role
of monitoring and alerting in preventing

242
00:16:21,585 --> 00:16:26,535
failures, ensuring system stability,
and maintaining business success.

243
00:16:27,035 --> 00:16:30,725
To build an effective monitoring and
alerting strategy, it's essential

244
00:16:30,725 --> 00:16:32,675
to follow the best practices.

245
00:16:33,605 --> 00:16:39,035
First, define key performance indicators
that matters most to your system,

246
00:16:39,365 --> 00:16:44,735
such as uptime, response time, error
rates, and re resources utilizations.

247
00:16:45,005 --> 00:16:50,345
These metrics help track system health
and detect potential issues early.

248
00:16:50,690 --> 00:16:54,650
Second, choose the right monitoring
and alerting tool that aligns with

249
00:16:54,650 --> 00:16:59,890
your infrastructure, whether open
source solutions like ERs and Grafana

250
00:16:59,950 --> 00:17:04,600
or commercial platforms like Datadog
and newly finally continuously

251
00:17:04,600 --> 00:17:09,250
irate and improve by analyzing
system behavior, refining alert.

252
00:17:09,275 --> 00:17:12,365
Thresholds and leveraging
automation to enhance efficiency.

253
00:17:12,875 --> 00:17:18,005
A well optimized approach ensures
reliability, minimizes downtime, and

254
00:17:18,005 --> 00:17:20,165
improves overall system performance.

255
00:17:20,665 --> 00:17:24,835
Real-time dashboards provide a
centralized view of system health by

256
00:17:25,495 --> 00:17:31,165
displaying key metrics such as CPU
usage, memory consumption, network

257
00:17:31,165 --> 00:17:33,715
activity, and application response times.

258
00:17:34,080 --> 00:17:38,070
These dashboards offer instant
visibility into performance trends,

259
00:17:38,100 --> 00:17:41,490
helping teams detect and address
issues before they escalate.

260
00:17:41,850 --> 00:17:47,190
For example, a server monitoring dashboard
might track CPU load and disc usage.

261
00:17:47,460 --> 00:17:50,430
While an application performance
dashboard could display

262
00:17:50,430 --> 00:17:52,200
response times and error rates.

263
00:17:52,220 --> 00:17:55,580
Security dashboards can also
provide insights into login

264
00:17:55,580 --> 00:17:57,230
attempt and potential threats.

265
00:17:57,590 --> 00:18:02,180
Real time insights enable proactive
issue resolution by alerting teams

266
00:18:02,180 --> 00:18:07,850
to anonymize anomalies as they occur
instead of reacting to system failures

267
00:18:07,970 --> 00:18:09,710
after they impacted the users.

268
00:18:10,275 --> 00:18:14,505
Teams can identify pattern, predict
potential failures, and take preventive

269
00:18:14,805 --> 00:18:19,455
actions, ensuring stability, reducing
downtime, and improving user experience.

270
00:18:20,055 --> 00:18:24,735
They allow customization to display
the most relevant KPIs for different

271
00:18:24,735 --> 00:18:29,665
teams, such as latency error rates,
throughput for engineering or user.

272
00:18:29,885 --> 00:18:33,575
Engagement metrics
metricses for product teams.

273
00:18:33,635 --> 00:18:38,615
Monitoring dashboards, consolidate
data from multiple sources like logs,

274
00:18:38,765 --> 00:18:44,885
APMs, infra metrics, metricses into a
single view, enabling faster diagnosis,

275
00:18:44,975 --> 00:18:49,145
streamlined communication, and informed
decision making across stack holders.

276
00:18:49,645 --> 00:18:52,100
The image shows a monitoring
dashboard in Azure.

277
00:18:52,775 --> 00:19:00,045
From Azure Monitoring Services this is for
a CH one real retail app AI application.

278
00:19:00,825 --> 00:19:05,415
It presents real time insights
into system performance across

279
00:19:05,565 --> 00:19:12,495
four key areas, usage, reliability,
responsiveness, and browser performance.

280
00:19:12,995 --> 00:19:18,875
Usage displays, unique session and
user currently 6.5 a users showing

281
00:19:18,875 --> 00:19:20,795
trends over the past 24 hours.

282
00:19:21,295 --> 00:19:25,585
You can change this time window and
see it for 12 hours, 48 hours, seven

283
00:19:25,585 --> 00:19:32,035
days, or any specified time window
reliability highlights the field request

284
00:19:32,275 --> 00:19:39,385
with 16.63 K and server exceptions
helping identify system issues.

285
00:19:40,090 --> 00:19:46,210
Responsiveness tracks server response
times, which is 1.2 seconds as an average.

286
00:19:46,270 --> 00:19:48,640
And CP utilization is 15.15.

287
00:19:49,030 --> 00:19:51,400
Ensuring system efficiency.

288
00:19:51,490 --> 00:19:56,290
Browser performance monitor, average
page load times 73 milliseconds

289
00:19:56,290 --> 00:19:58,240
network and 5 37 milliseconds.

290
00:19:58,640 --> 00:20:00,530
Client and browser errors.

291
00:20:01,385 --> 00:20:05,615
This dashboard helps teams quickly
access system health, performance

292
00:20:05,615 --> 00:20:10,325
trends, and potential failures,
enabling proactive troubleshooting.

293
00:20:10,825 --> 00:20:16,585
The future of monitoring and alerting is
evolving with our advanced technologies.

294
00:20:17,065 --> 00:20:21,930
AI powered anomaly detection is
transforming how systems identify issues.

295
00:20:22,735 --> 00:20:26,515
Using machine learning to detect
unusual pattern and reduce false

296
00:20:26,515 --> 00:20:30,985
positives, predictive men, maintenance,
and automated issues as solution,

297
00:20:31,015 --> 00:20:35,725
allow teams to proactively address
potential failures before they occur.

298
00:20:35,995 --> 00:20:38,875
Minimize downtime and
improving reliability.

299
00:20:39,250 --> 00:20:44,260
Enhanced integration across cloud and
on-prem systems ensure seamless monitoring

300
00:20:44,260 --> 00:20:48,670
in hybrid environments, providing a
unified view of system performance.

301
00:20:48,880 --> 00:20:53,050
Additionally, there is an increased
focus on security monitoring with

302
00:20:53,080 --> 00:20:57,880
AI driven threats, detection, and
real-time alert, helping organization

303
00:20:58,030 --> 00:20:59,650
protect against cyber threats.

304
00:20:59,950 --> 00:21:04,210
These advancements are making
monitoring more intelligent,

305
00:21:04,270 --> 00:21:05,890
proactive, and efficient.

306
00:21:06,390 --> 00:21:07,200
Key takeaways.

307
00:21:07,740 --> 00:21:10,740
Effective monitoring and
alerting are essential for

308
00:21:10,740 --> 00:21:12,480
maintaining system stability.

309
00:21:12,780 --> 00:21:17,430
Monitoring provides valuable insights
by continuously tracking performance,

310
00:21:18,060 --> 00:21:23,940
helping teams detect and prevent potential
failures before they actually escalate.

311
00:21:24,645 --> 00:21:29,175
Alerting ensures a quick response
by notifying the right team in real

312
00:21:29,175 --> 00:21:34,245
time, minimizing the impact of issues
and reducing downtime by implementing

313
00:21:34,245 --> 00:21:39,615
best practices such as settling clear
thresholds, using automations and

314
00:21:39,615 --> 00:21:44,775
refining alert rules, organizations can
significantly enhance system reliability.

315
00:21:45,405 --> 00:21:49,785
A well-structured monitoring and
alerting strategy led to better

316
00:21:49,785 --> 00:21:54,015
performance, improved user experience,
and seamless business operations.

317
00:21:54,465 --> 00:21:58,605
As applications, scale and
architecture evolve, monitoring

318
00:21:58,605 --> 00:22:04,395
strategies should be revisited to
ensure continued effectiveness.

319
00:22:05,325 --> 00:22:12,105
Regular audits, feedbacks, loops, and AI
driven insights can improve detection,

320
00:22:12,165 --> 00:22:14,925
accuracy, and reduce false positives.

321
00:22:15,225 --> 00:22:19,515
Example, if a company shifts from
a monolithic to a microservices,

322
00:22:19,545 --> 00:22:23,685
architecture monitoring tools
must evolve to track interservice

323
00:22:23,865 --> 00:22:26,325
communication and dependencies.

324
00:22:26,825 --> 00:22:29,545
Thank you all for your
time and attention today.

325
00:22:29,575 --> 00:22:36,125
I appreciate the opportunity to ensure
to opportunity to share and in share

326
00:22:36,125 --> 00:22:38,525
my insights on monitoring and alerting.

327
00:22:38,825 --> 00:22:41,555
I would love to hear your
questions or thoughts.

328
00:22:41,555 --> 00:22:44,225
Feel free to ask or
share your experiences.

329
00:22:44,565 --> 00:22:47,445
If you would like to connect or
discuss further, you can reach me

330
00:22:47,445 --> 00:22:53,145
out at my email or at LinkedIn,
which is mentioned in this slide.

331
00:22:53,485 --> 00:22:57,085
I look forward to continue
this conversation outside

332
00:22:57,085 --> 00:22:58,435
of this conference as well.

333
00:22:58,935 --> 00:22:59,355
Thank you.

