1
00:00:01,770 --> 00:00:06,030
Hey guys, this is Abha Alia, and
I'm here to talk about how do you

2
00:00:06,030 --> 00:00:10,230
harness microservices architectures
for really highly scalable and

3
00:00:10,800 --> 00:00:13,500
amazingly fault tolerant ML ecosystems.

4
00:00:14,190 --> 00:00:14,820
Let's begin.

5
00:00:16,390 --> 00:00:19,510
I. Architectures have been
really prevalent, right?

6
00:00:19,510 --> 00:00:24,310
And basically it's a traditional approach
which has very tightly coupled code base.

7
00:00:24,310 --> 00:00:27,520
And everything basically is
packaged into a single executable.

8
00:00:27,940 --> 00:00:32,260
Your data processing, your model training,
your service layer, your inference

9
00:00:32,260 --> 00:00:36,400
layer, all that stuff goes into a single
deployable unit, which basically that

10
00:00:36,879 --> 00:00:41,260
at the end of the day, what you're
scaling is that one cohesive unit.

11
00:00:41,540 --> 00:00:42,920
What that also means.

12
00:00:42,940 --> 00:00:49,540
On top of that is that when you run into
a hotspot in any of those layers, you

13
00:00:49,540 --> 00:00:53,500
will have to scale your service out,
which is single, deployable, unit based,

14
00:00:53,500 --> 00:00:58,780
and the ram, the CPU, all those use
cases or the usage of those particular

15
00:00:58,780 --> 00:01:03,640
service, resources is gonna be dependent
on what that one deployable unit is

16
00:01:03,640 --> 00:01:07,300
gonna need because everything's gonna
start into that single deployable unit.

17
00:01:07,710 --> 00:01:13,380
Another big thing is that there is
no very limited, or actually no very

18
00:01:13,380 --> 00:01:17,700
limited fault tolerance isolation
because everything is deployed together.

19
00:01:17,760 --> 00:01:20,280
So if one of those processes set faults.

20
00:01:21,945 --> 00:01:23,325
I think you're toast at that point.

21
00:01:23,325 --> 00:01:27,175
So basically to prevent any
kind of systemwide failures ease

22
00:01:27,175 --> 00:01:32,231
scaling things evolve around
microservices architectures, and it's.

23
00:01:33,145 --> 00:01:34,345
It's really convenient.

24
00:01:34,375 --> 00:01:39,145
It's modern, it's smaller, it's
independently deployable, capsule

25
00:01:39,145 --> 00:01:45,305
size services which you deploy and
operate as really discreet units.

26
00:01:45,785 --> 00:01:50,075
What happens to these discreet
units is that now you can, because

27
00:01:50,075 --> 00:01:55,505
they are discreet and independently
deployed, you are able to scale by

28
00:01:55,505 --> 00:01:57,395
themselves, scale them by themselves.

29
00:01:57,815 --> 00:01:59,675
You are able to isolate the faults.

30
00:02:00,005 --> 00:02:04,485
You are able to isolate any
issues that are going to happen.

31
00:02:04,785 --> 00:02:08,904
In the lifetime of the service
hotspots are also very isolated.

32
00:02:09,274 --> 00:02:12,424
The scaling is really good because
if you're influencing their needs

33
00:02:12,484 --> 00:02:16,924
a lot more CPU and ram, you don't
have to scale the entire service.

34
00:02:17,015 --> 00:02:20,464
You can just scale their influencer
layer and you're good, right?

35
00:02:20,855 --> 00:02:24,965
I personally believe microservice
architecture is a per win-win for

36
00:02:25,025 --> 00:02:28,445
any kind of deployments, especially
for the ML system deployments.

37
00:02:29,184 --> 00:02:31,584
As we talked about, there are,
these are the key benefits and

38
00:02:31,584 --> 00:02:32,454
we have been talking about this.

39
00:02:32,459 --> 00:02:35,760
It gives you dynamic scalability because
everything is independently deployed,

40
00:02:36,090 --> 00:02:41,549
so you scale all those components
by the need of those components.

41
00:02:41,820 --> 00:02:46,530
And what I mean by that
is if one component needs.

42
00:02:46,950 --> 00:02:49,950
X amount of ram and y amount of instances.

43
00:02:50,879 --> 00:02:56,640
Not every component has to get X amount
of ram and y amount of instances.

44
00:02:56,909 --> 00:02:59,459
Now you can dyna scale
each and every one of them.

45
00:03:00,029 --> 00:03:02,309
You get enhanced resilience, right?

46
00:03:02,519 --> 00:03:08,339
No Ssec faulting from one in service is
gonna affect the other service because

47
00:03:08,339 --> 00:03:10,019
they're just independently deployed.

48
00:03:10,365 --> 00:03:11,655
Big one, big win.

49
00:03:12,555 --> 00:03:13,725
Technology flexibility.

50
00:03:13,785 --> 00:03:16,614
This is a big difference which you get.

51
00:03:16,975 --> 00:03:19,704
Let's say you were deploying
everything in Python and suddenly

52
00:03:20,234 --> 00:03:25,724
you want maybe your API layer to go
into Golan instead of Python, just

53
00:03:25,724 --> 00:03:28,154
because Golan is a little faster.

54
00:03:28,314 --> 00:03:31,404
It's easier to parallelize
things in Golang as well.

55
00:03:31,734 --> 00:03:36,924
And API layer is pretty much
very easy to build in Golang.

56
00:03:37,509 --> 00:03:40,929
You wanna get to Golan, but you can't
because if you're deployed in the micro

57
00:03:40,959 --> 00:03:45,909
monolithic services pattern, there's no
way you're gonna move just one day out.

58
00:03:46,419 --> 00:03:49,209
To do that, you'll want to move
to the microservices pattern.

59
00:03:49,269 --> 00:03:55,579
And in that way you just rewrite your
API layer in Golan and deploy those

60
00:03:55,609 --> 00:03:57,169
services and you're good, right?

61
00:03:57,829 --> 00:04:01,189
And that the big win is the
accelerated deployment process.

62
00:04:01,519 --> 00:04:03,469
Now that because you deploy them.

63
00:04:04,114 --> 00:04:09,034
On their own, you, your CICD
processes can decide when each of

64
00:04:09,034 --> 00:04:10,504
those services can get deployed.

65
00:04:10,714 --> 00:04:13,534
One, their schedule could
be completely different.

66
00:04:13,924 --> 00:04:19,604
Second, you can actually have it linked
to something like a GitHub hook, and

67
00:04:19,664 --> 00:04:23,414
they just continuously keep getting
deployed, and you don't have to deploy

68
00:04:23,414 --> 00:04:26,984
your training modules just because
your APIs are getting refreshed or

69
00:04:26,984 --> 00:04:28,604
they're getting faster in the backend.

70
00:04:28,994 --> 00:04:31,544
So it gives you all those
flexibilities as well.

71
00:04:32,654 --> 00:04:36,344
All good with microservices, but there
are some challenges there as well, right?

72
00:04:36,684 --> 00:04:39,144
Data consistency is
big one of them, right?

73
00:04:39,144 --> 00:04:44,934
That now because you have to have all
those different service boundaries and

74
00:04:44,934 --> 00:04:48,804
those services now dependent on the data
from one service and they're dependent,

75
00:04:48,834 --> 00:04:51,024
interdependent on each other, what that.

76
00:04:51,519 --> 00:04:52,119
May.

77
00:04:52,209 --> 00:04:56,829
What that leads to is that your, you
will have data consistency challenges,

78
00:04:56,829 --> 00:05:00,939
and you will have to make sure that
your data is consistent across all those

79
00:05:00,939 --> 00:05:06,279
services and the services instances of
those processes that you have deployed.

80
00:05:06,829 --> 00:05:09,049
There is definitely a
communication overhead, right?

81
00:05:09,049 --> 00:05:14,089
Because one, you're not a monolithic
service anymore, so it's not an inter.

82
00:05:14,904 --> 00:05:19,704
Within InProcess communication, now
you're talking about T-C-P-G-R-P-C based

83
00:05:20,154 --> 00:05:24,084
communication, which will have some
amount of network overhead as well, right?

84
00:05:24,594 --> 00:05:29,934
It may not, because you might be in
the same box, but it'll still have

85
00:05:30,054 --> 00:05:35,604
an interprocess layer, which will
still have a little bit more effect

86
00:05:35,784 --> 00:05:37,554
on the communication throughput.

87
00:05:38,074 --> 00:05:40,704
So yeah it does change some of that stuff.

88
00:05:41,364 --> 00:05:42,324
System complexities.

89
00:05:43,179 --> 00:05:43,989
It gets.

90
00:05:44,889 --> 00:05:45,429
Higher.

91
00:05:45,479 --> 00:05:49,499
Definitely it's a lot higher because now
you have so many more components to look

92
00:05:49,499 --> 00:05:53,829
at, so many more components to monitor
if god forbid, you run into issues, you

93
00:05:53,829 --> 00:05:58,839
have to debug like six different services
in a singular time series fashion so that

94
00:05:58,839 --> 00:06:02,199
you can understand which service failed
and what pattern led to that failure.

95
00:06:02,714 --> 00:06:04,634
Diplomat architectures change a lot.

96
00:06:04,694 --> 00:06:08,084
You have to now make sure that they,
you're, they're scaling independently.

97
00:06:08,084 --> 00:06:10,784
They have their resources
tuned independently.

98
00:06:10,784 --> 00:06:12,224
All that stuff changes as well.

99
00:06:12,304 --> 00:06:17,794
So I agree that there are amazing benefits
to the microservices architecture patterns

100
00:06:18,664 --> 00:06:24,034
as long as you make sure that all these
challenges are taken care of as well.

101
00:06:24,134 --> 00:06:29,024
So it's not a free for buffet until,
unless you address some of these things.

102
00:06:30,239 --> 00:06:33,389
From a communication perspective, there
are like four different things, right?

103
00:06:33,419 --> 00:06:34,169
Which comes to mind.

104
00:06:34,199 --> 00:06:38,929
One is you can almost always
say that my services are just

105
00:06:38,929 --> 00:06:39,769
gonna talk to each other.

106
00:06:39,769 --> 00:06:44,289
If via rest it's an API layer and
I'm gonna just use REST or GRPC and

107
00:06:44,289 --> 00:06:45,549
that's how they're gonna communicate.

108
00:06:45,639 --> 00:06:46,329
Full stop, right?

109
00:06:46,389 --> 00:06:47,769
You don't have to worry about it too much.

110
00:06:47,769 --> 00:06:49,479
It gives you a strong consistency.

111
00:06:49,479 --> 00:06:54,339
Guarantees, because of the nature of being
asynchronous, it gets a little easier.

112
00:06:55,144 --> 00:06:59,224
You can establish a HTTP two
connection 2.0 connection one once,

113
00:06:59,224 --> 00:07:03,124
and then you reuse that particular
connection for all those multiple

114
00:07:03,154 --> 00:07:04,324
requests that you're gonna send.

115
00:07:04,624 --> 00:07:07,834
It gets much easier because now
you don't have to construct and

116
00:07:07,834 --> 00:07:11,824
deconstruct TTP connection every
single request that you want to.

117
00:07:12,334 --> 00:07:15,904
So win-win, but you just have to
make sure that you're doing that.

118
00:07:16,394 --> 00:07:20,654
As A-G-R-P-C layer, that is one
of the things that you get with

119
00:07:20,654 --> 00:07:22,394
G rrp C sgtp two connection.

120
00:07:23,074 --> 00:07:26,704
Another thing which has been
happening in the recent times

121
00:07:26,704 --> 00:07:27,664
have been immense streaming.

122
00:07:27,664 --> 00:07:32,284
People want to reuse those continuous
data pipelines that they have their,

123
00:07:32,404 --> 00:07:36,124
the constant barrage of data that's
coming in, and they want to utilize

124
00:07:36,124 --> 00:07:38,374
that high volume data as model inputs.

125
00:07:38,854 --> 00:07:42,539
In, in those use cases, those
event streaming patterns.

126
00:07:42,924 --> 00:07:49,204
Where this data, which is incoming,
never stops, never ceases to exist.

127
00:07:49,594 --> 00:07:52,894
You want to look at the event
streaming patterns to a degree.

128
00:07:53,294 --> 00:07:57,344
But yeah, again it's up to your use case
specifically that is event streaming

129
00:07:57,344 --> 00:07:59,054
the right pattern for you or not.

130
00:07:59,594 --> 00:08:00,524
Another one is.

131
00:08:01,034 --> 00:08:05,344
Where all your instances are kind
of stateless, and they use a single

132
00:08:05,344 --> 00:08:06,694
shared data store in the background.

133
00:08:06,724 --> 00:08:10,544
So basically all they do is they
talk to that single data store in via

134
00:08:10,544 --> 00:08:15,014
transactions, and everybody just gets
updated via those shared data stores.

135
00:08:15,494 --> 00:08:16,904
It's a lot heavier.

136
00:08:16,994 --> 00:08:22,185
It's a lot harder to do that shared
data store model because yes, you

137
00:08:22,185 --> 00:08:27,644
are relying on that one service,
which has all those data sets.

138
00:08:28,095 --> 00:08:30,315
So be a little careful when you do that.

139
00:08:30,445 --> 00:08:33,685
I generally recommend even streaming
patterns for all these things that,

140
00:08:33,805 --> 00:08:36,965
yeah, event happened, X X happened.

141
00:08:37,355 --> 00:08:38,495
This is the current state.

142
00:08:38,675 --> 00:08:39,785
Please update it everywhere.

143
00:08:39,785 --> 00:08:41,705
It could be a data store,
it could be anything.

144
00:08:42,155 --> 00:08:46,205
But I prefer those patterns because
again, that's just my preference,

145
00:08:46,415 --> 00:08:49,240
but you have to look at your use
case if that's useful or not.

146
00:08:50,240 --> 00:08:54,740
And message queues have been, they
have been there for years now, right?

147
00:08:54,740 --> 00:08:55,910
At decades at this point.

148
00:08:56,340 --> 00:09:01,800
It basically eases the decoupling
of services from each other.

149
00:09:02,250 --> 00:09:06,120
All you do is you talk to the message
queues and the message queues.

150
00:09:06,120 --> 00:09:07,140
Somebody's listening.

151
00:09:07,200 --> 00:09:10,950
Somebody's sending basically allows
you to do asynchronous processing

152
00:09:11,250 --> 00:09:12,690
while independently scaling.

153
00:09:12,900 --> 00:09:15,450
So you get the best of both worlds.

154
00:09:16,000 --> 00:09:16,900
But yeah.

155
00:09:17,245 --> 00:09:20,005
Again, like I said, for all of
them, depends on your use case.

156
00:09:20,005 --> 00:09:22,285
Do you want to use which
one do you want to use?

157
00:09:24,235 --> 00:09:30,815
ML specific deployment approaches are and
these are not something which are generic,

158
00:09:31,205 --> 00:09:34,595
but I have seen these used really heavily.

159
00:09:34,645 --> 00:09:37,225
Where I, in the ecosystems,
which I've seen, right.

160
00:09:37,645 --> 00:09:40,345
Containers have been really good.

161
00:09:41,095 --> 00:09:47,295
For formalizing the deployment
model, it's that unit which gets

162
00:09:47,295 --> 00:09:49,185
deployed anywhere and everywhere.

163
00:09:49,455 --> 00:09:52,140
It allows you to orchestrate
that really well and.

164
00:09:52,995 --> 00:09:57,675
Kubernetes in the recent times have
done it really beautifully, where

165
00:09:57,675 --> 00:10:02,415
you don't have to worry about how
things are gonna happen, the network

166
00:10:02,415 --> 00:10:07,295
apologies, the load balancers and how
they're gonna interact the domains,

167
00:10:07,295 --> 00:10:09,575
the in ingress, all that stuff.

168
00:10:09,635 --> 00:10:13,115
Kubernetes takes care of really
beautifully and again, in a really

169
00:10:13,955 --> 00:10:15,875
well defined, codified manner.

170
00:10:16,075 --> 00:10:18,505
More or less YAML files
for almost all of them.

171
00:10:19,015 --> 00:10:20,035
But again, it.

172
00:10:20,390 --> 00:10:22,610
It's something which is amazing.

173
00:10:23,420 --> 00:10:27,410
All that needs to happen is that you
need to understand that with all those

174
00:10:27,410 --> 00:10:32,330
great things, there might be some
overhead in the operational paradigm of

175
00:10:32,360 --> 00:10:34,610
the operation paradigm for these things.

176
00:10:34,650 --> 00:10:36,960
Kubernetes as amazing as it is.

177
00:10:37,455 --> 00:10:39,675
Operationally it's a
little bit challenging.

178
00:10:39,825 --> 00:10:43,825
So make sure that you have some
experts at hand who can deal with co

179
00:10:43,885 --> 00:10:46,435
kubernetes issues, network resolutions.

180
00:10:46,465 --> 00:10:50,155
The DNS, it's almost always
DNSI think everybody agrees

181
00:10:50,455 --> 00:10:51,415
whenever there's an issue.

182
00:10:51,475 --> 00:10:54,085
It's almost always DNS otherwise, right?

183
00:10:54,185 --> 00:10:57,125
It's, it allows you to intelligently
scale all those things.

184
00:10:57,125 --> 00:11:01,445
It allows you to make those
operations in a fault tolerant way.

185
00:11:01,865 --> 00:11:07,205
It's amazing at scheduling
resources, and it's amazing for

186
00:11:07,205 --> 00:11:08,975
a AB testing as well, right?

187
00:11:09,065 --> 00:11:10,745
Bluegreen deployments, AB testing.

188
00:11:11,100 --> 00:11:14,070
Yeah, Kubernetes can do it pretty easily.

189
00:11:14,500 --> 00:11:17,400
All you need to know is the way how
you configure those and you're done.

190
00:11:17,880 --> 00:11:19,650
Another big one is the
serverless functions.

191
00:11:20,200 --> 00:11:21,790
AWS Lambda comes to mind, right?

192
00:11:21,820 --> 00:11:23,560
Google Cloud functions is another one.

193
00:11:23,620 --> 00:11:29,030
Again, they're more or less the same but
it eliminates all this infrastructure

194
00:11:29,030 --> 00:11:30,470
management overhead for you, right?

195
00:11:30,830 --> 00:11:33,020
Kubernetes, one way or
the other, you are either.

196
00:11:33,390 --> 00:11:36,000
Allocating resources, you're making
sure the machines have enough

197
00:11:36,000 --> 00:11:40,470
capacity, you're still doing some node
pooling and all those related things.

198
00:11:41,160 --> 00:11:43,590
Serverless just gets rid
of all that complexity.

199
00:11:43,800 --> 00:11:45,810
All you do is deploy the
containers in that serverless

200
00:11:45,810 --> 00:11:47,130
function manner, and you get.

201
00:11:47,525 --> 00:11:54,745
Then there are specific, very specialized
ML platforms kerv, formerly known as

202
00:11:54,745 --> 00:11:56,455
KF Serving, if you have heard of that.

203
00:11:56,695 --> 00:11:57,925
That's a really good one.

204
00:11:58,225 --> 00:11:59,425
SageMaker is another one.

205
00:11:59,545 --> 00:12:02,635
The, these are framework optimized
for model serving, right?

206
00:12:03,035 --> 00:12:05,315
And for making sure
that they're performant.

207
00:12:05,885 --> 00:12:10,535
So if you are using any of
these, I think you are good.

208
00:12:10,935 --> 00:12:12,645
If you are looking at any of these.

209
00:12:13,470 --> 00:12:16,290
Look at, maybe start with
the serverless functions.

210
00:12:16,290 --> 00:12:18,780
Those are the easiest to approach.

211
00:12:19,260 --> 00:12:22,410
Then look at the specialized
platforms and the container

212
00:12:22,410 --> 00:12:23,550
orchestration if you have to.

213
00:12:25,425 --> 00:12:25,725
One.

214
00:12:25,725 --> 00:12:29,495
Another big thing that I I am a
big proponent of is observability

215
00:12:29,495 --> 00:12:30,275
and monitoring, right?

216
00:12:30,725 --> 00:12:35,535
Once you deploy a service it was easy
when, in the monolithic fashion where

217
00:12:35,535 --> 00:12:38,715
you just deploy that one process,
everything is in, contained in there.

218
00:12:38,715 --> 00:12:41,385
So you monitor that one process
and you're golden, right?

219
00:12:41,925 --> 00:12:42,315
With.

220
00:12:43,020 --> 00:12:44,160
Microservices sprawl.

221
00:12:44,190 --> 00:12:46,650
What happens is now you have
to monitor so many services.

222
00:12:46,650 --> 00:12:49,320
You have to make sure that logs are
available from all the services.

223
00:12:49,560 --> 00:12:53,760
The resource utilization is pretty well
handled so that you can find the hotspots.

224
00:12:54,150 --> 00:12:56,050
So all that stuff keeps adding up.

225
00:12:56,170 --> 00:13:00,940
So operationally there are a little
bit more involved as compared

226
00:13:00,940 --> 00:13:02,290
to the monolithic architecture.

227
00:13:02,830 --> 00:13:03,570
But it's.

228
00:13:04,325 --> 00:13:07,865
The pros that you get from it,
I think it over outweighs the

229
00:13:07,895 --> 00:13:09,485
monolithic way of deploying stuff.

230
00:13:10,085 --> 00:13:13,625
So from that perspective, the model
performance and metrics, right?

231
00:13:13,655 --> 00:13:17,825
You want all that stuff in some
per store like Prometheus, right?

232
00:13:17,825 --> 00:13:21,965
So you can graph it out in
something like Grafana or Giana, or.

233
00:13:22,985 --> 00:13:24,935
Anywhere else which you prefer, right?

234
00:13:25,355 --> 00:13:27,065
Distributor tracing is another one, right?

235
00:13:27,575 --> 00:13:32,425
And this probably comes a little bit
after logging and making sure that

236
00:13:32,425 --> 00:13:34,105
you have the resource utilization.

237
00:13:34,105 --> 00:13:37,255
But once you have distributed
tracing, you'll be able to trace

238
00:13:37,255 --> 00:13:42,055
a specific event going through
your microservices orchestration.

239
00:13:42,695 --> 00:13:46,055
It'll have a specific trace id and you'll
be able to pinpoint some performance

240
00:13:46,055 --> 00:13:47,915
bottlenecks if you need to, right?

241
00:13:47,915 --> 00:13:49,025
And it's really good at that.

242
00:13:49,445 --> 00:13:54,785
There are frameworks like Yeager
and Zipkin, which help you do that.

243
00:13:55,295 --> 00:13:56,345
Please take a look at them.

244
00:13:56,405 --> 00:14:00,445
If you're looking at distributor
tracing it's pretty well.

245
00:14:02,755 --> 00:14:08,825
Pretty well organized organized
library, and it solves a really

246
00:14:09,065 --> 00:14:13,325
decent problem, which a lot of systems
will face once they move into that

247
00:14:13,355 --> 00:14:15,035
microservices deployment pattern.

248
00:14:15,715 --> 00:14:20,085
Like I said, resource utilization and
centralized logging are cornerstones, you

249
00:14:20,085 --> 00:14:24,525
will want them, you will need them in the
long run to make sure that you are able

250
00:14:24,525 --> 00:14:27,015
to understand your resource utilization.

251
00:14:27,355 --> 00:14:31,285
Where hotspots are, if one service is
causing too much ruckus, if there is

252
00:14:31,285 --> 00:14:33,085
another service which needs to be handled.

253
00:14:33,545 --> 00:14:39,005
Centralized logging is a must because
now you have 6, 7, 10, 15 different

254
00:14:39,005 --> 00:14:40,865
services which won't be running and.

255
00:14:41,615 --> 00:14:46,475
If there is a fault in, and you're
tracing out the fault in these services,

256
00:14:46,475 --> 00:14:51,725
you'll want to have a time series styled
logs, which can tell you what happened,

257
00:14:51,725 --> 00:14:57,245
and then with service and what was the
prior activities happening, or adjacent

258
00:14:57,245 --> 00:15:00,875
activities happening at the same time
in other services so that you can figure

259
00:15:00,875 --> 00:15:02,585
out what's going on and what went wrong.

260
00:15:03,870 --> 00:15:07,050
But yeah, up to each and
every one of the teams.

261
00:15:07,290 --> 00:15:08,160
How do you wanna handle that?

262
00:15:08,820 --> 00:15:13,600
The emerging trends, which I have seen
recently is, service meshes, right?

263
00:15:13,810 --> 00:15:17,290
SDO is pretty great at creating
that service mesh with zero trust

264
00:15:17,670 --> 00:15:21,030
zero trust, security, and fault
tolerance, while requiring actually

265
00:15:21,030 --> 00:15:22,380
minimal code implementation.

266
00:15:22,380 --> 00:15:28,140
They deploy themselves as sidecars within
Kubernetes and have used SST O I've not

267
00:15:28,140 --> 00:15:33,330
used linker D yet, but maybe it's used
somewhere internally in East U as well.

268
00:15:33,340 --> 00:15:36,040
I don't know, and I don't
remember honestly, but.

269
00:15:36,335 --> 00:15:38,585
The Istio framework is
pretty good at that.

270
00:15:39,215 --> 00:15:43,355
The, another thing which has started
coming up recently is AI driven

271
00:15:43,355 --> 00:15:48,035
orchestration with the whole the
new frameworks that have been coming

272
00:15:48,035 --> 00:15:54,845
up, the Google's a to a, the tropics
service patterns, all those things are.

273
00:15:56,195 --> 00:16:03,005
Are gaining steam now and once these
agent tick systems actually start doing

274
00:16:03,005 --> 00:16:07,085
these orchestrations really well, I think
this is gonna pick up really heavily

275
00:16:07,085 --> 00:16:12,305
because it's gonna be able to understand
what it needs to do and take the right

276
00:16:12,305 --> 00:16:16,835
actions eventually with, because of those
details, which it has available, right?

277
00:16:17,835 --> 00:16:21,165
With that said, I'm just gonna
move on to the takeaways for

278
00:16:21,165 --> 00:16:22,335
a real world implementation.

279
00:16:22,335 --> 00:16:25,995
If you're actually interested in
doing a microservices based deployment

280
00:16:26,545 --> 00:16:28,225
please take a look at these.

281
00:16:28,225 --> 00:16:32,045
And this is the TLDR kind of a
slide deck, which I wanna present.

282
00:16:32,525 --> 00:16:35,135
The first and the foremost step
is gonna be identification.

283
00:16:35,435 --> 00:16:38,885
You'll wanna make sure that you identify
the right service to start with.

284
00:16:39,575 --> 00:16:44,345
One thumb, rule of thumb that I have
is pick a service, which will be the

285
00:16:44,345 --> 00:16:48,965
least amount of effort for you, but
will give you the most amount of bang

286
00:16:48,965 --> 00:16:50,915
for your buck, kind of thing, right?

287
00:16:50,915 --> 00:16:56,115
So if there is a service, which
can is the most painful, but it's

288
00:16:56,115 --> 00:16:59,475
gonna take a lot more steps to
decompose that service and do all

289
00:16:59,475 --> 00:17:01,185
that stuff, I would not start there.

290
00:17:01,650 --> 00:17:05,370
I would start with the service,
which is probably a little easier on

291
00:17:05,400 --> 00:17:09,540
decomposition, but it's gonna give
you almost the same amount of result.

292
00:17:09,960 --> 00:17:14,280
So you're not doing really critical
service right out of the gate, but

293
00:17:14,280 --> 00:17:18,610
you're still doing something which is
80% there and it's gonna give, take

294
00:17:18,610 --> 00:17:23,500
20% of the HE effort to get the 80% of
the gain probably start there, right?

295
00:17:24,010 --> 00:17:26,290
Service decomposition,
this is huge, right?

296
00:17:26,290 --> 00:17:28,795
And this is something which
you will have to think about.

297
00:17:29,215 --> 00:17:34,255
When you are partitioning that whole
system, you would want to partition

298
00:17:34,255 --> 00:17:40,795
it with some things in mind where
you are probably just decomposing it

299
00:17:40,975 --> 00:17:44,965
enough that it doesn't get overdone.

300
00:17:45,805 --> 00:17:48,970
I. What I mean by that is do not
decompose a single process into

301
00:17:48,970 --> 00:17:53,530
15 services because you want to
maybe segregate them out into 15.

302
00:17:54,250 --> 00:17:57,910
Start with maybe four or
five decomposition layers

303
00:17:58,420 --> 00:18:00,880
and see if you need more.

304
00:18:01,025 --> 00:18:04,660
I. Processes out of them and
extractions out of them, and

305
00:18:04,660 --> 00:18:05,830
then move forward with that.

306
00:18:06,490 --> 00:18:09,460
You don't want to overdo your
microservices architecture

307
00:18:09,460 --> 00:18:10,540
because that's not gonna help.

308
00:18:10,540 --> 00:18:14,080
It's just gonna make you skip
from one service to another.

309
00:18:14,410 --> 00:18:18,460
You just keep moving and bouncing around
when you're looking at the logs and when

310
00:18:18,460 --> 00:18:20,030
you're debugging any of those things.

311
00:18:20,540 --> 00:18:25,490
But yeah, so think carefully, really
carefully about how and where you

312
00:18:25,490 --> 00:18:28,940
de decide the boundary and what your
decomposition is gonna look like.

313
00:18:30,005 --> 00:18:33,025
Another big one, if you have
to look at the orchestration,

314
00:18:33,115 --> 00:18:37,375
orchestrated deployment models
nowadays Kubernetes is awesome, right?

315
00:18:37,375 --> 00:18:39,955
Like I said, but start
with serverless maybe.

316
00:18:40,165 --> 00:18:44,445
And if you are a fan of talker like
me my home lab runs purely on Docker.

317
00:18:44,445 --> 00:18:50,485
There's no Kubernetes in my home lab, but
I use Docker and it's, it has some amount

318
00:18:50,485 --> 00:18:53,455
of resource allocation, but there's.

319
00:18:54,220 --> 00:18:56,950
I don't think there's enough
auto-scaling in Docker self.

320
00:18:57,820 --> 00:18:58,540
Self-standing.

321
00:18:59,050 --> 00:19:00,940
With Docker Swarm, you
get some of these things.

322
00:19:01,030 --> 00:19:04,850
Yes, the capabilities are there
but with Plain Docker, which is on

323
00:19:04,850 --> 00:19:06,680
the same host, it's not that great.

324
00:19:07,280 --> 00:19:08,330
Measure your results.

325
00:19:08,735 --> 00:19:10,085
That's another big one, right?

326
00:19:10,175 --> 00:19:14,375
Make sure once you decompose all
your services, you are measuring some

327
00:19:14,375 --> 00:19:21,875
of them to understand that have you
over decomposed or is it good enough?

328
00:19:21,935 --> 00:19:25,835
Or there are still some hot spots
that you can change your patterns.

329
00:19:26,555 --> 00:19:29,970
From there, you will be able,
and all those results are gonna

330
00:19:29,970 --> 00:19:31,470
come from your observability.

331
00:19:32,160 --> 00:19:35,240
These if I have to pick and choose.

332
00:19:36,365 --> 00:19:41,705
The most critical ones are these, I'm
gonna say identify service decomposition

333
00:19:41,735 --> 00:19:43,265
and observability are my pick.

334
00:19:43,625 --> 00:19:47,825
For the three biggest right,
you need the observability.

335
00:19:47,825 --> 00:19:52,055
You need to know how to decompose the
service and have a pretty set boundary

336
00:19:52,085 --> 00:19:55,935
and a pretty set signatures to talk
to them, talk between each other.

337
00:19:56,455 --> 00:19:59,545
Infrastructure modernization can
probably wait a little right while

338
00:19:59,545 --> 00:20:01,195
you figure out all these three things.

339
00:20:01,675 --> 00:20:05,095
With Kubernetes, you will be able
to do observability improvements

340
00:20:05,095 --> 00:20:06,495
as well really quickly.

341
00:20:07,110 --> 00:20:10,770
But you will, you'll prob if you have
never used Kubernetes before, you

342
00:20:10,770 --> 00:20:14,980
can only be using learning Kubernetes
before you do all that stuff.

343
00:20:15,370 --> 00:20:16,000
So

344
00:20:18,100 --> 00:20:20,170
if you already are using Kubernetes.

345
00:20:20,800 --> 00:20:21,790
You're good, right?

346
00:20:22,090 --> 00:20:23,920
Get the Kubernetes going first.

347
00:20:24,310 --> 00:20:29,470
Observability is almost free in
Kubernetes to a degree, right?

348
00:20:29,470 --> 00:20:32,110
With Prometheus and labels
and things like that.

349
00:20:32,690 --> 00:20:33,650
Continuous evolution.

350
00:20:33,650 --> 00:20:34,820
This is a huge one, right?

351
00:20:34,880 --> 00:20:38,070
Again, optional thing and can
probably wait at the back of

352
00:20:38,070 --> 00:20:40,800
the line, but you'll wanna think
about it at some point of time.

353
00:20:40,800 --> 00:20:42,450
You want good?

354
00:20:42,770 --> 00:20:47,480
Established CICD patterns and pipelines,
which auto deploy some of these things.

355
00:20:47,780 --> 00:20:52,250
Once you have the first five of in
the play, you will want continuous

356
00:20:52,250 --> 00:20:56,600
evolution to be part of your play as
well, so that your systems are robust,

357
00:20:56,810 --> 00:20:59,480
fast, and almost always current.

358
00:20:59,690 --> 00:21:01,910
Instead of, Hey, which
version are we running?

359
00:21:01,970 --> 00:21:02,480
Let's see.

360
00:21:02,480 --> 00:21:04,010
And if we can deploy the latest versions.

361
00:21:04,460 --> 00:21:05,810
That's probably my takeaways.

362
00:21:06,500 --> 00:21:07,070
And with that.

363
00:21:07,575 --> 00:21:08,505
Thank you for your time.

364
00:21:08,925 --> 00:21:12,895
I think I hope you learned something
from this and if you have any

365
00:21:12,895 --> 00:21:14,575
questions, feel free to ping me.

366
00:21:14,575 --> 00:21:15,865
Feel free to reach out to me.

367
00:21:16,345 --> 00:21:16,885
Thank you again.

