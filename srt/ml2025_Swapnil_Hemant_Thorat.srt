1
00:00:01,830 --> 00:00:02,490
Hello everyone.

2
00:00:03,220 --> 00:00:07,630
My name is Swap Neil, and the
topic of today's discussion is

3
00:00:07,630 --> 00:00:11,340
going to be to cover one of the
critical use cases in conversational

4
00:00:11,340 --> 00:00:14,384
ai which is AI summarization.

5
00:00:15,749 --> 00:00:20,430
Generative AI is the process which
ingests large amount of data.

6
00:00:21,259 --> 00:00:26,179
Mostly for the scope of this discussion,
we are going to cover actual data.

7
00:00:27,199 --> 00:00:33,019
And AI summarization is a technique
used to generate some insights

8
00:00:33,109 --> 00:00:40,719
from large amount of text data to
summarize certain topics that are

9
00:00:40,719 --> 00:00:42,969
covered as part of any communication.

10
00:00:43,730 --> 00:00:49,099
The textual data can be of variety
of formats and a variety of

11
00:00:49,125 --> 00:00:51,194
applications generate textual data.

12
00:00:52,004 --> 00:00:53,595
But for the scope of this.

13
00:00:53,984 --> 00:00:54,644
Discussion.

14
00:00:55,195 --> 00:01:02,425
We will deep dive into utilization of
generative AI for business use cases.

15
00:01:03,295 --> 00:01:08,695
So when we talk about business
communications any communication that the

16
00:01:08,695 --> 00:01:15,475
business handles is between the consumers
of the business and then let's say the

17
00:01:15,475 --> 00:01:20,545
sales, marketing or customer service
departments of that business in addition.

18
00:01:21,475 --> 00:01:23,245
For the business to run smoothly.

19
00:01:24,355 --> 00:01:29,365
The business representatives and
employees would also be interacting

20
00:01:29,365 --> 00:01:34,525
with their coworkers for variety
of different business processes.

21
00:01:35,185 --> 00:01:42,055
So we can think of it as an internal
conversation between the business as

22
00:01:42,055 --> 00:01:47,065
well as an external conversation that
the business has with its customers.

23
00:01:48,790 --> 00:01:54,640
So we can think of customer trying to
reach customer service representative

24
00:01:55,030 --> 00:02:01,450
for a business using a chat bot that is
offered on their website, or they write an

25
00:02:01,450 --> 00:02:03,550
email to the customer service department.

26
00:02:04,240 --> 00:02:11,200
Or sometimes there might be a
shopping assistant that is there on

27
00:02:11,200 --> 00:02:14,380
the website and the person might be
interacting with the shopping assistant.

28
00:02:14,904 --> 00:02:17,875
And then asking for
product recommendations.

29
00:02:18,024 --> 00:02:21,355
And eventually when they're ready
to make a payment, they might have

30
00:02:21,355 --> 00:02:25,765
a question and they might reach
out to an expert to seek opinion.

31
00:02:26,035 --> 00:02:30,115
So they might write an email
or they might continue chatting

32
00:02:30,844 --> 00:02:32,195
with a customer service agent.

33
00:02:32,195 --> 00:02:35,915
So a variety of different
business use cases.

34
00:02:36,464 --> 00:02:38,874
Generate business conversations.

35
00:02:39,414 --> 00:02:41,504
And the data is mostly text based.

36
00:02:42,329 --> 00:02:47,389
So for the scope of this presentation,
we will cover some of the architectural

37
00:02:47,389 --> 00:02:52,999
challenges in developing AI
systems for summarizing message

38
00:02:54,109 --> 00:02:58,549
and email channel content across
different business communications.

39
00:03:00,049 --> 00:03:05,989
So to get started, we'll explore
some of the critical hurdles in

40
00:03:05,989 --> 00:03:09,349
building an AI summarization system.

41
00:03:10,654 --> 00:03:18,094
Some of those hurdles I've listed here
are model hallucination, inherent biases,

42
00:03:18,814 --> 00:03:24,484
data distribution shifts, information
preservation, and then contextual

43
00:03:25,084 --> 00:03:27,304
understanding and contextual awareness.

44
00:03:28,294 --> 00:03:33,664
So we will present certain
architectural approaches and

45
00:03:34,024 --> 00:03:36,369
methodological frameworks that you can.

46
00:03:37,369 --> 00:03:40,249
Adopt to address these
business challenges.

47
00:03:41,189 --> 00:03:46,769
So the focus would be on developing
robust AI summarization system that can

48
00:03:46,769 --> 00:03:52,139
operate for a single thread communication,
multi-threaded communication between

49
00:03:52,139 --> 00:03:58,094
multiple people or even cover
different departments of a business.

50
00:03:59,094 --> 00:04:04,284
Let's look at how the digital
communication have evolved for

51
00:04:04,284 --> 00:04:08,724
business interactions and what
areas they affect for a business.

52
00:04:09,534 --> 00:04:17,379
So for a typical day a customer service
agent who is interacting with business

53
00:04:18,539 --> 00:04:21,899
customers might be interacting on.

54
00:04:22,544 --> 00:04:28,544
Social channels, they might be interacting
with customers for email or they might

55
00:04:28,544 --> 00:04:31,244
be having a live chat with the customers.

56
00:04:31,694 --> 00:04:37,004
So on an average they spend about
five and a half hours out of a eight

57
00:04:37,004 --> 00:04:40,494
hour workday on active communication.

58
00:04:40,944 --> 00:04:45,624
So it is a significant portion of
the day at a contact center for a

59
00:04:45,624 --> 00:04:47,754
customer service department spending.

60
00:04:48,694 --> 00:04:53,444
This much amount of time managing digital
communications drafting documents,

61
00:04:53,624 --> 00:04:59,414
generating invoices, exchanging
emails with the customer, sometimes

62
00:04:59,834 --> 00:05:05,624
escalating things to their coworkers
or business partners, and then doing

63
00:05:05,624 --> 00:05:10,484
a wrap up of their interaction with
the customer to give them a summary.

64
00:05:10,904 --> 00:05:13,079
So a variety of different use cases.

65
00:05:14,009 --> 00:05:19,109
Can be solved with AI summarization
and introduction of instant

66
00:05:19,109 --> 00:05:26,189
messaging through Facebook Messenger,
WhatsApp, iMessages, et cetera.

67
00:05:26,639 --> 00:05:32,969
Just increases the kind of applications
that are generating text for businesses.

68
00:05:35,279 --> 00:05:40,664
Why it is important for
mediums size businesses.

69
00:05:41,324 --> 00:05:47,144
To focus on digital communication
channels is because it is crucial not

70
00:05:47,144 --> 00:05:53,504
only to have a good customer service
interaction for loyalty purposes, but

71
00:05:53,504 --> 00:05:57,284
also making sure the customer needs
are resolved at the end of the day.

72
00:05:58,104 --> 00:06:06,294
As well as having the right tools
at hand definitely leverages certain

73
00:06:06,294 --> 00:06:07,524
improvements in the business.

74
00:06:08,064 --> 00:06:09,534
That can be driven by ai.

75
00:06:10,254 --> 00:06:15,084
If AI summarization is introduced
as part of the business, the use

76
00:06:15,084 --> 00:06:20,064
case become even more complex when
we talk about multi-threaded emails.

77
00:06:20,544 --> 00:06:25,554
So imagine you reaching out to a customer
service representative regarding your

78
00:06:25,644 --> 00:06:33,829
concern, exchanging emails with them,
attaching proofs or your concerns, and

79
00:06:33,829 --> 00:06:35,909
then having transferred over to another.

80
00:06:36,504 --> 00:06:40,404
Customer service represe, and then
having them to go through all of that

81
00:06:40,464 --> 00:06:46,784
over again and then having you to repeat
all the information it's an frustrating

82
00:06:46,934 --> 00:06:53,564
customer experience, and this can easily
be solved by utilizing AI summarization

83
00:06:53,564 --> 00:06:58,934
for emails, especially multi-threaded
emails where multiple people are involved.

84
00:06:59,414 --> 00:07:03,104
There's a long trail of emails
and then some key information

85
00:07:03,104 --> 00:07:04,814
is being exchanged in the email.

86
00:07:05,684 --> 00:07:10,214
Customers are looking for
a speedy resolution without

87
00:07:10,214 --> 00:07:11,474
having to repeat themselves.

88
00:07:12,474 --> 00:07:18,234
So what's the impact of the AI
assisted Communication management

89
00:07:18,234 --> 00:07:20,854
systems in the businesses today?

90
00:07:21,394 --> 00:07:27,524
So it has been proven that businesses
have reduced the time spent on routine

91
00:07:27,524 --> 00:07:29,114
communication tasks significantly.

92
00:07:29,715 --> 00:07:35,085
Which allows more focused time for
the business representatives to

93
00:07:35,174 --> 00:07:40,034
attend other strategic initiatives
for the business and run the business

94
00:07:40,034 --> 00:07:42,585
for essentially driving it forward.

95
00:07:43,335 --> 00:07:47,564
Whereas before more time would
be spent on active communication.

96
00:07:48,314 --> 00:07:52,574
So this can be even leveraged
further with AI summarization.

97
00:07:53,994 --> 00:07:57,294
The key challenge here is maintaining
the right balance between.

98
00:07:57,744 --> 00:08:02,814
So summarization efficiency and
information retention so that

99
00:08:03,534 --> 00:08:04,884
the context gets carried from.

100
00:08:05,884 --> 00:08:10,234
Now let's take a look at how we
can achieve and highly efficient

101
00:08:10,654 --> 00:08:11,914
AI summarization system.

102
00:08:12,724 --> 00:08:17,494
So I would like to break it down into
three major layers for data processing.

103
00:08:18,514 --> 00:08:22,954
Firstly, at the bottom we
have a strong foundation.

104
00:08:23,945 --> 00:08:25,234
Of text processing.

105
00:08:25,534 --> 00:08:29,945
So this is crucial for any
ization system to have a very

106
00:08:29,945 --> 00:08:32,105
strong text processing pipeline.

107
00:08:33,155 --> 00:08:37,355
It involves multiple activities
such as text, normalization,

108
00:08:37,895 --> 00:08:39,664
text organization, and filtering.

109
00:08:40,625 --> 00:08:43,444
So let's look at what
text normalization is.

110
00:08:44,075 --> 00:08:50,194
So it involves a variety of techniques
such as converting uppercase to

111
00:08:50,194 --> 00:08:52,339
lowercase, removing punctuation marks.

112
00:08:53,209 --> 00:08:59,119
Expanding on certain abbreviations that
might be present in the conversation.

113
00:08:59,869 --> 00:09:05,569
Converting numbers, currencies,
and dates into words so that it

114
00:09:05,569 --> 00:09:07,909
is relevant for text processing.

115
00:09:08,790 --> 00:09:14,579
Normalization is crucial for a variety
of applications like search engines or

116
00:09:14,579 --> 00:09:18,730
text-based workflows and machine learning.

117
00:09:19,375 --> 00:09:19,954
And this is.

118
00:09:20,995 --> 00:09:26,015
At the high level an overview of the
text normalization, and the main goal

119
00:09:26,015 --> 00:09:31,805
of this is to reduce ambiguity and
improve the overall model performance.

120
00:09:32,855 --> 00:09:34,655
Now let's talk about text tokenization.

121
00:09:35,675 --> 00:09:42,155
So tokenization kind of simplifies
complex text by dividing it into smaller,

122
00:09:42,635 --> 00:09:48,030
manageable components, which allows
easier processing of the natural language.

123
00:09:49,085 --> 00:09:52,145
So there are different
types of text tokenization.

124
00:09:52,985 --> 00:09:56,345
We can split individual
words into characters.

125
00:09:56,975 --> 00:09:59,405
We can split a sentence into words.

126
00:10:00,065 --> 00:10:03,575
We can split a paragraph into sentences.

127
00:10:03,995 --> 00:10:09,065
So a variety of different tokenization
techniques can be utilized depending on

128
00:10:09,245 --> 00:10:11,435
the use case that you're trying to solve.

129
00:10:12,785 --> 00:10:17,075
So the next layer about
that is semantic analysis.

130
00:10:18,005 --> 00:10:22,535
So semantic analysis analyzes
the grammatical format of the

131
00:10:22,535 --> 00:10:26,825
sentences, including arrangement
of words, phrases, and clauses.

132
00:10:27,635 --> 00:10:33,485
And the main goal behind semantic
analysis is to establish relationships

133
00:10:33,515 --> 00:10:38,255
between the independent terms
identified as part of text processing.

134
00:10:38,855 --> 00:10:44,375
So this is something you can think
of it as identifying the actors.

135
00:10:45,095 --> 00:10:47,855
The system who are actively
participating in the conversation.

136
00:10:48,455 --> 00:10:52,025
And then what is the relation
between those actors whether your

137
00:10:52,025 --> 00:10:54,065
text is semantically correct.

138
00:10:54,545 --> 00:10:57,155
So all that is crucial.

139
00:10:57,845 --> 00:11:03,575
Before we can attempt generating a
summary based on the text at the very top

140
00:11:03,865 --> 00:11:06,805
we have the summary generation aspect.

141
00:11:07,405 --> 00:11:11,335
So this is largely
dependent on the efficiency.

142
00:11:12,115 --> 00:11:14,035
Success of the bottom two layers.

143
00:11:15,355 --> 00:11:22,405
So if we take this heretical
approach and if we combine this text

144
00:11:22,405 --> 00:11:26,575
processing with certain optimization
techniques like data caching,

145
00:11:27,805 --> 00:11:34,615
reducing latencies with multithreaded
systems, and those four significant

146
00:11:35,665 --> 00:11:38,665
advantages or mono architectures.

147
00:11:39,550 --> 00:11:42,250
While maintaining superior accuracy.

148
00:11:43,000 --> 00:11:46,970
So we'll cover this in more
detail in the upcoming slides.

149
00:11:47,970 --> 00:11:53,820
So one of the key considerations for a
highly efficient AI summarization system

150
00:11:53,820 --> 00:12:00,730
is that the analysis of a large scale
messaging data require certain data

151
00:12:00,730 --> 00:12:03,580
flow architectures to handle complex.

152
00:12:04,030 --> 00:12:07,540
Threading patterns while
maintaining the data consistency.

153
00:12:09,280 --> 00:12:16,840
So we need certain components as part of
architecture, and those would be scalable

154
00:12:16,840 --> 00:12:23,530
message processing systems or message
use, essentially that can be utilized to

155
00:12:24,010 --> 00:12:26,650
effectively manage concurrent processes.

156
00:12:27,820 --> 00:12:31,690
And this is like a divide
and conquer strategy where.

157
00:12:32,470 --> 00:12:37,570
Complex tasks can be broken down into
multiple threads, which can be executed

158
00:12:37,570 --> 00:12:43,410
in parallel, and then we can have
a governing thread that can stitch

159
00:12:43,410 --> 00:12:50,040
together all the insights driven by the
different threads, and eventually present

160
00:12:51,180 --> 00:12:53,760
complete picture for data integrity.

161
00:12:54,760 --> 00:12:56,710
Now let's take a look at the next.

162
00:12:57,475 --> 00:12:58,405
Key challenges.

163
00:12:59,455 --> 00:13:05,965
So here I'm covering top
three considerations.

164
00:13:06,655 --> 00:13:10,555
One is hallucination detection,
other one is quality metrics,

165
00:13:11,215 --> 00:13:13,735
and then performance accuracy.

166
00:13:13,735 --> 00:13:14,905
And what are the trade offs?

167
00:13:15,565 --> 00:13:18,115
So let's take a look
at hallucination first.

168
00:13:18,865 --> 00:13:23,725
So hallucination as the word indicates
is something that is not factual.

169
00:13:24,475 --> 00:13:28,435
In the world of generative
AI hallucination is an

170
00:13:28,435 --> 00:13:30,685
important problem to solve.

171
00:13:31,615 --> 00:13:37,165
And having the right systems in place to
detect hallucination is also critical.

172
00:13:37,885 --> 00:13:43,885
So just to give you an example, if
we want generative AI to be very

173
00:13:43,885 --> 00:13:51,025
creative, let's take an example of
using chat GPT for composing a poem.

174
00:13:51,385 --> 00:13:53,785
From certain text that you have.

175
00:13:54,415 --> 00:13:59,905
So for such a use case, we require high
level of creativity by the generative ai.

176
00:14:00,775 --> 00:14:05,015
So we would allow
hallucination in that use case.

177
00:14:05,495 --> 00:14:09,665
However, when it comes to business
conversations and business communications,

178
00:14:10,475 --> 00:14:15,315
we want to minimize any risks of
hallucination because if there is

179
00:14:15,315 --> 00:14:17,875
hallucination it would mean that.

180
00:14:18,280 --> 00:14:23,740
It is not factual for the business,
and then it can lead to significant

181
00:14:23,740 --> 00:14:28,180
consequences for the business,
which is why we have to have

182
00:14:28,840 --> 00:14:32,410
hallucination detection techniques
as part of the architecture.

183
00:14:33,410 --> 00:14:37,520
Now, regarding quality metrics,
evaluation of any national language

184
00:14:37,520 --> 00:14:41,090
processing system for that matter,
requires like comprehensive frameworks

185
00:14:41,690 --> 00:14:43,190
that can effectively assess.

186
00:14:43,850 --> 00:14:46,100
Multiple aspects of
the system performance.

187
00:14:46,670 --> 00:14:52,880
So we need some sort of structured
evaluation techniques that can accurately

188
00:14:52,880 --> 00:14:58,490
measure both the accuracy of the AI
summary that is generated, as well as it

189
00:14:58,490 --> 00:15:04,820
can gauge the practical usage or practical
usability of the AI summarization system.

190
00:15:06,050 --> 00:15:09,950
So while reviewing the quality
metrics, it would be apparent

191
00:15:10,580 --> 00:15:12,590
to review any hallucination.

192
00:15:13,180 --> 00:15:20,980
Scenarios and then flag them so that it
can be solved and avoid hallucination

193
00:15:21,070 --> 00:15:23,830
for the future implementations.

194
00:15:26,620 --> 00:15:30,820
So one of the considerations you
should also think of while doing

195
00:15:30,820 --> 00:15:37,450
the ity analysis is introducing
automated regressions so that let's

196
00:15:37,450 --> 00:15:39,535
say you are fine tuned AI summary.

197
00:15:40,510 --> 00:15:45,670
To be generated for a particular
use case and you want to update

198
00:15:46,210 --> 00:15:47,650
the large language model prompt.

199
00:15:48,650 --> 00:15:53,450
You don't necessarily want to
break anything that you have built.

200
00:15:54,080 --> 00:15:58,400
So it is important for you to
have automated digressions so

201
00:15:58,400 --> 00:16:03,770
that you can catch any new issues
that may arise by prompting.

202
00:16:04,880 --> 00:16:07,190
And in addition, it is
also important to have.

203
00:16:08,330 --> 00:16:13,070
A human in the loop for doing any
manual reviews because you cannot

204
00:16:14,870 --> 00:16:19,400
totally rely on automated regressions
if you are doing prompting.

205
00:16:21,110 --> 00:16:25,010
Now let's take a look at the
performance accuracy and trade offs.

206
00:16:25,860 --> 00:16:30,795
If you can think of improving the
summary accuracy, you would think.

207
00:16:31,545 --> 00:16:36,345
What if I try to scale horizontally
and just add more capacity and

208
00:16:36,345 --> 00:16:39,945
processing power so that my AI
summary quality is improved?

209
00:16:40,725 --> 00:16:45,795
However contradictory to that
understanding research demonstrates

210
00:16:45,795 --> 00:16:50,925
that the lean, the relationship
between the computational resources

211
00:16:50,925 --> 00:16:56,715
spent for AI summary generation versus
the output quality is not linear.

212
00:16:57,045 --> 00:16:59,445
So what that means is.

213
00:16:59,985 --> 00:17:05,355
Even if you spend additional dollars
scaling horizontally, adding more

214
00:17:05,355 --> 00:17:09,975
computational capacity, it does
not solve your s quality issues.

215
00:17:10,785 --> 00:17:15,645
So there has to be a robust, functional
component as part of your architecture

216
00:17:16,305 --> 00:17:21,675
to review the air summary quality and
then have different quality checks

217
00:17:22,295 --> 00:17:24,790
as you are tuning your prompts.

218
00:17:25,790 --> 00:17:33,350
Another key challenge to solve the AI
summary like fairly is generating the

219
00:17:33,350 --> 00:17:39,770
output such as such that it is relevant
to the business use case, but also

220
00:17:40,070 --> 00:17:46,370
it shouldn't be skewed introducing
bias against one of the metrics.

221
00:17:47,060 --> 00:17:48,230
So let's take an example.

222
00:17:48,280 --> 00:17:55,450
If there's a business use case, which
is about offering different pricing

223
00:17:55,450 --> 00:18:03,250
models for iPhones, and depending
on the color of your iPhone, you

224
00:18:03,250 --> 00:18:05,560
would be paying a different price.

225
00:18:06,220 --> 00:18:14,540
So if we give this task for, to
ai some AI models it is likely

226
00:18:14,540 --> 00:18:15,890
that based on the data that.

227
00:18:16,565 --> 00:18:19,325
Is fed to the large language model.

228
00:18:20,495 --> 00:18:24,365
It can be heavily biased towards
one gender versus another.

229
00:18:25,085 --> 00:18:30,515
And then the pricing, if it
is set based on AI algorithms,

230
00:18:30,995 --> 00:18:32,855
can be biased by the gender.

231
00:18:33,485 --> 00:18:40,025
So this is just one of the example of
bias, but there can be a variety of

232
00:18:40,025 --> 00:18:45,425
different attributes that can generate
biases for the AI summarization systems.

233
00:18:46,460 --> 00:18:49,550
So how do we solve these kind of problems?

234
00:18:50,390 --> 00:18:55,220
How do we solve the bias in the
A SMR and the model outputs?

235
00:18:55,850 --> 00:19:00,500
So one of the key techniques is
ha carefully selecting your data.

236
00:19:01,040 --> 00:19:05,990
So when you're training your
model, your data has to be neutral.

237
00:19:06,200 --> 00:19:10,430
It shouldn't be skewed in favor
of one trait versus another.

238
00:19:11,000 --> 00:19:14,540
That is one way of
achieving unbiased output.

239
00:19:16,280 --> 00:19:23,600
The next is having sufficient data
cleaning so that any noise in the data

240
00:19:24,300 --> 00:19:26,580
doesn't introduce any inherent biases.

241
00:19:27,390 --> 00:19:32,070
In addition, pre-processing the
data to neutralize the dataset.

242
00:19:33,300 --> 00:19:34,710
So those are some of the techniques.

243
00:19:37,020 --> 00:19:40,680
Now let's take a look at one of
the most critical challenges,

244
00:19:40,680 --> 00:19:42,240
which is context management.

245
00:19:43,335 --> 00:19:49,665
So having the right kind of context
for any communication is critical,

246
00:19:50,265 --> 00:19:55,935
whether you're talking to a robot
or you're talking to a human.

247
00:19:56,775 --> 00:20:04,665
So with AI summarization, what is
critical is whatever context is there

248
00:20:04,665 --> 00:20:07,095
for the communication, it is preserved.

249
00:20:07,545 --> 00:20:09,345
After you summarize the text.

250
00:20:10,345 --> 00:20:15,235
So identifying the right actors who are
participating in the communication and

251
00:20:15,235 --> 00:20:22,225
then effectively parsing the data based
on the actors, establishing the core

252
00:20:22,225 --> 00:20:27,365
relationships, and then identifying the
hierarchy of the communication based

253
00:20:27,365 --> 00:20:32,705
on the timestamps, based on the actors,
based on their roles for the particular

254
00:20:32,705 --> 00:20:34,760
business use case is very crucial.

255
00:20:35,480 --> 00:20:41,250
For achieving a successful summary
for complex use cases such as

256
00:20:41,730 --> 00:20:43,830
summarizing multi-threaded emails.

257
00:20:44,670 --> 00:20:50,960
So one of the key challenges
is having logical output.

258
00:20:51,440 --> 00:20:56,780
So as you are building your AI
summarization architecture, you can

259
00:20:56,780 --> 00:21:00,410
have different logical checkpoints
in the system necessary for

260
00:21:00,410 --> 00:21:03,350
optimizing the context so that.

261
00:21:04,250 --> 00:21:07,400
The context is relevant
for your communication.

262
00:21:07,940 --> 00:21:12,920
So for instance, if we come, if there
is a con conversation about an upcoming

263
00:21:12,920 --> 00:21:18,380
flight reservation and a customer
is reaching customer service on a

264
00:21:18,380 --> 00:21:23,490
date prior to their departure the
context is about an upcoming flight.

265
00:21:24,630 --> 00:21:29,370
However, in the same conversation,
if the member sends a

266
00:21:29,370 --> 00:21:31,710
follow up email a day after.

267
00:21:32,340 --> 00:21:38,850
The flight reservation, most likely
they're contacting about a flight

268
00:21:38,850 --> 00:21:45,420
that they missed or they had to cancel
or they lost baggage or something

269
00:21:45,960 --> 00:21:47,790
related to the flight after the fact.

270
00:21:48,450 --> 00:21:56,430
So with this contextual awareness, AI
summarization systems should modulate,

271
00:21:57,180 --> 00:22:01,560
and the way this can be achieved
is if you have logical checkpoints.

272
00:22:02,595 --> 00:22:05,595
As part of your architecture,
you will be able to achieve that.

273
00:22:05,985 --> 00:22:09,795
So when I say logical checkpoint,
it means introducing certain

274
00:22:09,795 --> 00:22:13,005
metadata as part of your text.

275
00:22:13,515 --> 00:22:17,085
So when you're processing your
text, you could introduce certain

276
00:22:17,085 --> 00:22:21,130
checkpoints based on the timestamps
in the conversation or based on who

277
00:22:21,130 --> 00:22:22,810
the actor is in the conversation.

278
00:22:23,810 --> 00:22:25,190
Now, if we compare.

279
00:22:25,930 --> 00:22:30,580
The performance of how these AI
summarization systems perform

280
00:22:30,580 --> 00:22:36,760
for different use cases if it
is a single threaded topic.

281
00:22:36,820 --> 00:22:41,620
For instance, I send an email
to a customer service department

282
00:22:42,310 --> 00:22:47,770
inquiring about a refund for
something I did not receive.

283
00:22:49,030 --> 00:22:54,400
It is a single thread where I have a clear
intention about inquiring about something.

284
00:22:55,165 --> 00:23:01,765
Then the AI summarization system detect
it as one actor and then it efficiently

285
00:23:01,945 --> 00:23:09,295
summarizes the conversation, whereas for
the same email, if the customer service

286
00:23:09,295 --> 00:23:16,285
respond with some information and I
send a follow up response, challenging

287
00:23:17,275 --> 00:23:23,725
the outcome of the discussion, and then
the customer service agent escalates.

288
00:23:24,760 --> 00:23:26,770
The conversation to a supervisor.

289
00:23:27,520 --> 00:23:31,270
Now we have three actors essentially
playing a role in this conversation.

290
00:23:31,840 --> 00:23:37,929
So for these multi topic threads it
is getting more complex to process

291
00:23:38,919 --> 00:23:43,360
the text and identifying the actors
and establishing relationships.

292
00:23:43,899 --> 00:23:49,509
So you can see that when the
complexity increases, the accuracy and

293
00:23:49,509 --> 00:23:51,969
contextual awareness dips slightly.

294
00:23:52,975 --> 00:23:59,185
Now let's continue the same example
and think about this use case where

295
00:23:59,305 --> 00:24:04,465
the supervisor is not able to solve
the customer problem and the refer

296
00:24:04,525 --> 00:24:06,085
the customer to another department.

297
00:24:06,865 --> 00:24:11,514
So in this scenario, there is another
fourth factor that is introduced.

298
00:24:11,695 --> 00:24:15,835
In addition, there's also a different
department that gets introduced

299
00:24:16,555 --> 00:24:18,175
in the mix of the conversation.

300
00:24:18,775 --> 00:24:19,470
So it is important.

301
00:24:20,620 --> 00:24:27,340
For it to factor in the right kind of
expectation for the accuracy when there

302
00:24:27,340 --> 00:24:34,600
is multi-threaded conversations that
span not only across different actors,

303
00:24:34,600 --> 00:24:36,850
but also across different departments.

304
00:24:37,210 --> 00:24:42,880
So you can see the accuracy dips even
further for cross department threats.

305
00:24:44,440 --> 00:24:47,290
And then lastly, for
time critical threats.

306
00:24:48,235 --> 00:24:55,435
So whenever there, there are time
critical conversations, like messages

307
00:24:55,585 --> 00:25:02,455
for instance, those tend to have slightly
less amount of text to be processed.

308
00:25:03,025 --> 00:25:07,255
So whenever the delta between
conversations is less, that would

309
00:25:07,255 --> 00:25:12,565
mean that the model would have more
contextual awareness and then higher

310
00:25:12,565 --> 00:25:16,645
accuracy, and it can finish processing in.

311
00:25:17,645 --> 00:25:22,245
Now let's take a look at what drives the
success for AI summarization systems?

312
00:25:22,815 --> 00:25:28,395
So having a good deployment strategy
and pushing for operational excellence

313
00:25:28,935 --> 00:25:31,725
is very critical in achieving success.

314
00:25:33,075 --> 00:25:38,475
So the system deployment strategies
can be having A-C-I-C-D pipeline.

315
00:25:39,220 --> 00:25:45,110
Having checkpointing system, having
automated regressions, having inherent

316
00:25:45,320 --> 00:25:51,490
bias detection techniques, having
hallucination detection techniques, so

317
00:25:51,490 --> 00:25:56,700
all this can be streamlined as part of
your architecture as a data pipeline.

318
00:25:57,420 --> 00:26:02,940
And it has proven that organizations
that invest in coming up with

319
00:26:02,940 --> 00:26:05,370
a comprehensive strategy.

320
00:26:05,985 --> 00:26:12,855
Planning for systematic implementation
and approaching the use case as it fits

321
00:26:12,855 --> 00:26:19,005
the organization has proven like higher
success for the summarization use case.

322
00:26:21,675 --> 00:26:26,815
In terms of performance optimization,
we did talk about it briefly earlier.

323
00:26:26,815 --> 00:26:33,790
With multi-threaded architectures, we
can reduce the execution times and.

324
00:26:34,600 --> 00:26:39,490
Wherever needed, we can have a
trade off in the storage between

325
00:26:39,550 --> 00:26:41,860
caching versus long-term storage.

326
00:26:42,280 --> 00:26:48,130
So there is no single strategy
that suits all use cases.

327
00:26:48,460 --> 00:26:54,980
So depending on the use cases definitely
have the flexibility to implement a hybrid

328
00:26:55,490 --> 00:27:02,180
architecture where you can have the best
of both worlds higher performance with.

329
00:27:03,890 --> 00:27:10,370
Faster memory access with caching
versus long term storage and

330
00:27:12,530 --> 00:27:14,510
reducing the processing times.

331
00:27:15,510 --> 00:27:17,670
Lastly, security and scalability.

332
00:27:18,510 --> 00:27:22,765
So developing a scalable security
framework is very crucial for

333
00:27:23,725 --> 00:27:27,660
maintaining the system integrity
while supporting the organized growth.

334
00:27:28,305 --> 00:27:34,035
For more use cases, AI related use
cases for generative ai, and as the

335
00:27:34,035 --> 00:27:40,755
business is evolving, it is crucial
to come up with some AI governance

336
00:27:40,815 --> 00:27:48,321
strategies so that the security of the
conversations remains intact as well as

337
00:27:49,155 --> 00:27:56,175
there is a, that there are, there is a
railroad established for your use case.

338
00:27:56,685 --> 00:28:00,975
So that it follows a certain pattern,
and then you've identified all the

339
00:28:00,975 --> 00:28:04,215
security constraints for your risk case.

340
00:28:06,945 --> 00:28:12,565
Lastly to conclude, if you want to address

341
00:28:14,845 --> 00:28:20,365
hallucination bias mitigation,
dynamic data adaptation and context

342
00:28:20,365 --> 00:28:22,735
preservation, then you need.

343
00:28:23,140 --> 00:28:28,450
Data pipeline for it, which factors
in this as part of architecture and as

344
00:28:28,450 --> 00:28:33,700
businesses rely more and more on digital
communications, these summarization

345
00:28:33,700 --> 00:28:39,130
systems are going to play a very crucial
role in enhancing the overall productivity

346
00:28:39,130 --> 00:28:43,270
of the organization as well as how
the information is managed across the

347
00:28:43,270 --> 00:28:46,300
organization and how data is exchanged.

348
00:28:47,380 --> 00:28:51,670
So by implementing these strategies
and frameworks that we discussed today.

349
00:28:53,380 --> 00:29:01,690
I hope you have the tidbits needed for
creating a summarization system that

350
00:29:01,690 --> 00:29:08,020
can effectively balance accuracy and
efficiency as well as it is contextual

351
00:29:08,020 --> 00:29:12,130
aware to understand the customer
needs to solve the business problem.

352
00:29:13,210 --> 00:29:18,100
And since this is an evolving
area, definitely have a

353
00:29:18,100 --> 00:29:20,260
robust AI governance process.

354
00:29:21,430 --> 00:29:24,880
Where your security of the
system does not get compromised.

355
00:29:25,880 --> 00:29:26,630
Thank you very much.

