1
00:00:00,500 --> 00:00:02,790
Hello everyone myself, Ika Ram.

2
00:00:03,290 --> 00:00:04,130
Welcome everyone.

3
00:00:04,189 --> 00:00:10,410
So today I will be walking you through
how AI and machine learning are changing

4
00:00:10,410 --> 00:00:12,700
instant management in the cloud.

5
00:00:13,390 --> 00:00:18,290
For over the years we have been stuck in
the reactor mode waiting for outages to

6
00:00:18,290 --> 00:00:20,570
happen and then scrambling to fix them.

7
00:00:21,245 --> 00:00:24,695
What I'll show you today is how
distributed AI architecture,

8
00:00:24,785 --> 00:00:29,075
observability, and automation
pipeline can change that.

9
00:00:29,225 --> 00:00:34,025
Focus in both strategic why and also
why this matters and the technical

10
00:00:34,445 --> 00:00:37,825
and also how to build into your stack.

11
00:00:38,605 --> 00:00:42,635
So next slide would be
today's agenda here.

12
00:00:42,635 --> 00:00:45,355
How we will structure the session first.

13
00:00:45,355 --> 00:00:50,435
We will look at how instant management
has evolved over, over the time.

14
00:00:50,915 --> 00:00:56,295
Then we'll break down the core AI and
ML capabilities that driven modern

15
00:00:56,295 --> 00:00:59,385
systems like things like an detection.

16
00:00:59,715 --> 00:01:02,865
Root cause analysis and
auto autonomous redemptions.

17
00:01:03,295 --> 00:01:07,925
Next next I'll walk you through
distributor AI architectures

18
00:01:08,435 --> 00:01:12,335
where telemetry models and
automation pipeline come together.

19
00:01:12,845 --> 00:01:16,995
So finally, we will wrap up with
the real world case studies with

20
00:01:16,995 --> 00:01:21,835
key metrics and step by step roadmap
so you can use for implementation.

21
00:01:22,525 --> 00:01:24,265
So next slide would be.

22
00:01:24,850 --> 00:01:28,250
The high stakes of modern
incident management.

23
00:01:28,750 --> 00:01:30,990
The stakes today are higher than ever.

24
00:01:30,990 --> 00:01:37,449
In cloud environment downtown downtime
can cascade through dozens of services

25
00:01:37,960 --> 00:01:39,880
and cost millions of dollar per hour.

26
00:01:40,380 --> 00:01:43,934
Incidents are still caused by
human error and alert feature tube.

27
00:01:44,324 --> 00:01:50,314
So where engineer get so many false
alarm that critical signal get lost.

28
00:01:50,734 --> 00:01:54,514
The complexity of distributed
microservices only multiplies the problem.

29
00:01:55,174 --> 00:01:59,355
The truth is manual approach
doesn't scale anymore.

30
00:01:59,564 --> 00:02:02,719
So we need intelligence
system that can shift.

31
00:02:03,519 --> 00:02:08,500
Through nausea, identify through
issues and guide engineers towards

32
00:02:08,500 --> 00:02:10,729
the right action as a faster,

33
00:02:11,229 --> 00:02:16,210
okay next slide would be the
evolution react to pro two.

34
00:02:16,840 --> 00:02:21,459
So let's break down this evolution, like
in past instant management was reactive.

35
00:02:21,910 --> 00:02:22,989
The Sure based.

36
00:02:23,435 --> 00:02:27,944
Monitoring would trigger alarm when
metrics like CPR memory crossed

37
00:02:27,944 --> 00:02:32,354
a limit and human had to dig
through, log to diagnose the issue.

38
00:02:33,149 --> 00:02:39,509
Over the time we moved to more responsive
system like correlation engines automated

39
00:02:39,539 --> 00:02:42,309
runbooks and structured post model.

40
00:02:43,059 --> 00:02:46,230
But the real leap forward
is predictive ance.

41
00:02:46,799 --> 00:02:52,889
So where a model forecast alarm
alarms before they turn into outages.

42
00:02:53,289 --> 00:02:57,189
Coming to the LSTM networks and
time series forecasting can predict

43
00:02:57,189 --> 00:03:03,009
failures, like casual interference
can pinpoint the dependencies and

44
00:03:03,099 --> 00:03:08,569
refor reformance learning agents
can handle redemption automatically.

45
00:03:09,559 --> 00:03:12,979
The shift is from reacting after
the fact to preventing issues

46
00:03:12,979 --> 00:03:15,319
before they impact the users.

47
00:03:15,819 --> 00:03:17,410
So next would be, yeah.

48
00:03:17,529 --> 00:03:19,779
Next would be the, oh my bad.

49
00:03:20,589 --> 00:03:21,369
Embarrassing.

50
00:03:21,369 --> 00:03:22,180
A new era.

51
00:03:23,050 --> 00:03:27,100
So this new era of intelligent
incident management changes the entire

52
00:03:27,100 --> 00:03:31,660
life cycle, like metrics, logs, and
traces are streamed in real time.

53
00:03:32,605 --> 00:03:37,254
Into a unified observability platform,
whereas in machine learning models

54
00:03:37,254 --> 00:03:41,785
continuously analyze that data
form an patterns and correlations.

55
00:03:42,144 --> 00:03:47,155
Instead of waiting for a human to review
dashboard, the system can detect the

56
00:03:47,274 --> 00:03:53,395
issue and map the root cause, and in many
ca cases, apply the fixed automatically.

57
00:03:53,995 --> 00:03:57,480
What this means in
practice is less downtime.

58
00:03:58,315 --> 00:04:02,405
Lower co operational cost and
higher customer satisfaction.

59
00:04:02,775 --> 00:04:06,195
Next slide would be core
AI or MI capabilities.

60
00:04:06,525 --> 00:04:09,874
So these are four key AI
capabilities at play here.

61
00:04:10,295 --> 00:04:14,100
The first is predictive validating,
whereas model trained on baseline so it

62
00:04:14,100 --> 00:04:19,140
can detect early warnings signals long
before traditional threshold are breached.

63
00:04:19,815 --> 00:04:23,484
The second would be is
automated Root Task Analysis.

64
00:04:23,874 --> 00:04:26,004
So it's a craft-based model.

65
00:04:26,304 --> 00:04:30,864
Look at service dependencies and
isolated with the fault originates.

66
00:04:31,254 --> 00:04:35,184
Where coming to the third is an
autonomous redemptions where this

67
00:04:35,184 --> 00:04:39,444
is reinforcement learning agents can
restart the services, reroute the

68
00:04:39,444 --> 00:04:42,414
traffic or scale, cluster on their own.

69
00:04:42,775 --> 00:04:43,584
And finally.

70
00:04:44,140 --> 00:04:47,409
Intelligent escalation where incidents
are routed automatically to the

71
00:04:47,409 --> 00:04:51,820
right engineer based on the expert
context and availability together.

72
00:04:52,090 --> 00:04:57,430
So these capability reduce the noise and
cut detection and response times and.

73
00:04:58,155 --> 00:05:00,614
Let human focus on the high value work.

74
00:05:01,194 --> 00:05:04,444
Coming to the next slide where it
driven to the leading platform.

75
00:05:04,924 --> 00:05:10,484
So there are the major cloud cover already
embedded this capability AWS SageMaker,

76
00:05:10,574 --> 00:05:14,444
which integrates with the CloudWatch
so it can deploy and it detects model

77
00:05:14,444 --> 00:05:16,154
and trigger the Lambda functions for.

78
00:05:16,489 --> 00:05:21,499
Automated redemptions, whereas coming
to the Azure ml. Ml, so it ties

79
00:05:21,499 --> 00:05:26,039
into the log analytics and log apps
where it detect can direct directly

80
00:05:26,039 --> 00:05:27,909
trigger correct corrective actions.

81
00:05:28,150 --> 00:05:31,909
But coming to the other cloud-based
vertex AI connects, which with

82
00:05:31,909 --> 00:05:36,169
the cloud operations and cloud
functions for event driven responses.

83
00:05:36,619 --> 00:05:42,155
While it's ML ops tooling keeps
model restrained on fresh telemetry.

84
00:05:42,675 --> 00:05:48,525
So each provider is making AI operational
intelligence a first class service.

85
00:05:49,025 --> 00:05:53,294
Coming to the next slide, like
distributed AI architecture here, how

86
00:05:53,294 --> 00:05:57,825
the architecture looks in practice
Telemetry is a collector from across

87
00:05:57,825 --> 00:06:00,015
your stack using open telemetry.

88
00:06:00,515 --> 00:06:06,375
Friendly or native cloud agents, a unified
observability layer like elastic or

89
00:06:06,525 --> 00:06:12,875
datadog which correlates metrics, logs,
and traces the a, these AI process layer.

90
00:06:13,325 --> 00:06:16,855
Runs the ML model for
anomaly anomaly detection.

91
00:06:17,155 --> 00:06:21,345
We are forecasting and root analysis
root cause analysis, typically

92
00:06:21,345 --> 00:06:26,075
using a distributor framework like
Spark, ml or TensorFlow serving.

93
00:06:26,405 --> 00:06:30,005
So in response to orchestration,
then connects to the ISTM tools

94
00:06:30,005 --> 00:06:34,560
like ServiceNow or pay page duty
to trigger automated runbooks.

95
00:06:35,235 --> 00:06:39,825
A feedback loop retrains models
continuously and secure data fabric

96
00:06:39,825 --> 00:06:42,294
ensure governance and compliance.

97
00:06:43,174 --> 00:06:46,894
This slide talks about it
and coming to the next slide,

98
00:06:46,894 --> 00:06:49,134
that training intelligence.

99
00:06:50,034 --> 00:06:54,594
So the effectiveness of these
systems comes down to the data.

100
00:06:54,594 --> 00:06:59,094
You train them on telemetry streams,
provide metrics like latency throughout,

101
00:06:59,244 --> 00:07:04,704
through output and saturation locks
can be praised with NVP techniques to

102
00:07:04,704 --> 00:07:07,554
extract error codes and correlation id.

103
00:07:08,364 --> 00:07:13,764
And coming to the torical incident
record like post-mortem cells as a why

104
00:07:14,034 --> 00:07:15,919
training sets for root cause models.

105
00:07:16,419 --> 00:07:19,025
But the most important
factor is data quality.

106
00:07:19,205 --> 00:07:21,125
So model trained on noisy.

107
00:07:21,575 --> 00:07:24,335
Inconsistent data will
produce false positive.

108
00:07:25,024 --> 00:07:29,644
So observability pipeline must be
cleaned and normalized before training.

109
00:07:30,144 --> 00:07:33,489
So coming to the next slide where it
talks about the real world impact.

110
00:07:33,989 --> 00:07:38,499
So when origination adopt intelligent
incident manager management,

111
00:07:38,619 --> 00:07:40,479
the numbers shift dramatically.

112
00:07:40,960 --> 00:07:44,440
We consistently see 82 and
90% reductions in meantime to

113
00:07:44,440 --> 00:07:45,940
detect and resolve incident.

114
00:07:46,509 --> 00:07:52,439
False alerts drop significantly ly, which
reduces engineer burnout and attrition.

115
00:07:52,829 --> 00:07:55,949
So auto redemption rates
climb as reinforcements.

116
00:07:56,279 --> 00:08:00,629
Learning models get better
at handling repeated issues.

117
00:08:01,229 --> 00:08:04,619
So let me give you one example
on the financial services side.

118
00:08:05,009 --> 00:08:09,089
For example used the predictive models
to detect database saturation like

119
00:08:09,089 --> 00:08:13,709
20 minutes before failure, so it
automatically scaled the cluster and

120
00:08:13,709 --> 00:08:15,989
avoid a multimillion dollar outage.

121
00:08:16,259 --> 00:08:19,769
So these are the kinds of outcome
that makes a business case clear.

122
00:08:20,269 --> 00:08:22,759
Next slide would be the
implementation roadmap.

123
00:08:23,684 --> 00:08:29,064
Whereas coming to this slide like adoption
work best in phases like first phase

124
00:08:29,134 --> 00:08:34,165
is data readiness, like centralized
telemetrics, normalized logs and train

125
00:08:34,165 --> 00:08:35,905
baseline anomaly detection model.

126
00:08:35,935 --> 00:08:40,775
In phase two, we add augmentation
and automation where it is deployed.

127
00:08:40,835 --> 00:08:43,385
AI driven alert, correlation, and run box.

128
00:08:44,210 --> 00:08:49,130
So coming to the phase three we introduce
a proactive intelligence where it is a

129
00:08:49,530 --> 00:08:54,210
graph driven based root cause analysis and
reinforcement learning for the redemption.

130
00:08:55,020 --> 00:09:00,340
Finally the fourth phase which is focused
on the optimization predictive capacity

131
00:09:00,340 --> 00:09:04,690
planning like it's maintaining and
expanding across region and the teams.

132
00:09:04,960 --> 00:09:08,200
So each step builds a capability
while limiting its risk.

133
00:09:08,755 --> 00:09:12,965
Whereas coming to the next slide, it
talks about the critical success factor

134
00:09:13,465 --> 00:09:17,245
where technology is only after equation.

135
00:09:17,275 --> 00:09:21,385
Success depends on high quality
data, pipeline, clean and label

136
00:09:21,385 --> 00:09:24,925
for training, it requires a
cross-functional collaboration like.

137
00:09:25,765 --> 00:09:30,585
Machine learner learning engineers,
SREs and domain expert working side

138
00:09:30,585 --> 00:09:35,715
by side where it rollout should be
iterate, like start with one service,

139
00:09:36,615 --> 00:09:39,375
do value, then scale and evolve.

140
00:09:39,465 --> 00:09:42,375
AI should augment human, not replace them.

141
00:09:43,035 --> 00:09:47,415
So exp expandability is key, like
engineer must trust AI recommendation

142
00:09:47,415 --> 00:09:49,725
and or they won't adapt it.

143
00:09:50,225 --> 00:09:50,825
The future.

144
00:09:50,825 --> 00:09:54,105
Next slide would be the future
is intelligent relations.

145
00:09:54,765 --> 00:09:58,455
The future is moving towards
adaptive self uhhe system.

146
00:09:58,455 --> 00:10:04,605
ML agents will forecast failures,
autoscale infrastructure and rero traffic

147
00:10:04,665 --> 00:10:06,775
before user ever notice a problem.

148
00:10:07,510 --> 00:10:08,910
Engineer won't disappear.

149
00:10:09,670 --> 00:10:13,860
They'll shift from firefighting to
higher level design and governance.

150
00:10:14,220 --> 00:10:18,640
The organization that invest now
will defend the operational religions

151
00:10:18,720 --> 00:10:20,130
standards for the next decade.

152
00:10:20,490 --> 00:10:24,180
The question isn't if the DA
change is coming, it's whether

153
00:10:24,230 --> 00:10:26,030
you can lead it or follow it.

154
00:10:26,530 --> 00:10:31,860
That's the roadmap for, inte into
the instant management, so thank you.

