1
00:00:00,000 --> 00:00:00,600
Everyone.

2
00:00:00,780 --> 00:00:01,950
I am PR Singh.

3
00:00:02,490 --> 00:00:07,320
Today I'm going to take your
insight how a spam detection is

4
00:00:07,320 --> 00:00:09,810
handled at truly massive scale.

5
00:00:10,350 --> 00:00:15,660
We are talking about billions of users,
millions of decisions every second, and

6
00:00:15,720 --> 00:00:17,640
everything has to happen in real time.

7
00:00:18,140 --> 00:00:23,210
Now when we talk about a spam,
it's not just annoying messages.

8
00:00:23,960 --> 00:00:29,750
We are talking about fraud, phishing,
scams, harmful content, et cetera,

9
00:00:30,560 --> 00:00:35,300
things that directly affects users
trust and platform integrity.

10
00:00:36,200 --> 00:00:42,920
And here is the hard part at this scale,
even a tiny error, say a 10th of a percent

11
00:00:43,429 --> 00:00:46,010
means millions of peoples are impacted.

12
00:00:46,610 --> 00:00:52,430
And that's why we need ML ops that
is not just clear, but resilient,

13
00:00:52,730 --> 00:00:54,890
privacy, preserving, and battle tested.

14
00:00:55,390 --> 00:00:59,530
So let me walk you through how we are
going to explore this challenge today.

15
00:01:00,460 --> 00:01:01,720
So here is the roadmap.

16
00:01:02,470 --> 00:01:06,699
We'll start by looking at
unique challenges of working

17
00:01:06,699 --> 00:01:08,350
at billion users scale.

18
00:01:09,235 --> 00:01:15,865
Then I will show you end to end
ML ops architecture, how large

19
00:01:15,865 --> 00:01:20,125
scale systems design pipelines to
keep up with a constant change.

20
00:01:20,625 --> 00:01:25,070
We'll also dive into data strategies
because what data you choose.

21
00:01:26,009 --> 00:01:30,450
Either to label and or to
train is absolutely critical.

22
00:01:31,380 --> 00:01:35,130
Then we'll look at the
production site like scaling

23
00:01:35,399 --> 00:01:37,679
monitoring and incident response.

24
00:01:38,610 --> 00:01:43,589
Finally, we'll end by looking
ahead, what spam looks like in

25
00:01:43,589 --> 00:01:47,524
the future, and the technologies
we will need to stay ahead of it.

26
00:01:48,024 --> 00:01:54,294
So think of this talk as a blueprint,
not just theory, but patterns you

27
00:01:54,294 --> 00:01:56,754
can adapt to your own systems.

28
00:01:57,254 --> 00:01:58,874
So let's start at the beginning.

29
00:01:58,994 --> 00:02:03,004
The sheer challenge of
operating at a scale every day.

30
00:02:03,214 --> 00:02:06,964
Billions of pieces of
content move across platform.

31
00:02:07,835 --> 00:02:13,714
At peak load, large scale systems are
making millions of evaluations per second.

32
00:02:14,214 --> 00:02:18,144
And for user facing decisions
like blocking a comment or

33
00:02:18,144 --> 00:02:22,105
flying a post response must be
under a hundred millisecond.

34
00:02:23,065 --> 00:02:26,274
Now, think about the consequences
of error at this scale.

35
00:02:26,934 --> 00:02:31,529
A 0.1% false positive rate does
not sound terrible in theory.

36
00:02:32,454 --> 00:02:37,134
But in practice that could mean
millions of legitimate users

37
00:02:37,134 --> 00:02:41,364
waking up to find their posts or
blocked, or comments are deleted.

38
00:02:41,864 --> 00:02:47,864
And on the other side, false negative
means spam or scams getting through to

39
00:02:47,864 --> 00:02:49,694
the millions of people in harming them.

40
00:02:50,194 --> 00:02:51,934
The constraints are equally tough.

41
00:02:52,594 --> 00:02:57,034
Large scale systems are detecting
across text, images, videos,

42
00:02:57,334 --> 00:02:58,744
even behavioral patterns.

43
00:02:59,244 --> 00:03:03,324
They have to support hundred of
languages as well, like they have to

44
00:03:03,354 --> 00:03:09,084
constantly adapt because attackers
change tactics every day and all

45
00:03:09,084 --> 00:03:14,000
of things must comply with strict
privacy laws like GDPR and CCPA.

46
00:03:14,500 --> 00:03:20,020
It's like playing chess with
millions of opponents, and they all

47
00:03:20,020 --> 00:03:21,430
change the strategies overnight.

48
00:03:21,930 --> 00:03:26,670
So meeting challenges like this
requires more than just good models.

49
00:03:27,300 --> 00:03:32,070
It requires end to end ML ops
architecture, and that is we

50
00:03:32,125 --> 00:03:33,270
are going to talk about next.

51
00:03:33,770 --> 00:03:34,905
Here's what that looks like.

52
00:03:35,645 --> 00:03:40,385
First ingest data from multiple
sources, which includes real

53
00:03:40,385 --> 00:03:42,785
time streams and batch histories.

54
00:03:43,445 --> 00:03:48,745
Then comes feature engineering where
they extract both instant signals

55
00:03:48,865 --> 00:03:53,065
like device fingerprinting and
long-term signals like account history.

56
00:03:53,565 --> 00:03:59,115
Models are retrained continuously,
often daily, but training is not enough.

57
00:04:00,005 --> 00:04:03,365
You have to validate rigorously
against colon data sets.

58
00:04:03,680 --> 00:04:06,470
Fairness checks and adversarial examples.

59
00:04:06,970 --> 00:04:11,030
And when a deployment happens
they don't just flip a switch.

60
00:04:11,600 --> 00:04:15,830
We have to use a shadow deployments
where new models can run in parallel

61
00:04:15,830 --> 00:04:19,460
silently for days or weeks or even months.

62
00:04:20,240 --> 00:04:23,690
And then can roll outs are there,
which are gradually sifting traffic

63
00:04:23,840 --> 00:04:25,415
with instant rollback if needed.

64
00:04:25,915 --> 00:04:28,795
This is not just a pipeline,
it's a living system.

65
00:04:28,855 --> 00:04:32,605
It adapts, learns and
recovers without stopping.

66
00:04:33,105 --> 00:04:39,185
But what makes this models powerful
is not this, but the features we

67
00:04:39,185 --> 00:04:41,915
built from the multi-model data.

68
00:04:42,845 --> 00:04:45,755
So let's discover about this
multi-model feature engineering.

69
00:04:46,255 --> 00:04:49,405
Spam today does not come in just one form.

70
00:04:50,350 --> 00:04:57,100
Attackers use text, images, videos, and
even behavioral manipulation for text.

71
00:04:57,560 --> 00:05:02,240
Large scale systems use transformer
embeddings like Bert and Grams,

72
00:05:02,300 --> 00:05:08,510
entity recognition, sentiment intent
classification, and et cetera.

73
00:05:09,200 --> 00:05:14,415
For image and video you can rely on
CNNs like efficient net and rest net.

74
00:05:14,915 --> 00:05:19,135
OCR are very common for memes
and frame signal analysis, but

75
00:05:19,135 --> 00:05:21,295
content is only half the story.

76
00:05:21,505 --> 00:05:23,305
Behavior is often the giveaway.

77
00:05:23,805 --> 00:05:28,605
Things like account as posting
frequency engagement metrics, or

78
00:05:28,605 --> 00:05:31,890
unusual device fingerprints can
just be as revealing as other.

79
00:05:32,390 --> 00:05:35,055
Finally, context matters the most.

80
00:05:35,655 --> 00:05:39,825
For example, a post at
2:00 AM from new device.

81
00:05:40,470 --> 00:05:44,880
Linked to trending spam topics tells
a different story than the same

82
00:05:44,880 --> 00:05:46,470
post from a long standing account.

83
00:05:47,430 --> 00:05:50,760
When you put all these signals
together, you catch patterns

84
00:05:50,970 --> 00:05:52,560
no single dimension can reveal.

85
00:05:53,060 --> 00:05:57,240
Now let's look at how we bring those
signal together in the model itself.

86
00:05:57,960 --> 00:06:01,320
Something we call a model
architecture ensemble approach.

87
00:06:01,680 --> 00:06:03,330
So where large scale systems.

88
00:06:03,665 --> 00:06:05,525
And don't rely on one big model.

89
00:06:05,795 --> 00:06:10,325
They, instead they use a
hierarchical ensemble first.

90
00:06:10,805 --> 00:06:15,245
Do a fast pre-filters, where light
model lightweight models that

91
00:06:15,245 --> 00:06:17,255
can process use volume quickly.

92
00:06:17,615 --> 00:06:22,145
They're designed for high recall, catching
anything even slightly suspicious.

93
00:06:22,645 --> 00:06:26,515
Now we bring into a specialist
model here, like deeper, which has

94
00:06:26,515 --> 00:06:30,415
deeper domain specific networks
for text, images, videos, behavior.

95
00:06:31,090 --> 00:06:34,420
And then comes the multimodal
fusion where they're combining

96
00:06:34,420 --> 00:06:37,060
the signals using cross attention.

97
00:06:37,900 --> 00:06:44,260
This is where we find hidden correlations,
like when the text looks fine, but

98
00:06:44,260 --> 00:06:49,240
paired with image features, it, it
becomes clearly a spam or a harm.

99
00:06:49,740 --> 00:06:54,000
Finally, a meta learner integrates
everything weighing outputs

100
00:06:54,005 --> 00:06:55,445
based on historical reliability.

101
00:06:55,945 --> 00:07:00,565
The result is speed when we need
it, and depth when it matters.

102
00:07:01,065 --> 00:07:04,935
It's the difference between quickly
scanning luggage at an airport

103
00:07:05,235 --> 00:07:08,895
versus pulling aside a suspicious
bag for deeper inspection.

104
00:07:09,395 --> 00:07:13,535
And to serve this model in production,
we need a specialized infrastructure.

105
00:07:14,075 --> 00:07:16,325
So let's talk about distributed
serving architecture.

106
00:07:17,285 --> 00:07:21,605
Serving at a scale is a systems
challenge as much as an ML one.

107
00:07:22,550 --> 00:07:26,710
Large scale systems use context
of air load balancing to send

108
00:07:26,710 --> 00:07:28,870
requests to the right resources.

109
00:07:29,360 --> 00:07:34,550
Horizontal autoscaling helps us
handle certain traffic spikes.

110
00:07:35,270 --> 00:07:39,755
A low latency feature store can ensure
models, gets what they need without

111
00:07:39,755 --> 00:07:45,080
recomputing, and a specialized hardwares
like GPUs and TPUs accelerates inferences.

112
00:07:45,580 --> 00:07:47,500
Performance optimization is constant.

113
00:07:47,950 --> 00:07:51,430
Model quantization makes
networks smaller and faster.

114
00:07:52,030 --> 00:07:55,650
Batching lets lets us process
multiple requests together.

115
00:07:55,980 --> 00:08:00,000
Prioritization ensures critical cases
are not stuck in the queue, and the

116
00:08:00,000 --> 00:08:03,240
circuit breaker prevents cost getting
failures if something goes wrong.

117
00:08:04,175 --> 00:08:09,480
All of this will allow to consistently
hit 80 millisecond end to end

118
00:08:09,480 --> 00:08:12,060
latency even under extreme load.

119
00:08:12,615 --> 00:08:13,365
80 millisecond.

120
00:08:13,365 --> 00:08:14,265
This just a figure.

121
00:08:14,325 --> 00:08:15,255
It could be anything.

122
00:08:15,315 --> 00:08:21,275
Whatever matters to organization, but even
the best infrastructure needs a smart data

123
00:08:21,275 --> 00:08:23,045
strategies to keep the model learning.

124
00:08:23,615 --> 00:08:26,435
So let's talk about a smart
sampling and learning strategies.

125
00:08:27,215 --> 00:08:30,335
Leveling billions of
sample is not possible.

126
00:08:30,835 --> 00:08:31,790
The simply not possible.

127
00:08:32,005 --> 00:08:34,465
The question is which samples matter most.

128
00:08:34,965 --> 00:08:37,450
So large scale systems
use uncertainty sampling.

129
00:08:38,220 --> 00:08:40,950
Extending low confidence
cases to human review.

130
00:08:41,370 --> 00:08:46,180
Diverse diversity sampling makes
sure we don't miss underrepresented

131
00:08:46,180 --> 00:08:47,470
languages or formats.

132
00:08:48,130 --> 00:08:52,900
Adversarial sampling, durability,
six out the cases where models fail

133
00:08:52,900 --> 00:08:55,690
on making the system even stronger.

134
00:08:56,065 --> 00:08:59,755
And time sensitive sampling
ensures we catch new attack

135
00:08:59,755 --> 00:09:02,455
vectors as they emerge together.

136
00:09:02,665 --> 00:09:06,025
This strategies a drastically
reduced labeling cost while

137
00:09:06,025 --> 00:09:07,555
keeping the models robust.

138
00:09:08,485 --> 00:09:13,045
One example I can think of is like when
attackers started hiding spam in memes.

139
00:09:13,435 --> 00:09:17,785
Adversarial sampling surface
these cases early, letting retrain

140
00:09:17,785 --> 00:09:19,645
before it is spread widely.

141
00:09:20,145 --> 00:09:22,995
But not all spam come from individual.

142
00:09:23,400 --> 00:09:25,020
Often it's coordinated campaigns.

143
00:09:25,230 --> 00:09:27,750
So let's discuss a little bit
about coronated attack detection.

144
00:09:28,710 --> 00:09:30,660
This is where things gets interesting.

145
00:09:30,880 --> 00:09:36,165
A single post or may look normal,
but when thousands of accounts act in

146
00:09:36,165 --> 00:09:38,685
unison, that's a coordinated attack.

147
00:09:39,185 --> 00:09:42,575
Large scale systems use real
time streaming analysis to spot

148
00:09:42,575 --> 00:09:44,615
anomalies in activity patterns.

149
00:09:45,335 --> 00:09:50,535
They apply graph neural networks to
model user content interaction as dynamic

150
00:09:50,535 --> 00:09:55,305
graphs exposing suspicious clusters,
and they deploy countermeasures in real

151
00:09:55,305 --> 00:09:59,565
time, like throttling activity, adding
friction with captures or flagging

152
00:09:59,685 --> 00:10:01,545
suspicious clusters for further review.

153
00:10:02,045 --> 00:10:06,775
One case we can discuss here
is like 10,000 accounts lacking

154
00:10:06,775 --> 00:10:08,725
a post in under one minute.

155
00:10:09,145 --> 00:10:13,435
Individually, nothing stood
out, but when viewed as a graph.

156
00:10:13,975 --> 00:10:15,445
The coordination will be obvious.

157
00:10:15,945 --> 00:10:20,955
Now while large scale systems
might fight these attacks, they

158
00:10:20,955 --> 00:10:23,835
also have to protect user privacy.

159
00:10:24,335 --> 00:10:29,035
Everything I've described so far has to
be done under strict privacy laws like

160
00:10:29,035 --> 00:10:35,025
GTPR and CCPA large scale systems use very
learning to train across decentralized

161
00:10:35,025 --> 00:10:37,095
data without centralizing raw content.

162
00:10:37,875 --> 00:10:42,165
Differential privacy ensures
individuals can't be re-identified.

163
00:10:43,005 --> 00:10:47,865
The systems also employ advanced
cryptographic techniques like homomorphic

164
00:10:47,865 --> 00:10:53,035
encryption for secure inferences,
multi-party computation for trust

165
00:10:53,035 --> 00:10:57,835
distribution, and geo knowledge proofs
for compliance without exposing our data.

166
00:10:58,345 --> 00:11:02,485
The key point being here, privacy
and performance are not opposites.

167
00:11:02,695 --> 00:11:04,930
With the right techniques,
you can have both.

168
00:11:05,430 --> 00:11:09,940
Now let's look at how to keep these
models fresh and reliable in production.

169
00:11:10,440 --> 00:11:12,315
The training cycle is continuous.

170
00:11:12,815 --> 00:11:18,155
The large scale systems, reference model
retrains models daily on fresh data using

171
00:11:18,155 --> 00:11:20,315
b optimization for hyper parameters.

172
00:11:20,705 --> 00:11:26,495
Then evaluate against golden data sets,
fairness slices, and adversarial examples.

173
00:11:27,365 --> 00:11:31,765
New models run in shadow deployment
first silently for scoring real

174
00:11:31,955 --> 00:11:33,815
traffic without affecting users.

175
00:11:34,235 --> 00:11:37,835
Once it's stable, they move into
progressive rollout, which means

176
00:11:37,835 --> 00:11:39,580
can retest gradual traffic shifts.

177
00:11:40,165 --> 00:11:44,875
Automated metric analysis and
instant rollback if something slips.

178
00:11:45,375 --> 00:11:47,415
This rhythm ensures the morals.

179
00:11:47,445 --> 00:11:52,245
Keep space with evolving spam tactics
without ever destabilizing the system.

180
00:11:53,235 --> 00:11:55,935
But the deployment is only half.

181
00:11:55,935 --> 00:11:56,536
The story.

182
00:11:57,195 --> 00:11:59,355
Monitoring keeps everything healthy.

183
00:11:59,855 --> 00:12:02,530
Usually large scale systems
monitor at four labels.

184
00:12:03,030 --> 00:12:08,490
Model performance, which basically is
precision recall and drift detection

185
00:12:09,210 --> 00:12:14,160
and system performance is another,
which has request latency, q, te,

186
00:12:14,520 --> 00:12:17,210
and resource utilization data.

187
00:12:17,210 --> 00:12:21,140
Drift is third one, which has includes
metrics like feature distributions is

188
00:12:21,140 --> 00:12:23,420
schema, validations, statistical tests.

189
00:12:24,230 --> 00:12:28,911
And business impact, of course, like
user eng, user engagement metrics, false

190
00:12:28,911 --> 00:12:31,370
positive appeals, and of platform health.

191
00:12:32,000 --> 00:12:35,000
The idea is to catch
problems before users do.

192
00:12:35,630 --> 00:12:38,930
When it's a model drifting, like
whether it's a model drifting

193
00:12:38,990 --> 00:12:40,690
or a certain traffic spike.

194
00:12:41,110 --> 00:12:46,440
We want to detect early and respond
fast, and when issues do happen, rely

195
00:12:46,440 --> 00:12:48,720
on a structured incident response.

196
00:12:49,220 --> 00:12:51,950
So let's talk about anomaly
detection, incident response here.

197
00:12:52,881 --> 00:12:55,491
So we know incidents are inevitable.

198
00:12:55,670 --> 00:12:58,220
Resilience comes from how you respond.

199
00:12:58,720 --> 00:13:02,830
The large scale systems use automated
anomaly detection, so involves

200
00:13:03,070 --> 00:13:07,271
outlay detection, multivariate
analysis, and baseline comparisons.

201
00:13:08,021 --> 00:13:11,096
If something is off the systems
follow structured playbooks.

202
00:13:11,596 --> 00:13:13,426
Severity based escalation.

203
00:13:13,546 --> 00:13:17,116
Automated rollbacks shadow
mode for investigations and

204
00:13:17,116 --> 00:13:18,766
configurable safety thresholds.

205
00:13:19,456 --> 00:13:22,576
And after every major
incident, run post-mortems.

206
00:13:23,356 --> 00:13:26,971
Not just to fix, but to learn
and strengthen the system.

207
00:13:27,681 --> 00:13:32,931
This structure discipline turns outages
into opportunities for resilience.

208
00:13:33,431 --> 00:13:36,891
Now let's look forward what's
next in this arm's rest.

209
00:13:37,391 --> 00:13:40,061
So the arm race is not slowing down First.

210
00:13:40,271 --> 00:13:41,321
Synthetic content.

211
00:13:41,381 --> 00:13:42,221
Let's talk about that.

212
00:13:42,731 --> 00:13:47,501
Attackers are already experimenting
with AI generated spam, deep fakes,

213
00:13:47,621 --> 00:13:50,681
synthetic text that slips past filters.

214
00:13:51,181 --> 00:13:55,111
Second cross platform coordination
is another thing where spam

215
00:13:55,111 --> 00:13:57,451
campaigns don't stay confined.

216
00:13:57,691 --> 00:14:00,151
They spread across apps and platforms.

217
00:14:00,991 --> 00:14:04,016
Collaboration, while preserving
privacy will be the key here.

218
00:14:04,516 --> 00:14:06,826
Third, let's talk about
adversarial robustness.

219
00:14:06,886 --> 00:14:11,446
We must strengthen defenses against
intentional manipulation of models.

220
00:14:12,166 --> 00:14:16,966
Finally, explainable AI enforcement
actions must be transparent

221
00:14:17,386 --> 00:14:19,366
both for users and regulators.

222
00:14:19,571 --> 00:14:24,671
We need models that not only predict, but
also explain why it took certain action.

223
00:14:25,171 --> 00:14:27,791
The future will demand
even faster Adaptation.

224
00:14:28,291 --> 00:14:32,791
This is not a one-time
problem, but a continuous race.

225
00:14:33,291 --> 00:14:36,251
So let's wrap this up
with the key takeaways.

226
00:14:36,751 --> 00:14:38,761
Here are four key principles.

227
00:14:38,911 --> 00:14:43,801
I want you to remember, spam
detection must be multi.

228
00:14:44,301 --> 00:14:49,821
Meaning you have to take care of text,
images, videos, and behavior together.

229
00:14:50,321 --> 00:14:54,581
ML ops at billion users scale
requires a specialized architecture

230
00:14:54,641 --> 00:14:56,141
is something we have to be aware of.

231
00:14:56,641 --> 00:15:00,871
Privacy and performance can
coexist with the right techniques.

232
00:15:01,081 --> 00:15:01,786
That's very important.

233
00:15:02,286 --> 00:15:04,686
Continuous adaptation is non-negotiable.

234
00:15:05,226 --> 00:15:07,616
We, you must know this
is an evolving arms race.

235
00:15:08,006 --> 00:15:11,336
If you keep these principles in mind,
you'll be better prepared to design

236
00:15:11,336 --> 00:15:15,986
systems that don't just work in research,
but that scales in the real world.

237
00:15:16,976 --> 00:15:18,836
And with that, let me thank you.

238
00:15:19,346 --> 00:15:20,546
So thank you for listening.

239
00:15:20,596 --> 00:15:25,306
I hope this gave you a clear look into
what it takes to build robust, scalable

240
00:15:25,516 --> 00:15:29,386
privacy, presuming ML ops system
for span detection at global scale.

241
00:15:30,286 --> 00:15:35,086
This fight against spam never
ends, but with the right

242
00:15:35,086 --> 00:15:37,036
architecture, we can stay ahead.

243
00:15:37,756 --> 00:15:38,116
Thank you.

