1
00:00:00,090 --> 00:00:04,019
Hi everyone, my name is Sam and
welcome to my session Hong Kong 42.

2
00:00:04,440 --> 00:00:07,260
Today we're gonna be talking about
the different ways in which you can

3
00:00:07,260 --> 00:00:09,270
integrate an AI your application.

4
00:00:09,870 --> 00:00:12,270
So let me share my screen
and we can get started.

5
00:00:12,780 --> 00:00:16,200
A big shout for Kong 42
for selecting my talk.

6
00:00:16,290 --> 00:00:18,090
It helps me spread the
ledge with a community.

7
00:00:19,080 --> 00:00:22,080
So lamb, right from data
to constructive insights.

8
00:00:22,650 --> 00:00:25,530
We're gonna be looking at
the sample application and.

9
00:00:25,935 --> 00:00:29,085
We will talk through its journey,
how we have evolved the usage

10
00:00:29,085 --> 00:00:30,885
of AI in that application.

11
00:00:31,385 --> 00:00:32,195
My name is Sandeep.

12
00:00:32,255 --> 00:00:34,745
I work as a principal
solution architect at Tack.

13
00:00:34,895 --> 00:00:36,785
I'm also an AWS community builder.

14
00:00:37,324 --> 00:00:41,814
I've also been certified as an
AWS, SA professional, and I love

15
00:00:41,874 --> 00:00:43,344
building service applications.

16
00:00:43,614 --> 00:00:46,164
I've been building serverless
applications for the last six years,

17
00:00:46,464 --> 00:00:49,734
and once you start building serverless
applications, that's not turning back.

18
00:00:50,235 --> 00:00:51,045
So let's get started.

19
00:00:51,990 --> 00:00:55,350
like I mentioned before, Aztec is a
company that builds all applications

20
00:00:55,350 --> 00:00:58,380
for our clients, and we have a
large engineering team as well.

21
00:00:59,190 --> 00:01:02,400
Now with this comes the next set
of problems, which is we have

22
00:01:02,400 --> 00:01:05,940
multiple project managers who
run different sprint schedules.

23
00:01:05,970 --> 00:01:09,925
Some of them are on common, and
each of them have their own way

24
00:01:09,925 --> 00:01:13,525
of collecting feedbacks from the
developers at the end of each sprint.

25
00:01:13,795 --> 00:01:17,755
So this data was pretty much
spread out and it was not usable

26
00:01:18,055 --> 00:01:20,695
because it's not centralized and
nobody knows what's happening.

27
00:01:21,195 --> 00:01:26,055
And the other problem we had is our folks
did not like to give negative feedbacks.

28
00:01:26,655 --> 00:01:29,865
We don't know why, but every
time we ask them to give a

29
00:01:29,865 --> 00:01:31,575
feedback, it's always positive.

30
00:01:31,635 --> 00:01:32,655
Everything is kick ass.

31
00:01:33,015 --> 00:01:36,985
And, if we try giving them a
scale, rate your repairs between

32
00:01:36,985 --> 00:01:38,845
one to 10, everybody got that.

33
00:01:39,085 --> 00:01:40,135
Every single person.

34
00:01:40,635 --> 00:01:44,235
So we came up with solution to
build an application with all

35
00:01:44,235 --> 00:01:45,945
feedback that we use internally.

36
00:01:46,395 --> 00:01:50,535
What it does is a simple interface,
which allows you to create projects,

37
00:01:50,535 --> 00:01:55,485
manage them, and it also sends a
notification to the user that, when

38
00:01:55,485 --> 00:01:58,695
the feedback cycle has started, now you
need to provide feedbacks to your peers.

39
00:01:59,565 --> 00:02:02,745
And all the data is again,
stored in one single place.

40
00:02:02,835 --> 00:02:06,255
So we have access to the data at
any given point in time, everything

41
00:02:06,255 --> 00:02:10,305
is now centralized, but we still
had the other problem, which was

42
00:02:10,305 --> 00:02:12,195
everybody getting 10, 10 ratings.

43
00:02:13,005 --> 00:02:15,855
That's when we started
experimenting with bedrock and AI

44
00:02:16,125 --> 00:02:17,965
to see, how it can help us out.

45
00:02:18,465 --> 00:02:20,415
So we start with the playground.

46
00:02:21,255 --> 00:02:25,635
What we did is we started testing out
a simple prompt, which basically says,

47
00:02:25,965 --> 00:02:27,255
I'm going to give you a feedback.

48
00:02:27,735 --> 00:02:31,335
Now you need to categorize them into
three different categories, positive

49
00:02:31,335 --> 00:02:37,545
energy, feedback, and reliability, and
rate them between one to five, one being

50
00:02:37,545 --> 00:02:38,835
the lowest and five being the highest.

51
00:02:39,330 --> 00:02:41,790
And here's the feedback
that the user has received.

52
00:02:42,290 --> 00:02:44,990
So to do this, we started using Bedrock.

53
00:02:45,170 --> 00:02:48,340
And Bedrock has a nice, chat
interface which allows you to test

54
00:02:48,340 --> 00:02:52,400
out different props, in Amazon
Bedrock In the chat playground,

55
00:02:52,910 --> 00:02:55,430
you can select different AI models.

56
00:02:56,045 --> 00:03:00,395
Provide the same prompt and see what kind
of responses each model is providing.

57
00:03:00,575 --> 00:03:04,295
So seeing them side by side helps
you understand the kind of responses

58
00:03:04,295 --> 00:03:07,025
each model is giving, and you can
select the right model for you.

59
00:03:07,525 --> 00:03:11,215
What it also provides is the
metrics on which it works.

60
00:03:11,245 --> 00:03:14,875
So the latency, how much input
to consuming, how much output

61
00:03:14,875 --> 00:03:15,895
photographer is consuming.

62
00:03:16,195 --> 00:03:20,455
So this also helps you to map out
what model is going to cost you how

63
00:03:20,455 --> 00:03:23,575
much, and you know which one you
should be using for your use case.

64
00:03:24,075 --> 00:03:26,795
With this being done, we
got the prompt working.

65
00:03:27,425 --> 00:03:29,015
The problem was consistency.

66
00:03:29,675 --> 00:03:34,070
As you all know, writing a
prompt is just the first step

67
00:03:34,280 --> 00:03:35,600
in building your application.

68
00:03:35,930 --> 00:03:39,500
The prompt has to be consistent
irrespective of what kind of

69
00:03:39,500 --> 00:03:40,910
inputs you're going to give to it.

70
00:03:41,300 --> 00:03:44,270
The prompt must always deliver
what it's supposed to deliver.

71
00:03:45,230 --> 00:03:48,140
So that is when we started
stepping into prompt engineering.

72
00:03:48,140 --> 00:03:48,200
Now.

73
00:03:48,700 --> 00:03:51,550
These are the basic rules that
we follow for prompt engineering.

74
00:03:52,050 --> 00:03:56,370
First thing you gotta do is set
a persona or a role for your ai.

75
00:03:56,790 --> 00:04:02,190
In our case, the role of the AI is to
be an evaluator, which basically takes

76
00:04:02,190 --> 00:04:06,870
the input or the feedback that the
user has provided and take the elements

77
00:04:06,870 --> 00:04:11,640
out of it and compress reliability,
productivity, and positive energy,

78
00:04:11,730 --> 00:04:13,200
and break that between quantify.

79
00:04:13,700 --> 00:04:15,530
Next, you provide an action.

80
00:04:16,025 --> 00:04:20,485
So you basically tell the AI how it
needs to do the task, and you provide

81
00:04:20,485 --> 00:04:22,015
the positive and negative cases.

82
00:04:22,285 --> 00:04:26,515
So in our case, we had three
categories, and if the comments were

83
00:04:26,515 --> 00:04:31,135
not adaptive to the one of these
categories, it would rate it minus one.

84
00:04:32,065 --> 00:04:34,585
So these are some of the
negative cases we had inputted.

85
00:04:35,035 --> 00:04:39,745
So the AI can let us know what
exactly the feedback is referring to.

86
00:04:40,245 --> 00:04:42,105
Next, we provide the variables.

87
00:04:42,795 --> 00:04:47,085
In our case, the variable is just the
feedback that is in input from the user.

88
00:04:47,585 --> 00:04:50,165
And then we also said,
what is the output format?

89
00:04:50,675 --> 00:04:54,335
But we wanted adjacent output
format, which has these three items,

90
00:04:54,965 --> 00:04:56,405
productivity and positive, negative.

91
00:04:56,855 --> 00:05:00,785
And it should have a value between
one to five in negative cases

92
00:05:00,785 --> 00:05:02,075
is going to have a minus one.

93
00:05:02,575 --> 00:05:07,045
Now to do this in Amazon Bedrock, you have
a prompt builder playground, which allows

94
00:05:07,045 --> 00:05:11,215
you to create a prompt and test out all
the different variations of it as well.

95
00:05:11,815 --> 00:05:14,815
So you can set a prompt, you
can set the variables that are

96
00:05:14,815 --> 00:05:16,075
there in the prompt in our case.

97
00:05:16,075 --> 00:05:18,385
That's the feedback,
and you can test it up.

98
00:05:18,885 --> 00:05:22,575
It also allows you to create different
variants of your prompt so you can see

99
00:05:22,935 --> 00:05:25,065
which prompt is working best for you.

100
00:05:25,335 --> 00:05:27,885
You can test it out against the
same model, or you can test it

101
00:05:27,885 --> 00:05:30,375
out against different models
based on your requirement.

102
00:05:30,875 --> 00:05:34,945
Now, if you look at this example on
the left side of the screen, we are

103
00:05:34,945 --> 00:05:38,455
asking the prompt to be lenient with
the ratings, and on the right side,

104
00:05:38,455 --> 00:05:39,535
we are asking you to be respect.

105
00:05:40,035 --> 00:05:45,045
It is just this one small line of
difference which affects the output a lot.

106
00:05:45,545 --> 00:05:48,215
You can see the responses
that is coming from the ai.

107
00:05:48,305 --> 00:05:51,515
It's the same model, but there's
only one line of difference.

108
00:05:51,905 --> 00:05:55,895
This is how you experiment with your
prompts on different types and see which

109
00:05:55,895 --> 00:05:57,425
is the best prompt that works for you.

110
00:05:57,925 --> 00:06:02,155
Now with all this being done, we
created a chat bot interface where the

111
00:06:02,155 --> 00:06:06,775
user can, provide the input, provide
the feedback, and three months go by.

112
00:06:07,275 --> 00:06:08,385
We have a lot of data.

113
00:06:08,385 --> 00:06:11,415
We have about 500 feedbacks
across the organization.

114
00:06:12,015 --> 00:06:17,295
Now we start to think what we can do,
with this data, can we make it more

115
00:06:17,295 --> 00:06:23,055
insightful to the user or to the people
so they can start improving on themselves?

116
00:06:23,555 --> 00:06:27,185
And that is when we started looking
into vector databases and drag.

117
00:06:27,905 --> 00:06:32,105
Before we jump into what we did with the
application, let's go through some basics.

118
00:06:32,605 --> 00:06:33,535
What is a vector?

119
00:06:33,715 --> 00:06:37,735
A vector is basically a mathematical
representation of the data

120
00:06:37,795 --> 00:06:39,145
that you have provided to it.

121
00:06:39,385 --> 00:06:43,135
So it's basically an array
of numbers to oversimplified.

122
00:06:43,635 --> 00:06:48,135
A dimension is the property of
the data that you're providing.

123
00:06:48,224 --> 00:06:53,385
So let's say we are providing fruit,
which is apple or a fruit that

124
00:06:53,385 --> 00:06:56,624
is orange, and this for different
properties, like what is the color?

125
00:06:56,624 --> 00:06:57,554
What is this sweetness?

126
00:06:57,554 --> 00:06:58,395
What is the sadness?

127
00:06:59,084 --> 00:07:03,395
All these becomes, each, becomes
one of the dimensions, which is

128
00:07:03,395 --> 00:07:07,025
basically a characteristic of
the data that you're providing.

129
00:07:07,525 --> 00:07:08,755
And what are indexes?

130
00:07:09,025 --> 00:07:12,145
Indexes are the entry
points for your database.

131
00:07:12,145 --> 00:07:13,765
So it can search a process.

132
00:07:13,795 --> 00:07:18,415
So let's say you have an index for
fruits, and when you provide the input,

133
00:07:18,445 --> 00:07:22,284
it's going to search on these indexes
and find out what you're looking for.

134
00:07:22,784 --> 00:07:24,349
Okay, now what is embedding?

135
00:07:24,829 --> 00:07:29,270
Embedding is basically the process
where your raw data with j text or

136
00:07:29,270 --> 00:07:34,280
any kind of data is taken, converted
into vectors and stored into the

137
00:07:34,280 --> 00:07:36,229
databases, into the right indexes.

138
00:07:36,799 --> 00:07:39,319
This entire process is called embedding.

139
00:07:39,819 --> 00:07:40,719
And what is rag?

140
00:07:41,199 --> 00:07:45,569
So basically when you ask a question
like list some red colored fruits, AI

141
00:07:45,569 --> 00:07:49,859
understands what is the intent of your
question and creates a vector out of it.

142
00:07:50,359 --> 00:07:55,609
Now that vector is used against the
indexes that got created and it does the

143
00:07:55,609 --> 00:07:59,239
nearest neighbor search, or there are
multiple search patterns, but nearest

144
00:07:59,239 --> 00:08:04,419
neighbor search is the most popular one,
and it identifies the data that you're

145
00:08:04,419 --> 00:08:06,579
looking for and provides the response.

146
00:08:06,729 --> 00:08:10,074
In this case, it will take that and
provide the first what has happened.

147
00:08:10,574 --> 00:08:16,034
So if you were to do it in Amazon Bedrock,
there's a very easy way to get started.

148
00:08:16,244 --> 00:08:19,154
You can start with something called,
let's chat with the document.

149
00:08:19,634 --> 00:08:24,375
So Bedrock has this, functionality called
knowledge Basis, and over there you can

150
00:08:24,434 --> 00:08:26,265
create different knowledge basis or all.

151
00:08:26,265 --> 00:08:28,640
You can start with the easy one,
with the chat, we can talk about.

152
00:08:29,140 --> 00:08:33,219
As it sounds, you just upload
a document in the portal and

153
00:08:33,219 --> 00:08:34,809
you can start chatting with it.

154
00:08:34,869 --> 00:08:36,489
It gives you a nice chat interface.

155
00:08:36,729 --> 00:08:40,299
You can provide a custom prompt if
you want, but that's basically it.

156
00:08:40,299 --> 00:08:42,999
You just upload a file and
ask questions on that file.

157
00:08:43,499 --> 00:08:46,439
Now to create your own database,
there are multiple options.

158
00:08:46,859 --> 00:08:50,789
So firstly, you can create a knowledge
base with a vector store, which is

159
00:08:50,789 --> 00:08:54,689
the most common pattern, but with
the recent reinvent announcements.

160
00:08:55,454 --> 00:08:57,194
They also improve these functionalities.

161
00:08:57,254 --> 00:09:00,974
So now you can create a knowledge
base with structured data stores

162
00:09:01,034 --> 00:09:04,214
like Amazon Redshift, which is
the data warehousing solution.

163
00:09:04,514 --> 00:09:08,234
Or you can also create them
on Berra Gen AI based indexes.

164
00:09:08,624 --> 00:09:11,864
So for our use case, we started with the
simple one, which is the vector store.

165
00:09:12,364 --> 00:09:15,554
So the way you do it is
you provide a data source.

166
00:09:15,854 --> 00:09:17,504
So in our case, we use S3.

167
00:09:17,774 --> 00:09:21,554
So all the feedbacks that we got from
the users, we started uploading them

168
00:09:21,554 --> 00:09:26,204
into S3 bucket, and that's the source
that we provided for the knowledge base.

169
00:09:26,704 --> 00:09:29,404
Next, you have to select
the parsing strategy.

170
00:09:29,974 --> 00:09:31,924
Now, what is the passing strategy?

171
00:09:32,524 --> 00:09:37,764
If you're using, I mean if your
data consists of J text or simple

172
00:09:38,244 --> 00:09:42,954
data, then the default Amazon
bedrock parcel is good enough.

173
00:09:43,314 --> 00:09:47,254
But if your data is complicated, like
it has some kind of media content,

174
00:09:47,284 --> 00:09:51,364
images, videos, audio, anything like
that, then you probably need to use

175
00:09:51,424 --> 00:09:53,854
another model to do the parceling.

176
00:09:54,354 --> 00:09:56,755
For our use case, we
use the default parcel.

177
00:09:57,714 --> 00:09:59,214
Next comes the chunking.

178
00:09:59,665 --> 00:10:03,535
Chunking is basically a way of
splitting your data into si, into

179
00:10:03,535 --> 00:10:06,814
smaller, in smaller sizes and
get it stored in the database.

180
00:10:06,935 --> 00:10:09,974
Think of it like a record that you
do in a regular database, except

181
00:10:09,974 --> 00:10:13,964
that one chunk is stored in a
particular data vector database.

182
00:10:14,624 --> 00:10:17,144
So this is very important.

183
00:10:17,234 --> 00:10:19,124
So here's what happened in our case.

184
00:10:19,574 --> 00:10:21,374
So we started with default chunking.

185
00:10:21,644 --> 00:10:26,404
So we selected default chunking, gave
the S3 file, S3, market as a source.

186
00:10:26,905 --> 00:10:27,844
It did the chunking.

187
00:10:28,069 --> 00:10:31,620
And when we asked the question, can
you provide, feedbacks about this

188
00:10:31,620 --> 00:10:35,580
user, it did provide the feedback
and it did summarize it really well.

189
00:10:36,480 --> 00:10:40,350
But the problem is it summarized
the feedback across all the users.

190
00:10:40,650 --> 00:10:44,490
So if I'm asking feedback for
Sandeep, instead of giving just my

191
00:10:44,490 --> 00:10:47,460
feedback, it was giving feedback
for everybody else as well.

192
00:10:48,390 --> 00:10:51,480
And that's when we understood
that the default chunking that

193
00:10:51,540 --> 00:10:53,040
we're using is not working out.

194
00:10:53,550 --> 00:10:58,140
And then we tried our different options
and eventually ended up with no chunking.

195
00:10:58,590 --> 00:11:02,100
So when you select no chunking,
what happens is that every single

196
00:11:02,100 --> 00:11:05,940
file you provide in the S3 bucket
is considered as one single chunk.

197
00:11:06,270 --> 00:11:12,510
So my file basically becomes one single
chunk and everybody else is as well.

198
00:11:12,600 --> 00:11:15,510
So now when I ask the
question about my feedbacks.

199
00:11:16,020 --> 00:11:21,230
It'll query only my set of
feedbacks and summarize and answer

200
00:11:21,230 --> 00:11:22,580
the question that I'm asking for.

201
00:11:23,080 --> 00:11:27,599
Now, if you want some advanced
chunking strategies, which none of

202
00:11:27,660 --> 00:11:31,949
the current ones fit, you can also use
a Lambda function to do some kind of

203
00:11:31,949 --> 00:11:36,125
custom parsing and add your own logic
on how you want to on these files.

204
00:11:36,625 --> 00:11:38,625
Next, you select the embedding model.

205
00:11:38,805 --> 00:11:42,405
So like I said, your data needs
to be converted into vectors, and

206
00:11:42,405 --> 00:11:44,145
that is done by an embedding model.

207
00:11:44,775 --> 00:11:48,045
In our case, we use the Titan
Embeddings, but there are other

208
00:11:48,045 --> 00:11:49,215
offerings available as well.

209
00:11:49,665 --> 00:11:52,065
Now, when you select the
embedding, have a look at the

210
00:11:52,065 --> 00:11:53,565
vector dimensions that it creates.

211
00:11:53,715 --> 00:11:58,575
So in this case, the Titan Membranes
creates thousand 536 dimensions.

212
00:11:58,905 --> 00:12:04,635
So every single piece of data that you
provide is split in 2,536 dimensions,

213
00:12:04,815 --> 00:12:09,375
each of them having its own properties,
which signify a particular characteristic

214
00:12:09,375 --> 00:12:10,965
of the data that you're providing.

215
00:12:11,465 --> 00:12:14,735
Next, you select the vector
database that you want to create.

216
00:12:15,545 --> 00:12:17,610
Now, AWS has made it easy.

217
00:12:18,110 --> 00:12:22,730
You can just select a quick create
and it creates a database for you.

218
00:12:22,730 --> 00:12:22,850
There's.

219
00:12:23,350 --> 00:12:27,280
You don't have to configure much,
but if you're already an advanced

220
00:12:27,280 --> 00:12:30,460
user, you can select a vector
database that you have created by

221
00:12:30,460 --> 00:12:34,095
yourself and provide the specific
information that it is working for.

222
00:12:34,595 --> 00:12:38,495
So when you select the, quick create,
there are a couple of options.

223
00:12:38,645 --> 00:12:44,245
So Amazon Open Search is the default
or the most widely used vector store,

224
00:12:44,605 --> 00:12:46,645
but with the recent announcements.

225
00:12:47,145 --> 00:12:52,125
There is also support added for
Postgres SQ and Amazon Neptune, which

226
00:12:52,125 --> 00:12:56,960
is a high-end analytical database,
which, you can run graph queries.

227
00:12:57,260 --> 00:13:00,080
Graph queries is more,
is like an advanced rag.

228
00:13:00,500 --> 00:13:04,280
so RAG does relationships on one
level graph, does it on two levels.

229
00:13:04,310 --> 00:13:07,040
So that's the simplified version of it.

230
00:13:07,880 --> 00:13:11,420
So for our use case, we started
testing out with open set serverless.

231
00:13:11,920 --> 00:13:16,450
So once you select, if you want to create
your own vector databases, these are

232
00:13:16,450 --> 00:13:18,250
the options that are available for you.

233
00:13:18,750 --> 00:13:22,720
So once you select the database, on a
quick create, all you have to do is click

234
00:13:22,720 --> 00:13:25,180
next and your data source is created.

235
00:13:25,600 --> 00:13:29,530
Now, after the data source is created,
you need to do something called as synced.

236
00:13:29,830 --> 00:13:31,210
So that's when.

237
00:13:31,710 --> 00:13:35,550
Amazon Bedrock actually takes the
file from S3, creates the embed

238
00:13:35,820 --> 00:13:37,590
and stores it into the database.

239
00:13:38,130 --> 00:13:42,080
Once that is done, now we can
start, querying your database.

240
00:13:42,860 --> 00:13:48,720
Now there are multiple search options that
are available by default hybrid, search

241
00:13:48,720 --> 00:13:54,330
work for us because it searches both on
semantic and on text, but it's again,

242
00:13:54,330 --> 00:13:56,730
left to you based on your data choice.

243
00:13:57,230 --> 00:13:59,150
Next comes the number of source chunks.

244
00:13:59,300 --> 00:14:01,550
So our use case was very specific.

245
00:14:01,970 --> 00:14:06,110
We want only one particular file for
one user, so the number of chunks it

246
00:14:06,110 --> 00:14:09,890
had to return is only one, but based
on your use case, you can increase

247
00:14:09,890 --> 00:14:13,600
it to up to a hundred and, retrieve
the data that you are looking for.

248
00:14:14,100 --> 00:14:19,030
And then you select the model that,
you want to run the database on Next.

249
00:14:19,530 --> 00:14:22,530
Knowledge base also has a custom
prompt that you can provide.

250
00:14:23,055 --> 00:14:26,295
So by default when you're trying
to query a knowledge base, there's

251
00:14:26,295 --> 00:14:28,065
an buil prompt that Amazon use us.

252
00:14:28,565 --> 00:14:32,435
For some reason, if that doesn't work
out for you and you want to, tell

253
00:14:32,435 --> 00:14:36,995
the knowledge base how it needs to
query the database, you can do that.

254
00:14:37,025 --> 00:14:41,105
You can provide a custom prompt where
you mention or you give a prompt,

255
00:14:41,465 --> 00:14:45,185
which says how the data needs to be
understood and what kind of questions

256
00:14:45,185 --> 00:14:48,875
the users are asking for, and, to make
more context out of it and give you

257
00:14:48,875 --> 00:14:51,395
the best or most relevant answers.

258
00:14:51,895 --> 00:14:53,905
So this is what the result looks like.

259
00:14:54,835 --> 00:14:57,155
So our queries, have two things.

260
00:14:57,215 --> 00:14:58,235
Email and query.

261
00:14:58,685 --> 00:15:02,015
Email is who's requesting
it and what is the query.

262
00:15:02,645 --> 00:15:06,815
So let's say in this case,
manic is asking, provide my top

263
00:15:06,965 --> 00:15:08,555
three points of improvements.

264
00:15:08,705 --> 00:15:14,255
So what this does is it takes monk's
file, which has all the feedbacks that

265
00:15:14,255 --> 00:15:19,565
he has received so far, identifies
the intent of the question, summarizes

266
00:15:19,565 --> 00:15:21,275
all of them, and gives the feedback.

267
00:15:21,775 --> 00:15:23,005
Same with the next user.

268
00:15:23,875 --> 00:15:26,965
We provide the email ID and
ask for the say, points of

269
00:15:26,965 --> 00:15:28,705
improvement and things like that.

270
00:15:29,245 --> 00:15:32,685
So it is going to take the feedbacks
that I have received, and it's going

271
00:15:32,685 --> 00:15:35,835
to summarize that based on the question
that it is that you have asked.

272
00:15:36,335 --> 00:15:38,165
Now with all this in place.

273
00:15:38,630 --> 00:15:41,120
We enable this chat bot for.

274
00:15:42,050 --> 00:15:46,760
So as an admin, I can query other people's
feedback to understand how they're doing,

275
00:15:47,120 --> 00:15:49,100
what improvement points I need to do on.

276
00:15:49,430 --> 00:15:52,970
So this essentially started as
a mentor mentee relationship.

277
00:15:53,180 --> 00:15:57,230
So I. What we started doing is
as mentors, we would query our

278
00:15:57,290 --> 00:16:00,650
mentee's feedbacks and ask questions
like, what, how are they doing?

279
00:16:00,740 --> 00:16:02,570
Or, what are the things that
they need to improve on?

280
00:16:03,140 --> 00:16:07,250
And then we get a summarize result based
on what everybody has said for them.

281
00:16:07,730 --> 00:16:11,360
And we take those points and
start guiding the mentee on how

282
00:16:11,360 --> 00:16:12,530
they should improve themselves.

283
00:16:12,860 --> 00:16:14,060
So this is how it started.

284
00:16:14,780 --> 00:16:18,950
And then we thought, why not just sustain,
enable it to the users themselves?

285
00:16:19,450 --> 00:16:24,310
Then they can ask questions and see how
they're doing and they can improve it.

286
00:16:24,760 --> 00:16:26,170
They can improve themselves.

287
00:16:26,500 --> 00:16:30,590
They don't, we don't need to have
this, feedback sessions every time.

288
00:16:30,980 --> 00:16:35,480
They can query the question whenever
they want and work on the points

289
00:16:35,480 --> 00:16:36,590
that they need to improve on.

290
00:16:37,550 --> 00:16:38,870
But there was one cache for this.

291
00:16:39,560 --> 00:16:44,300
The current chat bot, allows anybody
to request anybody else's feedback.

292
00:16:44,800 --> 00:16:47,530
So that's when we started
looking at agents.

293
00:16:47,800 --> 00:16:53,290
So, as an oversimplification, an agent
is basically a custom functionality

294
00:16:53,290 --> 00:16:57,790
that you want to put in, to the thought
to, to the thought process of an ai.

295
00:16:58,690 --> 00:17:03,370
So in Amazon Bedrock, you have, agents
where you can create your agent,

296
00:17:03,490 --> 00:17:05,110
specific agent that you're looking for.

297
00:17:05,110 --> 00:17:07,180
Select the model that it needs to run on.

298
00:17:07,780 --> 00:17:12,750
And the beauty of it is the actual
agent interception that happens inside

299
00:17:12,810 --> 00:17:16,610
an AWS Lambda, which is a serverless
component, and you can create

300
00:17:16,640 --> 00:17:22,200
multiple agents for the same, multiple
lambdas to be used in the same agent.

301
00:17:22,290 --> 00:17:25,080
And you can change them all using
the prompt that you're writing.

302
00:17:25,740 --> 00:17:29,340
So when you create the agent, you provide
the prompt, it says how it needs to

303
00:17:29,340 --> 00:17:32,670
interact with these agents to provide
the response that you're looking for.

304
00:17:33,300 --> 00:17:34,980
But in our case, it's
very straightforward.

305
00:17:35,880 --> 00:17:39,690
So we are telling the AI agent, you
are going to receive a query, and

306
00:17:39,690 --> 00:17:41,040
this is the flow you need to follow.

307
00:17:41,610 --> 00:17:46,260
Your flow is identify the user
ebit, identify what sort of

308
00:17:46,260 --> 00:17:47,370
question they're asking for.

309
00:17:47,430 --> 00:17:51,060
Is it a question for themself, or they're
asking the question for other users.

310
00:17:51,060 --> 00:17:55,280
So create these two inputs
and call an action group.

311
00:17:55,430 --> 00:17:58,580
So action group is basically
that it needs to invoke a lambda.

312
00:17:58,985 --> 00:18:03,515
So this Lambda is going to get these
two inputs, which is the email and

313
00:18:03,515 --> 00:18:05,135
what kind of query they're asking for.

314
00:18:05,525 --> 00:18:08,975
Inside the Lambda, we are calling a
database, which is having the list

315
00:18:08,975 --> 00:18:11,045
of admin users and regular users.

316
00:18:11,885 --> 00:18:15,755
Now, if the question is by an
admin, we allow the request.

317
00:18:16,055 --> 00:18:20,795
But if a user, regular user is asking
a question for other people's feedback.

318
00:18:21,155 --> 00:18:24,695
We deny the request and we have
instructed the agent in such a way

319
00:18:24,695 --> 00:18:29,315
that based on the response it receives
from the action group, it should either

320
00:18:29,405 --> 00:18:31,535
allow the request or deny the request.

321
00:18:32,405 --> 00:18:35,255
So when you create the agent,
the first thing you do is provide

322
00:18:35,255 --> 00:18:36,365
instructions to the agent.

323
00:18:37,235 --> 00:18:42,815
And you can also enable memory by default,
it is disabled, but, if you want to have

324
00:18:42,815 --> 00:18:46,920
consistent or sessions, you can enable
the memory and consume it accordingly.

325
00:18:47,420 --> 00:18:49,130
Next you create the action groups.

326
00:18:49,280 --> 00:18:53,240
The action groups are basically a bunch of
lambdas, and, you provide the name of the

327
00:18:53,240 --> 00:18:57,650
action group in the instruction that you
write for the agent and tell what it needs

328
00:18:57,650 --> 00:18:59,630
to do or how it needs to call this action.

329
00:18:59,630 --> 00:19:03,580
And what, what is the next
action that it needs to take.

330
00:19:04,080 --> 00:19:07,105
Apart from this, to a agent.

331
00:19:07,105 --> 00:19:10,285
You can also provide the knowledge
basis, so the knowledge base

332
00:19:10,285 --> 00:19:11,425
that we created previously.

333
00:19:12,160 --> 00:19:16,660
You can add them over here, and now
the agent has access to the know

334
00:19:16,720 --> 00:19:18,220
action groups and the knowledge base.

335
00:19:18,580 --> 00:19:23,140
So you can basically tell it, take these
three actions, query this knowledge

336
00:19:23,140 --> 00:19:25,600
base, and then call another action.

337
00:19:25,870 --> 00:19:29,680
But anything that you want based on the
workflow that you're looking for, can be

338
00:19:29,710 --> 00:19:35,020
done by using action groups and knowledge
bases in conjunction with N Agent.

339
00:19:35,520 --> 00:19:38,010
So this is how we define an action group.

340
00:19:38,250 --> 00:19:40,320
You start by giving a name.

341
00:19:40,560 --> 00:19:44,520
You select some basic parameters,
and you create the Lambda.

342
00:19:45,210 --> 00:19:47,130
Now this is the beauty of it.

343
00:19:47,190 --> 00:19:51,690
So here I'm specifying two
parameters, query type, and email.

344
00:19:52,665 --> 00:19:58,405
In my prompt, I have mentioned the
instructions that it needs to make these

345
00:19:58,405 --> 00:20:02,815
two parameters or identify these two
parameters and then call the action loop.

346
00:20:03,295 --> 00:20:07,465
So when the lambda is invo, it is always
going to get these two parameters.

347
00:20:07,965 --> 00:20:10,635
Now, this is how the Lambda
looks like, is just simple.

348
00:20:10,915 --> 00:20:11,275
code.

349
00:20:11,755 --> 00:20:15,595
We are just having a list of admin
users and, when the input comes in, we

350
00:20:15,595 --> 00:20:16,975
are just sticking against that list.

351
00:20:17,125 --> 00:20:18,955
If it's an admin, allow the request.

352
00:20:18,955 --> 00:20:22,405
If it's not, you're just going to
throw a response telling you're

353
00:20:22,405 --> 00:20:23,965
not authorized to run this query.

354
00:20:24,505 --> 00:20:28,225
And then the agent takes this
response and, summarizes that and

355
00:20:28,230 --> 00:20:29,575
provides it to the end percent.

356
00:20:30,075 --> 00:20:31,695
And this is how it looks like.

357
00:20:31,975 --> 00:20:36,275
In the first one, the email is random
at anstat io, which is obviously

358
00:20:36,275 --> 00:20:40,165
a fake email, and the query is
list Sandeep's, top feedbacks.

359
00:20:40,255 --> 00:20:45,325
So basically some other person is
asking my feedback and obviously

360
00:20:45,325 --> 00:20:47,335
random is not part of admin's group.

361
00:20:47,725 --> 00:20:53,125
So the agent is going to respond, telling
you don't have access to run this query.

362
00:20:53,625 --> 00:20:58,485
In the next scenario, I, the email
is sand t io, which is my email id.

363
00:20:58,950 --> 00:21:00,810
And I'm querying my feedbacks.

364
00:21:00,870 --> 00:21:03,540
just list my feedback and summarize it.

365
00:21:03,540 --> 00:21:09,660
Integrate 20 words, and of course the AI
is going to query the knowledge base and

366
00:21:09,660 --> 00:21:11,340
provide the result for it accordingly.

367
00:21:11,840 --> 00:21:15,870
Now, once we added this functionality,
once we are able to segregate the

368
00:21:15,870 --> 00:21:20,190
queries between what a user is asking
and what an admin is asking, we

369
00:21:20,190 --> 00:21:22,710
enable that chatbot to all the users.

370
00:21:23,260 --> 00:21:28,270
everybody could look at their queries,
ask questions about how they can improve

371
00:21:28,270 --> 00:21:33,040
themselves, or what are the more three
positive comments, what are the negative

372
00:21:33,040 --> 00:21:37,750
comments, and, get a dynamic of how
they're doing and move forward with that.

373
00:21:38,250 --> 00:21:42,810
At this point, we wanted to see what
we can do more, what we can push the

374
00:21:42,810 --> 00:21:48,325
system to do more, and that's when we
started looking into an ambitious plan.

375
00:21:48,825 --> 00:21:54,565
What we wanted to do was, we had the
skill assessments for each of these users.

376
00:21:55,525 --> 00:21:59,605
so we wanted to see if we can integrate
all of that into one platform.

377
00:22:00,055 --> 00:22:04,225
And at the end of it, if a user
is going to ask a question,

378
00:22:04,325 --> 00:22:05,465
how can I improve my career?

379
00:22:05,465 --> 00:22:10,045
Improve, we take the information
of what the feedback, of all the

380
00:22:10,045 --> 00:22:11,490
feedbacks that user has received.

381
00:22:11,995 --> 00:22:13,285
We take their skill sheets.

382
00:22:13,870 --> 00:22:17,800
We take their current role designations,
what is their next role designation?

383
00:22:18,220 --> 00:22:21,970
Summarize all of this and
point the user into the right

384
00:22:21,970 --> 00:22:23,740
direction to get their promotion.

385
00:22:24,610 --> 00:22:25,690
Imagine doing this.

386
00:22:25,930 --> 00:22:30,490
You don't have to sit on, on a
call with your boss at the end

387
00:22:30,490 --> 00:22:33,700
of a year to know whether you're
going to get the promotion or not.

388
00:22:34,420 --> 00:22:39,400
You can query this chat bot, say once in
three months or once in a month, and see.

389
00:22:40,060 --> 00:22:43,090
What you required to do
to get that promotion.

390
00:22:43,590 --> 00:22:45,670
We call this section, divide and Concur.

391
00:22:46,240 --> 00:22:52,500
So you can do all these things in a
single prompt or a single agent, but it

392
00:22:52,500 --> 00:22:55,110
gets the system complicated every time.

393
00:22:55,530 --> 00:22:59,070
you write a prompt, which has
multiple things, multiple steps to

394
00:22:59,070 --> 00:23:02,310
do, the AI becomes in such a system.

395
00:23:02,810 --> 00:23:07,370
That's why we call this divide and
conquer, where we split the execution or

396
00:23:07,370 --> 00:23:12,410
split the functionalities into smaller
AI chunks and consume it that way.

397
00:23:13,250 --> 00:23:18,020
So Amazon Bedrock has a beautiful
way with, let's just do this.

398
00:23:18,740 --> 00:23:19,895
They're called pro flows.

399
00:23:20,315 --> 00:23:23,550
So pro flows are basically, if
you're aware about step functions,

400
00:23:23,550 --> 00:23:25,230
is basically a step function for ai.

401
00:23:26,160 --> 00:23:32,280
It allows you to create different
prompts and, in Lambdas S3 downloads,

402
00:23:32,340 --> 00:23:37,500
knowledge basis, agency, all these
things, and it allows you to create a

403
00:23:37,560 --> 00:23:42,930
map out of it or a workflow out of it
and lets you take the action that way.

404
00:23:43,530 --> 00:23:46,710
So in our case, we split the
entire functionality that we

405
00:23:46,710 --> 00:23:49,890
wanted into smaller pieces, which
allows us to give more control.

406
00:23:50,250 --> 00:23:53,610
The other advantage you get by
doing this is each of these chunk.

407
00:23:54,015 --> 00:23:57,045
You can have a different AI
to do that particular thing.

408
00:23:57,135 --> 00:24:00,645
So if you're having some small
classification that needs to be done,

409
00:24:00,915 --> 00:24:06,405
you don't need to run a CLO 3.5 or a CLO
3.7, you might as well just run a smaller

410
00:24:06,405 --> 00:24:08,115
model, which is more cost efficient.

411
00:24:08,325 --> 00:24:12,015
It might take a little bit longer time,
but it is way more cost effective than

412
00:24:12,015 --> 00:24:14,055
using a very large, expensive model.

413
00:24:14,805 --> 00:24:15,645
But this is what we did.

414
00:24:16,005 --> 00:24:21,075
So our first step is a prompt, which
is to identify the intent of the user.

415
00:24:21,720 --> 00:24:27,210
So this prompt just identifies who
is the user and whether the question

416
00:24:27,210 --> 00:24:32,600
is for them or for somebody else, and
then it passes on to a Lambda, which

417
00:24:32,600 --> 00:24:34,280
does the role check for the user.

418
00:24:34,400 --> 00:24:37,705
So this lambda is connected to a
database which has the list of admins.

419
00:24:38,435 --> 00:24:39,605
And the regular users.

420
00:24:39,755 --> 00:24:42,545
So based on the input that it's
getting, it's going to identify

421
00:24:42,605 --> 00:24:46,825
whether the question is, from an
admin or a user, or whether they're

422
00:24:46,825 --> 00:24:50,635
asking for themself or for others,
and, provide the response accordingly.

423
00:24:51,135 --> 00:24:52,935
And then it goes into a condition block.

424
00:24:53,265 --> 00:24:57,015
In this condition, it checks the output
that is received from the Lambda.

425
00:24:57,135 --> 00:25:02,025
So in the Lambda, we say next step is
proceed, or next step is n. But based on

426
00:25:02,025 --> 00:25:04,635
this, it is going to take the next action.

427
00:25:04,755 --> 00:25:09,645
If the action is to end the execution,
we have, it moves to a flow output, which

428
00:25:09,645 --> 00:25:12,015
is basically the end of the prompt flow.

429
00:25:12,855 --> 00:25:16,395
If it's not, then it goes
into classified cushion.

430
00:25:16,845 --> 00:25:18,370
Now, this is where the beauty comes in.

431
00:25:18,870 --> 00:25:22,860
So we wanted to enable the chat
bot to do much more than just

432
00:25:23,010 --> 00:25:24,300
summarize feedbacks, right?

433
00:25:24,480 --> 00:25:29,850
So this classified question identifies
what kind of question the user is asking.

434
00:25:30,090 --> 00:25:34,770
Is that a question about their
feedbacks or is it a question about

435
00:25:34,770 --> 00:25:36,930
their overall career at the company?

436
00:25:37,560 --> 00:25:40,350
So based on this, it is
going to take the next steps.

437
00:25:40,410 --> 00:25:44,640
So after classifying this information,
it is going to call the knowledge base.

438
00:25:44,730 --> 00:25:48,570
So the knowledge base has the
information of all the feedbacks

439
00:25:48,570 --> 00:25:49,650
that the union has received.

440
00:25:50,490 --> 00:25:54,330
So irrespective of whether a question
is about their career or whether the

441
00:25:54,330 --> 00:25:57,840
question is about their feedbacks,
we need to query this knowledge

442
00:25:57,840 --> 00:25:59,610
base to summarize the feedbacks.

443
00:26:00,110 --> 00:26:03,560
After getting this information,
it goes into this lambda,

444
00:26:03,680 --> 00:26:04,640
which is called Data enricher.

445
00:26:05,540 --> 00:26:08,750
Which gets the intent of the question.

446
00:26:09,080 --> 00:26:12,630
And, whether it is a question about their
career or whether it's a question about

447
00:26:12,630 --> 00:26:17,550
the knowledge, feedbacks and it also
gets the output from the knowledge base.

448
00:26:17,550 --> 00:26:20,190
So everything that the knowledge
base is summarized and the

449
00:26:20,190 --> 00:26:21,390
raw data it gets offered.

450
00:26:22,380 --> 00:26:23,365
Now this lambda.

451
00:26:24,030 --> 00:26:29,000
Based on the, intent of the user, it is
going to query multiple other sources.

452
00:26:29,330 --> 00:26:33,550
The other sources is going to query
is our classification of, user roles.

453
00:26:33,880 --> 00:26:37,120
Basically, what is their current
designation, what is going to be

454
00:26:37,120 --> 00:26:41,050
the next designation, and it is
going to query their skill sets.

455
00:26:41,320 --> 00:26:44,650
What are the skills that they
have and to move to the next role.

456
00:26:44,830 --> 00:26:50,020
What are all skills they need to have as a
mandatory and inform It gets all this data

457
00:26:50,020 --> 00:26:51,940
from multiple sources that we have stored.

458
00:26:52,440 --> 00:26:56,850
And it combines all this information
and sends it to the final prompt.

459
00:26:57,000 --> 00:27:01,530
So this is the summarizer prompt, which
basically takes the input of all the

460
00:27:01,740 --> 00:27:06,660
data that we have received so far with
the user question and so on, and then

461
00:27:06,660 --> 00:27:12,120
it summarizes all of this and provides a
neat response to the user where the user

462
00:27:12,120 --> 00:27:14,710
can, use this bot to help themselves out.

463
00:27:15,210 --> 00:27:16,320
So this is what it looked like.

464
00:27:16,740 --> 00:27:20,380
So let's say, the user is asking
a question about somebody else and

465
00:27:20,380 --> 00:27:25,300
there's a regular user, the execution
fails, we throw a unauthorized error.

466
00:27:26,200 --> 00:27:29,430
Next, a user is asking a
question about their feedback.

467
00:27:29,820 --> 00:27:34,620
So it queries the knowledge base, it
doesn't query the role, it doesn't query

468
00:27:34,680 --> 00:27:36,680
the, skill sheets or anything like that.

469
00:27:36,920 --> 00:27:38,730
Just plain, feedback summary.

470
00:27:39,230 --> 00:27:40,580
And this is the interesting part.

471
00:27:40,730 --> 00:27:41,420
So in this.

472
00:27:42,230 --> 00:27:43,100
Particular query.

473
00:27:43,100 --> 00:27:45,920
The user is asking how
to improve my career.

474
00:27:46,160 --> 00:27:47,270
What are my setbacks?

475
00:27:47,990 --> 00:27:53,110
So we query feedbacks, we query
this person's skill sheets,

476
00:27:53,110 --> 00:27:55,930
we query this person's current
role, what is the next role?

477
00:27:56,440 --> 00:27:58,210
And summarize all that information.

478
00:27:58,990 --> 00:28:03,400
And this is how the AI response,
it provides the strengths based on

479
00:28:03,400 --> 00:28:07,660
all this information and based on
what people have said is going to

480
00:28:07,660 --> 00:28:09,370
provide the areas of improvement.

481
00:28:09,870 --> 00:28:14,940
It also says to get your next,
promotion what you need to do.

482
00:28:15,490 --> 00:28:19,120
and it's not just some,
random information.

483
00:28:19,300 --> 00:28:22,810
All of this is accumulated out of
the feedbacks that this person has

484
00:28:22,810 --> 00:28:27,310
received and the expectations that
we have set for a particular role.

485
00:28:27,850 --> 00:28:32,110
So if you take these points
seriously, then you will improve in

486
00:28:32,110 --> 00:28:35,140
your career and you will be in the
right track for the next promotions.

487
00:28:35,640 --> 00:28:39,330
Another nice thing note about
this is the query also asks, what

488
00:28:39,330 --> 00:28:41,970
are my setbacks for this user?

489
00:28:42,120 --> 00:28:45,780
He has not received the feedback,
which is so negative that it has

490
00:28:45,780 --> 00:28:47,220
become a setback in his career.

491
00:28:47,850 --> 00:28:52,710
So the chat bot is going to respond
to, there are no major setbacks.

492
00:28:52,830 --> 00:28:53,760
It is what it is.

493
00:28:54,260 --> 00:28:57,440
So imagine doing this in your company.

494
00:28:57,940 --> 00:29:01,090
You don't have to wait
at the end of the year.

495
00:29:01,615 --> 00:29:04,225
To get to know whether you are
getting the promotion or not.

496
00:29:04,915 --> 00:29:09,535
You can ask a chat bot once in three
months, once in a month, anytime

497
00:29:09,535 --> 00:29:13,725
that is, and see if you're on the
right track to get a promotion.

498
00:29:14,225 --> 00:29:17,885
Imagine how simple your conversation
with your bosses at the end of the year

499
00:29:18,065 --> 00:29:23,525
by looking at these feedback, you can,
you can provide the data to your boss

500
00:29:23,825 --> 00:29:25,385
telling why you need that promotion.

501
00:29:25,885 --> 00:29:27,145
Now coming to the pricing.

502
00:29:27,715 --> 00:29:31,645
So Amazon Bedrock, like any other,
AI provider is charged based on

503
00:29:31,645 --> 00:29:33,055
the number of tokens you consume.

504
00:29:33,390 --> 00:29:35,370
both the input tokens
and the output tokens.

505
00:29:35,880 --> 00:29:40,290
Now, if you're using the knowledge base,
there is no explicit charge for using

506
00:29:40,290 --> 00:29:44,850
the knowledge base, but you're charged
for the underlying vector database

507
00:29:45,120 --> 00:29:47,280
and the queries you run on top of it.

508
00:29:47,400 --> 00:29:50,160
It's basically like you're not
charged for cloud formation, but

509
00:29:50,160 --> 00:29:53,010
you're charged for the resources
that deploys a similar fashion.

510
00:29:53,635 --> 00:29:54,955
Same thing goes with agents.

511
00:29:54,955 --> 00:29:58,495
You're not charged extra for using
the agents, but you're charged for

512
00:29:58,495 --> 00:30:01,765
all the resources you create under,
like the Lambdas, the knowledge

513
00:30:01,765 --> 00:30:05,035
base, and the queries that you
run, how many tokens it consumes.

514
00:30:05,535 --> 00:30:10,105
Now, coming to the time, this is the
most, fascinating part, at least for me.

515
00:30:11,070 --> 00:30:14,100
To build the entire thing I
showed in this presentation.

516
00:30:14,340 --> 00:30:17,460
It takes less than 30 minutes
if you know what you're doing.

517
00:30:17,460 --> 00:30:19,950
It just takes less than 30 minutes.

518
00:30:20,190 --> 00:30:22,920
The first time I did pro
flows and everything else.

519
00:30:23,835 --> 00:30:25,925
The entire time it was
less than two hours.

520
00:30:25,985 --> 00:30:30,455
That is how easy it is to get started
with services like Amazon Bedrock.

521
00:30:30,515 --> 00:30:32,435
It just makes your life so easier.

522
00:30:32,795 --> 00:30:35,765
You don't have to think a
lot on what is happening.

523
00:30:35,945 --> 00:30:39,305
You can just build it, test it,
and then understand what exactly

524
00:30:39,305 --> 00:30:40,535
is happening in the system.

525
00:30:41,035 --> 00:30:42,565
And that's it for my session.

526
00:30:42,625 --> 00:30:43,915
Thank you everyone for joining.

527
00:30:44,245 --> 00:30:48,040
You can reach out to me on LinkedIn,
gi or you can email me at my

528
00:30:48,040 --> 00:30:50,050
official email id Sand patan stack.

529
00:30:50,050 --> 00:30:53,760
I, it's a pleasure meeting you all
and I hope to catch up with you soon.

530
00:30:54,510 --> 00:30:54,815
Thank you everyone.

