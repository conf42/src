1
00:00:00,010 --> 00:00:04,970
Welcome everyone to our presentation
on cloud native ML infrastructure.

2
00:00:05,670 --> 00:00:10,010
Today we will be exploring how
to build resilient Apache Spark

3
00:00:10,030 --> 00:00:15,970
clusters on Kubernetes specifically
designed for AI and ML workloads.

4
00:00:16,920 --> 00:00:22,260
I'm Anant Kumar and I'm excited to
share insights on addressing the

5
00:00:22,260 --> 00:00:27,450
unique challenges of scalability,
resource utilization and operational

6
00:00:27,490 --> 00:00:29,009
complexity in this domain.

7
00:00:29,509 --> 00:00:30,119
Let's begin.

8
00:00:30,619 --> 00:00:34,190
Let's begin by looking at the
evolution of ML infrastructure.

9
00:00:34,800 --> 00:00:42,309
Historically, ML workloads ran on premise,
requiring significant upfront investment

10
00:00:42,339 --> 00:00:44,699
in hardware and ongoing maintenance costs.

11
00:00:45,649 --> 00:00:49,469
This approach limited
scalability and flexibility.

12
00:00:49,969 --> 00:00:53,839
The shift to cloud native
infrastructure has revolutionized

13
00:00:54,169 --> 00:00:58,974
how we handle ML workloads, offering
greater scalability and flexibility.

14
00:00:59,274 --> 00:01:04,704
Flexibility and cost efficiency
through pay as you go models

15
00:01:05,125 --> 00:01:07,134
and dynamic resource allocation.

16
00:01:07,634 --> 00:01:12,184
This evolution has enabled
organizations to experiment more

17
00:01:12,195 --> 00:01:16,004
freely and deploy ML solutions faster.

18
00:01:16,504 --> 00:01:21,934
Despite advances, ML infrastructure
still faces significant challenges.

19
00:01:22,834 --> 00:01:25,664
First, scalability remains difficult.

20
00:01:26,339 --> 00:01:32,269
as ML model and datasets grow
increasingly complex and large.

21
00:01:33,179 --> 00:01:38,639
Second, resource utilization is
often inefficient with compute

22
00:01:38,739 --> 00:01:44,649
resources frequently over present,
over provisioned or underutilized.

23
00:01:45,149 --> 00:01:51,474
And finally, Operational complexity
increases as organizations manage

24
00:01:51,524 --> 00:01:56,334
distributed system spanning multiple
environments and technologies.

25
00:01:56,834 --> 00:02:00,404
These challenges are precisely
what we will address with our

26
00:02:00,414 --> 00:02:02,085
Spark on Kubernetes approach.

27
00:02:02,085 --> 00:02:08,674
Apache Spark has become a cornerstone
technology for ML workloads

28
00:02:08,684 --> 00:02:10,324
for several compelling reasons.

29
00:02:10,824 --> 00:02:16,984
Its distributed processing capabilities
allow for handling massive data

30
00:02:17,004 --> 00:02:19,154
set across clusters of machines.

31
00:02:20,074 --> 00:02:23,284
Essential for training modern ML models.

32
00:02:23,784 --> 00:02:28,534
It's in memory computing provides
speed advantages, critical

33
00:02:28,544 --> 00:02:30,464
for iterative ML algorithms.

34
00:02:30,964 --> 00:02:36,004
And additionally, Spark offers
pre built libraries for common

35
00:02:36,054 --> 00:02:42,114
ML tasks through MLlib, making
implementation More straightforward

36
00:02:42,364 --> 00:02:44,314
and reducing development time.

37
00:02:44,814 --> 00:02:49,764
Kubernetes has emerged as the leading
container orchestration platform,

38
00:02:50,224 --> 00:02:55,704
offering key capabilities that
complement Spark for ML workloads.

39
00:02:56,204 --> 00:03:00,944
Its container orchestration
simplifies deployment and

40
00:03:01,024 --> 00:03:02,834
management of Spark applications.

41
00:03:03,334 --> 00:03:08,284
Its sophisticated resource management
ensure Efficient allocation and

42
00:03:08,294 --> 00:03:10,514
utilization of computer resources.

43
00:03:11,304 --> 00:03:17,464
Perhaps, most importantly, its auto
scaling capabilities allow dynamic

44
00:03:17,464 --> 00:03:21,774
adjustment of resources based
on workload demands, optimizing

45
00:03:21,894 --> 00:03:24,694
both performance and cost.

46
00:03:25,194 --> 00:03:29,184
A comprehensive cloud native
ML architecture consists of

47
00:03:29,714 --> 00:03:31,124
four essential components.

48
00:03:31,714 --> 00:03:39,489
First, Data storage solutions, including
data lakes, object storage, and

49
00:03:39,489 --> 00:03:44,659
databases that provide the foundation
for managing large volume of data.

50
00:03:45,469 --> 00:03:51,369
Second, compute resources like
Kubernetes cluster, virtual machines,

51
00:03:51,629 --> 00:03:54,219
and GPUs that power processing.

52
00:03:54,719 --> 00:03:59,429
Third, ML frameworks such as
Spark, TensorFlow, and Vue.

53
00:03:59,894 --> 00:04:04,524
and PyTorch that provides the tool
for building and training models.

54
00:04:04,914 --> 00:04:10,744
And finally, model serving platforms
that deploy and serve trained

55
00:04:10,754 --> 00:04:13,954
models to end users or applications.

56
00:04:14,454 --> 00:04:19,514
Now, let's examine how Spark operates
within a Kubernetes environment.

57
00:04:20,504 --> 00:04:24,244
Spark applications are
deployed as Kubernetes pods.

58
00:04:24,744 --> 00:04:31,274
With each worker running in its
own pod, these workers communicate

59
00:04:31,334 --> 00:04:36,244
with each other and the master node
to coordinate processing tasks.

60
00:04:36,744 --> 00:04:37,604
Think about it.

61
00:04:38,104 --> 00:04:45,044
Master node is a driver node and these
workers are essentially the executors.

62
00:04:45,544 --> 00:04:51,284
Data is stored and accessed through
persistent volumes, ensuring.

63
00:04:51,769 --> 00:04:57,399
Data remains available even if
ports are rescued or restarted.

64
00:04:57,899 --> 00:05:02,659
This architecture combines Spark's
processing power with Kubernetes

65
00:05:02,739 --> 00:05:04,649
orchestration capabilities.

66
00:05:05,149 --> 00:05:09,879
Effective resource management is
very crucial for Spark on Kubernetes.

67
00:05:10,379 --> 00:05:16,129
We implement this through resource
requests and limits, defining

68
00:05:16,139 --> 00:05:17,469
the minimum resources required.

69
00:05:18,044 --> 00:05:22,014
Each Spark port requires and
the maximum it can consume.

70
00:05:22,514 --> 00:05:27,654
Resource quotas set boundaries on
resource consumption for namespaces,

71
00:05:28,204 --> 00:05:33,484
preventing any single application from
monopolizing the cluster resources.

72
00:05:33,984 --> 00:05:40,294
Node affinity and taints allow us
to assign Spark ports to specific

73
00:05:40,454 --> 00:05:45,604
nodes based on their requirements,
such as placing GPU intensive tasks

74
00:05:45,999 --> 00:05:48,379
on nodes with appropriate hardware.

75
00:05:48,879 --> 00:05:54,139
The Spark Operator simplifies Spark
application management on Kubernetes.

76
00:05:54,639 --> 00:06:00,919
Installation involves deploying the
operator into your Kubernetes cluster,

77
00:06:01,889 --> 00:06:04,859
which can be done via Helm Charts.

78
00:06:05,359 --> 00:06:07,569
Configuration is very simple.

79
00:06:08,489 --> 00:06:11,959
It's require, it requires
setting up the operator.

80
00:06:12,509 --> 00:06:18,499
with appropriate cluster settings and
standard Kubernetes resource limits.

81
00:06:18,999 --> 00:06:24,899
Once deployed, the operator enables
declarative application deployment

82
00:06:25,599 --> 00:06:31,119
through custom resource definition,
which is often abbreviated as CRDs,

83
00:06:32,099 --> 00:06:35,669
streamlining the entire process
of running Spark applications.

84
00:06:36,169 --> 00:06:43,584
You can get and orchestrate the Spark
applications through Spark Operator.

85
00:06:44,084 --> 00:06:50,204
All the CRUD operation can be
implemented through the Spark Operator.

86
00:06:50,854 --> 00:06:56,974
For example, you can create Spark
application, read Spark application,

87
00:06:57,024 --> 00:06:59,084
update Spark application, and delete it.

88
00:06:59,584 --> 00:07:04,154
Dynamic resource allocation is
a key advantage of our approach.

89
00:07:04,654 --> 00:07:07,494
This involves three critical elements.

90
00:07:07,994 --> 00:07:12,704
Resource monitoring to track SPARC
resource consumption in real time.

91
00:07:13,204 --> 00:07:18,014
Dynamic scaling to adjust
resources based on workload demand.

92
00:07:18,514 --> 00:07:23,244
And resource optimization to
ensure efficient utilization.

93
00:07:23,744 --> 00:07:24,374
Together.

94
00:07:25,089 --> 00:07:30,919
These elements create a responsive
system that can scale up during

95
00:07:31,049 --> 00:07:35,919
peak processing needs and scale
down when demand decreases.

96
00:07:36,419 --> 00:07:41,979
This is also help for handling
the bursty traffic and the burst

97
00:07:41,979 --> 00:07:46,359
passes when the workload stabilizes.

98
00:07:46,859 --> 00:07:50,619
This dynamic resource allocation
can help in those scenarios as well.

99
00:07:51,119 --> 00:07:55,449
Autoscaling implementation
focuses on two dimensions.

100
00:07:55,949 --> 00:08:01,289
Horizontal scaling adds or removes
spark worker nodes based on

101
00:08:01,289 --> 00:08:06,089
processing demands, allowing the
cluster to expand or contract.

102
00:08:06,589 --> 00:08:11,099
Horizontal scaling is generally a
preferred method of scaling because you

103
00:08:11,099 --> 00:08:14,729
can use a general purpose instances.

104
00:08:15,229 --> 00:08:20,079
that can scale horizontally and you
can deploy them in a large number.

105
00:08:20,579 --> 00:08:25,969
Cost wise, these instances are
not that expensive, so it makes

106
00:08:25,969 --> 00:08:30,049
sense to make use of the horizontal
scaling wherever it makes sense.

107
00:08:30,549 --> 00:08:36,289
Whereas vertical scaling adjusts
resources within existing nodes, such

108
00:08:36,289 --> 00:08:40,629
as increasing CPU or memory allocation.

109
00:08:41,129 --> 00:08:47,839
Both approaches put together, they
can be automated based on some metrics

110
00:08:48,419 --> 00:08:53,749
like CPU utilization, memory usage,
or application specific metrics.

111
00:08:54,249 --> 00:09:00,119
You can set up a threshold value, and
based on the threshold value, when these

112
00:09:00,119 --> 00:09:07,069
metrics exceed these threshold values,
the scaling can automatically trigger.

113
00:09:07,569 --> 00:09:12,729
Effective data management requires
understanding various storage options.

114
00:09:13,619 --> 00:09:18,849
This slide visually represents the
diverse storage solutions available,

115
00:09:19,509 --> 00:09:25,609
from cloud object storage for
raw data, to specialized database

116
00:09:25,609 --> 00:09:26,909
for structured information.

117
00:09:27,409 --> 00:09:32,699
The right storage strategy depends upon
your specific workload characteristics,

118
00:09:33,159 --> 00:09:35,719
access pattern, and latency requirement.

119
00:09:36,409 --> 00:09:43,749
And it can vary from blob storage,
to the database, to the data lake.

120
00:09:44,249 --> 00:09:48,079
Data persistence is
essential for ML workloads.

121
00:09:48,579 --> 00:09:54,499
We implement this through persistent
volumes that store data beyond

122
00:09:54,569 --> 00:09:59,429
pored life cycles, ensuring data
survives container restarts.

123
00:09:59,929 --> 00:10:00,859
We know that.

124
00:10:01,359 --> 00:10:05,489
In Kubernetes, the pod
lifecycle is ephemeral.

125
00:10:05,989 --> 00:10:10,229
Anytime, for any reason,
pod can be evicted.

126
00:10:11,029 --> 00:10:13,879
So it's important to have persistent data.

127
00:10:14,379 --> 00:10:18,959
Stateful sets manage stateful
applications with persistent

128
00:10:19,419 --> 00:10:22,179
identifiers and stable storage.

129
00:10:22,679 --> 00:10:23,949
Critical for maintaining state.

130
00:10:24,449 --> 00:10:30,369
And data replication across multiple
nodes provide redundancy, ensuring

131
00:10:30,419 --> 00:10:36,129
availability even if individual
nodes fail or get evicted.

132
00:10:36,629 --> 00:10:41,739
A robust monitoring infrastructure
is vital for production system.

133
00:10:42,239 --> 00:10:47,589
I haven't seen any production
system without a good monitoring

134
00:10:47,819 --> 00:10:49,379
and visibility infrastructure.

135
00:10:50,289 --> 00:10:56,859
So this is critical component and we
must have the high standard for setting

136
00:10:56,859 --> 00:10:58,249
up the monitoring infrastructure.

137
00:10:58,749 --> 00:11:04,949
We recommend implementing monitoring
tools like Prometheus and Grafana for

138
00:11:04,979 --> 00:11:07,119
matrix collection and visualization.

139
00:11:07,619 --> 00:11:13,189
You can run a sidecar container to your
main application container, which is

140
00:11:13,269 --> 00:11:17,239
responsible for sending out matrix.

141
00:11:17,999 --> 00:11:24,909
Exporting in the Prometheus format, which
can be exported to the external exporters.

142
00:11:25,909 --> 00:11:31,729
Logging solutions such as Fluentd
and Elasticsearch centralize

143
00:11:31,839 --> 00:11:34,579
logs for easier troubleshooting.

144
00:11:35,079 --> 00:11:42,029
Tracing systems like Jager and
Zipkin provide insights into requests

145
00:11:42,319 --> 00:11:44,659
flows across distributed systems.

146
00:11:45,159 --> 00:11:49,399
Putting this all together,
these tools offer comprehensive

147
00:11:49,399 --> 00:11:51,939
visibility into your infrastructure.

148
00:11:52,439 --> 00:11:56,449
You can set up these metrics
into your PagerDuty alerts.

149
00:11:56,949 --> 00:12:04,649
And you would come to know when these
production systems downgrade or fail.

150
00:12:05,149 --> 00:12:08,939
And you can do the manual intervention
to bring those systems back.

151
00:12:09,439 --> 00:12:11,729
without impacting the customer workflows.

152
00:12:12,229 --> 00:12:16,749
Performance optimization
require a multifaceted approach.

153
00:12:17,249 --> 00:12:23,929
Data partitioning optimizes distribution
across workers, reducing data movement

154
00:12:24,619 --> 00:12:27,329
and improving processing efficiency.

155
00:12:27,829 --> 00:12:34,204
You can also resort to a external
service which is responsible for Doing

156
00:12:34,204 --> 00:12:40,674
the spark shuffling, which reduces
the chances of shuffle, essentially

157
00:12:40,724 --> 00:12:44,704
increasing the efficiency across cluster.

158
00:12:45,204 --> 00:12:50,904
Data caching keeps frequently accessed
data in memory, reducing read latency.

159
00:12:51,404 --> 00:12:57,724
And code optimization improves application
efficiency through techniques like

160
00:12:58,349 --> 00:13:05,289
Predicate push down, which is one of
the key feature of Spark, where Spark

161
00:13:05,499 --> 00:13:11,189
push down the predicate or you can
say the filter down to the source.

162
00:13:11,689 --> 00:13:18,299
For example, let's say if you, there
is a SQL query, which is manipulating

163
00:13:18,299 --> 00:13:21,119
the data from Avro source file.

164
00:13:21,619 --> 00:13:28,239
Then Spark will push the filter down
to the Avro reader instead of reading

165
00:13:28,319 --> 00:13:30,099
all the records from the Avro file.

166
00:13:30,599 --> 00:13:35,409
And on top, you can have some
efficiency through broadcast join

167
00:13:35,459 --> 00:13:37,059
and query optimization as well.

168
00:13:37,559 --> 00:13:44,679
Spark provide catalyst, which does
convert, the logical, query plan

169
00:13:44,919 --> 00:13:47,499
into an optimized logical query plan.

170
00:13:47,999 --> 00:13:52,769
Security must be a priority
in any ML infrastructure.

171
00:13:53,269 --> 00:13:58,279
This chart illustrates the
balanced approach required

172
00:13:58,309 --> 00:14:00,199
across multiple security domains.

173
00:14:00,699 --> 00:14:04,069
Network policies to control
poor communications.

174
00:14:04,070 --> 00:14:08,549
Data encryption for protecting
sensitive information.

175
00:14:08,615 --> 00:14:17,154
Authentic authentication mechanism to
verify identities and vulnerability

176
00:14:17,154 --> 00:14:21,044
scanning to proactively identify weakness.

177
00:14:21,544 --> 00:14:27,324
Implementing proper authentication and
authorization involves several mechanism.

178
00:14:27,824 --> 00:14:31,314
Role based access control, which
is very native to Kubernetes.

179
00:14:31,814 --> 00:14:35,794
Restricts access based on
user roles, applying the

180
00:14:35,794 --> 00:14:37,484
principle of least privileges.

181
00:14:37,984 --> 00:14:43,514
OAuth integration leverages
external identity provider for

182
00:14:43,564 --> 00:14:45,044
streamlined authentication.

183
00:14:45,544 --> 00:14:50,724
And certificate based authentication
uses digital certificates for securing

184
00:14:50,844 --> 00:14:52,894
communication between components.

185
00:14:53,394 --> 00:14:56,164
You can also induce MTLS and MTLS.

186
00:14:56,544 --> 00:15:02,704
to communicate between internal
service endpoints for extra protection.

187
00:15:03,204 --> 00:15:06,304
Network security and data
protection work in tandem.

188
00:15:06,804 --> 00:15:11,924
Network segmentation isolates Spark
workloads from other applications,

189
00:15:12,614 --> 00:15:14,514
minimizing the attack surface.

190
00:15:15,014 --> 00:15:20,604
Data encryption both
at rest and in transit.

191
00:15:21,224 --> 00:15:26,624
Ensure sensitive data remains
protected even if other security

192
00:15:26,624 --> 00:15:28,284
measures are compromised.

193
00:15:28,784 --> 00:15:33,854
Cost management is increasingly
important as ML workloads scale.

194
00:15:34,354 --> 00:15:40,774
It's paramount important when these
workloads are running in cloud.

195
00:15:41,274 --> 00:15:47,479
We have heard lot of stories where some of
the EC2 instances run for a longer period

196
00:15:47,479 --> 00:15:51,549
of time, which warrants unnecessary cost.

197
00:15:52,049 --> 00:16:00,379
We can choose spot instances and we
can find out what time of the day and

198
00:16:00,379 --> 00:16:07,679
in what zone these spot instances are
cheaper to improve our cost efficiency.

199
00:16:08,179 --> 00:16:10,739
We can choose this for
non critical workload.

200
00:16:11,239 --> 00:16:15,929
Because spot instance has a
tendency to be taken away.

201
00:16:16,429 --> 00:16:21,209
The resource optimization, fine tune
allocation to reduce waste, ensuring

202
00:16:21,219 --> 00:16:22,839
you are not over provisioning.

203
00:16:23,339 --> 00:16:28,729
Idle resource management scales down
or terminates resources when not in

204
00:16:28,729 --> 00:16:31,769
use, avoiding unnecessary expenses.

205
00:16:32,269 --> 00:16:38,339
High availability ensures
your ML infrastructure Remains

206
00:16:38,719 --> 00:16:40,939
operational despite failures.

207
00:16:41,439 --> 00:16:47,279
This requires multiple master
nodes for redundancy, eliminating

208
00:16:47,279 --> 00:16:48,569
single point of failure.

209
00:16:49,069 --> 00:16:55,719
Also, multiple master nodes are
great if you have a larger cluster

210
00:16:56,219 --> 00:17:01,959
and they work in tandem to share the
workload, making the API Kubernetes

211
00:17:02,009 --> 00:17:03,789
API server highly available.

212
00:17:04,289 --> 00:17:08,309
For worker node, the redundant
Spark workers provide fault

213
00:17:08,329 --> 00:17:10,099
tolerance for processing tasks.

214
00:17:10,599 --> 00:17:16,019
A failed or evicted worker
pod can be restarted.

215
00:17:16,519 --> 00:17:23,079
And in many of the cases, those
tasks, when retried, succeed,

216
00:17:23,579 --> 00:17:27,099
leading it to the self healing
properties of the application.

217
00:17:27,599 --> 00:17:34,039
Data replication across multiple
nodes ensure data remains accessible

218
00:17:34,129 --> 00:17:35,789
even if individual nodes fail.

219
00:17:36,289 --> 00:17:40,109
Disaster recovery planning
prepares for worst case scenarios.

220
00:17:40,609 --> 00:17:46,419
Data backup and recovery procedure
preserve critical data and

221
00:17:46,429 --> 00:17:48,639
enable restoration when needed.

222
00:17:49,139 --> 00:17:53,629
Replication across multiple
regions protects against failure.

223
00:17:54,199 --> 00:17:55,459
regional outages.

224
00:17:55,959 --> 00:18:00,449
Failover mechanism automatically redirect
operation to functioning resources,

225
00:18:01,159 --> 00:18:04,549
minimizing downtime during failures.

226
00:18:05,049 --> 00:18:10,989
Implementing CI CD streamlines,
development and deployment.

227
00:18:11,489 --> 00:18:18,499
The build stage compiles and packages
Spark applications with dependencies.

228
00:18:18,999 --> 00:18:21,709
There are a lot of build
tools available in the market.

229
00:18:22,209 --> 00:18:30,169
Maven is often used predominantly,
but for monorepo cases, Bazel is

230
00:18:30,169 --> 00:18:32,119
also gaining a lot of traction.

231
00:18:32,619 --> 00:18:37,839
Testing runs automated tests to
verify functionality and performance.

232
00:18:38,339 --> 00:18:41,649
Deployment pushes applications
to the Kubernetes cluster

233
00:18:42,359 --> 00:18:44,249
using automated processes.

234
00:18:44,749 --> 00:18:50,489
Integration test is an essential
part of the CICD pipeline before

235
00:18:50,879 --> 00:18:56,959
we go and deploy the Docker image
monitoring tracks application health

236
00:18:57,629 --> 00:19:00,169
and performance post deployment.

237
00:19:00,669 --> 00:19:05,089
The value of ML model
lies in their application.

238
00:19:05,589 --> 00:19:13,829
We need effective ways to deploy trained
models from Spark to serving platforms

239
00:19:14,489 --> 00:19:17,424
like TensorFlow serving, KF serving.

240
00:19:17,714 --> 00:19:19,304
or custom solutions.

241
00:19:19,804 --> 00:19:26,554
Out of all the AI framework available
in the market, for example, TensorFlow,

242
00:19:26,554 --> 00:19:32,084
PyTorch, or Jaxx, TensorFlow comes
out to be one of the favorite

243
00:19:32,194 --> 00:19:37,994
which is being used for a lot of
production deployment scenarios.

244
00:19:38,494 --> 00:19:45,394
It provides high level APIs like Keras,
which simplifies the model deployment.

245
00:19:45,894 --> 00:19:50,394
And there is a light version
of this framework available

246
00:19:50,894 --> 00:19:52,264
for mobile applications.

247
00:19:52,764 --> 00:19:55,494
These platforms then serve model.

248
00:19:55,839 --> 00:20:01,409
for real time inference and predictions,
bringing, bridging the gap between

249
00:20:01,419 --> 00:20:04,329
model development and production use.

250
00:20:04,829 --> 00:20:10,209
Dependency management becomes
crucial as projects grow.

251
00:20:10,709 --> 00:20:18,899
Tools like Maven, SBT, or Gradle help
manage project dependencies efficiently.

252
00:20:19,399 --> 00:20:23,779
Containerization via Docker
packages application with their

253
00:20:23,779 --> 00:20:30,264
dependency, ensuring consistency
across lower and higher environment

254
00:20:31,004 --> 00:20:33,224
and simplifying deployment.

255
00:20:33,724 --> 00:20:37,534
Effective troubleshooting
requires multiple approaches.

256
00:20:38,034 --> 00:20:44,714
Logs analysis examines Spark and
Kubernetes logs to identify errors.

257
00:20:45,219 --> 00:20:47,289
And they are root case root causes.

258
00:20:47,789 --> 00:20:51,859
There are many logs analysis
tool available in the market.

259
00:20:52,359 --> 00:20:59,969
Which can source and aggregate loads from
all the containers running in the pod.

260
00:21:00,469 --> 00:21:05,459
Including all the side containers
as well as init containers.

261
00:21:05,959 --> 00:21:12,539
Debugging tools helps inspect code
execution and variable values.

262
00:21:13,039 --> 00:21:19,309
Kubernetes monitoring tools provide
insight into pod status, resource

263
00:21:19,309 --> 00:21:22,359
utilization, and cluster health.

264
00:21:22,859 --> 00:21:26,379
There are many Kubernetes monitoring
tools available in the market.

265
00:21:26,879 --> 00:21:33,259
There are many open source project as
well, which you can leverage to get

266
00:21:33,759 --> 00:21:38,879
monitoring to set up some monitoring
across your Kubernetes cluster.

267
00:21:39,379 --> 00:21:43,109
Continuous performance improvement
require systematic measurement.

268
00:21:43,609 --> 00:21:48,229
This involves measuring
performance metrics under various

269
00:21:48,229 --> 00:21:50,619
workload to establish baseline.

270
00:21:51,119 --> 00:21:57,019
Identify bottlenecks and areas for
improvement direct optimizations efforts.

271
00:21:57,519 --> 00:22:03,209
Validating performance after implementing
changes confirm their effectiveness.

272
00:22:03,709 --> 00:22:08,999
Let's examine a real world case study
involving a large scale ML pipeline.

273
00:22:09,499 --> 00:22:12,809
The challenge was building a
pipeline capable of processing.

274
00:22:13,019 --> 00:22:14,849
terabyte of data efficiently.

275
00:22:15,349 --> 00:22:20,949
The solution leverage Spark on
Kubernetes to provide distributed

276
00:22:20,949 --> 00:22:27,719
processing and dynamic scalability,
resulting in significant performance

277
00:22:27,749 --> 00:22:29,649
improvement and cost reduction.

278
00:22:30,149 --> 00:22:34,939
Pair it with some catalog service,
for example, Hive Metastore.

279
00:22:35,439 --> 00:22:35,889
End.

280
00:22:36,634 --> 00:22:45,224
Using the open source Iceberg open
table format to efficiently store

281
00:22:45,724 --> 00:22:51,464
and manipulate the table format and
store the data in the S3 format.

282
00:22:51,964 --> 00:22:58,894
Spark SQL, Hype Metastore and Iceberg
put together all three provide a very

283
00:22:58,894 --> 00:23:06,059
comprehensive and compelling data
lake solution, which has capability to

284
00:23:06,059 --> 00:23:12,689
store terabyte of data efficiently, as
well as provide the schema evolution

285
00:23:13,269 --> 00:23:17,579
in case the business need change
to change the schema of the table.

286
00:23:18,079 --> 00:23:22,109
Also, with the help of Iceberg,
we can do the time travel.

287
00:23:22,609 --> 00:23:25,119
which can be required
for compliance reasoning.

288
00:23:25,619 --> 00:23:30,079
From our experience, we have
distilled key best practices.

289
00:23:30,579 --> 00:23:35,589
Start small with a minimal
viable cluster and gradually

290
00:23:35,589 --> 00:23:37,549
scale as you gain experience.

291
00:23:38,049 --> 00:23:39,189
Automate deployment.

292
00:23:39,689 --> 00:23:46,059
scaling and monitoring process to reduce
manual intervention, continuously and

293
00:23:46,099 --> 00:23:53,259
periodically optimize resource utilization
and do the performance benchmarking based

294
00:23:53,259 --> 00:23:56,859
on metrics and evolving workload patterns.

295
00:23:57,359 --> 00:24:01,729
Looking ahead, several trends
will shape the future of cloud

296
00:24:01,749 --> 00:24:04,239
native AI and ML infrastructure.

297
00:24:04,739 --> 00:24:11,119
Serverless computing for ML workload will
reduce infrastructure management overhead.

298
00:24:11,619 --> 00:24:17,414
Edge computing will bring AI and
ML capabilities closer to data

299
00:24:17,434 --> 00:24:19,674
sources for real time applications.

300
00:24:20,174 --> 00:24:26,744
AI powered infrastructure management
will automate optimization and scaling

301
00:24:26,744 --> 00:24:30,094
decisions, creating self tuning systems.

302
00:24:30,594 --> 00:24:36,404
AI and ML, the space itself is a very
fast moving space, and there are a lot

303
00:24:36,404 --> 00:24:45,854
of community build tools, data set, and
models available on some of the websites.

304
00:24:45,864 --> 00:24:50,304
For example, Hugging Face,
where people collaborate.

305
00:24:51,194 --> 00:24:56,434
And leverage each other work
to take this space forward.

306
00:24:56,934 --> 00:25:01,734
This concludes our presentation
on building resilient Apache Spark

307
00:25:01,754 --> 00:25:04,174
cluster on Kubernetes for AI workload.

308
00:25:04,674 --> 00:25:10,414
We have covered key concepts,
best practices, and practical

309
00:25:10,444 --> 00:25:11,964
implementation strategies.

310
00:25:12,464 --> 00:25:15,654
I encourage you to explore
the additional resources.

311
00:25:16,154 --> 00:25:19,624
and continue learning about
this rapidly evolving.

312
00:25:20,124 --> 00:25:21,374
Thank you for your time.

313
00:25:21,874 --> 00:25:28,974
I hope my presentation is helpful to
you and you will be able to embark on

314
00:25:28,984 --> 00:25:32,584
your AI and ML infrastructure journey.

315
00:25:33,444 --> 00:25:34,454
Thank you for attending.

