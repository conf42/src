1
00:00:00,500 --> 00:00:01,099
Hello everyone.

2
00:00:01,369 --> 00:00:02,480
This is Akala.

3
00:00:02,980 --> 00:00:07,115
As you guys know, mainframes has been
around in multiple industries over,

4
00:00:07,389 --> 00:00:09,070
over the last couple of decades.

5
00:00:09,700 --> 00:00:14,290
They have been supporting with very
robustness, scalable, and have been

6
00:00:14,290 --> 00:00:18,680
supporting operations, like financial
transactions, insurance processing,

7
00:00:18,680 --> 00:00:20,540
healthcare transactions, and all of that.

8
00:00:21,479 --> 00:00:25,650
But however, at some point we have to
modernize these mainframe applications.

9
00:00:26,150 --> 00:00:30,760
The, and the best way possible is right
now to use an AI powered approach.

10
00:00:31,250 --> 00:00:36,620
And basically see how AI is basically
enhancing the reliability in this

11
00:00:36,620 --> 00:00:38,060
legacy trans system transformation.

12
00:00:38,060 --> 00:00:41,980
I. As enterprises continue to rely
on mainframes for mission critical

13
00:00:41,980 --> 00:00:46,120
applications, AI basically offers
groundbreaking approaches to modernize

14
00:00:46,120 --> 00:00:49,300
these application, these systems,
while maintaining operation stability.

15
00:00:49,800 --> 00:00:53,130
Today we are going to talk about
what are the different technologies

16
00:00:53,130 --> 00:00:58,540
and tools AI basically offers to
enable this transformation journey

17
00:00:58,870 --> 00:01:03,160
and focus primarily on the reliable
engineering principles as we do that.

18
00:01:03,660 --> 00:01:07,670
As you can see, that, there are some
key features from AI that, that are used

19
00:01:07,670 --> 00:01:10,790
as part of this transformation journey,
which is automated code analysis,

20
00:01:10,790 --> 00:01:15,530
intelligence testing, predictive
monitoring, and showcasing how these site

21
00:01:15,530 --> 00:01:20,240
liability engineers teams harness these
capabilities to ensure that seamless this

22
00:01:20,240 --> 00:01:24,950
transition is seamlessly done even in
the most critical environments possible.

23
00:01:25,450 --> 00:01:29,110
Now let's talk about some of the
challenges that we encounter when

24
00:01:29,140 --> 00:01:31,060
during this modernization process.

25
00:01:31,150 --> 00:01:34,180
One is the legacy dependencies.

26
00:01:34,210 --> 00:01:38,410
There's a lot of logic and code built
over the years that with limited

27
00:01:38,410 --> 00:01:42,670
documentation that we need to basically
start identifying and tracking down.

28
00:01:43,170 --> 00:01:45,750
We have to, there's very complex
interdependencies between

29
00:01:45,750 --> 00:01:47,610
systems built over decades.

30
00:01:48,110 --> 00:01:49,550
The next would be the knowledge gap.

31
00:01:50,015 --> 00:01:53,225
Most of these mainframe systems
are built based on cobol.

32
00:01:54,035 --> 00:01:57,725
The COBOL is a very obsolete language
today that we don't have the people

33
00:01:57,725 --> 00:02:01,640
with the right skills to manage and
maintain the system or even understand

34
00:02:01,640 --> 00:02:03,440
what the code in the current system is.

35
00:02:03,940 --> 00:02:05,860
The next would be the operational risk.

36
00:02:06,280 --> 00:02:10,420
Since, as we mentioned earlier, that
these mainframe systems are used in very

37
00:02:10,420 --> 00:02:12,820
highly transactional operation systems.

38
00:02:13,535 --> 00:02:17,175
The risk and stakes are very high
when they're during this transaction

39
00:02:17,175 --> 00:02:18,495
and there is downtime required.

40
00:02:18,995 --> 00:02:20,525
The last would be performance.

41
00:02:21,375 --> 00:02:25,005
So when during modernization, the
expectations are usually very high.

42
00:02:25,035 --> 00:02:29,115
That you know the performance should
be subpar in your and to ensure that

43
00:02:29,145 --> 00:02:33,955
it, it outperforms the traditional,
the old legacy transaction system.

44
00:02:34,585 --> 00:02:38,335
But the scale, there are factors,
a scalability that needs to

45
00:02:38,335 --> 00:02:39,775
be taken into concentration.

46
00:02:40,115 --> 00:02:42,035
During these, during this transition.

47
00:02:42,035 --> 00:02:42,635
Transition.

48
00:02:43,135 --> 00:02:46,795
Next would be how AI is
basically enabling us.

49
00:02:47,065 --> 00:02:52,455
To determine how what kind of resources
and scaling that are required for

50
00:02:52,485 --> 00:02:54,315
mi for this specific migration.

51
00:02:54,465 --> 00:02:58,545
As you can see on the graph that we
have three different types of tracking.

52
00:02:58,965 --> 00:03:01,155
One is a traditional tracking method.

53
00:03:01,155 --> 00:03:04,365
That means, traditionally if you don't
use ai, you come up with a prediction

54
00:03:04,605 --> 00:03:08,695
of this is how it's supposed to be
for how it's supposed to be scaled

55
00:03:08,785 --> 00:03:10,105
as part of this modernization.

56
00:03:10,720 --> 00:03:14,890
Second, that in the green you, that you
see that's an AI driven approach wherein

57
00:03:14,900 --> 00:03:19,610
it understands the existing system, tries
to identify the dependencies and gives

58
00:03:19,610 --> 00:03:23,660
you predictability of how much resources
need to be allocated to make this happen.

59
00:03:24,530 --> 00:03:27,200
Then when you start to compare
with the actual usage, you see

60
00:03:27,200 --> 00:03:31,140
that actual usage correlates highly
with how the AI is predicted.

61
00:03:31,640 --> 00:03:35,240
By, by leveraging these AI different
techniques, you can reach accuracy

62
00:03:35,240 --> 00:03:41,440
levels of 95%, 95%, and in very mature
app implementations even the best of the

63
00:03:41,440 --> 00:03:45,580
best traditional, mature implementation,
we achieve only to 60 to 70% accuracy.

64
00:03:46,080 --> 00:03:51,290
Next we talk about basically how
natural language processing is

65
00:03:51,290 --> 00:03:55,550
playing a very key role in trying
to understand, trying to basically

66
00:03:55,610 --> 00:03:57,560
transcript the existing documentation.

67
00:03:58,060 --> 00:04:03,490
So what NLP does is what AI brings
into the picture is it basically can

68
00:04:03,490 --> 00:04:08,230
start to document any kind of manuals,
documentation available and starts

69
00:04:08,230 --> 00:04:12,280
to learn and train itself, and trying
to provide you actionable insights

70
00:04:12,670 --> 00:04:16,480
to determine how reliability and
scalability needs to come into picture.

71
00:04:16,980 --> 00:04:20,220
Then at the same time, as we mentioned
earlier, by reading through this

72
00:04:20,220 --> 00:04:24,450
documentation, it tries to identify
the different dependencies and

73
00:04:24,450 --> 00:04:27,720
starts to create a semantic analysis
and mapping around the different

74
00:04:27,720 --> 00:04:29,310
components of this implementation.

75
00:04:29,810 --> 00:04:31,580
And the last would be knowledge graphing.

76
00:04:31,700 --> 00:04:36,320
The knowledge graphings, basically
trying to create a map around the

77
00:04:36,320 --> 00:04:39,560
different sources of information
identified as part of the documentation.

78
00:04:40,520 --> 00:04:45,650
An LP with AI basically provides us
the capability to, to pass through this

79
00:04:45,680 --> 00:04:50,180
unstructured documentation and provide
you very valuable insights, which are very

80
00:04:50,180 --> 00:04:52,669
key for any kind of migration activity.

81
00:04:53,169 --> 00:04:57,289
Next, let's take a case study, an active
case study, which is implemented out

82
00:04:57,349 --> 00:04:59,719
there in the financial services industry.

83
00:05:00,409 --> 00:05:03,799
So the project scope, as you
can see that it is a 30-year-old

84
00:05:03,799 --> 00:05:05,419
legacy core banking system.

85
00:05:05,944 --> 00:05:11,374
With comprising of around 5.2 million
lines of complex COBOL code and 400

86
00:05:11,374 --> 00:05:16,574
mission critical dependent applications
over the decade, and then there is strict

87
00:05:16,574 --> 00:05:19,994
zero downtime requirement because this
is a financial services environment,

88
00:05:20,494 --> 00:05:23,164
how AI basically enabled this migration.

89
00:05:23,554 --> 00:05:26,879
First, it was able to do
comprehensive automated dependency

90
00:05:26,884 --> 00:05:28,354
mappings as we mentioned earlier.

91
00:05:28,864 --> 00:05:31,954
That using NLP, trying to
understand documentation, trying

92
00:05:31,954 --> 00:05:35,164
to create those semantic mappings,
it was able to achieve that.

93
00:05:35,764 --> 00:05:41,074
Next, next would be to, to
use AI to to generate advanced

94
00:05:41,074 --> 00:05:42,334
predictive incident prevention.

95
00:05:42,364 --> 00:05:47,734
That means you have to understand
how to leverage AI to, to understand

96
00:05:47,734 --> 00:05:51,924
what kind of issues might foresee
while doing a migration activity.

97
00:05:52,284 --> 00:05:56,184
An AI can provide you better tools
and enablement to, to catch ahead

98
00:05:56,184 --> 00:06:00,524
of time and try to save save the
time for debugging and trying to

99
00:06:00,764 --> 00:06:02,294
resolve it ahead of time itself.

100
00:06:02,794 --> 00:06:06,574
The next would be the real time
performance monitoring with alerting.

101
00:06:06,844 --> 00:06:10,224
So while set, while doing
the migration transition of.

102
00:06:10,254 --> 00:06:13,224
Piece by piece or sections
of each of the of the system.

103
00:06:13,594 --> 00:06:17,494
This real time monitoring basically
enabled us to basically start to see

104
00:06:17,494 --> 00:06:21,304
if there is any dip in performance or
new spikes that we are noticing that

105
00:06:21,304 --> 00:06:26,754
we are not aware of, and also generate
alerting alerts to to enable users to

106
00:06:26,754 --> 00:06:28,539
understand where it is going wrong.

107
00:06:29,039 --> 00:06:31,889
And then the last would be this is
the most important critical piece

108
00:06:31,889 --> 00:06:35,749
while doing a migration from one,
from the legacy to a modern system.

109
00:06:36,139 --> 00:06:37,249
The key is testing.

110
00:06:37,909 --> 00:06:43,389
So how manual testing over the years
has always been a skew in entire

111
00:06:43,389 --> 00:06:46,779
project planning and pro project
planning or migration planning.

112
00:06:47,279 --> 00:06:51,389
AI basically enables us to do automated
intelligent test generation, which will

113
00:06:51,389 --> 00:06:53,339
automatically do the testing for us.

114
00:06:53,684 --> 00:06:56,584
While we transition the core
from one system to another, so

115
00:06:56,584 --> 00:06:59,254
the outcome of it, these are the
outcomes that we have encountered.

116
00:06:59,674 --> 00:07:03,694
We have basically reduced 72% in
critical production incidents.

117
00:07:04,414 --> 00:07:06,634
We have mi, we have cut
chart, the migration timeline.

118
00:07:06,634 --> 00:07:10,264
We have 14 months and in overall
cost savings, we have saved on

119
00:07:10,264 --> 00:07:15,544
$4.3 million and 99.998% system.

120
00:07:15,544 --> 00:07:18,004
Our time maintained through,
through throughout this

121
00:07:18,184 --> 00:07:19,624
implementation of this migration.

122
00:07:20,124 --> 00:07:24,514
Next, let's talk about as I mentioned
earlier the criticality of this

123
00:07:24,514 --> 00:07:27,544
testing is very key during any
kind of a migration initiative.

124
00:07:28,234 --> 00:07:32,174
There are four different capabilities
that AI offers during this,

125
00:07:32,234 --> 00:07:33,374
creating a testing framework.

126
00:07:34,079 --> 00:07:37,049
One it gen, it provides you
with this generation capability.

127
00:07:37,259 --> 00:07:41,699
It provides a comprehensive test
scenarios based off the documentation,

128
00:07:41,879 --> 00:07:45,839
the migration, the user stories, the
product documentation, all of that.

129
00:07:46,619 --> 00:07:50,919
Then the automated execution, once the
code is ready automate automatically.

130
00:07:50,919 --> 00:07:54,849
The AI basic in provides us the tools
to pick up the code, run through the

131
00:07:54,849 --> 00:07:58,269
testing scenarios and tell us whether
it is working or not, or it also

132
00:07:58,269 --> 00:08:01,239
tells you which part of the code is
basically causing the issues as well.

133
00:08:01,739 --> 00:08:05,549
Then based off the results that
we have encountered over a period

134
00:08:05,549 --> 00:08:09,809
of testing, it also enables us to
basically create pattern recognitions

135
00:08:09,809 --> 00:08:11,189
in all of the testing outcomes.

136
00:08:11,549 --> 00:08:16,760
It'll enable us to predict in future code
migrations how we can leverage all of that

137
00:08:16,760 --> 00:08:21,799
predictability to to write better code
and to do better migration activities.

138
00:08:22,490 --> 00:08:24,709
And then the last piece
is the test refinement.

139
00:08:25,039 --> 00:08:29,620
So as we start to train the model
to understand what the different

140
00:08:29,620 --> 00:08:33,610
test scenarios could be, and when
we start to implement these product

141
00:08:33,610 --> 00:08:38,530
scenarios via code, it starts to start
to self-improve itself and starts at

142
00:08:38,530 --> 00:08:41,890
better testing, testing scenarios and
provides a better testing coverage.

143
00:08:41,919 --> 00:08:42,250
Us

144
00:08:42,750 --> 00:08:43,260
next.

145
00:08:43,860 --> 00:08:46,470
This is, I'm talking about, this
is the implementation framework.

146
00:08:46,500 --> 00:08:48,390
How do we implement ai?

147
00:08:49,170 --> 00:08:52,590
First thing is the assessment phase
During any kind of migration activity,

148
00:08:52,590 --> 00:08:56,160
the assessment phase is very key
because that is where you catalog all

149
00:08:56,160 --> 00:09:01,814
existing systems, identify modernization
candidates, and establish reliability base

150
00:09:01,915 --> 00:09:03,754
baselines using automated discovery tools.

151
00:09:04,619 --> 00:09:06,155
Next, we start with the pilot.

152
00:09:06,795 --> 00:09:11,354
We basically take a simple MVP and
then start to migrate that or modernize

153
00:09:11,354 --> 00:09:15,944
that based off using these, using
AI driven reliability improvements

154
00:09:15,944 --> 00:09:20,564
and scalable approaches and refining
approaches to, to do that implementation.

155
00:09:21,064 --> 00:09:24,935
Once the SA pilot is successful,
then is basically the implementing

156
00:09:25,175 --> 00:09:29,824
AI at a larger scale, then we will
leverage AI to, and tooling to within

157
00:09:29,824 --> 00:09:33,275
existing SRE practices, focusing on
code analysis, predictor monitoring,

158
00:09:33,275 --> 00:09:35,255
and automated testing capabilities.

159
00:09:35,345 --> 00:09:38,165
The last would be scale, the deployments.

160
00:09:38,195 --> 00:09:41,585
Now that we have implemented a
pilot, you have now implemented

161
00:09:41,585 --> 00:09:42,965
the integration capabilities.

162
00:09:43,205 --> 00:09:49,145
Now we have to, we will leverage AI to
determine how much scaling is required for

163
00:09:49,145 --> 00:09:54,155
this to successfully work the way it is
supposed to work or a perform even better.

164
00:09:54,155 --> 00:09:57,445
So we extend proven approaches
across the enterprise, maintaining

165
00:09:57,445 --> 00:10:01,495
continuous learning, learning loops
to provide modernization outcomes.

166
00:10:01,995 --> 00:10:05,670
Then what are some of the common
challenges and mitigation strategies that

167
00:10:05,670 --> 00:10:08,550
we need to consider during this migration?

168
00:10:09,120 --> 00:10:10,980
One, data quality issues.

169
00:10:11,790 --> 00:10:15,390
Primarily when we move from one
system to another system, we have

170
00:10:15,390 --> 00:10:19,230
to take into account, but that the
EO system acts in a different way.

171
00:10:19,685 --> 00:10:21,240
It ingested in a different way.

172
00:10:21,240 --> 00:10:25,080
It reads data in a different way,
so we need to basically implement

173
00:10:25,080 --> 00:10:28,620
very data cleansing pipelines and
verification algorithms to ensure.

174
00:10:29,265 --> 00:10:33,675
AI systems receive reliable inputs,
and then we have to establish data

175
00:10:33,675 --> 00:10:37,305
quality scoring mechanisms and
trigger human review for edge cases.

176
00:10:38,205 --> 00:10:39,945
Then technical debt.

177
00:10:40,555 --> 00:10:43,825
Ideally there's a lot of technical
debt which is involved during

178
00:10:43,825 --> 00:10:45,295
any kind of a migration activity.

179
00:10:46,075 --> 00:10:49,885
We basically need to use AI to
quantify that and quant categorize

180
00:10:49,885 --> 00:10:52,735
the technical depth, creating
prioritization, remediation, roadmaps.

181
00:10:53,235 --> 00:10:56,085
Then we have to make sure that we
implement automated refactoring

182
00:10:56,085 --> 00:10:59,355
tools to systematically address
high impact issues first.

183
00:10:59,415 --> 00:11:02,835
So the prioritizations and
everything are very key to any

184
00:11:02,835 --> 00:11:04,215
kind of tech technical data.

185
00:11:05,025 --> 00:11:08,025
So whatever product backlog we have,
technical backlog we have to ensure

186
00:11:08,025 --> 00:11:11,025
that we prioritize it and then start to
roll it out according to that itself.

187
00:11:11,955 --> 00:11:13,575
And then comes the skill gaps.

188
00:11:13,785 --> 00:11:17,315
So as we mentioned, as I mentioned
earlier, the primary problem with.

189
00:11:17,630 --> 00:11:20,960
With legacy mainframe systems
is to find people who have that

190
00:11:21,360 --> 00:11:22,920
COBOL understanding and knowledge.

191
00:11:23,400 --> 00:11:28,490
So we need to basically start to bridge
the limited set of mainframe veterans

192
00:11:28,490 --> 00:11:32,300
that we can identify and bridge them
with AI specialists to basically do

193
00:11:32,300 --> 00:11:37,925
a proper knowledge transfer and then
ensure that that AI is properly educated

194
00:11:37,925 --> 00:11:41,855
along among these mainframe veterans to
understand and then bridge the product

195
00:11:41,855 --> 00:11:43,685
gap and bridge, bridge the technology gap.

196
00:11:44,185 --> 00:11:49,189
Then now let's talk about some future
directions, like how quantum computing

197
00:11:49,189 --> 00:11:53,545
applications will, is a game changer
in this specific migration activity.

198
00:11:54,455 --> 00:11:57,605
First it would be around
complex optimization problems.

199
00:11:57,935 --> 00:12:02,555
Quantum algorithms will dramatically
accelerate optimization, challenges in

200
00:12:02,555 --> 00:12:05,975
resource allocation and performance during
mainframe transition, solving in minutes.

201
00:12:05,975 --> 00:12:07,510
What currently takes days.

202
00:12:08,060 --> 00:12:13,150
Quantum computing basically gives you the
capability to process problems or solve

203
00:12:13,150 --> 00:12:16,150
problems in very, in a very fast method.

204
00:12:16,610 --> 00:12:19,490
I'm talking about
microseconds, not even seconds.

205
00:12:19,850 --> 00:12:20,540
It is that fast.

206
00:12:21,040 --> 00:12:24,370
We are still not there today, but in the
future day when once we get into quantum

207
00:12:24,370 --> 00:12:26,530
computing, it solves many other cases.

208
00:12:26,530 --> 00:12:31,160
Not just pertaining to modernization,
but it solves many other scenarios and

209
00:12:31,160 --> 00:12:35,300
questions as well, including space travel,
including automated language learning.

210
00:12:35,640 --> 00:12:38,130
There's a lot of areas that
quantum compute can help.

211
00:12:39,025 --> 00:12:42,915
Then next would be how the
enhanced security modeling of

212
00:12:42,915 --> 00:12:44,415
what quantum computing offers.

213
00:12:44,895 --> 00:12:47,715
Quantum resistant cryptographic
systems will safeguard

214
00:12:47,715 --> 00:12:49,335
sensitive data during migration.

215
00:12:49,635 --> 00:12:53,775
While quantum simulation will identify
potential security vulnerabilities

216
00:12:53,775 --> 00:12:55,785
possible to detect with classic computing.

217
00:12:56,505 --> 00:13:02,095
What this means is it provides you
the different tools and encryptions

218
00:13:02,095 --> 00:13:05,745
possible while transitioning data
from one system to another system.

219
00:13:06,420 --> 00:13:10,470
We have a traditional encryption
methods that we follow today.

220
00:13:10,770 --> 00:13:15,470
But this cryptographic encryption
is taking this to the next level the

221
00:13:15,470 --> 00:13:19,340
vulnerable, it, it'll proactively identify
all system vulnerabilities, security

222
00:13:19,340 --> 00:13:25,370
vulnerabilities, and try to identify what
remediations can be in place and provide

223
00:13:25,430 --> 00:13:29,461
better encryption and cryptographic
capabilities to, to safeguard it.

224
00:13:29,961 --> 00:13:33,361
Then the last the next capability
is system behavior prediction.

225
00:13:34,001 --> 00:13:37,901
Quantum machine learning models will
achieve unprecedented accuracy and

226
00:13:37,901 --> 00:13:42,101
predicted system behavior under load,
enabling perfect fit cap capacity

227
00:13:42,101 --> 00:13:44,621
planning during critical migration phases.

228
00:13:45,281 --> 00:13:49,661
What this means is basically it
allows you to provide you high

229
00:13:49,661 --> 00:13:51,641
levels of accuracy while predicting.

230
00:13:52,106 --> 00:13:55,736
A certain scenario, whether it is
system behaviors, whether it is

231
00:13:55,736 --> 00:13:59,646
capacity planning, whatever it might
be in every migration phase, it can

232
00:13:59,646 --> 00:14:03,326
give you unprecedented accuracies
when when trying to implement

233
00:14:03,326 --> 00:14:04,556
predictability in that scenario.

234
00:14:05,056 --> 00:14:08,176
So early research basically now
suggests that quantum approaches

235
00:14:08,176 --> 00:14:12,766
could possibly reduce complex
migration timelines with 30 to 40%

236
00:14:12,826 --> 00:14:14,626
while improving reliability outcomes.

237
00:14:15,286 --> 00:14:16,306
That is a big number.

238
00:14:16,806 --> 00:14:19,866
Then practical guidance for SRE teams.

239
00:14:20,106 --> 00:14:23,466
So for site reliability engineering
teams, some of the things that

240
00:14:23,466 --> 00:14:28,236
we need to consider why AI needs,
why AI is a major player in any

241
00:14:28,236 --> 00:14:30,456
kind of an SRE environment is one.

242
00:14:30,756 --> 00:14:33,516
It basically reduces the incidence by 89%.

243
00:14:33,576 --> 00:14:36,696
It is a proven fact done and
implemented and validated

244
00:14:36,696 --> 00:14:37,686
across multiple implementations.

245
00:14:38,186 --> 00:14:41,701
Average reduction in critical
incidents during modernization when

246
00:14:41,701 --> 00:14:43,501
using AI driven reliability tools.

247
00:14:43,876 --> 00:14:47,086
As reduced by 89% compared
to a traditional approach.

248
00:14:47,716 --> 00:14:49,876
Then the ROI is very key.

249
00:14:50,296 --> 00:14:53,696
The money plays a major factor
or any kind of an ROI plays a

250
00:14:53,696 --> 00:14:55,346
major factor during an investment.

251
00:14:56,216 --> 00:14:58,946
So any kind of a mainframe
modernization project has to

252
00:14:58,946 --> 00:15:00,056
be backed with an investment.

253
00:15:00,536 --> 00:15:05,606
So with AI being a major part of that
migration activity it has proven that,

254
00:15:05,606 --> 00:15:07,526
or theoretically we have identified that.

255
00:15:07,526 --> 00:15:12,611
Around we have the ROI is basically
generated 3.7 times what it was

256
00:15:12,611 --> 00:15:15,431
supposed to usually provide in a
traditional migration activity.

257
00:15:15,931 --> 00:15:21,541
Then using AI assistance, we can save
the time and planning efforts required

258
00:15:21,781 --> 00:15:24,061
as part of as part of the analysis.

259
00:15:24,421 --> 00:15:27,091
So during planning phases,
analysis phases, we were able

260
00:15:27,091 --> 00:15:28,591
to, there were proven cases.

261
00:15:28,621 --> 00:15:33,421
The studies say that we were able to
achieve 65% of time savings during that

262
00:15:33,471 --> 00:15:35,061
in, during analysis and planning phase.

263
00:15:35,061 --> 00:15:35,331
Us.

264
00:15:35,831 --> 00:15:39,245
So overall, I want to make sure this
is this is how I want to conclude that,

265
00:15:39,295 --> 00:15:44,355
AI plays a very major role in how the
reliability, scalability is, plays

266
00:15:44,355 --> 00:15:48,535
a major factor during any kind of a
complex migration activity involved.

267
00:15:49,035 --> 00:15:53,066
So all of your, all of my friends
who, who are thinking about migrating

268
00:15:53,066 --> 00:15:57,536
legacy system, please ensure that
AI is implemented as part of that

269
00:15:57,586 --> 00:16:02,635
and all of those key and use my
inputs to basically drive your your

270
00:16:02,635 --> 00:16:06,535
leadership towards understanding what
the different benefits AI can offer

271
00:16:06,595 --> 00:16:08,215
during any kind of migration activity.

272
00:16:08,785 --> 00:16:10,435
Thank you so much for everyone's time.

273
00:16:10,825 --> 00:16:11,755
Have a lovely day.

274
00:16:11,815 --> 00:16:12,115
Thank you.

275
00:16:12,115 --> 00:16:12,445
Bye.

