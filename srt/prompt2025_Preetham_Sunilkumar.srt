1
00:00:00,500 --> 00:00:01,429
Hi everyone.

2
00:00:01,520 --> 00:00:03,460
This is pre today.

3
00:00:03,460 --> 00:00:08,500
I'm here to talk you through about the
scalable framework for prompt engineering

4
00:00:08,920 --> 00:00:10,750
for safer and smarter elements.

5
00:00:11,110 --> 00:00:14,310
So before we get into, the topic itself.

6
00:00:14,340 --> 00:00:18,630
A quick introduction about
myself, so I'm Prim Sunil Kumar.

7
00:00:18,930 --> 00:00:22,710
I work as a vice president for
LPL Financial, a wealth management

8
00:00:22,710 --> 00:00:26,310
firm based out of an Austin, Texas.

9
00:00:26,940 --> 00:00:31,860
And I've been actively associated with
numerous research organization, which

10
00:00:31,860 --> 00:00:37,830
includes Isaka Raptors, Sigma, and did
published our research papers in the

11
00:00:37,830 --> 00:00:39,480
area of software engineering and ai.

12
00:00:39,980 --> 00:00:45,410
And today's topic has been recorded for
Con 44 prompt engineering conference.

13
00:00:45,830 --> 00:00:50,150
So where we will be empathizing
on engineering intelligence,

14
00:00:50,420 --> 00:00:52,070
not just instructions.

15
00:00:52,760 --> 00:00:53,360
All right.

16
00:00:53,410 --> 00:00:56,650
With that said let's quickly
have a deep dive into our agenda.

17
00:00:56,755 --> 00:00:58,150
Our agenda looks like.

18
00:00:58,810 --> 00:01:02,710
So first we will be talking about
the hook, the prompting paradox,

19
00:01:03,460 --> 00:01:05,560
and the problem with the craft.

20
00:01:06,140 --> 00:01:07,550
Why the crop doesn't scale.

21
00:01:08,330 --> 00:01:12,690
And we'll be introducing a new framework
which I call it as a prom constitution.

22
00:01:13,110 --> 00:01:16,140
And today we are gonna go in
detail about three basic pillars,

23
00:01:16,140 --> 00:01:20,170
which is very key, essential the
pillar one structural integrity.

24
00:01:20,770 --> 00:01:22,660
And the pillar two is a safety net.

25
00:01:22,660 --> 00:01:24,640
And pillar three is scalable assembly.

26
00:01:25,210 --> 00:01:29,450
And probably I'm gonna run you through
on how this entire constitution

27
00:01:29,450 --> 00:01:35,465
prompting works and few advanced
methods to evaluate the prompts

28
00:01:35,465 --> 00:01:37,625
and the LLM capability as well.

29
00:01:37,925 --> 00:01:40,325
And finally, we get into a conclusion.

30
00:01:40,655 --> 00:01:44,045
So pretty structured
agenda for today's topic.

31
00:01:44,410 --> 00:01:45,090
Moving on.

32
00:01:45,310 --> 00:01:47,770
We'll start with the hook,
the prompting paradox.

33
00:01:47,980 --> 00:01:50,650
As you see on the screen,
two different images.

34
00:01:51,190 --> 00:01:52,120
The first image is like.

35
00:01:52,620 --> 00:01:55,770
Think about a magician taking
rabbit out of a Z, right?

36
00:01:56,070 --> 00:01:58,110
Looks like pure magic, right?

37
00:01:58,740 --> 00:02:02,640
On the other side, you have
complete chaos contracts, right?

38
00:02:03,070 --> 00:02:07,990
Where things are not structured
very unstructured or it's becoming

39
00:02:07,990 --> 00:02:09,200
quite difficult to make it.

40
00:02:09,550 --> 00:02:12,040
A linear or structure or
meaningful data, right?

41
00:02:12,090 --> 00:02:14,160
The, basically the cast representation.

42
00:02:14,970 --> 00:02:19,620
So now let's take these two images
and compare with our LLM, right?

43
00:02:20,280 --> 00:02:23,570
So today, a few words to any LLM, right?

44
00:02:23,630 --> 00:02:26,180
We'll give you an immense
knowledge and creativity.

45
00:02:26,480 --> 00:02:28,160
It's just like a pure magic, right?

46
00:02:28,280 --> 00:02:30,860
The rabbit coming out of
that, of a magician, right?

47
00:02:31,360 --> 00:02:32,440
But think about.

48
00:02:33,130 --> 00:02:34,660
The same model.

49
00:02:34,780 --> 00:02:39,550
What's little tweak in your prompts
or little tweak in your user inputs

50
00:02:40,120 --> 00:02:44,620
can produce an dangerous nonsense,
which is completely magnets.

51
00:02:44,700 --> 00:02:48,480
Think about the chaos, which we
called out on the right side, right?

52
00:02:49,140 --> 00:02:53,460
So this is exactly the prompting
paradox, which we are talking about

53
00:02:53,640 --> 00:02:56,400
has elements, having the immense power.

54
00:02:56,900 --> 00:03:00,890
Trapped in that, but it can
provide us unpredictable craft.

55
00:03:01,430 --> 00:03:02,840
Let's take a few examples.

56
00:03:02,840 --> 00:03:05,150
We just don't wanna spend more
time on this slide, but just want

57
00:03:05,150 --> 00:03:07,070
to give you an example, right?

58
00:03:07,570 --> 00:03:12,339
You can say generative web app like
apple.com or provide me the insights

59
00:03:12,339 --> 00:03:15,850
into the company's performance,
or based on the data sets, provide

60
00:03:15,850 --> 00:03:17,559
me the investment ideas, right?

61
00:03:18,040 --> 00:03:20,769
So today the LLM can
do that for you, right?

62
00:03:20,769 --> 00:03:24,829
It can give you all the inputs, all
the insights so on and so forth.

63
00:03:25,220 --> 00:03:28,999
So similarly, if it change a little
verbiage of it, instead of saying,

64
00:03:28,999 --> 00:03:34,160
generating a web app like apple.com,
you say generate an Apple web app.

65
00:03:34,834 --> 00:03:36,394
Output is completely different.

66
00:03:36,484 --> 00:03:38,434
Again, based out of contest as well.

67
00:03:38,974 --> 00:03:45,664
So today we are moving from the artistic
view to the industrial view, right?

68
00:03:46,174 --> 00:03:49,204
And see how we can resolve
this prompting paradox.

69
00:03:49,355 --> 00:03:49,924
All right.

70
00:03:50,284 --> 00:03:55,275
With that said, let's let's move into
why this craft doesn't work, or what

71
00:03:55,275 --> 00:03:59,565
is the problem we are facing with this
unpredictable challenges with M'S.

72
00:03:59,565 --> 00:04:00,495
Output, right?

73
00:04:01,035 --> 00:04:05,105
So before before we see the three
walls, which is quite important,

74
00:04:05,525 --> 00:04:09,424
but we wanna talk about the
traditional system first, right?

75
00:04:09,904 --> 00:04:14,254
So our tradition systems were always
like deterministic systems, right?

76
00:04:14,314 --> 00:04:17,524
Which is basically works out of
your business logic or your set

77
00:04:17,524 --> 00:04:18,784
of rules, which we have derived.

78
00:04:19,084 --> 00:04:22,865
So you send a sequence of inputs, it
just gets through your business logic,

79
00:04:22,865 --> 00:04:24,544
and finally you get into the output.

80
00:04:24,694 --> 00:04:29,975
It's very deterministic in nature,
but whereas in LLM, it's completely

81
00:04:29,975 --> 00:04:31,804
unpredictable behavior, right?

82
00:04:31,804 --> 00:04:33,964
There's no logic or there is no.

83
00:04:34,539 --> 00:04:36,370
Systematic structure in place.

84
00:04:36,609 --> 00:04:41,469
And if you look at the way the LLM being
applied, the LLM being productionized

85
00:04:41,979 --> 00:04:47,319
in critical domains like, healthcare,
finance, as well as education, right?

86
00:04:48,129 --> 00:04:51,069
Has those domains start adopting the LLM?

87
00:04:51,639 --> 00:04:57,489
The how put of this particular
L LMS is a key role, right?

88
00:04:57,849 --> 00:05:00,279
We want unbiased content delivery.

89
00:05:01,034 --> 00:05:05,924
Though this LM is very powerful, but
it does exhibits the non-domestic

90
00:05:05,924 --> 00:05:10,424
responses, biases, vulnerabilities and
whatnot, which we already are aware.

91
00:05:11,114 --> 00:05:16,275
So if I wanna group all of them into
three walls which categorizes all the

92
00:05:16,275 --> 00:05:18,824
issues into it as the safety wall.

93
00:05:19,155 --> 00:05:21,674
So the safety wall is basically includes.

94
00:05:21,750 --> 00:05:22,920
Prompt injection.

95
00:05:22,980 --> 00:05:26,400
So you guys already know what's prompt
injection, but in a quick overview

96
00:05:26,780 --> 00:05:28,460
in a prompt injection basically.

97
00:05:28,460 --> 00:05:34,549
And, while she is user crafts an
attack, right to override the original

98
00:05:34,549 --> 00:05:36,169
instructions given to the model.

99
00:05:36,229 --> 00:05:41,239
Or we might ingest a new commands
or misleading the entire contest

100
00:05:41,659 --> 00:05:45,289
or tricks the model into revealing
restricted information or

101
00:05:45,289 --> 00:05:47,539
performing unintended actions.

102
00:05:47,650 --> 00:05:50,140
So the prompt injection is
part of the safety wall.

103
00:05:50,434 --> 00:05:54,764
And the jailbreaking the jailbreaking
again looks like, tricking the

104
00:05:54,764 --> 00:05:58,004
model into ignoring the safety
rules, what we have built in, or

105
00:05:58,004 --> 00:06:03,094
get the model to generate prohibited
content or access ed data, right?

106
00:06:03,194 --> 00:06:05,924
Which is not intended to be going out.

107
00:06:06,139 --> 00:06:09,919
That's all together combined into
a safety wall, prompt injection,

108
00:06:09,919 --> 00:06:11,569
jailbreaking and biased outputs.

109
00:06:11,679 --> 00:06:14,579
And the second key wall here
is the consistency wall.

110
00:06:14,789 --> 00:06:19,229
When we talk about the consistency wall,
we won't get the right results every

111
00:06:19,229 --> 00:06:26,259
time with simple bit of change in the
phrasings, you get all together a 180 ton.

112
00:06:26,884 --> 00:06:27,424
Output.

113
00:06:27,614 --> 00:06:32,654
So basically this refers to how different
ways of asking the same question can

114
00:06:32,654 --> 00:06:35,094
lead to different answers using LLM.

115
00:06:35,634 --> 00:06:39,324
So let's take an example to prove what
is this consistency I'm talking about?

116
00:06:39,774 --> 00:06:43,404
So the prompting me doing a
prompting, I'll ask, what's the

117
00:06:43,404 --> 00:06:45,414
best way to learn Python, right?

118
00:06:45,984 --> 00:06:49,224
And in the next time I ask,
how should a beginner get

119
00:06:49,224 --> 00:06:50,724
started with Python programming?

120
00:06:51,554 --> 00:06:55,574
In my view, both as the same
thing, but the model might

121
00:06:55,574 --> 00:06:57,554
recommend different resources.

122
00:06:58,154 --> 00:07:00,344
It emphasizes different learning styles.

123
00:07:00,484 --> 00:07:04,414
Even contradict itself in some cases,
which we all of us haven't seen.

124
00:07:05,044 --> 00:07:07,114
So why this happens, right?

125
00:07:07,354 --> 00:07:09,815
The LMS are sensitive
to wording and contest.

126
00:07:09,815 --> 00:07:11,164
We already know all of that.

127
00:07:11,705 --> 00:07:14,044
They don't understand
meaning the ways human do.

128
00:07:14,224 --> 00:07:15,575
They predict text based on patterns.

129
00:07:16,075 --> 00:07:19,525
The slight changes in phrasing the
way we did, in example, prompter and

130
00:07:19,525 --> 00:07:23,455
prompt B can activate different parts
of the model training data as well.

131
00:07:24,115 --> 00:07:28,165
So that's the consistency
wall is we hit with this lms.

132
00:07:28,245 --> 00:07:31,065
And the third important
one is the complexity wall.

133
00:07:31,120 --> 00:07:36,680
Though it looks like very simple, but when
you productionize your system, this wall

134
00:07:36,680 --> 00:07:39,034
plays a major blocker or major hurdle.

135
00:07:39,534 --> 00:07:44,905
So think about we generating
and numerous prompts, right?

136
00:07:45,415 --> 00:07:46,735
Prompts on top of prompts.

137
00:07:46,735 --> 00:07:51,355
Prompts are on top of prompts
to derive one of the derived

138
00:07:51,414 --> 00:07:52,914
output of the lms, right?

139
00:07:53,664 --> 00:07:57,114
So what we try to do is we try
to do too many things at once.

140
00:07:57,215 --> 00:07:59,675
That's how I have learned
my initial prompting.

141
00:08:00,005 --> 00:08:04,625
And I used to include nested instructions,
conditions, or role playing, everything

142
00:08:04,625 --> 00:08:08,855
combined together, and it was lacking
the model or structure or clarity.

143
00:08:09,520 --> 00:08:13,570
It's hard to reuse, debug, or scale,
which part of my instruction is not

144
00:08:13,570 --> 00:08:15,670
working or deriving the different results.

145
00:08:16,180 --> 00:08:20,740
So it's very important that we answer
that in our framework in a simple word.

146
00:08:20,860 --> 00:08:24,850
The complexity wall, which I'm talking
about is with our current methods.

147
00:08:24,940 --> 00:08:28,990
We are building like a skyscraper
with sticky nos, right?

148
00:08:29,060 --> 00:08:31,250
Without any structure in place.

149
00:08:31,670 --> 00:08:34,620
So that's the complexity
wall we are talking about.

150
00:08:34,620 --> 00:08:36,630
This is the three walls we hit.

151
00:08:37,135 --> 00:08:41,665
To craft why the craft doesn't
scale, why our LLM craft.

152
00:08:41,860 --> 00:08:43,120
It doesn't scale.

153
00:08:43,390 --> 00:08:47,410
So before we get into the solution
I want to just run through beyond

154
00:08:47,410 --> 00:08:48,820
traditional benchmarks, right?

155
00:08:49,120 --> 00:08:52,450
So our traditional benchmarks,
we all know it's on rule based

156
00:08:52,450 --> 00:08:54,160
or business logic based, right?

157
00:08:54,580 --> 00:08:58,630
But whereas evaluating LLM, we
need modern evaluation framework.

158
00:08:58,635 --> 00:08:58,835
We all.

159
00:08:59,465 --> 00:09:00,005
Agree.

160
00:09:00,335 --> 00:09:04,415
So why do we need modern evaluation
framework to address the challenges of

161
00:09:04,415 --> 00:09:11,165
generative ai, which are non-determinism,
emergent behaviors, contextual

162
00:09:11,165 --> 00:09:13,025
understanding, so on and so forth.

163
00:09:13,535 --> 00:09:17,255
So this is exactly has why
we need a AI framework.

164
00:09:17,665 --> 00:09:21,355
Which provides safety,
reliability, and trustworthiness.

165
00:09:21,655 --> 00:09:25,165
So just want to give you a bit of context
between the traditional benchmarks as

166
00:09:25,165 --> 00:09:29,645
well as the l alum and to prove to a
point that why we need a framework, right?

167
00:09:30,125 --> 00:09:33,045
So now let's talk about
the framework, right?

168
00:09:34,005 --> 00:09:38,145
So in today's topic, we introduce
something called a prompt constitution,

169
00:09:38,235 --> 00:09:42,535
think as a very similar constitutional
rules we all abide to, right?

170
00:09:43,495 --> 00:09:46,615
Baking ethics and the
evaluation is the key, right?

171
00:09:46,975 --> 00:09:50,065
So this prom constitution paradigm.

172
00:09:50,565 --> 00:09:55,755
Choose most modular, reusable and
verifiable framework that structures

173
00:09:55,755 --> 00:09:57,765
human element interactions, right?

174
00:09:58,395 --> 00:10:03,405
So the whole constitution is based
on three basic pillars and absolutely

175
00:10:03,405 --> 00:10:06,465
we look into the more advanced
con concepts as we move along.

176
00:10:07,035 --> 00:10:10,275
So the three basic pillars
are structural integrity.

177
00:10:10,575 --> 00:10:13,965
Why do we need structural
integrity for smarter s?

178
00:10:14,475 --> 00:10:16,245
And the third is safety nets.

179
00:10:16,635 --> 00:10:19,815
Why do we need the
guardrails for safer lums?

180
00:10:20,295 --> 00:10:23,085
And probably we'll talk about
the scalability assembly,

181
00:10:23,245 --> 00:10:24,475
for scalable framework.

182
00:10:24,775 --> 00:10:29,425
So this is exactly the three problems
which we have seen in Y craft doesn't

183
00:10:29,425 --> 00:10:32,705
scale the three walls, with spoke about.

184
00:10:32,885 --> 00:10:38,015
So similarly, the constitution addresses
those three walls with the three pillars.

185
00:10:38,465 --> 00:10:41,975
The pillars are structural integrity,
safety nets, and scalable assembly.

186
00:10:42,605 --> 00:10:46,175
So now we'll deep dive into
those three basic foundations.

187
00:10:46,175 --> 00:10:49,955
What's very important before
we move forward on some of

188
00:10:49,955 --> 00:10:51,245
the evaluation techniques?

189
00:10:51,905 --> 00:10:54,965
So the part one is, or the
pillar one, which I call it,

190
00:10:55,235 --> 00:10:56,795
is a structural integrity.

191
00:10:57,455 --> 00:11:01,205
So the whole idea what the
structural integrity brings in us

192
00:11:01,205 --> 00:11:03,995
top using one Jane Perfect product.

193
00:11:04,415 --> 00:11:07,775
So we are breaking our prompt
into a complex task, right?

194
00:11:08,075 --> 00:11:11,015
Whatever the complex task we have,
we are gonna break it down into a

195
00:11:11,015 --> 00:11:13,295
chain of specialized and simple steps.

196
00:11:13,655 --> 00:11:19,175
So the idea is to create most modular,
most testable, most reusable components.

197
00:11:19,745 --> 00:11:23,975
So think about this HU building
and a single story house, right?

198
00:11:24,245 --> 00:11:25,535
We won't do it.

199
00:11:25,805 --> 00:11:29,105
Everything on the day one or
everything grouped into day one, right?

200
00:11:29,525 --> 00:11:30,845
We start with the foundation.

201
00:11:31,490 --> 00:11:32,720
That's a decomposing.

202
00:11:32,930 --> 00:11:36,800
We start with the foundation, then we
go layer one, layer two, layer three.

203
00:11:36,860 --> 00:11:38,510
Then we'll finish everything together.

204
00:11:39,140 --> 00:11:43,070
So decomposing thought for
clarity and control is the call of

205
00:11:43,130 --> 00:11:44,930
action in the pillar one, right?

206
00:11:45,440 --> 00:11:49,310
So we spoke about what it is,
but let's take a look at it

207
00:11:49,310 --> 00:11:50,990
in real example right here.

208
00:11:51,470 --> 00:11:54,900
So I have a simple LLM
which performs a basic task.

209
00:11:55,230 --> 00:11:57,060
The task is something like this, right?

210
00:11:57,510 --> 00:12:00,750
It basically analyzes the
customer review saying I'm

211
00:12:00,750 --> 00:12:03,140
using any product as a customer.

212
00:12:03,140 --> 00:12:04,370
I provide the review.

213
00:12:05,060 --> 00:12:08,810
So it needs to analyze the customer
review for the sentiment in which

214
00:12:08,810 --> 00:12:13,580
I'm expressing it, and what the
key topics, i'm talking about and

215
00:12:13,580 --> 00:12:15,380
such as, back me a response, right?

216
00:12:16,040 --> 00:12:19,040
Sora of human, we want
our LLMs to do it, right?

217
00:12:19,070 --> 00:12:20,150
That's a simple task.

218
00:12:20,780 --> 00:12:24,650
Now let's look at the whole way our
monolithic prompting way we used to

219
00:12:24,800 --> 00:12:26,210
prompt this to our models, right?

220
00:12:26,300 --> 00:12:29,940
Or I used to do it in starting
of, my journey, right?

221
00:12:30,300 --> 00:12:31,620
Or my prompt journey.

222
00:12:32,610 --> 00:12:36,210
So I used to call it, Hey, read this
review and tell me the sentiment,

223
00:12:36,360 --> 00:12:39,600
the main topics discussed, and
write a customer service response.

224
00:12:40,100 --> 00:12:44,420
I was very happy, hey, I've given
kind of a very good prompt and,

225
00:12:44,420 --> 00:12:49,610
model is taking it and it's giving me
sentiments and analysis as I move along.

226
00:12:50,090 --> 00:12:53,270
I've learned is this is not
the right way of prompting.

227
00:12:53,810 --> 00:12:55,280
I need to break it down.

228
00:12:55,280 --> 00:12:57,200
I need to have a structure in place.

229
00:12:57,320 --> 00:13:02,960
How did we learn when we move, like a
hundred reviews, 200 reviews, 300 reviews.

230
00:13:03,020 --> 00:13:08,000
Then you start seeing model being, bias
model was giving you the outputs, which is

231
00:13:08,000 --> 00:13:10,730
not intended or so on and so forth, right?

232
00:13:11,180 --> 00:13:13,730
The accuracies in caution,
so on and so forth.

233
00:13:14,240 --> 00:13:16,910
So in order to resolve the issues to.

234
00:13:17,410 --> 00:13:19,810
And we recommend as
part of the filler one.

235
00:13:20,530 --> 00:13:24,640
So it consists of basically a router
which classifies the task, right?

236
00:13:24,760 --> 00:13:27,340
What task needs to be
done by bed specialist?

237
00:13:27,730 --> 00:13:31,420
So in our case, for this task, we
have three different specialists.

238
00:13:31,540 --> 00:13:35,650
The specialist A, basically
determine the sentiment of the text.

239
00:13:35,650 --> 00:13:36,935
It basically analyze.

240
00:13:37,825 --> 00:13:43,345
You know the review and gives you
an output of a sentiment, which

241
00:13:43,345 --> 00:13:44,725
is coming out of those texts.

242
00:13:44,935 --> 00:13:46,795
It won't do anything more than that.

243
00:13:47,110 --> 00:13:48,610
Right then absolutely.

244
00:13:48,610 --> 00:13:52,080
We will be having an, the ation
model which you'll talk in detail

245
00:13:52,140 --> 00:13:53,520
as part of our constitution.

246
00:13:54,040 --> 00:13:57,130
Which will ate the output
coming out of e specialist.

247
00:13:57,130 --> 00:14:01,790
But from now, let's think that specialist
a. Which will just determine the

248
00:14:01,790 --> 00:14:03,620
sentiment, all of the text, right?

249
00:14:03,830 --> 00:14:09,040
Then we are gonna have the specialist
B, which is chained workflow, which

250
00:14:09,040 --> 00:14:12,580
basically lists the key topics and
the concerns, which is coming out

251
00:14:12,580 --> 00:14:14,260
of the particular review, right?

252
00:14:14,470 --> 00:14:17,115
It just lists down, okay, here
is the topics which has been

253
00:14:17,260 --> 00:14:20,170
discussed about this particular
product, and these are the concerns.

254
00:14:20,920 --> 00:14:22,750
And specialist C, right?

255
00:14:23,230 --> 00:14:24,400
Given the sentiment.

256
00:14:24,975 --> 00:14:29,235
Which is an output from specialist
A. And given the topics which

257
00:14:29,235 --> 00:14:34,005
is output from specialist B, it
will draft a helpful responses

258
00:14:34,005 --> 00:14:36,415
which needs to, go to our clients.

259
00:14:36,515 --> 00:14:37,295
So what is that?

260
00:14:37,355 --> 00:14:42,305
We achieve all of the structural
integrity, our creating the different

261
00:14:42,305 --> 00:14:46,475
specialist and linking all together
to a workflow, which evaluation at

262
00:14:46,475 --> 00:14:48,875
the eat stage gives us more accuracy.

263
00:14:49,610 --> 00:14:53,930
More control and each component
is reusable for other tasks.

264
00:14:53,930 --> 00:14:54,920
Think about Tamara.

265
00:14:54,920 --> 00:14:59,780
You're gonna set up one more LLM, which
does need a topic extraction, so you

266
00:14:59,780 --> 00:15:02,060
no need to rebuild all the way again.

267
00:15:02,210 --> 00:15:06,410
Queue the specialist P. Similarly,
in one of your other project,

268
00:15:06,410 --> 00:15:08,900
you need a sentiment analyzer.

269
00:15:08,990 --> 00:15:09,470
Here we go.

270
00:15:09,470 --> 00:15:11,660
You have a specialist A,
which you can reuse it.

271
00:15:12,200 --> 00:15:15,620
So that's the part one,
the structural integrity.

272
00:15:15,770 --> 00:15:16,850
It's very crucial.

273
00:15:17,350 --> 00:15:22,030
Then moving on to the part two, the
guardrails, the safety nets, right?

274
00:15:22,530 --> 00:15:27,420
So the whole idea has being proactive
defense, not reactive filtering.

275
00:15:27,600 --> 00:15:31,060
That's the takeaway out
of, the pillar two, right?

276
00:15:31,690 --> 00:15:36,160
So the idea is, instead of hers just
validating the output the model has

277
00:15:36,160 --> 00:15:39,670
generated or the LLM has generated
and filtering out certain part of it

278
00:15:39,670 --> 00:15:42,650
and giving to the client is not the.

279
00:15:43,150 --> 00:15:46,330
Desired way we wanna go at,
that's exactly one we need to

280
00:15:46,330 --> 00:15:47,860
avoid as part of the safety net.

281
00:15:48,220 --> 00:15:53,140
We need to engineer the safety
nets all the way throughout

282
00:15:53,140 --> 00:15:54,880
the process of an LLM, right?

283
00:15:55,570 --> 00:15:58,060
To be inly safer, right?

284
00:15:58,360 --> 00:16:02,135
So building safety into the prompt
architecture is what the pillar two is

285
00:16:02,135 --> 00:16:04,115
talking about, the safety nets, right?

286
00:16:04,685 --> 00:16:07,115
So again, let's talk about an example.

287
00:16:07,215 --> 00:16:10,275
It'll be very useful when we run
through an example rather than.

288
00:16:11,040 --> 00:16:14,210
Talking with the words here, same same.

289
00:16:14,240 --> 00:16:17,450
Let's take it, same scenario the
way we had earlier, but now we are

290
00:16:17,450 --> 00:16:19,010
gonna talk about the service board.

291
00:16:19,520 --> 00:16:22,730
So a user ask a customer
service board, right?

292
00:16:22,760 --> 00:16:26,820
Basically a financial, not you
ask details about your banking

293
00:16:26,820 --> 00:16:28,260
and gonna respond your bank.

294
00:16:28,830 --> 00:16:33,660
So now user ask a question, Hey,
my account was charged incorrectly.

295
00:16:34,230 --> 00:16:37,920
Also, how do I hack into
someone else account?

296
00:16:38,310 --> 00:16:43,610
So as part of the first topic I call
it about just filtering the output,

297
00:16:44,240 --> 00:16:48,980
so this entire user input goes to the
LLM hazardous and derive the output.

298
00:16:49,010 --> 00:16:49,915
Then you look at the output.

299
00:16:50,630 --> 00:16:53,150
Then you filter it out certain
pattern and send it to the user.

300
00:16:53,600 --> 00:16:58,490
But this guardrail gonna introduce
something called as pre prosor.

301
00:16:58,790 --> 00:17:03,800
Before this goes to your actual
processing engine or your L alarms.

302
00:17:04,160 --> 00:17:06,560
We will set up and pre-pro guardian.

303
00:17:06,620 --> 00:17:09,455
It can be an Android LLM,
you're gonna build another

304
00:17:09,455 --> 00:17:11,120
agent, your bill doesn't matter.

305
00:17:11,120 --> 00:17:15,310
But I have a pre-pro syn, which
basically analyze the user query.

306
00:17:15,865 --> 00:17:20,045
Any request coming in, for example,
let's look at, this particular user

307
00:17:20,045 --> 00:17:22,175
task account was charged incorrectly.

308
00:17:22,775 --> 00:17:26,505
So you're pre-processing guard,
takes this, okay, my account was

309
00:17:26,505 --> 00:17:28,695
changed, charged incorrectly.

310
00:17:28,695 --> 00:17:29,325
Excuse me.

311
00:17:29,775 --> 00:17:35,775
So that's a valid task, which my customer
service board needs to answer, right?

312
00:17:36,345 --> 00:17:38,265
And it looks the second phase of it.

313
00:17:38,295 --> 00:17:41,535
Also, how do I hack into
someone's health account?

314
00:17:42,030 --> 00:17:44,430
Then that's a clear violation, right?

315
00:17:44,790 --> 00:17:49,260
My pre-pro or guardian will flag
it for the violation and say

316
00:17:49,260 --> 00:17:53,280
that, Hey, I can't consume the
second part of the statement here.

317
00:17:53,730 --> 00:17:56,160
Then the safe responses will be generated.

318
00:17:56,400 --> 00:17:59,130
Hey, it takes the first
one, which is important.

319
00:17:59,400 --> 00:18:02,340
It says that I would happy to help
with the billing issue on your account.

320
00:18:02,370 --> 00:18:03,570
That's why I'm intended to.

321
00:18:04,060 --> 00:18:08,140
The model is intended to do that, but it's
saying, regarding your other question, I

322
00:18:08,140 --> 00:18:12,610
cannot provide guidance on the topic as
it violates my safety policies, right?

323
00:18:12,940 --> 00:18:17,320
In that way, your alum never talks
through any data or any account, the

324
00:18:17,320 --> 00:18:21,650
pre-processing filter outs, what are the
valid actions, what are the violations,

325
00:18:22,010 --> 00:18:24,620
and it's just pre-pro at the stage one.

326
00:18:24,620 --> 00:18:28,490
But you can have the safety
net at each and every layer

327
00:18:28,490 --> 00:18:29,990
of your entire agent solution.

328
00:18:30,625 --> 00:18:34,735
So the benefit, what we are gonna
get out of us, the armful query

329
00:18:34,735 --> 00:18:38,575
is neutralized as we have seen in
an example, before it even reaches

330
00:18:38,575 --> 00:18:40,645
the core response generator, right?

331
00:18:41,035 --> 00:18:46,525
So baking in ethics from the start of
your solution is the key safety net

332
00:18:46,735 --> 00:18:51,295
pillar, which we need to build right,
all the way til to the output, just

333
00:18:51,295 --> 00:18:53,365
not filtering the data generated.

334
00:18:53,815 --> 00:18:55,165
As part of output response.

335
00:18:55,165 --> 00:18:58,115
So just the, that's the second
pillar that's a takeaway

336
00:18:58,115 --> 00:18:59,285
out of the second pillar.

337
00:18:59,825 --> 00:19:04,415
Now, moving on towards the
Pillar three, which I call it a

338
00:19:04,415 --> 00:19:06,305
scalable assembly, the connectors.

339
00:19:07,070 --> 00:19:11,120
So this purely talks about how we
maintain our prompts, though it looks

340
00:19:11,120 --> 00:19:16,730
simple or it looks, eh, we have an a
get, we maintain what, and we maintain

341
00:19:16,730 --> 00:19:19,070
prompts, but it's very important.

342
00:19:19,290 --> 00:19:22,710
We treat the each and every
prompt as a software component.

343
00:19:22,710 --> 00:19:23,625
Today we build, right?

344
00:19:24,125 --> 00:19:29,165
We version them, we test them at
huge unit level and integration

345
00:19:29,165 --> 00:19:31,055
level and whatnot, right?

346
00:19:31,715 --> 00:19:32,885
And we compose them.

347
00:19:33,690 --> 00:19:37,140
So make sure that the way the
software is delivered, you have CICD

348
00:19:37,140 --> 00:19:41,970
pipeline, you have BNB testing, right
between version one and version two.

349
00:19:42,810 --> 00:19:48,120
And always when we deliver software,
we are optimistic that it'll work, but

350
00:19:48,120 --> 00:19:49,830
in the meantime, we prepare for any.

351
00:19:50,760 --> 00:19:51,510
Failures, right?

352
00:19:51,510 --> 00:19:53,580
We prepare for the failures to roll back.

353
00:19:53,880 --> 00:19:56,550
You have feature flagging
concept today, right?

354
00:19:56,550 --> 00:19:59,340
Or you have, you roll back the
complete build automatically

355
00:19:59,340 --> 00:20:00,540
as part of the deployment.

356
00:20:01,110 --> 00:20:04,500
The same logic needs to be
applied for the prompting.

357
00:20:04,770 --> 00:20:07,290
So that's the scalable
assembly we are talking about.

358
00:20:07,740 --> 00:20:08,675
So the idea is.

359
00:20:09,175 --> 00:20:13,225
We differentiate your catalog, basically
your prompts, your sentiment, and

360
00:20:13,225 --> 00:20:16,825
analyze prompt your topic, extractor,
your guardian constitution, and

361
00:20:16,825 --> 00:20:20,665
the old architecture engine, which
runs those prompts and give us the

362
00:20:20,665 --> 00:20:24,805
results is a complete subset and
we version each and every prompt

363
00:20:24,805 --> 00:20:26,665
or each and every phrase we change.

364
00:20:27,165 --> 00:20:29,385
In our prompts, right?

365
00:20:29,745 --> 00:20:34,215
So in that way, if tomorrow we wanna
roll back, Hey, V one was working fine.

366
00:20:34,215 --> 00:20:36,285
The V two is not working,
you just roll back.

367
00:20:36,285 --> 00:20:37,395
It's as simple as that.

368
00:20:37,395 --> 00:20:41,625
You're using Cloudi model
and you have four sonet and

369
00:20:41,625 --> 00:20:43,815
you got three three dot Xnet.

370
00:20:43,995 --> 00:20:47,925
So three dot x is deriving you more
results and you wanna roll back from four

371
00:20:47,925 --> 00:20:49,120
to three products, which you can do it.

372
00:20:49,620 --> 00:20:54,570
The similar concept or component needs to
be applicable for each problem we build.

373
00:20:55,110 --> 00:20:59,000
So what the benefit we get out of it, the
complete stability and maintainability.

374
00:20:59,000 --> 00:21:02,320
If we think things are not working
in production, after all your

375
00:21:02,320 --> 00:21:07,120
A-B-E-A-B testing or CICD, it's
very easy for us to swap to the

376
00:21:07,120 --> 00:21:08,680
previous version and move forward.

377
00:21:09,190 --> 00:21:11,770
So that's exactly what we are talking and.

378
00:21:12,100 --> 00:21:15,160
Make sure the library in which
is a catalog, that's where

379
00:21:15,160 --> 00:21:16,600
all your versions are defined.

380
00:21:16,840 --> 00:21:20,225
If you wanna do a rollback, it
should be just one line change.

381
00:21:20,960 --> 00:21:24,140
So these are the three
foundational pillars which we

382
00:21:24,140 --> 00:21:28,020
recommend to follow as part of
constitutional prompting framework.

383
00:21:28,320 --> 00:21:33,190
Right now, let's take a look at,
how this constitution work, right?

384
00:21:33,640 --> 00:21:38,110
The constitution prompting or framework
starts with defining the Constitution.

385
00:21:38,410 --> 00:21:42,460
So you define your own
constitution, so based on your

386
00:21:42,460 --> 00:21:44,350
organizational values, right?

387
00:21:44,380 --> 00:21:47,030
Your regulatory requirements,
if you're working and.

388
00:21:47,530 --> 00:21:50,350
Finance, you might be
entitled to FINRA regulatory.

389
00:21:50,980 --> 00:21:54,640
If you're working in healthcare, you might
be entitled to healthcare regulatory.

390
00:21:54,640 --> 00:21:54,790
And.

391
00:21:55,660 --> 00:21:59,110
On top of this organization,
values and regulated requirements,

392
00:21:59,110 --> 00:22:01,780
the key important pieces.

393
00:22:02,140 --> 00:22:03,970
What are your ethical principles?

394
00:22:04,030 --> 00:22:08,530
What are your behavioral guidelines
that your Constitution should abide to?

395
00:22:08,890 --> 00:22:10,150
So that's the first step.

396
00:22:10,240 --> 00:22:11,650
Define your constitution.

397
00:22:11,950 --> 00:22:14,285
And the second one is self critic.

398
00:22:14,925 --> 00:22:19,275
Your output, your LLM output or
prompting output at each stage?

399
00:22:19,375 --> 00:22:23,785
So the idea is that each stage,
every model output is evaluated.

400
00:22:24,200 --> 00:22:25,040
Against what?

401
00:22:25,250 --> 00:22:28,310
Against the defined constitutional
principles we did in stage

402
00:22:28,310 --> 00:22:33,980
one and identify any potential
violations or misalignments, right?

403
00:22:34,400 --> 00:22:36,140
So that's the phase two.

404
00:22:36,890 --> 00:22:38,240
Define your constitution.

405
00:22:38,270 --> 00:22:42,650
Have self critic, baking yourself,
critic as part of your pipeline.

406
00:22:43,280 --> 00:22:44,900
And the third one is revision.

407
00:22:45,140 --> 00:22:49,490
As you do this critic, as you
define your constitution, Q is, see,

408
00:22:49,490 --> 00:22:53,150
there is a lot of areas where you
can generate improved responses.

409
00:22:53,480 --> 00:22:56,990
You can be more safety, you can
implement better constraints.

410
00:22:57,230 --> 00:22:58,850
So that's the revision, right?

411
00:22:58,865 --> 00:22:59,445
As I said.

412
00:23:00,200 --> 00:23:04,820
Treat your prompt as code,
structurize it, ize it, and move on.

413
00:23:05,300 --> 00:23:08,150
And finally, very key reinforcement.

414
00:23:08,330 --> 00:23:12,410
It's very important that we give feedback
to the LMS what we are building, or

415
00:23:12,410 --> 00:23:16,220
give feedback to the prompts which we
are sending or give feedback to the

416
00:23:16,220 --> 00:23:19,645
racks what's been implemented, pulled
over in a complete holistic view.

417
00:23:20,000 --> 00:23:21,500
And this feedback should be.

418
00:23:22,280 --> 00:23:27,920
Learned and self feel, self-evaluate,
whatever the reinforcement

419
00:23:27,920 --> 00:23:29,510
techniques you wanna define.

420
00:23:30,010 --> 00:23:32,200
We need to define as part
of this constitution.

421
00:23:32,350 --> 00:23:34,450
So the constitution works
out of the four ways.

422
00:23:34,450 --> 00:23:37,840
Define your constitution, have
itself critic, have it revised,

423
00:23:38,230 --> 00:23:41,980
and make sure you have the feedback
going in as part of reinforcement.

424
00:23:42,850 --> 00:23:47,670
All right so now I'm gonna talk
through a few of the, evaluation.

425
00:23:47,720 --> 00:23:52,035
What are the key objectives when we
want to evaluate it or when you wanna

426
00:23:52,035 --> 00:23:55,005
do a self or make sure your prompts are.

427
00:23:55,505 --> 00:24:00,425
Deriving the right results after you're
applying the three structured pillars.

428
00:24:00,845 --> 00:24:04,565
So the synthetic data
generation is very key, right?

429
00:24:04,625 --> 00:24:09,485
What kind of data has been
evaluated against the model

430
00:24:09,485 --> 00:24:10,715
or agent you're building?

431
00:24:10,925 --> 00:24:13,565
So before we define the data.

432
00:24:14,065 --> 00:24:19,075
I recommend we need to define
the evaluation objectives, right?

433
00:24:19,435 --> 00:24:20,365
Generate your data.

434
00:24:20,365 --> 00:24:23,965
Fair enough, but before
generating the data, define the

435
00:24:23,965 --> 00:24:25,615
evaluation objectives, right?

436
00:24:26,065 --> 00:24:30,535
You are generating the data to evaluate
what is it for factor accuracy.

437
00:24:30,535 --> 00:24:32,005
Is it for reasoning ability?

438
00:24:32,005 --> 00:24:34,315
Is it for bias, or is it for fairness?

439
00:24:34,315 --> 00:24:35,875
Is it for robustness?

440
00:24:36,415 --> 00:24:40,045
Towards the advisor inputs or
instruction following, or is it

441
00:24:40,045 --> 00:24:43,675
due to the multi turn dial, ance,
or safety and refusal behavior?

442
00:24:43,675 --> 00:24:47,065
It might be any one off
this evaluation techniques.

443
00:24:47,455 --> 00:24:49,225
Make sure you define the objective.

444
00:24:49,915 --> 00:24:55,665
Of this evaluation and create the
synthetic data, those particular criteria.

445
00:24:56,025 --> 00:24:59,835
So you can use l LMS to generate
synthetic inputs, right?

446
00:24:59,865 --> 00:25:03,685
Or you can have your own set of
caution answer pairs which you

447
00:25:03,685 --> 00:25:08,875
think, which generally coming in,
or you create your own paraphrased

448
00:25:08,875 --> 00:25:10,855
prompts to test consistency.

449
00:25:11,185 --> 00:25:13,345
Or simulate the user personas.

450
00:25:13,645 --> 00:25:18,075
So this was the kind of, data,
synthetic data templates you need to

451
00:25:18,075 --> 00:25:20,205
define for each evaluation techniques.

452
00:25:20,685 --> 00:25:24,315
And once you have the data
generated, try to label the

453
00:25:24,315 --> 00:25:25,815
synthetic data, which is a key.

454
00:25:26,305 --> 00:25:27,805
Is it rule-based data?

455
00:25:27,805 --> 00:25:30,985
Is it for which model to
evolve with, what are the.

456
00:25:31,220 --> 00:25:35,300
The synthetic data generated
automatically, or automatically, so

457
00:25:35,300 --> 00:25:40,100
you can use that labels to correlate
the data, what you are generated for.

458
00:25:40,400 --> 00:25:44,240
And finally, it's very important
to evolve with this metrics, again,

459
00:25:44,240 --> 00:25:48,510
as the systematic approach of,
identifying the criteria and building

460
00:25:48,510 --> 00:25:50,700
the test data against each criteria.

461
00:25:50,750 --> 00:25:55,100
And finally evaluate the metrics for
them, rather than just creating a set

462
00:25:55,100 --> 00:25:56,960
of 10 or 15 questions, which has been.

463
00:25:57,345 --> 00:26:02,085
Reuse or which are the questions you
want the model to answer and just go

464
00:26:02,085 --> 00:26:04,005
test them and pause and productionize it.

465
00:26:04,095 --> 00:26:04,335
Yeah.

466
00:26:04,965 --> 00:26:08,985
It's very important that you understand
the evaluation criteria and synthetically

467
00:26:08,985 --> 00:26:10,965
generate test data for all of them.

468
00:26:10,995 --> 00:26:13,035
Then evaluate the metrics, right?

469
00:26:14,025 --> 00:26:17,465
So that's the key for the
evaluation, the data generation.

470
00:26:18,170 --> 00:26:20,840
And the next part is red teaming.

471
00:26:20,840 --> 00:26:23,180
I don't know how many of you
heard about this red teaming

472
00:26:23,180 --> 00:26:24,980
or as advisory evaluation.

473
00:26:25,490 --> 00:26:26,750
This is very key.

474
00:26:27,020 --> 00:26:29,600
Think about the similarity,
ethical, lacking today.

475
00:26:29,600 --> 00:26:31,630
If you're building any systems, right?

476
00:26:31,690 --> 00:26:35,050
Any logging functionality or any
simple financial system or banking

477
00:26:35,050 --> 00:26:38,140
application or e-commerce application,
you do ethical lacking, right?

478
00:26:38,650 --> 00:26:41,260
You do SQL injection,
you check for the top.

479
00:26:42,080 --> 00:26:44,400
Security issues out there and whatnot.

480
00:26:44,500 --> 00:26:45,490
So the same thing.

481
00:26:45,490 --> 00:26:49,750
The red timing is a process which
involves intentionally probing the model

482
00:26:49,750 --> 00:26:55,540
to uncover vulnerabilities, biases,
unsafe behavior that can be exploited

483
00:26:55,570 --> 00:26:57,610
or cause harm in real world use.

484
00:26:57,820 --> 00:27:02,200
So there are five concepts I just wanna
stress upon and make sure that you

485
00:27:02,200 --> 00:27:04,360
include this as part of your teaming.

486
00:27:04,840 --> 00:27:06,880
One is the threat modeling right?

487
00:27:07,380 --> 00:27:09,600
And the second one is advisor generation.

488
00:27:09,720 --> 00:27:13,980
Third one is stress testing, and the
fourth one is vulnerability analysis.

489
00:27:13,980 --> 00:27:19,200
And absolutely make sure it rate your
hardening as part of this process.

490
00:27:19,410 --> 00:27:22,260
So that we spoke about the red teaming.

491
00:27:22,290 --> 00:27:27,150
What is that we gonna achieve out
of this red teaming capabilities?

492
00:27:27,495 --> 00:27:31,755
Just will help us to uncover all
the hidden risk or uncover the

493
00:27:31,755 --> 00:27:34,785
hidden risk in your prompts, in
your LMS and in your outputs.

494
00:27:34,825 --> 00:27:37,195
I've just given a basic difference here.

495
00:27:37,245 --> 00:27:40,845
Conventional testing, MRS rate,
but critical failure modes.

496
00:27:40,845 --> 00:27:44,405
But red teaming reveals prompt injection
vulnerabilities, your training, data

497
00:27:44,405 --> 00:27:48,815
leakage, alignment, failures, brittle
behavior, and systematic biases.

498
00:27:48,815 --> 00:27:49,835
It's very key that.

499
00:27:50,510 --> 00:27:55,310
You include red teaming as part
of your constitutional principles.

500
00:27:55,670 --> 00:28:01,730
All right, so then I wanna touch about
the last point before we conclude here.

501
00:28:02,130 --> 00:28:05,310
The regulatory compliance is a key, right?

502
00:28:05,360 --> 00:28:08,090
Based on your organization.

503
00:28:08,525 --> 00:28:10,685
Industry alignment, right?

504
00:28:10,835 --> 00:28:14,465
If it is finance, it is banking,
it is educational, it's medical.

505
00:28:14,945 --> 00:28:16,805
We have different regulatory complaints.

506
00:28:16,805 --> 00:28:21,555
And in terms of data you have, we
have all together and different data

507
00:28:21,555 --> 00:28:26,265
regulatory and especially for the
Europe, we have you, you AI hacked.

508
00:28:26,355 --> 00:28:30,285
If you're already known, there are certain
standards which you can take from them.

509
00:28:30,705 --> 00:28:32,445
Make sure that you include that.

510
00:28:32,905 --> 00:28:38,545
As per UEI act, any non-compliance
carries substan, substantial.

511
00:28:38,545 --> 00:28:42,235
Finalities up to 30 million or
6% of global annual turn award.

512
00:28:42,650 --> 00:28:46,640
So it's very key that you embed, you
bake in the regulatory compliance.

513
00:28:46,910 --> 00:28:50,840
So I would just wanna call out few
key complaints requirements, which UE

514
00:28:50,840 --> 00:28:55,340
Act has called down which basically
underline into the six categories, your

515
00:28:55,340 --> 00:29:00,090
risk and risk management, your data
governance, your technical documentation.

516
00:29:00,150 --> 00:29:02,250
Transparency and human oversight.

517
00:29:02,280 --> 00:29:04,740
We are gonna talk human in
the loop as an next point.

518
00:29:04,740 --> 00:29:07,650
That's very key and accuracy and ness.

519
00:29:07,850 --> 00:29:11,750
So make sure to bake in the regulatory
compliance as part of your constitution

520
00:29:11,750 --> 00:29:13,520
framework for prompts, right?

521
00:29:14,240 --> 00:29:17,470
Then finally, you wanna talk
about as human in the loop the

522
00:29:17,470 --> 00:29:19,120
critical feedback mechanism.

523
00:29:19,840 --> 00:29:23,440
We all know the elements are
powerful, but not perfect.

524
00:29:23,670 --> 00:29:28,530
They can ate facts, they can misinterpret
intent, they can amplify the bias,

525
00:29:28,530 --> 00:29:30,360
or they can fail in the edge cases.

526
00:29:31,020 --> 00:29:32,190
So human in the look.

527
00:29:32,280 --> 00:29:33,870
So I call it as the H high.

528
00:29:33,870 --> 00:29:34,680
Yeah, no.

529
00:29:34,860 --> 00:29:39,120
Bridges the gap between the model
capabilities and real world expectation.

530
00:29:39,720 --> 00:29:40,895
So what do humans do?

531
00:29:41,190 --> 00:29:45,360
Humans correct How outputs humans
guide behavior, human in the

532
00:29:45,360 --> 00:29:47,040
loop, evolve it for performance.

533
00:29:47,460 --> 00:29:50,880
Human in the loop will enforce
ethical and safety standards.

534
00:29:51,270 --> 00:29:54,875
So it's very important to have
the critical feedback mechanism

535
00:29:54,875 --> 00:29:55,985
through human in the loop.

536
00:29:56,485 --> 00:30:00,625
And holistically whatever we have
spoken today, the multidimensional

537
00:30:00,625 --> 00:30:05,425
testing framework, your building should
define your success criteria, should

538
00:30:05,425 --> 00:30:07,435
define your layer evaluation model.

539
00:30:07,495 --> 00:30:12,295
Should implement your constitutional AI
or constitutional framework or prompt

540
00:30:12,295 --> 00:30:16,435
framework at each and every level,
and establish continuous monitoring.

541
00:30:16,615 --> 00:30:19,735
Document everything and build expertise.

542
00:30:20,140 --> 00:30:25,310
So with that said I just want to
conclude with three points right here.

543
00:30:25,670 --> 00:30:30,830
So the first point is the constitutional
framework or the prompt framework,

544
00:30:30,830 --> 00:30:36,800
which we spoke about, help us to move
away from being the results prompt

545
00:30:36,800 --> 00:30:40,010
results to be a prompt engineers, right?

546
00:30:40,580 --> 00:30:44,880
So how did we solve that or how do
we achieve the prompt engineering?

547
00:30:45,525 --> 00:30:50,895
By bringing in the constitutional
three pillars, structure frame for

548
00:30:51,525 --> 00:30:57,075
smarter S, guardrails for safer s
and the connectors, which is pillar

549
00:30:57,075 --> 00:30:58,695
three for scalable framework.

550
00:30:58,995 --> 00:31:01,935
And after the pillars
we have learned about.

551
00:31:02,245 --> 00:31:07,015
The constitutional prompting, the
systematic data generation, red teaming,

552
00:31:07,015 --> 00:31:11,065
which is ethical, lacking, and even
in the loop evaluation criteria.

553
00:31:11,305 --> 00:31:16,285
So all this needs to be done to ensure
safe, transparent, and worthy at scale.

554
00:31:16,855 --> 00:31:18,470
But at closing the third point.

555
00:31:19,230 --> 00:31:24,600
Let's stop being prompt results and
stop being, start being, excuse me.

556
00:31:24,600 --> 00:31:26,220
Start being prompt engineers.

557
00:31:26,250 --> 00:31:30,870
Let's build constitutional prompting
for a smarter, safer future with ai.

558
00:31:31,470 --> 00:31:35,690
With that said, thank you for spending
almost like 20 to 30 minutes with me.

559
00:31:36,030 --> 00:31:37,050
You have a nice one.

560
00:31:37,280 --> 00:31:37,940
We'll meet again.

561
00:31:38,090 --> 00:31:38,570
Thank you.

562
00:31:38,570 --> 00:31:38,780
Bye.

