1
00:00:00,500 --> 00:00:01,250
Speaker 2: Hi everyone.

2
00:00:01,520 --> 00:00:05,650
My name is AB Kumar, and today
I'll be presenting Beyond Surveys

3
00:00:06,370 --> 00:00:09,970
realtime user Satisfaction
prediction with L LMS and Telemetry.

4
00:00:10,330 --> 00:00:14,559
This model realtime net promoter
score prediction using a multi-model

5
00:00:14,559 --> 00:00:18,340
AI aims to address one of the
most persistent challenges in

6
00:00:18,340 --> 00:00:19,510
customer experience analytics.

7
00:00:20,010 --> 00:00:24,630
The inability to capture timely and
unbiased user sentiment at scale.

8
00:00:25,130 --> 00:00:30,169
Dynamic net promoter score model
leverages behavioral data, telemetry

9
00:00:30,169 --> 00:00:35,000
signals and text analytics to
predict net promoter score in real

10
00:00:35,000 --> 00:00:39,289
time with significantly higher
accuracy than traditional approaches.

11
00:00:39,789 --> 00:00:41,595
Let's see, what is Net Promoter Score?

12
00:00:42,095 --> 00:00:46,355
Net promoter, so or NPS is widely
recorded as the industry standard

13
00:00:46,355 --> 00:00:49,144
me for measuring customer loyalty.

14
00:00:49,625 --> 00:00:51,515
It is based on a simple caution.

15
00:00:52,015 --> 00:00:57,054
How likely are you to take Windows
users respond on a zero to 10

16
00:00:57,054 --> 00:01:03,295
scale, and their responses or
categorized into detect passes and

17
00:01:03,295 --> 00:01:05,755
promoters despite its simplicity.

18
00:01:06,294 --> 00:01:10,794
NPS remains one of the most influential
metrics in product organizations,

19
00:01:11,124 --> 00:01:15,984
guiding strategy, customer satisfaction
initiatives, and growth forecasting.

20
00:01:16,484 --> 00:01:18,464
Let's see how NPS is calculated.

21
00:01:18,964 --> 00:01:25,070
As you see here, detectors are the one
who provided the rating of zero to six.

22
00:01:25,890 --> 00:01:32,399
Out of 10 and passes seven to eight
and promoters nine to 10 and NPS

23
00:01:32,399 --> 00:01:35,820
is calculated using the percentage
of promoters and detectors.

24
00:01:36,100 --> 00:01:39,730
It is calculated by subtracting
the percentage of detectors from

25
00:01:39,730 --> 00:01:43,570
the percentage of promoters NPS
changes from minus a hundred to a

26
00:01:43,570 --> 00:01:47,200
hundred scales below zero indicate.

27
00:01:47,695 --> 00:01:52,734
Poor customer sentiment While scales
between one and 30 are considered

28
00:01:52,734 --> 00:01:57,895
good scales, between 31 and 70
shows a strong market portion of

29
00:01:57,895 --> 00:02:01,945
the product, and anything above
70 is considered world class.

30
00:02:02,445 --> 00:02:05,145
This framework has been
adopted globally due to its

31
00:02:05,145 --> 00:02:07,025
simplicity, but I'll show later.

32
00:02:07,285 --> 00:02:10,490
It also comes with
significant limitations.

33
00:02:10,990 --> 00:02:12,910
Let's see how companies collect NPS today.

34
00:02:13,410 --> 00:02:16,980
Currently NPS data is collected
mostly through email service

35
00:02:16,980 --> 00:02:22,980
survey in app popups, SMS surveys
and more manual follow-ups.

36
00:02:23,340 --> 00:02:27,570
These methods rely heavily
on active user participation.

37
00:02:28,200 --> 00:02:32,215
They're slow disruptive to
the user experience, and often

38
00:02:32,215 --> 00:02:33,340
provide tail information.

39
00:02:33,985 --> 00:02:38,845
Sometimes collected days, or even weeks or
even months after the actual interaction.

40
00:02:39,295 --> 00:02:42,925
While these tools have become
standard practice, they fail to

41
00:02:42,925 --> 00:02:45,025
reflect real time user sentiment.

42
00:02:45,525 --> 00:02:49,575
The next slide is we'll see
what the companies are facing.

43
00:02:49,575 --> 00:02:51,015
Problem with the NPS.

44
00:02:51,255 --> 00:02:54,770
There are four major challenges
common in traditional NPS collection.

45
00:02:55,510 --> 00:02:57,615
First is the participation gap.

46
00:02:58,115 --> 00:03:02,255
Response rates generally fall
between G one, between one and 5%,

47
00:03:02,555 --> 00:03:07,115
which means majority of the users
remain silent, so less than 5%

48
00:03:07,115 --> 00:03:09,424
of users respond to our service.

49
00:03:09,924 --> 00:03:11,664
Second is the speed barrier.

50
00:03:12,564 --> 00:03:15,864
Insights become available only
after a significant delay.

51
00:03:15,864 --> 00:03:20,324
Third, the results suffer from
severe response bias because

52
00:03:20,384 --> 00:03:21,824
only extremely positive.

53
00:03:22,679 --> 00:03:28,049
Extremely native users tend to
answer service and it is reactive.

54
00:03:28,859 --> 00:03:34,559
By the time a team receives the NPS score,
the opportunity to fix the issue has

55
00:03:34,649 --> 00:03:41,540
already passed so we have the low response
rates, still data, vocal bias responses,

56
00:03:42,364 --> 00:03:47,254
which results in large customers, no
visibility and slow response, which

57
00:03:47,285 --> 00:03:49,564
in turn results in the millions.

58
00:03:49,954 --> 00:03:52,054
In lost revenue for the companies.

59
00:03:52,554 --> 00:03:55,405
This leads to us to an important question.

60
00:03:55,855 --> 00:03:58,434
What if we could eliminate
service altogether?

61
00:03:58,944 --> 00:04:02,514
What if we could calculate user
sentiment instantly without

62
00:04:02,514 --> 00:04:04,569
requiring any form of user input?

63
00:04:05,069 --> 00:04:08,969
What if we could reliably predict
net promoter score in real time?

64
00:04:09,479 --> 00:04:14,399
This forms the foundation for our work
predictive multi-model NPS estimation.

65
00:04:14,899 --> 00:04:17,659
Introducing DNPS Dynamic
Net Promoter Score.

66
00:04:18,589 --> 00:04:20,089
Let's see, what is DNPS?

67
00:04:20,240 --> 00:04:23,809
DNP predicts user sentiment
using its combination of tele

68
00:04:23,809 --> 00:04:26,360
metadata, behavioral analytics.

69
00:04:26,855 --> 00:04:29,075
Session patterns and machine learning.

70
00:04:29,735 --> 00:04:33,335
The goal is to produce a reliable,
continuously updated sentiment

71
00:04:33,335 --> 00:04:37,985
score for every user session without
requiring survey participation.

72
00:04:38,765 --> 00:04:42,995
This approach allows organizations to
transition from reactive measurement

73
00:04:43,145 --> 00:04:44,674
to proactive sentiment prediction.

74
00:04:45,395 --> 00:04:51,784
As you see here, we have different layers
for the DNPS model, data ingestion, AI

75
00:04:51,784 --> 00:04:54,065
prediction engine, and real time insights.

76
00:04:54,395 --> 00:04:56,075
Let's see what each layer do.

77
00:04:56,575 --> 00:05:01,825
So first one is the data collection layer
to achieve accurate predictions, DNP has

78
00:05:01,825 --> 00:05:04,510
reli on three key categories of data.

79
00:05:05,050 --> 00:05:10,810
First, behavioral interaction data,
which captures how users navigate

80
00:05:11,260 --> 00:05:12,580
and interact with the system.

81
00:05:13,090 --> 00:05:17,830
Second, telemetry and system signals which
provide insights into the performance

82
00:05:17,830 --> 00:05:20,050
of the platform during each session.

83
00:05:20,620 --> 00:05:21,040
Third.

84
00:05:22,000 --> 00:05:26,110
User feedback and textual inputs,
which include explicit comments,

85
00:05:26,320 --> 00:05:28,990
support messages, and survey responses.

86
00:05:29,230 --> 00:05:35,050
This multi-model signals enable a more
holistic understanding of user sentiment.

87
00:05:35,550 --> 00:05:39,530
Some of the examples of behavior
interaction data or click patterns

88
00:05:39,590 --> 00:05:44,120
and navigation flows, session
duration, drill time event.

89
00:05:44,620 --> 00:05:50,740
Error events and drop offs, future usage
sequences, tele and system signals, event

90
00:05:50,740 --> 00:05:56,719
logs from backend services, performance
metrics device application, metadata,

91
00:05:57,020 --> 00:06:00,049
user feedback and textual inputs in apps.

92
00:06:00,049 --> 00:06:04,449
Survey comments and
chart agent task scripts.

93
00:06:05,289 --> 00:06:06,489
So once the data is collected.

94
00:06:06,989 --> 00:06:09,809
It provides to the next
layer data processing layer.

95
00:06:10,469 --> 00:06:14,579
Data processing layer consists of
data cleaning, normalization, and

96
00:06:14,669 --> 00:06:20,429
structuring, timestamp alignment, future
extraction, data storage, staging.

97
00:06:21,089 --> 00:06:25,109
Our pipeline begins with data
cleaning to remove noise,

98
00:06:25,139 --> 00:06:27,179
duplicates, and incomplete entries.

99
00:06:27,569 --> 00:06:31,379
We then perform normalization and
structuring to convert raw session

100
00:06:31,379 --> 00:06:33,299
data into consistent formats.

101
00:06:33,869 --> 00:06:35,609
Timestamp alignment is critical.

102
00:06:36,109 --> 00:06:40,819
Since events from multi sources
must be ordered accurately.

103
00:06:41,319 --> 00:06:46,479
Next, we extract future key features,
including statistical metrics,

104
00:06:46,719 --> 00:06:49,389
behavioral patterns, and text embeds.

105
00:06:50,169 --> 00:06:54,099
Process data is stored in a staging
layer, which supports both offline

106
00:06:54,099 --> 00:06:55,840
training and real-time predictions.

107
00:06:56,340 --> 00:06:57,570
Let's go to the next layer.

108
00:06:57,929 --> 00:06:59,370
Hybrid a modeling.

109
00:06:59,870 --> 00:07:04,669
Our DNPS architecture uses hybrid
multi-model structured, designed

110
00:07:04,669 --> 00:07:08,330
to handle structured metrics,
sequential behavior, and text data.

111
00:07:08,780 --> 00:07:14,690
Each model type specializes in a
different modality and contributes unique

112
00:07:14,929 --> 00:07:16,940
insights into the final prediction.

113
00:07:17,510 --> 00:07:22,099
The fusion of these models ensures
higher predict accuracy than any

114
00:07:22,099 --> 00:07:23,960
single model could achieve alone.

115
00:07:24,590 --> 00:07:25,669
Additionally, this.

116
00:07:26,179 --> 00:07:30,289
Structured supports explainability
enabling us to assess the

117
00:07:30,289 --> 00:07:32,659
contributions of each input future.

118
00:07:33,379 --> 00:07:37,820
See here all the models, calculate
and provide it to the fusion layer.

119
00:07:38,119 --> 00:07:43,099
And fusion layer combines all the model
scores and provides the final NPS score.

120
00:07:43,599 --> 00:07:44,199
Let's see.

121
00:07:44,574 --> 00:07:46,179
Each model did in detail.

122
00:07:46,780 --> 00:07:50,140
The hybrid model is composed of
three components, core components.

123
00:07:50,640 --> 00:07:55,140
First, a structure, a structured
data model implemented using gradient

124
00:07:55,140 --> 00:08:01,530
boost radiation trees such as XG
Boost or light GPM, which as in ca,

125
00:08:01,590 --> 00:08:06,870
capturing non-linear patterns in
behavioral and teleme tele metrics.

126
00:08:07,370 --> 00:08:12,819
Second, a temporal sequence model
implemented using LSTM or transformer

127
00:08:12,879 --> 00:08:15,129
architectures, which learns.

128
00:08:15,474 --> 00:08:20,504
User behavior, behavioral trends
across time that a text model using

129
00:08:20,714 --> 00:08:26,594
but based emits, which captures
sentiment, semantics, and topical

130
00:08:26,684 --> 00:08:32,319
relevance from user generated text
Together, this models provide a

131
00:08:32,319 --> 00:08:34,619
multidimensional representation of user s.

132
00:08:35,119 --> 00:08:36,589
Let's talk about the fusion layer.

133
00:08:36,979 --> 00:08:41,089
Fusion layer combines outputs from all
three models into a single prediction.

134
00:08:41,780 --> 00:08:46,459
Rather than treating each model equally,
it lands to weight each mo, each one,

135
00:08:46,699 --> 00:08:48,979
depending on its predictive importance.

136
00:08:49,400 --> 00:08:53,689
This selective vein ensures that the
most relevant signals, whether behavior

137
00:08:54,540 --> 00:08:58,800
performance related or textual,
dominate the final NPS estimation.

138
00:08:59,300 --> 00:09:03,439
The fusion player has explain
explainable a i two to ensure

139
00:09:03,780 --> 00:09:06,089
transparency and interpretability.

140
00:09:06,329 --> 00:09:10,260
We apply post hoc explainability
methods such as shop and online.

141
00:09:10,890 --> 00:09:15,329
These methods allow us to analyze
how each future influences the

142
00:09:15,329 --> 00:09:20,459
predicted NPS Explainability is
essential for trust and adoption.

143
00:09:21,240 --> 00:09:24,540
Especially in operational
environments where business leaders

144
00:09:24,930 --> 00:09:28,439
need to understand why your model
generates a particular prediction.

145
00:09:28,920 --> 00:09:32,189
See here clarifies why
your prediction was made.

146
00:09:32,579 --> 00:09:37,110
Use sharpen online, improves trust
and transparency, helps with debugging

147
00:09:37,110 --> 00:09:42,689
and violation, supports compliance and
audit needs the excess increases ness by

148
00:09:42,689 --> 00:09:44,954
showing how and why prediction was made.

149
00:09:45,454 --> 00:09:47,144
Finally, it produces the fuck.

150
00:09:47,789 --> 00:09:53,279
Final DN dynamic NPS score provides the
ES level of the prediction and shows

151
00:09:53,549 --> 00:09:59,129
root cause factors affecting the score,
suggests actionable recommendations, and

152
00:09:59,129 --> 00:10:01,709
delivers insights to business dashboards.

153
00:10:02,209 --> 00:10:05,150
Let's talk about the prediction
results and model performance.

154
00:10:05,569 --> 00:10:12,079
D-S-P-D-N-P-S model achieved an
accuracy of approximately 85.9%

155
00:10:12,439 --> 00:10:13,489
outperforming all baseline.

156
00:10:13,989 --> 00:10:18,339
Models evaluated the model,
produced a low mean absolute error

157
00:10:18,339 --> 00:10:23,739
of around 1.21 and demonstrated
strong F1 scores across promoter,

158
00:10:23,800 --> 00:10:27,249
passive and detected in categories.

159
00:10:27,749 --> 00:10:31,514
Application study is performed
and shows that removing text data

160
00:10:31,664 --> 00:10:37,259
reduces accuracy to around 55% while
removing behavioral and tele data

161
00:10:37,259 --> 00:10:39,509
results in a drop to about 78%.

162
00:10:40,009 --> 00:10:45,319
As you see in this chart, removing
each one like no text, no structured

163
00:10:45,349 --> 00:10:50,509
text, only unstructured only drops the
accuracy of the percentage of the model.

164
00:10:51,009 --> 00:10:55,300
Real time inference latency is
roughly 80 milliseconds, which

165
00:10:55,300 --> 00:10:59,349
makes the system viable for live
dashboards and operational workflows,

166
00:10:59,849 --> 00:11:02,609
explainability and insights,
and business value.

167
00:11:03,109 --> 00:11:08,599
Explainability analysis reveals several
key drivers of NPS High back click.

168
00:11:08,599 --> 00:11:11,539
Frequency strongly correlates
with negative sentiment.

169
00:11:11,899 --> 00:11:15,739
Short session durations often
indicate dissatisfaction.

170
00:11:16,239 --> 00:11:20,874
Higher intentional click activity tends
to correlate with promoter behavior.

171
00:11:21,544 --> 00:11:25,935
This insights help product and
engineering teams identify root causes

172
00:11:25,935 --> 00:11:29,204
such as UI friction system buffering.

173
00:11:30,009 --> 00:11:34,899
Our negative feedback patterns
From a business perspective, DSPS

174
00:11:34,959 --> 00:11:40,119
enables proactive patient making,
reduces reliance on service, and

175
00:11:40,119 --> 00:11:44,949
produces the realtime sentiment
intelligence across customer journey.

176
00:11:45,449 --> 00:11:47,670
Let's talk about the
limitations on future work.

177
00:11:47,969 --> 00:11:50,069
Despite it, its advantages.

178
00:11:50,249 --> 00:11:53,369
The DNPS approach has several limitations.

179
00:11:53,910 --> 00:11:55,920
It requires access to large.

180
00:11:56,475 --> 00:12:01,564
High quality data sets and performance may
degrade in cold start scenarios involving

181
00:12:01,564 --> 00:12:08,134
new users model complexity introduces
operational overhead and text base signals

182
00:12:08,134 --> 00:12:11,915
can introduce bias for future work.

183
00:12:11,915 --> 00:12:18,334
We intend to explore more drivers data
sources, incorporate advanced transformer

184
00:12:18,574 --> 00:12:23,864
architectures improve cold start handling
and enhance real time explainability.

185
00:12:24,364 --> 00:12:27,814
This improvements will support
broader adoption and even

186
00:12:27,814 --> 00:12:30,124
more reliable NPS predictions.

187
00:12:30,624 --> 00:12:31,104
Thank you.

188
00:12:31,704 --> 00:12:33,684
If you have any questions, please
reach out to me on LinkedIn.

189
00:12:34,184 --> 00:12:34,574
Thank you.

