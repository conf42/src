1
00:00:00,500 --> 00:00:01,160
Speaker 11: Good morning.

2
00:00:01,160 --> 00:00:02,900
Good afternoon, everyone.

3
00:00:03,400 --> 00:00:07,870
Topic of ml, power machine learning
Power, iot, internet of Things

4
00:00:07,870 --> 00:00:12,280
from warehouse data to production
intelligence in real time elevator pitch.

5
00:00:12,610 --> 00:00:14,350
So first of all, lemme introduce myself.

6
00:00:14,960 --> 00:00:21,010
I'm Dineh Ger working for Honeywell
Inte, and I work as a senior IT

7
00:00:21,010 --> 00:00:24,910
manager in the supply chain management.

8
00:00:24,910 --> 00:00:27,190
So I'm a digital supply chain IT man.

9
00:00:27,690 --> 00:00:30,920
So let's go back to
the start on the topic.

10
00:00:31,880 --> 00:00:35,240
So my class is better panicky,
so I'm hoping it'll work fine.

11
00:00:35,740 --> 00:00:39,550
So real challenge comes up is that
today most industries does have,

12
00:00:39,550 --> 00:00:42,190
the data is lot more collected.

13
00:00:42,519 --> 00:00:46,710
But what now since data is there
installed in most of the ERP

14
00:00:46,710 --> 00:00:50,430
systems, most of the machine learning
system, most of the databases.

15
00:00:50,929 --> 00:00:51,559
What next?

16
00:00:51,979 --> 00:00:54,499
Beyond data collections,
what's the real challenge?

17
00:00:55,189 --> 00:01:00,139
So modern warehouses generate
multiple terabytes or gigabytes

18
00:01:00,139 --> 00:01:01,369
of the operational data.

19
00:01:02,029 --> 00:01:07,820
And basically every transaction when you
do it, it requires like load of data.

20
00:01:08,449 --> 00:01:14,539
So every assume that if you do inventory
transactions, so it stores like at least

21
00:01:14,689 --> 00:01:16,364
four or five record in the database.

22
00:01:16,864 --> 00:01:21,884
And that means all those records
doesn't mean anything unless we really,

23
00:01:21,884 --> 00:01:25,274
somebody needs to analyze it and figure
out what really needs to be happening.

24
00:01:25,274 --> 00:01:28,544
Now, that's why I just state our
statement is raw data doesn't

25
00:01:28,604 --> 00:01:30,854
equal actionable intelligence.

26
00:01:31,184 --> 00:01:35,109
Road data doesn't mean anything unless
we somebody make a mean out of it.

27
00:01:35,609 --> 00:01:39,949
So we are right now looking at a lot
more doing in the machine learnings.

28
00:01:39,949 --> 00:01:42,889
A lot of studies are doing
in AI last three, four years.

29
00:01:42,889 --> 00:01:47,179
There is a lot of AI and machine learnings
are coming up, but if you really think

30
00:01:47,179 --> 00:01:52,879
about, say most of this AI and ML projects
are really still not live in the industry

31
00:01:53,389 --> 00:01:56,359
because they are just still theoretical.

32
00:01:56,539 --> 00:02:01,159
Most of them are still not really
far away from the industry.

33
00:02:01,659 --> 00:02:05,499
So if you see about, say some of
the examples like we do have noisy

34
00:02:05,499 --> 00:02:09,459
sensors, equipments is failing,
evolving the conditions, all the

35
00:02:09,459 --> 00:02:14,589
stuffs are really the examples of
the sum of these like data failures

36
00:02:14,589 --> 00:02:16,659
or accuracy failures in operations.

37
00:02:17,229 --> 00:02:18,789
And I'm just going to talk about it.

38
00:02:18,789 --> 00:02:23,024
How do we really think about it in
terms of the ML and how do the AI

39
00:02:23,024 --> 00:02:25,104
and ML can help out in the line?

40
00:02:25,604 --> 00:02:25,894
Okay.

41
00:02:26,394 --> 00:02:30,384
Next one is why traditional machine
learning approaches fails in production?

42
00:02:30,564 --> 00:02:31,494
That's a good question.

43
00:02:31,544 --> 00:02:36,854
So traditional machine learnings generally
fails in the production we needs to be.

44
00:02:36,854 --> 00:02:38,804
There are generally three reasons.

45
00:02:38,864 --> 00:02:42,494
One is the data quality issues as
data has, there's a lot of data

46
00:02:42,764 --> 00:02:47,504
in the system survey, but still we
do not have the data what we need.

47
00:02:47,954 --> 00:02:49,484
And methodologies are today.

48
00:02:49,574 --> 00:02:53,084
They're still getting out away
from the exact methodology, but

49
00:02:53,084 --> 00:02:54,734
still they are still far away.

50
00:02:55,304 --> 00:02:57,494
Second one is integration challenges.

51
00:02:57,584 --> 00:03:01,424
So everyone know who's working in the
industry knows about integrations.

52
00:03:01,634 --> 00:03:03,994
So integration are the
hard of the industries.

53
00:03:04,054 --> 00:03:07,934
So assume there, say for any
data we capture from the.

54
00:03:08,010 --> 00:03:13,590
The shop floor, your, like any
devices, any sensors, everything

55
00:03:13,590 --> 00:03:16,290
requires indication to the databases.

56
00:03:16,590 --> 00:03:20,200
Now you can argue about say,
Hey, why do we need a databases?

57
00:03:20,200 --> 00:03:22,839
We're still in the world
of the study databases.

58
00:03:22,929 --> 00:03:25,329
All the data is still
level lying behind there.

59
00:03:25,829 --> 00:03:28,679
And of course there's a third
point is performance degradations.

60
00:03:28,829 --> 00:03:34,499
So after, say over time there is
too much data, too much scenarios,

61
00:03:34,559 --> 00:03:38,179
and humans are getting a lot more
intelligence, that means those data

62
00:03:38,509 --> 00:03:40,459
performance is degrading over on time.

63
00:03:41,029 --> 00:03:43,849
So let's go a little bit deeper
on the data quality issues.

64
00:03:43,849 --> 00:03:46,304
So data quality issues
means sensors failed out.

65
00:03:47,164 --> 00:03:48,154
Data is drifting.

66
00:03:48,364 --> 00:03:51,724
I recently wrote an article on the
inventory drifting, so I'm assuming

67
00:03:51,724 --> 00:03:52,984
that it's very similar route.

68
00:03:53,174 --> 00:03:57,854
Say if you're talking about, say
I do have, the shop floor does

69
00:03:57,854 --> 00:04:01,364
have the 10 pieces and I actually
may have the eight pieces.

70
00:04:01,544 --> 00:04:06,969
So data is actually drifting from the
equipment ing network is a big things.

71
00:04:07,694 --> 00:04:09,644
Of course environment interference, right?

72
00:04:09,854 --> 00:04:13,954
So somewhere say, or most of
these computers or sensors

73
00:04:13,954 --> 00:04:15,304
sometimes just fail out.

74
00:04:15,634 --> 00:04:20,315
I've seen our industries where we do have
the robotics and things like robots are

75
00:04:20,315 --> 00:04:25,735
trying to record all the transactions
and in certain, like some kind of

76
00:04:25,735 --> 00:04:29,539
like heat wave comes up and then all
those one transaction per period out.

77
00:04:30,475 --> 00:04:34,195
Integration challenges if you, most
of them are aware of say, APIs.

78
00:04:34,345 --> 00:04:38,570
Everything is trying to be in,
there's a, this a world of APIs.

79
00:04:38,570 --> 00:04:40,345
Rest APIs are a lot more common.

80
00:04:40,825 --> 00:04:45,565
So how do we really, how will we
connect the two systems with the APIs?

81
00:04:45,865 --> 00:04:50,395
And most product will claim that hey,
they a P, they're rest a P compatible.

82
00:04:50,875 --> 00:04:55,285
But in reality, most cases, like
rest APIs are not really compatible.

83
00:04:55,785 --> 00:04:56,565
Latency.

84
00:04:56,755 --> 00:05:00,715
Big gaps is we are moving into
the cloud and that means if you're

85
00:05:00,715 --> 00:05:04,415
talking about the everything is
moving in cloud, not on-prem, they

86
00:05:04,415 --> 00:05:06,365
will be, they intend to be latency.

87
00:05:06,365 --> 00:05:09,755
Internet is really speaking,
moving speeds, but still we will

88
00:05:09,755 --> 00:05:14,555
have the latency match between the
components, synchronization issues.

89
00:05:14,555 --> 00:05:16,150
It is similar to integration, I will say.

90
00:05:17,030 --> 00:05:18,260
Of course handling.

91
00:05:18,760 --> 00:05:24,789
Now on the third topic of the perform, if
you talk about the scenario moving so many

92
00:05:25,419 --> 00:05:32,374
and of course things I say and productions
like human behavior, as system behavior,

93
00:05:32,874 --> 00:05:33,504
quickly moving.

94
00:05:34,004 --> 00:05:37,544
Topic is talking about the, from
the raw internet or things data,

95
00:05:37,544 --> 00:05:40,064
raw IOT data to the ML features.

96
00:05:40,334 --> 00:05:46,244
So if you talk about say, how do we really
get into the machine learning features

97
00:05:46,244 --> 00:05:50,034
where we can really use the production.

98
00:05:50,439 --> 00:05:54,489
So if you see on those one, right
there are like, say four techniques

99
00:05:54,489 --> 00:05:57,309
that are mentioned out here, but
honestly, there could be like,

100
00:05:57,369 --> 00:05:58,659
could be way more than that.

101
00:05:58,899 --> 00:06:02,979
So I will really think about say
like simple examples on the first

102
00:06:02,979 --> 00:06:04,569
technique is say the rolling windows.

103
00:06:04,569 --> 00:06:07,149
Rolling windows means if you
talk about the lead times in the

104
00:06:07,149 --> 00:06:09,009
industry, which is still static.

105
00:06:09,009 --> 00:06:13,119
So I will say that, hey, why not drive
instead of making a static lead test, why

106
00:06:13,119 --> 00:06:15,009
not making a lot more rolling windows?

107
00:06:15,509 --> 00:06:19,969
And of course we need to be tracking
or tracking our say time times.

108
00:06:20,269 --> 00:06:25,849
Since the event tracking, so recently
wrote an article on the time based

109
00:06:25,849 --> 00:06:30,019
lead times, to be honest or time-based
cycle counting or physically, mentally,

110
00:06:30,349 --> 00:06:34,009
that means what will happened there is
that hey, I started my counting of the

111
00:06:34,009 --> 00:06:39,019
parts and since the last time I counted
parts was the current counting there.

112
00:06:39,079 --> 00:06:43,444
And if I'm doing a adjustment in
systems, can I take a like a. Detect

113
00:06:43,624 --> 00:06:47,434
both the events and say, find out,
hey, I can do an hour detection.

114
00:06:47,674 --> 00:06:50,945
Hey, normally I do a 10 pieces
of manufacturing or backlash.

115
00:06:50,945 --> 00:06:52,535
Can I do it like eight pieces?

116
00:06:52,745 --> 00:06:55,775
This time I only did, I
did the only one piece.

117
00:06:55,865 --> 00:06:57,065
So something really happened.

118
00:06:57,245 --> 00:07:00,605
Either the demand drop so badly
or supply English too badly.

119
00:07:00,725 --> 00:07:05,210
So that's where the hour detection
really help out in the machine learnings.

120
00:07:05,570 --> 00:07:06,800
Time series importations.

121
00:07:07,490 --> 00:07:11,120
Basically, this is more of say
standard of forecasting methodology.

122
00:07:11,120 --> 00:07:15,230
I would normally call us, so even
most of the ML models are really

123
00:07:15,230 --> 00:07:16,910
getting on the time series as well.

124
00:07:17,510 --> 00:07:21,230
So it's pretty helpful, but still
I think it needs to be really.

125
00:07:22,025 --> 00:07:23,195
Use very carefully.

126
00:07:23,195 --> 00:07:26,855
It may be useful in defining all
the missing data so that in terms

127
00:07:26,855 --> 00:07:29,705
of say I do have, the demand is
missing for the period number three,

128
00:07:30,004 --> 00:07:35,285
how can I still find the demand for
that one without doing out, without

129
00:07:35,285 --> 00:07:37,085
asking, or without guessing it out.

130
00:07:37,565 --> 00:07:41,315
Even still, I've seen industry, a
lot of planners still guess the data.

131
00:07:41,765 --> 00:07:45,994
Then of course, edge computings, which
means of course we need to increase our.

132
00:07:46,494 --> 00:07:49,585
Power and so that we do have, the
latency is pretty low, and then

133
00:07:49,644 --> 00:07:51,144
we can see the real time data.

134
00:07:51,644 --> 00:07:56,305
And of course that's a pre, pre
really story of pre production,

135
00:07:56,305 --> 00:08:00,145
handling the messiness, missing
data and sensor failures.

136
00:08:00,535 --> 00:08:05,095
Of course, every day we see out a
data is missed out in the industry.

137
00:08:05,095 --> 00:08:09,265
When I see water every month where my
support team comes up and they tell

138
00:08:09,265 --> 00:08:14,395
me that, Hey, we do have the 10,000
transactions failed, and they say, why?

139
00:08:14,755 --> 00:08:18,505
They say, one of my interface fail
out, or one of the census fail on

140
00:08:18,505 --> 00:08:22,585
the production line, which then teams
record the data properly and then we,

141
00:08:22,585 --> 00:08:24,715
it comes up like, Hey, what shall we do?

142
00:08:25,215 --> 00:08:29,535
Spreadsheets on these production floors,
they are still, the network is really

143
00:08:29,535 --> 00:08:32,120
messy, so it is going to be happening out.

144
00:08:32,850 --> 00:08:36,210
So there are three techniques
which normally will be helpful.

145
00:08:36,210 --> 00:08:38,430
I'm still not very confident there.

146
00:08:38,435 --> 00:08:42,150
It is still, we are still there, but we
will be at point of time we'll be there.

147
00:08:42,210 --> 00:08:44,280
One is time series awareness invitation.

148
00:08:44,580 --> 00:08:47,190
Second is Multisensor fusion,
and third is metadata.

149
00:08:47,190 --> 00:08:51,900
Features time series Awareness means
if there is a data missed out, least

150
00:08:51,900 --> 00:08:56,850
we can make it somewhat guess and
somewhat real, more informed decisions.

151
00:08:56,850 --> 00:08:58,740
We can at least do her some context.

152
00:08:59,265 --> 00:09:03,685
Of course instead of the one sensor,
can we do it multiple sensors or can we

153
00:09:03,685 --> 00:09:05,665
do that requires a lot of cost as well.

154
00:09:06,025 --> 00:09:08,305
So that means the cost will increase.

155
00:09:08,605 --> 00:09:10,195
And then of course metadata features.

156
00:09:10,195 --> 00:09:14,425
So metta features will tell out, say with
signals, are there, or in terms of the

157
00:09:14,425 --> 00:09:17,485
metadatas, how do we really find out?

158
00:09:17,485 --> 00:09:20,675
Say this transaction does have
the four kinds of metadata.

159
00:09:20,975 --> 00:09:22,355
Can we really break down?

160
00:09:22,505 --> 00:09:24,335
Can we really do an informed decision?

161
00:09:24,835 --> 00:09:30,655
So that will actually analyze, help us
analyze the patterns of the signals, as

162
00:09:30,655 --> 00:09:32,985
well as equipment health issues as well.

163
00:09:33,485 --> 00:09:34,595
Let's move the next one.

164
00:09:35,314 --> 00:09:38,705
Next one is machine learning operator
ops, architecture for production.

165
00:09:39,635 --> 00:09:41,525
So this is pretty interesting there.

166
00:09:41,824 --> 00:09:46,805
So we need to be really looking
at revamping the productions.

167
00:09:46,895 --> 00:09:52,505
So basically we need to be creating the
systems that will actually work at scale.

168
00:09:52,715 --> 00:09:55,685
Current bio machine learning
algorithms are pretty theoretical.

169
00:09:55,685 --> 00:10:00,165
They're still evolving, but they are not
at a scale that production can be using.

170
00:10:00,165 --> 00:10:02,775
Now we, I will say at least
five few years behind it.

171
00:10:03,275 --> 00:10:06,755
So in this case, if you say there are
three technologies, we are talking about

172
00:10:06,755 --> 00:10:08,435
containerization and model serving.

173
00:10:08,885 --> 00:10:11,135
And second one is model
versioning and deployment.

174
00:10:11,135 --> 00:10:12,814
And third one is continuous monitoring.

175
00:10:13,325 --> 00:10:18,214
So let's think about what each means
containerization and model serving means.

176
00:10:18,214 --> 00:10:20,224
Have you heard all the microservices?

177
00:10:20,344 --> 00:10:22,745
So microservices
architecture is pretty small.

178
00:10:22,995 --> 00:10:24,435
It's pretty lean architecture.

179
00:10:24,435 --> 00:10:27,885
That means we are also using
our NoSQL kind of concepts.

180
00:10:28,065 --> 00:10:29,175
NoSQL means.

181
00:10:29,520 --> 00:10:31,080
Databases are pretty lean.

182
00:10:31,110 --> 00:10:33,270
They do not store these steady things.

183
00:10:33,270 --> 00:10:38,850
They're like say pretty much storing only
the metadatas, and that means what happens

184
00:10:38,850 --> 00:10:40,770
there is production doesn't need out.

185
00:10:41,100 --> 00:10:43,080
Like a big core, big APIs.

186
00:10:43,110 --> 00:10:49,579
And also in that cases latency becomes
really reduced because we can do the

187
00:10:49,579 --> 00:10:55,130
similar research using the one of
the AI or vector DB methodology where

188
00:10:55,130 --> 00:10:58,800
you can simple example is how instead
of doing the static matches, why not

189
00:10:58,800 --> 00:11:01,770
use the cosign similarly distances.

190
00:11:02,400 --> 00:11:05,490
So in that case, you can do
the fast latency and you can

191
00:11:05,490 --> 00:11:06,840
do the high serviceability.

192
00:11:06,840 --> 00:11:08,190
It may not be exact.

193
00:11:08,625 --> 00:11:13,005
But if you think about life, say once,
at the end of the day, it may most of the

194
00:11:13,005 --> 00:11:17,865
production data, even as long as it is
80, 90% accurate, it'll be good enough.

195
00:11:17,925 --> 00:11:21,315
Since even in the today's production
one, we're seeing so much loss,

196
00:11:21,585 --> 00:11:23,715
we hardly get like 50, 60%.

197
00:11:23,775 --> 00:11:29,085
But even if this, apply this, and if
we gives my 80%, 90%, 95%, so it's

198
00:11:29,135 --> 00:11:33,155
most like the microservice architecture
and where the dbs normally are not

199
00:11:33,155 --> 00:11:36,665
looking for exact matches since
exact matches, means you'll have the.

200
00:11:37,070 --> 00:11:38,000
High latency.

201
00:11:38,500 --> 00:11:43,410
And of course, poison of traffics
will always try to be, plot the

202
00:11:43,410 --> 00:11:46,955
graphs and you can just run the,
like a traditional methodology.

203
00:11:46,955 --> 00:11:50,405
The quality in production is used
as scatter ploting, for example.

204
00:11:50,405 --> 00:11:52,475
Or say fish one diagrams.

205
00:11:52,475 --> 00:11:55,475
People can like, quality can
do it all those diagrams still.

206
00:11:55,775 --> 00:11:57,935
And they can look at it
like, Hey, where's the scale?

207
00:11:58,235 --> 00:12:00,630
Where's the really, the anoma out there?

208
00:12:00,730 --> 00:12:01,870
And they can actually do it.

209
00:12:02,420 --> 00:12:04,405
So then we call the containerization.

210
00:12:04,820 --> 00:12:08,930
Even the most databases currently are
coming up as like they're containerized

211
00:12:08,930 --> 00:12:14,320
databases for the sake of so that we
can be really sustainable as well as

212
00:12:14,320 --> 00:12:16,300
the architecture is pretty smooth.

213
00:12:16,800 --> 00:12:19,425
And of course there's a second
method as we talk about the

214
00:12:19,425 --> 00:12:21,090
model versioning and deployment.

215
00:12:21,790 --> 00:12:26,500
I will say this one is more of say
not for the production, but it's

216
00:12:26,500 --> 00:12:27,910
again, the technologies are going in.

217
00:12:28,410 --> 00:12:34,470
So that means we are looking for say a
lot more like metadata data tracking.

218
00:12:34,470 --> 00:12:38,040
We do have the lot more versions, like
instead of having the single version,

219
00:12:38,040 --> 00:12:39,540
we can have like multiple versions.

220
00:12:40,040 --> 00:12:44,574
And so that if it needed out, say
if you something went wrong, we can

221
00:12:44,574 --> 00:12:49,255
always go back, like a sensor field
on the floor can be really really bad.

222
00:12:49,255 --> 00:12:51,385
Go back to the old version real quick.

223
00:12:51,475 --> 00:12:54,535
Like version would be like as fast
as like a couple of minutes back.

224
00:12:55,495 --> 00:12:59,050
So what that means that you don't,
you're not dependent on say something

225
00:12:59,050 --> 00:13:00,185
about parallel the production.

226
00:13:00,185 --> 00:13:02,285
You don't need to rebuild a pil it.

227
00:13:02,375 --> 00:13:05,845
All you just do is just simply go
back and redeploy the old versions.

228
00:13:06,345 --> 00:13:10,065
Which may be like as, as good as a
couple of minutes ago because as we

229
00:13:10,065 --> 00:13:13,845
are talking about containerization, if
you say that latency is pretty low and

230
00:13:13,845 --> 00:13:17,625
you say Microsoft service architecture,
that means database is pretty lean.

231
00:13:17,925 --> 00:13:21,755
So reimbursing a rollback
becomes really fast.

232
00:13:22,535 --> 00:13:24,125
Of course continuous monitoring.

233
00:13:24,515 --> 00:13:28,390
That means as I'm just a big, not
a big fan of drifting, so I always

234
00:13:28,390 --> 00:13:32,685
talk about, I say inventory drifting,
always talking about injections

235
00:13:32,685 --> 00:13:35,064
are drifting sources are drifting.

236
00:13:35,275 --> 00:13:38,415
So how do we really monitor it every day?

237
00:13:38,415 --> 00:13:40,850
And that's where AI development, right?

238
00:13:40,910 --> 00:13:43,035
Hey, can we manage the trips?

239
00:13:43,575 --> 00:13:45,975
Can we find out the
different kind of others?

240
00:13:46,305 --> 00:13:48,105
Can we do the automation trailers?

241
00:13:48,105 --> 00:13:51,475
Can we do the say business tracking?

242
00:13:51,475 --> 00:13:54,265
Say I do have this spreadsheet or
something came out on the floor.

243
00:13:54,445 --> 00:13:55,525
Can I use that one?

244
00:13:55,885 --> 00:13:58,135
So that will truly help
out all this stuff.

245
00:13:58,495 --> 00:14:03,255
This is is ML ops architecture for
production is again, a suggestion.

246
00:14:03,555 --> 00:14:07,725
It may not really, we are
still not there, so it will be,

247
00:14:08,445 --> 00:14:08,635
it will take some more time.

248
00:14:09,135 --> 00:14:11,300
So deployment strategies
that reduce the risk.

249
00:14:12,075 --> 00:14:15,215
So there are, like, say, I
would say there are three or

250
00:14:15,215 --> 00:14:16,385
four different types of there.

251
00:14:16,385 --> 00:14:17,885
We should be doing shadow mode.

252
00:14:17,915 --> 00:14:21,335
We should be doing candidate
deployment, AB testing, full rollouts.

253
00:14:22,175 --> 00:14:27,345
Again, if you talk about say shadow modes
means you can just do the predictions

254
00:14:27,405 --> 00:14:31,515
alongside the existing system with
no operational impact to the compare.

255
00:14:32,340 --> 00:14:33,300
Current practices.

256
00:14:33,300 --> 00:14:38,350
Basically you run the, run your
predictions that, hey this existing system

257
00:14:38,350 --> 00:14:43,180
and this new systems, i'll just say, run
the current system in the side, and then

258
00:14:43,180 --> 00:14:48,550
I'll just deploy the am new system on the
side and then say, can I just try to see

259
00:14:48,605 --> 00:14:51,505
run parallel and see can I make it closer?

260
00:14:52,005 --> 00:14:55,065
Can I do the can management
instead of doing the full one?

261
00:14:55,065 --> 00:14:59,815
That means we do a small production,
small percentage, like a agile kind

262
00:14:59,815 --> 00:15:04,105
of methodology where you do this in
chunks rather than doing the full.

263
00:15:04,605 --> 00:15:09,245
And of course we can compare out the run
still the parallel for AB testing while

264
00:15:09,245 --> 00:15:13,625
doing the testing run, still run the, both
the transaction, the system parallel, but

265
00:15:13,685 --> 00:15:16,385
the test mode and let's try to be compare.

266
00:15:17,345 --> 00:15:21,275
Both these systems, and of course
there are the waterfall, traditional

267
00:15:21,275 --> 00:15:23,105
water methodology, full rollouts.

268
00:15:23,345 --> 00:15:25,710
Instead of doing everything,
we just monitor everything.

269
00:15:26,325 --> 00:15:30,105
Last one is pretty risky, but I will
say that generally I was, I would

270
00:15:30,105 --> 00:15:34,125
be really a big supporter of the
shadow methodology or shadow model.

271
00:15:34,125 --> 00:15:36,810
Can deployment a testing is still written.

272
00:15:36,900 --> 00:15:41,460
I will say it's there but may
not be as much as possible.

273
00:15:41,960 --> 00:15:43,430
Detection and retraining.

274
00:15:43,910 --> 00:15:49,820
So once we define all the new methodology
is our what doesn't really end here.

275
00:15:50,060 --> 00:15:54,950
So all these more models will be
really going to be degrading, right?

276
00:15:54,950 --> 00:15:56,990
They will be running
out for time and time.

277
00:15:56,990 --> 00:15:58,775
They'll more scenarios will come up.

278
00:15:58,875 --> 00:16:02,690
Humans becomes intelligent, systems
become intelligence, and then

279
00:16:02,690 --> 00:16:03,895
data will start acting again.

280
00:16:04,395 --> 00:16:08,685
So if you've seen outline the industry
from the last 20 years and I'm

281
00:16:08,985 --> 00:16:13,185
seeing our, every new tools comes
up and say, oh, this is the best.

282
00:16:13,425 --> 00:16:15,525
And after a couple of
years, oh, it's not working.

283
00:16:16,335 --> 00:16:19,395
So we always, it doesn't
mean that tool has changed.

284
00:16:19,395 --> 00:16:23,395
It means that new scenarios has
been error and people have been

285
00:16:23,455 --> 00:16:26,870
detected, people have been intelligent
and that's where is come up.

286
00:16:27,415 --> 00:16:29,390
So that's why it's really
important that hey.

287
00:16:30,040 --> 00:16:33,940
We have models keeps on getting
retrained and it keeps on.

288
00:16:34,440 --> 00:16:35,940
That's a kind of another one.

289
00:16:35,940 --> 00:16:40,460
Really edge versus cloud distributor
machine learning architecture.

290
00:16:40,880 --> 00:16:46,635
So if you talk about the as inferences,
can we do the time critical operations

291
00:16:46,635 --> 00:16:49,750
like the A ZV navigation, realtime
routing, and quality and avoidance.

292
00:16:50,250 --> 00:16:55,140
Again, this is say ultra, this
architecture will be really going on the

293
00:16:55,260 --> 00:17:00,370
very ultralow latency with, because of
the lightweight architecture and, but it

294
00:17:00,370 --> 00:17:04,540
will be, of course, as soon as you go on
the very low latency and light lightweight

295
00:17:04,540 --> 00:17:10,030
architecture, that means you will be
sacrificing the speed or in the accuracy,

296
00:17:10,090 --> 00:17:14,575
sorry, speed will be extremely fast, but
it'll be really sacrificing the accuracy.

297
00:17:15,075 --> 00:17:19,665
Compared with Cloud Inference, which
will be a lot more exact, but it

298
00:17:19,665 --> 00:17:23,445
will be really speed will be, sorry.

299
00:17:23,535 --> 00:17:27,375
Accuracy will be really not
be compromised, but speed

300
00:17:27,375 --> 00:17:28,520
will be really compromised.

301
00:17:28,935 --> 00:17:32,505
Cloud inference is more of say
current study databases, but as

302
00:17:32,505 --> 00:17:34,530
will be a lot more like animal diet.

303
00:17:35,030 --> 00:17:39,920
So I will be really say that it has to
be chosen between one or the other one.

304
00:17:40,080 --> 00:17:44,160
If you talk about like a medical industry,
like I will choose the cloud one.

305
00:17:44,160 --> 00:17:49,380
But if you're like say talking about like
production one for something really making

306
00:17:49,380 --> 00:17:54,060
our, like I do have, my industry makes
a convey bats, so we may be going out in

307
00:17:54,060 --> 00:17:58,730
the, and of course there's a third one is
like you can do a hybrid of both of them.

308
00:17:59,375 --> 00:18:03,545
So you can say, okay, some something I
will do in the time critical operation

309
00:18:03,545 --> 00:18:08,895
I'll do in the edge and which are like,
say really quality kind of operations need

310
00:18:09,225 --> 00:18:11,385
and maybe using all the cloud inferences.

311
00:18:11,885 --> 00:18:15,374
So most of them I just out
again, this is a curator.

312
00:18:15,554 --> 00:18:18,645
We are still really researching
out how to, we really use this one

313
00:18:18,645 --> 00:18:22,060
more and more production machine
learning application in action.

314
00:18:22,544 --> 00:18:26,264
So well, that's like the three
different actions we talk about.

315
00:18:26,264 --> 00:18:27,365
This is very interesting topic.

316
00:18:27,905 --> 00:18:30,875
Predictive maintenance, demand
forecasting, inventory, organization,

317
00:18:30,875 --> 00:18:34,865
intelligent beginner, R. So I'm
just really excited about talking

318
00:18:34,865 --> 00:18:37,534
about these three things you
asked me about demand forecasting,

319
00:18:37,534 --> 00:18:40,340
inventory opener, optimization
has been there in the industry.

320
00:18:41,180 --> 00:18:42,050
It's not new.

321
00:18:42,140 --> 00:18:46,010
If somebody tell me that a AI is new
in this work, no, this is not new.

322
00:18:46,070 --> 00:18:49,400
All these algorithms already exist
in forecasting and organization

323
00:18:49,400 --> 00:18:51,500
for like almost more than 10 years.

324
00:18:52,220 --> 00:18:53,750
Intelligent picking and routings.

325
00:18:53,750 --> 00:18:57,460
That's again, our industry is
really working really hard.

326
00:18:57,460 --> 00:19:01,315
So my industry, for example, is a
export in the picking and routings.

327
00:19:01,655 --> 00:19:03,915
So we do have say, palletizer.

328
00:19:04,385 --> 00:19:07,659
What that does is it automatically
points the routes and automatically

329
00:19:07,659 --> 00:19:09,250
find out most efficient routes.

330
00:19:09,594 --> 00:19:15,335
So what that means that we, and we
optimize our conveyors repair factories.

331
00:19:15,875 --> 00:19:19,655
So all you do is you on the
door dock door, you just put the

332
00:19:20,014 --> 00:19:23,814
parts and route into the current
lane and current operations.

333
00:19:24,745 --> 00:19:27,445
Now, predictive maintenance
is the one which is really

334
00:19:27,445 --> 00:19:28,404
getting more, more popular.

335
00:19:29,034 --> 00:19:32,364
And that means all these parameters
and sensors are still doing

336
00:19:32,364 --> 00:19:33,475
in manuals in the industry.

337
00:19:33,655 --> 00:19:36,865
But they are getting out a lot more.

338
00:19:37,045 --> 00:19:39,295
That's where the AI is really helping out.

339
00:19:39,445 --> 00:19:42,955
As machine learning models are really
helping out and those are actually

340
00:19:42,955 --> 00:19:47,215
monitoring the parameters, giving us
the signals, and then we'll say, okay,

341
00:19:47,215 --> 00:19:49,050
do we need to adjust this parameters?

342
00:19:49,590 --> 00:19:53,205
Now, steroids is not doing the automation,
but this is again, ai, I would say

343
00:19:53,205 --> 00:19:57,490
the doing animal detection and just
taking the decisions really fast.

344
00:19:57,990 --> 00:19:59,640
Next one is responsible ai.

345
00:20:00,180 --> 00:20:05,400
So AI is really growing really
fast, so we as a human being,

346
00:20:05,400 --> 00:20:07,530
needs to be really responsible.

347
00:20:08,100 --> 00:20:11,580
Basically we needs to be fair, we
need to be making design such a

348
00:20:11,580 --> 00:20:15,750
model that they can be explainable
and we need to build trust.

349
00:20:16,169 --> 00:20:20,879
So a lot of models, formulas
are really extremely complex.

350
00:20:21,270 --> 00:20:25,230
They are still not easy for the simple
human behaviors to be understanding of.

351
00:20:25,830 --> 00:20:29,284
So that's where say we need to
be reducing all the, so all the

352
00:20:29,284 --> 00:20:31,445
models should be really fair.

353
00:20:31,879 --> 00:20:34,670
So that you put up say they shouldn't be.

354
00:20:35,270 --> 00:20:36,820
I'll say equally.

355
00:20:36,970 --> 00:20:40,640
It's like a human behavior
even applies in the model.

356
00:20:40,640 --> 00:20:42,179
In the model school model.

357
00:20:42,179 --> 00:20:43,080
Explanatory.

358
00:20:43,080 --> 00:20:43,439
Again.

359
00:20:43,439 --> 00:20:47,059
I set out they needs to
be really simple still.

360
00:20:47,059 --> 00:20:51,409
Current models, what we do have it, they
operation teams or for the operation

361
00:20:51,409 --> 00:20:52,999
team, it's really difficult to understand.

362
00:20:53,459 --> 00:20:55,864
I was just like working on
like a safety staff home.

363
00:20:56,434 --> 00:21:00,504
And when I developed my formula, it
was really complex and then finally I

364
00:21:00,504 --> 00:21:01,884
just tried to explain operation team.

365
00:21:01,884 --> 00:21:02,814
I was struggled out.

366
00:21:03,054 --> 00:21:06,504
So what I ended up doing is simplify
the formula in such a way that any

367
00:21:06,864 --> 00:21:11,184
Excel even completed easily so that
operation could understand as soon as

368
00:21:11,184 --> 00:21:15,684
I did the same formula Rewr in the such
a methodology breaking down formulas,

369
00:21:15,774 --> 00:21:18,714
even though it is five steps or patients
could understand it really well.

370
00:21:19,164 --> 00:21:21,174
So that's where all
these models are still.

371
00:21:21,864 --> 00:21:25,704
Really how large needs to make
sure that, how do we really openly

372
00:21:25,884 --> 00:21:30,564
understand it, like the work on the
planning industry planning methodology,

373
00:21:30,564 --> 00:21:34,259
planning engine are still difficult to
understand, but again, it's going there.

374
00:21:34,759 --> 00:21:36,219
And of course, regress validation.

375
00:21:36,434 --> 00:21:40,219
That means we need to be
really testing really well.

376
00:21:40,979 --> 00:21:44,699
We needs to be doing a lot more
shadow, a lot more AB testing, a

377
00:21:44,699 --> 00:21:48,034
lot more canary deployments instead
of doing the full deployment.

378
00:21:48,034 --> 00:21:52,749
Pull deployments means you'll be either
the recipe of failure that's going on

379
00:21:52,749 --> 00:21:56,590
the, that's why I say that, like in
terms of the IT product management,

380
00:21:56,739 --> 00:22:01,735
we talk about say waterfall metal
almost getting over a lot more as well.

381
00:22:01,739 --> 00:22:04,389
A lot more people say, Hey, I need D one.

382
00:22:04,389 --> 00:22:05,259
I want to see this.

383
00:22:05,759 --> 00:22:07,139
They don't really care.

384
00:22:07,139 --> 00:22:11,604
Say what will be the system down the
line, but they want to see day one.

385
00:22:11,704 --> 00:22:12,764
Day one every day.

386
00:22:13,264 --> 00:22:18,379
Now, as I say about the edge deployment
means you do have the ultra low model.

387
00:22:18,619 --> 00:22:19,429
Basically.

388
00:22:20,059 --> 00:22:20,969
It's a lot more.

389
00:22:20,974 --> 00:22:22,404
Speed is really fast.

390
00:22:22,494 --> 00:22:26,124
Agency really, actually,
our LA agency is pretty low.

391
00:22:26,664 --> 00:22:27,744
So three things on that.

392
00:22:27,744 --> 00:22:30,234
One, we do should be
doing the quantitation.

393
00:22:30,504 --> 00:22:32,724
We do should be looking at the parameters.

394
00:22:32,964 --> 00:22:38,424
We should be looking at the knowledge
distillation so that anyone can really

395
00:22:38,924 --> 00:22:43,839
those whatever we do, the whatever models
we use it or so their families are really

396
00:22:44,239 --> 00:22:45,799
accurate and blockchain can understand it.

397
00:22:46,299 --> 00:22:50,289
So all these one are basically really
good in terms of theory as well

398
00:22:50,289 --> 00:22:51,759
as in terms of the practical even.

399
00:22:51,759 --> 00:22:54,999
We start doing all the As development
only for critical operations.

400
00:22:54,999 --> 00:22:59,379
It makes our life so much
easier, and of course the, it'll

401
00:22:59,649 --> 00:23:01,689
be lot more faster decisions

402
00:23:02,189 --> 00:23:04,889
in trends reshaping, warehouse.

403
00:23:05,389 --> 00:23:06,649
That's exciting as well.

404
00:23:06,829 --> 00:23:10,139
So if you see about say first
one is auto machine learning and

405
00:23:10,169 --> 00:23:11,579
automatic feature engineering.

406
00:23:12,149 --> 00:23:15,479
That means all the operation
teams are really looking for

407
00:23:15,479 --> 00:23:16,889
the rapid deployment cycles.

408
00:23:17,309 --> 00:23:21,409
They don't care about say, gone are
the days where the system where the

409
00:23:21,619 --> 00:23:27,164
businesses say that, hey you do have 12
months, 18 months for deployment now, like

410
00:23:27,164 --> 00:23:29,419
two months, three months, weeks, even.

411
00:23:29,419 --> 00:23:30,829
Some cases you're asking for days.

412
00:23:31,329 --> 00:23:33,639
Multimodal learning and sensor fusions.

413
00:23:34,149 --> 00:23:38,109
Instead of the having the one model,
can we use the multiple models together?

414
00:23:38,109 --> 00:23:40,389
Can we compare the data
and which model is better?

415
00:23:40,689 --> 00:23:44,559
Can we have the multiple type
of sensor sensors instead of the

416
00:23:44,559 --> 00:23:46,149
having the one type of sensor?

417
00:23:46,149 --> 00:23:50,919
Can we have the like R sensors and
IOT sensors or environ sensors?

418
00:23:51,474 --> 00:23:54,774
So that we can compare our say
different kind of the models

419
00:23:54,774 --> 00:23:58,314
together, and then we can have the
better operational restraining.

420
00:23:58,314 --> 00:24:00,534
And then of course we can
have the another detection.

421
00:24:00,534 --> 00:24:04,204
And so then we apply our
time series to find the data.

422
00:24:04,704 --> 00:24:06,594
5G enabled real time intelligence.

423
00:24:07,014 --> 00:24:12,024
So 5G is really another
one shaping the world.

424
00:24:12,024 --> 00:24:12,774
Like anything.

425
00:24:13,104 --> 00:24:15,024
So now we don't need our like, say.

426
00:24:15,524 --> 00:24:19,044
A lot more wifi, internet stuff that
everywhere there is a 5G available.

427
00:24:19,464 --> 00:24:23,529
And that means you don't need
to be doing all the vast,

428
00:24:23,529 --> 00:24:26,279
massive networking investments.

429
00:24:26,309 --> 00:24:30,239
So we can use our, the
latency becomes really low.

430
00:24:30,779 --> 00:24:33,239
And then of course the network slicing.

431
00:24:33,239 --> 00:24:36,904
And for the machine learning
workloads enables automation,

432
00:24:37,504 --> 00:24:39,124
anonymous vehicle coordination.

433
00:24:39,124 --> 00:24:41,644
That means your databases a lot
more getting outta the autonomous.

434
00:24:42,144 --> 00:24:45,399
So that means if not talking
about milliseconds, we are

435
00:24:45,399 --> 00:24:49,824
talking about sub milliseconds or
really go even further than that.

436
00:24:50,274 --> 00:24:53,244
So this isn't, are really getting
faster with this one as well,

437
00:24:53,454 --> 00:24:55,344
because data is getting real times.

438
00:24:55,614 --> 00:25:01,164
So it's not like we are talking
about data like a few hours ago.

439
00:25:01,164 --> 00:25:03,654
Batch processing, all the
stuffs are not really there.

440
00:25:04,154 --> 00:25:07,214
Sustainable and machine
learning and green computing.

441
00:25:07,694 --> 00:25:10,124
Of course, we need to make
sure that whatever we do in our

442
00:25:10,624 --> 00:25:12,664
models, they are energy efficien.

443
00:25:12,874 --> 00:25:15,454
All the carbon awareness shield are there.

444
00:25:15,484 --> 00:25:17,284
Hardwares are really optimized.

445
00:25:17,869 --> 00:25:21,389
And that's where say we are talking
about the edge computing is really

446
00:25:21,889 --> 00:25:24,889
shaping the world where you do
the models are pretty lightweight.

447
00:25:25,309 --> 00:25:28,034
That means we don't need out
lot of commend, lot of resources

448
00:25:28,534 --> 00:25:32,529
out and then we sure that light
lot more like workload manager.

449
00:25:33,009 --> 00:25:36,689
So assuming that, say, just take out
the example, one of the biggest company

450
00:25:36,689 --> 00:25:41,729
that I was really looking at it, the
e-commerce program was having service

451
00:25:41,969 --> 00:25:43,984
and 20,000 service means who does that?

452
00:25:44,879 --> 00:25:50,309
So what are the means that they do have
20,000 servers, but all the really lot

453
00:25:50,309 --> 00:25:54,234
of them are the backup servers to make
sure that everything is optimized.

454
00:25:54,494 --> 00:25:59,559
But all those 20,000 were really low
low capacity, low, pretty much in

455
00:25:59,559 --> 00:26:01,864
terms of the schedules and everything.

456
00:26:01,864 --> 00:26:03,094
They are really optimized.

457
00:26:03,594 --> 00:26:04,104
Excuse me.

458
00:26:04,604 --> 00:26:05,654
Lessons from the field.

459
00:26:06,154 --> 00:26:08,014
What separates winner
from the field project?

460
00:26:08,514 --> 00:26:13,464
So field product means if you're
talking about again, or same or say

461
00:26:13,734 --> 00:26:18,594
full deployment, we should be definitely
avoiding out, do it in this lesson Pieces.

462
00:26:18,984 --> 00:26:22,409
We should be doing the we, instead
of doing our report deployment,

463
00:26:22,989 --> 00:26:26,139
do Azure methodology, which
means incremental deployments.

464
00:26:26,639 --> 00:26:29,429
We should be doing a lot more
cross-functional integration.

465
00:26:29,429 --> 00:26:34,019
That means we should be looking
at the lot more teams together.

466
00:26:34,619 --> 00:26:38,609
So instead of doing one team, doing
all the only work, all the teams

467
00:26:38,609 --> 00:26:42,719
needs should be working together,
finding out with what works best.

468
00:26:43,259 --> 00:26:45,899
And then of course, the upfront
we need to do the machine

469
00:26:45,899 --> 00:26:47,159
learning operation, investment.

470
00:26:48,089 --> 00:26:50,219
Otherwise, what will happen
that if you don't need machine

471
00:26:50,219 --> 00:26:51,539
learning operation, investment.

472
00:26:51,944 --> 00:26:55,444
You you'll be this
before failure basically.

473
00:26:55,944 --> 00:26:59,484
Main idea on that one is the
production, engineering, testing,

474
00:26:59,514 --> 00:27:00,954
everything can be automated.

475
00:27:01,854 --> 00:27:06,204
Otherwise, what will happen there is that
you taking the people out of the floor

476
00:27:06,204 --> 00:27:10,164
and then trying to redo something and then
people will be not be able to testing out.

477
00:27:10,664 --> 00:27:11,984
Pattern should be awarding out.

478
00:27:11,984 --> 00:27:15,494
Big banks, boss, big banks for
deployment should be over out.

479
00:27:16,394 --> 00:27:18,374
We shouldn't be doing the silo teams.

480
00:27:18,374 --> 00:27:23,414
We shouldn't be not doing all
the algorithms we shouldn't be.

481
00:27:24,014 --> 00:27:26,864
We should be away from the
without any monitoring.

482
00:27:26,864 --> 00:27:27,704
Monitoring is must.

483
00:27:28,204 --> 00:27:30,574
I would say reactive
approach to the issues.

484
00:27:30,634 --> 00:27:34,834
I will be not a big fan of reactive, but
I would say reactive as well as proactive,

485
00:27:34,839 --> 00:27:37,459
both of them, and may proactive as well.

486
00:27:37,804 --> 00:27:38,074
Far

487
00:27:38,574 --> 00:27:41,214
from insights to be implementations.

488
00:27:41,714 --> 00:27:45,374
So if you talk about IC still,
production machine learning is not

489
00:27:45,374 --> 00:27:47,624
same as academic and machine learnings.

490
00:27:47,684 --> 00:27:49,304
Academic is a lot more theoretical.

491
00:27:49,304 --> 00:27:51,584
Production is a lot more practical.

492
00:27:51,614 --> 00:27:53,744
Production doesn't need
a lot more big formulas.

493
00:27:53,744 --> 00:27:57,494
They're really looking at the symbol
where the people can understand it.

494
00:27:57,994 --> 00:28:01,084
Start small scales, more smart, basically.

495
00:28:01,414 --> 00:28:03,459
Same repeating or the methodology.

496
00:28:03,959 --> 00:28:09,479
Should be at people, process, technology,
all feeling should be prepared together.

497
00:28:09,979 --> 00:28:12,229
And of course, architecture matters.

498
00:28:12,729 --> 00:28:13,869
It's a normal no brainer.

499
00:28:14,369 --> 00:28:17,069
Next steps, if you talk about it, assess.

500
00:28:17,099 --> 00:28:22,019
Assess your current methods, current
machine learning, maturity level, and.

501
00:28:22,519 --> 00:28:26,654
So pilot is really, they
always go with 80 20 rule.

502
00:28:26,874 --> 00:28:30,199
So 80 20 rule means high value
use case should be pilot first.

503
00:28:30,829 --> 00:28:34,069
They're investing in machine learning
operation, infrastructure early,

504
00:28:34,569 --> 00:28:37,419
and of course cross-functional teams
are a lot more people are doing it.

505
00:28:37,449 --> 00:28:42,314
And deployment strategies should be
really made with the so safety gate.

506
00:28:42,814 --> 00:28:47,404
So that's the takeaways from,
and thank you so much everyone.

507
00:28:47,434 --> 00:28:50,884
That's all my side today and bye.

