1
00:00:00,000 --> 00:00:00,270
Hello.

2
00:00:00,270 --> 00:00:00,750
Hello.

3
00:00:00,840 --> 00:00:01,800
Good afternoon.

4
00:00:01,800 --> 00:00:03,390
Good morning, good evening.

5
00:00:03,690 --> 00:00:05,100
Thanks for joining our session.

6
00:00:05,430 --> 00:00:08,520
My name is Guillermo with and today
we're going to talk about how we

7
00:00:08,520 --> 00:00:14,210
build a Roseberry pie super cluster
using Postgres on Kubernetes and all

8
00:00:14,210 --> 00:00:16,459
the journey we've had till today.

9
00:00:16,549 --> 00:00:21,529
It's been like eight months of project and
I would like to introduce you to the team.

10
00:00:22,340 --> 00:00:24,500
today is not Jorge Ano with us.

11
00:00:24,560 --> 00:00:26,665
Jorge is a software engineer on Andre.

12
00:00:27,165 --> 00:00:30,734
The company that created a solution
that we will be deploying today that

13
00:00:30,734 --> 00:00:35,315
it's called Stackgres, Postgres on
Kubernetes, and myself, which is Guillermo

14
00:00:35,524 --> 00:00:38,694
Ruiz, and I'm Senior Developer for AWS.

15
00:00:38,974 --> 00:00:42,614
Before we start in this journey,
I would like to give thanks

16
00:00:42,634 --> 00:00:44,565
to a person and a project.

17
00:00:45,284 --> 00:00:48,994
This has been inspired by Chris Benson,
who is the guy that built the largest

18
00:00:48,995 --> 00:00:53,765
Raspberry Pi cluster that we know
of, with 1053 Raspberry Pi cards, and

19
00:00:53,765 --> 00:00:55,855
also Los Alamos National Laboratory.

20
00:00:56,315 --> 00:00:58,545
Which they had back in 2019.

21
00:00:58,935 --> 00:01:04,425
Moreover, a 750 Raspberry Pi cluster
that was divided in five clusters with

22
00:01:04,445 --> 00:01:08,825
mounted in racks, each one with 150
Raspberry Pis and everything integrated.

23
00:01:09,275 --> 00:01:13,765
It was such a big project that got our
attention and we came and said, why don't

24
00:01:13,765 --> 00:01:16,675
we build a Raspberry Pi super cluster?

25
00:01:17,345 --> 00:01:18,345
why we did this?

26
00:01:18,405 --> 00:01:21,145
first of all, It's supposed to
be affordable computing, and

27
00:01:21,145 --> 00:01:24,365
we will see as we go into the
session that is not the case.

28
00:01:24,825 --> 00:01:29,625
It's much cheaper than having big servers
out there and a lot of compute, but even

29
00:01:29,625 --> 00:01:31,715
though it's a cost that we need to afford.

30
00:01:32,105 --> 00:01:36,185
Also from an educational and practical
perspective, we wanted a hands on

31
00:01:36,185 --> 00:01:38,205
approach for distributed computing.

32
00:01:38,375 --> 00:01:41,445
And we've been learning the hard way, to
be honest, and you will see it throughout

33
00:01:41,445 --> 00:01:42,945
the lessons that we're going to share.

34
00:01:43,315 --> 00:01:47,445
With our audience today, but also we
wanted to have a real world application,

35
00:01:47,485 --> 00:01:52,914
a live demo of a functional stack risk
cluster running on the 63 Raspberry Pi.

36
00:01:53,755 --> 00:01:55,625
So how does it look like?

37
00:01:56,065 --> 00:01:57,445
This is the cluster that we build.

38
00:01:57,445 --> 00:02:01,795
It's on a pelican case, and it's a
way that we can port it to events and

39
00:02:01,795 --> 00:02:04,285
showcasing meetup and many other places.

40
00:02:04,395 --> 00:02:08,585
So Why don't we start and say, why do
we need to build this kind of projects?

41
00:02:08,615 --> 00:02:10,515
First of all, we need a
bunch of Raspberry Pi.

42
00:02:10,555 --> 00:02:13,495
And I want to give thanks to many
people, because this has been a

43
00:02:13,495 --> 00:02:18,585
friend project, asking friends
to lend us the Raspberry Pis.

44
00:02:18,925 --> 00:02:23,365
Thanks to Ongres, thanks to the guys
from the Brain School, Datadobe.

45
00:02:23,925 --> 00:02:26,835
They brought a bunch of
Raspberry Pis, and we'll see.

46
00:02:27,225 --> 00:02:28,545
They were not the latest one.

47
00:02:28,565 --> 00:02:31,505
We will be working with
a 3B which is cool.

48
00:02:31,870 --> 00:02:35,920
Quite a bit old, to be honest,
but that's what we had.

49
00:02:36,270 --> 00:02:40,770
We also had all the electronics, the PDUs,
the fans, all the servers, and you will

50
00:02:40,780 --> 00:02:44,430
see that we had to split and increase
the number of devices for this cluster.

51
00:02:44,810 --> 00:02:46,620
And we had this wonderful Pelican case.

52
00:02:46,660 --> 00:02:50,880
But one of the components that was
really interesting was the 3D printer,

53
00:02:50,940 --> 00:02:54,550
because we use, and thanks to our
friends from Prusa Research that lent

54
00:02:54,550 --> 00:03:00,220
us the MP4 3D printer, We print the bay
where we're going to connect all the

55
00:03:00,220 --> 00:03:05,300
Raspberry Pis, and even how we handle
the fans on the back was 3D printed.

56
00:03:05,680 --> 00:03:09,790
From a software perspective,
we're going to use Ubuntu 24.

57
00:03:09,830 --> 00:03:13,460
04, which is the latest long
term support release of this

58
00:03:13,460 --> 00:03:15,210
popular Linux operating system.

59
00:03:15,605 --> 00:03:19,545
We will also have K3S, which is a
lightweight Kubernetes distribution

60
00:03:19,545 --> 00:03:22,365
that is optimized for resource
constrained environments like

61
00:03:22,405 --> 00:03:26,185
this one that we're talking about
IoT, and it's easy to install.

62
00:03:26,505 --> 00:03:30,205
Although it requires minimal memory and
CPU, but we will see that's going to

63
00:03:30,215 --> 00:03:32,135
be also a challenge during our project.

64
00:03:32,285 --> 00:03:35,635
The second component is the Stackgres,
which is an open source platform for

65
00:03:35,635 --> 00:03:40,015
running Postgres on Kubernetes, and
it combines the power of both tools.

66
00:03:40,360 --> 00:03:41,419
We have PX boot.

67
00:03:41,420 --> 00:03:44,850
We run out of money, so we couldn't
have SD cards for every single

68
00:03:44,890 --> 00:03:46,160
Raspberry Pi in the cluster.

69
00:03:46,190 --> 00:03:48,450
So what we're going to do is
we're going to boot it from the

70
00:03:48,450 --> 00:03:50,540
network and see what happens.

71
00:03:51,080 --> 00:03:56,060
We've seen hardware, software, and
a lot of hours, immensely a lot of

72
00:03:56,060 --> 00:03:57,650
hours to build this whole thing.

73
00:03:58,180 --> 00:04:01,020
Let's start with the engineer
feature, how we plan and how we

74
00:04:01,020 --> 00:04:02,630
see this cluster come in life.

75
00:04:03,040 --> 00:04:05,750
We had a phase of planning and
designing of how we wanted to

76
00:04:05,750 --> 00:04:09,370
connect and how many Raspberry Pis,
which was dependent of the month.

77
00:04:09,995 --> 00:04:13,765
Of raspberries that we could get from
the friends and the people, but also

78
00:04:13,765 --> 00:04:17,465
how we could assemble this into a
cluster and using the 3D printers.

79
00:04:17,475 --> 00:04:19,435
This is mainly from the
hardware perspective.

80
00:04:19,575 --> 00:04:22,085
So we got from unify.

81
00:04:22,085 --> 00:04:25,604
We've got a couple of switches in
a gateway, but we also had, to Two

82
00:04:26,114 --> 00:04:29,664
USB chargers, each of 40 ports, so
the maximum capacity we will have

83
00:04:29,664 --> 00:04:32,294
in our cluster is 80 Raspberry Pi.

84
00:04:32,374 --> 00:04:37,315
So there are the brackets where we had
three rows with 21 Raspberry Pis each.

85
00:04:37,374 --> 00:04:39,744
But there are multiple pieces
on the 3D printed side.

86
00:04:39,814 --> 00:04:43,314
We had to print over 84
pieces just to assemble.

87
00:04:43,630 --> 00:04:46,159
Not just the Raspberry, but also the fans.

88
00:04:46,159 --> 00:04:49,280
As you can see, we're using
five fans per row, which takes

89
00:04:49,280 --> 00:04:52,090
us into 15 in total for this.

90
00:04:52,130 --> 00:04:55,070
let's take an overall view of
the whole specs that we have.

91
00:04:55,070 --> 00:04:59,179
It's Raspberry Pi, it's a 3B we have 63.

92
00:04:59,759 --> 00:05:03,730
On CPU bit quad core ARM with 1.

93
00:05:03,730 --> 00:05:05,240
2 GHz per core.

94
00:05:05,240 --> 00:05:08,570
We have 250 cores and we
have a clock speed of 302.

95
00:05:09,390 --> 00:05:11,250
4 GHz.

96
00:05:11,840 --> 00:05:13,960
Each Raspberry Pi card has one gig.

97
00:05:14,734 --> 00:05:19,274
Total of 63 gigs in this one and
then a bunch of multiple ports that

98
00:05:19,294 --> 00:05:20,905
many of them were not used here.

99
00:05:21,014 --> 00:05:22,154
let's start with the networking.

100
00:05:22,154 --> 00:05:24,974
Once we've got everything assembled
and we have everything in our

101
00:05:25,014 --> 00:05:30,154
Pelikan case, we started with a flat
topology for this 63 Raspberry Pis.

102
00:05:30,264 --> 00:05:33,764
Meaning that all nodes were directly
connected without any hierarchy.

103
00:05:34,424 --> 00:05:38,215
To manage the cluster, we implemented
a central control plane acting as

104
00:05:38,215 --> 00:05:42,015
the brain of the system, and it was
responsible for coordinating tasks,

105
00:05:42,015 --> 00:05:46,455
collecting metrics, and ensuring a
smooth operation across all the nodes.

106
00:05:46,915 --> 00:05:51,635
The network config was kept simple, with
all Raspberry Pi sharing the single 300

107
00:05:51,684 --> 00:05:56,185
megs bandwidth, that is what we have
with these 3B plus Raspberry Pis, which

108
00:05:56,185 --> 00:05:59,605
enable the communication between the
nodes and the central control plane.

109
00:06:00,220 --> 00:06:04,340
this setup allow us to quickly deploy and
test the cluster, but it also highlighted

110
00:06:04,340 --> 00:06:09,370
challenges like bandwidth saturation
and CPU overhead as the system scale.

111
00:06:09,570 --> 00:06:12,689
Here is a bit of how we implemented
the structure topology, where we're

112
00:06:12,690 --> 00:06:17,970
using two switches of 48 ports
connecting the 63 Raspberry Pi, and

113
00:06:17,970 --> 00:06:22,710
the switches handle the intra cluster
communication, ensuring that low latency

114
00:06:22,710 --> 00:06:23,890
connectivity between all the nodes.

115
00:06:24,585 --> 00:06:29,875
To provide external access to manage all
the routing, we integrated a gateway which

116
00:06:29,875 --> 00:06:32,075
connects the cluster directly to Internet.

117
00:06:32,424 --> 00:06:37,445
And additionally, there are small devices
called UCK G2, it's the unified cloud

118
00:06:37,445 --> 00:06:42,085
key generation 2, was deployed to manage
and monitor the network configuration.

119
00:06:42,254 --> 00:06:46,675
It offers us centralized control and
visibility into network performance.

120
00:06:47,264 --> 00:06:49,624
as you can see, very simple setup.

121
00:06:49,694 --> 00:06:53,684
It provides us a manageable infrastructure
for the cluster while we balance

122
00:06:53,684 --> 00:06:55,874
communication and internet connectivity.

123
00:06:56,704 --> 00:06:58,074
I want to show how it looks like.

124
00:06:58,804 --> 00:07:02,454
The Raspberry Pi is connected
to different switches.

125
00:07:02,454 --> 00:07:03,754
We talk about two switches.

126
00:07:03,754 --> 00:07:08,174
This is the bottom switch that is
organized to port the whole strategy.

127
00:07:08,714 --> 00:07:12,184
The idea is to simplify and you
will see that the nomenclature of

128
00:07:12,294 --> 00:07:16,204
every Raspberry Pi is coincident
with the port they are connected to.

129
00:07:16,294 --> 00:07:19,604
It will help us reduce troubleshooting
in case we have Problems.

130
00:07:19,624 --> 00:07:23,604
As you can see, odd number Raspberry
Pis 1, 3, 5 are connected to the

131
00:07:23,614 --> 00:07:25,574
odd numbers ports and even to even.

132
00:07:26,424 --> 00:07:31,254
This cover ports 1 to 42 on the
bottom switch and the remaining

133
00:07:31,284 --> 00:07:34,194
ports were reserved for key
infrastructure components.

134
00:07:34,714 --> 00:07:39,474
For example, port 43 will connect it
to the top of the switch, 44 is to

135
00:07:39,484 --> 00:07:45,144
the gateway for internet, 45 to the
cloud key and 46 to the Pi server.

136
00:07:45,684 --> 00:07:50,429
However, If you want to do it really
well, you should know and understand how

137
00:07:50,429 --> 00:07:56,149
many ASICs your switch has and try to
put the big servers in different ASICs so

138
00:07:56,149 --> 00:08:00,529
they have their own booths and their own
pipelines to move traffic between things.

139
00:08:00,799 --> 00:08:05,049
We place it here in the last part of
the switch because we learned by the

140
00:08:05,059 --> 00:08:08,829
hard way in the old days when Cisco
came with a design that they have

141
00:08:08,829 --> 00:08:12,409
the reset button in port number one,
so when you were plugging the cable,

142
00:08:12,459 --> 00:08:14,429
you were rebooting the whole switch.

143
00:08:14,909 --> 00:08:16,359
So because of that.

144
00:08:16,794 --> 00:08:20,834
We took panic and we just deploy
everything at the end of the switch.

145
00:08:20,914 --> 00:08:25,314
As again, take a look to your ASICs
and see where it fits to ensure that

146
00:08:25,324 --> 00:08:26,944
traffic goes one way or the other.

147
00:08:27,784 --> 00:08:30,744
Here is how it looks on the top
of the switch where we have still

148
00:08:30,744 --> 00:08:33,554
available space for new Raspberry Pis.

149
00:08:33,794 --> 00:08:38,614
As we mentioned earlier, just 80
Raspberry Pi can be fit in this cluster.

150
00:08:39,484 --> 00:08:42,864
Bit of a view of how much
traffic we are moving here.

151
00:08:42,944 --> 00:08:44,305
As you can see, it's not trivial.

152
00:08:44,474 --> 00:08:48,415
We are moving gigs of traffic, even
terabytes, if we go to the Pi server

153
00:08:48,915 --> 00:08:52,405
that is acting as the gateway to
get all the metrics and collections.

154
00:08:53,395 --> 00:08:57,295
And how does this Raspberry Pi
cluster looks like in reality?

155
00:08:57,295 --> 00:08:59,265
Because we show a
picture at the beginning.

156
00:08:59,645 --> 00:09:03,355
Here is a little video of
the whole thing running.

157
00:09:03,925 --> 00:09:06,645
So let's boot up this whole thing.

158
00:09:07,114 --> 00:09:08,084
Let's start with the build.

159
00:09:08,824 --> 00:09:13,214
In this setup, as we mentioned, pxboot,
which is pre boot execution environment,

160
00:09:13,224 --> 00:09:17,424
is used to streamline the boot process
for the Raspberry Pi cluster, removing

161
00:09:17,425 --> 00:09:19,304
the need for individual SD cards.

162
00:09:20,045 --> 00:09:24,114
The process begins when the Raspberry
Pi powers on and requests an IP

163
00:09:24,114 --> 00:09:25,744
address from the DHCP server.

164
00:09:26,545 --> 00:09:30,185
It's supposed that the DHCP server will
handle this with specific auctions.

165
00:09:30,255 --> 00:09:34,515
What we've done is we hard coded
the IP address to ensure that they

166
00:09:34,515 --> 00:09:36,905
always be given the same IP address.

167
00:09:37,805 --> 00:09:41,765
Once the Raspberry Pi receives
the predefined static IP, which

168
00:09:41,765 --> 00:09:42,564
is configured on the dhcp.

169
00:09:42,564 --> 00:09:46,954
conf file, the next step involves
requesting the bootloader

170
00:09:46,954 --> 00:09:48,655
file from the TFTP server.

171
00:09:49,219 --> 00:09:54,790
For the Ubuntu and Raspbian
images served via the NFS mounts.

172
00:09:55,019 --> 00:09:57,719
To ensure and prevent storage
conflicts across the nodes,

173
00:09:58,179 --> 00:09:59,989
overlay file systems are used.

174
00:10:00,189 --> 00:10:03,049
This allows the Raspberry to
efficiently mount their operating

175
00:10:03,049 --> 00:10:06,969
system image and share the storage
while isolating writes, so we ensure

176
00:10:06,969 --> 00:10:11,399
that we have a scalable and manageable
boot process for the entire cluster.

177
00:10:11,954 --> 00:10:16,114
Here we came with a little
bit of how this process goes.

178
00:10:16,314 --> 00:10:19,614
Raspberry Pi comes and shouts,
Hey, I want my IP address.

179
00:10:20,464 --> 00:10:21,664
Which one I can use?

180
00:10:21,704 --> 00:10:27,314
We have the DHCP server, the Raspberry Pi
server, the NAS, which is sleeping because

181
00:10:27,314 --> 00:10:29,994
it doesn't intervene in this process.

182
00:10:30,425 --> 00:10:33,495
We have our router coming and
say, okay, you have this fixed IP

183
00:10:33,635 --> 00:10:37,425
assigned, but now it's okay, but
I don't have operating system.

184
00:10:37,425 --> 00:10:38,825
And here is my serial number.

185
00:10:38,965 --> 00:10:39,825
Who can help me?

186
00:10:40,315 --> 00:10:43,145
The router doesn't know because
it's not configured for that.

187
00:10:43,515 --> 00:10:49,055
So here is where our PX boot server
will come and we'll say, okay, here are

188
00:10:49,055 --> 00:10:51,255
your boot files for your serial numbers.

189
00:10:51,425 --> 00:10:55,295
And then he will ask finally the
NAS on, hey, I need storage here.

190
00:10:55,635 --> 00:10:56,935
Could you please share it with me?

191
00:10:57,555 --> 00:10:58,715
And it will hand over there.

192
00:10:59,355 --> 00:11:01,754
Easy process, three
different devices involved.

193
00:11:02,454 --> 00:11:08,254
But, to configure the Raspberry Pis
for PX boot, With the latest one,

194
00:11:08,254 --> 00:11:11,404
it's enabled by default, but with the
old ones, you have to do it manually.

195
00:11:12,004 --> 00:11:13,384
You have different ways of doing.

196
00:11:13,984 --> 00:11:18,424
You could just go and update the
ware, edit the boot config, and

197
00:11:18,424 --> 00:11:22,564
ensure that you set up the one time
flag to enable networking boot,

198
00:11:22,564 --> 00:11:28,534
which is this 73 0 2 bunch of zeros
and a, and then remove the SD card.

199
00:11:28,864 --> 00:11:32,194
Problem is that you need to do it for
the 63, so you will have to be doing

200
00:11:32,194 --> 00:11:35,704
that 63 times, which is not very fun way.

201
00:11:36,104 --> 00:11:40,434
To get things working
to set up the PX server.

202
00:11:41,084 --> 00:11:44,964
What we found was there's already out
there on the Internet and here's the

203
00:11:44,964 --> 00:11:48,204
link for the GitHub, which will help you.

204
00:11:48,224 --> 00:11:52,034
This solution, it's designed
specifically to run on Raspberry Pi OS.

205
00:11:52,254 --> 00:11:56,004
However, to use it on Ubuntu,
that was our operating system.

206
00:11:56,564 --> 00:11:58,134
We had to do some adjustments.

207
00:11:58,604 --> 00:12:03,034
As the Ubuntu system structure is
slightly different, a key challenges

208
00:12:03,074 --> 00:12:08,444
arise with the new Raspberry Pi OS
that is based on Debian 12, that is

209
00:12:08,454 --> 00:12:13,484
the book one, which is, which isn't
fully compatible with the PX script.

210
00:12:13,614 --> 00:12:17,914
To make it work, we use the older
legacy Raspberry Pi OS based on

211
00:12:17,964 --> 00:12:21,564
Debian which maintains compatibility.

212
00:12:21,764 --> 00:12:26,194
And additionally, the current script
runs in interactive mode, meaning

213
00:12:26,194 --> 00:12:30,534
that it requires the user input step
by step to configure the PX server.

214
00:12:31,144 --> 00:12:34,344
To streamline the whole deployment for
a large cluster like the one we are

215
00:12:34,344 --> 00:12:35,894
building, the script needs to be built.

216
00:12:36,234 --> 00:12:40,724
have minor modifications to run
in non interactive mode, which

217
00:12:40,724 --> 00:12:44,314
will allow the configuration to be
automated without manual intervention.

218
00:12:44,814 --> 00:12:46,444
This is the way we proceed.

219
00:12:47,164 --> 00:12:48,344
Here is how it looks like.

220
00:12:48,824 --> 00:12:52,074
You usually just use three
options, one, seven, and eight.

221
00:12:52,104 --> 00:12:54,874
That is how we install the PX server.

222
00:12:54,934 --> 00:12:57,274
We provision, we get things done.

223
00:12:57,774 --> 00:13:01,284
Here is a short demo on how this works.

224
00:13:01,784 --> 00:13:06,174
Option one we just installed with the boot
capabilities, option seven we create the

225
00:13:06,184 --> 00:13:09,854
image, and option eight we just provision
the nodes by deploying the prepared

226
00:13:10,364 --> 00:13:12,354
operating system over the network.

227
00:13:12,854 --> 00:13:13,674
Looks easy, right?

228
00:13:14,114 --> 00:13:16,324
we face different challenges
even in this first step.

229
00:13:16,754 --> 00:13:19,404
First of all is the manual
MAC addressing collection.

230
00:13:20,314 --> 00:13:23,294
Building this whole thing
and having static IP required

231
00:13:23,294 --> 00:13:26,514
detailed DHCP configuration, how
we predefined the whole thing.

232
00:13:26,534 --> 00:13:30,564
We had also initial configuration
barrier that was difficult without

233
00:13:30,704 --> 00:13:33,474
having a pre configured network settings.

234
00:13:34,434 --> 00:13:38,564
Having this on the PX side just to
boot things came hey, what are the

235
00:13:38,564 --> 00:13:41,314
different type of solutions that
we could have on this whole thing?

236
00:13:42,054 --> 00:13:42,854
There are a few of them.

237
00:13:43,144 --> 00:13:46,354
For example, we could manually,
collect all the MAC address.

238
00:13:47,104 --> 00:13:51,724
You check the MAC address from the
step one where we were enabling

239
00:13:51,724 --> 00:13:56,114
the flag, you can just go and do
it 63 times to see which class

240
00:13:56,114 --> 00:13:57,684
on the Ethernet address you have.

241
00:13:58,154 --> 00:14:01,074
But you can also do it from the
network switch, just getting

242
00:14:01,084 --> 00:14:02,584
the show MAC address table.

243
00:14:02,664 --> 00:14:07,614
Remember that we designed the way to
understand the nomenclature of each

244
00:14:07,634 --> 00:14:12,524
Raspberry Pi that it's correlated to
each port that we have in the switch.

245
00:14:12,524 --> 00:14:14,754
So a couple of times you
will get the whole thing.

246
00:14:14,874 --> 00:14:14,934
Thank you.

247
00:14:15,434 --> 00:14:19,114
As we said, the nomenclature, we use
the last octet and the port number of

248
00:14:19,114 --> 00:14:23,924
the switch, so for bottom switch would
be 1 something, top switch 2 something.

249
00:14:24,094 --> 00:14:27,614
If you see, for example,
this IP address 172.

250
00:14:27,664 --> 00:14:28,144
16.

251
00:14:28,184 --> 00:14:28,754
5.

252
00:14:28,814 --> 00:14:33,764
105, we will set the Raspberry
Pi to 105, which will be located

253
00:14:33,764 --> 00:14:35,584
in the bottom switch on port 5.

254
00:14:36,464 --> 00:14:41,534
Here is a view from the console on
how it looks, the nomenclature of

255
00:14:41,574 --> 00:14:43,054
everything what we have installed.

256
00:14:43,554 --> 00:14:46,924
And now comes the serial number
to provision the operating system.

257
00:14:46,924 --> 00:14:49,234
So there were also different options.

258
00:14:49,614 --> 00:14:54,134
You can do it 63 times again
and just see the CPU info that

259
00:14:54,134 --> 00:14:55,504
will extract the serial number.

260
00:14:55,704 --> 00:14:59,364
This will read the CPU information,
search for the serial line, and

261
00:14:59,364 --> 00:15:00,674
it will extract that number.

262
00:15:01,104 --> 00:15:05,294
Or we can use the device tree
to extract the serial number.

263
00:15:05,794 --> 00:15:09,114
What it does here, it reads the
serial number directly from the

264
00:15:09,114 --> 00:15:11,134
Raspberry Pi's firmware device tree.

265
00:15:12,024 --> 00:15:15,014
And having a, you need to have
a working operating system

266
00:15:15,094 --> 00:15:16,554
and access to the SD card.

267
00:15:17,224 --> 00:15:19,974
Again, we didn't have SD
cards for the whole thing.

268
00:15:20,154 --> 00:15:23,094
So doing 63 times was not
really the way to do it.

269
00:15:23,784 --> 00:15:25,344
So we went with option three.

270
00:15:26,184 --> 00:15:27,934
We check DNS mask logs.

271
00:15:27,934 --> 00:15:31,804
That is what is using this BX
boot script that we just deployed.

272
00:15:31,864 --> 00:15:34,594
There's some manual work and instruction.

273
00:15:34,874 --> 00:15:38,154
You need to manually check the
logs, filter the data using tools

274
00:15:38,154 --> 00:15:42,794
like AWK and GREP, and extract
the relevant, serial information.

275
00:15:43,674 --> 00:15:44,644
This is how it looks.

276
00:15:45,144 --> 00:15:48,319
If you look up there, As you can
see, this is just for a single IP.

277
00:15:48,319 --> 00:15:51,799
So you will have very long
logs to get all the 63.

278
00:15:52,149 --> 00:15:56,149
So it takes a bit of time, but you can
get the IP address with the serial number.

279
00:15:56,649 --> 00:16:02,609
So strategies to tackle all the network
issues because we are sharing just

280
00:16:02,619 --> 00:16:05,229
300 mix for the whole thing there.

281
00:16:05,969 --> 00:16:09,209
One of the things we could do is
traffic segmentations on the villains.

282
00:16:09,279 --> 00:16:10,329
We could implement there.

283
00:16:10,329 --> 00:16:13,959
For example, we can create separate
villains for the px boot traffic.

284
00:16:14,779 --> 00:16:18,739
That would be something that is used just
in the initial phase to provision the

285
00:16:18,739 --> 00:16:20,809
whole information on our Raspberry Pis.

286
00:16:21,079 --> 00:16:24,399
We also have the Kubernetes
communication that is the server to the

287
00:16:24,409 --> 00:16:26,529
Raspberry Pi traffic in our solution.

288
00:16:26,999 --> 00:16:30,819
But we also are going to have the
Postgres API calls on Kubernetes,

289
00:16:30,839 --> 00:16:32,549
which is the data plane communication.

290
00:16:33,239 --> 00:16:35,239
So to prevent this, we could probably go.

291
00:16:35,569 --> 00:16:40,139
And just set up VLAN 10 for PX boot
traffic, 20 for server Raspberry

292
00:16:40,139 --> 00:16:45,119
Pi control plane, and VLAN 30
for Postgres API communication.

293
00:16:45,969 --> 00:16:48,009
We can also configure QoS rules.

294
00:16:48,009 --> 00:16:52,519
For example, we can assign higher priority
to the Postgres API communication and

295
00:16:52,519 --> 00:16:57,179
Kubernetes control plane message, which
is what is the main topic and what's going

296
00:16:57,179 --> 00:16:58,779
to be heavily happening in the future.

297
00:16:58,959 --> 00:17:02,659
In our cluster, and we can set
a lower priority for the PX boot

298
00:17:02,659 --> 00:17:04,449
and other non critical traffic.

299
00:17:04,619 --> 00:17:09,029
As mentioned, we're just going to
do it one time for the setup or

300
00:17:09,029 --> 00:17:12,379
every time you just need to add a
new Raspberry Pi to this cluster.

301
00:17:13,139 --> 00:17:18,769
We could also implement IGMP snooping and
broadcast storm control on the switches.

302
00:17:18,869 --> 00:17:23,049
We could limit the impact of broadcast
and multicast traffic on the network.

303
00:17:23,949 --> 00:17:28,809
To minimize the number of
intermediate switches trying to

304
00:17:29,299 --> 00:17:32,449
reduce the amount of latency that
we can have in the whole setup.

305
00:17:32,989 --> 00:17:36,289
We could have flow control, which
helps manage traffic congestion.

306
00:17:36,789 --> 00:17:39,939
We could have flow control that
helps us manage traffic congestion

307
00:17:39,939 --> 00:17:43,659
by signaling when buffers are
full, but also jumbo frames, which

308
00:17:43,659 --> 00:17:46,309
increase the maximum MTU unit size.

309
00:17:46,699 --> 00:17:49,309
Those allow for more
efficient data transmission.

310
00:17:49,349 --> 00:17:53,669
Set this to 9000 bytes on both
the Bionetwork interfaces and

311
00:17:53,669 --> 00:17:57,329
the switch can reduce the packet
fragmentation and improve throughput.

312
00:17:57,669 --> 00:18:01,089
To be honest, didn't have too
much impact in our deployment.

313
00:18:01,644 --> 00:18:06,474
And then we have also the DNS Kubernetes
clusters are rely heavily on DNS lookups,

314
00:18:06,894 --> 00:18:10,794
so we can ensure that the DNS catching
is configured on both the server and

315
00:18:10,794 --> 00:18:15,414
the Raspberry Pi nodes to avoid repeated
external DNS queries, which can introduce

316
00:18:15,414 --> 00:18:20,164
latency, we can set up a local DNS
cache or DNS forward on our server

317
00:18:20,164 --> 00:18:22,384
to handle DNS requests more quickly.

318
00:18:22,984 --> 00:18:27,034
And last but not least, link aggregation
port channels on the switches.

319
00:18:27,224 --> 00:18:31,194
Trying to load balance across multiple
switches there, and to be honest,

320
00:18:31,444 --> 00:18:34,784
there's always things that we can
just go and upgrade from 1 to 10 gigs

321
00:18:34,924 --> 00:18:36,594
and have high speed connectivity.

322
00:18:37,574 --> 00:18:38,164
now what?

323
00:18:38,884 --> 00:18:42,924
we had the assembling of the Raspberry
Pi, we have the network under control.

324
00:18:43,574 --> 00:18:47,034
Let's go ahead and start this, and
let's see how this whole thing works.

325
00:18:47,679 --> 00:18:52,579
As we mentioned, StackGrid is a PostgreSQL
as a service platform that will simplify

326
00:18:52,719 --> 00:18:55,099
the way you deploy Postgres on Kubernetes.

327
00:18:55,569 --> 00:18:58,219
To be honest, it's just a single
command in your Helm chart.

328
00:18:58,729 --> 00:19:01,719
You put it there and it will have
the whole installation process.

329
00:19:02,119 --> 00:19:05,449
I was surprised because I was expecting
with all the problems and challenges

330
00:19:05,449 --> 00:19:10,029
we had before, that this was going to
be, again, another big challenge and

331
00:19:10,029 --> 00:19:12,019
ended up being the easiest solution.

332
00:19:12,849 --> 00:19:16,374
So We have different
deployment strategies here.

333
00:19:16,375 --> 00:19:21,214
As you can see, we have the running
Kubernetes on Raspberry Pi using tools

334
00:19:21,214 --> 00:19:27,414
like K3S or you can even use the K3S
soup from Alex Elix that has also another

335
00:19:27,424 --> 00:19:30,084
wrapper to make it easier installation.

336
00:19:30,734 --> 00:19:34,874
For this one, we will have from sharding
with Ctools and it will integrate

337
00:19:34,894 --> 00:19:39,014
management of Postgres clusters and
all the high availability features

338
00:19:39,014 --> 00:19:41,584
that we can find on this database.

339
00:19:42,029 --> 00:19:45,109
So here is a bit of the architecture.

340
00:19:45,359 --> 00:19:49,409
It's a modular, and let's break down
a little bit of the key components.

341
00:19:49,979 --> 00:19:53,199
We have a stackgress controller
at the core, which extends the

342
00:19:53,219 --> 00:19:57,389
Kubernetes functionality by defining
custom resource definitions or CRDs.

343
00:19:57,390 --> 00:20:02,389
The stackgress controller will act as
the orchestrator and manage these CRDs.

344
00:20:03,059 --> 00:20:06,929
Cube Control is used to interact with
the controller, enabling the users

345
00:20:06,929 --> 00:20:11,369
to create, configure, and manage
the Postgre clusters declaratively,

346
00:20:11,639 --> 00:20:14,099
using Kubernetes native YAMA files.

347
00:20:14,599 --> 00:20:19,309
We also have the rest API for the
API users IT expose the rest PI for

348
00:20:19,309 --> 00:20:22,139
programmatic access and external use.

349
00:20:22,839 --> 00:20:26,499
The API users can interact with
the Postgres cluster to perform

350
00:20:26,529 --> 00:20:30,969
operations like scaling, configuration,
updates, backups, or monitoring.

351
00:20:31,209 --> 00:20:37,639
Also, the REST API acts as the abstraction
layer of the CRDs, so it will simplify

352
00:20:37,639 --> 00:20:39,869
the interaction for developers and tools.

353
00:20:40,789 --> 00:20:44,219
We have also the distributed
log server for observability.

354
00:20:44,229 --> 00:20:48,079
Stack REST uses Fluentd to
collect and aggregate logs.

355
00:20:48,359 --> 00:20:52,569
The logs are then stored in Postgres
database and enhanced with the TimescaleDB

356
00:20:53,039 --> 00:20:54,569
for time series data management.

357
00:20:55,489 --> 00:20:58,489
And we will save it to persistent
volume storage, ensuring that

358
00:20:58,489 --> 00:21:03,359
it's durable and available for
historical logs for later analysis.

359
00:21:04,039 --> 00:21:07,989
Then we have the service primary,
which is a read write traffic.

360
00:21:08,489 --> 00:21:12,329
This is responsible for handling the read
write client traffic and it routes the

361
00:21:12,329 --> 00:21:16,229
connections from the primary Postgres
instance, ensuring that transactional

362
00:21:16,789 --> 00:21:18,779
consistency and data integrity.

363
00:21:18,999 --> 00:21:22,729
It's essential for applications that
require updates to the database.

364
00:21:23,614 --> 00:21:26,864
We have also the service replica,
which are read only traffic.

365
00:21:27,604 --> 00:21:32,314
This will route the read only client
traffic to the Postgres replica instances.

366
00:21:32,434 --> 00:21:36,044
This setup offloads the read traffic
from the primary instance, so we

367
00:21:36,044 --> 00:21:39,734
will improve the performance and
scalability for read heavy workloads.

368
00:21:40,484 --> 00:21:43,104
And then we have the
Kubernetes pods and replicas.

369
00:21:43,154 --> 00:21:47,274
Each Postgres instance, including
the primary and the replicas, runs

370
00:21:47,294 --> 00:21:49,124
within its own Kubernetes pods.

371
00:21:49,864 --> 00:21:53,254
Stackgres will ensure high
availability and scalability by

372
00:21:53,344 --> 00:21:56,444
managing multiple replica pods.

373
00:21:56,554 --> 00:21:57,424
What else?

374
00:21:57,864 --> 00:22:01,294
we need to introduce the concept of
sharding, that it's a technique to

375
00:22:01,304 --> 00:22:05,964
horizontally scale Postgres databases
by splitting the data into smaller and

376
00:22:05,974 --> 00:22:07,954
more manageable parts called shards.

377
00:22:08,404 --> 00:22:12,434
Each shard contains a subset of the
data and is managed by an independent

378
00:22:12,454 --> 00:22:14,234
Postgres instance or replica set.

379
00:22:15,094 --> 00:22:18,284
What this does, it will help us
to have a better performance for

380
00:22:18,304 --> 00:22:21,895
large datasets by reducing the
load on individual database nodes.

381
00:22:21,895 --> 00:22:26,574
For example, the queries are routed
to the appropriate shard based on

382
00:22:26,574 --> 00:22:30,444
the partitioning key, which will
ensure efficient data retrieval.

383
00:22:31,014 --> 00:22:35,364
This will allow us the system to
handle increasingly workloads without

384
00:22:35,394 --> 00:22:38,074
overwhelming a single database instance.

385
00:22:38,804 --> 00:22:44,424
As we mentioned earlier, Citus acts as
an extension to PostgreSQL, transforming

386
00:22:44,424 --> 00:22:46,674
it into a distributed database.

387
00:22:46,834 --> 00:22:50,824
It splits table into shards,
distributed them across different pods.

388
00:22:51,284 --> 00:22:55,914
A coordinator node will manage the
query routing and parallel execution

389
00:22:55,964 --> 00:22:59,314
ensuring that the queries are
directed to the appropriate shard.

390
00:23:00,084 --> 00:23:04,564
This architecture allows us to
scale of read and write operations,

391
00:23:05,104 --> 00:23:09,124
having parallel query execution and
seamless handling of large datasets.

392
00:23:09,244 --> 00:23:09,894
As you can see.

393
00:23:10,594 --> 00:23:12,574
Each worker has its own replica.

394
00:23:13,174 --> 00:23:17,324
To deploy this whole thing, if you
do it by hand, it can take two weeks.

395
00:23:17,714 --> 00:23:21,654
Probably you would like to do it with
Ansible and it would be like two months.

396
00:23:21,994 --> 00:23:22,364
It's reproducible.

397
00:23:22,864 --> 00:23:26,209
However, and sorry for that line that
should be on the Stackdress side, the

398
00:23:26,209 --> 00:23:31,614
Stackdress you have 20, 30 lines of YAML
with the whole configuration and you

399
00:23:31,614 --> 00:23:34,184
can just start deploying your cluster.

400
00:23:34,304 --> 00:23:35,654
So let's start building.

401
00:23:36,154 --> 00:23:39,424
for the kubernetes setup, we
already talked about k3s, which is a

402
00:23:39,424 --> 00:23:42,184
lightweight kubernetes distribution.

403
00:23:42,684 --> 00:23:47,549
We are going, we found that the control
groups or cgroups That is a feature of the

404
00:23:47,549 --> 00:23:52,199
Linux kernel, which allows you to allocate
resources such as CPU time and system

405
00:23:52,199 --> 00:23:56,639
memory for a specific process or group
of process was not enabled by default.

406
00:23:57,189 --> 00:24:02,189
So we just enabled cgroups and we're
going to use the external etcd instance,

407
00:24:02,279 --> 00:24:06,529
which is deployed on the NAS server as
a single instance using shared storage.

408
00:24:07,339 --> 00:24:09,259
So etcd is distributed.

409
00:24:09,794 --> 00:24:13,984
It has a consistent key value store
that acts as the brain of Kubernetes,

410
00:24:13,984 --> 00:24:18,234
and it will store all cluster
configuration, data, state, and metadata.

411
00:24:18,614 --> 00:24:21,994
So hosting this externally, we
will centralize the control plane

412
00:24:21,994 --> 00:24:26,294
statements management, so we
ensure persistence and reliability.

413
00:24:26,804 --> 00:24:31,474
However, running a single instance
means there's no redundancy.

414
00:24:31,724 --> 00:24:32,264
take care!

415
00:24:32,674 --> 00:24:36,244
Because this must be taken into
account when you deploy into

416
00:24:36,244 --> 00:24:39,944
production challenges, let's
get a bit of the challenges.

417
00:24:39,944 --> 00:24:41,304
We heart we had here.

418
00:24:41,444 --> 00:24:45,734
So we had hardware constraints
running Kubernetes control plane on

419
00:24:45,734 --> 00:24:50,904
a three B plus is nearly impossible
because of the limited memory.

420
00:24:50,904 --> 00:24:53,824
We have 910 mix and under power CPU.

421
00:24:53,944 --> 00:24:54,924
We're running on 1.

422
00:24:55,074 --> 00:24:58,144
2 Gigahertz with four course.

423
00:24:58,214 --> 00:25:03,034
The Pi server intended to handle both
NAS and Kubernetes stacks lacks the

424
00:25:03,034 --> 00:25:05,354
capacity to manage the load effectively.

425
00:25:05,984 --> 00:25:09,484
Additionally, the lack of
local storage further restricts

426
00:25:09,484 --> 00:25:13,314
operations, making resource
management a significant challenge.

427
00:25:14,114 --> 00:25:17,814
We also had all the network limitation
we've been talking around the session

428
00:25:17,814 --> 00:25:20,804
on these 300 megs of network bandwidth.

429
00:25:21,184 --> 00:25:25,274
Which becomes a network bottleneck
for data intensive operations

430
00:25:25,274 --> 00:25:26,654
and cluster communications.

431
00:25:27,244 --> 00:25:29,524
So this whole thing limited
the overall performance and

432
00:25:29,524 --> 00:25:31,864
scalability of our solution.

433
00:25:32,034 --> 00:25:36,674
As a very clever guy said once, there is
no problem in computer science that can't

434
00:25:36,684 --> 00:25:39,014
be solved by another level of indirection.

435
00:25:39,474 --> 00:25:42,519
Which means, Let's just
throw more hardware there.

436
00:25:43,269 --> 00:25:44,959
We added these servers.

437
00:25:44,959 --> 00:25:50,639
We had a Lenovo was using a
Ryzen 5, which, was a bit old.

438
00:25:50,739 --> 00:25:54,679
We had a Slimbook there,
a Ryzen 7 with 16 gigs.

439
00:25:55,499 --> 00:25:57,029
And let's see how this works now.

440
00:25:57,909 --> 00:25:59,419
Let's get our hands dirty.

441
00:25:59,629 --> 00:26:01,994
Let's install the K3s server.

442
00:26:02,669 --> 00:26:03,689
So here's the command.

443
00:26:03,729 --> 00:26:07,299
We're going to curl and
install the version 1 29.

444
00:26:07,299 --> 00:26:10,019
I will define the endpoints.

445
00:26:10,499 --> 00:26:14,779
The TLS and will level the
notes as a service controller.

446
00:26:15,009 --> 00:26:16,249
What's the note 10?

447
00:26:17,109 --> 00:26:20,989
And we will disable traffic
metrics and health controller.

448
00:26:21,219 --> 00:26:24,759
As you can see, we're already
disabling monitoring things.

449
00:26:25,229 --> 00:26:27,929
And it's there's a simple
reason behind the scenes.

450
00:26:28,499 --> 00:26:29,919
There was not enough bandwidth.

451
00:26:30,434 --> 00:26:34,694
To get the node exporters inside
the infrastructure, and we'll

452
00:26:34,694 --> 00:26:36,414
see later how this works also.

453
00:26:36,884 --> 00:26:39,894
let's wait and automate this whole thing.

454
00:26:39,974 --> 00:26:44,484
As you can see, it can take two hours
to get the 63 Raspberry Pis and you can

455
00:26:44,484 --> 00:26:49,524
just go and grab a coffee, have a meeting
with your manager or peers, and two hours

456
00:26:49,524 --> 00:26:52,324
later, get back to get the whole setup.

457
00:26:52,824 --> 00:26:57,754
We got it, everything deployed,
but If we get here and we get our

458
00:26:57,814 --> 00:27:01,934
kubectl get nodes, we see that we
have several that are not ready.

459
00:27:02,434 --> 00:27:05,704
They were flapping and we're
seeing a lot of this happening.

460
00:27:05,854 --> 00:27:10,004
We find out of memory issues,
storage disconnections, high load

461
00:27:10,004 --> 00:27:11,484
and network congestion happening.

462
00:27:11,954 --> 00:27:18,094
Also at the beginning, we found that
The USB charger that was providing the

463
00:27:18,094 --> 00:27:22,144
power to the Raspberry Pi was not working
properly and we had to replace it.

464
00:27:22,534 --> 00:27:25,614
It took us some time to find
that it was the charger that

465
00:27:25,614 --> 00:27:27,404
was giving out all the problems.

466
00:27:27,684 --> 00:27:28,904
What's the solution here?

467
00:27:29,044 --> 00:27:32,844
Hope that you guys like it crowd
because hey, I've been trying to turn

468
00:27:32,844 --> 00:27:35,144
it off and on again and it worked.

469
00:27:35,554 --> 00:27:38,024
We got things back and now the easy part.

470
00:27:38,374 --> 00:27:40,374
Let's get on the stackgres solution.

471
00:27:40,724 --> 00:27:42,134
So this command will start.

472
00:27:42,894 --> 00:27:46,514
Or upgrade the stackless operator
in a new namespace with Prometheus

473
00:27:46,514 --> 00:27:49,834
and Grafana turned off again.

474
00:27:50,334 --> 00:27:53,674
Things that are monitoring and
observability, we will run in with

475
00:27:53,674 --> 00:27:55,584
the basics to see if this was working.

476
00:27:56,064 --> 00:27:58,434
And then we'll get into the next
phase that is observability.

477
00:27:58,934 --> 00:28:01,874
So we try to reduce the
resource consumption.

478
00:28:02,494 --> 00:28:07,304
because of this limited CPU and memory
that couldn't handle additional load for

479
00:28:07,534 --> 00:28:09,894
the monitoring and visualization tools.

480
00:28:10,004 --> 00:28:11,854
We're running version 1.

481
00:28:11,854 --> 00:28:16,844
13, and you just get kubectl,
getpod, stagress, and you

482
00:28:16,864 --> 00:28:18,164
have here things running.

483
00:28:18,874 --> 00:28:22,084
Challenges to get this up and running.

484
00:28:22,994 --> 00:28:25,264
We had a lot of compatibility issues.

485
00:28:25,524 --> 00:28:28,244
running stagress on ARM
based Raspberry Pis.

486
00:28:28,529 --> 00:28:32,099
Requires adapting the software for
ARM architecture and fine tuning the

487
00:28:32,099 --> 00:28:36,789
Kubernetes settings to accommodate
the limited CPU and memory resources.

488
00:28:37,579 --> 00:28:42,209
Default configuration often assumes
more powerful x86 hardware, so be

489
00:28:42,209 --> 00:28:46,789
careful with adjustments where needed
if you want stability and performance.

490
00:28:47,289 --> 00:28:47,579
We'll show.

491
00:28:48,079 --> 00:28:52,529
Improve the storage, so implement a
ZFS pool for shared management and

492
00:28:52,559 --> 00:28:56,939
configuration of the ESCASI volumes
for a reliable and high speed access.

493
00:28:57,689 --> 00:29:01,629
Due to the Raspberry Pi limitations,
we offloaded intensive tasks like

494
00:29:01,629 --> 00:29:06,199
the Kubernetes control plane and
the NAS server to the two AMD64

495
00:29:06,199 --> 00:29:08,089
desktops that we just showed before.

496
00:29:08,729 --> 00:29:11,829
It was a way to ensure that
the cluster remained functional

497
00:29:11,909 --> 00:29:13,299
and at least a bit performant.

498
00:29:13,799 --> 00:29:15,119
Software compatibility.

499
00:29:16,009 --> 00:29:19,039
To overcome these challenges,
we had to recompile the Envoy

500
00:29:19,039 --> 00:29:20,779
component for a better performance.

501
00:29:21,279 --> 00:29:24,219
Now, Everybody can get
because thanks to staggers.

502
00:29:24,269 --> 00:29:25,809
This is public for everybody.

503
00:29:26,039 --> 00:29:30,339
So now you can use the envoy component
in the staggered solution using arm.

504
00:29:30,699 --> 00:29:31,909
Also for networking.

505
00:29:31,909 --> 00:29:34,989
We wanted and tested ceiling,
but we encounter failures that

506
00:29:34,989 --> 00:29:36,829
we require alternative approach.

507
00:29:37,589 --> 00:29:42,579
Initially, he is Cassie targets were
confer using TGT power later switches

508
00:29:42,609 --> 00:29:44,979
to Leo, the Linux input output target.

509
00:29:45,669 --> 00:29:48,719
The idea was to try to improve
the stability in the performance,

510
00:29:48,799 --> 00:29:50,439
but the whole entire process.

511
00:29:50,984 --> 00:29:55,104
Involve extensive trial and
errors to fine tune the setup.

512
00:29:55,584 --> 00:29:57,424
It was not a single shot.

513
00:29:57,874 --> 00:29:59,454
It took us a few weeks.

514
00:29:59,454 --> 00:30:03,264
I would even say a month and a half
to get everything working and sorted

515
00:30:03,264 --> 00:30:07,734
out all the compatibility issue
despite the challenges we achieve.

516
00:30:08,034 --> 00:30:12,474
We were able to successfully deploy
all these taggers, overcoming the whole

517
00:30:12,494 --> 00:30:17,904
architecture limitations and integration
to build this functional environment,

518
00:30:18,234 --> 00:30:23,044
how we started and how we did that can
be reflected in this picture, we were

519
00:30:23,064 --> 00:30:24,774
really eager to start the project.

520
00:30:24,894 --> 00:30:27,359
I'm very excited, but
we end up let's do it.

521
00:30:27,899 --> 00:30:29,619
Finish this as soon as possible.

522
00:30:29,629 --> 00:30:30,829
Let's move to something else.

523
00:30:31,449 --> 00:30:34,649
A lot of headaches, a lot of
hours and nightmares running

524
00:30:34,659 --> 00:30:36,149
this whole thing, but it was fun.

525
00:30:36,329 --> 00:30:40,039
Usually learning the hard way is
the best way to get things done.

526
00:30:40,509 --> 00:30:42,109
let us show you just a quick demo.

527
00:30:42,739 --> 00:30:47,689
And just getting on the patroni topology
and how you can see all the workers.

528
00:30:48,459 --> 00:30:52,209
in the demo, we run the following
command to display the whole topology.

529
00:30:52,539 --> 00:30:55,779
Patroni is an open source cluster
management tool that automates the

530
00:30:55,779 --> 00:30:59,859
deployment and the failover of high
availability Postgres clusters.

531
00:31:00,549 --> 00:31:04,089
Let we just here and this command
will provide a clear view.

532
00:31:04,819 --> 00:31:08,429
Of the clusters set up, it will
show us the node that has as

533
00:31:08,449 --> 00:31:10,379
primary, which ones are replica.

534
00:31:10,839 --> 00:31:15,019
In our case, that we had 20
workers, each with its own replica.

535
00:31:15,519 --> 00:31:17,079
And now comes the fun questions.

536
00:31:17,299 --> 00:31:20,449
You say, what happens with
the whole observability thing?

537
00:31:20,949 --> 00:31:22,949
we found many key problems here.

538
00:31:23,369 --> 00:31:24,639
we had resource constraints.

539
00:31:24,659 --> 00:31:28,949
We had limited CPU, memory, even
disk space on each Raspberry Pi node.

540
00:31:29,419 --> 00:31:31,739
And there was no space
available to install any

541
00:31:31,739 --> 00:31:33,769
monitoring agents or exporters.

542
00:31:34,529 --> 00:31:40,949
We also had this bandwidth limitation of
300 Mbps that become a huge bottleneck.

543
00:31:41,499 --> 00:31:45,979
And we had high data volume
from metrics collation that was

544
00:31:45,999 --> 00:31:47,549
overwhelming the whole network.

545
00:31:48,049 --> 00:31:51,389
Last but not least, we had
inefficient observability data flow.

546
00:31:51,919 --> 00:31:56,789
We were trying to send directly the
metrics from each node to AWS Cloud, and

547
00:31:56,789 --> 00:32:00,799
it resulted in high latency, excessive
bandwidth consumption, and increased

548
00:32:00,799 --> 00:32:03,099
cloud costs for the storage and transfer.

549
00:32:03,989 --> 00:32:07,399
So we were trying to find, hey,
what are solutions that could help

550
00:32:07,399 --> 00:32:09,719
us minimize all these problems?

551
00:32:09,809 --> 00:32:13,419
We look at defining our own
custom metric collection.

552
00:32:13,469 --> 00:32:17,579
We could use a lightweight python script
to collect just essential metrics, CPU,

553
00:32:17,619 --> 00:32:25,129
memory, disk and network using the PS util
tool, we can consolidate and batch data

554
00:32:25,399 --> 00:32:30,759
at the gateway node, one of the servers
that we were using and compressing the

555
00:32:30,759 --> 00:32:35,339
whole payloads before sending that to
the cloud from a bandwidth perspective.

556
00:32:35,839 --> 00:32:39,949
We could reduce the sampling frequency,
collect metrics every 60 seconds,

557
00:32:39,949 --> 00:32:43,039
or even 120 seconds, 1 to 2 minutes.

558
00:32:43,119 --> 00:32:48,529
We could use a lightweight data transfer
protocol, like MQTT, with compression.

559
00:32:49,279 --> 00:32:53,339
And we can send only aggregated data
summaries instead of the raw metrics.

560
00:32:54,299 --> 00:32:58,289
And also, we could implement some
edge processing to analyze and filter

561
00:32:58,319 --> 00:32:59,769
metrics locally, as we did before.

562
00:33:00,504 --> 00:33:04,474
The whole transmission, and we
could send only critical alerts or

563
00:33:04,694 --> 00:33:08,324
anomalies to the cloud for further
action and remove anything else there.

564
00:33:08,564 --> 00:33:12,834
So scaling observability solutions
for a large number of Raspberry Pi

565
00:33:12,874 --> 00:33:17,404
nodes is not feasible with traditional
exporter like Prometheus node.

566
00:33:17,904 --> 00:33:21,684
exporter and so on using
the three B plus cards.

567
00:33:21,784 --> 00:33:25,464
Probably if you use modern ones, you
can feed exporters in a better way.

568
00:33:26,104 --> 00:33:26,984
This is how it looks.

569
00:33:26,984 --> 00:33:27,814
The whole thing.

570
00:33:28,114 --> 00:33:30,654
We had a couple of scripts
that we were using.

571
00:33:30,664 --> 00:33:36,104
One is the metrics collector that collects
the CPU memory and the network metrics.

572
00:33:36,134 --> 00:33:40,604
It will compress the metrics using gzip
to minimize bandwidth and will send

573
00:33:40,604 --> 00:33:43,324
metrics every 120 seconds to the gateway.

574
00:33:44,164 --> 00:33:45,404
Then the gateway script.

575
00:33:45,824 --> 00:33:50,394
We'll receive all the compressed metrics,
decompress them, store them in a list,

576
00:33:50,614 --> 00:33:56,494
and it will aggregate metrics every
five minutes and will send those to AWS

577
00:33:56,494 --> 00:33:58,584
CloudWatch using the CloudWatch API.

578
00:33:58,704 --> 00:34:03,174
Note, if you're going to use AWS,
you need to install Boto3 AWS

579
00:34:03,214 --> 00:34:08,584
Python libraries in the monitoring
gateway for the AWS integration.

580
00:34:08,929 --> 00:34:13,089
You could set up alerts in CloudWatch
for critical thresholds, things like

581
00:34:13,229 --> 00:34:17,729
over 80 percent just send me alerts,
and visualize all those metrics using

582
00:34:17,729 --> 00:34:22,529
Grafana by connecting CloudWatch
as a data source in the Manage.

583
00:34:22,699 --> 00:34:25,929
You have two ways of doing Grafana,
by the way, in the Apple OS.

584
00:34:25,929 --> 00:34:29,989
You just can go and manually install
it on your EC2 instance, or you can use

585
00:34:30,009 --> 00:34:32,279
just the Manage service to make it work.

586
00:34:33,079 --> 00:34:34,199
Here it looks.

587
00:34:34,699 --> 00:34:35,219
How.

588
00:34:35,649 --> 00:34:39,159
Here are the Python scripts used
for both the gateways and the node.

589
00:34:39,899 --> 00:34:43,649
We will use our own AI assistant to
explain the code that we have here.

590
00:34:43,669 --> 00:34:50,149
As you can see, it will create a flash
server, install the metrics, will

591
00:34:50,149 --> 00:34:54,919
accept POST requests, decompress the
data and store metrics that we were

592
00:34:54,919 --> 00:35:01,129
talking about, CPU, memory, disk, and
do the CloudWatch integration out there.

593
00:35:01,629 --> 00:35:04,219
There's some background processing
happening as you can see there,

594
00:35:04,219 --> 00:35:08,139
we'll send them to CloudWatch, logs
the results, and even it tells us

595
00:35:08,139 --> 00:35:09,899
how we should look the output there.

596
00:35:10,399 --> 00:35:14,419
If we go to the metrics collector, as you
can see here, we're collecting different

597
00:35:14,429 --> 00:35:20,469
metrics and sending to the gateway,
we'll ask also to highlight this code

598
00:35:20,469 --> 00:35:22,039
and explain it in different sections.

599
00:35:22,089 --> 00:35:23,959
it looks at the different things we have.

600
00:35:24,829 --> 00:35:26,559
We can ask them to improve by the way.

601
00:35:27,039 --> 00:35:28,499
maybe our function is not.

602
00:35:28,659 --> 00:35:30,929
I'm not a expert programmer.

603
00:35:30,929 --> 00:35:32,339
I just do things for fun.

604
00:35:32,949 --> 00:35:34,229
But maybe you can ask your A.

605
00:35:34,229 --> 00:35:34,449
I.

606
00:35:34,499 --> 00:35:36,449
To improve the quality of your code.

607
00:35:36,809 --> 00:35:37,809
And here we'll send.

608
00:35:37,909 --> 00:35:39,789
Look, we just configured the gateway A.

609
00:35:39,789 --> 00:35:40,029
P.

610
00:35:40,029 --> 00:35:40,489
I.

611
00:35:41,209 --> 00:35:44,859
And it will include the error handling
and the main loop on the whole thing.

612
00:35:45,359 --> 00:35:48,269
a bit of examples of how
the matrix looks like.

613
00:35:49,009 --> 00:35:50,249
And how the scripts.

614
00:35:50,559 --> 00:35:53,659
It takes that it's appeared to
be a larger monitoring system

615
00:35:53,659 --> 00:35:57,789
where multiple nodes will send the
metrics to the gateway compressed.

616
00:35:58,289 --> 00:36:03,439
So the results here, frequent metric
transmission from all these 63 Raspberry

617
00:36:03,439 --> 00:36:09,319
Pi nodes saturated the 300 megs shared
bandwidth, causing latency, packet loss,

618
00:36:09,319 --> 00:36:13,789
and a very huge degradation on performance
for other workloads that we were running.

619
00:36:14,744 --> 00:36:21,274
Also high CPU overhead we had there,
processing this whole thing in

620
00:36:21,274 --> 00:36:23,004
compression was not a very good idea.

621
00:36:23,834 --> 00:36:27,814
Probably would have been better just
to send raw data, but also we had

622
00:36:27,864 --> 00:36:32,704
consistence on the network and led the
server to compress and do the whole thing.

623
00:36:33,434 --> 00:36:36,844
We had some gateway bottlenecks,
so centralized aggregation on a

624
00:36:36,854 --> 00:36:38,819
single gateway, leads to problems.

625
00:36:39,179 --> 00:36:43,849
Processing delays and scalability
limits with risk of getting drop or

626
00:36:43,849 --> 00:36:45,619
delay metrics under a heavy load.

627
00:36:46,389 --> 00:36:49,139
And we had also an
unreliable observability.

628
00:36:49,259 --> 00:36:53,909
So resource constraints result in
inconsistent reporting gaps in data

629
00:36:53,949 --> 00:36:57,789
and potential cardinality explosions,
which makes our dashboards and

630
00:36:57,819 --> 00:36:59,609
alerts less accurate and actionable.

631
00:37:00,109 --> 00:37:03,889
So this is a bit of how we went
with the whole thing of setting

632
00:37:03,889 --> 00:37:06,529
up a 63 Raspberry Pi cluster.

633
00:37:07,099 --> 00:37:10,799
We had some overall lessons
learned out here, mainly on

634
00:37:11,549 --> 00:37:12,799
the importance of planning.

635
00:37:12,799 --> 00:37:18,649
It might take much more time than what
you expect to really design how you

636
00:37:18,649 --> 00:37:24,109
want, not just the hardware, how you
want the software, but also that the

637
00:37:24,109 --> 00:37:29,179
adaptability, how we can merge both
software and hardware to make it work.

638
00:37:29,539 --> 00:37:34,759
As a single unit, recompile many
things that we had to achieve on the

639
00:37:34,759 --> 00:37:38,599
journey to make this work, but also
collaboration because this is not just

640
00:37:38,599 --> 00:37:40,179
Jorge and myself doing the whole thing.

641
00:37:40,179 --> 00:37:44,509
We got people from Stagres helping
us on validating some of the

642
00:37:44,509 --> 00:37:48,699
configurations, helping us with
the compiling of the Envoy proxy.

643
00:37:49,089 --> 00:37:51,709
And we brought other
experts to take a look here.

644
00:37:52,099 --> 00:37:54,789
But moreover, Experimentation.

645
00:37:55,429 --> 00:37:59,089
If you want real production workloads,
you need to have a distributed

646
00:37:59,089 --> 00:38:03,219
storage and other kind of updates
that we didn't consider here because

647
00:38:03,319 --> 00:38:04,989
this is a work in progress so far.

648
00:38:05,489 --> 00:38:08,489
And when I mention work in
progress, we are not stopping here.

649
00:38:08,489 --> 00:38:12,829
It's been like seven, eight months of
project, but we want to optimize Linux.

650
00:38:12,829 --> 00:38:18,799
We were going with Ubuntu, probably try
other alternative like Hokey Linux, also

651
00:38:18,839 --> 00:38:23,589
benchmarking a shared cluster and have
a real world application running on top.

652
00:38:24,039 --> 00:38:28,849
Probably we will need to change most
of the hardware to go to more improve.

653
00:38:29,579 --> 00:38:33,789
Raspberry Pi or even just try
another nodes like the Orange Pi

654
00:38:33,799 --> 00:38:37,719
and, but mainly also how we can
fine tune the kubernetes thing.

655
00:38:37,859 --> 00:38:41,929
And the best part is how we
can bring AI to the edge.

656
00:38:42,479 --> 00:38:46,139
The idea is that we can have a chatbot
for stack grace incident support.

657
00:38:46,679 --> 00:38:50,899
We want to train the chatbot using all
the errors and things that can happen

658
00:38:50,899 --> 00:38:56,139
in our cluster to provide a solution
for other customers in the near future.

659
00:38:56,784 --> 00:38:58,464
And how does the near future look like?

660
00:38:58,664 --> 00:39:02,074
superclusters can be used to train
and deploy lightweight machine

661
00:39:02,074 --> 00:39:04,724
learning and AI models at scale.

662
00:39:04,724 --> 00:39:08,124
So for example, the Raspberry Pis
could process smaller datasets for

663
00:39:08,184 --> 00:39:12,964
tasks like image recognition or natural
language processing, which can enable

664
00:39:13,024 --> 00:39:15,734
a cost effective edge AI solution.

665
00:39:16,484 --> 00:39:21,779
But by bringing Computation closer
to the data source, Raspberry

666
00:39:21,779 --> 00:39:25,259
Pi clusters can serve as a
powerful edge computing platform.

667
00:39:25,809 --> 00:39:30,389
They can enable real time data processing
for cases like smart sensors, video

668
00:39:30,389 --> 00:39:34,969
analytics, and autonomous systems, which
can reduce the latency and reliance

669
00:39:35,509 --> 00:39:37,499
on centralized cloud infrastructure.

670
00:39:38,129 --> 00:39:40,289
And last but not least, IoT management.

671
00:39:40,369 --> 00:39:44,919
I think that they can also act as hubs
to manage large scale IoT deployments.

672
00:39:45,579 --> 00:39:48,369
And they can handle tasks like
device orchestration, data

673
00:39:48,369 --> 00:39:50,199
aggregation, and monitoring.

674
00:39:50,919 --> 00:39:55,359
The ability to process and analyze
IoT data locally makes them ideal

675
00:39:55,389 --> 00:39:59,339
for smart cities, industrial
automation, and connected environments.

676
00:39:59,839 --> 00:40:03,179
And with that, thanks
for joining this session.

677
00:40:03,279 --> 00:40:07,719
Here are our handles if you want
to follow up or just get in touch.

678
00:40:07,759 --> 00:40:09,499
Let us know if you have any questions.

679
00:40:09,519 --> 00:40:12,929
Just throw it out there
and we'll try to solve it.

680
00:40:13,529 --> 00:40:14,399
Thanks very much.

681
00:40:14,864 --> 00:40:15,844
See you in the next one.

