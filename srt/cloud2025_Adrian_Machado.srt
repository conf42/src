1
00:00:00,010 --> 00:00:00,760
Hello, everyone.

2
00:00:00,780 --> 00:00:02,230
My name is Adrian Machado.

3
00:00:02,310 --> 00:00:06,550
I'm a staff engineer at Zupelo API
management, and I wanted to talk

4
00:00:06,550 --> 00:00:11,880
to you about why your API needs to
operate at the edge or the worldwide

5
00:00:11,920 --> 00:00:13,310
edge, as it's sometimes called.

6
00:00:13,810 --> 00:00:17,150
In this talk, I'm going to go over quite
a few things with regard to the edge.

7
00:00:17,150 --> 00:00:20,700
So if you're not familiar with the
edge or serverless, don't you worry,

8
00:00:20,869 --> 00:00:21,840
I'm going to cover that for you.

9
00:00:22,350 --> 00:00:25,339
I'm also going to cover some
considerations and trade offs

10
00:00:25,360 --> 00:00:29,410
that you should consider,
before you adopt the Edge.

11
00:00:29,750 --> 00:00:32,530
It's not just like a silver bullet
that's going to improve the performance

12
00:00:32,530 --> 00:00:34,770
of your APIs or microservices.

13
00:00:35,270 --> 00:00:39,450
I'm also going to talk about why
APIs, specifically, are a good

14
00:00:39,775 --> 00:00:43,405
Application of the edge, why they're
well suited to be deployed to the

15
00:00:43,405 --> 00:00:45,445
edge or at least parts of APIs.

16
00:00:46,035 --> 00:00:48,915
And then finally, I'm going to end
with a quick demo of an edge API

17
00:00:48,925 --> 00:00:52,864
that I built, and it's going to help
showcase some of the trade offs that

18
00:00:52,864 --> 00:00:56,334
I mentioned earlier in the talk, as
well as how you can debug performance

19
00:00:56,334 --> 00:00:58,385
issues when building an edge API.

20
00:00:59,085 --> 00:00:59,975
So let's jump into it.

21
00:01:00,475 --> 00:01:01,215
So who am I?

22
00:01:01,475 --> 00:01:02,065
I'm Adrian.

23
00:01:02,275 --> 00:01:05,155
Like I mentioned earlier, I'm
a staff engineer at Zuplo.

24
00:01:05,455 --> 00:01:08,804
I love writing about all things
API related, and I also create a

25
00:01:08,804 --> 00:01:10,664
lot of open source API tooling.

26
00:01:11,205 --> 00:01:14,455
One thing I created recently is called
RateMyOpenAPI, which is an open source

27
00:01:14,495 --> 00:01:16,275
API governance and scoring tool.

28
00:01:16,994 --> 00:01:20,035
I'm also a big fan of shoehorns,
just decided to throw that in there.

29
00:01:20,065 --> 00:01:23,035
If you don't currently use a shoehorn
to put on your shoes, you should.

30
00:01:23,115 --> 00:01:24,745
It's definitely a lifestyle enhancer.

31
00:01:25,245 --> 00:01:26,445
I like to qualify.

32
00:01:26,870 --> 00:01:30,649
The people attending my talks, just so
you don't waste your time, 20, 30 minutes

33
00:01:30,850 --> 00:01:32,530
on a talk that you don't find useful.

34
00:01:32,690 --> 00:01:36,220
So I think you'll enjoy this presentation
if you're one of the following buckets.

35
00:01:36,660 --> 00:01:39,630
If you're like an API engineer
or developer that's looking to

36
00:01:39,630 --> 00:01:44,170
modernize and legacy API stack
using the latest and greatest, I

37
00:01:44,170 --> 00:01:45,374
think this talk is good for you.

38
00:01:45,955 --> 00:01:49,764
If you're an executive, like a
CTO that oversees API development,

39
00:01:49,994 --> 00:01:54,524
you're learning, techniques and
architectures to help improve API

40
00:01:54,535 --> 00:01:56,335
developer experience at your company.

41
00:01:56,684 --> 00:02:00,754
Whether that's internal APIs or external
APIs, but especially public facing

42
00:02:00,754 --> 00:02:02,865
external APIs, this is a good fit for you.

43
00:02:03,524 --> 00:02:06,874
If you're just looking to build an API
for the first time, and you don't know

44
00:02:06,874 --> 00:02:10,534
the best practices and tools that you
should be using, this is also a good

45
00:02:10,565 --> 00:02:14,524
talk to you, and this is not a very
introductory level, but it's a good

46
00:02:14,815 --> 00:02:19,435
high level concept around the edge, so
it's not gonna get too in the weeds.

47
00:02:19,935 --> 00:02:23,505
So let's start with what
exactly the edge is.

48
00:02:24,185 --> 00:02:29,495
So when you typically deploy a
microservice or an API, your application

49
00:02:29,495 --> 00:02:33,815
or API is deployed to a single region
or a data center that's EU West

50
00:02:33,815 --> 00:02:37,715
one, or maybe that's NA East two.

51
00:02:37,925 --> 00:02:42,715
Wherever it's deployed, it's
in some geographic, region and.

52
00:02:43,269 --> 00:02:48,839
Unfortunately, we operate in a world where
our users can be anywhere, so all of these

53
00:02:48,850 --> 00:02:53,200
requests from around the world need to be
routed through all these, undersea cables,

54
00:02:53,230 --> 00:02:57,609
and eventually they get to the your data
center, and by the time the response gets

55
00:02:57,610 --> 00:03:01,780
back, it's gonna have pretty high latency,
sometimes in the order of seconds.

56
00:03:01,800 --> 00:03:06,980
If a call is coming from, let's say Japan
and hitting your data center in Munich.

57
00:03:07,480 --> 00:03:12,129
So there are some ways of getting around
this that has have been explored in the

58
00:03:12,149 --> 00:03:15,645
kind of application development space
slash front end development space,

59
00:03:15,905 --> 00:03:19,725
CDNs, which stand for content delivery
networks, were created to host the

60
00:03:19,734 --> 00:03:22,375
static content that is closer to users.

61
00:03:22,504 --> 00:03:28,154
So think like images, JavaScript,
fonts, all of those will be hosted

62
00:03:28,364 --> 00:03:32,595
in some local data center in Japan,
and when you load a web page, all of

63
00:03:32,595 --> 00:03:34,494
those will be able to load faster, and.

64
00:03:34,709 --> 00:03:38,280
those are typically chosen one because
there's static content, so they can be

65
00:03:38,300 --> 00:03:43,230
essentially cashed and two because they're
typically large files that would take

66
00:03:43,230 --> 00:03:45,720
a long time to deliver over a network.

67
00:03:46,660 --> 00:03:51,279
But a problem arose, this is all
well and good for websites over

68
00:03:51,290 --> 00:03:54,470
for dynamic content like code.

69
00:03:55,390 --> 00:03:58,000
Your compute, essentially,
is going to be slow.

70
00:03:58,000 --> 00:04:02,010
the actual processing of the website,
the rendering of the webpage, that

71
00:04:02,010 --> 00:04:05,420
can't all be cached because it's
essentially rerun every single time.

72
00:04:05,920 --> 00:04:11,760
a bunch of, CDN creators, like CloudFlare,
Vercel, who works a lot in the application

73
00:04:11,760 --> 00:04:15,370
space, they all got together and they
formed like a working group called

74
00:04:15,370 --> 00:04:21,065
WinterCG and they came up with this
idea around deploying Code to the edge.

75
00:04:21,225 --> 00:04:24,535
When I talk about code, I'm primarily
talking about function as a service.

76
00:04:24,835 --> 00:04:30,455
So if you're familiar with AWS Lambda,
for example, or Google Cloud Run, then

77
00:04:30,455 --> 00:04:33,105
you'll know what function as a service is.

78
00:04:33,105 --> 00:04:37,635
Essentially, it's just like an
isolated function that is spun up.

79
00:04:37,675 --> 00:04:42,685
So realistically, it'll execute some
code and then It'll be essentially put

80
00:04:42,685 --> 00:04:46,145
to sleep when it's done and another
request will come in and wake it up again.

81
00:04:47,075 --> 00:04:50,885
So these are, this code is actually
distributed at the pop layer.

82
00:04:50,895 --> 00:04:54,385
So it's essentially at the same
level that your CDN operates in.

83
00:04:54,885 --> 00:04:58,975
And what's nice about this is it provides
like a lightweight runtime that typically

84
00:04:59,035 --> 00:05:01,405
has a zero millisecond cold start.

85
00:05:01,455 --> 00:05:05,065
When I was talking earlier about latency,
one characteristic we talked about was,

86
00:05:05,065 --> 00:05:08,935
the round trip time to even get to the
data center, but if you don't have an

87
00:05:08,975 --> 00:05:15,695
active instance of your application
or like essentially a warm VPC or a

88
00:05:15,795 --> 00:05:19,895
machine, essentially, or server that
is, actively taking requests, if a new

89
00:05:19,895 --> 00:05:23,955
one needs to be like spun up to handle
some requests, that's going to take

90
00:05:23,955 --> 00:05:27,325
a lot of time, especially with how
heavy, Run times like no GS can be.

91
00:05:27,605 --> 00:05:32,185
So what's nice about edge is
that typically this run time

92
00:05:32,185 --> 00:05:34,615
is super lightweight and has
a zero millisecond cold start.

93
00:05:34,805 --> 00:05:39,285
So not only are you close to your user,
your application code will actually wake

94
00:05:39,285 --> 00:05:44,515
up and execute faster, which is good for
instant responses like APIs and web pages.

95
00:05:45,475 --> 00:05:48,145
There are some tradeoffs,
though, with most Edge runtimes.

96
00:05:48,145 --> 00:05:51,725
I'm going to go into some a little
bit later, but your bundle size, the

97
00:05:51,725 --> 00:05:55,785
languages you can use, and even the
libraries you can use are limited.

98
00:05:56,185 --> 00:06:02,435
And some examples of Edge compute
platforms include Clever Workers, as well

99
00:06:02,435 --> 00:06:04,315
as the Vercel Edge for web development.

100
00:06:04,815 --> 00:06:07,525
So now let's go into those tradeoffs
that I mentioned because the edge

101
00:06:07,525 --> 00:06:10,405
might sound good, it sounds great to
be able to run your code essentially

102
00:06:10,405 --> 00:06:13,675
as close to your customers as
possible, but it's not a silver bullet.

103
00:06:14,175 --> 00:06:15,685
So let's start with the edge runtime.

104
00:06:16,125 --> 00:06:18,975
So the edge runtime primarily
the one that I'm familiar with is

105
00:06:18,975 --> 00:06:20,725
the one developed by cloud flare.

106
00:06:21,255 --> 00:06:25,285
It's Currently limited to
JavaScript only right now with

107
00:06:25,285 --> 00:06:26,935
some support for WebAssembly.

108
00:06:27,215 --> 00:06:32,765
So if you're, someone developing an API
or application in Python or in Rust, for

109
00:06:32,765 --> 00:06:36,545
example, you're out of luck unless you
can compile that down to WebAssembly.

110
00:06:36,795 --> 00:06:42,230
Otherwise, if you're doing You know,
your basic work in like scripting

111
00:06:42,280 --> 00:06:43,960
application, but not like Node.

112
00:06:43,960 --> 00:06:47,360
js, you should be fine to run
your application at the edge.

113
00:06:47,650 --> 00:06:49,790
there is some limited support for Node.

114
00:06:49,790 --> 00:06:53,190
js libraries, but most of these
are done by hand by the Winter

115
00:06:53,190 --> 00:06:55,610
CG group, so you can't just.

116
00:06:56,170 --> 00:06:57,350
Import a Node.

117
00:06:57,350 --> 00:07:00,120
js library and expect it
to work out of the box.

118
00:07:00,320 --> 00:07:06,220
A lot of times if it, relies on like
TCP or other networking APIs that Node.

119
00:07:06,220 --> 00:07:08,770
js exposes, it probably won't work.

120
00:07:09,170 --> 00:07:11,510
And there's also limits on
the maximum bundle size.

121
00:07:11,510 --> 00:07:14,460
I think It's something like 100
megabytes or 10 megabytes can

122
00:07:14,460 --> 00:07:15,430
remember off the top of my head.

123
00:07:15,430 --> 00:07:17,510
It depends on the platform
you're executing on and it

124
00:07:17,510 --> 00:07:19,000
always changes over time.

125
00:07:19,230 --> 00:07:22,910
But yeah, you can't have a massive
application running on this function

126
00:07:22,920 --> 00:07:27,140
as a service, which is similar to
existing fast applications like Lambda.

127
00:07:27,640 --> 00:07:30,030
I will say, though, that things
are getting a little bit better.

128
00:07:30,070 --> 00:07:33,240
There are many libraries out there
that now have support, or they have,

129
00:07:33,240 --> 00:07:37,400
essentially, an edge version of their
library that doesn't rely on Node.

130
00:07:37,420 --> 00:07:38,570
js primitives.

131
00:07:38,570 --> 00:07:43,900
And any library that's built to run in
the browser for JavaScript can typically

132
00:07:43,900 --> 00:07:45,660
be executed at the edge as well.

133
00:07:45,860 --> 00:07:50,070
Because the edge is essentially a
version of the V8 runtime that's

134
00:07:50,070 --> 00:07:52,600
used in your browser, which is
why it's so fast and lightweight.

135
00:07:53,100 --> 00:07:58,230
So aside from complications with
the runtime, a big factor on why or

136
00:07:58,250 --> 00:08:02,450
whether or not you should use the
edge is where your data is located.

137
00:08:02,900 --> 00:08:07,150
So your compute may be globally
distributed, which is super nice,

138
00:08:07,220 --> 00:08:10,730
but your database and or data store,
wherever you're storing your data

139
00:08:10,940 --> 00:08:12,920
is often not globally distributed.

140
00:08:13,540 --> 00:08:15,770
And this results in actually.

141
00:08:15,990 --> 00:08:20,430
pretty poor latency characteristic
when you're doing something like a crud

142
00:08:20,450 --> 00:08:24,900
operation because you have to account
for not just the time to access your

143
00:08:24,900 --> 00:08:29,160
function, but the round trip time from
like your edge location to your database

144
00:08:29,310 --> 00:08:33,030
and then back from your database to
your edge function, which can often

145
00:08:33,030 --> 00:08:37,842
lead to worse response times than if
you just Co located your function and

146
00:08:37,842 --> 00:08:40,532
your database in a single data center.

147
00:08:40,862 --> 00:08:46,342
It depends where the call is coming from,
but this is often the case due to routing.

148
00:08:46,842 --> 00:08:50,102
You can also end up exhausting
connections to your database as well.

149
00:08:50,112 --> 00:08:53,242
You can imagine, if you have users all
around the world, they're all invoking

150
00:08:53,622 --> 00:08:54,922
all these different edge functions.

151
00:08:55,092 --> 00:08:56,932
If you're doing something like
connection pooling, you can

152
00:08:56,932 --> 00:09:01,322
probably easily exceed the number of
connections that your database allows.

153
00:09:01,342 --> 00:09:01,732
And.

154
00:09:02,487 --> 00:09:04,317
you might just end up stuck or locked out.

155
00:09:04,317 --> 00:09:06,607
And again, this leads to worse latency.

156
00:09:07,427 --> 00:09:11,167
I'd like to mention that there
are answers to all of these kind

157
00:09:11,167 --> 00:09:13,547
of issues, and I'm going to start
covering some of them right now.

158
00:09:14,527 --> 00:09:18,277
So this is an image that indicates,
demonstrates what I'm talking about.

159
00:09:18,277 --> 00:09:21,837
You have this central function in
the middle here that's really nice.

160
00:09:21,837 --> 00:09:24,407
But then, you have your
functions over here and you're

161
00:09:24,417 --> 00:09:25,867
trying to return data to users.

162
00:09:26,027 --> 00:09:28,937
And it's just a long trip from your
function to your server over here

163
00:09:28,937 --> 00:09:30,957
and then back through your database.

164
00:09:31,457 --> 00:09:35,207
the easiest to adopt way to
mitigate this problem is to

165
00:09:35,207 --> 00:09:38,027
introduce a database proxy database.

166
00:09:38,027 --> 00:09:43,597
A proxy is essentially a kind of layer
that will be like a gateway, to your

167
00:09:43,597 --> 00:09:47,807
database, where the functions as a
service or edge functions will connect

168
00:09:47,807 --> 00:09:50,147
to it instead of database directly.

169
00:09:50,357 --> 00:09:54,137
And then this database proxy will
field all of these connections and

170
00:09:54,137 --> 00:09:58,547
maintain its own pool of connections
to connect to the database.

171
00:09:58,557 --> 00:10:02,387
So it won't exhaust the
connections to your database.

172
00:10:02,407 --> 00:10:05,227
And you end up with crashing on
your Postgres or anything like that.

173
00:10:05,457 --> 00:10:08,597
So there are solution managed solutions
out there like Prisma Accelerate.

174
00:10:08,807 --> 00:10:13,387
I think AWS has something
called like RDS proxy as well.

175
00:10:13,557 --> 00:10:16,537
And, this is like an easy solution
is you don't have to change anything

176
00:10:16,537 --> 00:10:18,247
about like your database configuration.

177
00:10:18,457 --> 00:10:22,107
From my understanding, you can just simply
start connecting to a proxy instead,

178
00:10:22,367 --> 00:10:25,827
and it'll manage all the connections
from your edge functions automatically.

179
00:10:26,327 --> 00:10:28,507
yeah, so like I mentioned, this is
good if you're like transitioning

180
00:10:28,507 --> 00:10:32,317
from an existing database, and
you can also introduce caching at

181
00:10:32,347 --> 00:10:34,557
the database proxy layer as well.

182
00:10:34,677 --> 00:10:38,037
Rather than, using one of the
connection pools, if you if your

183
00:10:38,037 --> 00:10:41,757
query is something that is cash,
then it could return it directly.

184
00:10:41,757 --> 00:10:45,007
And that's the best case possible
is if your data is stored

185
00:10:45,007 --> 00:10:46,117
somewhere close to your function.

186
00:10:46,617 --> 00:10:50,877
There is another solution out there, which
is essentially having a global data store.

187
00:10:51,087 --> 00:10:55,727
So that would be like distributing your
database across multiple regions, which

188
00:10:55,727 --> 00:10:59,647
is very common in high scale systems,
I'd say, in order to minimize latency,

189
00:10:59,807 --> 00:11:01,197
whether you're using the edge or not.

190
00:11:01,487 --> 00:11:05,127
So you can use a specialized type of
database like Cassandra or CockroachDB,

191
00:11:05,627 --> 00:11:09,407
which can be placed closer to your edge
function, not exactly in the same place.

192
00:11:09,857 --> 00:11:10,337
Layer.

193
00:11:10,647 --> 00:11:14,787
you can imagine you have a database for
Japan and then you have edge locations in

194
00:11:14,797 --> 00:11:17,787
Tokyo and Osaka that will connect to that.

195
00:11:17,807 --> 00:11:21,877
And it's going to be a lot less
of a round trip time to get there.

196
00:11:22,377 --> 00:11:24,497
The trade off here is
going to be primarily with.

197
00:11:24,717 --> 00:11:27,067
consistency, depending on
how you do your writes.

198
00:11:27,227 --> 00:11:30,327
So if you're doing like asynchronous
writes, and this is just like a read

199
00:11:30,327 --> 00:11:35,297
replica that you placed in Japan, you
can potentially have stale data because

200
00:11:35,297 --> 00:11:38,897
it's going to take time for the writes
that happened in, let's say, Munich, to

201
00:11:38,937 --> 00:11:41,347
propagate to your read replica in Japan.

202
00:11:41,757 --> 00:11:42,947
if you do them asynchronously.

203
00:11:43,217 --> 00:11:45,127
Or, you can have issues with latency.

204
00:11:45,947 --> 00:11:47,437
If you're doing synchronous, right?

205
00:11:47,447 --> 00:11:52,487
So if you hold on to your database
and your replica and lock it while

206
00:11:52,487 --> 00:11:56,157
you're performing rights, then you
can have slow reads because of that

207
00:11:56,157 --> 00:11:59,927
database replica might be locked
while you're serving API calls.

208
00:12:00,827 --> 00:12:04,817
So there are definitely tradeoffs here,
but typically this can result in better

209
00:12:04,817 --> 00:12:06,357
performance and kind of solves the issue.

210
00:12:06,857 --> 00:12:09,427
just like a basic image of you have
your main data store somewhere in

211
00:12:09,437 --> 00:12:14,377
North America distributed and Europe
and Africa and all over the world.

212
00:12:14,877 --> 00:12:18,297
There's a third solution, which is
a little bit less common, I'd say,

213
00:12:18,317 --> 00:12:20,087
but it's becoming more popular.

214
00:12:20,277 --> 00:12:24,217
And that's the idea that you
know, your data should live where

215
00:12:24,227 --> 00:12:27,127
it needs to live, where it would
provide the best user experience.

216
00:12:27,377 --> 00:12:33,047
So in some cases, you can have data that
is hosted or cached at the edge itself.

217
00:12:33,247 --> 00:12:35,027
And there are different
kind of use cases here.

218
00:12:35,317 --> 00:12:38,612
So say you want to do some
sort of like blob storage,

219
00:12:38,782 --> 00:12:40,122
some sort of like cash, right?

220
00:12:40,372 --> 00:12:44,372
you can use a solution like Cloudflare's
R2, which is essentially an edge

221
00:12:44,372 --> 00:12:46,402
distributed, edge, blob store.

222
00:12:46,642 --> 00:12:50,607
if you want to do Database transactions
and want to have something like a per

223
00:12:50,607 --> 00:12:53,287
user database or per instance database.

224
00:12:53,657 --> 00:12:57,367
Maybe you want to have a database
that's specific to like a region for

225
00:12:57,407 --> 00:12:59,357
GDPR compliance or something like that.

226
00:12:59,577 --> 00:13:05,147
Then you can use D1 from Cloudflare
or Upstash to have an edge distributed

227
00:13:05,157 --> 00:13:09,627
SQLite database that lives very close to
users and is locked to a certain region.

228
00:13:10,572 --> 00:13:14,702
Lastly, if you want to do something
like, key value store, Redis and

229
00:13:14,702 --> 00:13:18,122
Vercel both provide solutions for
their for like key value store, which

230
00:13:18,122 --> 00:13:21,452
is, good for like configurations,
for example, that you don't want to

231
00:13:21,452 --> 00:13:24,172
travel to a central location for.

232
00:13:24,877 --> 00:13:28,587
But again, there are going to be that
kind of trade off of consistency.

233
00:13:28,587 --> 00:13:35,437
So this is ideal for configurations or
data that doesn't get updated very often

234
00:13:35,667 --> 00:13:40,337
or doesn't need to be like replicated, So
this is a happy path where each kind of

235
00:13:40,337 --> 00:13:45,027
instance has its own database over here
and everyone lives happily ever after.

236
00:13:45,527 --> 00:13:51,167
So that's a basic idea of the tradeoffs
of deploying an application to the edge.

237
00:13:51,367 --> 00:13:56,187
But why should you deploy your API to the
edge or parts of your API to the edge?

238
00:13:56,687 --> 00:13:59,807
when it comes to APIs these
days, especially public APIs, I

239
00:13:59,807 --> 00:14:01,507
think performance matters a lot.

240
00:14:02,077 --> 00:14:04,677
Your public API users can be anywhere.

241
00:14:04,867 --> 00:14:07,907
And, this is by nature of
you actually have no control

242
00:14:07,917 --> 00:14:09,227
over what your customers do.

243
00:14:09,457 --> 00:14:13,247
Once give them like an API key, they can
deploy, their application, which uses your

244
00:14:13,247 --> 00:14:18,887
API anywhere, whether your API customers
in Japan or China or in Africa, you don't

245
00:14:18,887 --> 00:14:21,577
know where their customer is going to
be, but you're going to have to serve

246
00:14:21,577 --> 00:14:23,267
all that traffic all the same, right?

247
00:14:23,537 --> 00:14:26,857
And if you don't have good performance
characteristics in a certain region,

248
00:14:27,287 --> 00:14:29,937
that can be like lost customers
for your company, for example.

249
00:14:30,782 --> 00:14:35,062
and another thing that is nice
about APIs, I'd say, is how

250
00:14:35,062 --> 00:14:36,852
compute heavy they can often be.

251
00:14:37,052 --> 00:14:42,642
So I'd say like a lot of work done by
APIs is often just filtering out calls.

252
00:14:42,892 --> 00:14:46,352
So that's, and I'll get to some
examples later, but like a lot of

253
00:14:46,372 --> 00:14:49,832
time spent within an API, besides like
the actual like CRUD and like data

254
00:14:50,092 --> 00:14:52,232
portion of it, is just like compute.

255
00:14:52,462 --> 00:14:56,002
If you're doing a lot of compute based
work, that's good to actually move that

256
00:14:56,042 --> 00:14:58,692
portion of your A P I code to the edge.

257
00:14:59,192 --> 00:15:03,022
So to give you like an example of
the tail of two calls over here

258
00:15:03,242 --> 00:15:05,282
on the left, we have an example.

259
00:15:05,282 --> 00:15:08,412
If you're doing like a single region
where you know your data centers

260
00:15:08,412 --> 00:15:12,792
history in Dallas, Texas and your A P
I calls coming in from Japan, you have

261
00:15:12,792 --> 00:15:15,587
some customer over there essentially
just to do something like Yeah.

262
00:15:15,727 --> 00:15:17,767
Authentication even if
you're denying the request.

263
00:15:17,767 --> 00:15:19,207
Let's say they forgot their API key.

264
00:15:19,397 --> 00:15:23,417
You have to travel all the way from
Japan over to Texas over here to do

265
00:15:23,417 --> 00:15:27,117
your off handshake and then you travel
all the way back just to say 401.

266
00:15:27,757 --> 00:15:28,867
It's not a very good experience.

267
00:15:29,562 --> 00:15:33,492
Versus over here when you deploy to earth
or that's commonly known as like how

268
00:15:33,492 --> 00:15:36,772
to deploy to the edges to point earth
because you deploy globally typically,

269
00:15:37,152 --> 00:15:40,952
you essentially can have this edge
based proxy in front that can do stuff

270
00:15:40,952 --> 00:15:45,962
like authentication, authorization, a
lot of again, the compute based stuff

271
00:15:45,992 --> 00:15:50,182
that can result in like quick returns
of responses in case of invalid data

272
00:15:50,182 --> 00:15:52,022
or invalid, like tokens are sent over.

273
00:15:52,522 --> 00:15:55,822
So examples of work that can be done
at the edge that's compute heavy,

274
00:15:56,022 --> 00:16:00,242
authentication and authorization unless
you, if you're, especially if you're

275
00:16:00,262 --> 00:16:04,852
in housing this through something like
API keys, or, anything basically other

276
00:16:04,852 --> 00:16:08,582
than using like a, like an identity
provider, if you're doing it, Yourself

277
00:16:08,592 --> 00:16:12,692
or you're writing the code yourself
doing it at the edge is a lot faster.

278
00:16:12,702 --> 00:16:17,072
You can respond with that for a wine or
403 so much faster compared to having

279
00:16:17,072 --> 00:16:19,282
to travel all the way across continents.

280
00:16:19,812 --> 00:16:21,812
If you're doing logging and
monitoring within your API,

281
00:16:22,442 --> 00:16:24,082
doing that within the edge is.

282
00:16:24,437 --> 00:16:25,627
Again, going to be faster.

283
00:16:25,857 --> 00:16:27,347
it's just code being executed.

284
00:16:27,547 --> 00:16:30,177
Request validation again is something
that's going to be a lot faster.

285
00:16:30,687 --> 00:16:35,167
You can use libraries like AJV, for
example, or Zod at the edge, and

286
00:16:35,177 --> 00:16:38,587
you can do schema validation of like
request body and filter out like that

287
00:16:38,587 --> 00:16:43,127
request or SQL injections or any kind
of like bad stuff that like a WAF

288
00:16:43,127 --> 00:16:45,527
would catch web application firewall.

289
00:16:45,657 --> 00:16:50,127
so Bot filtering or bad actor filtering
or even filtering out agents these days.

290
00:16:50,327 --> 00:16:52,587
you can do that all at the edge
as well, because that's all just

291
00:16:52,587 --> 00:16:54,537
like computations being run.

292
00:16:55,257 --> 00:16:59,617
More interesting to be done at the
edge is rate limiting, for example.

293
00:16:59,717 --> 00:17:03,287
So rate limiting at the edge
will actually have a win effect.

294
00:17:03,567 --> 00:17:07,547
The win, I'd say, is that since you're
doing it, since you're filtering

295
00:17:07,547 --> 00:17:10,927
out at the edge, it doesn't make
it to your central service at all.

296
00:17:11,217 --> 00:17:15,447
so wherever you're, Your actual like API
and microservices are hosted and that

297
00:17:15,607 --> 00:17:19,297
reduces the number of requests going to
them, which frees them up for with more

298
00:17:19,297 --> 00:17:21,477
resources to actual handle legit requests.

299
00:17:21,667 --> 00:17:24,667
So you might actually end up with
like better latency by introducing

300
00:17:24,747 --> 00:17:26,257
rate limiting for your customers.

301
00:17:27,142 --> 00:17:30,212
And you also filter out, like
DDoS attacks and stuff like that.

302
00:17:31,152 --> 00:17:33,602
The last one I want to mention
that is really good to be

303
00:17:33,602 --> 00:17:34,892
done at the edge is caching.

304
00:17:35,172 --> 00:17:39,732
So if your API is amenable to caching,
so let's say it's like a basic like trud,

305
00:17:40,242 --> 00:17:44,242
that first call may take like a while
depending on where your data store is,

306
00:17:44,432 --> 00:17:49,172
but subsequent calls to that Same API will
have like very good performance because

307
00:17:49,362 --> 00:17:51,232
essentially it's stored at the CDN layer.

308
00:17:51,372 --> 00:17:52,072
It's cash.

309
00:17:52,082 --> 00:17:54,782
your user in Japan doesn't need
to, the request doesn't need to

310
00:17:54,782 --> 00:17:56,362
leave Osaka to get like data.

311
00:17:56,362 --> 00:18:00,192
So like refreshing a webpage, will
be very quick or navigating back to

312
00:18:00,192 --> 00:18:01,922
a webpage that you previously loaded.

313
00:18:02,422 --> 00:18:06,372
So I'd say like my ideal setup and
the one that I advocate for when

314
00:18:06,372 --> 00:18:10,442
it comes to running APIs at the
edge is as follows, essentially.

315
00:18:10,622 --> 00:18:14,302
You run all of those functionality
that I mentioned earlier at the edge,

316
00:18:14,512 --> 00:18:17,802
and in that case, that should be done
probably at the API gateway layer.

317
00:18:18,012 --> 00:18:21,262
So you should have, an API gateway
that can run at the edge, and that's

318
00:18:21,262 --> 00:18:24,632
what I work on at Zuplo, actually, is
developing an API gateway that can run

319
00:18:24,632 --> 00:18:29,622
at the edge, whereas your microservices
that actually, serve your API traffic

320
00:18:29,812 --> 00:18:33,782
are hosted somewhere close to where
your data store is, and ideally

321
00:18:33,812 --> 00:18:35,662
replicated across multiple regions.

322
00:18:35,892 --> 00:18:40,632
So you would have, a read replica of
your database, as well as a kind of

323
00:18:40,632 --> 00:18:44,982
like function as a service or Lambda of
your actual microservice hosted, one in

324
00:18:44,982 --> 00:18:50,812
the US, one in Japan, one in Germany,
and you would have these, your gateway

325
00:18:50,812 --> 00:18:57,707
distributed to specific cities like Munich
and in, I don't know, London and London.

326
00:18:58,027 --> 00:19:01,307
Maybe the west coast of the U. S. And
the east coast of the U. S. you can do

327
00:19:01,307 --> 00:19:05,367
a lot of that filtering at the edge,
but the computer is actually done within

328
00:19:05,367 --> 00:19:07,137
some central server close to your data.

329
00:19:07,137 --> 00:19:10,917
So you can minimize latency on this
kind of gives you a lot of freedom, too.

330
00:19:10,917 --> 00:19:14,517
So you're not limited by having your
microservices be bound by like the

331
00:19:14,517 --> 00:19:16,027
restrictions of the edge runtime.

332
00:19:16,217 --> 00:19:19,257
You can write your code in like Django
or Python or whatever you want to do.

333
00:19:19,467 --> 00:19:20,057
That's fine.

334
00:19:20,277 --> 00:19:22,647
It's just that the gateway
layer would be written in like

335
00:19:22,727 --> 00:19:24,387
JavaScript, essentially, or wasm.

336
00:19:24,387 --> 00:19:29,042
And, Yeah, this is probably
like the ideal scenario.

337
00:19:29,302 --> 00:19:34,122
I wouldn't say many companies run this way
yet, it's becoming, I'd say, increasingly

338
00:19:34,122 --> 00:19:38,802
popular as APIs become like a product more
than just like an infrastructure piece.

339
00:19:38,822 --> 00:19:42,512
And, a company like Scribe, for
example, that sells their API and runs

340
00:19:42,512 --> 00:19:45,942
at a huge scale probably wants to,
pursue a solution similar to this.

341
00:19:46,442 --> 00:19:47,692
as I promised at the beginning.

342
00:19:48,182 --> 00:19:51,622
early in the talk, I'm going to give
you a quick demo of an edge API that

343
00:19:51,622 --> 00:19:56,282
I built when I talk about an edge API,
essentially, I tried to have as much as

344
00:19:56,282 --> 00:20:02,652
the code and the data live as close to me
as possible where my local data center is.

345
00:20:03,152 --> 00:20:06,962
The application I decided to build here
is an ATM locator, so if you ever use

346
00:20:06,962 --> 00:20:11,142
like a banking app, trying to find like
an ATM nearby, and you didn't use Google

347
00:20:11,142 --> 00:20:13,992
Maps for some reason, I don't know why
you wouldn't, but, this is in every

348
00:20:13,992 --> 00:20:18,822
banking app I'm aware of, essentially you
find all of the local, ATMs of Capital

349
00:20:18,832 --> 00:20:23,002
One, let's say, nearby, and, what's nice
about this and like why I decided to

350
00:20:23,012 --> 00:20:25,262
build this at the edge, a few things.

351
00:20:25,382 --> 00:20:28,919
One, ATM locations, essentially,
essentially, They can be like

352
00:20:28,919 --> 00:20:34,339
replicated in store at the edge
because, one like location of ATMs are

353
00:20:34,469 --> 00:20:37,829
specific to a specific like region,
like you're not going to look at,

354
00:20:38,099 --> 00:20:41,799
ATMs in London when you live in New
York, that just wouldn't make sense.

355
00:20:41,929 --> 00:20:44,119
there's no reason why like
your data needs to be like.

356
00:20:44,369 --> 00:20:48,969
totally replicated, for every single
user, and it's also really written

357
00:20:48,969 --> 00:20:50,269
to like it takes a long time.

358
00:20:50,269 --> 00:20:51,939
I assumed to install an ATM.

359
00:20:51,949 --> 00:20:56,029
So the API or like the data store
for writing to a specific regions

360
00:20:56,079 --> 00:20:59,989
ATM list probably doesn't happen very
often unless you have something like

361
00:21:00,179 --> 00:21:03,569
I don't know, like downtime monitoring
or something like that of your ATMs.

362
00:21:03,589 --> 00:21:06,639
But again, I'd say like the
number of right query is going

363
00:21:06,639 --> 00:21:07,769
to this is going to be very low.

364
00:21:08,269 --> 00:21:11,339
I also think that the performance of
this API is going to matter a lot.

365
00:21:11,509 --> 00:21:15,029
Someone's probably, looking around,
probably needs cash quickly for settling

366
00:21:15,029 --> 00:21:18,399
up like at the bar or they forgot their
credit card at home, but they have like

367
00:21:18,399 --> 00:21:22,259
their debit card for some reason, and
they just want to find an ATM quickly.

368
00:21:22,409 --> 00:21:24,519
they want to open up the app,
be able to find the closest

369
00:21:24,519 --> 00:21:26,889
ATM super fast, navigate there.

370
00:21:27,389 --> 00:21:30,999
In your instant time, essentially,
and another good thing about this, I'd

371
00:21:30,999 --> 00:21:34,179
say, carrying off like the previous
point is that you can cash these

372
00:21:34,179 --> 00:21:39,159
results super easily since again, it's
like very local and rarely updated.

373
00:21:39,159 --> 00:21:42,349
So you can have a long lived
cash for best performance.

374
00:21:42,849 --> 00:21:45,769
In terms of the data set I'm going to
use to build this API, I'm going to

375
00:21:45,769 --> 00:21:50,119
use Capital One's Nessie Hackathon API,
which is essentially just a virtual bank.

376
00:21:50,399 --> 00:21:52,809
it's like a subset of their
data, of their banking data,

377
00:21:52,819 --> 00:21:55,019
including stuff like ATM locations.

378
00:21:55,399 --> 00:21:57,949
And, one thing I'll mention is
that their API performance is

379
00:21:57,949 --> 00:21:59,319
actually already really good.

380
00:21:59,519 --> 00:22:02,319
The reason why I choose, chose
Capital One actually is because

381
00:22:02,509 --> 00:22:05,269
I know they're a company that's
already adopted serverless and edge

382
00:22:05,269 --> 00:22:07,539
functions for their APIs at scale.

383
00:22:07,759 --> 00:22:10,039
And I'm just going to quickly
show you what that looks like.

384
00:22:11,029 --> 00:22:13,799
Essentially, if you fire a request
against, their API, they can

385
00:22:13,799 --> 00:22:15,264
return, something like 10 results.

386
00:22:15,574 --> 00:22:19,124
They paginate it, but they return,
10 results in, 100 milliseconds,

387
00:22:19,134 --> 00:22:22,884
which is pretty fast, given that, I
don't know exactly what this data is.

388
00:22:23,104 --> 00:22:26,024
I'm just going to quickly Exit
out of my slides over here.

389
00:22:26,234 --> 00:22:29,214
I'm going to pop over to
the Capital One website.

390
00:22:29,424 --> 00:22:34,224
I'm going to call their API for ATMs
over here, and all you do is you can

391
00:22:34,224 --> 00:22:38,284
put like a latitude and longitude
and then a radius in miles, and

392
00:22:38,284 --> 00:22:41,394
then you just click try it out.

393
00:22:42,114 --> 00:22:46,204
And on the right over here, it's going
to be a little bit hard for you to see,

394
00:22:46,574 --> 00:22:52,014
but let me zoom in a little bit and pop
this open and you can see the response

395
00:22:52,014 --> 00:22:55,494
we got back was within 171 milliseconds.

396
00:22:55,494 --> 00:22:58,164
And probably if you click it a
few more times, it's even faster.

397
00:22:58,174 --> 00:22:58,584
There we go.

398
00:22:58,584 --> 00:23:01,204
Within 89 over there.

399
00:23:01,344 --> 00:23:02,594
So that's a pretty fast API.

400
00:23:02,594 --> 00:23:07,044
I'd say, this is like sub 100 milliseconds
average case, except the first one.

401
00:23:07,044 --> 00:23:08,334
Probably that was the cold start.

402
00:23:08,534 --> 00:23:10,694
That was talking about earlier,
there is probably a server that's.

403
00:23:10,794 --> 00:23:14,444
like a sleep, up there, or maybe the
data store was just like further away.

404
00:23:14,444 --> 00:23:16,804
And there, this is with caching over here.

405
00:23:16,814 --> 00:23:20,364
So overall for, a hackathon API
that probably uses some production

406
00:23:20,364 --> 00:23:21,914
infrastructure, this is pretty good.

407
00:23:22,414 --> 00:23:22,794
Okay.

408
00:23:22,954 --> 00:23:26,524
So now I'm going to try and
build my own version of this API.

409
00:23:27,134 --> 00:23:30,424
I scrape the data set off of capital
one to get all of the list of ATMs,

410
00:23:31,064 --> 00:23:32,484
and I'm going to build my own.

411
00:23:32,984 --> 00:23:37,424
API locator, or sorry,
ATM locator at the edge.

412
00:23:37,694 --> 00:23:39,494
So what's that going to consist of?

413
00:23:39,754 --> 00:23:42,294
that's going to consist of the following.

414
00:23:42,304 --> 00:23:46,214
We're going to have a simple Brazil
website that's hosted by, it's in Next.

415
00:23:46,214 --> 00:23:49,394
js, hosted by Brazil, wherever
it's going to end up hosted,

416
00:23:49,424 --> 00:23:50,844
probably somewhere in the U. S.

417
00:23:51,214 --> 00:23:53,704
And that's going to call an API.

418
00:23:54,204 --> 00:23:56,564
that I've set up and that
API consists of two parts.

419
00:23:56,774 --> 00:23:59,064
It's going to consist of an edge
cache, which is going to cache

420
00:23:59,064 --> 00:24:00,884
the results for me at the edge.

421
00:24:00,924 --> 00:24:03,924
But before it does that and on the
initial call, it's going to invoke

422
00:24:03,924 --> 00:24:07,524
essentially a simple edge function
that is connected to an API route.

423
00:24:07,604 --> 00:24:09,444
This is done through Zooplo.

424
00:24:09,774 --> 00:24:13,124
And then I need some
data to host the, ATMs.

425
00:24:13,304 --> 00:24:16,414
So I have a D1 database over here.

426
00:24:16,424 --> 00:24:19,334
That's the one I mentioned
earlier that Cloudflare produces.

427
00:24:19,334 --> 00:24:25,834
That essentially is like a just highly
replicatable, distributed SQLite fork.

428
00:24:26,334 --> 00:24:27,674
that's basically the gist of it.

429
00:24:27,734 --> 00:24:30,574
you can read over this in case
any of that didn't make sense.

430
00:24:30,814 --> 00:24:35,104
But, in the best case, I'd say is
that, Purcell just, Places the instance

431
00:24:35,104 --> 00:24:36,664
of the website somewhere close by.

432
00:24:36,864 --> 00:24:41,434
Zuplo finds an edge location that's
also close by, to perform the function.

433
00:24:41,604 --> 00:24:47,714
And then, ideally, D1 finds a place to
put the SQLite database, also close by,

434
00:24:47,714 --> 00:24:49,124
somewhere close by to those functions.

435
00:24:49,174 --> 00:24:52,074
ideally, all three of these are close to
each other, and we have very low latency.

436
00:24:52,414 --> 00:24:53,854
let's jump into it.

437
00:24:53,864 --> 00:24:55,964
I have the sample over here.

438
00:24:56,489 --> 00:24:59,319
This is my edge API locator.

439
00:24:59,319 --> 00:25:01,309
I'm going to refresh it to
prove to you that it's real.

440
00:25:01,529 --> 00:25:05,039
I have a demo location here
in McLean, Virginia, USA.

441
00:25:05,039 --> 00:25:06,679
That's just where the dataset is.

442
00:25:06,959 --> 00:25:10,559
And I'm going to search
for ATMs within five miles.

443
00:25:11,044 --> 00:25:13,474
Just the same thing is like the
Nessie example that I showed

444
00:25:13,474 --> 00:25:15,344
you earlier, and there you go.

445
00:25:15,344 --> 00:25:17,044
We have some examples over here.

446
00:25:17,054 --> 00:25:20,014
These are some of the
closest ATMs is able to find.

447
00:25:20,024 --> 00:25:22,724
I guess there aren't that many
in McLean, Virginia there.

448
00:25:22,974 --> 00:25:25,944
There are a few times over in Arlington,
but one thing you'll notice that

449
00:25:25,944 --> 00:25:27,334
actually took quite a bit of time.

450
00:25:27,834 --> 00:25:32,544
If you ever over here, I think they'll
tell you it took about, let's see.

451
00:25:33,039 --> 00:25:33,989
That took about 1.

452
00:25:34,029 --> 00:25:36,019
34 seconds, to get the results.

453
00:25:36,019 --> 00:25:38,809
That's actually a lot slower
than what Capital One took.

454
00:25:38,819 --> 00:25:42,399
If you remember, Capital One took,
essentially 90 percent less time,

455
00:25:42,399 --> 00:25:44,619
about 134, milliseconds to get results.

456
00:25:44,629 --> 00:25:45,819
why was that so slow?

457
00:25:46,319 --> 00:25:49,119
Let's pop over back to the slides,
and we can start debugging things.

458
00:25:50,069 --> 00:25:53,589
So in any, function as a service, there's
going to be some sort of slowness.

459
00:25:53,799 --> 00:25:57,269
so we should try and debug it and try
to rule out what could be going on.

460
00:25:57,569 --> 00:26:00,749
the initial call, like I showed
you, took between, 1, 000 and 2, 000

461
00:26:00,749 --> 00:26:05,109
milliseconds, which is obviously too slow
for any, user, especially when I just

462
00:26:05,119 --> 00:26:06,889
said we were prioritizing performance.

463
00:26:07,169 --> 00:26:09,339
so here are some reasons
of what might be happening.

464
00:26:09,739 --> 00:26:13,639
So the first one is that, D
one itself could be slow at

465
00:26:13,639 --> 00:26:15,109
executing queries like this.

466
00:26:15,619 --> 00:26:18,319
The sequel query is essentially
just like a between queries where

467
00:26:18,549 --> 00:26:22,599
I have all these like latitude and
longitudes set up and have to find

468
00:26:22,599 --> 00:26:26,439
like a all the results between these
two sets of latitudes and longitudes.

469
00:26:26,729 --> 00:26:28,049
And, we can have a lot of data.

470
00:26:28,049 --> 00:26:29,869
I think there's like
several hundred ATMs here.

471
00:26:30,109 --> 00:26:33,299
that shouldn't be too much for, a typical
database, but I don't know how fast D1 is.

472
00:26:33,639 --> 00:26:37,319
but, yeah, there are different ways of
debugging database slowness, for example.

473
00:26:37,539 --> 00:26:40,859
And, probably introducing an index
based on longitude and latitude would

474
00:26:40,869 --> 00:26:44,289
be the way to resolve that, if the
query is what's taking a long time.

475
00:26:45,209 --> 00:26:50,874
their most likely suspect, I'd say,
is that D1 was simply placed on

476
00:26:50,874 --> 00:26:52,604
an instance that's too far away.

477
00:26:52,914 --> 00:26:56,374
and this is typically because
Cloudflare will only assign you a,

478
00:26:56,424 --> 00:27:00,184
high value, high performance database
instance if you're sending, high

479
00:27:00,184 --> 00:27:01,924
volumes of traffic, essentially.

480
00:27:02,094 --> 00:27:05,494
So this is actually, this is not
very good for hobbyists that I say,

481
00:27:05,494 --> 00:27:08,884
and, if I knew D1 did this before I
started building this demo, I probably

482
00:27:08,884 --> 00:27:11,134
wouldn't have used, D1, but here we are.

483
00:27:11,324 --> 00:27:12,454
the best way to get around this.

484
00:27:12,859 --> 00:27:15,559
is probably the cache results at the edge.

485
00:27:15,559 --> 00:27:18,909
So you have to make that round
trip as few times as possible.

486
00:27:19,409 --> 00:27:23,129
The last thing to rule out, I'd
say, is API gateway latency.

487
00:27:23,359 --> 00:27:26,529
that would be like, latency introduced
by the function as a service from,

488
00:27:26,539 --> 00:27:28,239
Zuplo and compute that's being done.

489
00:27:28,449 --> 00:27:30,899
And even just the routing
of, that API endpoint.

490
00:27:31,139 --> 00:27:33,769
and probably, if, if that's the issue
over there, you should probably move to

491
00:27:33,769 --> 00:27:36,009
another platform or move off the edge.

492
00:27:36,059 --> 00:27:37,109
there's clearly something wrong.

493
00:27:37,129 --> 00:27:40,149
Maybe you're, maybe you should just use
a different language than JavaScript.

494
00:27:40,149 --> 00:27:41,369
I don't know what's going on there.

495
00:27:41,709 --> 00:27:43,449
Let's, pop over here.

496
00:27:43,469 --> 00:27:45,899
I've performed these kind of
tests already, just in case that

497
00:27:46,139 --> 00:27:49,459
the demo didn't work and didn't
want to didn't want to bore you.

498
00:27:49,659 --> 00:27:54,679
But essentially what I did is I made
a call to Cloudflare's API directly.

499
00:27:54,869 --> 00:27:57,559
This API is essentially allows
you to access your database

500
00:27:57,559 --> 00:27:58,779
for like reads and writes and.

501
00:27:58,959 --> 00:28:00,679
Whatever types of queries
you want to perform.

502
00:28:00,889 --> 00:28:03,119
this is my SQL query over here.

503
00:28:03,309 --> 00:28:07,029
essentially I'm just selecting
star from my ATM list where

504
00:28:07,029 --> 00:28:11,019
latitude is between two values and
longitude is between two values.

505
00:28:11,019 --> 00:28:15,049
And I'm limiting down to ten results so
I can match what was done by capital one.

506
00:28:15,719 --> 00:28:18,629
And here are my parameters, that's
my latitudes and longitudes.

507
00:28:18,829 --> 00:28:21,679
don't worry about how I computed this,
there's a, there's something called like

508
00:28:21,679 --> 00:28:25,939
the Habersine, algorithm to determine
latitudes and longitudes between two

509
00:28:25,939 --> 00:28:27,909
points that are within a certain radius.

510
00:28:28,279 --> 00:28:29,149
just don't worry about it.

511
00:28:29,379 --> 00:28:32,079
But, what you should worry about,
I'd say, is these numbers in greens.

512
00:28:32,304 --> 00:28:33,104
Green over here.

513
00:28:33,274 --> 00:28:36,504
You can see the result size is not like
too large, just a few kilobytes, right?

514
00:28:37,004 --> 00:28:37,724
The things to look at.

515
00:28:37,734 --> 00:28:42,724
One, that query to Cloudflare itself,
so that's excluding the API gateway

516
00:28:42,724 --> 00:28:43,984
or whatever latency it brings.

517
00:28:44,354 --> 00:28:49,754
That took alone 830 milliseconds,
which is most of the time of our call.

518
00:28:49,954 --> 00:28:51,114
I've run this a few times.

519
00:28:51,114 --> 00:28:51,799
It can take up to 1.

520
00:28:51,799 --> 00:28:54,414
2, 1. 3 seconds, for example.

521
00:28:54,424 --> 00:28:57,114
So this is like the bulk
of our duration over here.

522
00:28:57,114 --> 00:28:58,384
It's just the network request.

523
00:28:58,644 --> 00:29:00,984
And if we were to look at What
the component of that network

524
00:29:01,004 --> 00:29:05,734
request is it purely like network
latency or SQL code execution time?

525
00:29:05,744 --> 00:29:08,764
What's nice about Cloudflare D1 is
that they actually send you back this

526
00:29:08,774 --> 00:29:14,474
property called Duration where they
tell you exactly how long the query took

527
00:29:14,664 --> 00:29:17,824
to execute and in this case it took 0.

528
00:29:17,874 --> 00:29:22,009
24 and that's actually I think in second.

529
00:29:22,059 --> 00:29:23,079
or maybe that's in, sorry.

530
00:29:23,079 --> 00:29:24,339
Yeah, that's in milliseconds.

531
00:29:24,339 --> 00:29:27,699
So it took 0.24 milliseconds
to execute that query.

532
00:29:27,819 --> 00:29:32,709
So pretty much all of this was from
network agency and whatever is going on

533
00:29:32,709 --> 00:29:36,799
in Cloudflare's, API, whatever they have,
going on like checks and authorization

534
00:29:36,799 --> 00:29:38,359
or authentication, things like that.

535
00:29:38,539 --> 00:29:41,129
Their API itself and accessing
over like a network, the

536
00:29:41,129 --> 00:29:43,059
internet, is taking a long time.

537
00:29:43,229 --> 00:29:48,799
So I suspect that wherever the D1
database is placed, is likely somewhere

538
00:29:48,799 --> 00:29:51,669
that's like too far to actually
benefit from being at the edge.

539
00:29:52,079 --> 00:29:54,139
This is again a result
of being at low volume.

540
00:29:54,139 --> 00:29:58,539
So I'd probably use a different database
like SuperBase or Torso, for example, that

541
00:29:58,539 --> 00:30:02,879
can be like distributed, but I have more
control over where it gets distributed.

542
00:30:03,379 --> 00:30:06,619
So what I ended up doing is I added,
caching using something called

543
00:30:06,619 --> 00:30:09,939
zone cache, which is a feature
that we use, at Zoopla, which is

544
00:30:09,949 --> 00:30:12,199
essentially an edge, caching solution.

545
00:30:12,469 --> 00:30:17,059
and basically what I decided to
do was cache based on the prefix,

546
00:30:17,219 --> 00:30:20,739
so like the first few, digits
of the latitude and longitude.

547
00:30:20,969 --> 00:30:24,589
what you do actually is when you remove
like the specificity of the longitude

548
00:30:24,589 --> 00:30:28,769
and latitude or truncated essentially,
you're creating like a geo map.

549
00:30:29,034 --> 00:30:32,574
so there's like a square, of Earth
essentially that's that all the

550
00:30:32,574 --> 00:30:34,094
locations are going to be cached for.

551
00:30:34,264 --> 00:30:37,334
So as long as you have like over 10
locations in your results for that

552
00:30:37,334 --> 00:30:41,074
area, that's probably going to be the
same 10 results for everywhere within

553
00:30:41,084 --> 00:30:43,504
that geographic block essentially.

554
00:30:43,834 --> 00:30:45,994
and this cache is done at the edge.

555
00:30:46,024 --> 00:30:48,684
I can show you the code, if you're
interested, it's all open source.

556
00:30:48,684 --> 00:30:51,164
So I'll mention that later on.

557
00:30:51,414 --> 00:30:55,194
But essentially I took all these
results for this, Geographic square,

558
00:30:55,404 --> 00:30:59,444
cached at the edge, and this results
in calls that take a lot less time,

559
00:30:59,634 --> 00:31:01,874
about 70 milliseconds on average.

560
00:31:02,214 --> 00:31:03,564
And, that's pretty good actually.

561
00:31:03,564 --> 00:31:06,164
that's faster than what Capital
One was doing on their API.

562
00:31:06,164 --> 00:31:09,374
I remember, if you recall, it
took them about 89 milliseconds.

563
00:31:09,424 --> 00:31:11,864
I'm gonna go and refresh this guy again.

564
00:31:12,574 --> 00:31:13,794
Clear this out.

565
00:31:14,479 --> 00:31:19,229
pop this over to the side and the first
call again, that's going to take a while.

566
00:31:19,229 --> 00:31:19,649
It took 1.

567
00:31:19,679 --> 00:31:24,439
84 seconds to make a second call that's
cached and look at that 25 milliseconds.

568
00:31:24,789 --> 00:31:26,399
Let's make a handful more called.

569
00:31:26,409 --> 00:31:26,749
Look at that.

570
00:31:26,919 --> 00:31:32,009
All of these are like sub 40
milliseconds in terms of like response.

571
00:31:32,019 --> 00:31:37,439
So that's half of what Cloudflare or
say half of what Capital One took to

572
00:31:37,459 --> 00:31:39,299
respond with the same number of results.

573
00:31:39,479 --> 00:31:41,419
And that's all a result of caching.

574
00:31:41,629 --> 00:31:46,689
So as you can see, Your data's location
matters a lot when it comes to where,

575
00:31:46,779 --> 00:31:50,809
if you should be using an API at the
edge or have your gateway at the edge

576
00:31:50,809 --> 00:31:55,879
or data at the edge, your data store,
what you choose to use for it, and it

577
00:31:55,919 --> 00:31:58,799
matters a lot basically in terms of
your first call, but for subsequent

578
00:31:58,799 --> 00:32:03,659
calls, caching at the edge is almost
always a better solution, so much better

579
00:32:03,659 --> 00:32:07,669
in fact that this is a mind boggling
fast, I should probably fix my slides.

580
00:32:07,669 --> 00:32:11,989
I'd say around 40 milliseconds, which
is like crazy fast for an API response.

581
00:32:12,489 --> 00:32:14,009
So that's it for my demo.

582
00:32:14,009 --> 00:32:16,879
And that's it for you know why you
should run your APIs at the edge.

583
00:32:17,069 --> 00:32:19,929
If you have any questions, feel
free to connect with me on LinkedIn.

584
00:32:20,279 --> 00:32:21,219
This is the QR code.

585
00:32:21,219 --> 00:32:22,409
You can scan over here.

586
00:32:22,909 --> 00:32:26,019
If you have any, if you're interested
in seeing the code for how I wrote

587
00:32:26,019 --> 00:32:28,129
this API, I've open sourced all of it.

588
00:32:28,139 --> 00:32:31,239
Please send me a DM again on LinkedIn
if you're interested, and I'll see if

589
00:32:31,239 --> 00:32:34,839
there's some sort of resources for the
conference I can share this in later.

590
00:32:35,229 --> 00:32:37,959
You can also take a look at the slides,
I think, after the fact, in case

591
00:32:37,959 --> 00:32:41,629
you're interested to get links to the
code or any of the images that I had.

592
00:32:42,089 --> 00:32:45,099
Thank you so much for attending my talk,
and enjoy the rest of your conference.

593
00:32:45,289 --> 00:32:45,789
See ya.

