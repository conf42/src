1
00:00:00,010 --> 00:00:00,620
Hi, everyone.

2
00:00:00,930 --> 00:00:04,620
Welcome to my presentation,
Python and UX teams, smart ways to

3
00:00:04,620 --> 00:00:06,250
support research and innovation.

4
00:00:06,610 --> 00:00:09,760
I'm Liv McFarlane and I'm the
principal UX architect at Wheels.

5
00:00:10,259 --> 00:00:14,240
So before getting started, I want to warn
you that this is not a technical talk.

6
00:00:14,560 --> 00:00:16,939
I won't be showing much code
and I won't be demonstrating

7
00:00:16,939 --> 00:00:18,069
how to implement anything.

8
00:00:18,560 --> 00:00:22,160
Instead, I'm going to take you through my
journey of learning Python and applying

9
00:00:22,160 --> 00:00:26,080
it so I could alleviate some of the issues
I and my team have faced since 2021.

10
00:00:26,749 --> 00:00:30,529
You'll hear me talk a lot about having big
ideas, but then having to temper them with

11
00:00:30,529 --> 00:00:33,620
reality because I don't have enough time
to build what I think should be built,

12
00:00:33,669 --> 00:00:37,300
Or because I can't get support to deploy
my tools internally for others to use.

13
00:00:37,660 --> 00:00:40,390
Or because I have to build something
that can be used by people whose

14
00:00:40,390 --> 00:00:41,510
level of skill with Python.

15
00:00:42,010 --> 00:00:44,449
Regardless, these concerns
haven't diminished the value

16
00:00:44,449 --> 00:00:45,969
of Python to me or to my team.

17
00:00:46,349 --> 00:00:49,939
In fact, I think they reinforce
just how critical having Python

18
00:00:49,939 --> 00:00:51,589
skills on a UX team like mine is.

19
00:00:52,089 --> 00:00:55,979
I would argue that Python is a critical
tool because as the product development

20
00:00:55,979 --> 00:01:00,179
landscape evolves with advancements in AI
and machine learning, teams like mine have

21
00:01:00,179 --> 00:01:02,229
to evaluate how they operate and evolve.

22
00:01:02,679 --> 00:01:06,029
And I think that, at least for UX
professionals, that starts with

23
00:01:06,029 --> 00:01:07,449
looking at our tools and processes.

24
00:01:08,429 --> 00:01:10,779
Tools and processes are
linked to an extent, right?

25
00:01:10,839 --> 00:01:14,189
So your processes, what you can
do with others and for others,

26
00:01:14,459 --> 00:01:15,939
are impacted by your tools.

27
00:01:16,279 --> 00:01:19,959
It's more nuanced though than simply
having more tools to do more things.

28
00:01:20,059 --> 00:01:21,269
Sometimes more is just more.

29
00:01:21,779 --> 00:01:25,109
A balance needs to be found between
the number of tools a team has

30
00:01:25,199 --> 00:01:26,709
and the quality of those tools.

31
00:01:27,209 --> 00:01:29,869
At the risk of sounding
cliched, tools should help us

32
00:01:29,869 --> 00:01:31,349
work smarter and not harder.

33
00:01:31,699 --> 00:01:33,554
We should expect to have
to learn a tool, right?

34
00:01:33,804 --> 00:01:35,854
But we should not be
overburdened by a tool.

35
00:01:36,354 --> 00:01:39,854
UX tools and processes generally
cover two big buckets for my

36
00:01:39,854 --> 00:01:41,524
team, design and research.

37
00:01:41,844 --> 00:01:44,724
And while they generally feed back
and forth between one another,

38
00:01:44,774 --> 00:01:46,534
they do have separate concerns.

39
00:01:46,804 --> 00:01:51,304
for example, on the design side, we need
to move quickly to create prototypes that

40
00:01:51,314 --> 00:01:52,804
have to display large amounts of data.

41
00:01:53,159 --> 00:01:56,669
Or we have to consult internally
to other groups about designs of

42
00:01:56,669 --> 00:01:58,129
products, leveraging dashboards.

43
00:01:58,129 --> 00:02:02,589
And then for research, we need to answer
a variety of questions that range from

44
00:02:02,589 --> 00:02:06,349
the more tactical, such as are the
steps for completing a task, easy to

45
00:02:06,349 --> 00:02:08,679
figure out to the more strategic like.

46
00:02:08,904 --> 00:02:11,854
How have attitudes been changing
about our products and services?

47
00:02:12,424 --> 00:02:15,064
And it doesn't end with doing
design and conducting research.

48
00:02:15,274 --> 00:02:18,284
We have to ensure that information
we generate remains available

49
00:02:18,284 --> 00:02:19,804
to our partners across the org.

50
00:02:20,134 --> 00:02:23,994
And we have to do it in such a way that
we, the UX team, are not a roadblock.

51
00:02:24,784 --> 00:02:28,169
We have to do it in a way that
encourages collaboration with us.

52
00:02:28,499 --> 00:02:31,419
But does not infringe on the
autonomy of our internal partner.

53
00:02:31,919 --> 00:02:36,239
Now, as you can probably tell from the way
I'm describing things so far, there are

54
00:02:36,239 --> 00:02:38,199
a lot of tasks caught in these buckets.

55
00:02:38,599 --> 00:02:41,509
And Python is a language that
enables me to do a lot of heavy

56
00:02:41,509 --> 00:02:43,249
lifting for my team and others.

57
00:02:43,519 --> 00:02:44,234
By me, just me.

58
00:02:44,404 --> 00:02:49,114
One person on the team learning Python,
our UX team has been able to alleviate

59
00:02:49,154 --> 00:02:53,104
pain points during prototype creation,
which has the great downstream effect

60
00:02:53,124 --> 00:02:58,184
of leading to faster prototype creation,
create more realistic prototypes, at least

61
00:02:58,184 --> 00:03:02,734
in terms of processing and displaying
data, support other teams participating

62
00:03:02,734 --> 00:03:04,429
in innovation and product development.

63
00:03:04,759 --> 00:03:08,399
Speed up data analysis for
research and create more valuable

64
00:03:08,409 --> 00:03:11,849
insights by being able to perform
a wider variety of analyses for

65
00:03:11,849 --> 00:03:13,429
qualitative and quantitative data.

66
00:03:13,879 --> 00:03:17,399
And all of these things combined
have enabled us over the past several

67
00:03:17,399 --> 00:03:20,449
years to build new partnerships
across the company with teams

68
00:03:20,479 --> 00:03:23,959
involved in the processes for product
development, innovation, and research.

69
00:03:24,459 --> 00:03:27,469
in today's presentation, I will
walk you through how our team

70
00:03:27,489 --> 00:03:31,619
applies Python based solutions for
design, research, and collaboration.

71
00:03:32,029 --> 00:03:34,469
Some of the things I will mention
have evolved since they were

72
00:03:34,469 --> 00:03:36,039
first created and used on my team.

73
00:03:36,419 --> 00:03:39,409
Some solutions have changed very
little, and we have gone so far as

74
00:03:39,409 --> 00:03:42,299
to create our own guidebooks for
standards of use that we treat as

75
00:03:42,349 --> 00:03:43,979
living documents and revise as needed.

76
00:03:44,539 --> 00:03:47,259
Other solutions are still in
development and testing phase.

77
00:03:47,809 --> 00:03:50,939
now that I've introduced you to all
my topics, I'll take us into the

78
00:03:50,939 --> 00:03:52,559
design portion of the presentation.

79
00:03:52,919 --> 00:03:56,239
And just to let you know, this will
be a shorter part of the presentation.

80
00:03:56,569 --> 00:04:00,589
There are a lot of changes happening
on the design side due to the inclusion

81
00:04:00,589 --> 00:04:04,719
of generative AI in some of the more
common UX design tools, and this has

82
00:04:04,729 --> 00:04:08,229
impacted how I plan to continue working
with Python for design activities.

83
00:04:08,729 --> 00:04:14,229
So for design, the key takeaway is
that Python support for prototyping

84
00:04:14,249 --> 00:04:18,149
tools speeds up prototyping and
design exploration within the UX

85
00:04:18,159 --> 00:04:20,839
team and with our internal partners.

86
00:04:21,239 --> 00:04:24,189
Now, before digging into this
topic, I want to be very clear

87
00:04:24,739 --> 00:04:28,949
that when I speak about design,
I'm speaking about prototyping and

88
00:04:28,949 --> 00:04:32,009
not finished designs that look like
what you would find in production.

89
00:04:32,369 --> 00:04:35,699
This is because the largest gains
we found for our team has been at

90
00:04:35,699 --> 00:04:37,029
this point in the design process.

91
00:04:37,654 --> 00:04:38,514
what's that gain?

92
00:04:38,734 --> 00:04:39,094
Time.

93
00:04:39,564 --> 00:04:40,614
And how do we get it?

94
00:04:41,014 --> 00:04:41,684
Fake data.

95
00:04:41,794 --> 00:04:44,984
many times we are creating
prototypes that require anywhere

96
00:04:44,984 --> 00:04:49,634
between 50 to 300 data points to
make realistic seeming interactions

97
00:04:49,714 --> 00:04:51,524
and reasonably realistic outputs.

98
00:04:52,019 --> 00:04:54,699
the data points that feed into
these prototypes range from the

99
00:04:54,699 --> 00:04:56,809
very simple to the somewhat complex.

100
00:04:56,989 --> 00:05:01,009
And so just to give you some examples,
on the simpler side, we need first names,

101
00:05:01,009 --> 00:05:05,849
last names, phone numbers, zipper postal
codes, cities, states, and provinces.

102
00:05:06,289 --> 00:05:09,199
And then on the more complicated
side, we need VIN numbers,

103
00:05:09,239 --> 00:05:12,479
license plates, company IDs.

104
00:05:13,479 --> 00:05:17,199
As an added complication, we have
some restrictions for data points like

105
00:05:17,199 --> 00:05:21,369
VIN numbers, where we want to avoid
accidentally creating a real VIN number.

106
00:05:21,519 --> 00:05:26,669
So prior to the introduction of
Python, what did the process of getting

107
00:05:26,669 --> 00:05:28,599
data for our prototypes look like?

108
00:05:28,929 --> 00:05:29,399
it varied.

109
00:05:29,899 --> 00:05:34,059
Sometimes people would create about 10
unique data points that they roughly

110
00:05:34,069 --> 00:05:38,109
modeled off of client data in our systems,
and then they would copy and paste those

111
00:05:38,109 --> 00:05:42,049
data points over and over, making changes
to them as needed, until they had the

112
00:05:42,049 --> 00:05:45,199
number of data points that would let
them accurately depict the interaction.

113
00:05:46,134 --> 00:05:48,784
Sometimes people would have a set
of links for multiple websites they

114
00:05:48,784 --> 00:05:52,564
could go to, to create the data for
them, such as VIN number generators

115
00:05:52,564 --> 00:05:53,774
and plate number generators.

116
00:05:53,844 --> 00:05:58,384
all in all, there's a lot of time and
effort spent on making up data that seems,

117
00:05:58,494 --> 00:06:03,104
realistic enough, or a lot of time and
effort spent jumping across multiple sites

118
00:06:03,164 --> 00:06:05,254
and concatenating blocks of information.

119
00:06:05,569 --> 00:06:09,329
And then doing cleanup to make sure
it fits the rules for how certain

120
00:06:09,329 --> 00:06:11,009
data points look in our system.

121
00:06:11,679 --> 00:06:15,889
as you can imagine, this is not only
time consuming, but it's error prone.

122
00:06:15,899 --> 00:06:19,669
just to give you a very quick example,
say you need to prototype out a table

123
00:06:19,669 --> 00:06:23,749
with filtering, sorting, actions like
creating, updating, and deleting.

124
00:06:24,119 --> 00:06:27,739
if you aren't careful when differentiating
your data points, your filters will

125
00:06:27,739 --> 00:06:31,049
capture too many data points, or you
might delete too many data points.

126
00:06:31,459 --> 00:06:32,969
So then you have to go back
and you have to fix everything.

127
00:06:32,979 --> 00:06:35,049
You have to hunt down where
the problem went wrong and

128
00:06:35,049 --> 00:06:36,219
then put in your corrections.

129
00:06:36,799 --> 00:06:40,259
Now, you may also be wondering at
this point, how long would it take

130
00:06:40,259 --> 00:06:41,619
to make the data up on your own?

131
00:06:42,049 --> 00:06:46,869
on average, 30 minutes up to an hour, not
counting the time you would spend having

132
00:06:46,869 --> 00:06:50,459
to test the data in the prototype and
make adjustments if you found anything

133
00:06:50,479 --> 00:06:51,869
odd in your prototype's behaviors.

134
00:06:52,404 --> 00:06:56,974
so while this might not seem like a big
sacrifice, given that this should only be

135
00:06:56,974 --> 00:07:00,634
a one time thing, there's a couple things
about our team I would like to point out.

136
00:07:00,954 --> 00:07:05,494
First, we're not a large team, so it
isn't unusual for people to be working

137
00:07:05,494 --> 00:07:07,194
on two or more projects at a time.

138
00:07:07,414 --> 00:07:08,534
I, as the principal, don't do that.

139
00:07:08,774 --> 00:07:10,644
I can be on four projects at a time.

140
00:07:11,144 --> 00:07:13,024
And then changes might be necessary.

141
00:07:13,034 --> 00:07:15,794
there's sometimes some moving
around of interactions or data

142
00:07:15,794 --> 00:07:17,434
points that has to happen.

143
00:07:17,934 --> 00:07:19,524
how is this whole process solved?

144
00:07:19,934 --> 00:07:23,544
a little package named Data Generator,
which I'm showing in a rather

145
00:07:23,604 --> 00:07:25,434
abstract manner on this slide.

146
00:07:25,834 --> 00:07:29,094
And you can see that it's a collection
of Python scripts and text files.

147
00:07:29,669 --> 00:07:33,779
And as its name implies, Data Generator
generates fake data that the user can

148
00:07:33,779 --> 00:07:36,319
download as either an Excel file or a PDF.

149
00:07:36,799 --> 00:07:38,859
they can then use that
data in their prototypes.

150
00:07:38,919 --> 00:07:41,779
And the fake data includes
all of our core data points.

151
00:07:41,879 --> 00:07:46,769
names, contact information, vehicle
details, any unique IDs, membership

152
00:07:46,799 --> 00:07:48,619
category and subcategory IDs.

153
00:07:49,219 --> 00:07:52,879
The Excel file output is probably the
most used output type on our team.

154
00:07:52,929 --> 00:07:56,509
And this is because we use both
Acture and Figma as design tools.

155
00:07:56,929 --> 00:07:59,709
And that file type is the
easiest to use with both of them.

156
00:08:00,329 --> 00:08:04,489
The first generation of data
generator ran through a very

157
00:08:04,499 --> 00:08:07,279
minimal UI built using MLJAR Studio.

158
00:08:07,779 --> 00:08:09,979
however, allowing access became an issue.

159
00:08:10,099 --> 00:08:13,669
the UI portion was abandoned and
it now runs from the command line

160
00:08:13,689 --> 00:08:15,449
or within a Jupyter notebook.

161
00:08:16,369 --> 00:08:18,199
that solved an issue for our team.

162
00:08:18,569 --> 00:08:22,199
But there are other teams involved in
innovation and we're obligated to support.

163
00:08:22,699 --> 00:08:26,169
For some time now, there's been
an effort to improve the quality

164
00:08:26,209 --> 00:08:27,859
of our data visualizations.

165
00:08:27,859 --> 00:08:31,149
Serve up new visualizations
and build new data products.

166
00:08:31,614 --> 00:08:35,104
and since the teams aligned with
these efforts often roll up into

167
00:08:35,164 --> 00:08:39,454
different departments from ours, the
UX team found we had some blind spots.

168
00:08:39,544 --> 00:08:42,284
so we made time to listen to these
teams, and after hearing their

169
00:08:42,284 --> 00:08:46,044
concerns, we took some time to
figure out how best to support them.

170
00:08:46,394 --> 00:08:48,274
And this brought us again
to our prototyping tools,

171
00:08:48,304 --> 00:08:49,384
and we found two things.

172
00:08:49,434 --> 00:08:54,454
first, Acture isn't always the easiest
for creating higher fidelity interactive

173
00:08:54,454 --> 00:08:58,274
data visualizations, or depending on
what you're doing, even static ones.

174
00:08:58,274 --> 00:09:02,124
It's and then Figma can produce high
fidelity visualizations, but sometimes

175
00:09:02,134 --> 00:09:03,914
the interactivity is a little bit lacking.

176
00:09:04,644 --> 00:09:08,454
And this was a concern because, while
typically prototyping shouldn't always

177
00:09:08,454 --> 00:09:12,754
be too tied up in being super detailed,
when it comes to data products,

178
00:09:12,844 --> 00:09:16,524
higher fidelity designs and detailed
interactions can make a difference

179
00:09:16,524 --> 00:09:21,144
during user testing between accurately
understanding feedback and incorrectly

180
00:09:21,144 --> 00:09:23,054
interpreting feedback and actions.

181
00:09:23,839 --> 00:09:28,419
another finding was we don't have enough
people on our team to always offer

182
00:09:28,419 --> 00:09:32,569
support beyond consultation sessions
around implementing design standards.

183
00:09:32,899 --> 00:09:36,699
we have a style guide that anybody in
the company can access, but it's not

184
00:09:36,699 --> 00:09:40,359
right to simply point a team to a set
of guidelines and then abandon them.

185
00:09:40,869 --> 00:09:45,319
So it became a question of what, if any,
tools exist that could solve our issues.

186
00:09:45,689 --> 00:09:48,499
one of the teams we work with
happens to use Streamlet.

187
00:09:48,549 --> 00:09:51,979
if you're unfamiliar with Streamlet,
it's an open source framework for

188
00:09:51,979 --> 00:09:53,759
building data apps using Python.

189
00:09:53,879 --> 00:09:58,779
again, and quite unexpectedly, Python came
through as a way to devise a tool that

190
00:09:58,779 --> 00:10:00,669
saved the day for our team and another.

191
00:10:01,519 --> 00:10:05,139
Now, that's not to say that everything
went smoothly right out of the gate.

192
00:10:05,469 --> 00:10:09,119
For starters, our design system
components at that time were only

193
00:10:09,139 --> 00:10:13,639
built out in a low code development
app So we had nothing in Streamlit.

194
00:10:13,959 --> 00:10:17,779
Furthermore, our partners didn't really
have the time to take our standards

195
00:10:17,779 --> 00:10:19,619
and adapt them to their products.

196
00:10:19,879 --> 00:10:23,679
They also would not have access to the
location where all of our components and

197
00:10:23,699 --> 00:10:25,859
assets live for our development teams.

198
00:10:25,919 --> 00:10:28,909
So that meant that whatever solution
we did create for them would have

199
00:10:28,909 --> 00:10:32,079
to be one that lived in their little
corner of the corporate world.

200
00:10:32,994 --> 00:10:36,824
Thankfully though, Streamlit is flexible
enough that through a combination of

201
00:10:36,825 --> 00:10:41,964
CSS and Streamlit functions, we're
able to recreate a substantial chunk

202
00:10:41,984 --> 00:10:45,494
of our style guide, complete with
code snippets and examples of how

203
00:10:45,494 --> 00:10:47,204
to use them for our partner team.

204
00:10:47,644 --> 00:10:50,744
And they can then host that
app on one of their servers.

205
00:10:51,074 --> 00:10:54,074
let me show you a little bit of work
from the earliest implementation

206
00:10:54,074 --> 00:10:55,044
of what we made for them.

207
00:10:55,544 --> 00:10:58,444
on this slide is our
page laying out colors.

208
00:10:58,474 --> 00:10:59,214
for light mode.

209
00:10:59,224 --> 00:11:03,004
And you can see we've provided
color chips, the CSS variable name

210
00:11:03,024 --> 00:11:04,624
and the actual hex color code.

211
00:11:04,874 --> 00:11:08,094
And we do the same thing for the dark
mode if you were to click on that tab.

212
00:11:08,624 --> 00:11:12,464
and I do want to mention at this point
that as part of this effort, our team

213
00:11:12,464 --> 00:11:15,724
supplied our colleagues with a style
sheet pointing to all the web fonts they

214
00:11:15,724 --> 00:11:19,464
would need and with the light mode and
dark mode colors all set up for them.

215
00:11:19,964 --> 00:11:24,344
And on this slide, you see a sample
from our icon library complete with

216
00:11:24,364 --> 00:11:27,754
code snippets that can be adapted
as well as the file path to use.

217
00:11:28,444 --> 00:11:32,954
And so I will add that the file path
is based on how we recommend other

218
00:11:32,954 --> 00:11:34,804
teams to set up their images directory.

219
00:11:35,104 --> 00:11:39,144
Again, our colleagues in this instance
aren't connected to where we have our

220
00:11:39,164 --> 00:11:43,094
assets for the broader development group,
so we provided them with the necessary

221
00:11:43,134 --> 00:11:47,534
SVG files to start and then gave a
recommendation on how to access them.

222
00:11:48,034 --> 00:11:52,714
And, in case you're curious, I know it's
a bit hard to see, but on the left of

223
00:11:52,714 --> 00:11:56,794
this slide is what the code looks like
for the Streamlit Icon Library page.

224
00:11:57,074 --> 00:12:00,394
And you'll notice at the top two
lines, Import StreamlitComponents.

225
00:12:00,974 --> 00:12:06,414
v1 as Components, and From Utils
Import LoadCSS, Generate Icon

226
00:12:06,414 --> 00:12:07,554
Table, and Generate Footer.

227
00:12:08,054 --> 00:12:11,524
I'm calling all of this out because
it's a great capability when

228
00:12:11,564 --> 00:12:13,334
building out this style guide app.

229
00:12:13,634 --> 00:12:18,204
in Streamlit, you can write Python
functions to generate chunks of HTML that

230
00:12:18,204 --> 00:12:19,594
will then be treated like components.

231
00:12:19,949 --> 00:12:24,119
if you look at line 54 in the image on
the left, you can see the call to generate

232
00:12:24,149 --> 00:12:28,449
icon table that will display each of
the icons in the engine icons folder.

233
00:12:28,759 --> 00:12:30,979
Then in the image on the
right, you can see the actual

234
00:12:30,979 --> 00:12:32,689
generate icon table function.

235
00:12:32,799 --> 00:12:36,839
I do want to stress though that
recreating our entire style guide

236
00:12:36,859 --> 00:12:38,129
in this way is not possible.

237
00:12:38,814 --> 00:12:42,744
There are multiple components in
our design system that have to be

238
00:12:42,744 --> 00:12:46,554
created from scratch for use in
Streamlit due to styling choices that

239
00:12:46,554 --> 00:12:49,904
were made before we knew Streamlit
even needed to be on our radar.

240
00:12:50,454 --> 00:12:56,314
Some of those components include
buttons, radio buttons, tabs, input

241
00:12:56,314 --> 00:12:58,684
fields, notifications, and modals.

242
00:12:59,144 --> 00:12:59,674
it's a lot.

243
00:13:00,144 --> 00:13:03,684
But the bright side here is that
Streamlit has tutorials and templates

244
00:13:03,684 --> 00:13:05,564
for creating custom components.

245
00:13:05,574 --> 00:13:09,919
So as time permits, These components
are being built using a React template.

246
00:13:09,999 --> 00:13:13,059
And to date, only buttons and
input fields have been completed.

247
00:13:13,389 --> 00:13:16,879
But we expect to have more time this year
to work on some of the other components.

248
00:13:17,379 --> 00:13:22,329
Now, before wrapping up this section on
design, I want to state that I expect our

249
00:13:22,329 --> 00:13:26,999
use of Python within design activities
to increase, despite the growing presence

250
00:13:26,999 --> 00:13:28,969
of generative AI in design tools.

251
00:13:29,274 --> 00:13:33,114
And this will be due in part to that
growing presence, but also to the

252
00:13:33,114 --> 00:13:36,294
types of products and services we
will need to design and then test.

253
00:13:36,604 --> 00:13:39,554
So for example, I expect that
Streamlit will actually be used

254
00:13:39,565 --> 00:13:43,445
to prototype out dashboards and
reports as we build new data products

255
00:13:43,445 --> 00:13:45,194
because more so than our other tools.

256
00:13:45,415 --> 00:13:46,895
It can do what we need very well.

257
00:13:47,395 --> 00:13:51,425
So next in this presentation, I
will talk about our use of Python

258
00:13:51,435 --> 00:13:52,555
in the UX research process.

259
00:13:53,095 --> 00:13:56,815
And research has really been where the
use of Python has shined for our team.

260
00:13:57,355 --> 00:14:01,095
So if I were to identify the major
point of this section, I would say

261
00:14:01,105 --> 00:14:05,205
Python expands our research toolkit
so we can provide deeper insights

262
00:14:05,275 --> 00:14:07,145
and more widely apply our findings.

263
00:14:07,645 --> 00:14:11,695
Now, before I jump into telling you
how Python has improved our research

264
00:14:11,695 --> 00:14:15,685
practice, let me take a moment to
quickly tell you about the types of

265
00:14:15,685 --> 00:14:20,405
research our UX team deals in so you can
understand why we use Python like we do.

266
00:14:20,955 --> 00:14:25,605
one way to categorize our research
activities is as generative or evaluative.

267
00:14:25,885 --> 00:14:29,285
Generative research creates a deep
understanding of user needs and

268
00:14:29,285 --> 00:14:32,945
motivations to uncover problems for
which we can then build solutions.

269
00:14:33,535 --> 00:14:38,025
And evaluative research evaluates a
solution, like a prototype product

270
00:14:38,025 --> 00:14:41,725
or service, with respect to a problem
that's been previously identified.

271
00:14:42,225 --> 00:14:46,565
another way to think about UX
research is to view it as either

272
00:14:46,565 --> 00:14:47,825
qualitative or quantitative.

273
00:14:48,125 --> 00:14:51,165
And this is probably the way
most people are familiar with

274
00:14:51,175 --> 00:14:52,565
thinking of UX research, right?

275
00:14:52,735 --> 00:14:55,845
qualitative UX research focuses
on the perceptions, behaviors,

276
00:14:55,875 --> 00:14:57,345
and emotions of experiences.

277
00:14:57,685 --> 00:15:02,865
And quantitative UX research focuses on
measuring aspects of experiences, both

278
00:15:02,875 --> 00:15:05,205
subject and subjective and objective.

279
00:15:05,745 --> 00:15:08,945
And based on these descriptions, you can
probably tell that depending on what you

280
00:15:08,945 --> 00:15:13,165
want to know, you can lean more heavily
on qualitative methods or quantitative

281
00:15:13,165 --> 00:15:15,245
methods, or you can even combine them.

282
00:15:16,155 --> 00:15:20,965
And so the big takeaway from these
two ways of classifying UX research is

283
00:15:20,965 --> 00:15:25,285
that they can be deployed in a tactical
manner or a strategic manner with the

284
00:15:25,285 --> 00:15:28,815
objective that these two approaches
will play off of one another during

285
00:15:28,815 --> 00:15:30,775
innovation and product development.

286
00:15:31,345 --> 00:15:34,295
And so now, this is where I bring
up a topic that has appeared

287
00:15:34,295 --> 00:15:35,935
repeatedly in this presentation.

288
00:15:36,315 --> 00:15:38,175
The extent to which you can do things.

289
00:15:38,235 --> 00:15:42,365
in this case, conducting research and
blending tactical and strategic research

290
00:15:42,365 --> 00:15:44,915
activities depends partly on your tools.

291
00:15:45,045 --> 00:15:48,435
obviously, the better your tools,
the better insights you can turn out.

292
00:15:49,005 --> 00:15:52,315
For us, having better tools
means multiple things.

293
00:15:52,445 --> 00:15:54,385
First, we can move faster.

294
00:15:54,985 --> 00:15:57,395
Then, we can do a wider
variety of analyses.

295
00:15:57,845 --> 00:16:02,255
We can communicate our findings better,
and we can expand the data sources we use.

296
00:16:02,755 --> 00:16:06,895
And a really good example of how some
of these things fit together is in

297
00:16:06,895 --> 00:16:08,525
the analysis of qualitative data.

298
00:16:08,785 --> 00:16:11,825
And that's actually the bulk of
our data, qualitative feedback.

299
00:16:12,265 --> 00:16:15,895
And so we get this data from user
testing, interviews, and surveys.

300
00:16:16,380 --> 00:16:20,000
And mostly we're interested in
identifying topics or themes and

301
00:16:20,000 --> 00:16:22,050
suggestions for products and services.

302
00:16:22,600 --> 00:16:25,640
so typically the process for
uncovering what we're interested

303
00:16:25,640 --> 00:16:27,730
in is rather slow and evolved.

304
00:16:28,060 --> 00:16:32,450
there's a lot of reading and a lot of
manually applying tags to observations

305
00:16:32,450 --> 00:16:36,350
in the data, and occasionally reaching
out to teammates to discuss how you

306
00:16:36,350 --> 00:16:37,864
have interpreted and tagged the data.

307
00:16:38,475 --> 00:16:39,335
observations.

308
00:16:39,525 --> 00:16:44,535
So again, it's a rather involved process,
and that can easily take a week or

309
00:16:44,535 --> 00:16:48,845
longer depending on how much data you
have, the tools available to you for

310
00:16:48,845 --> 00:16:52,415
the work, and how big the team is you're
working with on the research project.

311
00:16:53,405 --> 00:16:57,675
So from my perspective, this domain had a
lot of opportunity not only for speeding

312
00:16:57,675 --> 00:17:02,975
things up, but also for experimenting
with what information we could extract.

313
00:17:03,275 --> 00:17:07,845
And on that last point, incorporating
Python into the analysis process

314
00:17:07,845 --> 00:17:10,905
enabled us to start looking at
sentiment and emotion, as well

315
00:17:10,905 --> 00:17:14,375
as introduce topic modeling and
applying new data visualizations.

316
00:17:14,875 --> 00:17:18,285
you might be unsurprised to learn though,
all of it started out pretty slow.

317
00:17:18,525 --> 00:17:22,255
But over time, the values really added
up as I've included new libraries

318
00:17:22,255 --> 00:17:25,355
and tried out new approaches to
see what fits best for our needs.

319
00:17:25,800 --> 00:17:30,510
And so this slide lays out the progression
of how we started incorporating Python

320
00:17:30,540 --> 00:17:32,850
as a tool for qualitative data analysis.

321
00:17:33,270 --> 00:17:37,660
So going all the way back to
2021, I kicked off the effort

322
00:17:37,660 --> 00:17:41,260
with sentiment analysis and then
expanded it rather quickly to

323
00:17:41,260 --> 00:17:43,250
include some basic text metrics.

324
00:17:43,360 --> 00:17:46,920
And this is because it's a fairly
common question to ask how the features

325
00:17:46,970 --> 00:17:48,640
of text change with sentiments.

326
00:17:48,930 --> 00:17:52,870
So for example, we might want to know
whether the length of comments measured

327
00:17:52,870 --> 00:17:54,780
in word counts changes with valence.

328
00:17:55,280 --> 00:17:59,870
and then for the second phase, and that
was, I would say late 2021 into earlier,

329
00:17:59,870 --> 00:18:05,250
mid 2022, I began experimenting with
different types of topic modeling and how

330
00:18:05,250 --> 00:18:07,170
to present the information from that work.

331
00:18:07,960 --> 00:18:12,970
And the third phase, which I would say
is ongoing, has expanded to include using

332
00:18:12,970 --> 00:18:16,660
pre-trained models from hugging phase as
well as some of the features of Spacey.

333
00:18:17,020 --> 00:18:20,020
And it's really this phase
which has enabled our team to

334
00:18:20,020 --> 00:18:23,020
provide deeper insights to our
partners across the organization.

335
00:18:23,385 --> 00:18:27,825
As we can now blend activities from
all phases to explore links between

336
00:18:27,825 --> 00:18:31,595
topics, sentiment, and emotion, and
see how the various text features

337
00:18:31,595 --> 00:18:33,705
we track relate to those things.

338
00:18:34,015 --> 00:18:39,325
and spaCy in particular has improved
how we analyze text data, as it's rather

339
00:18:39,375 --> 00:18:42,615
easy to create domain specific NER tags.

340
00:18:42,905 --> 00:18:46,115
So now we can quickly identify where
certain features and products are called

341
00:18:46,125 --> 00:18:49,675
out in the comments, and then also link
those back with topics and sentiments.

342
00:18:49,945 --> 00:18:54,875
Just as an example, another area where
we had a strong gain was in using LLMs

343
00:18:54,895 --> 00:18:56,825
and some very basic prompt engineering.

344
00:18:57,455 --> 00:19:00,645
And here we started with
scikit llm and OpenAI.

345
00:19:00,775 --> 00:19:04,735
It was really just a test to see
how well an LLM would perform

346
00:19:04,735 --> 00:19:07,795
at few shot classification
and zero shot classification

347
00:19:07,795 --> 00:19:09,235
activities without fine tuning.

348
00:19:09,865 --> 00:19:14,055
And the results were actually pretty
solid, both after I and another person

349
00:19:14,065 --> 00:19:15,435
on the team reviewed the output.

350
00:19:15,825 --> 00:19:18,505
as a team, we went forward
with developing guidelines for

351
00:19:18,505 --> 00:19:20,645
using LLMs as analysis tools.

352
00:19:20,965 --> 00:19:24,275
And at a high level, those guidelines
mentioned things like always pair

353
00:19:24,315 --> 00:19:28,255
LLMs with a UXer, so somebody
with domain knowledge and project

354
00:19:28,255 --> 00:19:31,805
knowledge can evaluate the output,
catch issues early, and change

355
00:19:31,805 --> 00:19:33,255
prompt writing strategy if needed.

356
00:19:33,935 --> 00:19:37,575
clarity and specificity of writing
prompts for analysis, which was

357
00:19:37,575 --> 00:19:41,315
developed over time from our personal
experience and from recommendations

358
00:19:41,385 --> 00:19:43,115
released by reputable sources.

359
00:19:43,215 --> 00:19:45,715
And then finally, code
snippets to use for prompts.

360
00:19:46,215 --> 00:19:49,605
as great as this was, concerns
mounted pretty quickly with the

361
00:19:49,605 --> 00:19:52,004
safety of not using local LLMs.

362
00:19:52,285 --> 00:19:54,825
we eventually shifted over to using Olama.

363
00:19:55,155 --> 00:19:58,635
Now, OLAMA, if you're not familiar
with it, is a way for you to

364
00:19:58,635 --> 00:20:00,845
download LLMs and run them locally.

365
00:20:00,935 --> 00:20:06,005
with this change to OLAMA, we shifted
from using OpenAI models to Metas LLAMA.

366
00:20:06,445 --> 00:20:10,655
And there hasn't been any downgrade
in terms of, the quality of results

367
00:20:10,655 --> 00:20:13,875
we receive for the aforementioned
classification strategies.

368
00:20:14,785 --> 00:20:18,475
Also, the shift to OLAMA brought
with it experimentation with

369
00:20:18,525 --> 00:20:21,075
LangChain, and then, scikit olama.

370
00:20:22,025 --> 00:20:26,345
And one thing driving this shift is
that while the use of LLMs and prompt

371
00:20:26,375 --> 00:20:30,715
engineering benefits my team, my team
does need to be able to use the tools.

372
00:20:30,795 --> 00:20:34,894
Not everybody on my team wants to
learn Python or has the time to do it.

373
00:20:34,974 --> 00:20:40,145
So in that regard, scikit olama is a bit
more friendly for people who aren't really

374
00:20:40,145 --> 00:20:42,105
familiar or comfortable with Python.

375
00:20:42,105 --> 00:20:46,075
Another thing is, it's very
hard for me to create a UI and

376
00:20:46,075 --> 00:20:49,475
then have it stored somewhere
internally for my teammates to use.

377
00:20:49,955 --> 00:20:53,195
There's just not a lot of
support for that from IT.

378
00:20:53,505 --> 00:20:56,945
So I have to find the simplest
ways to do things with lots of

379
00:20:56,974 --> 00:20:59,035
plug and play code snippets.

380
00:20:59,695 --> 00:21:03,325
Now, that doesn't mean I
abandoned the explorations of

381
00:21:03,325 --> 00:21:05,125
using line chain with LLMs.

382
00:21:06,085 --> 00:21:09,335
It has served as a key component
for some experiments that I'll talk

383
00:21:09,345 --> 00:21:13,275
about later in the collaboration
section of this presentation.

384
00:21:13,775 --> 00:21:17,575
So now, I'd like to talk a little
bit about how our approach to

385
00:21:17,575 --> 00:21:19,675
quantitative data analysis has changed.

386
00:21:19,875 --> 00:21:24,205
And our main sources of quantitative
data include surveys, ratings

387
00:21:24,205 --> 00:21:28,415
from user tests and quantification
of aspects of qualitative data.

388
00:21:29,075 --> 00:21:32,815
we have some web analytics,
but the vendor we use doesn't

389
00:21:32,825 --> 00:21:34,465
give us much of the raw data.

390
00:21:34,715 --> 00:21:37,455
They aggregate it for us, and
they make it very difficult for us

391
00:21:37,455 --> 00:21:38,895
to go back and get the raw data.

392
00:21:38,955 --> 00:21:40,254
for my purposes, it's useless.

393
00:21:40,959 --> 00:21:44,669
So until all that's resolved,
it's not really a great source

394
00:21:44,669 --> 00:21:46,239
of quantitative data for us.

395
00:21:47,039 --> 00:21:51,749
But the quickest gains we got from
using Python were with exploratory data

396
00:21:51,749 --> 00:21:57,099
analysis, data visualizations, and basic
methods like linear regression logistic.

397
00:21:57,999 --> 00:22:03,359
So at this point, this is early
2021, and we had one survey that

398
00:22:03,369 --> 00:22:05,459
had roughly 3, 000 data points.

399
00:22:05,479 --> 00:22:09,619
So it's not a lot, but you can still
do something with 3, 000 data points.

400
00:22:09,999 --> 00:22:11,179
And we combined.

401
00:22:11,524 --> 00:22:15,154
This survey analysis with
sentiment analysis using VADR.

402
00:22:15,954 --> 00:22:19,634
And so for our first attempt, our effort
was actually pretty well received.

403
00:22:20,124 --> 00:22:24,055
So you might be wondering then, what won
the day for us with just this one attempt?

404
00:22:24,304 --> 00:22:28,494
previously analysis was done using
Excel, which, no shade on Excel.

405
00:22:28,554 --> 00:22:30,774
You can produce legitimate
analyses with it.

406
00:22:31,094 --> 00:22:35,604
But with Python, we were able to produce
better and more varied visualizations.

407
00:22:35,809 --> 00:22:39,929
Finer detail showing how responses
on one variable related to another

408
00:22:40,319 --> 00:22:43,409
and then explorations of links
between ratings and sentiments.

409
00:22:43,909 --> 00:22:48,489
So that one survey got our team more
credibility and enabled my boss and

410
00:22:48,489 --> 00:22:50,020
I to keep pushing for more data.

411
00:22:50,279 --> 00:22:54,169
we found other groups conducting surveys
or collecting data on interactions with

412
00:22:54,169 --> 00:22:58,439
our customers, and we just simply asked
them for their raw data so we could devise

413
00:22:58,439 --> 00:23:00,679
new hypotheses and try out new analyses.

414
00:23:00,939 --> 00:23:05,709
So now in 2025, as you can see from
the timeline on this slide, the use

415
00:23:05,709 --> 00:23:10,239
of Python as a tool for data analysis
has grown well beyond exploratory data

416
00:23:10,239 --> 00:23:12,489
analysis, visualizations, and regressions.

417
00:23:12,539 --> 00:23:14,719
And that's not to say we
don't still use all of that.

418
00:23:14,729 --> 00:23:15,459
We do.

419
00:23:15,779 --> 00:23:20,399
But where we have large enough data sets
to support such work, we can perform

420
00:23:20,399 --> 00:23:25,129
cluster analyses, association mining,
and we've even done network analysis.

421
00:23:25,629 --> 00:23:29,859
And so these methods have all helped
create new ways of thinking about our

422
00:23:29,859 --> 00:23:34,119
clients that go beyond things like,
industry effects, fleet size effects,

423
00:23:34,119 --> 00:23:35,849
or even fleet composition effects.

424
00:23:36,069 --> 00:23:39,309
And they've also helped us understand
things like how attitudes toward

425
00:23:39,309 --> 00:23:43,099
one set of services may impact
attitudes towards another set.

426
00:23:43,669 --> 00:23:47,549
And so these are all insights that had
I not made the effort to learn Python

427
00:23:47,559 --> 00:23:51,649
and apply it, our team likely would not
have been able to provide them ever.

428
00:23:51,859 --> 00:23:55,769
but now, because of it, we have teams
even outside of product development

429
00:23:55,769 --> 00:23:59,189
and innovation functions who take
an interest in this work that we do.

430
00:23:59,689 --> 00:24:04,530
Now, while it's great that we're able to
provide such value using data provided by

431
00:24:04,539 --> 00:24:08,949
internal sources, a key part of innovation
is looking outside your world, right?

432
00:24:08,949 --> 00:24:10,750
Going externally for useful data.

433
00:24:11,030 --> 00:24:13,089
And Python does a great
job of enabling that.

434
00:24:13,660 --> 00:24:18,020
So let me offer you a very early
example with context, and I'll

435
00:24:18,020 --> 00:24:21,290
share that my employer is a fleet
management firm, and as such, we

436
00:24:21,290 --> 00:24:24,520
have an interest in understanding
attitudes toward electric vehicles.

437
00:24:24,999 --> 00:24:30,450
So in the spring of 2022, using TWINT,
Twitter intelligence tool, I was able to

438
00:24:30,450 --> 00:24:34,220
scrape several thousand tweets about EVs
for topic modeling and text analytics.

439
00:24:35,040 --> 00:24:39,619
Now, while it's still possible to get
some data from X, we've since moved

440
00:24:39,650 --> 00:24:43,630
on to other more reliable sources when
we want to explore specific topics.

441
00:24:44,289 --> 00:24:48,930
And the internet is a very large place
and tools like Beautiful Soup and Selenium

442
00:24:49,265 --> 00:24:50,985
have really helped us gather what we need.

443
00:24:51,485 --> 00:24:55,785
Now this next portion of my presentation,
collaboration, covers some of the

444
00:24:55,795 --> 00:24:59,835
recent and in progress experimentations
with Python happening on my team.

445
00:25:00,275 --> 00:25:03,855
And the broader point from this
section is, Python can help provide

446
00:25:03,884 --> 00:25:07,824
better access to information which
facilitates collaboration between

447
00:25:07,824 --> 00:25:09,855
UX and our internal partners.

448
00:25:10,355 --> 00:25:15,120
Now, if you remember during the research
portion of my presentation, I mentioned

449
00:25:15,120 --> 00:25:19,470
that I was still exploring how to use
Lang Chain with LLMs, and one idea we

450
00:25:19,470 --> 00:25:24,150
looked at in 2023, but deprioritized
was the use of Lang chain's, SQL

451
00:25:24,150 --> 00:25:28,650
chain and a GPT model with a post gray
SQL database to interact with data.

452
00:25:29,080 --> 00:25:32,020
and it started with simple
things like retrieving raw data,

453
00:25:32,020 --> 00:25:34,060
generating counts, getting averages.

454
00:25:34,710 --> 00:25:35,780
very simple.

455
00:25:36,190 --> 00:25:38,250
And there were a few
reasons behind the data.

456
00:25:38,690 --> 00:25:39,640
Idea, rather.

457
00:25:40,590 --> 00:25:44,190
first, we have some data from
studies before I joined the team.

458
00:25:44,569 --> 00:25:48,689
but it's all over the place, and so
trying to find that data, if you weren't

459
00:25:48,689 --> 00:25:52,255
involved on the study, It can be a bit of
an adventure, let's just put it that way.

460
00:25:52,705 --> 00:25:54,715
plus we're always generating new data.

461
00:25:55,035 --> 00:25:59,345
So this activity would require getting
all of that data organized and stored

462
00:25:59,345 --> 00:26:03,265
so that it could be interacted with by
us or by others across the organization.

463
00:26:03,975 --> 00:26:07,535
second, not everybody on our
team wants to dig into data.

464
00:26:07,904 --> 00:26:12,794
we are a mixed team of practitioners where
some people like me are more geared toward

465
00:26:12,794 --> 00:26:17,374
research and analytical processes while
others strictly prefer design activities.

466
00:26:17,664 --> 00:26:21,624
So I have to ensure that everyone is
supported regardless of their comfort

467
00:26:21,624 --> 00:26:23,244
level and preference for activities.

468
00:26:23,654 --> 00:26:27,064
And third, sometimes others in the
organization want to see our data.

469
00:26:27,884 --> 00:26:32,144
the intent behind the proof of concept
was well received, but there were

470
00:26:32,164 --> 00:26:33,644
questions about interacting with it.

471
00:26:33,654 --> 00:26:37,915
the big one being, How do we control the
prompts given to the tool so that the

472
00:26:37,915 --> 00:26:42,525
user will get back the specific data they
want with the correct SQL queries applied?

473
00:26:42,865 --> 00:26:46,435
this ultimately led into a broader
discussion about database design and

474
00:26:46,435 --> 00:26:50,644
maintaining data integrity that, frankly,
our team is not equipped to handle at the

475
00:26:50,644 --> 00:26:52,945
moment given our size and project loads.

476
00:26:53,164 --> 00:26:56,264
for these reasons, this idea
has been de prioritized.

477
00:26:56,334 --> 00:27:00,564
Doesn't mean we gave up on it, we're
just not focusing a lot of effort on it.

478
00:27:01,514 --> 00:27:05,794
however We still do have an issue with
others in the organization wanting

479
00:27:05,794 --> 00:27:10,464
to see our past reports, or even
look at relevant UX or HCI research

480
00:27:10,464 --> 00:27:12,344
from peer reviewed publications.

481
00:27:12,754 --> 00:27:16,594
And while this isn't the exact
same problem as using an agent to

482
00:27:16,594 --> 00:27:20,444
interact with data in the database,
it's not entirely dissimilar, right?

483
00:27:20,454 --> 00:27:24,234
It's still a user feeding prompts
to an LLM that then goes to retrieve

484
00:27:24,234 --> 00:27:26,244
information stored in a database.

485
00:27:26,744 --> 00:27:29,794
And in general, this is a very
well documented scenario, right?

486
00:27:29,824 --> 00:27:33,874
there are online tutorials you can
read on Medium or watch on YouTube.

487
00:27:34,354 --> 00:27:38,224
So for the initial phase of this
work, I chose to pair ChromaDB

488
00:27:38,254 --> 00:27:39,754
with LangChain and Olama.

489
00:27:40,494 --> 00:27:44,134
While there are better options
than Chroma out there, I have some

490
00:27:44,135 --> 00:27:47,514
constraints, like I have to move
quickly, I can't incur additional costs,

491
00:27:47,934 --> 00:27:49,994
and there's nobody in IT to help me.

492
00:27:50,344 --> 00:27:53,574
So knowing all of that, Chroma
seemed to be the best option for me.

493
00:27:54,434 --> 00:27:59,094
Then I had the choice of testing this
idea out with different sets of documents.

494
00:27:59,424 --> 00:28:01,634
So one choice was to use
our internal reports.

495
00:28:01,714 --> 00:28:04,974
And these are templated documents
with consistent layouts and headers

496
00:28:04,994 --> 00:28:09,374
where the only real difference
is the actual reported content.

497
00:28:09,784 --> 00:28:13,084
And with everything being so similar,
there's not a lot of challenge here.

498
00:28:13,864 --> 00:28:17,304
The other choice, though, was
to use a subset of PDFs our

499
00:28:17,304 --> 00:28:19,084
team uses like a mini library.

500
00:28:19,404 --> 00:28:22,334
And this choice is where things
got interesting because these

501
00:28:22,334 --> 00:28:24,424
PDFs aren't just journal articles.

502
00:28:24,674 --> 00:28:27,684
some of them are industry reports,
others are design toolkits.

503
00:28:28,094 --> 00:28:31,224
So there are pockets of
consistency, but for the most

504
00:28:31,224 --> 00:28:33,604
part, there's not a lot of it.

505
00:28:34,554 --> 00:28:37,714
And then the next thing to consider
is the knowledge level of who

506
00:28:37,714 --> 00:28:39,304
would be using a tool like this.

507
00:28:39,714 --> 00:28:45,154
So regardless, if we're storing UX
reports and UX or HCI publications,

508
00:28:45,234 --> 00:28:47,074
the people on my team are the ones.

509
00:28:47,334 --> 00:28:51,344
who know all the jargon and how
we internally organize documents,

510
00:28:51,354 --> 00:28:54,584
while our partners in product
management, for example, might

511
00:28:54,584 --> 00:28:56,014
not know all that same stuff.

512
00:28:56,154 --> 00:29:01,604
So there has to be a way to store each
PDF with some information that could help

513
00:29:01,624 --> 00:29:03,174
the person interacting with the tool.

514
00:29:03,554 --> 00:29:06,494
And so as a team, we thought that
information could include things

515
00:29:06,494 --> 00:29:11,784
like title, authors, publication
dates, summaries and topic lists.

516
00:29:12,634 --> 00:29:18,944
Now, the problem is we already have over
100 PDFs from external sources alone.

517
00:29:19,144 --> 00:29:23,574
So assigning someone to go through
each article and generate this

518
00:29:23,574 --> 00:29:26,364
information is not a good idea.

519
00:29:26,664 --> 00:29:29,764
and considering that we will add
more documents in the future,

520
00:29:30,204 --> 00:29:33,674
it's just even more unrealistic
to ask someone to do that.

521
00:29:34,344 --> 00:29:38,539
But as our team has already discovered
though, LLMs with appropriate

522
00:29:38,539 --> 00:29:41,809
prompt engineering can substantially
reduce this kind of workload.

523
00:29:42,179 --> 00:29:47,449
the tool in this particular phase allowed
someone to submit a document, extract

524
00:29:47,469 --> 00:29:51,339
and generate key pieces of information
from that document, and then store the

525
00:29:51,339 --> 00:29:52,459
information along with the document.

526
00:29:52,959 --> 00:29:56,449
And this current slide shows
the prompt used for testing the

527
00:29:56,449 --> 00:29:58,239
extraction and generation activities.

528
00:29:58,569 --> 00:30:01,969
you can see we assign a system role
as a helpful research assistant

529
00:30:02,259 --> 00:30:05,719
and a user role as the entity that
would actually use that output from

530
00:30:05,729 --> 00:30:07,269
the helpful research assistant.

531
00:30:07,529 --> 00:30:10,009
And we use a formatted string
to present the request for a

532
00:30:10,009 --> 00:30:13,379
summary, up to five topics, the
title, authors, and publication

533
00:30:13,379 --> 00:30:14,739
date for a particular document.

534
00:30:15,239 --> 00:30:19,289
And this slide shows the code for
accessing and printing the LLMs

535
00:30:19,299 --> 00:30:20,849
output and the output itself.

536
00:30:21,059 --> 00:30:23,774
as you can see, it's
fairly coherent, right?

537
00:30:24,104 --> 00:30:27,534
but depending on the contents of the
document, the output quality dropped.

538
00:30:27,864 --> 00:30:32,404
But from what I noticed, that seemed to
almost always be for documents that relied

539
00:30:32,414 --> 00:30:34,404
heavily on visuals and less on text.

540
00:30:34,694 --> 00:30:40,454
And so that would be more for things like
design toolkit documents, as opposed to

541
00:30:40,504 --> 00:30:42,604
research articles or industry reports.

542
00:30:42,614 --> 00:30:46,454
Those last two would always turn
out fairly coherent outputs.

543
00:30:46,954 --> 00:30:51,104
So the next phase in this work that we're
hoping to make progress on this year.

544
00:30:51,369 --> 00:30:52,939
looks at using LLAMA Index.

545
00:30:53,369 --> 00:30:56,779
So if you're not familiar with
LLAMA Index, it's a framework for

546
00:30:56,779 --> 00:30:58,739
connecting LLMs and data sources.

547
00:30:59,159 --> 00:31:02,659
So basically, if you need a RAG
model for your application, you

548
00:31:02,659 --> 00:31:04,349
may wind up using LLAMA Index.

549
00:31:04,529 --> 00:31:08,569
And that's the next stage, really,
transforming this into a RAG application.

550
00:31:08,879 --> 00:31:13,479
And for me, here, the question is,
What type of RAG model to apply here?

551
00:31:13,789 --> 00:31:18,259
Graph RAG is probably not appropriate
here, but maybe RAG with re ranking is.

552
00:31:18,289 --> 00:31:22,429
So there's going to be some time on my
part to do a little bit deeper dives into

553
00:31:22,429 --> 00:31:26,619
the different RAG models and to talk to
some people in my company and get some

554
00:31:26,619 --> 00:31:27,909
feedback and then just see what works.

555
00:31:28,409 --> 00:31:29,819
Try it out, see what happens.

556
00:31:30,319 --> 00:31:34,249
Now, we're almost at the end of the
presentation, but before we wrap

557
00:31:34,249 --> 00:31:37,219
everything up, I would like to share
with you four things I think you

558
00:31:37,219 --> 00:31:40,469
should keep in mind if you ever find
yourself in a situation like mine.

559
00:31:40,969 --> 00:31:45,349
So first, find the problems to
solve that are repetitive, error

560
00:31:45,349 --> 00:31:46,949
prone, or mentally draining.

561
00:31:47,269 --> 00:31:51,549
You would be surprised what alleviating
tasks like that can do for yourself or for

562
00:31:51,549 --> 00:31:53,559
someone else's well being on a project.

563
00:31:54,099 --> 00:31:58,369
Second, if others will be using your
solution, don't assume they can do what

564
00:31:58,369 --> 00:32:00,559
you can do or even that they want to.

565
00:32:00,949 --> 00:32:05,139
and this is something I think it's
pretty innate to UXers, just because

566
00:32:05,139 --> 00:32:09,059
of, The problems we have to solve,
but, helping others sometimes

567
00:32:09,059 --> 00:32:10,789
means meeting them on their level.

568
00:32:11,149 --> 00:32:14,509
like I said, while it's common for
UXers to have that viewpoint, I

569
00:32:14,529 --> 00:32:17,559
think in general, it could extend
well to all creative and building.

570
00:32:18,059 --> 00:32:20,969
third, know when to
step back from an idea.

571
00:32:21,289 --> 00:32:24,879
So an idea might seem good or
sound interesting, but it may

572
00:32:24,879 --> 00:32:28,249
not meet the greatest need, or it
may take way longer to implement

573
00:32:28,249 --> 00:32:29,789
than the time you have to spare.

574
00:32:30,354 --> 00:32:33,534
And if you have to step back, there's
nothing wrong with doing this.

575
00:32:33,584 --> 00:32:37,194
Sometimes it's just a sign that now
is not the right time for your idea.

576
00:32:37,694 --> 00:32:40,764
And then finally, don't let
a lack of support stop you

577
00:32:40,764 --> 00:32:41,974
from building something out.

578
00:32:42,414 --> 00:32:46,464
Sometimes you won't get the support
you need to bring the best version of

579
00:32:46,464 --> 00:32:48,464
your idea to life, and that's okay.

580
00:32:48,794 --> 00:32:51,664
Just adapt it within the
constraints you face if you can.

581
00:32:52,014 --> 00:32:53,604
and show that off to others.

582
00:32:53,654 --> 00:32:57,324
And when people see the value in
it, use them and their excitement to

583
00:32:57,324 --> 00:33:01,594
help you get the support you need to
make improvements for your vision.

584
00:33:02,094 --> 00:33:04,834
So with that, we've reached
the end of my presentation.

585
00:33:05,184 --> 00:33:08,274
If you've stuck with me to the end, I
want you to know that I appreciate you.

586
00:33:08,454 --> 00:33:10,434
So thank you for spending
your time with me today.

587
00:33:10,704 --> 00:33:11,084
Bye.

