1
00:00:00,039 --> 00:00:00,669
Hello everyone.

2
00:00:00,739 --> 00:00:01,670
my name is Mi Panda.

3
00:00:01,859 --> 00:00:05,250
and today, I'll be presenting an
interesting topic, which is how should we

4
00:00:05,250 --> 00:00:08,080
think of scaling, ai, with large models.

5
00:00:08,450 --> 00:00:11,970
as you see, since the advent of,
charge G PT in November, 2022, there

6
00:00:11,970 --> 00:00:15,240
has been a lot of disruption that is
happening in the field of generative ai.

7
00:00:15,270 --> 00:00:16,530
And, we see every week.

8
00:00:17,100 --> 00:00:21,810
We see a new sophisticated models, now
key for us and key for some executives,

9
00:00:21,900 --> 00:00:25,440
key for the executives is how can
they leverage large model, what the

10
00:00:25,440 --> 00:00:28,980
ecosystems should look like, what the
architecture archetypes would look like,

11
00:00:28,980 --> 00:00:32,080
and what the infrastructure should be,
to make sure that now you'll be able

12
00:00:32,080 --> 00:00:33,550
to scale the generative AI use cases.

13
00:00:34,050 --> 00:00:38,230
So from my experience, and I have
brought a, brought few content, but

14
00:00:38,260 --> 00:00:41,260
important is, what should be the key
design principles And to make it very

15
00:00:41,260 --> 00:00:45,280
simple, if we want to enable generative
AI use cases at scale, of course the

16
00:00:45,280 --> 00:00:49,330
infrastructure has to be in the cloud
that the master to adapt, in any.

17
00:00:49,830 --> 00:00:51,330
And solving so many use cases.

18
00:00:51,409 --> 00:00:54,869
we are not talking about just billing
one chat, chat bot kind of use cases.

19
00:00:54,869 --> 00:00:55,469
It's throughout.

20
00:00:55,849 --> 00:00:59,149
Building a whole in a portfolio
of generative age cases

21
00:00:59,149 --> 00:01:00,199
across the organizations.

22
00:01:00,499 --> 00:01:02,239
So fast design principle is flexibility.

23
00:01:02,239 --> 00:01:05,799
So making sure that know your design
principle, architecture design must

24
00:01:05,799 --> 00:01:09,739
be flexible enough, because, as I
mentioned, know we have new large

25
00:01:09,739 --> 00:01:11,179
language models coming up every week.

26
00:01:11,509 --> 00:01:13,819
So making sure that you
are is, you are not locked.

27
00:01:14,119 --> 00:01:15,529
Your architecture must be flexible.

28
00:01:15,799 --> 00:01:16,699
Second is scalable.

29
00:01:16,789 --> 00:01:20,659
There's no denial fact that no,
you have, your architecture must

30
00:01:20,659 --> 00:01:24,549
be solid, to, Basically support
the scaling scalability of it.

31
00:01:24,549 --> 00:01:27,909
And so cloud, definitely the cloud
and elastic scaling and hosting,

32
00:01:28,209 --> 00:01:30,669
leveraging the cloud, capabilities,
and you can achieve that.

33
00:01:31,599 --> 00:01:33,219
The third is the security piece of it.

34
00:01:33,279 --> 00:01:36,169
Security is very important and
as we know that, the privacy and

35
00:01:36,169 --> 00:01:37,979
security, and is very important.

36
00:01:38,009 --> 00:01:41,769
And when we try to scale on gene use
cases, and the final is monitoring.

37
00:01:41,819 --> 00:01:45,509
we always leverage some tools,
but making sure that we have the

38
00:01:45,509 --> 00:01:47,079
right reward, on the monitoring of.

39
00:01:47,619 --> 00:01:48,789
Generative AI use cases.

40
00:01:49,289 --> 00:01:52,589
Now, when you look at, the AI driven
ecosystems on the architecting

41
00:01:52,619 --> 00:01:54,119
AI driven ecosystems, we,

42
00:01:54,619 --> 00:01:56,029
infrastructure is really important.

43
00:01:56,529 --> 00:01:59,259
and this is where, we have the
compute, you have the storage,

44
00:01:59,259 --> 00:02:01,839
you have the network, the
monitoring, provisioning, et cetera.

45
00:02:02,149 --> 00:02:07,629
and for the gene DBA applications, we
have GPU, is really important to drive

46
00:02:08,049 --> 00:02:11,859
and to train a large models and to
drive that kind of applications, right?

47
00:02:12,564 --> 00:02:15,814
The next is the data management
engineering, which, I mean we have been

48
00:02:15,814 --> 00:02:19,874
doing this since the traditional machine
learning and AI side of it where we

49
00:02:19,874 --> 00:02:23,174
need to integrate with various source
systems, acquire the data, and just

50
00:02:23,534 --> 00:02:26,494
store, and making sure that we have
the right data governance piece of it.

51
00:02:27,214 --> 00:02:29,884
Then we go to the analytics platform
side of it, which is the number third

52
00:02:29,884 --> 00:02:31,114
bucket as you see a third layer.

53
00:02:31,894 --> 00:02:35,644
And which is when we build the models,
we solve the model, we train the model,

54
00:02:35,644 --> 00:02:39,514
we test the model, et cetera, and then
we go to the modern software platform.

55
00:02:39,514 --> 00:02:42,564
So what modern software platforms,
talks about is our architecture

56
00:02:42,564 --> 00:02:46,434
designed for real time or event
driven or microservices, and making

57
00:02:46,434 --> 00:02:49,494
sure that how AI can be embedded
into various business processes.

58
00:02:49,794 --> 00:02:51,684
We are working in FinTech,
we are working in healthcare.

59
00:02:51,684 --> 00:02:55,314
We are working in pharmaceutical,
irrespective, making sure that no AI is

60
00:02:55,314 --> 00:02:56,724
embedded into various business processes.

61
00:02:56,889 --> 00:02:58,119
To drive value.

62
00:02:58,509 --> 00:03:01,299
And the finally number five point
is the digital channels and the

63
00:03:01,299 --> 00:03:02,469
experience of the modalities.

64
00:03:02,469 --> 00:03:04,329
And this is where you
have mobile, your wave.

65
00:03:04,389 --> 00:03:05,739
We have wearable devices.

66
00:03:06,009 --> 00:03:07,539
If you're working in the healthcare
industry, you know you have

67
00:03:07,539 --> 00:03:10,714
wearable device and the data
you are getting, you're going to

68
00:03:10,714 --> 00:03:11,609
connect with various source systems.

69
00:03:12,109 --> 00:03:15,109
Integrate with your platform
and the seventh, the security.

70
00:03:15,109 --> 00:03:16,249
Security is really important.

71
00:03:16,709 --> 00:03:19,049
and as you see here, seventh,
it's vertically caught across

72
00:03:19,049 --> 00:03:20,069
in all the channels here.

73
00:03:20,279 --> 00:03:23,039
so make making sure that you have
the right privacy and security fast

74
00:03:23,039 --> 00:03:25,359
architecture, it's a kind of approach.

75
00:03:25,719 --> 00:03:28,419
You should not think that at the end
it should happen from the beginning

76
00:03:28,419 --> 00:03:29,649
of your architecture transcript.

77
00:03:30,149 --> 00:03:31,889
Now to deep dive here.

78
00:03:31,999 --> 00:03:35,709
this is what kind of, again, this is
an illustrative, but if you see here,

79
00:03:35,709 --> 00:03:38,449
number one, infrastructure on the
bottom side of it, bottom part of it

80
00:03:38,449 --> 00:03:41,929
where we have, we are leveraging cloud
and distributor computing, moving away

81
00:03:41,929 --> 00:03:44,079
from on-prem to, now cloud and then.

82
00:03:44,679 --> 00:03:45,909
Multi-cloud approach as well.

83
00:03:45,939 --> 00:03:50,349
this is when we leverage GPU, GPH
service as well, the serverless

84
00:03:50,349 --> 00:03:54,009
storage, scalable storage,
infrastructure provision, et cetera.

85
00:03:54,519 --> 00:03:56,499
Then we go to the data management
engineering side of it.

86
00:03:56,499 --> 00:03:58,309
Now, this is where, we ingest the data.

87
00:03:58,309 --> 00:04:03,699
We capture, the batch or the real time
change, our CDC, we transform the data.

88
00:04:03,759 --> 00:04:05,799
We make sure that we apply
the data quality tools.

89
00:04:06,259 --> 00:04:09,529
and then for the generative bi, I'll just
focus on the generative BI component here.

90
00:04:10,264 --> 00:04:13,434
And back database is very important
here in, second layer, which is

91
00:04:13,434 --> 00:04:14,664
the data management engineering.

92
00:04:14,664 --> 00:04:19,064
this is when we, leverage the semantic
power of back database, right?

93
00:04:19,564 --> 00:04:21,209
On the LLM side of it.

94
00:04:21,229 --> 00:04:21,529
We have.

95
00:04:22,029 --> 00:04:26,109
Open source, LLM, we have close, l
lms, but making sure that no, based

96
00:04:26,109 --> 00:04:30,509
on your use case, you are, leveraging
the right, large model and make sure

97
00:04:30,509 --> 00:04:31,829
that no, you're also evaluating right.

98
00:04:31,829 --> 00:04:33,929
The selection of LLM
is happening correctly.

99
00:04:34,449 --> 00:04:36,669
then model serving LLM
inference is really important.

100
00:04:36,769 --> 00:04:37,669
and this is where.

101
00:04:38,129 --> 00:04:41,439
it depends again on the use
case that how much, latency that

102
00:04:41,619 --> 00:04:43,179
you need is really important.

103
00:04:43,179 --> 00:04:45,579
And finally, the final layer is
the AI application and software.

104
00:04:46,119 --> 00:04:47,469
And then finally, digital channels.

105
00:04:47,469 --> 00:04:51,129
It's been a view of and how all the
layers are stacked together, how

106
00:04:51,129 --> 00:04:53,979
your ecosystems should be together
and the options that you have.

107
00:04:54,479 --> 00:04:56,904
Now what are the kind of strategy
foundational choices we should be

108
00:04:56,904 --> 00:04:59,394
thinking on generative AI building blocks?

109
00:04:59,394 --> 00:05:02,004
Again, going back to the
six layers that, I defined,

110
00:05:02,104 --> 00:05:03,514
earlier, was the infrastructure.

111
00:05:03,514 --> 00:05:04,589
So we have a lot of choices, right?

112
00:05:04,654 --> 00:05:08,304
We have single cloud, we have
multi-cloud, we have, SaaS, there

113
00:05:08,424 --> 00:05:12,334
a lot of infrastructure, Nvidia,
these infrastructure, the services

114
00:05:12,514 --> 00:05:13,624
also going to very important.

115
00:05:13,754 --> 00:05:14,804
and it's coming up as well.

116
00:05:15,104 --> 00:05:16,874
Second is the vector
databases, and vector.

117
00:05:17,384 --> 00:05:21,674
We have open source and we have an A
paid such as spine cone on EV eight.

118
00:05:21,724 --> 00:05:24,394
there are a lot of enterprise level
vector storage or application level.

119
00:05:24,944 --> 00:05:25,904
and so on and so forth.

120
00:05:26,404 --> 00:05:30,194
Maybe a database, approach,
to please ensure that, make

121
00:05:30,194 --> 00:05:32,564
sure that your architectures
are really flexible and solid.

122
00:05:33,104 --> 00:05:34,154
Then LLM selection and I again.

123
00:05:34,754 --> 00:05:38,114
going back to the, my previous, what
I just mentioned, making sure that you

124
00:05:38,114 --> 00:05:41,564
are choosing the, you are selecting the
right large language metal model for

125
00:05:41,564 --> 00:05:45,374
your generated via applications and then
the ML lops or LLM ops platforms, right?

126
00:05:45,434 --> 00:05:45,734
Uh.

127
00:05:46,624 --> 00:05:48,394
you can leverage, definitely open source.

128
00:05:48,394 --> 00:05:52,074
You can go and bring the
best of breed, kind of niche.

129
00:05:52,464 --> 00:05:54,924
There are a lot of penalties
available in this market.

130
00:05:54,984 --> 00:05:57,474
and finally, multi-cloud
architecture on General bi, right?

131
00:05:57,474 --> 00:05:59,164
it's, it's a no brainer.

132
00:05:59,294 --> 00:06:02,474
and the adoption of multi-cloud
that know is happening these days

133
00:06:02,474 --> 00:06:03,614
and which will continue to happen.

134
00:06:04,074 --> 00:06:07,654
and, I have, sold various clients and on
their regenerative billing, generative

135
00:06:07,654 --> 00:06:09,694
applications, leveraging multi-cloud.

136
00:06:10,194 --> 00:06:10,914
So that's it.

137
00:06:11,014 --> 00:06:15,514
as that large language model, unstructured
data is a fuel of, large language model.

138
00:06:15,614 --> 00:06:18,974
but if you look at the traditional
last 30, 40 years in the industry,

139
00:06:18,974 --> 00:06:23,744
you, we did not pay a lot of attention
or we did not apply the same regard

140
00:06:23,744 --> 00:06:25,334
to unstructured data management.

141
00:06:25,664 --> 00:06:27,405
Then we provided to
structured data manage.

142
00:06:27,410 --> 00:06:28,454
And this is very obvious, right?

143
00:06:28,514 --> 00:06:31,574
It is very obvious and
I still believe that.

144
00:06:31,574 --> 00:06:33,734
Now there are three key data
management challenges here, right?

145
00:06:33,764 --> 00:06:34,244
One is.

146
00:06:34,744 --> 00:06:35,734
Units within the farm.

147
00:06:36,364 --> 00:06:36,514
The

148
00:06:37,014 --> 00:06:38,994
second is in the storage
piece of it, right?

149
00:06:39,044 --> 00:06:42,284
And making sure that you have the right
governance in the storage practices.

150
00:06:42,554 --> 00:06:44,444
It should not be sitting in
your email or it should not be

151
00:06:44,444 --> 00:06:45,584
sitting on your hard drive, right?

152
00:06:45,584 --> 00:06:48,324
It should be in a centralized
and must be level correctly.

153
00:06:48,834 --> 00:06:52,219
And then extracting and physical
ETL side a it, making sure that you

154
00:06:52,219 --> 00:06:54,669
have the right data pipelines with
the right governance, strategy.

155
00:06:55,029 --> 00:06:58,869
This when you'll be able to real leverage
the power of the unstructured data

156
00:06:58,869 --> 00:07:01,089
to drive your generated AI use cases.

157
00:07:01,589 --> 00:07:04,259
Now look, and there are certain
difficulties in building an operational

158
00:07:04,259 --> 00:07:05,909
generative use cases as well, right?

159
00:07:05,989 --> 00:07:08,299
the typical a ML project,
and we already know that.

160
00:07:08,359 --> 00:07:11,269
But in terms of technical
challenges, definitely you see

161
00:07:11,269 --> 00:07:12,589
hallucinated in adjustments, right?

162
00:07:12,959 --> 00:07:15,839
but again, there are certain
techniques that we must adopt,

163
00:07:15,889 --> 00:07:16,854
to reduce the hallucinations.

164
00:07:17,669 --> 00:07:21,849
your ML ops, you have, databases, video
databases, you have cyber security risk,

165
00:07:22,239 --> 00:07:25,469
you have diverse data, improves, and
then you have scalability challenges

166
00:07:25,469 --> 00:07:26,729
and deployment challenges as well.

167
00:07:27,099 --> 00:07:30,389
and making sure that you have the
right, key, ecosystems, or right.

168
00:07:30,389 --> 00:07:33,669
Flexible architecture, in terms of to
deal with the technical challenges.

169
00:07:33,669 --> 00:07:34,959
In terms of the operational challenges.

170
00:07:34,959 --> 00:07:36,549
And we already know that now because.

171
00:07:37,239 --> 00:07:39,639
Ey, user interface and user
expense is very important.

172
00:07:39,819 --> 00:07:42,199
We, if we are building
generative AI applications, it

173
00:07:42,199 --> 00:07:43,579
should have the right roadmap.

174
00:07:44,069 --> 00:07:45,819
and then, also right talent strategy.

175
00:07:45,819 --> 00:07:47,289
And there's going to be
another conversations.

176
00:07:47,289 --> 00:07:50,079
And if you look at ations now,

177
00:07:50,579 --> 00:07:55,469
again, going back to the tech stack and
the architecture, It is very high level.

178
00:07:55,469 --> 00:07:58,759
Again, this is illustrative, but I'll
really emphasize on six key elements.

179
00:07:58,760 --> 00:08:01,429
as we think of one is generative
tech stack, and then data and

180
00:08:01,429 --> 00:08:02,419
infrastructure side of it.

181
00:08:02,939 --> 00:08:05,380
as you see the first, three,
architecture elements, which is

182
00:08:05,380 --> 00:08:08,620
the large language models, then
embeddings and the back database.

183
00:08:08,730 --> 00:08:11,800
these are really important, and,
And what should be your decisioning

184
00:08:11,800 --> 00:08:15,260
criteria, to choose LLMs or the
embeddings or the Vector database?

185
00:08:15,850 --> 00:08:18,760
now to choose the large model
and embeddings, definitely

186
00:08:18,760 --> 00:08:19,930
it's capabilities, right?

187
00:08:20,140 --> 00:08:22,930
it is not just one large model
is going to cover or solve

188
00:08:22,930 --> 00:08:24,310
all kind of use cases for you.

189
00:08:24,790 --> 00:08:27,340
So making sure that you have
to understand the capabilities.

190
00:08:27,370 --> 00:08:28,900
The second, the security aspect of it.

191
00:08:29,440 --> 00:08:30,790
The third is an ease of use.

192
00:08:30,890 --> 00:08:33,110
and the fourth is also
multilingual capabilities that

193
00:08:33,110 --> 00:08:33,890
also you need to think of.

194
00:08:34,880 --> 00:08:37,760
In terms of the back door database,
again, we go with the latency, the

195
00:08:37,760 --> 00:08:41,360
performance and scalability side of
it, flexibility and then availability.

196
00:08:41,390 --> 00:08:45,270
Not all the back door database is
available in every cloud, but making sure

197
00:08:45,270 --> 00:08:48,600
that you understand that and what kind of
back door database would be appropriate

198
00:08:48,600 --> 00:08:50,100
for your organizations and also cost.

199
00:08:50,155 --> 00:08:51,205
Cost is very important.

200
00:08:51,385 --> 00:08:53,545
then in terms of infrastructure,
again, it is a very simple

201
00:08:53,545 --> 00:08:55,075
platform hosting and data store.

202
00:08:55,175 --> 00:08:57,715
in terms of the platform,
again, we already know that.

203
00:08:58,215 --> 00:09:00,285
What should be your decision
for considerations again?

204
00:09:00,785 --> 00:09:01,715
It's a kind of a choice.

205
00:09:01,775 --> 00:09:04,875
We have, compliance with the security
team, the security norms of your

206
00:09:04,875 --> 00:09:08,925
organizations, and the scalability
to accommodate, new use cases, making

207
00:09:08,925 --> 00:09:12,575
sure that your platform and the
infrastructure is really robust, to

208
00:09:13,025 --> 00:09:15,275
help you accelerate various use cases.

209
00:09:15,775 --> 00:09:17,935
Now just a, you a couple
of examples in here.

210
00:09:18,005 --> 00:09:21,455
it's very, intuitive to understand,
and how it fits together.

211
00:09:22,065 --> 00:09:25,335
those six elements, so we have bunch
of documents on structured data.

212
00:09:25,335 --> 00:09:28,515
Then we chunk, we provide
a chunking strategy.

213
00:09:28,515 --> 00:09:31,995
We just create chunks or divide
into chunks, and then we embed

214
00:09:31,995 --> 00:09:33,255
and load into vector databases.

215
00:09:33,255 --> 00:09:34,485
This is very simple, right?

216
00:09:34,885 --> 00:09:37,615
and both metadata and document
embedding are prepared here.

217
00:09:37,615 --> 00:09:40,015
And, then we get loaded
into vector databases.

218
00:09:40,015 --> 00:09:40,165
There.

219
00:09:40,665 --> 00:09:44,480
And then in, in your architecture,
basically, when user query comes,

220
00:09:44,480 --> 00:09:48,060
then again, we send it to the LLM and
the LLM kind of refrige, making sure

221
00:09:48,060 --> 00:09:51,270
that gets again, embedded using the
same embedding technique, which we,

222
00:09:51,700 --> 00:09:53,590
passed to load into Vector database.

223
00:09:53,890 --> 00:09:56,290
And then the similarity of
the semantic search happens,

224
00:09:56,510 --> 00:09:57,590
against the Vector database.

225
00:09:57,590 --> 00:09:58,040
Then it.

226
00:09:58,475 --> 00:10:02,705
You get retried in a top or three or top
five or top kind of retried documents.

227
00:10:03,045 --> 00:10:07,015
and then, basically it gets
fed into the LLM and then you

228
00:10:07,015 --> 00:10:08,335
get the right answer, right?

229
00:10:08,435 --> 00:10:11,565
this is just a very basic
knife, approach of a rag re

230
00:10:11,865 --> 00:10:13,065
augment generated applications.

231
00:10:13,065 --> 00:10:15,070
So there is more panel I'll end off.

232
00:10:15,570 --> 00:10:19,460
giving this last piece here, that
if you wanna scale your generative

233
00:10:19,460 --> 00:10:21,430
use cases, so your delivery team.

234
00:10:22,000 --> 00:10:25,640
Most of the right, capabilities,
starting from your use case definitions,

235
00:10:25,640 --> 00:10:28,880
making sure that you have the, you
are defining the use case properly.

236
00:10:28,930 --> 00:10:31,210
you are identifying the, what
the KPIs should look like.

237
00:10:31,570 --> 00:10:32,980
How would you measure the performance?

238
00:10:33,030 --> 00:10:34,230
how do you measure the KPIs?

239
00:10:34,230 --> 00:10:35,040
This is very important.

240
00:10:35,040 --> 00:10:36,360
What are the value you're
going to get out of it?

241
00:10:36,840 --> 00:10:38,715
The second is the definitely
discovery part of it.

242
00:10:38,745 --> 00:10:42,090
What kind of data is necessary to
enable that particular use cases?

243
00:10:42,620 --> 00:10:44,480
And then the, then third
is the setup, right?

244
00:10:44,540 --> 00:10:45,560
Do you have the right infrastructure?

245
00:10:45,560 --> 00:10:46,700
Did you choose the right LLM?

246
00:10:46,700 --> 00:10:49,760
Did you choose the right factor,
database, et cetera, et cetera.

247
00:10:50,270 --> 00:10:53,480
And then you start getting into the
development piece of it, and then making

248
00:10:53,480 --> 00:10:57,860
sure that you are designing the UI and
UX and developing the UI perfectly.

249
00:10:58,000 --> 00:11:02,030
your backend is correct, making sure that
it is modular and flexible architecture,

250
00:11:02,120 --> 00:11:04,700
leveraging content, relations of
principles and the techniques.

251
00:11:05,180 --> 00:11:06,680
Then you move to the
deployment and monitoring.

252
00:11:07,370 --> 00:11:09,350
And then finally application
maintenance and support.

253
00:11:09,380 --> 00:11:12,920
Now, in terms of the key resources,
definitely, we need data engineering

254
00:11:13,040 --> 00:11:17,530
team, data science, data engineers,
data scientist, LLM ops or ML ops,

255
00:11:17,530 --> 00:11:18,700
or DataOps, whatever you call it.

256
00:11:18,830 --> 00:11:19,940
ML engineers.

257
00:11:20,000 --> 00:11:24,840
then, product owner, product managers,
site reliability engineers, UX developers.

258
00:11:24,930 --> 00:11:27,680
So it's across, starting from
the use case definitions.

259
00:11:28,180 --> 00:11:33,250
From discovery to design, to development,
to deployment, to maintenance and support.

260
00:11:33,750 --> 00:11:35,590
that's all about this, presentations.

261
00:11:35,590 --> 00:11:38,290
And I hope, this is very
short and hope, you like the

262
00:11:38,290 --> 00:11:39,970
conversa, like the presentation.

263
00:11:40,150 --> 00:11:40,840
Thank you very much.

264
00:11:40,840 --> 00:11:40,870
I.

