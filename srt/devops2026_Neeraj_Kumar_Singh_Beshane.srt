1
00:00:00,570 --> 00:00:00,990
Speaker 23: Hello.

2
00:00:01,260 --> 00:00:01,740
Good morning.

3
00:00:01,740 --> 00:00:03,300
Good afternoon everyone.

4
00:00:03,630 --> 00:00:05,430
Thank you for tuning in for the talk.

5
00:00:05,930 --> 00:00:10,820
I wanted to talk about something that
probably keep a lot of us up at night.

6
00:00:11,419 --> 00:00:16,190
Our CACD pipeline, we have spent
the last decade perfecting them.

7
00:00:16,460 --> 00:00:17,985
We have got them deterministic.

8
00:00:18,165 --> 00:00:19,345
We have got them fast.

9
00:00:19,565 --> 00:00:25,385
We have gotten them reliable, and now
we have got a new variable in the mix.

10
00:00:25,885 --> 00:00:29,185
The big question isn't
just how do we use it?

11
00:00:29,575 --> 00:00:34,974
How do we actually make AI work in our
pipelines without breaking everything?

12
00:00:35,754 --> 00:00:38,965
Because right now I see a lot of
teams trying to figure that out,

13
00:00:38,965 --> 00:00:40,675
and honestly, it's terrifying.

14
00:00:41,215 --> 00:00:45,894
You have a non-deterministic,
probabilistic agent trying to control

15
00:00:45,985 --> 00:00:48,205
a deterministic infrastructure.

16
00:00:48,265 --> 00:00:49,855
It's like oil and water.

17
00:00:50,150 --> 00:00:50,980
Let's figure that out.

18
00:00:51,480 --> 00:00:55,140
So why am I spending time on this top?

19
00:00:55,800 --> 00:00:57,510
Why involving you in this journey?

20
00:00:58,290 --> 00:01:02,190
For the last decade and a half,
I have been the guy getting the

21
00:01:02,190 --> 00:01:03,960
calls when production goes down.

22
00:01:04,530 --> 00:01:10,965
I started my career in an I ages of
ops debugging, dash being print jobs.

23
00:01:11,465 --> 00:01:15,965
COBOL scripts have lived through
every shift, starting from the

24
00:01:16,535 --> 00:01:18,525
manual batch script to puppet.

25
00:01:18,630 --> 00:01:22,735
From VM to Kubernetes, I build
infrastructure at Meta where

26
00:01:22,740 --> 00:01:26,420
I learned the religion of move
fast, especially at scale.

27
00:01:26,920 --> 00:01:33,040
I saw what happens when you out
thousands of engineers to deploy.

28
00:01:33,700 --> 00:01:39,080
Constant code has scaled platforms
at Wayfair, handling millions of

29
00:01:39,080 --> 00:01:43,100
requests where every millisecond
count, every millisecond is a dollar.

30
00:01:43,600 --> 00:01:48,730
I safeguarded high value transactions
at JP Morgan Chase and AM American

31
00:01:48,730 --> 00:01:51,215
Express, where the rule was never failed.

32
00:01:51,905 --> 00:01:59,485
I learned the cost of caution and
necessity of absolute pressure, why my

33
00:01:59,485 --> 00:02:04,705
whole career has been one long argument
between speed and safety, and now with

34
00:02:04,945 --> 00:02:07,165
generative AI entering the ops world.

35
00:02:07,665 --> 00:02:09,675
The augment is getting even more louder.

36
00:02:10,175 --> 00:02:11,765
Why is this relevant right now?

37
00:02:12,305 --> 00:02:14,765
Because we are at a tipping point.

38
00:02:15,365 --> 00:02:17,825
Every tool vendor is selling AI ops.

39
00:02:17,885 --> 00:02:23,045
Every CIO wants gen AI integration,
but nobody talks about the

40
00:02:23,285 --> 00:02:25,355
governance required to make it safer.

41
00:02:25,855 --> 00:02:32,755
I want to share this car, but I collected
and the solutions that I have built, so

42
00:02:32,755 --> 00:02:34,525
you don't have to learn the hard way.

43
00:02:35,025 --> 00:02:36,345
Gen is how I propose.

44
00:02:36,845 --> 00:02:42,155
We settle the argument between
speed and safety one and for all.

45
00:02:42,655 --> 00:02:45,475
So let's look at the industry right now.

46
00:02:45,655 --> 00:02:47,245
It's a bit of a paradox.

47
00:02:47,745 --> 00:02:49,845
On the left, you see the promises.

48
00:02:50,385 --> 00:02:54,075
McKenzie report says 88% adoption.

49
00:02:54,575 --> 00:02:56,000
This is how many of us are.

50
00:02:56,500 --> 00:02:58,000
Deploying AI right now.

51
00:02:58,210 --> 00:03:05,520
Not piloting, not testing, deploying ai
right now, we are all changing that 55%

52
00:03:05,520 --> 00:03:12,070
productivity boost that the benchmark as
a benchmark that co-pilot had promised us.

53
00:03:12,610 --> 00:03:13,690
We want the speed.

54
00:03:13,780 --> 00:03:17,530
We want to ship features
before our coffee gets cold.

55
00:03:18,130 --> 00:03:20,345
But look at the right side, the price.

56
00:03:20,845 --> 00:03:23,410
It goes to $13,000 per minute.

57
00:03:24,010 --> 00:03:29,340
That's the average cost of a
production outage today or 2,100 hours.

58
00:03:29,840 --> 00:03:32,375
That's just the recorded diamond plan.

59
00:03:32,895 --> 00:03:37,490
Downtime of a major
platform like Jira in 2024.

60
00:03:38,420 --> 00:03:39,500
And here is the number.

61
00:03:39,500 --> 00:03:41,375
That's case me 7.2%.

62
00:03:42,305 --> 00:03:47,645
The Dora report of 2024 says that
there is a drop in delivery stability

63
00:03:47,645 --> 00:03:49,655
for the teams rushing to adopt ai.

64
00:03:50,155 --> 00:03:50,935
Think about that.

65
00:03:51,295 --> 00:03:56,965
We are coding 55% faster, but we are
breaking production 7% more often.

66
00:03:57,465 --> 00:04:01,265
We are driving a faster car,
but we have taken off the seat

67
00:04:01,265 --> 00:04:03,335
belts and the reason is simple.

68
00:04:03,395 --> 00:04:09,785
We are trying to fit unpredictable
random agents into the pipelines

69
00:04:10,085 --> 00:04:12,995
designed for a predictable binary logic.

70
00:04:13,495 --> 00:04:18,835
This slide captures most, most
of the things especially the

71
00:04:18,835 --> 00:04:20,335
deadlock we are currently in.

72
00:04:20,835 --> 00:04:25,905
This isn't just a technical problem, it's
an existential one for DevOps at least.

73
00:04:26,595 --> 00:04:28,725
The first one is unpredictability.

74
00:04:29,225 --> 00:04:33,875
Let me walk you through an example
running a bad script today.

75
00:04:34,235 --> 00:04:36,905
Exit code zero means successful tomorrow.

76
00:04:36,965 --> 00:04:38,975
Running the same bad script.

77
00:04:39,095 --> 00:04:43,720
Exit code zero means still
successful six months from now.

78
00:04:43,780 --> 00:04:45,055
It is still successful.

79
00:04:45,115 --> 00:04:47,425
Exit core, zero means successful.

80
00:04:48,295 --> 00:04:52,605
But if you ask LLM to
optimize the Docker file.

81
00:04:53,295 --> 00:04:58,095
Three times, fingers crossed, you
get three different qua files.

82
00:04:58,635 --> 00:05:04,655
And in CACD pipeline variance isn't
a feature, it's a bug, it's a noise.

83
00:05:05,155 --> 00:05:08,095
The next is the dis disruption.

84
00:05:08,595 --> 00:05:10,245
Then human makes a mistake.

85
00:05:10,815 --> 00:05:14,910
They usually break a feature,
maybe add to card button, click.

86
00:05:15,410 --> 00:05:16,760
But when an AI makes a mistake.

87
00:05:17,555 --> 00:05:23,005
Especially with an infrastructure access,
it doesn't just break the feature,

88
00:05:23,455 --> 00:05:25,405
it demolishes the whole platform.

89
00:05:25,905 --> 00:05:28,095
I seen this happen firsthand.

90
00:05:28,595 --> 00:05:33,935
I was an AI agent originating
a Terraform resource division.

91
00:05:34,085 --> 00:05:38,585
It just looked at a legacy service and
authentication handler and decided that.

92
00:05:39,155 --> 00:05:42,635
It was unused because there
were no, any recent commits.

93
00:05:43,325 --> 00:05:44,555
It tried to delete it.

94
00:05:45,055 --> 00:05:48,330
That service authenticated
20 million users.

95
00:05:49,130 --> 00:05:55,675
That wasn't a bug, that was a potential
to regionwide outage waiting to happen.

96
00:05:56,245 --> 00:06:00,955
The only reason it doesn't, it
didn't happen is because we caught it

97
00:06:00,955 --> 00:06:03,915
manually, but that almost movement.

98
00:06:04,415 --> 00:06:05,675
Kept me up for a week.

99
00:06:06,175 --> 00:06:11,335
The rec, reconciliation,
speed, and safety.

100
00:06:11,835 --> 00:06:13,125
So we are stuck here.

101
00:06:13,125 --> 00:06:19,020
Security teams try to flip the block
switch because they are terrified.

102
00:06:19,710 --> 00:06:22,770
Developer find workaround
because they need speed.

103
00:06:23,270 --> 00:06:24,980
We need to break this standoff.

104
00:06:25,480 --> 00:06:27,580
So how do we do this?

105
00:06:27,970 --> 00:06:32,760
To fix this, we have a fundamental, we
have to have a fundamental change in

106
00:06:32,760 --> 00:06:35,700
our mental model of what, and AI is.

107
00:06:36,240 --> 00:06:41,270
On the left is a legacy ai which
most of us are be using, and I'm

108
00:06:41,270 --> 00:06:47,775
sure most of us have used it co-pilot
or co-piloting IPE or chat bots.

109
00:06:48,275 --> 00:06:49,410
It's an external helper.

110
00:06:49,980 --> 00:06:51,325
It has zero accountability.

111
00:06:51,465 --> 00:06:55,950
If the code it suggested breaks
the bill, you broke the bill.

112
00:06:56,070 --> 00:06:56,670
It's not the ai.

113
00:06:57,170 --> 00:07:01,580
It's a tool like a fancy spell
checker on the right where

114
00:07:02,080 --> 00:07:04,950
you need to go to generals.

115
00:07:05,370 --> 00:07:09,680
This is a model, basically a
set of system practices or a

116
00:07:09,680 --> 00:07:11,450
set of system principles that.

117
00:07:11,950 --> 00:07:14,910
I suggest it's a pipeline
actor, basically.

118
00:07:15,870 --> 00:07:20,340
It has a service account, it has
permissions, it triggers bill, it

119
00:07:20,340 --> 00:07:24,740
can apply code, it opens its own pr.

120
00:07:25,240 --> 00:07:30,435
I know it sounds terrifying, but
giving LLM as service account,

121
00:07:31,000 --> 00:07:32,950
giving it the key of the kingdom.

122
00:07:33,940 --> 00:07:34,780
But think about it.

123
00:07:35,280 --> 00:07:37,020
How do we onboard a junior engineer?

124
00:07:37,290 --> 00:07:42,450
We don't just give them a road access
on day one, we give them a sandbox.

125
00:07:43,440 --> 00:07:46,160
We give them, you review every pr.

126
00:07:46,730 --> 00:07:52,130
You don't let them deploy to production
on a Friday at a 5:00 PM without

127
00:07:52,130 --> 00:08:00,670
supervision, gen ops is simply applying
the same rigorous mentorship model.

128
00:08:00,730 --> 00:08:06,520
To our AI agents, we treat them as
employees that need supervision,

129
00:08:06,940 --> 00:08:12,830
not the tools that needs running
to through the supervision.

130
00:08:13,330 --> 00:08:15,550
I call it as four pillars of governance.

131
00:08:16,030 --> 00:08:21,480
Think of this as a distal nervous system
of the AI contextualization, which

132
00:08:21,480 --> 00:08:24,180
is basically a memory you use a rag.

133
00:08:24,680 --> 00:08:29,000
Not just for docs, but for build history.

134
00:08:29,500 --> 00:08:33,190
AI remembers every failure,
so it doesn't repeat it.

135
00:08:33,690 --> 00:08:37,560
It need to know how we do
things here on our earth.

136
00:08:38,060 --> 00:08:42,610
That is, we define the blast
radius of every change.

137
00:08:42,970 --> 00:08:46,120
High risk means stricter rules.

138
00:08:46,120 --> 00:08:47,110
We don't treat.

139
00:08:47,635 --> 00:08:48,445
It typo.

140
00:08:48,445 --> 00:08:52,335
The same as a database
migration can redeployment.

141
00:08:52,845 --> 00:08:54,675
We never trust the AI fully.

142
00:08:55,305 --> 00:08:58,515
We let it prove itself on a 1% traffic.

143
00:08:58,515 --> 00:08:58,995
First.

144
00:08:59,495 --> 00:09:01,105
Runtime assurance.

145
00:09:01,605 --> 00:09:06,275
We need an immutable auditory
three basically for every thought

146
00:09:06,275 --> 00:09:08,555
and every decision that AA makes.

147
00:09:09,055 --> 00:09:11,395
Now, let's get deeper into each of them.

148
00:09:11,895 --> 00:09:13,575
The context of air ingestion.

149
00:09:14,415 --> 00:09:16,275
This is basically a flow where

150
00:09:16,775 --> 00:09:18,575
we provide the context to ai.

151
00:09:18,665 --> 00:09:22,925
The biggest failure or the
biggest mode of failure for AI

152
00:09:22,925 --> 00:09:24,815
and DevOps, is it hallucination?

153
00:09:25,115 --> 00:09:26,525
It's a lack of context.

154
00:09:27,215 --> 00:09:32,975
How much of information do we provide and
how much of information can an EA use?

155
00:09:33,475 --> 00:09:39,235
When it comes up with its next token,
it doesn't know what, it doesn't

156
00:09:39,235 --> 00:09:45,945
know if you ask an AI to update the
payments, API, it uses its training data.

157
00:09:46,605 --> 00:09:52,800
Maybe the data that, that it was
trained in 2024 or 2025, it has no

158
00:09:52,800 --> 00:09:56,790
idea that you have already deprecated
the version to work at the last month.

159
00:09:57,290 --> 00:10:01,100
So we build a system that acts
like an organizational memory.

160
00:10:01,600 --> 00:10:09,640
We stack our extracts, build logs,
incidents, postmortem, incident

161
00:10:09,640 --> 00:10:12,490
postmortems, slack threads, outages.

162
00:10:12,940 --> 00:10:15,160
Basically we ize all of them.

163
00:10:15,845 --> 00:10:16,805
And when an AI.

164
00:10:17,305 --> 00:10:18,955
Prepares for deployment.

165
00:10:19,435 --> 00:10:20,695
We intercept the prompt.

166
00:10:20,935 --> 00:10:24,715
We inject the last 50 relevance build.

167
00:10:25,195 --> 00:10:27,535
We inject the current
infrastructure state.

168
00:10:27,955 --> 00:10:33,745
So AI isn't just guessing, it knows,
oh, last time someone tried to change

169
00:10:33,745 --> 00:10:35,725
this config, it caused a memory leak.

170
00:10:36,225 --> 00:10:41,115
We are effectively giving AI a
short-term memory to complement

171
00:10:41,205 --> 00:10:43,420
its long-term training data.

172
00:10:43,920 --> 00:10:50,900
This simple step eliminates about what
I call it as 95% of stupid errors.

173
00:10:51,400 --> 00:10:53,350
Now let's move on to the next pillar.

174
00:10:53,850 --> 00:10:57,980
Context helps, but it
doesn't guarantee safety.

175
00:10:58,340 --> 00:10:59,990
AI is still probabilistic.

176
00:11:00,740 --> 00:11:04,640
It can still take risk, so
we need strategic guardrails.

177
00:11:05,140 --> 00:11:07,780
We introduce a concept
called blast radius score.

178
00:11:08,380 --> 00:11:13,060
Before any code merges, we
analyze the dependency graph.

179
00:11:13,120 --> 00:11:19,590
We ask if the change falls, how
big of a crater does it form?

180
00:11:20,090 --> 00:11:22,750
Is it just a read me the blast?

181
00:11:22,750 --> 00:11:23,770
Radius is one.

182
00:11:24,270 --> 00:11:24,690
Go ahead.

183
00:11:24,920 --> 00:11:25,850
Automat the code.

184
00:11:26,350 --> 00:11:33,370
Are you changing a core authentication
library used by 50 other microservices?

185
00:11:33,370 --> 00:11:36,190
The blast rate says 90% block it.

186
00:11:36,190 --> 00:11:37,930
This requires human sign off.

187
00:11:38,430 --> 00:11:44,125
We map this to an something
we call it as an error budget.

188
00:11:44,755 --> 00:11:46,795
So what is an error budget?

189
00:11:47,295 --> 00:11:52,275
Your login service, that's the critical
path, has a very tiny error budget.

190
00:11:52,275 --> 00:11:53,205
Almost zero.

191
00:11:54,075 --> 00:11:55,155
Zero tolerance.

192
00:11:56,025 --> 00:11:58,005
The AI is on a thing.

193
00:11:58,605 --> 00:12:03,875
Lease your internal admin
tool like your Wiki pages.

194
00:12:04,325 --> 00:12:08,825
It has a huge error budget
outage of one hour or two hours.

195
00:12:08,915 --> 00:12:09,485
It's fine.

196
00:12:10,085 --> 00:12:13,345
They can experiment more freely and.

197
00:12:14,260 --> 00:12:21,250
To make this more deterministic, we use
open policy agent OPA to enforce this.

198
00:12:21,460 --> 00:12:25,270
The governance isn't a
PDF policy document here.

199
00:12:25,600 --> 00:12:30,800
It's a code, it's a Boolean gate,
basically pass or a fa now let's talk

200
00:12:30,960 --> 00:12:34,090
about the third pillar deployment.

201
00:12:34,590 --> 00:12:35,800
Most team use gallery.

202
00:12:36,195 --> 00:12:41,015
Okay, but they use the
canary in a very dumb way.

203
00:12:41,465 --> 00:12:45,575
They just time wait for five
minutes, increase the traffic by 10%.

204
00:12:46,075 --> 00:12:47,155
This is not engineering.

205
00:12:47,365 --> 00:12:48,595
This is basically a hope.

206
00:12:49,555 --> 00:12:51,535
Our canary is an SLO based.

207
00:12:51,655 --> 00:12:55,195
We deploy for 1% traffic, a tiny slice.

208
00:12:55,795 --> 00:12:58,075
The AI monitor its own rollout.

209
00:12:58,465 --> 00:13:00,505
It watches the latency error rate.

210
00:13:00,505 --> 00:13:00,925
CPU.

211
00:13:01,780 --> 00:13:04,210
Memory IO operations.

212
00:13:05,080 --> 00:13:10,270
If the latency drift by even two
standard deviations, the automatic

213
00:13:11,050 --> 00:13:12,670
rollback triggers instantly.

214
00:13:13,300 --> 00:13:15,880
We don't want a customer
to complain on a Twitter.

215
00:13:16,120 --> 00:13:19,060
We don't wait for a PagerDuty alert.

216
00:13:19,900 --> 00:13:24,820
The system kills the bad deployment
before human even wakes up.

217
00:13:25,320 --> 00:13:28,410
We are shifting from
a mean time to repair.

218
00:13:28,910 --> 00:13:31,040
To meantime of prevention.

219
00:13:31,540 --> 00:13:38,830
So the pillar four, which is governance,
and for all the security folks who tuned

220
00:13:38,830 --> 00:13:41,490
in, this is how you sleep at night better.

221
00:13:42,210 --> 00:13:48,845
In a traditional audit, who means the
person who call, who created the change

222
00:13:49,385 --> 00:13:52,170
in gen ops, who is a neural network model?

223
00:13:52,670 --> 00:13:55,820
That creates a complaints nightmare.

224
00:13:56,330 --> 00:13:59,380
So we built a centralized model registry.

225
00:13:59,980 --> 00:14:04,540
Every single line of a code, every
config change generated by an

226
00:14:04,630 --> 00:14:06,700
AI is cryptographically signed.

227
00:14:07,300 --> 00:14:09,670
We record the exact model version.

228
00:14:10,600 --> 00:14:18,970
Was it A GPT five, 5.1,
5.2, Florida 4.1, 4.5.

229
00:14:19,375 --> 00:14:24,555
The exact prompt that was used, the
context chunk that was injected, this

230
00:14:24,555 --> 00:14:26,745
creates an immutable audit trail.

231
00:14:27,585 --> 00:14:32,895
If a vulnerability appears six months
from now, I can run one single query,

232
00:14:32,895 --> 00:14:37,635
show me every service modified by Model X.

233
00:14:37,650 --> 00:14:43,475
Using the prompt wire, I can trace the
thought process of the infrastructure.

234
00:14:44,420 --> 00:14:50,480
Auditors are going to love this
because it actually makes more

235
00:14:50,480 --> 00:14:53,480
transparent than a human change.

236
00:14:53,980 --> 00:14:59,980
So this slide is the real
story, 55% faster cycle time.

237
00:15:00,480 --> 00:15:07,310
And I want to be clear, this isn't just
typing fast, this is removing friction.

238
00:15:08,000 --> 00:15:12,190
The AI handles the heavy lifting
config updates, the boiler plate

239
00:15:12,190 --> 00:15:14,579
test, the documentation sync.

240
00:15:15,079 --> 00:15:19,790
These are the things that drain your
senior engineer at Meta have built a tool

241
00:15:19,790 --> 00:15:27,079
that turned a multi-hour onboarding task
into a five minutes automated flow, saving

242
00:15:27,079 --> 00:15:30,980
95% of a reduction in operation overhead.

243
00:15:31,730 --> 00:15:36,500
This means that your senior engineers
stop being a Yammer or a Jason spearhead

244
00:15:36,500 --> 00:15:39,320
and start being an architect again.

245
00:15:39,820 --> 00:15:45,930
And the governance, because policy
is a code, it cannot be skipped.

246
00:15:46,430 --> 00:15:50,310
A tied engineer at a 2:00 AM
might choose to bypass a check.

247
00:15:50,930 --> 00:15:52,010
AI cannot everyone.

248
00:15:52,780 --> 00:15:54,820
Allows the zero incident.

249
00:15:55,240 --> 00:15:59,220
That's great, but look
at this number, 14.4%.

250
00:16:00,150 --> 00:16:02,010
This is the protection rate.

251
00:16:02,510 --> 00:16:09,500
14.4% of the times ai, despite of
all of context, prompt engineering

252
00:16:09,950 --> 00:16:11,840
tried to do something dangerous.

253
00:16:12,020 --> 00:16:15,415
He tried to push a change
that violated an SLA.

254
00:16:15,675 --> 00:16:18,950
He tried to merge a dependency
with the vulnerability.

255
00:16:19,450 --> 00:16:23,920
Without gen ops, this 14.4%
would have been an outage.

256
00:16:24,670 --> 00:16:28,660
They would have been panic, there
would have been revenue loss.

257
00:16:28,870 --> 00:16:33,790
Instead, they are just sitting in a
log saying that blocked by governance

258
00:16:33,790 --> 00:16:39,835
layer, the mechanism work, the immune
system that is built blocks the virus.

259
00:16:40,795 --> 00:16:41,635
This proves that.

260
00:16:42,025 --> 00:16:44,245
Safety and velocity are in opposite.

261
00:16:44,455 --> 00:16:51,065
The only reason we can move fast
is because we know it's safe.

262
00:16:51,565 --> 00:16:54,745
There is a safety net of 14.4%.

263
00:16:55,245 --> 00:17:00,274
Okay, so what are the next
set of frontiers to summarize?

264
00:17:00,964 --> 00:17:06,364
Why our current tool system isn't
enough Static code analysis.

265
00:17:06,864 --> 00:17:09,984
This is something that only
checks for the code addressed.

266
00:17:10,704 --> 00:17:14,634
It catches bad syntax, but
it misses the bad intent.

267
00:17:15,564 --> 00:17:22,474
It looks for SQL injection vulnerability,
but it doesn't look for an end point

268
00:17:22,474 --> 00:17:24,519
trying to delete the whole table.

269
00:17:25,019 --> 00:17:27,089
Anomaly detection is reactive.

270
00:17:27,359 --> 00:17:32,189
It tells you the house is on
fire after the smoke starts.

271
00:17:32,669 --> 00:17:34,199
Gen ops is proactive.

272
00:17:34,814 --> 00:17:37,424
We act at the moment of generation.

273
00:17:37,924 --> 00:17:42,364
We evaluate the intent of the change
before it even becomes a full request.

274
00:17:42,724 --> 00:17:47,129
We shift left past the bill, past the
commit, all the way to the thought.

275
00:17:47,629 --> 00:17:48,804
And this is the blueprint.

276
00:17:49,194 --> 00:17:54,494
It's a continuous learning loop
monitoring, basically the eyes

277
00:17:55,064 --> 00:18:00,304
we watch, the AI proposals,
the system state analysis.

278
00:18:00,604 --> 00:18:02,644
We run the blast radius calculation.

279
00:18:02,674 --> 00:18:09,304
We check the Policy Engine Act, which is
basically the, or the governance layer.

280
00:18:09,964 --> 00:18:12,334
We execute through a safety hardness.

281
00:18:12,589 --> 00:18:14,989
AI never touches the production directly.

282
00:18:15,769 --> 00:18:17,539
Learn the feedback.

283
00:18:17,989 --> 00:18:22,879
Every time we block that 14.4%,
we feed it back to the memory.

284
00:18:22,879 --> 00:18:26,559
The system learns from
its own near mistakes.

285
00:18:27,189 --> 00:18:30,489
It gets smarter on every failure.

286
00:18:30,989 --> 00:18:32,669
So we are getting close.

287
00:18:33,169 --> 00:18:35,310
If you live here with three things.

288
00:18:35,810 --> 00:18:37,370
Make them these three things.

289
00:18:37,870 --> 00:18:45,179
Governance, ai, AI as a pipeline actor,
and embracing closed loop systems.

290
00:18:45,679 --> 00:18:50,829
So when I say governance, when, let
me talk about an example, like breaks

291
00:18:50,829 --> 00:18:53,859
in a Formula One race aren't there?

292
00:18:53,859 --> 00:18:55,149
Just to make it slow.

293
00:18:55,929 --> 00:18:56,199
They're there.

294
00:18:56,699 --> 00:19:03,439
So that the driver can go 200 miles,
300 miles without any injuries.

295
00:19:03,939 --> 00:19:06,249
Governance gives the confidence to speed.

296
00:19:06,749 --> 00:19:09,029
The next is ai.

297
00:19:09,629 --> 00:19:12,384
Stop treating AI like a text editor.

298
00:19:12,714 --> 00:19:14,419
Treat it like a junior engineer.

299
00:19:14,479 --> 00:19:18,109
Give it a badge, give
it its limit and audit.

300
00:19:18,259 --> 00:19:18,649
Its well.

301
00:19:19,149 --> 00:19:24,840
Embraced closed loop system, the day
of fire and forget scripts are over.

302
00:19:25,320 --> 00:19:31,830
We need system that self monitor, self
correct, and learn from the mistakes.

303
00:19:32,330 --> 00:19:36,730
The future of DevOps isn't just
about deploying code faster,

304
00:19:36,820 --> 00:19:38,409
it's about deploying intelligent.

305
00:19:39,310 --> 00:19:40,240
Safer.

306
00:19:40,740 --> 00:19:43,260
We are building the nervous
system of the enterprise.

307
00:19:43,290 --> 00:19:47,580
Let's make sure that it has
a brain, not just reflexes.

308
00:19:48,060 --> 00:19:49,530
Thank you so much for your time.

309
00:19:50,280 --> 00:19:54,360
I love to hear your horror
stories, success stories in a

310
00:19:54,360 --> 00:19:56,820
chat comment, or on LinkedIn.

311
00:19:57,320 --> 00:19:59,590
Let's learn from each other.

312
00:20:00,100 --> 00:20:00,490
Take care.

313
00:20:00,520 --> 00:20:00,790
Thank you.

