1
00:00:00,210 --> 00:00:03,730
Today we're going to be talking about
scaling from zero to 25 million.

2
00:00:04,100 --> 00:00:04,930
My name is Josip.

3
00:00:05,170 --> 00:00:07,460
I'm the CTO at a company
called Sophoscore.

4
00:00:07,800 --> 00:00:13,139
And we do a live score app that
has a lot of supports in it.

5
00:00:13,190 --> 00:00:16,990
We have a lot of data, a lot of different
providers, which we then aggregate

6
00:00:17,110 --> 00:00:19,059
and give out to our users for free.

7
00:00:19,549 --> 00:00:22,919
We have more than 28 million
monthly active users.

8
00:00:22,970 --> 00:00:24,290
They generate 1.

9
00:00:24,390 --> 00:00:28,640
4 petabytes of traffic every
month, and that's 400 billion

10
00:00:28,640 --> 00:00:31,480
requests, and the peak we had was 1.

11
00:00:31,530 --> 00:00:33,720
6 million requests per second.

12
00:00:34,260 --> 00:00:38,349
So when we first started, we had a lot
of issues with the servers breaking

13
00:00:38,379 --> 00:00:40,809
down when there's a lot of users.

14
00:00:41,559 --> 00:00:48,170
So as soon as there's a peak happening,
the servers were offline and the way

15
00:00:48,820 --> 00:00:51,290
You solve that, is by adding cache.

16
00:00:51,340 --> 00:00:55,850
So we added memcache and in
fact it was a full page cache.

17
00:00:55,860 --> 00:01:02,550
So when a user came to the website
if it the result was not in the

18
00:01:02,550 --> 00:01:07,070
cache it was Calculated, stored in
the cache, and returned to the user.

19
00:01:07,440 --> 00:01:08,400
And this works well.

20
00:01:08,430 --> 00:01:12,750
This is one of the simplest things
you can do to have a system that can

21
00:01:12,750 --> 00:01:14,469
handle more than a couple of users.

22
00:01:14,519 --> 00:01:19,620
But the problem with that approach
is, called cache stampede problem.

23
00:01:19,629 --> 00:01:24,129
So if something is not in the cache,
and you have a lot of users coming

24
00:01:24,229 --> 00:01:29,630
to and trying to fetch the same
thing, All of those requests will

25
00:01:29,630 --> 00:01:33,880
go to the back end to your database,
because it's not in the cache.

26
00:01:34,220 --> 00:01:37,500
And basically your database
or back end servers will die.

27
00:01:37,879 --> 00:01:43,910
What you want to have is To have
all of the requests waiting and

28
00:01:43,910 --> 00:01:48,150
only one request going to your
database or a backend service.

29
00:01:48,820 --> 00:01:54,060
And this is not an easy thing to solve
because then you have, if you have

30
00:01:54,069 --> 00:01:58,549
more servers, you have a distributed
system and to have those requests

31
00:01:58,550 --> 00:02:01,010
waiting is not a simple thing to do.

32
00:02:01,810 --> 00:02:07,250
especially in the early days when we
ourselves weren't really all that savvy

33
00:02:07,330 --> 00:02:09,780
in dealing with distributed systems.

34
00:02:10,080 --> 00:02:10,900
So.

35
00:02:11,250 --> 00:02:16,660
What we did is we knew how our users
were using the app and since most

36
00:02:16,660 --> 00:02:24,539
of the users actually fetch want to
view live matches They we knew that

37
00:02:24,559 --> 00:02:28,949
we want to have the matches that are
live there Going to be looked at.

38
00:02:29,009 --> 00:02:30,499
We wanted to have that in the cache.

39
00:02:30,849 --> 00:02:35,369
So we ended up creating a worker that
would fetch all of the games that are

40
00:02:35,369 --> 00:02:40,149
being played, in the last couple of
hours and will be played in the next

41
00:02:40,149 --> 00:02:46,279
couple of hours and basically proactively
cache and put the result in the cache.

42
00:02:46,279 --> 00:02:52,759
So that every time somebody was trying
to fetch a game that should be live.

43
00:02:53,059 --> 00:02:57,879
We were sure to have it in the cache
So it's really important to know how

44
00:02:57,879 --> 00:03:01,749
your users interact with your app in
your system And proactive caching is

45
00:03:01,749 --> 00:03:05,429
actually something that all of the big
companies are doing So if you look at

46
00:03:05,429 --> 00:03:09,469
facebook instagram and so on they all
have your results prepared for you.

47
00:03:09,969 --> 00:03:17,419
We also have a really interesting
thing in our system in that Before

48
00:03:17,449 --> 00:03:23,569
a game So before big games happen,
usually people will start opening the

49
00:03:23,609 --> 00:03:26,359
app and the games 15 minutes before.

50
00:03:26,609 --> 00:03:29,089
And this was especially
true in the early days.

51
00:03:29,099 --> 00:03:35,179
So in the early days, whenever there
were big games being played, 15 minutes

52
00:03:35,179 --> 00:03:37,459
before we would have a lot of users.

53
00:03:37,509 --> 00:03:43,359
And in those 15 minutes, the number of
users would usually multiply by 3 or 4.

54
00:03:43,359 --> 00:03:45,369
So it would quadruple.

55
00:03:45,779 --> 00:03:50,019
The traffic we had on the site, which was
really useful knowledge because we knew

56
00:03:50,029 --> 00:03:51,909
how, how the system is going to behave.

57
00:03:52,369 --> 00:03:57,859
So 15 minutes before a really big
and important game called El Clasico.

58
00:03:57,899 --> 00:04:00,649
So for those of you who don't
follow sports, that's when two

59
00:04:00,649 --> 00:04:04,419
of the most popular teams in the
world play against each other.

60
00:04:05,119 --> 00:04:06,289
So 15 minutes before.

61
00:04:06,789 --> 00:04:11,609
Our CPU on the server was going through
the roof, and at that time, we only

62
00:04:11,619 --> 00:04:17,039
had two servers, one for the back end
service and one for the database, and

63
00:04:17,039 --> 00:04:22,899
it was just basically dying 15 minutes
before, and we knew that if we didn't

64
00:04:22,899 --> 00:04:28,719
do anything, the whole site will crash,
which is not really something you

65
00:04:28,719 --> 00:04:30,259
want to have when you have a to do.

66
00:04:30,419 --> 00:04:31,949
really big event like that.

67
00:04:31,949 --> 00:04:34,589
So that's the event that brings
in the most money during the year.

68
00:04:35,089 --> 00:04:40,199
and we do have cash and we do have
proactive caching, but still the

69
00:04:40,839 --> 00:04:43,269
back end app needs to be booted.

70
00:04:43,639 --> 00:04:48,869
The request has to go through all
of the steps that need to happen.

71
00:04:49,129 --> 00:04:53,499
Then fetch from the cache and
return and we were running PHP

72
00:04:53,549 --> 00:04:59,109
and PHP is slow and there's not a
whole lot you can do in that case.

73
00:04:59,169 --> 00:05:03,789
But what we did know is that
Apache was much, much faster than

74
00:05:03,789 --> 00:05:05,379
PHP in serving static content.

75
00:05:06,119 --> 00:05:10,709
So we got to thinking we only have one URL
that's going to be access, nothing else.

76
00:05:10,949 --> 00:05:16,804
If that URL was in fact a static
HTML, everything should work.

77
00:05:17,444 --> 00:05:20,194
And then we were like,
well, it can be, right?

78
00:05:20,374 --> 00:05:27,364
So we opened the page, just that one
page, file, save as, saved as HTML,

79
00:05:27,514 --> 00:05:33,414
and we wrote a simple rule in Apache
that said, if the users visit this

80
00:05:33,424 --> 00:05:35,234
URL, just return this static file.

81
00:05:35,484 --> 00:05:36,084
That's it.

82
00:05:36,684 --> 00:05:43,454
And once we did that, the load immediately
dropped and was performing extremely well.

83
00:05:43,584 --> 00:05:49,074
So problem solved, but we had an issue
because now, that was static content.

84
00:05:49,224 --> 00:05:50,214
It wasn't changing.

85
00:05:50,224 --> 00:05:50,524
Right?

86
00:05:50,844 --> 00:05:56,424
So we ended up watching the game live and
whenever something happened, a goal, red

87
00:05:56,424 --> 00:06:02,344
card, anything else we had to manually
edit the HTML file, save it, upload it

88
00:06:02,344 --> 00:06:04,184
to the server so that it gets refreshed.

89
00:06:04,484 --> 00:06:05,064
But it worked.

90
00:06:05,564 --> 00:06:09,824
That got us thinking, so
obviously we need something else.

91
00:06:09,834 --> 00:06:14,114
We have really big peaks and this is
not something we want to do for all

92
00:06:14,114 --> 00:06:15,924
of the big matches to do it manually.

93
00:06:16,524 --> 00:06:19,314
And that's when cloud came into play.

94
00:06:19,484 --> 00:06:21,204
So this was 2013.

95
00:06:21,704 --> 00:06:23,754
Not a lot of people were using the cloud.

96
00:06:24,164 --> 00:06:27,924
And I got to the founders and I
said, look, this is the best thing

97
00:06:28,004 --> 00:06:29,984
that we can do for our use case.

98
00:06:30,714 --> 00:06:32,154
We can scale up when we need to.

99
00:06:32,154 --> 00:06:34,054
We can scale down when we don't need to.

100
00:06:35,024 --> 00:06:35,844
And they said yes.

101
00:06:35,914 --> 00:06:38,724
And the only game in
town was basically AWS.

102
00:06:38,814 --> 00:06:40,234
So that's what we chose.

103
00:06:40,604 --> 00:06:46,559
And also looking back at the story
that I told where we had a server that

104
00:06:46,579 --> 00:06:50,939
was serving static content, which was
really fast, much faster than PHP.

105
00:06:51,319 --> 00:06:53,269
we found out about Varnish.

106
00:06:53,519 --> 00:07:01,389
So Varnish is a reverse HTTP caching proxy
written in C, which is extremely fast.

107
00:07:01,429 --> 00:07:04,264
It respects the cache control headers.

108
00:07:04,914 --> 00:07:08,904
And basically, stores your
full page cache in its cache.

109
00:07:09,274 --> 00:07:12,214
and if you're gonna remember
anything from this talk, it's this.

110
00:07:12,254 --> 00:07:17,224
This is the single most important
part of infrastructure that we have.

111
00:07:17,614 --> 00:07:23,424
once we started using this, our, The
whole app just was blazingly fast.

112
00:07:23,524 --> 00:07:27,774
And also, it solves one of the difficult
problems that I was talking about

113
00:07:27,834 --> 00:07:29,904
earlier, which is request coalescing.

114
00:07:30,244 --> 00:07:35,484
So, if something is not in the cache
and you get a lot of requests for the

115
00:07:35,484 --> 00:07:40,634
same content, Varnish will only let
one request go to your origin server.

116
00:07:40,635 --> 00:07:42,634
All of the rest will be queued up.

117
00:07:43,149 --> 00:07:47,449
And once the response is received,
all of the requests will get the same

118
00:07:47,449 --> 00:07:49,499
response, which is, which is great.

119
00:07:50,459 --> 00:07:53,899
So the cloud, was pretty straightforward.

120
00:07:54,299 --> 00:07:59,009
We had an image that had Varnish
and the backend server baked in.

121
00:07:59,369 --> 00:08:00,829
We had an auto scaling group.

122
00:08:00,849 --> 00:08:04,829
We got rid of memcache because it was
no longer needed because of Varnish.

123
00:08:05,139 --> 00:08:06,469
We had a couple of workers database.

124
00:08:06,724 --> 00:08:08,474
Pretty straightforward for stuff.

125
00:08:08,854 --> 00:08:13,044
And the reason why we could do this
pretty easily is because the server

126
00:08:13,044 --> 00:08:18,614
itself was stateless and it was easy
to port to cloud and also it was

127
00:08:18,654 --> 00:08:20,434
easy to do on auto scaling group.

128
00:08:20,574 --> 00:08:24,624
So it's really important wherever
possible, you should be stateless.

129
00:08:25,274 --> 00:08:28,894
scaling state is extremely difficult
and this is something that should

130
00:08:28,904 --> 00:08:30,654
be done early in the project.

131
00:08:31,654 --> 00:08:34,014
We also like to try out new technologies.

132
00:08:34,024 --> 00:08:35,054
So we.

133
00:08:35,699 --> 00:08:41,109
switched from MySQL to MongoDB,
because, you know, web scale.

134
00:08:41,229 --> 00:08:45,049
and it was working
really great for a time.

135
00:08:45,689 --> 00:08:48,219
And then we started getting into issues.

136
00:08:48,249 --> 00:08:53,759
So we, got replication issues, which
were really difficult to debug.

137
00:08:54,059 --> 00:08:56,239
we had data type errors.

138
00:08:56,629 --> 00:08:58,909
It was really difficult to analyze data.

139
00:08:59,219 --> 00:09:05,374
We had issues with locking, because in
those times, If you were to change a

140
00:09:05,764 --> 00:09:09,334
single document in a collection, the
whole collection would need to be locked.

141
00:09:09,994 --> 00:09:14,874
And we have a lot of updates, so it
was really difficult to have that.

142
00:09:15,314 --> 00:09:19,564
And also no foreign keys, which was
just a disaster because the whole

143
00:09:19,564 --> 00:09:24,269
project is like basically analyzing and
connecting different parts of the data.

144
00:09:24,939 --> 00:09:30,059
So we, got to the conclusion that
this was not a great choice for us.

145
00:09:30,069 --> 00:09:32,539
And we need to switch back
to a relational database.

146
00:09:33,229 --> 00:09:37,379
And then we found Postgres, which
is what we are currently still

147
00:09:37,379 --> 00:09:39,139
using because it is amazing.

148
00:09:39,869 --> 00:09:41,119
So why Postgres?

149
00:09:41,139 --> 00:09:42,799
Because it's open source.

150
00:09:42,909 --> 00:09:45,239
it has advanced SQL capabilities.

151
00:09:45,689 --> 00:09:49,359
It has minimal locking with
the mechanism called MVCC.

152
00:09:49,939 --> 00:09:52,629
it's, it stands for multi
version concurrency control.

153
00:09:52,679 --> 00:09:53,709
it can be a talk.

154
00:09:53,899 --> 00:09:55,109
all onto itself.

155
00:09:55,159 --> 00:10:00,689
But basically what it allows you to
do is to read while you are updating

156
00:10:00,749 --> 00:10:02,899
at the same time without any locking.

157
00:10:03,899 --> 00:10:05,839
And it has great performance.

158
00:10:06,569 --> 00:10:07,849
How great performance?

159
00:10:07,879 --> 00:10:11,939
So on our machine, we can get 1
million queries per second and

160
00:10:11,939 --> 00:10:14,779
90, 000 transactions per second.

161
00:10:15,329 --> 00:10:18,204
And one transaction in
a benchmark is 5, 000.

162
00:10:18,394 --> 00:10:19,764
Things that change the state.

163
00:10:19,764 --> 00:10:24,164
So basically we can do half a
million updates in peak times.

164
00:10:24,894 --> 00:10:27,794
So great performance, great abilities.

165
00:10:27,874 --> 00:10:32,004
We decided to switch from
MongoDB to Postgres, but the

166
00:10:32,074 --> 00:10:34,184
issue was we have to do it live.

167
00:10:34,254 --> 00:10:34,794
So.

168
00:10:35,044 --> 00:10:37,764
We have users, all over the world.

169
00:10:38,034 --> 00:10:39,884
we cannot have any downtime.

170
00:10:39,914 --> 00:10:43,824
And in my mind, when we were trying to
do this, it's called something like this.

171
00:10:43,834 --> 00:10:47,424
So changing the tires were
while driving on a highway.

172
00:10:47,934 --> 00:10:50,944
but we decided we need
to do it and we did it.

173
00:10:51,084 --> 00:10:53,334
And it was actually not that difficult.

174
00:10:53,354 --> 00:10:54,434
What we end up.

175
00:10:55,009 --> 00:10:59,429
doing was time stamping all of the
collections that we have all of the

176
00:10:59,429 --> 00:11:04,949
data and then we wrote a tool that would
switch that would replicate from MongoDB

177
00:11:05,029 --> 00:11:08,049
to Postgres and do so in iterations.

178
00:11:08,729 --> 00:11:15,289
So every iteration would transfer all of
the changes from the last run and then we

179
00:11:15,289 --> 00:11:17,079
got to a point where the database were.

180
00:11:17,514 --> 00:11:18,534
Databases were in sync.

181
00:11:19,534 --> 00:11:25,054
So what we lost with this is simple
replication and configuration and

182
00:11:25,054 --> 00:11:29,444
leader election, which works great
in MongoDB, but what we gained was

183
00:11:29,454 --> 00:11:34,544
stability, foreign keys and analytical
power, which is really important to us.

184
00:11:35,484 --> 00:11:40,394
So it is important to recognize
the right tool for the job and

185
00:11:40,404 --> 00:11:41,834
change in this if necessary.

186
00:11:42,544 --> 00:11:46,324
And just a small digression
when we were talking about hype

187
00:11:46,364 --> 00:11:48,094
and cool new things, I get a.

188
00:11:48,229 --> 00:11:52,409
A lot of, lots of times people ask me,
what do I think about microservices?

189
00:11:52,879 --> 00:11:57,239
And we don't have a
microservice, architecture.

190
00:11:57,249 --> 00:12:00,719
We do have a lot of services
that do certain things.

191
00:12:00,769 --> 00:12:05,129
But in my mind, You
probably don't need them.

192
00:12:05,809 --> 00:12:10,359
If you don't have a really big team
or a really complex app, then you're

193
00:12:10,369 --> 00:12:15,409
just, making yourself, making your life
more complicated than it should be.

194
00:12:15,819 --> 00:12:20,109
a lot of problems can be solved
by just using async communication.

195
00:12:20,634 --> 00:12:26,554
And it's an easier thing to, to manage
and, it works really well for us.

196
00:12:26,574 --> 00:12:33,364
So what we do have and what we implemented
early on was basically everything that

197
00:12:33,364 --> 00:12:37,954
is slow and everything that doesn't need
to happen right away is put in a queue.

198
00:12:38,564 --> 00:12:41,404
And then you have workers
that just consume the queue

199
00:12:41,464 --> 00:12:43,154
and then you can scale those.

200
00:12:43,449 --> 00:12:45,889
Producers and consumers independently.

201
00:12:46,719 --> 00:12:52,369
What we use is Beanstalk V, which is a
job queue, but like any queue, any message

202
00:12:52,369 --> 00:12:56,869
queue works, it's really important to
queue everything that is slow because then

203
00:12:56,869 --> 00:13:02,289
you have, you can scale your system more
easily going back to the, to the cloud.

204
00:13:02,579 --> 00:13:09,159
So we had an auto scaling group that
would trigger once the CPU is high But the

205
00:13:09,159 --> 00:13:12,689
problem with this is the more you scale.

206
00:13:13,049 --> 00:13:19,649
The worst the cache gets, because in our
case, we had the caching system baked

207
00:13:19,649 --> 00:13:21,779
into the image with the backend server.

208
00:13:22,089 --> 00:13:27,989
So once we scaled, the more we
scaled, the more the cache was,

209
00:13:28,289 --> 00:13:33,869
basically, not as effective,
because Every cache is for itself.

210
00:13:34,139 --> 00:13:38,299
So if you have one machine, you only
get one request to the backend servers.

211
00:13:38,339 --> 00:13:43,869
But if you have 20, then all of
those, we have to fetch their requests

212
00:13:43,909 --> 00:13:46,139
independently, which is not great.

213
00:13:46,709 --> 00:13:49,589
The solution to this is not that hard.

214
00:13:50,089 --> 00:13:54,159
It's just to separate your caching
layer from your backend services.

215
00:13:54,659 --> 00:13:55,874
So that's what we did.

216
00:13:56,414 --> 00:14:01,594
And you obviously have to have at least
two, to avoid single points of failure.

217
00:14:01,984 --> 00:14:05,924
The problem with this is, I mean,
this works really well, but still,

218
00:14:05,984 --> 00:14:12,244
you will have, the number of requests
for one single resource will always

219
00:14:12,264 --> 00:14:14,464
be the number of machines you have.

220
00:14:14,514 --> 00:14:18,404
So if you have two machines in the
caching layer, they don't talk to each

221
00:14:18,404 --> 00:14:22,334
other, and you will get two requests
to your backend services, Which is

222
00:14:22,344 --> 00:14:28,184
not really needed and I have a really
big desire to optimize everything.

223
00:14:28,184 --> 00:14:32,934
This can be one request and the way
to solve this is by using sharding.

224
00:14:33,424 --> 00:14:40,474
So if you shard your caching servers
so that a single server will always be

225
00:14:40,474 --> 00:14:47,374
responsible for a specific URL, then you
can scale your caching layer linearly.

226
00:14:47,375 --> 00:14:47,909
for your time and enjoy.

227
00:14:48,284 --> 00:14:52,634
And basically get, as much
memory as you as you need.

228
00:14:53,154 --> 00:14:57,844
and we do this, we did it actually
on a bit more complicated scale.

229
00:14:57,864 --> 00:15:02,854
So instead of having a
random load balancer, so we

230
00:15:02,864 --> 00:15:05,154
have two layers of varnish.

231
00:15:05,204 --> 00:15:08,744
The first layer is to load
balance, and it has to have a lot

232
00:15:08,744 --> 00:15:10,624
of CPU and a lot of bandwidth.

233
00:15:11,279 --> 00:15:17,579
And then we use consistent hashing to
hit, just one machine in the second layer.

234
00:15:17,769 --> 00:15:18,899
And then it goes to the backend.

235
00:15:18,899 --> 00:15:22,829
So basically, this allows us to
have a really high hit rate ratio,

236
00:15:22,829 --> 00:15:24,799
and we can cache everything.

237
00:15:25,149 --> 00:15:29,429
So we can even do database updates
without people noticing, because most

238
00:15:29,429 --> 00:15:31,759
of the important stuff is in the cache.

239
00:15:32,509 --> 00:15:35,299
And we can just shut down for half an
hour, and nobody's going to notice.

240
00:15:35,749 --> 00:15:38,659
But cache invalidation is hard.

241
00:15:39,139 --> 00:15:43,909
that's why we built an internal library,
which is actually open sourced for PHP,

242
00:15:44,189 --> 00:15:46,399
that builds out the graph of dependencies.

243
00:15:46,699 --> 00:15:50,089
And you can specify which endpoint
depends on which entities.

244
00:15:50,419 --> 00:15:55,284
And once an entity changes, we can
invalidate just that URL that's important.

245
00:15:56,224 --> 00:15:58,894
There's also cool cache control headers.

246
00:15:59,204 --> 00:16:03,874
So maxage is for the end client,
smaxage is for Varnish or any

247
00:16:03,894 --> 00:16:06,364
intermediate caching, servers.

248
00:16:06,884 --> 00:16:09,804
it basically tells it how long
it should be in the cache.

249
00:16:10,174 --> 00:16:14,094
a really cool header is sale while
revalidate, which will, essentially

250
00:16:14,374 --> 00:16:16,554
return the old version code.

251
00:16:16,759 --> 00:16:20,439
of the resource while fetching the new
one in the background, which is really

252
00:16:20,439 --> 00:16:22,759
useful if you have slow endpoints.

253
00:16:23,289 --> 00:16:29,989
Stale if error will allow you to
return, the last response you have if

254
00:16:30,629 --> 00:16:36,109
backend services are, not currently
healthy, which is really cool.

255
00:16:36,109 --> 00:16:39,299
You basically have a always on, site.

256
00:16:39,799 --> 00:16:41,539
Now, AWS was great.

257
00:16:42,239 --> 00:16:42,939
Love the cloud.

258
00:16:42,989 --> 00:16:48,494
The problem with All the cloud service
services are, they're really expensive

259
00:16:48,604 --> 00:16:50,864
and especially expensive is traffic.

260
00:16:51,084 --> 00:16:54,794
We got to a point where we were
paying more for traffic than we

261
00:16:54,794 --> 00:16:58,284
were paying for compute, which is
something that really bothered me.

262
00:16:58,304 --> 00:17:01,864
It makes no sense to pay
so much for, for traffic.

263
00:17:02,484 --> 00:17:09,554
So we got to thinking and we saw that
if you rent out bare metal servers,

264
00:17:10,389 --> 00:17:18,329
Usually, you have a certain number of
terabytes included with your server and

265
00:17:18,329 --> 00:17:20,819
it's either free or really, really cheap.

266
00:17:21,339 --> 00:17:26,129
So, since our caching layer is
separate from everything else, we

267
00:17:26,129 --> 00:17:30,354
can basically just put Put it out of
the cloud, and that's what we did.

268
00:17:30,954 --> 00:17:37,064
We rented out a couple of machines and
we set up our Varnish instances on them

269
00:17:37,384 --> 00:17:39,034
and then pointed that to the cloud.

270
00:17:39,144 --> 00:17:44,454
So really simple change, but it got
us a 10x reduction in bandwidth.

271
00:17:44,969 --> 00:17:46,339
Which was a lot.

272
00:17:46,619 --> 00:17:51,579
So we caught our AWS
bill by a huge margin.

273
00:17:52,299 --> 00:17:55,709
And then we did a back
of the net calculation.

274
00:17:55,709 --> 00:18:01,509
What would happen if we would move other
services from the cloud to bare metal?

275
00:18:02,289 --> 00:18:02,829
And.

276
00:18:03,329 --> 00:18:08,899
Our calculation was that we can over
provision the system by a double and

277
00:18:08,899 --> 00:18:12,159
still see a 5x reduction in price.

278
00:18:12,339 --> 00:18:15,759
So we migrated everything
from cloud to data center.

279
00:18:16,749 --> 00:18:20,739
Now, when I started this talk, I
said that we had really big peaks

280
00:18:20,969 --> 00:18:26,399
and that we need to scale up and
scale down in short amount of time.

281
00:18:26,899 --> 00:18:33,179
The thing is, when you have a really good
caching system, the cache layer will kind

282
00:18:33,179 --> 00:18:36,519
of buffer out and flatten out those peaks.

283
00:18:36,919 --> 00:18:42,089
So once we figured out the caching
layer, our peaks weren't really that big.

284
00:18:42,329 --> 00:18:47,569
It was, it was just, it was just a 2x
increase in the biggest peaks that we

285
00:18:47,569 --> 00:18:49,409
have that goes to the backend servers.

286
00:18:49,629 --> 00:18:54,699
The caching servers can get like 20x
peaks, but the backend servers will not.

287
00:18:55,389 --> 00:18:57,869
So that's what, why we
were able to migrate.

288
00:18:58,369 --> 00:19:02,559
and we switched from, AWS instances
to Docker containers, and, we

289
00:19:02,559 --> 00:19:03,799
installed everything ourselves.

290
00:19:04,389 --> 00:19:07,609
And the reduction in price was really big.

291
00:19:07,639 --> 00:19:13,409
And this is the graph of our
infrastructure cost throughout time.

292
00:19:13,729 --> 00:19:16,189
And this might not seem like much.

293
00:19:16,469 --> 00:19:19,859
there is a, a slow and
steady decline in price.

294
00:19:20,314 --> 00:19:24,534
But if you overlay this with the number
of users that we had in that period,

295
00:19:24,534 --> 00:19:28,964
you can see that the number of users
is growing a lot, but the price is

296
00:19:28,994 --> 00:19:30,864
going down or, or staying the same.

297
00:19:31,364 --> 00:19:35,604
And there's also one
other benefit of being.

298
00:19:36,009 --> 00:19:43,204
on bare mill and that's, you avoid
accidental really big spikes in price.

299
00:19:43,204 --> 00:19:45,814
So this is a true screenshot
from a friend of mine.

300
00:19:46,224 --> 00:19:50,594
they had a developer create a bug,
which was not detected until it was too

301
00:19:50,594 --> 00:19:52,954
late in just a short amount of time.

302
00:19:52,954 --> 00:19:56,564
Their bill, jumped from
360 k to 2 million.

303
00:19:56,974 --> 00:19:58,024
and if you're off the cloud.

304
00:19:58,754 --> 00:20:00,314
Your app will simply not work.

305
00:20:00,334 --> 00:20:01,244
And that's a trade off.

306
00:20:01,244 --> 00:20:06,094
So for someone, it's important
to always be on and pay millions.

307
00:20:06,314 --> 00:20:10,264
For others, paying a couple of
millions for a mistake is too much.

308
00:20:11,174 --> 00:20:15,094
Also, when we are not on the
cloud, RAM is really, really cheap.

309
00:20:15,354 --> 00:20:17,444
We have a lot of RAM to spare.

310
00:20:17,884 --> 00:20:20,904
And what we do with that is
we utilize it for the cache.

311
00:20:20,914 --> 00:20:24,924
So the second layer of varnishes that
I talked about is running, On those

312
00:20:24,944 --> 00:20:28,574
machines, and it's utilizing orders,
all the spare ram and basically

313
00:20:28,654 --> 00:20:33,114
everything that we have can be
stored in the cash and be always on.

314
00:20:33,694 --> 00:20:38,784
and usually people ask me, okay, so,
but surely you have to, you have cost

315
00:20:38,784 --> 00:20:44,274
of people, you have to pay more people
to do DevOps infrastructure and in

316
00:20:44,274 --> 00:20:45,454
our case, that's simply not true.

317
00:20:45,794 --> 00:20:47,544
So up until.

318
00:20:48,004 --> 00:20:52,724
like four years ago, we only
had one guy managing everything.

319
00:20:53,134 --> 00:20:59,634
Now it's a team of, five people and they
can manage that in their spare time.

320
00:20:59,944 --> 00:21:05,684
So basically in dev ops, We have
people working from backend, part of

321
00:21:05,684 --> 00:21:08,924
the time on, on, on the infrastructure
and everything works perfectly.

322
00:21:09,274 --> 00:21:13,004
But you have to have your
infrastructure really optimized

323
00:21:13,054 --> 00:21:14,034
and know what you're doing.

324
00:21:14,534 --> 00:21:16,054
We have really big peaks.

325
00:21:16,064 --> 00:21:19,184
So this is from our, caching layer.

326
00:21:19,514 --> 00:21:23,784
And you can see in football for
first and second half really clearly.

327
00:21:24,314 --> 00:21:27,739
and those peaks are, you know,
really big because we do send

328
00:21:27,739 --> 00:21:29,579
out a lot of push notifications.

329
00:21:29,869 --> 00:21:33,849
We try to send out as many push
notifications as we can in a

330
00:21:33,849 --> 00:21:37,199
short amount of time so that
people get their results faster.

331
00:21:37,609 --> 00:21:41,859
And what happens is people open
their mobile phone, they click on

332
00:21:41,859 --> 00:21:45,839
the notification, and basically they
open the app all at the same time.

333
00:21:46,459 --> 00:21:49,179
And it kind of looks like
a DDoS attack, right?

334
00:21:49,619 --> 00:21:55,369
So, in Cloudflare, which we were using,
at the time, Was detecting this as a

335
00:21:55,369 --> 00:21:59,719
DDoS attack and we were having issues
because people couldn't open the app

336
00:21:59,729 --> 00:22:01,229
because they were detected as a DDoS.

337
00:22:01,239 --> 00:22:06,589
So we actually had to go to their office
to talk with their engineers to explain

338
00:22:06,599 --> 00:22:10,869
what kind of issues we were having and
the response was, Oh, yeah, you're surely

339
00:22:10,869 --> 00:22:14,229
triggering the DDoS protection system.

340
00:22:14,594 --> 00:22:19,124
And they added special values
just for our site where the DDoS

341
00:22:19,134 --> 00:22:23,304
wasn't as aggressive as it usually
is, and that fixed our problem.

342
00:22:24,054 --> 00:22:29,224
it's also important to monitor everything
you have, and the best thing you can have

343
00:22:29,224 --> 00:22:30,734
is application performance monitoring.

344
00:22:31,514 --> 00:22:35,474
by having this, you know which
endpoints you need to optimize because

345
00:22:35,994 --> 00:22:40,534
it's not important if something
is slow, if it's not being called.

346
00:22:41,034 --> 00:22:47,084
Also, if something is, is fast, but it's,
it's being called millions of times,

347
00:22:47,394 --> 00:22:50,154
then it might make sense to optimize.

348
00:22:50,664 --> 00:22:55,534
And to do this is you should always
optimize most time consuming.

349
00:22:55,544 --> 00:22:59,874
So that, which is, being
called a lot and is slow.

350
00:23:00,364 --> 00:23:04,194
and you can get really good
results by using this any APM.

351
00:23:04,354 --> 00:23:04,884
works.

352
00:23:05,214 --> 00:23:08,374
This is a screenshot from New Relic,
but it's like it's not important.

353
00:23:09,334 --> 00:23:15,434
Sometimes the endpoint is as optimal as
it can be and you cannot optimize anymore.

354
00:23:16,104 --> 00:23:20,534
In those cases, usually you can increase
the cache and the correlation between

355
00:23:20,534 --> 00:23:24,224
cache and the number of requests that
you get to the server is not linear.

356
00:23:24,544 --> 00:23:33,024
So small improvements in the TTL of
the cache can lead to a large gains.

357
00:23:33,454 --> 00:23:35,714
In the number of requests
that go to your service.

358
00:23:35,724 --> 00:23:39,344
So if you increase your cash just
by a little bit, you can get a

359
00:23:39,354 --> 00:23:42,694
really high decrease in throughput
to your backend service and make

360
00:23:42,694 --> 00:23:44,784
everything faster and cheaper.

361
00:23:45,444 --> 00:23:47,944
So you should monitor everything.

362
00:23:48,389 --> 00:23:49,809
Optimize something.

363
00:23:50,109 --> 00:23:55,119
I think there is a good quote where,
premature optimization is the root of all

364
00:23:55,119 --> 00:24:01,629
evil, which I agree with, but you should
monitor so that you know what to optimize,

365
00:24:01,869 --> 00:24:06,889
especially if you have microservices that
system can get really complex really fast.

366
00:24:07,389 --> 00:24:10,904
Another question I get is like,
what is the number of users?

367
00:24:11,144 --> 00:24:13,109
Exceeds your current capacity.

368
00:24:13,694 --> 00:24:16,174
since you're not on the cloud,
which is completely legitimate

369
00:24:16,224 --> 00:24:20,594
thing that usually people ask first,
yeah, we are not on the cloud.

370
00:24:20,594 --> 00:24:22,204
We rent out dedicated machines.

371
00:24:22,474 --> 00:24:25,814
Sometimes we can rent out new
machines in a couple of minutes.

372
00:24:25,824 --> 00:24:29,974
Sometimes it takes days, so it's
not really a, you can really

373
00:24:30,134 --> 00:24:31,594
scale up fast kind of thing.

374
00:24:32,074 --> 00:24:38,184
So what we do instead is we have dedicated
machines and if the load gets too high,

375
00:24:38,644 --> 00:24:42,494
We spin up virtual machines, and those
virtual machines joined the cluster.

376
00:24:43,224 --> 00:24:46,384
The traffic gets distributed
to them, and everything works.

377
00:24:46,744 --> 00:24:52,404
This happens almost never because the
system is over provisioned, but this is an

378
00:24:52,404 --> 00:24:56,274
option that we have and sometimes utilize.

379
00:24:56,374 --> 00:24:59,374
So this is kind of a
hybrid cloud approach.

380
00:24:59,874 --> 00:25:02,844
Also, there's this thing called physics.

381
00:25:02,844 --> 00:25:11,134
We have Our data centers in Europe, but we
have users worldwide and due to physics,

382
00:25:11,174 --> 00:25:16,914
they get their responses slower because,
the speed of light is what hampers us.

383
00:25:17,484 --> 00:25:21,804
So we didn't know how
big of an impact this is.

384
00:25:21,994 --> 00:25:24,554
And I decided that we
need to look into this.

385
00:25:25,144 --> 00:25:30,464
And we sent, sent out an email to
one of our users from Australia.

386
00:25:31,274 --> 00:25:38,724
And he was asked if he can record the app
too, so that we can see how good the app

387
00:25:38,724 --> 00:25:40,614
is performing, if there are any issues.

388
00:25:41,044 --> 00:25:43,714
And he replied, yeah,
everything works great.

389
00:25:43,774 --> 00:25:44,484
No problem.

390
00:25:44,484 --> 00:25:45,464
Everything is fast.

391
00:25:45,534 --> 00:25:46,214
love your app.

392
00:25:46,774 --> 00:25:50,404
And when we were watching
the video, we saw this.

393
00:25:50,904 --> 00:25:55,584
I didn't know that we had loaders in
the app because in Europe, it's so

394
00:25:55,584 --> 00:25:59,774
fast that you don't even see the loader
because like everything is in the cache.

395
00:26:00,294 --> 00:26:04,944
But in Australia, they have a
half, half a second latency, just

396
00:26:04,954 --> 00:26:06,724
to fish the data from Europe.

397
00:26:06,959 --> 00:26:12,089
To Australia, but this is normal for
for them because all of the competition

398
00:26:12,099 --> 00:26:15,769
had the same issue and this is
just like the way things are and we

399
00:26:15,769 --> 00:26:18,069
wanted to solve this and solve this.

400
00:26:18,779 --> 00:26:23,809
We actually distributed our caching
servers throughout the world and use geo

401
00:26:23,809 --> 00:26:26,489
routing to fetch from the nearest cache.

402
00:26:27,209 --> 00:26:33,069
And we got a, really big reduction in
latency for Australia, Brazil, and all

403
00:26:33,069 --> 00:26:37,849
of the countries outside of Europe, where
Australia dropped from half a second

404
00:26:37,849 --> 00:26:42,069
to 80 milliseconds, which is a lot,
which is a difference between, you can

405
00:26:42,069 --> 00:26:44,249
see a loader, and it's imperceptible.

406
00:26:45,189 --> 00:26:48,369
And you might ask,
shouldn't a CDN do that?

407
00:26:48,819 --> 00:26:49,799
Well, yes, they should.

408
00:26:49,979 --> 00:26:50,669
They should.

409
00:26:50,689 --> 00:26:53,009
But you are not the only user.

410
00:26:53,259 --> 00:26:54,089
of that CDN.

411
00:26:54,319 --> 00:26:55,949
They have other clients.

412
00:26:56,629 --> 00:26:58,779
Maybe it's not in the cache.

413
00:26:59,089 --> 00:27:04,919
Also, we do a lot of cache invalidations
so that we can have a high hit rate.

414
00:27:05,369 --> 00:27:10,259
And the problem with invalidations is
that not all CDNs do that properly.

415
00:27:10,449 --> 00:27:13,649
So Cloudflare has issues
with doing invalidation.

416
00:27:14,339 --> 00:27:16,719
So we had to build out ourselves.

417
00:27:17,169 --> 00:27:18,839
In the meantime, we'll switch to Fastly.

418
00:27:18,949 --> 00:27:22,009
So Fastly has really good
invalidation, so it works.

419
00:27:22,809 --> 00:27:25,319
But if you're having issues
with your carriers, this might

420
00:27:25,489 --> 00:27:27,139
be something to look into.

421
00:27:27,639 --> 00:27:29,519
Also, data centers can burn.

422
00:27:29,639 --> 00:27:32,819
Even if you're on the cloud, it's
just somebody else's machine.

423
00:27:33,249 --> 00:27:34,569
Data centers can burn.

424
00:27:35,159 --> 00:27:41,169
This is a screenshot from
OVH, where their DC burned.

425
00:27:41,609 --> 00:27:42,609
We use OVH.

426
00:27:42,619 --> 00:27:44,809
Fortunately, this wasn't our problem.

427
00:27:45,019 --> 00:27:45,829
Data center.

428
00:27:46,329 --> 00:27:47,979
But it got us thinking.

429
00:27:48,049 --> 00:27:53,329
and at that point in time, we knew that
we needed to be in multiple dcs to avoid

430
00:27:53,569 --> 00:27:56,619
issues with fires or network issues.

431
00:27:57,049 --> 00:27:59,789
so we moved to multiple dcs.

432
00:28:00,049 --> 00:28:04,459
The problem is, managing those and
having them communicate with each other.

433
00:28:04,459 --> 00:28:05,894
And that's why we
started using Kubernetes.

434
00:28:06,534 --> 00:28:10,504
So we have Kubernetes
because it is multi DC aware.

435
00:28:10,544 --> 00:28:14,464
So services know which,
where other services are.

436
00:28:14,814 --> 00:28:20,344
So that allows us to have a mechanism
that's robust and that can heal itself.

437
00:28:20,604 --> 00:28:23,934
And basically, we can have
cloud like capabilities.

438
00:28:24,359 --> 00:28:26,929
On bare metal with bare metal prices.

439
00:28:27,649 --> 00:28:32,989
the only thing that's difficult to solve
on bare metal and Kubernetes is state

440
00:28:33,039 --> 00:28:38,169
because in cloud you get it solved by
default by using the cloud components,

441
00:28:38,529 --> 00:28:40,759
but on bare metal it is more difficult.

442
00:28:41,399 --> 00:28:43,089
So we use Longhorn for that.

443
00:28:43,429 --> 00:28:46,189
Longhorn is basically
a distributed volumes.

444
00:28:46,259 --> 00:28:50,889
So, you have a volume, it's
replicated to other DC.

445
00:28:50,899 --> 00:28:56,759
So if your container pod fails,
it can switch to a different data

446
00:28:56,759 --> 00:28:59,979
center and also have that data, safe.

447
00:29:00,479 --> 00:29:03,319
We also do a lot of real time updates.

448
00:29:03,369 --> 00:29:11,194
so usually, it's being done, via
some sort of So the apps pull out all

449
00:29:11,194 --> 00:29:16,154
of the data via REST and then they
subscribe to a PubSub server to fetch

450
00:29:16,704 --> 00:29:18,894
real time updates, to fetch changes.

451
00:29:19,764 --> 00:29:24,844
And we were doing this ourselves with a
custom piece of software, but that just

452
00:29:24,934 --> 00:29:27,274
kept getting more and more complicated.

453
00:29:27,374 --> 00:29:30,014
So we found out about NATS.

454
00:29:30,474 --> 00:29:35,524
NATS is an open source messaging system,
a PubSub server, which is written in Go.

455
00:29:36,024 --> 00:29:36,644
It's free.

456
00:29:36,724 --> 00:29:41,794
It has support for clustering
out of the box, works perfectly.

457
00:29:42,174 --> 00:29:45,954
and just on a couple of servers,
we can get more than 800,

458
00:29:46,004 --> 00:29:49,604
000 connections at, in peaks.

459
00:29:50,114 --> 00:29:55,154
and we do more than half a million
messages per second without any issues.

460
00:29:55,664 --> 00:29:56,824
We also have a lot of data.

461
00:29:56,964 --> 00:30:02,904
So all of the clicks in the
apps are tracked via Firebase.

462
00:30:03,194 --> 00:30:08,204
They're anonymized and they are
exported so that we can download them.

463
00:30:08,294 --> 00:30:11,284
And we have more than
two petabytes of data.

464
00:30:11,534 --> 00:30:13,314
If you're in the cloud, it's a no brainer.

465
00:30:13,314 --> 00:30:15,244
You can just use cloud services.

466
00:30:15,364 --> 00:30:18,194
They are expensive, but
like they solve your issues.

467
00:30:18,464 --> 00:30:22,524
If you're on bare metal, two petabytes
of data is really hard to manage.

468
00:30:22,844 --> 00:30:25,824
So to do that, we use Clickhouse.

469
00:30:26,079 --> 00:30:28,539
And Apache Superset to visualize.

470
00:30:28,899 --> 00:30:33,759
Qlikos is basically a, SQL
database that's column oriented.

471
00:30:34,079 --> 00:30:38,829
It's specifically designed to
have the analytical workload.

472
00:30:39,279 --> 00:30:45,329
so we have two petabytes of data that's
compressed into just 50 terabytes.

473
00:30:45,679 --> 00:30:47,030
And we have more than 1.

474
00:30:47,030 --> 00:30:52,759
4 trillion rows and we can do more
than 2 million inserts per second.

475
00:30:52,819 --> 00:30:54,509
That's how fast it is.

476
00:30:55,489 --> 00:31:01,299
And that allows us to build
out really complex systems that

477
00:31:01,359 --> 00:31:02,939
do the query a lot of data.

478
00:31:02,959 --> 00:31:06,289
So this is a screenshot from our
anti scraping, anti scraping system

479
00:31:06,709 --> 00:31:12,589
that can, that takes, like 5 billion
rows and does some operations.

480
00:31:12,639 --> 00:31:15,169
And then we know which IPs to ban.

481
00:31:15,949 --> 00:31:19,779
And the interface to Clickhouse
by using Superset is really great.

482
00:31:20,299 --> 00:31:24,239
And using all of this that I've
talked about earlier, we have

483
00:31:24,239 --> 00:31:26,029
a system that's really robust.

484
00:31:26,169 --> 00:31:31,839
And in peak time, we had, almost 2
million users, in Google real time.

485
00:31:32,074 --> 00:31:37,884
Overview without any issues and without
and by just just by having everything

486
00:31:37,894 --> 00:31:42,694
work automatically and the reason why
you are not on the cloud is because all

487
00:31:42,694 --> 00:31:49,234
of this, all of the infrastructure cost
all of the so we do have some cloud

488
00:31:49,234 --> 00:31:52,834
services like all the cloud services,
all of the city ends, all the servers,

489
00:31:53,144 --> 00:31:55,314
everything that's needed for production.

490
00:31:55,714 --> 00:31:57,324
And development is 0.

491
00:31:57,324 --> 00:32:00,024
6 percent of revenue.

492
00:32:00,524 --> 00:32:04,944
So the take home from this would
be cash, all of the things.

493
00:32:04,964 --> 00:32:06,554
This is the most important thing.

494
00:32:07,184 --> 00:32:09,504
Usually people say, yeah,
but I have personalization.

495
00:32:09,504 --> 00:32:10,224
We cannot cash.

496
00:32:10,754 --> 00:32:11,314
Yes, you can.

497
00:32:11,354 --> 00:32:14,264
There are techniques that
you can use to cash things.

498
00:32:14,264 --> 00:32:18,074
We have a lot of personalized
content in the app.

499
00:32:18,514 --> 00:32:22,404
Be stateless wherever possible, because
it will allow you to scale more easily.

500
00:32:22,854 --> 00:32:24,624
Know how your users.

501
00:32:24,784 --> 00:32:26,334
Interact with the app.

502
00:32:27,114 --> 00:32:31,534
Recognize the right tool for
the job and change if necessary.

503
00:32:32,044 --> 00:32:33,434
Cloud should be the default.

504
00:32:33,454 --> 00:32:34,074
I love the cloud.

505
00:32:34,074 --> 00:32:36,564
I think it's one of the most
important technologies that we have.

506
00:32:36,834 --> 00:32:41,844
But you should keep your options open,
especially if your monthly bill is high.

507
00:32:42,444 --> 00:32:44,774
Queue everything that is slow.

508
00:32:45,254 --> 00:32:49,804
Monitor everything, optimize
something, and try to keep it

509
00:32:50,124 --> 00:32:52,604
simple for as long as you can.

510
00:32:53,114 --> 00:32:56,614
if you have any questions,
I'll be happy to answer them.

511
00:32:56,614 --> 00:32:58,364
This is my LinkedIn.

512
00:32:59,094 --> 00:33:02,554
Feel free to add me and hopefully
you learned something new

513
00:33:02,554 --> 00:33:04,234
today and this was fun for you.

514
00:33:04,764 --> 00:33:04,984
Thank you.

