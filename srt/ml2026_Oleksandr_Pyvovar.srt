1
00:00:00,500 --> 00:00:01,450
Speaker 17: Hello everyone.

2
00:00:01,750 --> 00:00:03,370
My name is Alexander Pivar.

3
00:00:03,820 --> 00:00:07,840
I am machine learning engineer at Miata,
and today we are gonna talk about why

4
00:00:07,840 --> 00:00:11,140
good models fail in the production and
how to build a system that don't fail.

5
00:00:11,640 --> 00:00:14,700
So imagine a situation you
train a model and your model

6
00:00:14,700 --> 00:00:16,920
achieved 95% accuracy in the lab.

7
00:00:17,310 --> 00:00:21,540
So now you deploy it with a confidence,
but six months later it's performance

8
00:00:21,540 --> 00:00:23,100
barely better than a random guessing.

9
00:00:23,460 --> 00:00:25,320
And you think what happened?

10
00:00:25,890 --> 00:00:28,950
And unfortunately, that scenario
is not a rare exception.

11
00:00:29,010 --> 00:00:32,489
And industry report that 87%
of data science project never

12
00:00:32,489 --> 00:00:33,510
make it to the production.

13
00:00:33,840 --> 00:00:36,539
And those that do, many
of them fail silently.

14
00:00:37,039 --> 00:00:41,959
So today we are gonna talk about the
core reason, core failure modes and

15
00:00:42,049 --> 00:00:43,909
deep dive into the why model fail.

16
00:00:44,269 --> 00:00:47,599
We'll talk about the monitoring
framework, how to build our instrumental

17
00:00:47,599 --> 00:00:49,699
panel, what exactly we want to monitor.

18
00:00:50,089 --> 00:00:54,199
The remediation playbook, how to
fix what's broken, the best model

19
00:00:54,349 --> 00:00:58,039
training scenarios and the principles
of the production machine learning.

20
00:00:58,339 --> 00:01:00,079
It's a best practice for success.

21
00:01:00,579 --> 00:01:04,809
And we'll move beyond the theoretical
and dive into the practical challenges

22
00:01:05,229 --> 00:01:06,789
of production machine learning.

23
00:01:07,289 --> 00:01:12,269
So talking about the core failure
modes, we will cover data drift concept

24
00:01:12,269 --> 00:01:17,669
drift label, drift feature pipeline
degradation, and train source queue and

25
00:01:17,669 --> 00:01:20,069
feedback loops, and PS amplification.

26
00:01:20,569 --> 00:01:23,694
And now let's go to
the first failure mode.

27
00:01:24,274 --> 00:01:24,934
Data drift.

28
00:01:25,894 --> 00:01:31,774
So imagine you train a self-driving
car and you do it exclusively on the

29
00:01:31,774 --> 00:01:37,114
sunny and clear days, and now you
want to deploy it in a city famous

30
00:01:37,114 --> 00:01:39,154
for its rainy and foggy weather.

31
00:01:39,755 --> 00:01:42,184
And suddenly the performance
of your car drop.

32
00:01:42,544 --> 00:01:48,294
It's because that the images that camera,
cars, camera received is different

33
00:01:48,324 --> 00:01:50,544
from what was used in a training data.

34
00:01:50,994 --> 00:01:52,740
This is a data drift in a nutshell.

35
00:01:53,240 --> 00:01:56,059
The real world example
is Zillow buying failure.

36
00:01:56,149 --> 00:02:01,560
So in 2020 first Zillow, automated home
buying division, Zillow offers collapsed.

37
00:02:01,620 --> 00:02:07,590
Leading to the staggering was $1 billion
loss in layoff of 25% of its workforce.

38
00:02:07,710 --> 00:02:10,020
And of course, the multiple
factors were in play.

39
00:02:10,020 --> 00:02:13,890
But the main failure was
because of the pricing model.

40
00:02:13,890 --> 00:02:17,670
It failed to the adapt to the
unprecedented market volatility

41
00:02:17,670 --> 00:02:19,850
and shifting by performance of the.

42
00:02:20,165 --> 00:02:21,305
Post pandemic era.

43
00:02:21,805 --> 00:02:24,565
So what the data drift exactly.

44
00:02:24,565 --> 00:02:29,335
So data drift occurs when the distribution
of the input data in production.

45
00:02:29,705 --> 00:02:33,455
It's different from the
distribution of the training data.

46
00:02:33,955 --> 00:02:34,710
So that's.

47
00:02:35,515 --> 00:02:36,715
Tracking this distribution.

48
00:02:36,715 --> 00:02:40,265
It's a good detection method and
the first detection method it's

49
00:02:40,265 --> 00:02:41,795
a population stability index.

50
00:02:42,185 --> 00:02:46,415
It's measures a change in the distribution
of a single variable, and it's

51
00:02:46,415 --> 00:02:50,885
calculated by the bin in the data and
comparing the percentage of observation

52
00:02:50,915 --> 00:02:52,835
in each bin between the two samples.

53
00:02:53,375 --> 00:02:57,595
It's perfect for a tracking of the key
features and its performance over time.

54
00:02:58,095 --> 00:03:01,605
The next one is a Coog Agoro
S Mironov test or Key S test.

55
00:03:02,085 --> 00:03:05,265
It's a non-parametric test that
compares the cumulative distribution

56
00:03:05,265 --> 00:03:07,065
functions over two samples.

57
00:03:07,815 --> 00:03:12,245
And the best way to use it, it's
for a numerical features as the

58
00:03:12,245 --> 00:03:14,405
last one is yen Shannon tests.

59
00:03:14,615 --> 00:03:19,225
It's measures the similarity between
two probability distributions at it's

60
00:03:19,225 --> 00:03:22,675
useful for compare the distributions
of the two categorical features.

61
00:03:23,175 --> 00:03:24,675
Let's talk about the resolution.

62
00:03:24,855 --> 00:03:28,365
And the first one, it's continuous
monitoring and retraining.

63
00:03:28,725 --> 00:03:31,305
So that's the most
fundamental line of defense.

64
00:03:31,815 --> 00:03:36,015
By implementing the automated pipeline
that can continuously monitors the

65
00:03:36,015 --> 00:03:39,615
data drift, we can integrate it into
the, our machine learning pipeline.

66
00:03:39,885 --> 00:03:46,015
And as soon as the data drift detector
alert any problems with our features,

67
00:03:46,285 --> 00:03:48,145
we can initiate the modular training.

68
00:03:48,955 --> 00:03:50,995
The next one is adaptive learning.

69
00:03:51,700 --> 00:03:55,000
For some model, it's possible to
use an online learning techniques

70
00:03:55,030 --> 00:03:58,330
and update the model parameters
when the new data arrived.

71
00:03:58,830 --> 00:04:00,840
And the last one is the main adaptation.

72
00:04:01,750 --> 00:04:07,610
It's a more advanced technique that
attempt to adapt the model training

73
00:04:07,610 --> 00:04:12,020
on the source data distribution
to a different target data

74
00:04:12,020 --> 00:04:14,000
distribution without relabeling.

75
00:04:14,500 --> 00:04:16,180
Now let's talk about the constant lift.

76
00:04:16,680 --> 00:04:21,510
Let's go back to our self driving
car example and it's known fact

77
00:04:21,510 --> 00:04:26,700
that the red octagon signal with a
letter stop mean that car must break.

78
00:04:27,360 --> 00:04:31,980
But what if tomorrow society will decide
to change it, for example, and prepare

79
00:04:32,070 --> 00:04:36,360
to the prepare of stop meaning or just
speed up to clear the intersection.

80
00:04:37,140 --> 00:04:40,890
In that case input feature has
not changed, but the relationship

81
00:04:40,890 --> 00:04:44,870
between input changes input features
and target variable has changed.

82
00:04:45,380 --> 00:04:49,140
This is an example of the tive
talking about the real life the

83
00:04:49,170 --> 00:04:51,930
frog detection models there in
a constant battle with a tive.

84
00:04:52,875 --> 00:04:57,355
So imagine that you train a model
to predict the fraud transactions.

85
00:04:57,595 --> 00:05:01,095
And for example, now you model
learned that transaction from the

86
00:05:01,095 --> 00:05:03,225
specific countries at a specific time.

87
00:05:03,465 --> 00:05:07,625
It's likely a high risk and
but fraudster, they can adapt.

88
00:05:07,625 --> 00:05:11,375
They might start using the VPN pretending
that they're from the low risk countries,

89
00:05:11,645 --> 00:05:13,985
or they just can see their attack times.

90
00:05:14,435 --> 00:05:17,665
So that's a really aggressive
example of the concept drift.

91
00:05:18,165 --> 00:05:22,545
The concept drift, it's usually more
challenging to detect since we don't only

92
00:05:22,545 --> 00:05:26,905
need to look at the input data, but we
also need to track the model performance.

93
00:05:26,935 --> 00:05:30,685
It's offline and online metrics like
accuracy of fund score over time.

94
00:05:31,435 --> 00:05:34,645
And that actually would be the
perfect first detection methods.

95
00:05:34,645 --> 00:05:35,665
Performance monitoring.

96
00:05:36,235 --> 00:05:39,765
We want to monitor the main
performance metrics of our model,

97
00:05:39,765 --> 00:05:42,095
like accuracy, precision F1 score.

98
00:05:42,595 --> 00:05:44,945
And on a labeled validation set.

99
00:05:45,605 --> 00:05:49,255
And as soon as we will see any
sustainable drop, it will be

100
00:05:49,255 --> 00:05:51,445
the signal of the concept drift.

101
00:05:51,945 --> 00:05:53,765
The next one is adaptive window.

102
00:05:54,065 --> 00:05:57,695
It's an algorithm that maintains
a sliding window of a recent data,

103
00:05:57,785 --> 00:06:02,605
so it automatically, that window
automatically grow or shrink the window

104
00:06:02,605 --> 00:06:06,085
size when the statistical property
of the data within the window change.

105
00:06:06,850 --> 00:06:07,510
Signal in the drift.

106
00:06:08,470 --> 00:06:10,690
And the last one is
drift detection methods.

107
00:06:10,740 --> 00:06:15,870
It's when we want to monitor the model
error rate, and as soon as that model

108
00:06:15,870 --> 00:06:20,360
error rate exceeds a certain threshold,
it's a signal of the concept drift.

109
00:06:20,860 --> 00:06:22,810
Now let's talk about
the resolution strategy.

110
00:06:23,320 --> 00:06:25,900
And the first one is online learning.

111
00:06:26,020 --> 00:06:30,630
So we can use the models that
can update its parameters

112
00:06:30,630 --> 00:06:32,820
incrementally when new data arrives.

113
00:06:33,060 --> 00:06:35,880
For example, algorithms like
stochastic gradient, distance,

114
00:06:35,880 --> 00:06:40,080
and naturally suited for this, or
we can use some sample methods.

115
00:06:40,470 --> 00:06:45,600
And sample methods is when each model it's
trained on a different window of the data.

116
00:06:46,100 --> 00:06:51,110
And assemble can give a higher weights
to the recent data, and, for example,

117
00:06:51,110 --> 00:06:53,870
phasing out an older and outdated concept.

118
00:06:54,590 --> 00:06:57,830
And the last one is trigger
based retrain on label data.

119
00:06:57,860 --> 00:07:00,560
This is a most common industry practice.

120
00:07:01,070 --> 00:07:04,930
It's when we, when monitoring
tools, detecting any problems any

121
00:07:04,930 --> 00:07:08,800
significant drops in our model, we
will initiate the model retraining.

122
00:07:09,300 --> 00:07:09,750
Perfect.

123
00:07:10,050 --> 00:07:12,240
Now let's move on to the label drift.

124
00:07:13,200 --> 00:07:17,750
And so imagine that you are working
on a model that predict that.

125
00:07:17,810 --> 00:07:24,420
User will add an item, will click the
add item to the shopping cart button.

126
00:07:24,920 --> 00:07:28,220
And usually probability of
that event is around the 5%.

127
00:07:28,805 --> 00:07:33,545
But now the Blake Friday comes and
the input feature still the same.

128
00:07:33,875 --> 00:07:36,365
And user user intended also the same.

129
00:07:36,365 --> 00:07:41,605
They still want to buy something, but now
the probability that the user will click

130
00:07:41,635 --> 00:07:44,365
add to the cart bottom is around the 20%.

131
00:07:44,865 --> 00:07:49,425
So this is where the proportion
of the model output changed.

132
00:07:49,665 --> 00:07:51,140
And this is an example of the label drift.

133
00:07:51,640 --> 00:07:55,750
Talking about the real life, it's
let's think about the economic

134
00:07:55,750 --> 00:07:57,610
recession and loan defaults model.

135
00:07:57,790 --> 00:08:03,170
For example, model builds to predict the
loan defaults and model training trains

136
00:08:03,320 --> 00:08:08,625
in a stable period of economic can set
the default rates as, for example, 2%.

137
00:08:09,125 --> 00:08:13,175
But let's imagine that unexpected
recession hit and unemployment

138
00:08:13,175 --> 00:08:16,700
skyrocket, and suddenly the actual
default rates jumps to the 10%.

139
00:08:17,200 --> 00:08:22,630
Models still celebrate on the
2% rate, but now it's completely

140
00:08:22,630 --> 00:08:25,750
underestimated the risk across the
board, and it can potentially lead

141
00:08:25,750 --> 00:08:27,340
to the massive financial loss.

142
00:08:27,880 --> 00:08:29,555
This is a label drift in a nutshell.

143
00:08:30,055 --> 00:08:35,405
So talking about the detection, it's
more more similar to the data drift.

144
00:08:35,855 --> 00:08:39,665
Because label drift can be detected by
the monitoring of the distribution of

145
00:08:39,665 --> 00:08:44,825
the target variables itself, so again,
we need to look only on the specific

146
00:08:45,125 --> 00:08:47,315
targets specific targets values.

147
00:08:47,815 --> 00:08:51,955
And the first method, it's monitoring
monitors the class distribution.

148
00:08:52,195 --> 00:08:53,905
It's a most straightforward way.

149
00:08:54,235 --> 00:08:57,985
We will track the proportion of
each class in our label data.

150
00:08:57,985 --> 00:09:02,775
Over time, a significant change in
any amount of object of specific class

151
00:09:03,015 --> 00:09:04,665
might be signal of a label drift.

152
00:09:05,165 --> 00:09:07,925
The next detection method
is a he square test.

153
00:09:08,375 --> 00:09:12,425
It's a statistical test that can
be used to determine if there is

154
00:09:12,425 --> 00:09:15,635
significant association between
two categorical variables.

155
00:09:15,905 --> 00:09:20,535
And it also can be to compare
the distribution of labels in a

156
00:09:20,535 --> 00:09:23,515
reference window in comparison
with the current window.

157
00:09:24,015 --> 00:09:27,995
And the last one is track prediction
distribution, for example.

158
00:09:28,075 --> 00:09:32,755
We can check the proportion of
the amount of the positive class.

159
00:09:33,085 --> 00:09:37,345
For example, if model used to predict
the 5% of positive outcomes, and now it

160
00:09:37,345 --> 00:09:41,975
predict around the 15%, it's could be
noisy, but still indicator of the label

161
00:09:41,975 --> 00:09:44,815
drift, talking about the resolution.

162
00:09:45,145 --> 00:09:47,435
So the first one is recalibration.

163
00:09:47,855 --> 00:09:48,575
It's the.

164
00:09:48,995 --> 00:09:53,685
Model output can often be adjusted post
hoc for the new class distribution.

165
00:09:53,715 --> 00:09:57,765
For example, by using the techniques like
plate scaling or isotonic regression,

166
00:09:58,005 --> 00:10:02,505
it can be used to recalibrate the model
probability scores to better marginality.

167
00:10:03,005 --> 00:10:04,945
The next one is performance weighting.

168
00:10:05,035 --> 00:10:09,975
So during the training we can
assign the, so during the training,

169
00:10:10,035 --> 00:10:11,325
we can have, we can see the.

170
00:10:11,830 --> 00:10:15,189
Difference in the distribution
of the class labels, for example

171
00:10:15,380 --> 00:10:19,850
minority and majority of the objects
of the targets of the classes.

172
00:10:20,330 --> 00:10:24,370
And we can use the weights to adjust,
for example, the higher weights to

173
00:10:24,370 --> 00:10:27,880
the minority and lower weights to
the majority to balance our data.

174
00:10:28,380 --> 00:10:30,890
And the last one is
cost sensitive learning.

175
00:10:31,310 --> 00:10:35,010
When we train our model we can
use a specific learning algorithm

176
00:10:35,200 --> 00:10:39,670
which can finalize the more costly
errors for model more heavily.

177
00:10:40,570 --> 00:10:44,280
This can make the model more robust
to change in a class distribution.

178
00:10:44,780 --> 00:10:45,080
Good.

179
00:10:45,500 --> 00:10:48,920
Now let's talk about the failure
mode for feature pipeline

180
00:10:48,920 --> 00:10:50,355
degradation and train source queue.

181
00:10:50,855 --> 00:10:54,725
So imagine that you're a
chef working on the price.

182
00:10:55,225 --> 00:11:01,465
And so now p recip is ready and it's
flawless, and you send it to the

183
00:11:01,465 --> 00:11:03,745
chain of the really busy restaurants.

184
00:11:04,345 --> 00:11:08,845
And for example, one restaurant
is using different ingredients on

185
00:11:08,845 --> 00:11:11,095
salted butter against the salted.

186
00:11:11,725 --> 00:11:15,740
Another one has 20 degrees o of oven.

187
00:11:16,240 --> 00:11:19,750
And in the third one, for example,
keen ingredients is simply missing.

188
00:11:20,240 --> 00:11:23,800
The is type hasn't changed, but
the ingredients and the cooking

189
00:11:23,800 --> 00:11:25,330
environment has been compromised.

190
00:11:25,880 --> 00:11:31,475
This is an example of the feature pipeline
degradation, and in the reality the world.

191
00:11:31,840 --> 00:11:36,550
The best example would be the
Google Diabetic Rec Party ai.

192
00:11:37,150 --> 00:11:41,350
So once Google developed a state of
the art deep learning model that could

193
00:11:41,480 --> 00:11:46,040
detect the diabetic retinopathy by
using the high quality pictures and

194
00:11:46,100 --> 00:11:50,240
the model performance was on pair
with a real human ophthalmologist.

195
00:11:50,840 --> 00:11:55,040
And as I said in the lab, they used a
high quality, perfectly captured images.

196
00:11:55,490 --> 00:11:59,810
But in the reality when the model was
deployed in the clinic in Thailand, it's.

197
00:12:00,245 --> 00:12:04,085
Performance dropped because the
nurses working in a busy poorly.

198
00:12:04,085 --> 00:12:08,405
Lead conditions often capture
images in the very lower quality.

199
00:12:08,705 --> 00:12:12,125
So lead to the model mis classifications.

200
00:12:12,625 --> 00:12:16,495
This is again an example where the
environment has been compromised.

201
00:12:16,705 --> 00:12:18,775
Lead to the Fisher Pipeline degradation.

202
00:12:19,275 --> 00:12:24,425
So talking about the best
way to detect it, we need to

203
00:12:24,425 --> 00:12:25,925
consider different issue types.

204
00:12:25,955 --> 00:12:28,385
For example, the first one
is a data quality issue.

205
00:12:29,075 --> 00:12:31,205
It's when the data itself is corrupted.

206
00:12:31,205 --> 00:12:35,595
For example, some column can have
different data types or increased

207
00:12:35,595 --> 00:12:36,795
amount of the new variables.

208
00:12:37,515 --> 00:12:40,065
New variables can even be
unexpected for this column.

209
00:12:40,525 --> 00:12:44,935
It's where the data validation framework,
like great expectation or DQ, can help us.

210
00:12:45,425 --> 00:12:50,155
This tool allow us to define suit
of expectations for our data.

211
00:12:50,455 --> 00:12:53,875
For example, expected amount
of new variables or expected

212
00:12:53,875 --> 00:12:55,705
mean in the shorten threshold.

213
00:12:56,205 --> 00:12:58,985
This check will run every
time when the new data arrive.

214
00:12:59,485 --> 00:13:01,895
The second issue type is schema changes.

215
00:13:01,955 --> 00:13:06,325
This is pretty common for big corporations
where multiple people involved into

216
00:13:06,325 --> 00:13:09,745
a different part of machine learning
pipeline, for example, multiple

217
00:13:09,745 --> 00:13:13,900
people responsible for the feature
lifecycle, model lifecycle, et cetera.

218
00:13:14,400 --> 00:13:17,840
And this is where, for example,
the schema had been compromised.

219
00:13:17,840 --> 00:13:22,070
For example column was renamed
removed, or the data type changed.

220
00:13:22,610 --> 00:13:25,340
And it's where the schema
monitoring can help us.

221
00:13:25,670 --> 00:13:30,440
And our pipeline will automatically
validate schema and prevent the

222
00:13:30,440 --> 00:13:32,870
corrupted data lead reach the model.

223
00:13:33,770 --> 00:13:35,980
And the last one is train source queue.

224
00:13:36,460 --> 00:13:41,290
It's when, we can have a feature
value from a specific pipeline or

225
00:13:41,380 --> 00:13:42,910
from the specific part of the code.

226
00:13:43,240 --> 00:13:46,270
And this pipeline or part of
the code can use a different

227
00:13:46,270 --> 00:13:51,070
packages, for example leading to
the different value of the feature.

228
00:13:51,550 --> 00:13:58,330
So it's where we want to log inputs
and outputs of the training and of

229
00:13:58,330 --> 00:14:02,910
the same data, but on the different
environment training and the production.

230
00:14:03,180 --> 00:14:04,440
And if.

231
00:14:04,940 --> 00:14:08,660
Training environment and
production environment, and with

232
00:14:08,660 --> 00:14:12,820
the same model produce different
responses for the same data.

233
00:14:12,910 --> 00:14:16,300
This is a signal of the
feature pipeline degradation.

234
00:14:16,800 --> 00:14:19,830
So talking about the resolution,
the main resolution here would be.

235
00:14:20,415 --> 00:14:24,095
The feature store, it's a gold
standard industry gold standard.

236
00:14:24,675 --> 00:14:28,905
So the feature store is a centralized
system that manages the definition,

237
00:14:28,905 --> 00:14:33,015
computation and solving of feature
for both training and environment.

238
00:14:33,345 --> 00:14:37,165
And it's programmatically
eliminate the class of problems.

239
00:14:37,665 --> 00:14:40,035
The next one is robust data validation.

240
00:14:40,305 --> 00:14:45,335
It's, as I said, we can integrate the
data validation checks into the directly

241
00:14:45,335 --> 00:14:46,595
into the machine learning pipeline.

242
00:14:46,845 --> 00:14:50,835
Preventing the bio corrupt data will
reach the model and cause any harm.

243
00:14:51,465 --> 00:14:54,285
And the next one is data contracts.

244
00:14:54,405 --> 00:14:55,545
The data contracts.

245
00:14:55,935 --> 00:15:00,585
It's when we want to establish the formal
agreement between the different team

246
00:15:00,585 --> 00:15:02,895
working on a machine learning pipeline.

247
00:15:03,585 --> 00:15:07,975
For example to have an agreement in a
schema changed and prepare the model

248
00:15:07,975 --> 00:15:10,695
for the, any feature changes, let's say.

249
00:15:11,565 --> 00:15:13,545
And the last one, it's a containerization.

250
00:15:13,575 --> 00:15:16,745
It's ba basically packaging
our model and its dependencies

251
00:15:17,465 --> 00:15:20,275
ensuring that the training and
production environment is the same.

252
00:15:20,775 --> 00:15:22,635
Now let's talk about the last one.

253
00:15:22,665 --> 00:15:25,205
It's feedback loops and b simplification.

254
00:15:25,895 --> 00:15:30,395
So let's think about the popular
musing streaming music streaming

255
00:15:30,395 --> 00:15:33,185
service, and its recommendation engine.

256
00:15:33,185 --> 00:15:34,055
Recommendation algorithm.

257
00:15:34,055 --> 00:15:35,675
Suggest you have few rock on.

258
00:15:36,095 --> 00:15:37,535
And yeah, you like them.

259
00:15:38,045 --> 00:15:42,195
And now in return, the algorithm
re recommend you a few more rock

260
00:15:42,195 --> 00:15:44,175
song and you like them as well.

261
00:15:44,625 --> 00:15:48,825
And now algorithm thinks that
you are diehard rock fan and it's

262
00:15:48,825 --> 00:15:52,035
completely ignoring your potential
interest in jazz and classical music.

263
00:15:52,995 --> 00:15:59,085
So the model created a reality by
amplification its initial bias.

264
00:15:59,805 --> 00:16:03,495
The real world example is a
compass recidivism algorithm.

265
00:16:03,525 --> 00:16:04,575
So the compass.

266
00:16:04,635 --> 00:16:09,255
A correctional offender management
profiling for alternative sanctions.

267
00:16:09,645 --> 00:16:13,935
It's a tool that had been used
by the United States Justice

268
00:16:13,935 --> 00:16:17,565
System to predict the likelihoods
of a defendant re-offending.

269
00:16:18,405 --> 00:16:22,605
And 2016 investigation revealed
that the algorithm was significantly

270
00:16:22,695 --> 00:16:26,115
pierced against the black defendants
flagging them as a higher risk for

271
00:16:26,115 --> 00:16:28,575
the future crimes at nearly twice.

272
00:16:28,575 --> 00:16:31,335
Rate as a defendant
with a similar history.

273
00:16:32,235 --> 00:16:33,735
Why defendants with a similar history.

274
00:16:34,185 --> 00:16:38,625
The defendant flagged as a high risk
and received a longer sentence be denied

275
00:16:38,625 --> 00:16:41,385
parole and faced with a heavier police.

276
00:16:41,445 --> 00:16:46,005
And all of that lead to the higher
likelihood of the future arrest regarding

277
00:16:46,005 --> 00:16:47,865
their individual individual actions.

278
00:16:48,255 --> 00:16:52,185
So this is where, again,
the feedback got broken.

279
00:16:52,685 --> 00:16:56,945
So talking about the detection, they
usually feedback loops occur when

280
00:16:56,945 --> 00:17:02,765
the model output y from t let's say
timestamp influence the state of the

281
00:17:02,765 --> 00:17:07,420
world that will be used as an input
for the model retraining XT plus one.

282
00:17:07,920 --> 00:17:11,730
And yeah, so we can use a several
detection method to prevent it.

283
00:17:11,730 --> 00:17:14,580
And the first one is
diversity and exposure metric.

284
00:17:15,030 --> 00:17:18,690
For example, we can quantify
the variety of prediction in

285
00:17:18,690 --> 00:17:19,950
the mo the model is making.

286
00:17:20,100 --> 00:17:23,240
For example, for the recommendation
system, we can ensure that number

287
00:17:23,240 --> 00:17:25,750
of unique items we can ensure
that there are specific, unique

288
00:17:25,750 --> 00:17:27,015
items recommended over appear.

289
00:17:27,515 --> 00:17:33,195
Or we can use an AB test a test like
for example, run a small percentage

290
00:17:33,225 --> 00:17:38,165
of a user that use a non-personalized
version of our software and the

291
00:17:38,315 --> 00:17:39,875
personalized model recommendation.

292
00:17:40,205 --> 00:17:45,205
And if we can see that the behavioral
of the model driven group has changed.

293
00:17:45,655 --> 00:17:48,550
So it can be a strong
feedback loop in a place.

294
00:17:49,050 --> 00:17:53,550
And the last one is a casual inference
techniques so we can employ more advanced

295
00:17:53,550 --> 00:17:55,770
statistical methods to try dis tangle.

296
00:17:55,770 --> 00:17:58,770
The model's influence from
the user organic preferences.

297
00:17:59,190 --> 00:18:02,750
It's, for example, techniques like
uplifting model can help estimate the

298
00:18:02,750 --> 00:18:05,480
true persuasive effect in a production.

299
00:18:06,470 --> 00:18:10,800
It's can be used when, for
example, we cannot use the A tests.

300
00:18:11,300 --> 00:18:15,200
So talking about the resolution, the
first one is exploration strategy.

301
00:18:15,360 --> 00:18:18,200
For example, we can extensionally
introduce some randomness

302
00:18:18,200 --> 00:18:19,640
into our recommendation model.

303
00:18:20,100 --> 00:18:24,620
So this will allow the model to collect
data on a wider range of possibilities.

304
00:18:25,400 --> 00:18:30,470
For example, if we recommend the batch
of 10 elements, one or two elements

305
00:18:30,470 --> 00:18:32,705
could be randomly randomly selected.

306
00:18:33,205 --> 00:18:35,005
The next one is positional dbs.

307
00:18:35,005 --> 00:18:38,825
N. So when we talk about the
recommendation system usually they

308
00:18:38,825 --> 00:18:42,585
can return rank at least where
the higher elements usually has a

309
00:18:42,585 --> 00:18:45,885
higher probability that the user
will click of them and or like them.

310
00:18:46,455 --> 00:18:49,425
And the model can misrepresented
as a stronger preference.

311
00:18:49,725 --> 00:18:52,725
So that's where we want to add some
positional, the BS and technique.

312
00:18:52,725 --> 00:18:56,775
So tell the model about the position
of the item in a recommended list.

313
00:18:57,275 --> 00:19:00,215
And the last one is failure,
fairness constraints.

314
00:19:00,665 --> 00:19:04,445
It's during the model training we can
introduce a mathematical constraints

315
00:19:04,445 --> 00:19:08,645
to ensure that the model prediction
satisfies a certain fairness criteria.

316
00:19:08,855 --> 00:19:13,105
For example, if we work on a loan
approval model, we can just use

317
00:19:13,105 --> 00:19:16,725
statistical statistical concepts,
statistical similarity across

318
00:19:16,725 --> 00:19:17,735
different demographic groups.

319
00:19:18,235 --> 00:19:24,085
Now we covered the main main problems
and we can think about the proper way

320
00:19:24,085 --> 00:19:26,335
to set up the monitoring and yeah.

321
00:19:26,335 --> 00:19:29,365
So deploying a model without the
monitoring, it's like flying on

322
00:19:29,365 --> 00:19:31,045
a plane without an instruments.

323
00:19:31,285 --> 00:19:33,775
We are simply blind to any changes.

324
00:19:34,155 --> 00:19:37,245
And it's also can make the
debug in this a, a nightmare.

325
00:19:37,665 --> 00:19:40,065
So the first thing that we
want to cover with additional

326
00:19:40,065 --> 00:19:41,595
monitoring is model performance.

327
00:19:41,955 --> 00:19:45,715
We want to track the business metrics
and the model performance metrics

328
00:19:45,815 --> 00:19:47,855
online and offline model performance.

329
00:19:48,285 --> 00:19:54,665
It's recall F1 score accuracy and as an
online, for example, CTR or revenue lift.

330
00:19:55,165 --> 00:19:57,535
The next one, which we want
to cover is data health.

331
00:19:57,865 --> 00:20:01,645
It's statistical integrity of the
data which we feed to our model.

332
00:20:02,615 --> 00:20:08,555
This is our early warning system, and we
want to track the PSI K statistic, new

333
00:20:08,555 --> 00:20:12,085
rates, data types Hema changes me and Max.

334
00:20:12,385 --> 00:20:15,415
All of that type of
changes in our features.

335
00:20:16,240 --> 00:20:17,650
The last one is system health.

336
00:20:17,830 --> 00:20:21,640
So system health is an operational
performance of the whole infrastructure,

337
00:20:21,970 --> 00:20:25,600
and it's not only perfect for
debugging, but it's also perfect

338
00:20:25,600 --> 00:20:30,180
for understanding the bottlenecks
and plan our future optimization.

339
00:20:30,510 --> 00:20:34,710
So we want to track the inference
latency for output error rates

340
00:20:34,710 --> 00:20:37,030
C-P-O-G-P-U and memory utilization.

341
00:20:37,530 --> 00:20:41,130
And yeah, you don't need to
implement anything from scratch.

342
00:20:41,370 --> 00:20:45,000
There exists a lot of open source
tools that can provide this

343
00:20:45,000 --> 00:20:46,380
functionality out of the box.

344
00:20:46,620 --> 00:20:51,840
For example in open source tools like
evidentiary AI in NEML and IB detection

345
00:20:52,250 --> 00:20:55,460
they provide framework for detecting
data drift concept drift, and the

346
00:20:55,760 --> 00:20:57,475
performance model performance degradation.

347
00:20:57,975 --> 00:21:03,525
There also exists a lot of commercial
platforms like yaps, Fiddler ai arise ai.

348
00:21:04,155 --> 00:21:08,360
They not only offer you end-to-end
observability platforms, but also can

349
00:21:08,360 --> 00:21:13,400
allow you to integrate your model into the
more broader machine learning ecosystem.

350
00:21:13,900 --> 00:21:18,460
Now when, for example, we have a
proper detection and let's say that

351
00:21:18,490 --> 00:21:23,230
our detection framework just signal
alerting, and so we need to understand.

352
00:21:23,800 --> 00:21:26,340
What we want to do how we
want to retrain our model.

353
00:21:27,090 --> 00:21:28,980
And there exist different strategies.

354
00:21:29,100 --> 00:21:31,680
And the first one is
a time-based strategy.

355
00:21:32,190 --> 00:21:35,670
It's basically the skittle base,
for example, when we want to

356
00:21:35,670 --> 00:21:39,390
train, retrain our model on a
daily, weekly, or monthly basis.

357
00:21:39,960 --> 00:21:44,810
And it's on the one hand it's simple
to implement and it's predictable,

358
00:21:45,050 --> 00:21:48,020
but it's also highly inefficient and.

359
00:21:48,520 --> 00:21:52,000
Waste of the resources because
not always we need to retrain our

360
00:21:52,000 --> 00:21:56,470
model so we can think about the
performance based on that case.

361
00:21:56,470 --> 00:22:00,340
For example, we can retrain our model
once key performance metrics drop.

362
00:22:00,880 --> 00:22:04,690
It's directly tied to the business
variable, and it's a train only when

363
00:22:04,780 --> 00:22:08,380
we need it, but unfortunately, it's a
reactive and not proactive approach.

364
00:22:08,380 --> 00:22:13,030
So the model already been underperforming
and it's already produced some losses.

365
00:22:13,530 --> 00:22:14,070
Okay.

366
00:22:14,190 --> 00:22:16,380
In that case, we can think
about the drift based approach.

367
00:22:17,190 --> 00:22:22,460
It's when we can we can retrain the
model once we can observe any drift

368
00:22:22,460 --> 00:22:26,360
metrics, any drift feature drifts,
for example, by track and PSI or

369
00:22:26,360 --> 00:22:28,300
key statistic for key features.

370
00:22:28,800 --> 00:22:30,300
And this approach is proactive.

371
00:22:30,600 --> 00:22:35,450
So we can trigger we can trigger a retrain
before the model performance drop, but

372
00:22:35,510 --> 00:22:39,170
it's also can be noisy and not all that
drift lead to the performance degradation.

373
00:22:39,680 --> 00:22:43,550
So instead we can use a hybrid approach,
and it's a recommended approach.

374
00:22:43,550 --> 00:22:46,970
It's basically a combination
combination of multiple triggers

375
00:22:47,000 --> 00:22:48,800
into more sophisticated policy.

376
00:22:49,190 --> 00:22:52,850
It's a more robust and practical
approach, and it's balanced pros

377
00:22:52,850 --> 00:22:54,200
and cons of the other methods.

378
00:22:54,500 --> 00:22:58,370
But unfortunately, it's also more
complex to design and implement it.

379
00:22:58,385 --> 00:23:01,680
It require a lot of adjusting
of the multiple thresholds.

380
00:23:02,180 --> 00:23:05,370
Yeah, talking about the best
practicing for building our

381
00:23:05,370 --> 00:23:06,390
machine learning pipeline.

382
00:23:06,890 --> 00:23:09,460
The first one is designed
for drift from day one.

383
00:23:09,730 --> 00:23:12,910
So don not treat your monitoring
and retraining as an afterthoughts.

384
00:23:13,210 --> 00:23:17,200
The architecture for detection and
responding to drift should be designed

385
00:23:17,200 --> 00:23:18,700
in parallel with the model itself.

386
00:23:19,200 --> 00:23:21,800
The next one is maintain
training, serving parity.

387
00:23:22,320 --> 00:23:25,230
So we need to use an, we need
to ensure that we are using the

388
00:23:25,230 --> 00:23:30,040
identical code and libraries for
production and training environment.

389
00:23:30,540 --> 00:23:35,469
The next one is grad or allowed, so that's
not a secret, that never deploy your

390
00:23:35,469 --> 00:23:37,600
model directly to 100% of the traffic.

391
00:23:38,110 --> 00:23:41,409
Just deploy it to the low
amount, for example, 5% traffic

392
00:23:41,409 --> 00:23:43,060
and monitor its performance.

393
00:23:43,420 --> 00:23:47,290
And once you ensure that the performance
of your model on payer or even

394
00:23:47,290 --> 00:23:51,520
better than the production in that
case, you can roll out those 100%.

395
00:23:52,020 --> 00:23:55,159
The next one is instrument
for a feedback model.

396
00:23:55,159 --> 00:23:58,850
Performance can only be measured if
you have a ground truth and you need

397
00:23:58,850 --> 00:24:01,909
to design your system to collect
the feedback for models prediction.

398
00:24:02,554 --> 00:24:06,054
It's also helpful for the not
only for the understanding of the

399
00:24:06,054 --> 00:24:09,725
model performance, but also for
future improvement of the model.

400
00:24:10,225 --> 00:24:12,025
The next one, it's document everything.

401
00:24:12,365 --> 00:24:13,775
It's when the future you will.

402
00:24:13,775 --> 00:24:14,345
Thank you.

403
00:24:14,795 --> 00:24:16,535
It's, we need to track everything.

404
00:24:16,535 --> 00:24:20,105
Model cards, data lineage, decision
logs, everything that possible.

405
00:24:20,435 --> 00:24:24,835
It's not only helpful for understanding
the problems with the pipeline and yeah.

406
00:24:24,895 --> 00:24:27,535
Monitoring of the model, machine
learning pipelines without.

407
00:24:28,155 --> 00:24:28,785
Proper login.

408
00:24:28,785 --> 00:24:32,625
It's a real nightmare, but it's also
helpful for understanding of the

409
00:24:32,655 --> 00:24:34,305
bottlenecks and future improvements.

410
00:24:34,805 --> 00:24:38,825
Yeah, my final suggestion is, the
first one is stop thinking of the

411
00:24:38,825 --> 00:24:43,235
machine learning as a project and
start, think about it as a product.

412
00:24:43,575 --> 00:24:47,775
Different part of the machine learning
pipeline has has all its own lifecycle,

413
00:24:47,775 --> 00:24:50,265
features, models even infrastructure.

414
00:24:50,765 --> 00:24:53,465
The next one is an invest into the lops.

415
00:24:53,885 --> 00:24:58,355
So we already talked a lot about why we
need to add additional monitor into our

416
00:24:58,355 --> 00:25:00,945
models and testing the model performance.

417
00:25:01,635 --> 00:25:04,375
And the last one is foster
a cross-functional car,

418
00:25:04,855 --> 00:25:06,055
cross-functional culture.

419
00:25:06,355 --> 00:25:09,175
It's data scientist, machine
learning engineers, software

420
00:25:09,175 --> 00:25:10,585
engineers and product managers.

421
00:25:10,585 --> 00:25:14,605
They all must work together to build
and maintain this complex system.

422
00:25:15,105 --> 00:25:16,815
Yeah, that's all from my side.

423
00:25:16,815 --> 00:25:18,105
Thanks a lot everyone.

424
00:25:18,385 --> 00:25:21,985
Feel free to reach out to me on LinkedIn
in case if you will have any questions.

