1
00:00:00,190 --> 00:00:05,159
Hey there, welcome to my talk
at the Conf 42 cloud event.

2
00:00:05,800 --> 00:00:08,560
Today I'm going to be talking
about exploring container native

3
00:00:08,569 --> 00:00:10,490
simplicity for AI ML workloads.

4
00:00:11,000 --> 00:00:15,240
I'm Shailambha and you can follow me
on X or Twitter at TheRateHowDevelop

5
00:00:15,620 --> 00:00:19,750
and I'm also a community member of
the open source project KitOps, which

6
00:00:19,750 --> 00:00:24,089
is currently being donated to the
Cloud Native Computing Foundation and

7
00:00:24,099 --> 00:00:28,189
is undergoing application for being
a sandbox project within the CNCF.

8
00:00:28,750 --> 00:00:30,490
So without further ado, let's get started.

9
00:00:30,980 --> 00:00:37,230
Now, we truly live in an era where
we are seeing a lot of adoption of AI

10
00:00:37,579 --> 00:00:42,089
and different companies are adopting
generative AI in their workloads or

11
00:00:42,189 --> 00:00:44,489
shipping products that have gen AI.

12
00:00:44,989 --> 00:00:51,475
Now, One of the key challenges that have
always existed ever since the era of just

13
00:00:51,535 --> 00:00:55,355
typical machine learning models and of
course today with the generative AI models

14
00:00:55,585 --> 00:01:00,874
is that transforming these AI models from
these experimental Jupyter notebooks being

15
00:01:00,874 --> 00:01:05,250
written by interested AI researchers,
data scientists into robust production

16
00:01:05,250 --> 00:01:09,350
ready deployable machine learning
models can be extremely challenging.

17
00:01:09,390 --> 00:01:12,760
And there are a number of different
reasons because these experimental

18
00:01:12,760 --> 00:01:17,920
notebooks do not offer the capability of
direct deployment with the help of a CICD

19
00:01:17,920 --> 00:01:20,729
solution or perhaps on top of communities.

20
00:01:20,970 --> 00:01:24,870
In fact, like a lot of times there
are, a lot of transformational

21
00:01:24,880 --> 00:01:28,319
steps that are required to move away
from these experimental notebooks.

22
00:01:28,630 --> 00:01:33,469
And there's a really unique statistic over
here that almost 80 percent of the machine

23
00:01:33,469 --> 00:01:38,010
learning models that are being written
by the researchers or by the scientists

24
00:01:38,269 --> 00:01:43,860
never make it to production because of
the complex model deployment issues or the

25
00:01:43,860 --> 00:01:45,679
procedures that we have just spoken about.

26
00:01:46,210 --> 00:01:50,300
what is the biggest challenge today that
we find with machine learning packaging?

27
00:01:50,320 --> 00:01:53,800
And the reason we are talking about
packaging is that we want to move these

28
00:01:53,819 --> 00:01:58,929
models from these Jupyter notebooks into
production so that they can be used.

29
00:01:59,300 --> 00:02:02,260
but the biggest one is that
there is actually no standard

30
00:02:02,269 --> 00:02:06,130
for packaging and versioning the
various artifacts which are needed.

31
00:02:06,480 --> 00:02:08,410
to reproduce an AML project.

32
00:02:08,440 --> 00:02:12,780
So of course, as we know that an AML
project is not just your source code

33
00:02:12,780 --> 00:02:15,440
with the version dependencies that
you will have in a typical software.

34
00:02:15,860 --> 00:02:20,710
There are different pieces or there
are different puzzles or parts of the

35
00:02:20,710 --> 00:02:22,460
puzzle of a machine learning project.

36
00:02:22,819 --> 00:02:27,860
So it starts off with your models that are
typically stored in your Zupyte notebooks

37
00:02:27,900 --> 00:02:29,700
or might be part of some envelopes tool.

38
00:02:30,080 --> 00:02:33,640
Then your data sets might be stored
in a data lake or in a database.

39
00:02:34,125 --> 00:02:36,465
Your code for your project
might be stored now.

40
00:02:36,965 --> 00:02:41,495
Get repository and then all of the
metadata that's involved with your models

41
00:02:41,525 --> 00:02:45,944
such as the hyper parameter tuning or the
features of the weights might be scattered

42
00:02:45,944 --> 00:02:47,834
across different storage systems.

43
00:02:48,085 --> 00:02:52,654
So what you're seeing is that there
are all of these moving fragments of

44
00:02:52,654 --> 00:02:56,165
a machine learning project and they're
all being stored in different locations.

45
00:02:56,435 --> 00:02:58,005
So being able to then.

46
00:02:58,585 --> 00:03:03,575
Get all of them under one location and
then using them for productionizing them

47
00:03:03,575 --> 00:03:08,245
can be a big challenge So there is this
lack of standardization for packaging

48
00:03:08,245 --> 00:03:14,115
these artifacts, which is causing a lot
of different issues Now why can't we

49
00:03:14,115 --> 00:03:17,195
actually use the same pipeline for MLOps?

50
00:03:17,825 --> 00:03:21,435
You know that we might actually
use for conventional DevOps based

51
00:03:21,435 --> 00:03:25,015
applications So there are a lot of
different reasons for that, right?

52
00:03:25,265 --> 00:03:29,520
So as we covered that Because of the
fact that the nature of a machine

53
00:03:29,520 --> 00:03:35,079
learning project is a bit different as
compared to a software project, right?

54
00:03:35,510 --> 00:03:40,390
So that's the reason that we cannot just
directly just use all of the tools that

55
00:03:40,390 --> 00:03:44,470
we typically use for a DevOps project
and apply that for machine learning

56
00:03:44,589 --> 00:03:48,760
and that's also because for machine
learning you might actually need more

57
00:03:48,810 --> 00:03:54,010
expertise and the complexity of running
these machine learning projects is also

58
00:03:54,120 --> 00:03:58,920
significantly different because you
generally need a things such as GPUs or

59
00:03:58,920 --> 00:04:02,450
even a cluster of GPUs if you're running
very large machine learning models.

60
00:04:02,810 --> 00:04:07,230
So the above challenges have
essentially led organizations to adopt

61
00:04:07,280 --> 00:04:09,480
a completely separate MLOps pipeline.

62
00:04:09,750 --> 00:04:13,740
However, implementing that comes
with its own set of challenges,

63
00:04:13,760 --> 00:04:17,820
which is, the data management and
standardization, the running cost of

64
00:04:18,090 --> 00:04:20,590
having to deal with expensive hardware.

65
00:04:20,865 --> 00:04:23,795
Security and compliance that
has to be occurring with

66
00:04:23,805 --> 00:04:25,325
machine learning itself, right?

67
00:04:25,345 --> 00:04:28,765
And then of course, managing the
complex model life cycle, the

68
00:04:28,765 --> 00:04:32,404
different steps involving with pre
training the model, then training

69
00:04:32,445 --> 00:04:37,180
it and then inference, all of those
lead to their own set of challenges.

70
00:04:37,180 --> 00:04:41,685
And a lot of times the standard SRE
teams or DevOps teams might not be

71
00:04:41,695 --> 00:04:45,155
equipped in order how to handle all
of these challenges because machine

72
00:04:45,155 --> 00:04:46,245
learning might be new for them.

73
00:04:46,905 --> 00:04:50,730
if we explore this even further, we
will have distinct workflows that will

74
00:04:50,760 --> 00:04:53,920
be for their scientists because they
are working with the Python notebooks

75
00:04:53,920 --> 00:04:57,740
or model training DevOps team because
they are dealing with the deployment

76
00:04:57,740 --> 00:05:00,280
and setting up the infrastructure
that is required for deployment.

77
00:05:00,725 --> 00:05:05,055
And all of this basically leads to
increased cost because you're more

78
00:05:05,055 --> 00:05:08,415
often than not having to duplicate
the efforts because you're having

79
00:05:08,415 --> 00:05:11,845
a separate DevOps pipeline and then
you have a separate MLOps pipeline

80
00:05:12,144 --> 00:05:14,945
and then you have to do the manual
handoff between the different teams.

81
00:05:15,314 --> 00:05:17,205
So this increases the technical depth.

82
00:05:17,610 --> 00:05:20,810
And, can lead to inconsistent
deployment processes, right?

83
00:05:21,190 --> 00:05:25,719
So if we also look at how over
the duration of time we have

84
00:05:25,719 --> 00:05:29,359
seen, the different kind of,
specific centric approach.

85
00:05:29,369 --> 00:05:32,189
So we of course started off with
machine centric where we were

86
00:05:32,189 --> 00:05:34,369
just running simple servers.

87
00:05:34,400 --> 00:05:38,719
Then we went into VMs because we
found that, okay, like there are a

88
00:05:38,719 --> 00:05:43,060
lot of inherent benefits of being
able to run VMs because then, you can

89
00:05:43,060 --> 00:05:47,360
actually, Virtualize your software and
not have to worry about whether it's

90
00:05:47,880 --> 00:05:50,270
supported on a local server or not.

91
00:05:50,560 --> 00:05:55,770
And then we went into container centric
approach where we saw that we are

92
00:05:55,770 --> 00:06:00,750
able to ship, your applications in
a much more smaller footprint while

93
00:06:00,949 --> 00:06:05,080
not having to worry about the system
dependencies because you can run these.

94
00:06:05,190 --> 00:06:08,900
particular, small containers
in the host VM, right?

95
00:06:08,930 --> 00:06:11,640
And not have to ship an entire
operating system that we had

96
00:06:11,640 --> 00:06:13,230
to do with the virtual machine.

97
00:06:13,720 --> 00:06:18,290
So now, of course, we are looking
at what we are calling as a model

98
00:06:18,290 --> 00:06:21,580
centric approach where we are
able to actually containerize.

99
00:06:22,530 --> 00:06:25,990
Not only the model, but all of the
different dependencies of a model.

100
00:06:26,090 --> 00:06:30,450
So how would that look like if you
were to build a model centric approach?

101
00:06:30,510 --> 00:06:31,390
How would that look like?

102
00:06:31,390 --> 00:06:33,740
So that's what we're going to
be covering in today's session.

103
00:06:34,150 --> 00:06:37,280
And that is where KitOps actually helps
us to solve this particular problem.

104
00:06:37,660 --> 00:06:41,550
So KitOps is a completely open
source standard based packaging and

105
00:06:41,550 --> 00:06:46,140
versioning system that has been designed
specifically for AI and ML projects.

106
00:06:46,420 --> 00:06:51,220
So what KitOps allows you to do is that It
takes advantage of your existing software

107
00:06:51,220 --> 00:06:57,690
standards and tools that can be used by
the DevOps and the SRE teams to basically

108
00:06:57,700 --> 00:06:59,150
build containerized applications.

109
00:06:59,160 --> 00:07:04,070
So the idea is that it will use the
similar OCI compliant format, which

110
00:07:04,130 --> 00:07:09,055
allows you to package your Standard
software applications as container images

111
00:07:09,085 --> 00:07:13,435
and then you can deploy these container
images on any model registry or for that

112
00:07:13,435 --> 00:07:15,725
matter a private or a public registry.

113
00:07:15,885 --> 00:07:21,285
We can use those same set of tools
and use an OCI compliant format such

114
00:07:21,285 --> 00:07:24,925
that it can be, you can take all
the different components of your

115
00:07:24,925 --> 00:07:26,455
machine learning model systems.

116
00:07:26,855 --> 00:07:30,175
And you can basically package
the different components with our

117
00:07:30,185 --> 00:07:34,965
models, datasets, and metadata into
a format that is called as model kit.

118
00:07:35,265 --> 00:07:37,605
And this model kit is
completely OCI compliant.

119
00:07:38,085 --> 00:07:42,835
So KitOps allows AI teams to not have
to deal with all of these different

120
00:07:42,875 --> 00:07:45,595
locations where different parts
of your model are being stored.

121
00:07:45,885 --> 00:07:48,165
You can store all of them
together into this model kit.

122
00:07:48,525 --> 00:07:52,125
Now let's dive deeper into what
this model kit basically means.

123
00:07:52,355 --> 00:07:56,795
So at the heart of KitOps, what we have
mentioned is model kit, which is, as I

124
00:07:56,795 --> 00:08:02,135
mentioned, an OCI compliant packaging
format that will seamlessly take all of

125
00:08:02,135 --> 00:08:03,415
the different artifacts that you have.

126
00:08:03,730 --> 00:08:07,010
In your machine learning life cycle
and this basically includes the

127
00:08:07,050 --> 00:08:11,270
data set and the code configuration
model itself and package it together

128
00:08:11,530 --> 00:08:15,200
into just one single unit, which is
called as a model kit and then can be

129
00:08:15,200 --> 00:08:17,390
deployed to any OCI compliant registry.

130
00:08:17,400 --> 00:08:20,700
So whether you have things like a
docker hub or you might have a private.

131
00:08:21,200 --> 00:08:26,160
A cloud based registry like a Azure,
registry or an AWS or Google registry,

132
00:08:26,430 --> 00:08:31,850
you can deploy this particular model kit
on those same set of registry, right?

133
00:08:32,050 --> 00:08:36,870
So it uses the OCI compliant standard and,
of course it, you can basically version

134
00:08:36,880 --> 00:08:38,420
all the different parts of your code.

135
00:08:38,500 --> 00:08:42,450
at the core, you will basically define
what we call as a kit file, which is

136
00:08:42,450 --> 00:08:44,290
similar to something like a Docker file.

137
00:08:44,850 --> 00:08:47,980
And then, your model, the code,
dataset, documentation, all of

138
00:08:47,980 --> 00:08:49,390
them will be packaged together.

139
00:08:50,140 --> 00:08:54,630
Now, the kit file, as I mentioned,
is what, is complementing, like

140
00:08:54,630 --> 00:08:58,190
how we have a docker file that
complements the docker image.

141
00:08:58,450 --> 00:09:01,700
Similar to the model kit, we have
the kit file, which is a YAML based

142
00:09:01,910 --> 00:09:03,880
configuration file, which simplifies.

143
00:09:04,175 --> 00:09:07,775
The, description that, okay, what are the
different components that you will have.

144
00:09:08,095 --> 00:09:12,185
And, of course, this kit file has been
designed specifically with ease of use and

145
00:09:12,185 --> 00:09:16,385
security in mind so that you can basically
officially package your, software.

146
00:09:16,725 --> 00:09:18,955
And this is how a typical
kit file would look like.

147
00:09:18,955 --> 00:09:23,515
So it will be a very similar to a YAML
file that has been designed to encapsulate

148
00:09:23,545 --> 00:09:25,065
all of the necessary information.

149
00:09:25,400 --> 00:09:27,170
that you need to actually
package together.

150
00:09:27,510 --> 00:09:32,660
and this, manifest will be broken down
into different sections, which is the

151
00:09:32,730 --> 00:09:36,950
manifest version, if you're having the
package details, then the code, the

152
00:09:36,950 --> 00:09:40,610
dataset, and where exactly they are
stored, because all of them are then

153
00:09:40,640 --> 00:09:42,760
packaged together into the model kit.

154
00:09:43,240 --> 00:09:47,295
And, then, finally, we talk about the
kit CLI, which is, similar to, a Docker

155
00:09:47,325 --> 00:09:51,935
CLI, where the idea is that you get a
set of command line tools that enable

156
00:09:51,945 --> 00:09:58,074
the users, not only, to manage, but to
also go ahead and create and run these

157
00:09:58,075 --> 00:10:00,085
model kits and then also publish them.

158
00:10:00,295 --> 00:10:01,525
So you can, have your.

159
00:10:01,915 --> 00:10:06,305
Git file, and then create the kit
or the model kit from it, and then

160
00:10:06,565 --> 00:10:09,855
go ahead and actually deploy to any
container registry that you want.

161
00:10:10,105 --> 00:10:13,085
Now, the great thing over here
is that since these particular

162
00:10:13,085 --> 00:10:16,115
model kits are compliant with OCA
compliant registry, that means that.

163
00:10:16,515 --> 00:10:20,345
you can use a set of DevOps tools,
whether it's CICD tools, deployment

164
00:10:20,355 --> 00:10:23,575
tools, that you would typically use
with a container image, because these

165
00:10:23,615 --> 00:10:25,295
are similar to like a container image.

166
00:10:25,565 --> 00:10:28,805
That means you don't have to reinvent
the wheel and introduce new tools

167
00:10:28,835 --> 00:10:30,995
for machine learning based systems.

168
00:10:31,355 --> 00:10:35,704
And that's the entire idea about
reusing your software, right?

169
00:10:35,705 --> 00:10:36,675
so that's the KitCLI.

170
00:10:37,105 --> 00:10:39,945
Now let's look at how a typical
KitOps pipeline would look like.

171
00:10:40,400 --> 00:10:45,720
So the kit unpack would allow you to
pull model kits that have been stored in

172
00:10:45,720 --> 00:10:51,205
a private or a public registry They're
like a docker Pull, or Docker Unpack.

173
00:10:51,205 --> 00:10:55,235
So what it allows you to do is that
when you do kit unpack, it will pull the

174
00:10:55,235 --> 00:10:59,095
model kit and then it will produce all
of the individual components that you

175
00:10:59,095 --> 00:11:02,465
had locally stored, that you had stored
in the model kit as separate files.

176
00:11:02,715 --> 00:11:06,565
And we'll see that in action and then
kit pull will allow you to then retrieve

177
00:11:06,565 --> 00:11:10,395
a model kit that has been stored in a
remote registry into a local environment.

178
00:11:11,015 --> 00:11:14,295
And if you want to create one
from scratch, so you can create a

179
00:11:14,580 --> 00:11:16,940
new kit file for your AI project.

180
00:11:16,960 --> 00:11:20,050
And then you will use the kit
pack command to basically create

181
00:11:20,050 --> 00:11:21,510
the model kit from that kit file.

182
00:11:21,730 --> 00:11:24,740
And then you can use the kit push,
which is like similar to a Docker

183
00:11:24,740 --> 00:11:28,260
push, which will allow you to push
your newly created model kit from

184
00:11:28,260 --> 00:11:29,910
your local repository to your.

185
00:11:30,525 --> 00:11:34,385
Private, cloud based registry and
you get a lot of, things out of the

186
00:11:34,385 --> 00:11:38,645
box because you can also, sign your
images, so that increases the security.

187
00:11:38,645 --> 00:11:42,015
So if you want, because of
compliance reasons, you want your

188
00:11:42,055 --> 00:11:45,385
AI models to be more secure, then
you can leverage, the kit push with

189
00:11:45,435 --> 00:11:46,625
signing off the images as well.

190
00:11:46,765 --> 00:11:48,655
So it comes with inbuilt security.

191
00:11:48,655 --> 00:11:54,285
So with signing, you can know that the
model kits are actually, Verifiable so

192
00:11:54,285 --> 00:11:59,424
let's look at the demo and we are going
to be seeing a demo of the kit file

193
00:11:59,425 --> 00:12:04,795
So here I'm going to be running a kit
CLI where I'm have opened my terminal.

194
00:12:04,815 --> 00:12:10,385
I have already installed kit CLI So
let's take a look at how you know, how

195
00:12:10,385 --> 00:12:14,225
that would basically function So I'll
proceed a bit further and show you

196
00:12:14,545 --> 00:12:18,255
so first of all to verify whether you
have kit version installed you can just

197
00:12:18,255 --> 00:12:23,695
use kit version and that shows you the
current version of your, kit CLI and

198
00:12:23,975 --> 00:12:26,255
now, let's basically, proceed further.

199
00:12:26,595 --> 00:12:32,035
So now, I will use kit login to basically
log in to my kit and here you will

200
00:12:32,065 --> 00:12:36,225
basically provide the details of what
is the registry that you're using.

201
00:12:36,225 --> 00:12:39,685
So in this case, I'm going to be
using Zozo Hub, which is a really

202
00:12:39,685 --> 00:12:43,745
specialized registry for being
able to store your model kits.

203
00:12:43,855 --> 00:12:46,085
And here I just put my
username and password.

204
00:12:46,085 --> 00:12:47,095
And once I've logged in.

205
00:12:47,385 --> 00:12:50,385
Now I can start to manage, like
this is very similar to a Docker

206
00:12:50,385 --> 00:12:52,645
Hub sign in that you have to do
when you're using the Docker CLI.

207
00:12:53,015 --> 00:12:57,395
So here you can see that I have
this example of a Zozohub model

208
00:12:57,455 --> 00:13:01,745
kit that has been hosted on
Zozohub, which is this YOLOv10.

209
00:13:02,125 --> 00:13:07,325
I can very easily now go ahead
and actually use the pull tag or

210
00:13:07,515 --> 00:13:11,815
I can do kit unpack and give the
name of this particular registry.

211
00:13:12,105 --> 00:13:14,775
In this case, you can see that this
particular model kit has a model,

212
00:13:14,815 --> 00:13:16,315
the docs and the configuration.

213
00:13:16,665 --> 00:13:18,375
Files which are available.

214
00:13:18,575 --> 00:13:22,435
So in order to basically create what
I'll use is the kit unpack command

215
00:13:22,745 --> 00:13:26,375
now Of course, I can do it in this
particular registry here What you are

216
00:13:26,375 --> 00:13:29,345
seeing is that the kit unpack jozu.

217
00:13:29,385 --> 00:13:33,985
ml is of course where this model
kit is being Deployed and then I

218
00:13:33,995 --> 00:13:38,620
give the name as the name of the the
owner and the name of the repository.

219
00:13:38,650 --> 00:13:42,590
So name of the owner is Dozu and
then the repository name is YOLOv10

220
00:13:42,650 --> 00:13:44,550
and then the v10x is the tag.

221
00:13:44,860 --> 00:13:48,030
So I'm just creating this
new, repo, locally, and then

222
00:13:48,070 --> 00:13:49,270
this is where I'll unpack it.

223
00:13:49,530 --> 00:13:52,830
Now, as soon as I unpack, you'll
see that it will unpack all of the

224
00:13:52,830 --> 00:13:56,290
different components of the model
kit that had been used to store.

225
00:13:56,595 --> 00:13:59,495
which is like very similar to like
we have layers in a docker image.

226
00:13:59,565 --> 00:14:01,495
So these can be thought
of as different layers.

227
00:14:01,825 --> 00:14:04,335
So it is unpacking all of these
different files right now.

228
00:14:04,665 --> 00:14:08,845
as soon as it basically does that, if
I take a look at my list of the model

229
00:14:09,035 --> 00:14:13,675
of the files, you can see that it has
the kit file, the readme, the model

230
00:14:13,705 --> 00:14:15,265
itself, like in the tensors format.

231
00:14:15,850 --> 00:14:19,210
And if I see the model kit itself,
you can see the kit file over here,

232
00:14:19,570 --> 00:14:24,510
which shows me the manifest file, the
package details, and the model details.

233
00:14:24,510 --> 00:14:27,470
In this case, it's the safe
tensors and it's the YOLOv10 model.

234
00:14:27,895 --> 00:14:30,675
And, I have my docs,
which has the README file.

235
00:14:31,005 --> 00:14:33,875
So this shows all of the
details, about my kit file.

236
00:14:33,905 --> 00:14:38,825
Now, what I can do is that I can actually
use this same kit file to now package a

237
00:14:38,825 --> 00:14:40,685
new model kit that I can store locally.

238
00:14:41,015 --> 00:14:44,915
So for that, you can see that the list
kit list, like a Docker list shows you

239
00:14:44,915 --> 00:14:47,895
the list of all the model kits that
you have, locally stored right now.

240
00:14:48,065 --> 00:14:50,455
so the one that I just
recently downloaded, you'll

241
00:14:50,485 --> 00:14:51,555
be able to also see those.

242
00:14:51,890 --> 00:14:57,890
Now, if I want to create a new model kit,
I can use the command kit pack, right?

243
00:14:58,020 --> 00:15:02,500
So I'll use the command kit pack
and I will give it the details where

244
00:15:02,730 --> 00:15:04,950
exactly have I stored my kit file.

245
00:15:05,200 --> 00:15:07,680
So dot means that it's
in the same directory.

246
00:15:08,000 --> 00:15:10,480
Then I use the hyphen, T command.

247
00:15:10,780 --> 00:15:12,550
and then I provide it the name.

248
00:15:12,640 --> 00:15:16,120
so in this case, because I'll be
published, publishing this on those

249
00:15:16,120 --> 00:15:19,840
who, ML, I just give it the name
and then I will give it the name of

250
00:15:19,840 --> 00:15:21,180
the user where I'll be uploading it.

251
00:15:21,180 --> 00:15:24,490
So that is Shivalamba in my case,
because that's my name on those who

252
00:15:24,490 --> 00:15:26,150
have, and then I'll give it a new name.

253
00:15:26,170 --> 00:15:30,110
So this is the name of the model
kit with a tag that I'll give to it.

254
00:15:30,200 --> 00:15:33,600
And you'll see that it basically
packs the different layers from

255
00:15:33,600 --> 00:15:34,660
the model, from the kit file.

256
00:15:35,100 --> 00:15:39,250
So different layers are the model,
the, data set, and you can see that it

257
00:15:39,250 --> 00:15:40,700
just created that particular model kit.

258
00:15:41,060 --> 00:15:44,140
Now in order to actually upload it, I
will have to also create a repository

259
00:15:44,140 --> 00:15:48,000
name and we'll keep it as the same name
as our model kit so that it matches when

260
00:15:48,000 --> 00:15:50,420
we push it to this remote, registry.

261
00:15:50,830 --> 00:15:54,580
And now once I've created that
particular, repository on those who

262
00:15:54,580 --> 00:15:56,890
have, I can now use the kit push command.

263
00:15:57,410 --> 00:16:01,650
And, again, provide the model kit
that's stored locally in my system.

264
00:16:01,660 --> 00:16:05,770
So that's Shivalamba and this
will upload it to, the repository

265
00:16:05,770 --> 00:16:08,410
YOLOv3 that we have pushed online.

266
00:16:08,680 --> 00:16:11,970
So as you can see, it's starting
to push it to this repository.

267
00:16:11,980 --> 00:16:14,930
So just to ensure that name of the
model kit locally and the repository

268
00:16:15,180 --> 00:16:18,860
in your Zozohub registry matches or
for that matter, any other registry.

269
00:16:18,950 --> 00:16:21,520
So you can see again, it,
pushes this layer by layer.

270
00:16:21,860 --> 00:16:26,060
And, one thing to keep in note is that
when you basically also use like the

271
00:16:26,150 --> 00:16:30,880
git unpack command, you can do selective
download of different components.

272
00:16:30,890 --> 00:16:33,960
Because as I said that there are
different components, the data set,

273
00:16:33,990 --> 00:16:36,000
the model, all of those are separate.

274
00:16:36,010 --> 00:16:39,500
So if you just want, let's say,
the data scientist does not want to

275
00:16:39,500 --> 00:16:40,990
download the actual original model.

276
00:16:41,230 --> 00:16:42,670
They just want to download the data set.

277
00:16:43,020 --> 00:16:44,010
So I can selectively.

278
00:16:44,290 --> 00:16:48,700
Let's say that by giving the filter,
by giving the flag that filter, I

279
00:16:48,700 --> 00:16:52,110
just want the dataset and the model
instead of download all the things.

280
00:16:52,400 --> 00:16:55,580
So this way, like in case multiple
teams are using the same model kit,

281
00:16:55,880 --> 00:16:58,920
you don't need to download every
time, all the things like only if

282
00:16:58,920 --> 00:17:01,385
they need some specific parts of
the model kit, they can do that.

283
00:17:01,695 --> 00:17:05,865
So that's the great part about re sharing
this model kit across the different team

284
00:17:05,865 --> 00:17:07,975
members that you will have in your team.

285
00:17:07,975 --> 00:17:11,305
So by using that particular filter
that allows you to very easily just

286
00:17:11,305 --> 00:17:16,545
manage specific parts and now you'll
see that, when I go back into Jozuhub,

287
00:17:17,015 --> 00:17:18,885
I would have uploaded it successfully.

288
00:17:19,205 --> 00:17:22,285
Now you can see some of the most
popular repositories including

289
00:17:22,285 --> 00:17:23,305
the ones that are signed.

290
00:17:23,535 --> 00:17:28,750
So this basically tells you that
these are Proper properly, security

291
00:17:28,750 --> 00:17:29,960
tested and these are signed.

292
00:17:30,110 --> 00:17:34,400
So these are properly authenticated
as well So we can apply those type of

293
00:17:34,670 --> 00:17:39,410
security measures when you are uploading
your model kits to the registry In

294
00:17:39,410 --> 00:17:42,200
this case like you can see like it has
successfully, you know uploaded it.

295
00:17:42,620 --> 00:17:46,625
So that's a quick overview
of the Kit file and how, what

296
00:17:46,625 --> 00:17:47,865
basically the kit file looks like.

297
00:17:48,245 --> 00:17:53,385
Now, of course, one important aspect
is that how can we automate the machine

298
00:17:53,385 --> 00:17:55,195
learning life cycle with the help of CICD?

299
00:17:55,195 --> 00:18:00,220
Because as we know that CICD is an
important aspect for Us not having to

300
00:18:00,510 --> 00:18:05,870
manually, like every time we pushed
some code, having to, test it and rerun

301
00:18:05,920 --> 00:18:07,800
our pipelines each and every time.

302
00:18:07,800 --> 00:18:09,470
So that's where the CICD really works.

303
00:18:09,710 --> 00:18:12,200
And the similar is the case
for machine learning as well.

304
00:18:12,470 --> 00:18:15,630
So imagine that when you, whenever you're
trying to push a machine learning model.

305
00:18:16,010 --> 00:18:17,390
to production with the new version.

306
00:18:17,410 --> 00:18:20,950
So you push the code, then you,
generate the new, dependencies.

307
00:18:21,000 --> 00:18:25,400
for example, the model files that
could be a H5 format or a pickle format

308
00:18:25,400 --> 00:18:29,600
and manually having to then deploy it
where you are running it in production.

309
00:18:29,630 --> 00:18:32,000
So all these steps can be
automated with the help of CICD.

310
00:18:32,440 --> 00:18:36,380
So you can also then add GitOps
as part of your CICD pipeline to

311
00:18:36,430 --> 00:18:39,820
automate the deployment of these
AI models, which can be triggered

312
00:18:39,850 --> 00:18:41,410
either manually or automatically.

313
00:18:41,835 --> 00:18:45,015
Based on let's say the changes that
are taking place in your model or the

314
00:18:45,015 --> 00:18:49,335
artifacts So this means that kit ops not
only helps you to simplify the packaging

315
00:18:49,335 --> 00:18:53,825
of the models But by leveraging it with
the help of CICD you also automate the

316
00:18:53,825 --> 00:18:59,935
deployment of the AI to make it You
know make it something that you have

317
00:18:59,935 --> 00:19:01,455
to do manually each and every time.

318
00:19:01,465 --> 00:19:05,395
So you can trigger these deployments
and truly streamline the model life

319
00:19:05,395 --> 00:19:09,595
cycle management by defining your
own way in in which, how you want

320
00:19:09,665 --> 00:19:14,155
new versions of the model, or your
entire model pipeline to look like.

321
00:19:14,215 --> 00:19:18,805
So you can very easily then adopt
GitOps with GitHub Actions, Jenkins.

322
00:19:18,895 --> 00:19:23,005
in fact, like you'll find a lot of
different resources to use it in

323
00:19:23,005 --> 00:19:25,495
conjunction with your CICD tool.

324
00:19:25,995 --> 00:19:29,405
And here's like an example of how
you can use it with a Dagger CICD.

325
00:19:29,415 --> 00:19:32,974
So you install kit ops, you
have Dagger, I've installed.

326
00:19:33,045 --> 00:19:37,924
And here you'll see that, what we are
doing is that you create your file, you

327
00:19:37,934 --> 00:19:41,794
run your Dagger pipeline and based on
the Dagger pipeline, what would happen is

328
00:19:41,794 --> 00:19:44,959
that once you have created the model kit
with the kit file, you initialize your.

329
00:19:45,249 --> 00:19:48,679
Dagger module and then you Daggerize
your kit file and then when you

330
00:19:48,679 --> 00:19:52,069
define your pipeline functions, and
then you can you know integrate your

331
00:19:52,069 --> 00:19:56,849
Dagger module with a CICD That could
be an example of a GitHub action.

332
00:19:56,869 --> 00:20:01,399
So whenever you are pushing some new
changes to your kit file, it will

333
00:20:01,399 --> 00:20:06,634
instantiate your Dagger module and
then that basically goes ahead and

334
00:20:06,834 --> 00:20:11,554
kicks off your, CICD workflow pipeline
that's running in GitHub actions.

335
00:20:11,824 --> 00:20:15,724
And then you can automate the deployment
of your, latest changes to your kit file

336
00:20:15,824 --> 00:20:17,404
or to your model kit to the registry.

337
00:20:17,404 --> 00:20:19,304
In that case, that could be a Zozo hub.

338
00:20:19,564 --> 00:20:22,384
So this is an example, like a typical
example of how it would look like.

339
00:20:22,569 --> 00:20:25,409
In case you had Jenkins, you, it
would look like something like

340
00:20:25,409 --> 00:20:28,979
similar where you define your Jenkins
pipeline, you define your model kit

341
00:20:29,169 --> 00:20:34,109
behavior when you want it actually
to in, kick off the Jenkins pipeline.

342
00:20:34,109 --> 00:20:36,369
So you can define all of
that in your configuration.

343
00:20:37,049 --> 00:20:37,619
so of course.

344
00:20:38,454 --> 00:20:42,474
MLOps is also a really important
aspect and you can really, instantiate

345
00:20:42,504 --> 00:20:43,834
that with the help of model kits.

346
00:20:43,844 --> 00:20:46,484
So whether you like, you're using,
your machine learning models for

347
00:20:46,484 --> 00:20:50,684
training experimentation, that's
where you need, the ability to package

348
00:20:50,684 --> 00:20:52,744
and validate your model deployments.

349
00:20:53,014 --> 00:20:57,284
And even then you can use, your model kit
as inference because you can technically

350
00:20:57,294 --> 00:21:01,574
go ahead and, leverage, the model kit that
you have deployed on Zozo Hub, let's say.

351
00:21:01,854 --> 00:21:05,374
You can run it as a container
image or you can deploy it on

352
00:21:05,594 --> 00:21:11,084
communities as an init container or
as a kit file or a kit CLI, right?

353
00:21:11,244 --> 00:21:14,424
So you can basically do
experimentation because let's say

354
00:21:14,694 --> 00:21:15,824
that you have defined a model kit.

355
00:21:15,854 --> 00:21:18,054
Now you could have different
versions of the model kit.

356
00:21:18,324 --> 00:21:21,104
You can store them as
different tags and upload them.

357
00:21:21,154 --> 00:21:24,014
So now you can very easily
see the differences between.

358
00:21:24,304 --> 00:21:28,114
The different, versions or the tags
based on experimentation and the changes

359
00:21:28,374 --> 00:21:30,354
that you had to make to your, model.

360
00:21:30,624 --> 00:21:34,694
And then you can very easily understand
all of them and do experimentation

361
00:21:34,694 --> 00:21:37,334
as well with the help of model
kits and having the different

362
00:21:37,344 --> 00:21:38,564
versions that you will have, right?

363
00:21:38,814 --> 00:21:42,584
So this makes training experimentation
very easy and then inference, you can

364
00:21:42,584 --> 00:21:46,684
deploy a model kit as an inference
service with the help of, and on top of

365
00:21:46,684 --> 00:21:51,244
like different type of modern day cloud
platforms like Kubernetes or Docker.

366
00:21:51,744 --> 00:21:55,264
And as I mentioned that you can deploy
these model kits, by either creating a

367
00:21:55,264 --> 00:21:56,894
container or a Kubernetes deployment.

368
00:21:56,904 --> 00:22:01,254
So it could either be an init container or
a kit cli, which is a highly specialized,

369
00:22:01,524 --> 00:22:05,324
containerized kit cli that will be used
to tailor the running of the model kit.

370
00:22:05,634 --> 00:22:08,944
because you can basically run the
kit cli command, or if you don't want

371
00:22:08,944 --> 00:22:11,994
to do that, you can just use an init
container, which is like a default

372
00:22:12,014 --> 00:22:15,834
way to basically then run it inside
of a Kubernetes based environment.

373
00:22:15,944 --> 00:22:18,859
So those are readily
available, to all of you.

374
00:22:19,599 --> 00:22:21,689
these are some of the resources
that you can check out as you

375
00:22:21,689 --> 00:22:22,919
can check out GitOps on GitOps.

376
00:22:22,919 --> 00:22:25,719
ml. You can take a look
at the documentation.

377
00:22:25,729 --> 00:22:27,189
You can take a look at the dev.

378
00:22:27,389 --> 00:22:30,329
to blogs which show how you can
integrate with CICD tools with.

379
00:22:30,699 --> 00:22:32,209
different kind of MLOPS tools.

380
00:22:32,539 --> 00:22:36,529
And another thing is that, as I mentioned
earlier, that we are looking at a

381
00:22:36,529 --> 00:22:41,949
wave where we meant from, the storage,
to, the VMs, to our, containers.

382
00:22:41,969 --> 00:22:43,179
And now we're looking at models.

383
00:22:43,249 --> 00:22:46,559
So we are proactively having
discussions on the model spec

384
00:22:46,559 --> 00:22:48,159
discussion on the CNC of Slack.

385
00:22:48,509 --> 00:22:52,159
and here is a Google doc that
actively takes part in that.

386
00:22:52,169 --> 00:22:56,679
So the primary target here is that we want
to make AI models as first class citizens.

387
00:22:56,689 --> 00:23:00,229
So we want to proactively make
some changes to our OCI spec

388
00:23:00,239 --> 00:23:03,619
that is better well suited for
machine learning based models.

389
00:23:04,279 --> 00:23:05,959
with that, thank you
so much for attending.

390
00:23:05,969 --> 00:23:10,129
You can scan the QR code for these
slides and you can also connect with me

391
00:23:10,179 --> 00:23:13,569
and you can join the kit ops discord,
which is again, an open source project,

392
00:23:13,849 --> 00:23:17,669
that will lead you to, have discussions
around kit ops and of course you can

393
00:23:17,669 --> 00:23:19,279
connect with me on how to develop.

394
00:23:19,539 --> 00:23:22,119
So thank you so much for watching
this video and I hope you have a

395
00:23:22,369 --> 00:23:26,659
wonderful time watching the rest of
the amazing talks at the conference.

