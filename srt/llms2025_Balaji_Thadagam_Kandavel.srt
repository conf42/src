1
00:00:00,000 --> 00:00:00,720
Hello everyone.

2
00:00:01,200 --> 00:00:02,970
I'm Balaji today.

3
00:00:03,060 --> 00:00:04,950
I'll be talking about securing l ls.

4
00:00:05,850 --> 00:00:07,270
Let's get into the topic.

5
00:00:07,770 --> 00:00:12,810
So today I'm dying diving into a
pressing issue in artificial intelligence

6
00:00:13,290 --> 00:00:15,090
securing launch language models.

7
00:00:15,975 --> 00:00:21,495
To prevent leaks on sensitive
code, critical data, and valuable

8
00:00:21,495 --> 00:00:26,655
intellectual property, these leaks
can undermine business and trust.

9
00:00:27,155 --> 00:00:31,475
A, as the LMS become indispensable,
tools across the Indus industries

10
00:00:31,745 --> 00:00:35,285
from tech to healthcare, protecting
them is no longer optional.

11
00:00:36,065 --> 00:00:36,995
It's a necessity.

12
00:00:37,415 --> 00:00:41,465
So let's start this journey
to understand and fortify.

13
00:00:42,229 --> 00:00:46,759
artificial intelligence
systems against these risks.

14
00:00:47,260 --> 00:00:52,180
So what are s elements are cutting
edge AI systems designed to

15
00:00:52,184 --> 00:00:55,975
understand and generate human-like
text with remarkable accuracy.

16
00:00:56,845 --> 00:00:58,975
Take GPT with its staggering.

17
00:00:59,035 --> 00:01:00,895
One 75 billion parameters.

18
00:01:01,885 --> 00:01:03,855
It's a pioneer in natural
language processing.

19
00:01:04,360 --> 00:01:10,510
These models drive tasks like content
creation, language translation, and

20
00:01:10,510 --> 00:01:12,550
even customer support automation.

21
00:01:13,540 --> 00:01:19,570
They act like digital's, linguists,
interpreting and crafting languages

22
00:01:19,570 --> 00:01:23,285
in ways that revolutionize
technology interactions.

23
00:01:23,785 --> 00:01:27,355
So the problem, so the real
problem that we're facing right

24
00:01:27,355 --> 00:01:29,995
now with LLMs is data leaks.

25
00:01:30,495 --> 00:01:34,275
The thing is the data leaks happens
even without knowing that it happens.

26
00:01:34,775 --> 00:01:38,378
So despite these powers of L
lms, LMS can leak sensitive

27
00:01:38,383 --> 00:01:41,030
information in several sneaky ways.

28
00:01:41,960 --> 00:01:46,850
Leaks can stem from training data
where private details like names

29
00:01:46,850 --> 00:01:49,310
or emails might linger unnoticed.

30
00:01:49,984 --> 00:01:54,065
All from prompts where users
accidentally input this data.

31
00:01:54,565 --> 00:02:00,384
And also from model, inversion, a
technique attackers used to reverse

32
00:02:00,384 --> 00:02:04,335
engineering data from LM outputs picture.

33
00:02:04,335 --> 00:02:10,995
And LM as a leaky bucket sends sensitive
code data and IP spill out, unchecked,

34
00:02:10,995 --> 00:02:16,035
threatening privacy breaches, intellectual
property theft and competitive losses.

35
00:02:16,770 --> 00:02:21,480
So I ask, are you, are your
A tools truly secure against

36
00:02:21,480 --> 00:02:23,340
these vulnera vulnerabilities,

37
00:02:23,840 --> 00:02:25,220
data leaks and their impact?

38
00:02:25,700 --> 00:02:30,400
So the real world example that
we can go with is with Samsung in

39
00:02:30,400 --> 00:02:34,060
2023, the employees inadvertently.

40
00:02:34,660 --> 00:02:39,340
Leaked proprietary source code
by using Chad GBT exposing trade

41
00:02:39,340 --> 00:02:41,650
secrets to potential rivals.

42
00:02:41,980 --> 00:02:45,769
A healthcare provider lost pat,
patient data through L-N-L-L-M,

43
00:02:46,370 --> 00:02:48,200
bridging trust and regulations.

44
00:02:48,829 --> 00:02:54,290
A startup saw its intellectual property
vanished due to sloppy prompt handling.

45
00:02:55,010 --> 00:03:00,470
IBM picks the average
database cost at 4.45 billion.

46
00:03:00,970 --> 00:03:02,830
Which is a really hefty price.

47
00:03:03,330 --> 00:03:09,000
The stable lists, these incidents,
their fallout and lessons like enforcing

48
00:03:09,000 --> 00:03:14,570
strict input policies and sanitizing
data to avoid these costly mistakes.

49
00:03:15,070 --> 00:03:17,140
Technologies for securing L lms.

50
00:03:17,620 --> 00:03:20,385
Thankfully a new technologies can share.

51
00:03:20,685 --> 00:03:20,905
can.

52
00:03:21,404 --> 00:03:23,954
Shore up the LMS against these leaks.

53
00:03:24,454 --> 00:03:29,674
Differential privacy, add statistical
noise to the data set, masking

54
00:03:29,674 --> 00:03:33,514
the individual details while
keeping overall pattern consistent,

55
00:03:34,014 --> 00:03:35,394
which is ideal for privacy.

56
00:03:35,894 --> 00:03:41,324
Second option is federated learning,
which trains models on decentralized

57
00:03:41,324 --> 00:03:46,244
devices like phones and servers, so
the raw data never leaves its source.

58
00:03:46,744 --> 00:03:51,184
The third option is homomorphic
encryption and emerging model that

59
00:03:51,184 --> 00:03:56,014
lets the LMS process encrypted
data without even decrypting it.

60
00:03:56,514 --> 00:03:57,714
So it's a true frontier.

61
00:03:58,404 --> 00:04:04,604
Things of these, things like these act
as a study ball and then it helps, for

62
00:04:04,604 --> 00:04:07,814
the, companies to protect their data.

63
00:04:08,314 --> 00:04:10,534
Data privacy solutions for L lms.

64
00:04:10,954 --> 00:04:15,844
So beyond these core technologies that
are in use that we can use, we have got

65
00:04:15,844 --> 00:04:18,294
specialized tools also in play data.

66
00:04:18,294 --> 00:04:24,414
Privacy walls like those
from Sky Flow Act as secure.

67
00:04:24,724 --> 00:04:28,854
repositories tokenizing the
data, like credit card numbers.

68
00:04:29,354 --> 00:04:31,094
Before LMS really cease them.

69
00:04:31,934 --> 00:04:38,264
LM Shield developed by patented AI
that filters user inputs in real time,

70
00:04:39,024 --> 00:04:43,194
catching personal and proprietary
info before it really leaks.

71
00:04:43,614 --> 00:04:45,174
Imagine a digital vault.

72
00:04:45,354 --> 00:04:46,349
You were secrets.

73
00:04:46,849 --> 00:04:52,179
Stay locked tight inside, and only
safe anonymous tokens can reach the.

74
00:04:52,679 --> 00:04:56,159
These solutions are really
pivotal for complaints and also

75
00:04:56,159 --> 00:05:01,219
for safeguarding our assets, best
practices for using LLM securely.

76
00:05:01,719 --> 00:05:05,379
So that is tech technology that
is available right now, but that

77
00:05:05,379 --> 00:05:11,509
alone won't cut it, that are also,
complaints that we need to make sure.

78
00:05:12,059 --> 00:05:13,919
so the best practices that could be used.

79
00:05:14,419 --> 00:05:19,969
Or, sanitizing the training data and
restricting access to limited people

80
00:05:20,469 --> 00:05:24,729
and not to everyone, and who is training
the data and who can use the data.

81
00:05:25,229 --> 00:05:29,899
And also conducting regular
audits and training employees

82
00:05:30,319 --> 00:05:32,089
to handle, a responsibly.

83
00:05:33,019 --> 00:05:37,759
So these four things will definitely
make sure that the best practices

84
00:05:37,759 --> 00:05:42,729
are implemented in, each company
that could make LLM secure.

85
00:05:43,229 --> 00:05:45,419
Next is, regulatory, complaints.

86
00:05:45,919 --> 00:05:53,314
regulatory complaints talks about, how
standards can be set, which can, prevent.

87
00:05:53,864 --> 00:05:54,524
data leaks.

88
00:05:54,944 --> 00:06:01,854
So GDPI from, European Union in insists
on data rights, which becomes tricky

89
00:06:01,914 --> 00:06:04,114
when models can memorize this, data.

90
00:06:04,594 --> 00:06:08,404
HIPAA safeguards, health information
in the US demanding highend cloud

91
00:06:08,404 --> 00:06:10,594
protection for patient records.

92
00:06:10,924 --> 00:06:14,394
CCPA gives California consumers,
control over their data.

93
00:06:14,394 --> 00:06:17,744
Pursuing for transparency,
the staple ties.

94
00:06:18,224 --> 00:06:22,824
These, laws of strategies like
differential privacy of A-G-D-P-R

95
00:06:22,824 --> 00:06:27,084
walls for HIPAA complaints, isn't
just a, just a checkbox, right?

96
00:06:27,084 --> 00:06:30,144
It's the legal foundation for
safeguarding the AI deployment.

97
00:06:30,694 --> 00:06:32,734
next is implementing a secure alarms.

98
00:06:33,124 --> 00:06:39,174
So since we have seen, everything right
now on different ways we can, Secure lums.

99
00:06:39,289 --> 00:06:41,069
We can see how to implement it.

100
00:06:41,569 --> 00:06:45,739
So to put it in practice first,
assess, assess your data, what's

101
00:06:45,739 --> 00:06:47,939
sensitive and what needs, guarding.

102
00:06:48,719 --> 00:06:54,089
Then select the tools like privacy
walls or shields to protect it.

103
00:06:54,089 --> 00:06:58,009
Set up, access controls to
limit the exposure to the data.

104
00:06:58,519 --> 00:07:02,789
Train your staff on secure,
a use and audit systems

105
00:07:02,789 --> 00:07:05,069
regularly for any weak spots.

106
00:07:05,219 --> 00:07:09,639
This flow chart maps, out
your path to a leak proof LLM.

107
00:07:10,029 --> 00:07:15,054
It's a clear actionable plan that turns
security theory into real world results.

108
00:07:15,554 --> 00:07:16,904
Future trends and conclusion.

109
00:07:17,564 --> 00:07:23,069
So looking at future trends, privacy,
preserving, AI is the need of the heart,

110
00:07:23,549 --> 00:07:25,504
and that is what we see in the future.

111
00:07:26,004 --> 00:07:30,564
And also there will be new protocols that
could be implemented, which can act as,

112
00:07:30,664 --> 00:07:37,844
secure a on its own secure agents that can
help, to preserving the data on its own.

113
00:07:38,344 --> 00:07:44,724
In summary, secure L LMS will help
to protect the assets and, the

114
00:07:44,724 --> 00:07:46,914
companies need not have the fear.

115
00:07:47,414 --> 00:07:51,074
If their intellectual property is
really lost to any of the other

116
00:07:51,074 --> 00:07:53,114
companies and potential rivals.

117
00:07:53,614 --> 00:08:01,254
the real priority right now is to secure
our lums to make sure that the data that

118
00:08:01,254 --> 00:08:07,679
we want is not left out in the open so
that anyone can access it as they want to.

119
00:08:08,179 --> 00:08:08,929
Thanks for listening.

