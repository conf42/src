<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: You get an LLM, you get an LLM, everyone gets an LLM, but does it work?</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Ashwin%20Phadke_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="You get an LLM, you get an LLM, everyone gets an LLM, but does it work? | Conf42"/>
    <meta property="og:description" content="While everyone wants to say those magical words AI, LLM, have you evaluated your models to see if they actually work for you and your use case, or are you just using whatever's the most trending model out there? In this talk, we will explore the language models and evaluate those choices."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2024_Ashwin_Phadke_llm_work_everyone"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/DEVSECOPS2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        DevSecOps 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-12-05
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/devsecops2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2024-04-11T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-11T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "anmXNMEaNhg"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "TQwxk0c4sh0"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBjR6ZR0g0LRq9Fp8c_4HrI" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone, and thanks for joining me today. I\u0027m excited here to talk about", "timestamp": "00:00:20,840", "timestamp_s": 20.0}, {"text": "large language models, especially large language models evaluations", "timestamp": "00:00:24,646", "timestamp_s": 24.0}, {"text": "and how you can evaluate your model in a better way, or how you", "timestamp": "00:00:28,652", "timestamp_s": 28.0}, {"text": "can use certain frameworks that are available to understand how", "timestamp": "00:00:31,948", "timestamp_s": 31.0}, {"text": "a particular language model is performing for your specific use case.", "timestamp": "00:00:35,332", "timestamp_s": 35.0}, {"text": "For those of you who don\u0027t know me, I\u0027m Ashwin. I\u0027ve been working", "timestamp": "00:00:39,404", "timestamp_s": 39.0}, {"text": "in the field of machine learning, computer vision, and NLP for over three years,", "timestamp": "00:00:42,996", "timestamp_s": 42.0}, {"text": "and I\u0027ve also worked in some other domains throughout my", "timestamp": "00:00:47,284", "timestamp_s": 47.0}, {"text": "career. Today I would like to dive into into a", "timestamp": "00:00:50,652", "timestamp_s": 50.0}, {"text": "specific aspect of course evaluations, but also", "timestamp": "00:00:55,164", "timestamp_s": 55.0}, {"text": "why they\u0027re necessary and how we can get to", "timestamp": "00:00:58,852", "timestamp_s": 58.0}, {"text": "that particular evaluation metric. So, to get started,", "timestamp": "00:01:02,924", "timestamp_s": 62.0}, {"text": "let me just quickly move the screen. Yep. Okay.", "timestamp": "00:01:07,404", "timestamp_s": 67.0}, {"text": "Yeah. So, will the language model speak", "timestamp": "00:01:10,540", "timestamp_s": 70.0}, {"text": "the truth? I guess that\u0027s the question that everyone\u0027s been asking.", "timestamp": "00:01:14,380", "timestamp_s": 74.0}, {"text": "Everyone\u0027s been really concerned about the whole evaluation flow,", "timestamp": "00:01:17,788", "timestamp_s": 77.0}, {"text": "or if we can trust these language models into", "timestamp": "00:01:21,804", "timestamp_s": 81.0}, {"text": "telling us something that it definitely knows versus making things", "timestamp": "00:01:25,484", "timestamp_s": 85.0}, {"text": "up and telling us something that even we are not sure whether this", "timestamp": "00:01:29,476", "timestamp_s": 89.0}, {"text": "is the truth or not. So the bigger question that we probably tend", "timestamp": "00:01:33,140", "timestamp_s": 93.0}, {"text": "to answer today is whether the language model is", "timestamp": "00:01:36,412", "timestamp_s": 96.0}, {"text": "going to be truthful in answering the questions that we ask them or,", "timestamp": "00:01:40,084", "timestamp_s": 100.0}, {"text": "you know, getting summaries out of it. So,", "timestamp": "00:01:43,644", "timestamp_s": 103.0}, {"text": "moving ahead, we are jumping into", "timestamp": "00:01:47,074", "timestamp_s": 107.0}, {"text": "a particular aspect is why we need these evaluations", "timestamp": "00:01:50,786", "timestamp_s": 110.0}, {"text": "and why these particular evaluations are necessary. The reason being", "timestamp": "00:01:54,282", "timestamp_s": 114.0}, {"text": "that these evaluations are important", "timestamp": "00:01:57,786", "timestamp_s": 117.0}, {"text": "as a part of a measure of your overall large language", "timestamp": "00:02:00,994", "timestamp_s": 120.0}, {"text": "model development workflow. So think about it on how.", "timestamp": "00:02:04,874", "timestamp_s": 124.0}, {"text": "Think about it as how we can effectively manage or", "timestamp": "00:02:08,754", "timestamp_s": 128.0}, {"text": "leverage these language models, while also making sure that", "timestamp": "00:02:12,826", "timestamp_s": 132.0}, {"text": "we are not letting it lose completely and having a", "timestamp": "00:02:16,362", "timestamp_s": 136.0}, {"text": "bad customer experience in general. So the", "timestamp": "00:02:20,122", "timestamp_s": 140.0}, {"text": "three aspects that you need to take care of here is the management", "timestamp": "00:02:23,834", "timestamp_s": 143.0}, {"text": "of these language models. Maybe you\u0027re using just a few APIs", "timestamp": "00:02:27,626", "timestamp_s": 147.0}, {"text": "that are available online and getting the results and just publishing them", "timestamp": "00:02:31,474", "timestamp_s": 151.0}, {"text": "to your users. Or maybe you\u0027re using, or maybe you\u0027re hosting", "timestamp": "00:02:35,554", "timestamp_s": 155.0}, {"text": "your own models using frameworks like B LLM.", "timestamp": "00:02:39,002", "timestamp_s": 159.0}, {"text": "I guess there\u0027s one more called Lama CPP or something like", "timestamp": "00:02:42,824", "timestamp_s": 162.0}, {"text": "that. So these frameworks also allow you to", "timestamp": "00:02:46,392", "timestamp_s": 166.0}, {"text": "host your own models and also", "timestamp": "00:02:49,760", "timestamp_s": 169.0}, {"text": "probably understand how you can improve", "timestamp": "00:02:53,576", "timestamp_s": 173.0}, {"text": "the overall performance of these language models.", "timestamp": "00:02:56,952", "timestamp_s": 176.0}, {"text": "Understanding these models, measuring these models will ultimately lead", "timestamp": "00:03:00,008", "timestamp_s": 180.0}, {"text": "to how you can improve these models, how you can understand on", "timestamp": "00:03:03,704", "timestamp_s": 183.0}, {"text": "where these llms fall short, so that we can either refine", "timestamp": "00:03:07,908", "timestamp_s": 187.0}, {"text": "our training data, we can start thinking about fine tuning these", "timestamp": "00:03:11,484", "timestamp_s": 191.0}, {"text": "language models, maybe lower adapters or,", "timestamp": "00:03:15,644", "timestamp_s": 195.0}, {"text": "you know, just in general testing out different language models or different specifically", "timestamp": "00:03:19,164", "timestamp_s": 199.0}, {"text": "publicly available, fine tuned language models.", "timestamp": "00:03:23,636", "timestamp_s": 203.0}, {"text": "Moving ahead, we are concerned", "timestamp": "00:03:27,164", "timestamp_s": 207.0}, {"text": "about what kind of frameworks or what kind", "timestamp": "00:03:30,764", "timestamp_s": 210.0}, {"text": "of measurement techniques,", "timestamp": "00:03:34,188", "timestamp_s": 214.0}, {"text": "or maybe let\u0027s just call them frameworks,", "timestamp": "00:03:38,008", "timestamp_s": 218.0}, {"text": "would help us in doing a particular thing.", "timestamp": "00:03:41,752", "timestamp_s": 221.0}, {"text": "So we have three selection criteria, or let\u0027s", "timestamp": "00:03:45,944", "timestamp_s": 225.0}, {"text": "say three evaluation criteria that we can think", "timestamp": "00:03:49,480", "timestamp_s": 229.0}, {"text": "of, and we can jump right into that.", "timestamp": "00:03:52,976", "timestamp_s": 232.0}, {"text": "But let\u0027s seeing that we can have task", "timestamp": "00:03:56,184", "timestamp_s": 236.0}, {"text": "specific scores that measure the right", "timestamp": "00:03:59,560", "timestamp_s": 239.0}, {"text": "outcome of a particular language model. Imagine a", "timestamp": "00:04:03,182", "timestamp_s": 243.0}, {"text": "toolbox where you have specifically designed metrics", "timestamp": "00:04:07,446", "timestamp_s": 247.0}, {"text": "or specifically designed items that you use to assess", "timestamp": "00:04:11,790", "timestamp_s": 251.0}, {"text": "llms. And while when you consider the", "timestamp": "00:04:15,654", "timestamp_s": 255.0}, {"text": "toolbox, your tools would be these three things that we\u0027ve", "timestamp": "00:04:18,894", "timestamp_s": 258.0}, {"text": "mentioned are the task specific scores that we talked about", "timestamp": "00:04:22,262", "timestamp_s": 262.0}, {"text": "here. I must say that a one size fits all approach", "timestamp": "00:04:26,534", "timestamp_s": 266.0}, {"text": "usually doesn\u0027t work. So the ideal framework", "timestamp": "00:04:30,734", "timestamp_s": 270.0}, {"text": "will offer you the metrics tailored to your different tasks.", "timestamp": "00:04:35,134", "timestamp_s": 275.0}, {"text": "To specific tasks, let\u0027s say question answering", "timestamp": "00:04:38,622", "timestamp_s": 278.0}, {"text": "or summarization. It will help you,", "timestamp": "00:04:41,998", "timestamp_s": 281.0}, {"text": "or it will allow you to evaluate these models on these", "timestamp": "00:04:45,190", "timestamp_s": 285.0}, {"text": "specific tasks. The other thing that we need to consider", "timestamp": "00:04:49,206", "timestamp_s": 289.0}, {"text": "for a good evaluation framework is the metric list.", "timestamp": "00:04:52,590", "timestamp_s": 292.0}, {"text": "You know you have the toolbox, you know how you have the toolset.", "timestamp": "00:04:56,964", "timestamp_s": 296.0}, {"text": "But if you don\u0027t have a reliable set of metrics that have been", "timestamp": "00:05:00,348", "timestamp_s": 300.0}, {"text": "proven before, there is no way in really understanding what", "timestamp": "00:05:03,572", "timestamp_s": 303.0}, {"text": "a particular score or what a particular metric", "timestamp": "00:05:07,252", "timestamp_s": 307.0}, {"text": "will mean if it is presented to you in an aggregate", "timestamp": "00:05:11,412", "timestamp_s": 311.0}, {"text": "or a abstracted manner. So having a good list of", "timestamp": "00:05:14,780", "timestamp_s": 314.0}, {"text": "available metrics that you can easily implement is really crucial when", "timestamp": "00:05:18,836", "timestamp_s": 318.0}, {"text": "deciding what framework or what library or what general research you\u0027re", "timestamp": "00:05:22,252", "timestamp_s": 322.0}, {"text": "going to follow to evaluate your language models. And the third part is", "timestamp": "00:05:26,108", "timestamp_s": 326.0}, {"text": "basically, really,", "timestamp": "00:05:30,060", "timestamp_s": 330.0}, {"text": "we could discuss this broadly or narrowly, depending on what the", "timestamp": "00:05:33,484", "timestamp_s": 333.0}, {"text": "context is. But the framework that we\u0027re going to use", "timestamp": "00:05:36,860", "timestamp_s": 336.0}, {"text": "should be extensible, it should be maintainable,", "timestamp": "00:05:40,308", "timestamp_s": 340.0}, {"text": "and of course it should provide you an ease of access to the", "timestamp": "00:05:43,972", "timestamp_s": 343.0}, {"text": "underlying function or the underlying classes of it. The reason for this", "timestamp": "00:05:48,356", "timestamp_s": 348.0}, {"text": "is because if the framework is adaptable to a particular task,", "timestamp": "00:05:52,410", "timestamp_s": 352.0}, {"text": "that\u0027s public, but your task requires some specific understanding", "timestamp": "00:05:57,330", "timestamp_s": 357.0}, {"text": "or specific knowledge, or a specific way of loading, maybe loading the model", "timestamp": "00:06:01,362", "timestamp_s": 361.0}, {"text": "weights. Or maybe if you use a different tokenizer", "timestamp": "00:06:05,402", "timestamp_s": 365.0}, {"text": "for tokenizing your particular request", "timestamp": "00:06:09,562", "timestamp_s": 369.0}, {"text": "responses, then this becomes a really crucial", "timestamp": "00:06:13,306", "timestamp_s": 373.0}, {"text": "aspect in determining whether a particular framework is going to be useful", "timestamp": "00:06:17,082", "timestamp_s": 377.0}, {"text": "for you. So, for example, the LM eval,", "timestamp": "00:06:20,914", "timestamp_s": 380.0}, {"text": "the LM evaluation harness framework, a really good framework,", "timestamp": "00:06:24,300", "timestamp_s": 384.0}, {"text": "a really good design made to evaluate any", "timestamp": "00:06:27,996", "timestamp_s": 387.0}, {"text": "model that you can think of, any supported support model", "timestamp": "00:06:31,708", "timestamp_s": 391.0}, {"text": "that you can think of on public datasets. But while working", "timestamp": "00:06:35,092", "timestamp_s": 395.0}, {"text": "on this particular framework, if you have a task that\u0027s", "timestamp": "00:06:39,684", "timestamp_s": 399.0}, {"text": "specific to your needs, it\u0027s a really difficult,", "timestamp": "00:06:43,388", "timestamp_s": 403.0}, {"text": "how do I say it\u0027s a really difficult way of implementing", "timestamp": "00:06:48,214", "timestamp_s": 408.0}, {"text": "that in this particular library? It\u0027s not just about this particularly,", "timestamp": "00:06:51,886", "timestamp_s": 411.0}, {"text": "it\u0027s in general, any library that has come up for", "timestamp": "00:06:55,390", "timestamp_s": 415.0}, {"text": "evaluations which does, which kind of abstract these", "timestamp": "00:06:59,550", "timestamp_s": 419.0}, {"text": "evaluation metrics for us. So,", "timestamp": "00:07:03,526", "timestamp_s": 423.0}, {"text": "moving ahead, by incorporating all these elements, we can", "timestamp": "00:07:07,294", "timestamp_s": 427.0}, {"text": "create a robust, or we can decide", "timestamp": "00:07:10,958", "timestamp_s": 430.0}, {"text": "on what robust evaluation framework we can use.", "timestamp": "00:07:14,944", "timestamp_s": 434.0}, {"text": "Now, let\u0027s dive deeper into the two main approaches", "timestamp": "00:07:17,992", "timestamp_s": 437.0}, {"text": "for the LM evaluation and why they", "timestamp": "00:07:22,032", "timestamp_s": 442.0}, {"text": "are necessary. As you can see in this particular diagram,", "timestamp": "00:07:25,736", "timestamp_s": 445.0}, {"text": "you can see that the part where the human evaluation is", "timestamp": "00:07:29,704", "timestamp_s": 449.0}, {"text": "concerned, it ranks really higher, as opposed", "timestamp": "00:07:33,272", "timestamp_s": 453.0}, {"text": "to user testing, fine tuning", "timestamp": "00:07:36,952", "timestamp_s": 456.0}, {"text": "and maybe public data sets, public benchmarks,", "timestamp": "00:07:40,848", "timestamp_s": 460.0}, {"text": "auto evaluation. And the reason really being for that", "timestamp": "00:07:44,820", "timestamp_s": 464.0}, {"text": "is the human evaluation aspect really focuses", "timestamp": "00:07:48,140", "timestamp_s": 468.0}, {"text": "on multiple geographies, multiple languages, and the", "timestamp": "00:07:51,732", "timestamp_s": 471.0}, {"text": "way people understand a particular response,", "timestamp": "00:07:55,452", "timestamp_s": 475.0}, {"text": "a particular language, and that really determines a", "timestamp": "00:07:59,092", "timestamp_s": 479.0}, {"text": "proper metric or a proper score for your language model to be evaluated", "timestamp": "00:08:02,756", "timestamp_s": 482.0}, {"text": "upon. Because as we know, there\u0027s multiple dialects", "timestamp": "00:08:06,636", "timestamp_s": 486.0}, {"text": "for a particular language, there\u0027s multiple people talking or", "timestamp": "00:08:10,998", "timestamp_s": 490.0}, {"text": "using different style of grammar, that is not a common", "timestamp": "00:08:14,830", "timestamp_s": 494.0}, {"text": "way of speaking or understanding things in their own", "timestamp": "00:08:19,534", "timestamp_s": 499.0}, {"text": "countries. And that could really mean a", "timestamp": "00:08:22,726", "timestamp_s": 502.0}, {"text": "lot of difference. When you\u0027re evaluating a framework, let\u0027s say,", "timestamp": "00:08:26,030", "timestamp_s": 506.0}, {"text": "for someone in the US, versus if you\u0027re evaluating,", "timestamp": "00:08:29,550", "timestamp_s": 509.0}, {"text": "sorry, if you\u0027re evaluating model on a specific response", "timestamp": "00:08:33,238", "timestamp_s": 513.0}, {"text": "for, let\u0027s say, for someone in the US, versus for someone who\u0027s", "timestamp": "00:08:36,702", "timestamp_s": 516.0}, {"text": "not a native english speaker, for them, understanding the context,", "timestamp": "00:08:40,614", "timestamp_s": 520.0}, {"text": "understanding what\u0027s going on around a particular", "timestamp": "00:08:44,990", "timestamp_s": 524.0}, {"text": "response may or may not differ, and they", "timestamp": "00:08:48,398", "timestamp_s": 528.0}, {"text": "may or may not think that this particular answer suits them well.", "timestamp": "00:08:51,934", "timestamp_s": 531.0}, {"text": "So having a human evaluation framework,", "timestamp": "00:08:55,254", "timestamp_s": 535.0}, {"text": "that\u0027s drug geography, region specific, or, and of course,", "timestamp": "00:08:58,198", "timestamp_s": 538.0}, {"text": "application specific, is a really important aspect", "timestamp": "00:09:01,710", "timestamp_s": 541.0}, {"text": "of evaluating these models. Now, once we\u0027ve talked about human", "timestamp": "00:09:05,054", "timestamp_s": 545.0}, {"text": "evaluators and why", "timestamp": "00:09:09,134", "timestamp_s": 549.0}, {"text": "those are necessary, we should also consider that it is not", "timestamp": "00:09:12,318", "timestamp_s": 552.0}, {"text": "always possible to collect all of this feedback. And it", "timestamp": "00:09:15,590", "timestamp_s": 555.0}, {"text": "is not also always possible to have your customers decide or determine", "timestamp": "00:09:19,078", "timestamp_s": 559.0}, {"text": "whether a particular answer was good or bad. The customers are,", "timestamp": "00:09:23,974", "timestamp_s": 563.0}, {"text": "the customers are really concerned about the value that", "timestamp": "00:09:27,678", "timestamp_s": 567.0}, {"text": "your application or your use case is providing. So in", "timestamp": "00:09:30,942", "timestamp_s": 570.0}, {"text": "general, we can think of these evaluation metrics.", "timestamp": "00:09:36,062", "timestamp_s": 576.0}, {"text": "So in general, these evaluation metrics you can", "timestamp": "00:09:41,214", "timestamp_s": 581.0}, {"text": "understand from two different perspectives. One is of course,", "timestamp": "00:09:44,334", "timestamp_s": 584.0}, {"text": "the one we discussed, which is the human evaluator part, and one is", "timestamp": "00:09:47,614", "timestamp_s": 587.0}, {"text": "the frameworks of the libraries that we\u0027ll be exploring in this talk,", "timestamp": "00:09:51,422", "timestamp_s": 591.0}, {"text": "we can call them as auto evaluators or, you know,", "timestamp": "00:09:55,342", "timestamp_s": 595.0}, {"text": "anything that\u0027s non human evaluator. And so", "timestamp": "00:09:58,638", "timestamp_s": 598.0}, {"text": "previously or traditionally, the way these language models even came", "timestamp": "00:10:03,024", "timestamp_s": 603.0}, {"text": "into being were based on a", "timestamp": "00:10:06,584", "timestamp_s": 606.0}, {"text": "large number of data sets, a large number of text or", "timestamp": "00:10:09,848", "timestamp_s": 609.0}, {"text": "material that was open, that was available publicly.", "timestamp": "00:10:13,472", "timestamp_s": 613.0}, {"text": "And so overall, while these", "timestamp": "00:10:17,112", "timestamp_s": 617.0}, {"text": "companies are use cases that are trying to test these models,", "timestamp": "00:10:20,888", "timestamp_s": 620.0}, {"text": "they\u0027ve made human evaluators a kind of a standard,", "timestamp": "00:10:24,704", "timestamp_s": 624.0}, {"text": "or how do I say, kind of a stop", "timestamp": "00:10:28,408", "timestamp_s": 628.0}, {"text": "in the loop on giving users a complete access", "timestamp": "00:10:32,776", "timestamp_s": 632.0}, {"text": "to the language model use case, versus maybe", "timestamp": "00:10:36,384", "timestamp_s": 636.0}, {"text": "releasing it as an experiment, or maybe releasing it as a beta,", "timestamp": "00:10:41,704", "timestamp_s": 641.0}, {"text": "so that when people interact with it and people understand", "timestamp": "00:10:45,184", "timestamp_s": 645.0}, {"text": "what\u0027s going on, and sometimes you get oh no, this answer is totally", "timestamp": "00:10:49,288", "timestamp_s": 649.0}, {"text": "false, and then people will just bash you for whatever you\u0027ve", "timestamp": "00:10:53,012", "timestamp_s": 653.0}, {"text": "done and just give you negative remarks that in turn helps", "timestamp": "00:10:56,404", "timestamp_s": 656.0}, {"text": "you in better serving the model or", "timestamp": "00:11:00,012", "timestamp_s": 660.0}, {"text": "better evaluating on what went wrong and where. So the", "timestamp": "00:11:03,372", "timestamp_s": 663.0}, {"text": "strengths really here are that humans can provide a nuanced", "timestamp": "00:11:07,324", "timestamp_s": 667.0}, {"text": "feedback, judging whether an outcome is simply right or wrong", "timestamp": "00:11:11,268", "timestamp_s": 671.0}, {"text": "based on their understanding, but also considering factors", "timestamp": "00:11:15,324", "timestamp_s": 675.0}, {"text": "like creativity, coherence, and relevance to the task.", "timestamp": "00:11:18,900", "timestamp_s": 678.0}, {"text": "Just as I mentioned before, the same thing that", "timestamp": "00:11:22,780", "timestamp_s": 682.0}, {"text": "probably would be relevant or coherent or creative to a", "timestamp": "00:11:27,204", "timestamp_s": 687.0}, {"text": "native english speaker wouldn\u0027t be the same as for a non native", "timestamp": "00:11:31,476", "timestamp_s": 691.0}, {"text": "speaker, just because of how they understand the language.", "timestamp": "00:11:35,068", "timestamp_s": 695.0}, {"text": "There is obviously many challenges with human evaluation,", "timestamp": "00:11:39,844", "timestamp_s": 699.0}, {"text": "which has its own limitations. The choices, as I said, can be", "timestamp": "00:11:43,636", "timestamp_s": 703.0}, {"text": "subjective, based on location and defining success", "timestamp": "00:11:47,152", "timestamp_s": 707.0}, {"text": "matrix, only based on what someone from a particular place", "timestamp": "00:11:50,688", "timestamp_s": 710.0}, {"text": "said is obviously challenging and may raise", "timestamp": "00:11:54,624", "timestamp_s": 714.0}, {"text": "questions on how this came out to be. So, to this,", "timestamp": "00:11:58,320", "timestamp_s": 718.0}, {"text": "adding to the fact that human evaluation will also take", "timestamp": "00:12:03,704", "timestamp_s": 723.0}, {"text": "time, it is an iterative process and it is also expensive", "timestamp": "00:12:07,568", "timestamp_s": 727.0}, {"text": "because you will probably be putting this into the", "timestamp": "00:12:11,880", "timestamp_s": 731.0}, {"text": "hands of your potential customers, who probably would get", "timestamp": "00:12:16,440", "timestamp_s": 736.0}, {"text": "maybe frustrated, who stop using this app, and then you have to convince", "timestamp": "00:12:19,952", "timestamp_s": 739.0}, {"text": "them to use it and give feedback and whatever all", "timestamp": "00:12:23,848", "timestamp_s": 743.0}, {"text": "this, that entire flow costs time,", "timestamp": "00:12:27,200", "timestamp_s": 747.0}, {"text": "costs money, so we can move towards", "timestamp": "00:12:30,752", "timestamp_s": 750.0}, {"text": "automatic evaluators. Now, when I say automatic evaluators,", "timestamp": "00:12:34,152", "timestamp_s": 754.0}, {"text": "I don\u0027t necessarily mean that everything\u0027s happening by itself and", "timestamp": "00:12:38,040", "timestamp_s": 758.0}, {"text": "you\u0027re just calling a simple function and everyone\u0027s happy,", "timestamp": "00:12:41,360", "timestamp_s": 761.0}, {"text": "and all the language models have achieved nirvana or greatness.", "timestamp": "00:12:44,744", "timestamp_s": 764.0}, {"text": "And whenever I say automatic evaluators, it really means that", "timestamp": "00:12:48,400", "timestamp_s": 768.0}, {"text": "the toolbox that we set up with the three different criteria,", "timestamp": "00:12:51,912", "timestamp_s": 771.0}, {"text": "that toolbox allows you to evaluate", "timestamp": "00:12:55,432", "timestamp_s": 775.0}, {"text": "a particular large language model on its own while", "timestamp": "00:12:59,152", "timestamp_s": 779.0}, {"text": "you\u0027re iterating over the use cases and the strengths.", "timestamp": "00:13:03,776", "timestamp_s": 783.0}, {"text": "Basically, here are their fast, they\u0027re efficient,", "timestamp": "00:13:07,424", "timestamp_s": 787.0}, {"text": "and they\u0027re objective. They assess how well specific parts", "timestamp": "00:13:10,398", "timestamp_s": 790.0}, {"text": "of speech or output match your expectations based on the", "timestamp": "00:13:14,110", "timestamp_s": 794.0}, {"text": "data sets that you have. And choices are based usually", "timestamp": "00:13:17,990", "timestamp_s": 797.0}, {"text": "on known outcomes and well defined metrics. Now,", "timestamp": "00:13:21,446", "timestamp_s": 801.0}, {"text": "how do these known outcomes come come into picture? It\u0027s the", "timestamp": "00:13:25,294", "timestamp_s": 805.0}, {"text": "people who are actually serving these models determining what a", "timestamp": "00:13:28,782", "timestamp_s": 808.0}, {"text": "particular output for a particular, let\u0027s say,", "timestamp": "00:13:32,566", "timestamp_s": 812.0}, {"text": "question or a summary should be, so that whenever you", "timestamp": "00:13:36,086", "timestamp_s": 816.0}, {"text": "are close to it, like for example, root scores,", "timestamp": "00:13:40,596", "timestamp_s": 820.0}, {"text": "whenever you\u0027re really close to it, you think that this is probably a better understand", "timestamp": "00:13:44,348", "timestamp_s": 824.0}, {"text": "the better understood answer rather than something that\u0027s completely", "timestamp": "00:13:48,500", "timestamp_s": 828.0}, {"text": "made up. However, we can also cannot", "timestamp": "00:13:52,236", "timestamp_s": 832.0}, {"text": "discount the limitations that they possess.", "timestamp": "00:13:55,764", "timestamp_s": 835.0}, {"text": "They can\u0027t replicate what we talked about before,", "timestamp": "00:13:58,756", "timestamp_s": 838.0}, {"text": "which was a great thing about human evaluator, as well", "timestamp": "00:14:02,364", "timestamp_s": 842.0}, {"text": "as its limitation, is that the ability to", "timestamp": "00:14:05,860", "timestamp_s": 845.0}, {"text": "understand the context and nuance of this in a", "timestamp": "00:14:09,610", "timestamp_s": 849.0}, {"text": "overall sense of what a", "timestamp": "00:14:14,154", "timestamp_s": 854.0}, {"text": "particular response should be, or what particular answer,", "timestamp": "00:14:17,642", "timestamp_s": 857.0}, {"text": "or what particular future question can come", "timestamp": "00:14:22,874", "timestamp_s": 862.0}, {"text": "over based on that particular answer. So,", "timestamp": "00:14:26,490", "timestamp_s": 866.0}, {"text": "automatic evaluators, they do struggle with creativity and overall quality judgment,", "timestamp": "00:14:29,498", "timestamp_s": 869.0}, {"text": "but they are a lot better evaluator in terms of metrics and", "timestamp": "00:14:34,122", "timestamp_s": 874.0}, {"text": "in terms of, let\u0027s say, as I said,", "timestamp": "00:14:37,860", "timestamp_s": 877.0}, {"text": "Google scores, n gram matching. So they somehow", "timestamp": "00:14:41,428", "timestamp_s": 881.0}, {"text": "work well together. But the real, the golden", "timestamp": "00:14:45,684", "timestamp_s": 885.0}, {"text": "chance, or the golden opportunity here is", "timestamp": "00:14:49,332", "timestamp_s": 889.0}, {"text": "to mix these two human evaluators as well", "timestamp": "00:14:52,892", "timestamp_s": 892.0}, {"text": "as the auto evaluators in having your entire flow", "timestamp": "00:14:56,036", "timestamp_s": 896.0}, {"text": "is such a way that you leverage the best of", "timestamp": "00:14:59,940", "timestamp_s": 899.0}, {"text": "these two and you also overcome the bad,", "timestamp": "00:15:04,000", "timestamp_s": 904.0}, {"text": "I would not say bad parts, but the less best parts,", "timestamp": "00:15:08,392", "timestamp_s": 908.0}, {"text": "I guess, from each of those.", "timestamp": "00:15:12,472", "timestamp_s": 912.0}, {"text": "So I would the takeaway from overall, this is", "timestamp": "00:15:15,848", "timestamp_s": 915.0}, {"text": "a collaborative option is probably better, and which", "timestamp": "00:15:19,168", "timestamp_s": 919.0}, {"text": "one to choose really depends on your particular use case.", "timestamp": "00:15:23,496", "timestamp_s": 923.0}, {"text": "And the ideal approach most likely often", "timestamp": "00:15:27,424", "timestamp_s": 927.0}, {"text": "involves a combination where humans provide valuable", "timestamp": "00:15:30,880", "timestamp_s": 930.0}, {"text": "feedback on whether this was right or wrong. And the auto evaluators", "timestamp": "00:15:35,752", "timestamp_s": 935.0}, {"text": "often consistency in checking whether the answer", "timestamp": "00:15:39,664", "timestamp_s": 939.0}, {"text": "that you\u0027re getting for the, let\u0027s say, for the same question", "timestamp": "00:15:43,536", "timestamp_s": 943.0}, {"text": "or for requesting the same summary is always", "timestamp": "00:15:47,200", "timestamp_s": 947.0}, {"text": "going to be somewhat similar.", "timestamp": "00:15:51,424", "timestamp_s": 951.0}, {"text": "Let shift gears to what we are talking about when we were talking", "timestamp": "00:15:55,434", "timestamp_s": 955.0}, {"text": "about whole evaluators, and let shift gears", "timestamp": "00:15:58,954", "timestamp_s": 958.0}, {"text": "on understanding how do these two evaluators function,", "timestamp": "00:16:02,722", "timestamp_s": 962.0}, {"text": "or how do these two evaluators work with different sorts", "timestamp": "00:16:07,642", "timestamp_s": 967.0}, {"text": "of data sets. So we have two kind of", "timestamp": "00:16:11,762", "timestamp_s": 971.0}, {"text": "data set divergence or data set paths here.", "timestamp": "00:16:16,514", "timestamp_s": 976.0}, {"text": "One is using the public benchmarks that are already available. You don\u0027t have", "timestamp": "00:16:19,754", "timestamp_s": 979.0}, {"text": "to do much, you just trust these benchmarks that are", "timestamp": "00:16:23,380", "timestamp_s": 983.0}, {"text": "available probably on these public leaderboards,", "timestamp": "00:16:26,468", "timestamp_s": 986.0}, {"text": "maybe hugging face or individual competitions.", "timestamp": "00:16:31,604", "timestamp_s": 991.0}, {"text": "And the other way is using golden datasets.", "timestamp": "00:16:37,204", "timestamp_s": 997.0}, {"text": "Now, whenever I say golden datasets, it doesn\u0027t", "timestamp": "00:16:40,796", "timestamp_s": 1000.0}, {"text": "mean that this is literally the gold standard. It just means", "timestamp": "00:16:44,044", "timestamp_s": 1004.0}, {"text": "that these are datasets or these are the values", "timestamp": "00:16:47,676", "timestamp_s": 1007.0}, {"text": "that you control and these are the values that are", "timestamp": "00:16:52,212", "timestamp_s": 1012.0}, {"text": "definitely, or I should say almost 90%", "timestamp": "00:16:56,444", "timestamp_s": 1016.0}, {"text": "true to be really effective in giving you an answer.", "timestamp": "00:17:01,764", "timestamp_s": 1021.0}, {"text": "So public benchmarks, these are predefined data sets. You can", "timestamp": "00:17:05,332", "timestamp_s": 1025.0}, {"text": "easily get that from hugging face. And they are more.", "timestamp": "00:17:08,660", "timestamp_s": 1028.0}, {"text": "The more the research that was put into creating these data", "timestamp": "00:17:13,024", "timestamp_s": 1033.0}, {"text": "sets, understanding or training a particular model to test on these data", "timestamp": "00:17:16,624", "timestamp_s": 1036.0}, {"text": "sets, the more fair assessment these public benchmarks", "timestamp": "00:17:20,504", "timestamp_s": 1040.0}, {"text": "will give you. And they will give you an understanding of the", "timestamp": "00:17:24,368", "timestamp_s": 1044.0}, {"text": "general capabilities of a model on different sorts of", "timestamp": "00:17:27,864", "timestamp_s": 1047.0}, {"text": "data sets, like how well a model is,", "timestamp": "00:17:31,360", "timestamp_s": 1051.0}, {"text": "how well a model performs with, let\u0027s say, something as", "timestamp": "00:17:35,624", "timestamp_s": 1055.0}, {"text": "something called, as maybe abstractive summarization,", "timestamp": "00:17:39,744", "timestamp_s": 1059.0}, {"text": "summarization, question answering, or even giving you", "timestamp": "00:17:42,696", "timestamp_s": 1062.0}, {"text": "answers to a particular code, debugging or explaining maybe", "timestamp": "00:17:46,152", "timestamp_s": 1066.0}, {"text": "programming concepts or scientific concepts, or, you know,", "timestamp": "00:17:51,224", "timestamp_s": 1071.0}, {"text": "any concepts in general. However, these public", "timestamp": "00:17:55,224", "timestamp_s": 1075.0}, {"text": "benchmarks, given the broad scope of what", "timestamp": "00:17:59,224", "timestamp_s": 1079.0}, {"text": "kind of data sets they usually have and the formats of these,", "timestamp": "00:18:02,640", "timestamp_s": 1082.0}, {"text": "they don\u0027t necessarily guarantee success, or they don\u0027t necessarily", "timestamp": "00:18:06,794", "timestamp_s": 1086.0}, {"text": "guarantee a yes or no answer whenever you\u0027re", "timestamp": "00:18:10,626", "timestamp_s": 1090.0}, {"text": "looking at a particular model and making a decision whether you should use that model", "timestamp": "00:18:14,586", "timestamp_s": 1094.0}, {"text": "or not, because your use case is really", "timestamp": "00:18:18,562", "timestamp_s": 1098.0}, {"text": "a specific use case that\u0027s coming out of the model, rather than people", "timestamp": "00:18:22,090", "timestamp_s": 1102.0}, {"text": "asking travel tips or money saving tips,", "timestamp": "00:18:26,306", "timestamp_s": 1106.0}, {"text": "which is what we usually see. The most popular use cases", "timestamp": "00:18:29,986", "timestamp_s": 1109.0}, {"text": "of these language models are so the takeaway on public benchmarks.", "timestamp": "00:18:34,220", "timestamp_s": 1114.0}, {"text": "They do offer valuable starting point, as in,", "timestamp": "00:18:37,844", "timestamp_s": 1117.0}, {"text": "they do offer something to give you a edge over,", "timestamp": "00:18:41,084", "timestamp_s": 1121.0}, {"text": "but they shouldn\u0027t be the sole measure of what you\u0027re trying", "timestamp": "00:18:45,564", "timestamp_s": 1125.0}, {"text": "to achieve and are trying to test based on the LLM\u0027s effectiveness.", "timestamp": "00:18:48,884", "timestamp_s": 1128.0}, {"text": "Moving ahead to the golden data sets, these data sets,", "timestamp": "00:18:53,508", "timestamp_s": 1133.0}, {"text": "as I already said, are tailored to your specific needs.", "timestamp": "00:18:56,900", "timestamp_s": 1136.0}, {"text": "You control what output you expect, you control", "timestamp": "00:19:00,298", "timestamp_s": 1140.0}, {"text": "what prompt, or let\u0027s say, what metrics or", "timestamp": "00:19:04,098", "timestamp_s": 1144.0}, {"text": "how to put it in a better way. You control what the exact", "timestamp": "00:19:07,978", "timestamp_s": 1147.0}, {"text": "result from the large language model that you\u0027re expecting", "timestamp": "00:19:11,810", "timestamp_s": 1151.0}, {"text": "is. Of course, you do not control what the large language model obviously", "timestamp": "00:19:15,634", "timestamp_s": 1155.0}, {"text": "gives you to a certain extent. But what you know is", "timestamp": "00:19:19,474", "timestamp_s": 1159.0}, {"text": "that if I refer this to particular,", "timestamp": "00:19:22,842", "timestamp_s": 1162.0}, {"text": "let\u0027s say, a particular sentence, I know, the more this sentence", "timestamp": "00:19:27,174", "timestamp_s": 1167.0}, {"text": "matches with what the LLM has given me. It\u0027s more", "timestamp": "00:19:31,230", "timestamp_s": 1171.0}, {"text": "accurate, or I would assume that it\u0027s more accurate and performs well", "timestamp": "00:19:35,190", "timestamp_s": 1175.0}, {"text": "on the task that I have made it to.", "timestamp": "00:19:38,790", "timestamp_s": 1178.0}, {"text": "So these, let\u0027s say golden data", "timestamp": "00:19:41,694", "timestamp_s": 1181.0}, {"text": "sets are used will allow you to evaluate how well an LLM", "timestamp": "00:19:45,054", "timestamp_s": 1185.0}, {"text": "performs of the tasks that matter most to you, rather than being", "timestamp": "00:19:49,262", "timestamp_s": 1189.0}, {"text": "a generic data set of maybe", "timestamp": "00:19:53,066", "timestamp_s": 1193.0}, {"text": "Reddit comments on maybe people just posting this, this,", "timestamp": "00:19:56,418", "timestamp_s": 1196.0}, {"text": "this in a chain that doesn\u0027t make sense to you anymore.", "timestamp": "00:19:59,802", "timestamp_s": 1199.0}, {"text": "But obviously this is a part of the", "timestamp": "00:20:03,394", "timestamp_s": 1203.0}, {"text": "whole training data set if they weren\u0027t clean before.", "timestamp": "00:20:07,130", "timestamp_s": 1207.0}, {"text": "So some examples of golden data", "timestamp": "00:20:11,034", "timestamp_s": 1211.0}, {"text": "sets would be for a, let\u0027s say for", "timestamp": "00:20:14,354", "timestamp_s": 1214.0}, {"text": "a use case, like checking semantic similarity of the", "timestamp": "00:20:17,842", "timestamp_s": 1217.0}, {"text": "content that was given out, or measuring perplexity,", "timestamp": "00:20:21,864", "timestamp_s": 1221.0}, {"text": "or as I said, root scores in summarization", "timestamp": "00:20:25,056", "timestamp_s": 1225.0}, {"text": "tasks so that you could understand how well a summary was generated,", "timestamp": "00:20:28,472", "timestamp_s": 1228.0}, {"text": "how short or how long that summary even was. And these are instrumental", "timestamp": "00:20:32,104", "timestamp_s": 1232.0}, {"text": "in building the rag based workflows,", "timestamp": "00:20:36,072", "timestamp_s": 1236.0}, {"text": "which is the retrieval augmented generation based workflows.", "timestamp": "00:20:39,880", "timestamp_s": 1239.0}, {"text": "And these will give you a really good idea on how your rag", "timestamp": "00:20:43,320", "timestamp_s": 1243.0}, {"text": "workflow should be, which is what", "timestamp": "00:20:47,400", "timestamp_s": 1247.0}, {"text": "we are evaluating or what we are", "timestamp": "00:20:50,998", "timestamp_s": 1250.0}, {"text": "understanding to evaluate here. So the most effective approach,", "timestamp": "00:20:54,158", "timestamp_s": 1254.0}, {"text": "again, leverage the as we discussed before,", "timestamp": "00:20:57,654", "timestamp_s": 1257.0}, {"text": "leverage the public.", "timestamp": "00:21:01,190", "timestamp_s": 1261.0}, {"text": "Leverage the public information, as well as leverage the", "timestamp": "00:21:05,654", "timestamp_s": 1265.0}, {"text": "data sets that you prepare because they both provide you a", "timestamp": "00:21:09,230", "timestamp_s": 1269.0}, {"text": "certain benchmark that you can then evaluate and iterate", "timestamp": "00:21:12,422", "timestamp_s": 1272.0}, {"text": "over. Moving ahead. Now that we understand", "timestamp": "00:21:16,026", "timestamp_s": 1276.0}, {"text": "what these evaluation methods resources are, what usually", "timestamp": "00:21:20,354", "timestamp_s": 1280.0}, {"text": "works, let\u0027s talk about applying this knowledge to the specific", "timestamp": "00:21:23,922", "timestamp_s": 1283.0}, {"text": "needs. As I said before, your use case is probably", "timestamp": "00:21:27,610", "timestamp_s": 1287.0}, {"text": "well defined. You\u0027re looking for a model that performs really well", "timestamp": "00:21:31,474", "timestamp_s": 1291.0}, {"text": "in a particular sector rather than a general model for.", "timestamp": "00:21:35,218", "timestamp_s": 1295.0}, {"text": "Let\u0027s assume this Chevrolet case where someone", "timestamp": "00:21:38,794", "timestamp_s": 1298.0}, {"text": "tried to ask the language model and try to get a brand", "timestamp": "00:21:43,554", "timestamp_s": 1303.0}, {"text": "new Chevrolet Tahoe for like $1.", "timestamp": "00:21:47,106", "timestamp_s": 1307.0}, {"text": "Let\u0027s assume that you are in the scientific research community and your", "timestamp": "00:21:50,394", "timestamp_s": 1310.0}, {"text": "model is really open to answering", "timestamp": "00:21:53,962", "timestamp_s": 1313.0}, {"text": "any and all sorts of questions that\u0027s not really", "timestamp": "00:21:57,194", "timestamp_s": 1317.0}, {"text": "good for you, that\u0027s not really conducive for you. And the", "timestamp": "00:22:01,274", "timestamp_s": 1321.0}, {"text": "evaluation metrics when they\u0027re actually in progress", "timestamp": "00:22:05,122", "timestamp_s": 1325.0}, {"text": "or work with these models. These will tell you how close people", "timestamp": "00:22:08,820", "timestamp_s": 1328.0}, {"text": "are talking about the use case,", "timestamp": "00:22:12,316", "timestamp_s": 1332.0}, {"text": "how close the topics are, and whether they really make", "timestamp": "00:22:15,668", "timestamp_s": 1335.0}, {"text": "sense, or whether the user feedback makes sense.", "timestamp": "00:22:18,836", "timestamp_s": 1338.0}, {"text": "So in general, you could consider", "timestamp": "00:22:22,308", "timestamp_s": 1342.0}, {"text": "this as do you need a particular use case to answer questions?", "timestamp": "00:22:25,812", "timestamp_s": 1345.0}, {"text": "Do you need to answer summaries? Or do you need particular", "timestamp": "00:22:30,076", "timestamp_s": 1350.0}, {"text": "use case to provide you citations,", "timestamp": "00:22:33,682", "timestamp_s": 1353.0}, {"text": "references, or just be a general language model", "timestamp": "00:22:36,322", "timestamp_s": 1356.0}, {"text": "that really answers the question without any external source", "timestamp": "00:22:40,058", "timestamp_s": 1360.0}, {"text": "and answers questions from its knowledge database.", "timestamp": "00:22:43,890", "timestamp_s": 1363.0}, {"text": "So the content that goes in and the content that", "timestamp": "00:22:47,466", "timestamp_s": 1367.0}, {"text": "comes basically, whatever the content that goes in and", "timestamp": "00:22:50,802", "timestamp_s": 1370.0}, {"text": "whatever the content that LLM interacts with, is it supporting", "timestamp": "00:22:54,650", "timestamp_s": 1374.0}, {"text": "a document library, a vector database,", "timestamp": "00:22:58,898", "timestamp_s": 1378.0}, {"text": "or just a vast collection of text data? That\u0027s how", "timestamp": "00:23:02,010", "timestamp_s": 1382.0}, {"text": "your use case will determine what the output,", "timestamp": "00:23:07,714", "timestamp_s": 1387.0}, {"text": "or how well defined your output should", "timestamp": "00:23:11,010", "timestamp_s": 1391.0}, {"text": "be. And eventually, once this is defined,", "timestamp": "00:23:14,906", "timestamp_s": 1394.0}, {"text": "you could really understand on how the model is performing.", "timestamp": "00:23:18,450", "timestamp_s": 1398.0}, {"text": "You could maybe involve some fine tuning for it.", "timestamp": "00:23:21,922", "timestamp_s": 1401.0}, {"text": "You could go on topic modeling and maybe restrict the model on", "timestamp": "00:23:25,058", "timestamp_s": 1405.0}, {"text": "answering, or even,", "timestamp": "00:23:28,810", "timestamp_s": 1408.0}, {"text": "or even getting the model to answer particular questions based on", "timestamp": "00:23:32,424", "timestamp_s": 1412.0}, {"text": "what your use case is. And it\u0027s also crucial to establish", "timestamp": "00:23:35,720", "timestamp_s": 1415.0}, {"text": "certain guardrails, certain input validation,", "timestamp": "00:23:39,056", "timestamp_s": 1419.0}, {"text": "certain output validation, so that you\u0027re not drifting into something that", "timestamp": "00:23:43,272", "timestamp_s": 1423.0}, {"text": "you shouldn\u0027t be doing or you shouldn\u0027t be talking about. Of course,", "timestamp": "00:23:47,704", "timestamp_s": 1427.0}, {"text": "prompt engineering or in general,", "timestamp": "00:23:51,008", "timestamp_s": 1431.0}, {"text": "defining the prompt is also somewhat an", "timestamp": "00:23:54,016", "timestamp_s": 1434.0}, {"text": "aspect of this particular flow. But once these metrics that", "timestamp": "00:23:57,574", "timestamp_s": 1437.0}, {"text": "we\u0027ll discuss now are defined, you really know", "timestamp": "00:24:01,830", "timestamp_s": 1441.0}, {"text": "how a particular language model is working for your", "timestamp": "00:24:05,286", "timestamp_s": 1445.0}, {"text": "particular flow. Moving ahead, let\u0027s dive", "timestamp": "00:24:09,158", "timestamp_s": 1449.0}, {"text": "into the nitty gritty, or, you know, the specifics of", "timestamp": "00:24:12,574", "timestamp_s": 1452.0}, {"text": "what we were talking about. How do we measure the effectiveness of a tailored", "timestamp": "00:24:16,222", "timestamp_s": 1456.0}, {"text": "large language model? We could first move", "timestamp": "00:24:20,694", "timestamp_s": 1460.0}, {"text": "to traditional metrics, the most familiar", "timestamp": "00:24:24,260", "timestamp_s": 1464.0}, {"text": "how these tools are. These tools are effective", "timestamp": "00:24:28,084", "timestamp_s": 1468.0}, {"text": "kind of outputs we outputs we get", "timestamp": "00:24:32,964", "timestamp_s": 1472.0}, {"text": "from flavors of rules of rule scores.", "timestamp": "00:24:37,604", "timestamp_s": 1477.0}, {"text": "More language", "timestamp": "00:24:42,564", "timestamp_s": 1482.0}, {"text": "language processing language processing approach.", "timestamp": "00:24:47,844", "timestamp_s": 1487.0}, {"text": "How well the LLM in n gram matches,", "timestamp": "00:24:54,744", "timestamp_s": 1494.0}, {"text": "or in other use cases where", "timestamp": "00:24:58,832", "timestamp_s": 1498.0}, {"text": "you check other scores, will help", "timestamp": "00:25:02,384", "timestamp_s": 1502.0}, {"text": "you understand on how better to how", "timestamp": "00:25:06,024", "timestamp_s": 1506.0}, {"text": "better your model is performing. Also, there\u0027s another particular", "timestamp": "00:25:09,816", "timestamp_s": 1509.0}, {"text": "metric that we should also be exploring is perplexity.", "timestamp": "00:25:13,648", "timestamp_s": 1513.0}, {"text": "It\u0027s a metric that takes a slightly different approach.", "timestamp": "00:25:18,002", "timestamp_s": 1518.0}, {"text": "Rather than having a well", "timestamp": "00:25:21,674", "timestamp_s": 1521.0}, {"text": "put dataset together, having a well put timeline together.", "timestamp": "00:25:24,978", "timestamp_s": 1524.0}, {"text": "It assesses the LLM\u0027s internal ability to predict the next word", "timestamp": "00:25:28,842", "timestamp_s": 1528.0}, {"text": "in a sequence. So it will tell you how confident a particular", "timestamp": "00:25:32,970", "timestamp_s": 1532.0}, {"text": "LLM was in predicting the next word, and a lower the score.", "timestamp": "00:25:36,914", "timestamp_s": 1536.0}, {"text": "Lower the overall score. It indicates that the LLM is more", "timestamp": "00:25:41,804", "timestamp_s": 1541.0}, {"text": "confident in its predictions and is less likely to generate", "timestamp": "00:25:45,324", "timestamp_s": 1545.0}, {"text": "surprising results, or even completely non", "timestamp": "00:25:49,444", "timestamp_s": 1549.0}, {"text": "essential results. So while these traditional metrics are available,", "timestamp": "00:25:53,028", "timestamp_s": 1553.0}, {"text": "things like regas", "timestamp": "00:25:56,972", "timestamp_s": 1556.0}, {"text": "or ragas, I should say, I don\u0027t know how it\u0027s", "timestamp": "00:26:00,252", "timestamp_s": 1560.0}, {"text": "actually pronounced, but things like ragas or regas, they are really", "timestamp": "00:26:04,484", "timestamp_s": 1564.0}, {"text": "good workflows to to treat your retrieval augmented", "timestamp": "00:26:08,420", "timestamp_s": 1568.0}, {"text": "generation pipelines. And the metrics like faithfulness", "timestamp": "00:26:12,786", "timestamp_s": 1572.0}, {"text": "or relevance or other aspects of", "timestamp": "00:26:16,466", "timestamp_s": 1576.0}, {"text": "this particular framework will allow you to understand more better on how", "timestamp": "00:26:19,850", "timestamp_s": 1579.0}, {"text": "your whole rag pipeline is working.", "timestamp": "00:26:24,338", "timestamp_s": 1584.0}, {"text": "And also another good framework", "timestamp": "00:26:27,562", "timestamp_s": 1587.0}, {"text": "is the QA Ul by Daniel. It also provides", "timestamp": "00:26:31,346", "timestamp_s": 1591.0}, {"text": "good insights and it checks whether a particular LLM", "timestamp": "00:26:35,274", "timestamp_s": 1595.0}, {"text": "captures the key concepts or the key information that", "timestamp": "00:26:39,190", "timestamp_s": 1599.0}, {"text": "was asked of it. So these are some of the I", "timestamp": "00:26:42,782", "timestamp_s": 1602.0}, {"text": "guess the next step on this, now that we have", "timestamp": "00:26:47,678", "timestamp_s": 1607.0}, {"text": "established a benchmark is what about llms evaluating", "timestamp": "00:26:51,638", "timestamp_s": 1611.0}, {"text": "llms? There\u0027s been some good research,", "timestamp": "00:26:56,006", "timestamp_s": 1616.0}, {"text": "some good findings based on whether an LLM can", "timestamp": "00:26:59,054", "timestamp_s": 1619.0}, {"text": "actually evaluate other LLM.", "timestamp": "00:27:02,830", "timestamp_s": 1622.0}, {"text": "And this is most likely a trial", "timestamp": "00:27:05,922", "timestamp_s": 1625.0}, {"text": "and error approach on making sure to be understand the", "timestamp": "00:27:11,594", "timestamp_s": 1631.0}, {"text": "use case and something like chatbot arena,", "timestamp": "00:27:15,770", "timestamp_s": 1635.0}, {"text": "which basically you could use the outputs generated from", "timestamp": "00:27:18,954", "timestamp_s": 1638.0}, {"text": "that from two different models and evaluate and see", "timestamp": "00:27:22,906", "timestamp_s": 1642.0}, {"text": "whether these two different models could compete with each other in generating", "timestamp": "00:27:26,170", "timestamp_s": 1646.0}, {"text": "the text. If you ask one model, hey, is this factually correct", "timestamp": "00:27:30,146", "timestamp_s": 1650.0}, {"text": "based on this answer, and you could iterate", "timestamp": "00:27:34,118", "timestamp_s": 1654.0}, {"text": "on that, I wouldn\u0027t put", "timestamp": "00:27:37,614", "timestamp_s": 1657.0}, {"text": "much stress on how efficient", "timestamp": "00:27:41,278", "timestamp_s": 1661.0}, {"text": "or how correct these metrics", "timestamp": "00:27:44,854", "timestamp_s": 1664.0}, {"text": "are, these judgment would be, but considering", "timestamp": "00:27:49,006", "timestamp_s": 1669.0}, {"text": "that most models were trained on somewhat similar data", "timestamp": "00:27:52,774", "timestamp_s": 1672.0}, {"text": "sets, you should expect that the results would be more subjective", "timestamp": "00:27:57,206", "timestamp_s": 1677.0}, {"text": "and will give you a good insight on how a model", "timestamp": "00:28:01,680", "timestamp_s": 1681.0}, {"text": "would perform against some other model. The other", "timestamp": "00:28:05,024", "timestamp_s": 1685.0}, {"text": "approach of this is definitely the metrics that", "timestamp": "00:28:08,784", "timestamp_s": 1688.0}, {"text": "we discussed. So the metrics that you", "timestamp": "00:28:12,600", "timestamp_s": 1692.0}, {"text": "choose, your own metrics, you compare those metrics, you have a", "timestamp": "00:28:16,432", "timestamp_s": 1696.0}, {"text": "definite set of iterative metrics that you\u0027ve had so far.", "timestamp": "00:28:19,992", "timestamp_s": 1699.0}, {"text": "You have a data set that you can test on for, and you can", "timestamp": "00:28:23,280", "timestamp_s": 1703.0}, {"text": "really put that into a number or an understanding", "timestamp": "00:28:26,692", "timestamp_s": 1706.0}, {"text": "in a perspective that even your customers,", "timestamp": "00:28:30,844", "timestamp_s": 1710.0}, {"text": "people in your management, or people you\u0027re working", "timestamp": "00:28:34,244", "timestamp_s": 1714.0}, {"text": "with, or even the scientists that you\u0027re working with, really have", "timestamp": "00:28:37,612", "timestamp_s": 1717.0}, {"text": "a good benchmark on where they are right now", "timestamp": "00:28:41,980", "timestamp_s": 1721.0}, {"text": "and where they are looking to be.", "timestamp": "00:28:45,388", "timestamp_s": 1725.0}, {"text": "So the human touch, the ultimate judge, what human evaluation", "timestamp": "00:28:48,724", "timestamp_s": 1728.0}, {"text": "does, what a multifaceted approach will", "timestamp": "00:28:53,614", "timestamp_s": 1733.0}, {"text": "give you. And despite the rise of all of these automated", "timestamp": "00:28:57,446", "timestamp_s": 1737.0}, {"text": "metrics, I believe that we", "timestamp": "00:29:01,654", "timestamp_s": 1741.0}, {"text": "should be also looking at the human aspect of it and be", "timestamp": "00:29:05,662", "timestamp_s": 1745.0}, {"text": "really sure that we are closing the gap between what we", "timestamp": "00:29:09,494", "timestamp_s": 1749.0}, {"text": "are evaluating versus what is necessary.", "timestamp": "00:29:12,998", "timestamp_s": 1752.0}, {"text": "So that instead of chasing the next", "timestamp": "00:29:16,446", "timestamp_s": 1756.0}, {"text": "cool model or the next best model, the next", "timestamp": "00:29:20,194", "timestamp_s": 1760.0}, {"text": "public best model available, we really make an informed", "timestamp": "00:29:23,874", "timestamp_s": 1763.0}, {"text": "decision on whether we are falling behind just because", "timestamp": "00:29:27,674", "timestamp_s": 1767.0}, {"text": "there was a new model launch, or whether we are falling behind because", "timestamp": "00:29:32,002", "timestamp_s": 1772.0}, {"text": "the data set that we fine tuned on isn\u0027t that good.", "timestamp": "00:29:36,058", "timestamp_s": 1776.0}, {"text": "Or maybe we need more of that data set, or maybe we", "timestamp": "00:29:39,402", "timestamp_s": 1779.0}, {"text": "are good with whatever the metrics that we have so slowly", "timestamp": "00:29:43,098", "timestamp_s": 1783.0}, {"text": "iterating over that we\u0027ll get good at the game and we\u0027ll", "timestamp": "00:29:47,200", "timestamp_s": 1787.0}, {"text": "be able to clearly determine what is essentially required.", "timestamp": "00:29:51,400", "timestamp_s": 1791.0}, {"text": "Moving ahead. These are some available frameworks,", "timestamp": "00:29:55,824", "timestamp_s": 1795.0}, {"text": "Regas helm, which is a really good benchmark.", "timestamp": "00:29:59,680", "timestamp_s": 1799.0}, {"text": "Again, these benchmarks will tell you how a", "timestamp": "00:30:03,104", "timestamp_s": 1803.0}, {"text": "particular model was working on a particular large", "timestamp": "00:30:07,112", "timestamp_s": 1807.0}, {"text": "corpus of data sets. There\u0027s also langsmith by Lang chain,", "timestamp": "00:30:11,512", "timestamp_s": 1811.0}, {"text": "with and without the integration for the weights", "timestamp": "00:30:15,762", "timestamp_s": 1815.0}, {"text": "and biases for you to eval. There\u0027s OpenAI evals", "timestamp": "00:30:19,298", "timestamp_s": 1819.0}, {"text": "that gives you a good idea on what evaluation frameworks", "timestamp": "00:30:23,554", "timestamp_s": 1823.0}, {"text": "or what other evaluation metrics are available. There\u0027s deep eval,", "timestamp": "00:30:28,162", "timestamp_s": 1828.0}, {"text": "there\u0027s this LM evaluation harness that I\u0027ve really grown", "timestamp": "00:30:31,922", "timestamp_s": 1831.0}, {"text": "kind of fond of. They do a really good job at", "timestamp": "00:30:35,898", "timestamp_s": 1835.0}, {"text": "allowing you to evaluate a particular model on a", "timestamp": "00:30:40,554", "timestamp_s": 1840.0}, {"text": "particular public dataset with really less overhead.", "timestamp": "00:30:44,098", "timestamp_s": 1844.0}, {"text": "But as I said, there\u0027s some", "timestamp": "00:30:47,970", "timestamp_s": 1847.0}, {"text": "overhead to making it work for your own custom use case.", "timestamp": "00:30:52,026", "timestamp_s": 1852.0}, {"text": "And that\u0027s where I found that using simply basic", "timestamp": "00:30:56,234", "timestamp_s": 1856.0}, {"text": "hugging face functions to load your data set to calculate", "timestamp": "00:31:01,042", "timestamp_s": 1861.0}, {"text": "scores is probably what is beats,", "timestamp": "00:31:04,938", "timestamp_s": 1864.0}, {"text": "or is more easier to use or is more efficient to use.", "timestamp": "00:31:09,620", "timestamp_s": 1869.0}, {"text": "So that\u0027s the frameworks that are available that", "timestamp": "00:31:13,468", "timestamp_s": 1873.0}, {"text": "we can try and test. And at the end, all you", "timestamp": "00:31:17,724", "timestamp_s": 1877.0}, {"text": "need is a test eval set,", "timestamp": "00:31:21,284", "timestamp_s": 1881.0}, {"text": "a multifaceted approach on how", "timestamp": "00:31:26,164", "timestamp_s": 1886.0}, {"text": "you can use the existing test eval", "timestamp": "00:31:29,820", "timestamp_s": 1889.0}, {"text": "set, or whatever the existing data set you have, or you", "timestamp": "00:31:33,370", "timestamp_s": 1893.0}, {"text": "will create, and into understanding really", "timestamp": "00:31:37,194", "timestamp_s": 1897.0}, {"text": "how you can develop a particular set of metrics", "timestamp": "00:31:40,818", "timestamp_s": 1900.0}, {"text": "around it. And you can use those. So the foundation is", "timestamp": "00:31:44,554", "timestamp_s": 1904.0}, {"text": "going to be your test set or evaluation set, and the", "timestamp": "00:31:47,890", "timestamp_s": 1907.0}, {"text": "properties, some which are internal to the model or which", "timestamp": "00:31:51,090", "timestamp_s": 1911.0}, {"text": "are internal to the framework that you\u0027re using, like perplexity, which can be", "timestamp": "00:31:54,338", "timestamp_s": 1914.0}, {"text": "called calculated from the outputs that you get, or any", "timestamp": "00:31:57,918", "timestamp_s": 1917.0}, {"text": "existing implementations for any", "timestamp": "00:32:01,646", "timestamp_s": 1921.0}, {"text": "particular public task, or any particular specific task that you\u0027re trying to", "timestamp": "00:32:05,078", "timestamp_s": 1925.0}, {"text": "look. And the benefits of this", "timestamp": "00:32:08,630", "timestamp_s": 1928.0}, {"text": "would be that you really control what sort of metrics", "timestamp": "00:32:11,926", "timestamp_s": 1931.0}, {"text": "are used in particular evaluation, what sort of metrics", "timestamp": "00:32:15,590", "timestamp_s": 1935.0}, {"text": "you can quantify your application against.", "timestamp": "00:32:19,550", "timestamp_s": 1939.0}, {"text": "And you can also have an established set", "timestamp": "00:32:23,750", "timestamp_s": 1943.0}, {"text": "of data sets that can help you over the long term in understanding", "timestamp": "00:32:26,962", "timestamp_s": 1946.0}, {"text": "how the model performed over a certain duration or", "timestamp": "00:32:30,954", "timestamp_s": 1950.0}, {"text": "a certain time, and what you can do more better after.", "timestamp": "00:32:34,538", "timestamp_s": 1954.0}, {"text": "Let\u0027s say you fine tuned the model multiple times,", "timestamp": "00:32:38,514", "timestamp_s": 1958.0}, {"text": "you\u0027ve changed the model, so it gives you a good flow of all of", "timestamp": "00:32:41,618", "timestamp_s": 1961.0}, {"text": "the metrics that you can make the decisions", "timestamp": "00:32:45,458", "timestamp_s": 1965.0}, {"text": "on. I guess that\u0027s probably", "timestamp": "00:32:48,722", "timestamp_s": 1968.0}, {"text": "it. That\u0027s what I want to discuss. And I", "timestamp": "00:32:52,726", "timestamp_s": 1972.0}, {"text": "would in general say that adapting public libraries or", "timestamp": "00:32:57,430", "timestamp_s": 1977.0}, {"text": "public frameworks like hugging face eval or lmewal", "timestamp": "00:33:00,622", "timestamp_s": 1980.0}, {"text": "harness is a really good start at first to get", "timestamp": "00:33:04,486", "timestamp_s": 1984.0}, {"text": "any metrics like f one aggregated scores,", "timestamp": "00:33:08,230", "timestamp_s": 1988.0}, {"text": "blue scores or root scores, blue scores or root", "timestamp": "00:33:12,854", "timestamp_s": 1992.0}, {"text": "scores, or all of these scores, to decide", "timestamp": "00:33:17,054", "timestamp_s": 1997.0}, {"text": "or define a particular evaluation framework for", "timestamp": "00:33:20,848", "timestamp_s": 2000.0}, {"text": "a RNG based flow. And these will work seamlessly", "timestamp": "00:33:24,400", "timestamp_s": 2004.0}, {"text": "with your chosen data sets. Also, of course,", "timestamp": "00:33:27,856", "timestamp_s": 2007.0}, {"text": "including human evaluation, human flow into", "timestamp": "00:33:31,176", "timestamp_s": 2011.0}, {"text": "the application and comparing really on", "timestamp": "00:33:34,560", "timestamp_s": 2014.0}, {"text": "what human evaluation results are with", "timestamp": "00:33:38,048", "timestamp_s": 2018.0}, {"text": "what you\u0027re getting, as opposed to a certain particular", "timestamp": "00:33:41,504", "timestamp_s": 2021.0}, {"text": "benchmark, will be a overall", "timestamp": "00:33:45,224", "timestamp_s": 2025.0}, {"text": "good strategy to evaluate large language models", "timestamp": "00:33:48,852", "timestamp_s": 2028.0}, {"text": "on. In conclusion, we\u0027ve really,", "timestamp": "00:33:52,324", "timestamp_s": 2032.0}, {"text": "in a really abstract manner, explored how", "timestamp": "00:33:55,700", "timestamp_s": 2035.0}, {"text": "you can evaluate why a particular evaluation type", "timestamp": "00:33:59,300", "timestamp_s": 2039.0}, {"text": "is necessary. And it\u0027s, and at the end, it is not just", "timestamp": "00:34:03,308", "timestamp_s": 2043.0}, {"text": "about whether you get a score out of it", "timestamp": "00:34:07,188", "timestamp_s": 2047.0}, {"text": "or not. It\u0027s not about establishing a particular metric and,", "timestamp": "00:34:10,580", "timestamp_s": 2050.0}, {"text": "you know, charting out six", "timestamp": "00:34:14,116", "timestamp_s": 2054.0}, {"text": "months of metric data and just", "timestamp": "00:34:17,304", "timestamp_s": 2057.0}, {"text": "saying that, hey, this is the model that works for me. It\u0027s about", "timestamp": "00:34:21,224", "timestamp_s": 2061.0}, {"text": "establishing a foundation so that whenever you\u0027re developing", "timestamp": "00:34:24,672", "timestamp_s": 2064.0}, {"text": "iteratively, whenever you\u0027re mark, you\u0027re managing", "timestamp": "00:34:28,952", "timestamp_s": 2068.0}, {"text": "these large language models so that you can continuously", "timestamp": "00:34:33,440", "timestamp_s": 2073.0}, {"text": "improve on the remarkable research that", "timestamp": "00:34:37,288", "timestamp_s": 2077.0}, {"text": "has already done into putting these large language models out public with", "timestamp": "00:34:40,920", "timestamp_s": 2080.0}, {"text": "their weights. And by leveraging these right metrics,", "timestamp": "00:34:45,131", "timestamp_s": 2085.0}, {"text": "you can now unlock the potential of these models", "timestamp": "00:34:48,659", "timestamp_s": 2088.0}, {"text": "in for your specific use case and determine", "timestamp": "00:34:52,019", "timestamp_s": 2092.0}, {"text": "whether a particular model works for you, or if it doesn\u0027t", "timestamp": "00:34:55,715", "timestamp_s": 2095.0}, {"text": "work for you, why does it not work for you?", "timestamp": "00:34:59,475", "timestamp_s": 2099.0}, {"text": "And in general, understanding or delivering", "timestamp": "00:35:02,699", "timestamp_s": 2102.0}, {"text": "real world benefits to the user. And as this field", "timestamp": "00:35:06,707", "timestamp_s": 2106.0}, {"text": "grows, there\u0027s new, more new research into", "timestamp": "00:35:11,374", "timestamp_s": 2111.0}, {"text": "it. We\u0027d probably move ahead, or we\u0027ve probably already moved", "timestamp": "00:35:14,574", "timestamp_s": 2114.0}, {"text": "ahead beyond these basic scores and we\u0027ve gone into more", "timestamp": "00:35:18,790", "timestamp_s": 2118.0}, {"text": "a complex understanding of context,", "timestamp": "00:35:22,582", "timestamp_s": 2122.0}, {"text": "whether the particular model understands a particular context grammar", "timestamp": "00:35:26,254", "timestamp_s": 2126.0}, {"text": "and all of these ideas. And it", "timestamp": "00:35:30,094", "timestamp_s": 2130.0}, {"text": "is going to be really exciting on what more,", "timestamp": "00:35:34,326", "timestamp_s": 2134.0}, {"text": "what more metrics or frameworks that come up so", "timestamp": "00:35:37,674", "timestamp_s": 2137.0}, {"text": "that we could evaluate a large language model better.", "timestamp": "00:35:41,370", "timestamp_s": 2141.0}, {"text": "So yeah, that\u0027s it from me, and I", "timestamp": "00:35:45,394", "timestamp_s": 2145.0}, {"text": "hope you got a really good starting point. This was meant", "timestamp": "00:35:48,642", "timestamp_s": 2148.0}, {"text": "to be a good, this was meant to be just an introduction on", "timestamp": "00:35:51,850", "timestamp_s": 2151.0}, {"text": "what kind of frameworks are available and what you can do with those and which", "timestamp": "00:35:55,618", "timestamp_s": 2155.0}, {"text": "approaches work really well. So I hope you enjoyed", "timestamp": "00:35:59,434", "timestamp_s": 2159.0}, {"text": "this, you learned something, or maybe you confirmed", "timestamp": "00:36:04,080", "timestamp_s": 2164.0}, {"text": "something that you already knew, and I\u0027d be happy to connect", "timestamp": "00:36:07,816", "timestamp_s": 2167.0}, {"text": "and explore more in depth given the time restraint", "timestamp": "00:36:11,944", "timestamp_s": 2171.0}, {"text": "that we have. And if you have any questions, or if you want to really", "timestamp": "00:36:15,592", "timestamp_s": 2175.0}, {"text": "go dive deep into any of these concepts, or why you", "timestamp": "00:36:18,752", "timestamp_s": 2178.0}, {"text": "should make a particular choice or what my previous experiences", "timestamp": "00:36:22,768", "timestamp_s": 2182.0}, {"text": "have been. You could connect with me on LinkedIn and we could discuss", "timestamp": "00:36:26,776", "timestamp_s": 2186.0}, {"text": "that as well. Again, thank you Khan 42 for giving", "timestamp": "00:36:30,780", "timestamp_s": 2190.0}, {"text": "me this platform explaining this. I\u0027ve learned a lot while", "timestamp": "00:36:34,060", "timestamp_s": 2194.0}, {"text": "researching over this particular topic from my previous experience and", "timestamp": "00:36:38,284", "timestamp_s": 2198.0}, {"text": "I hope you guys learned too.", "timestamp": "00:36:42,100", "timestamp_s": 2202.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'anmXNMEaNhg',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              You get an LLM, you get an LLM, everyone gets an LLM, but does it work?
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>While everyone wants to say those magical words AI, LLM, have you evaluated your models to see if they actually work for you and your use case, or are you just using whatever&rsquo;s the most trending model out there? In this talk, we will explore the language models and evaluate those choices.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Ashwin has been working in the field of machine learning, computer vision, and NLP for over three years. Today he will talk about large language models evaluations and how you can evaluate your model in a better way.

              </li>
              
              <li>
                Will the language model speak the truth? That's the question that everyone's been asking. The bigger question is whether the language models will be truthful in answering the questions that we ask them.

              </li>
              
              <li>
                These evaluations are important as a part of a measure of your overall large language model development workflow. Think about it as how we can effectively manage or leverage these language models. Understanding these models, measuring these models will ultimately lead to how you can improve these models.

              </li>
              
              <li>
                The ideal framework will offer you the metrics tailored to your different tasks. The other thing that we need to consider for a good evaluation framework is the metric list. The framework that we're going to use should be extensible, it should be maintainable.

              </li>
              
              <li>
                The human evaluation aspect really focuses on multiple geographies, multiple languages. The way people understand a particular response, a particular language, determines a proper metric or a proper score for your language model to be evaluated upon. There is obviously many challenges with human evaluation which has its own limitations.

              </li>
              
              <li>
                Automatic evaluators assess how well specific parts of speech or output match your expectations. They do struggle with creativity and overall quality judgment, but they are a lot better evaluator in terms of metrics. Which one to choose really depends on your particular use case.

              </li>
              
              <li>
                Using the public benchmarks that are already available. And the other way is using golden datasets. They will give you an understanding of the general capabilities of a model on different sorts of data sets. But they don't necessarily guarantee success.

              </li>
              
              <li>
                Moving ahead to the golden data sets, these data sets are tailored to your specific needs. These are instrumental in building the rag based workflows. And these will give you a really good idea on how your rag workflow should be.

              </li>
              
              <li>
                Your use case is probably well defined. You're looking for a model that performs really well in a particular sector. And the evaluation metrics when they're actually in progress or work with these models. Once these metrics are defined, you really know how a language model is working for your particular flow.

              </li>
              
              <li>
                How do we measure the effectiveness of a tailored large language model? We could first move to traditional metrics. Another metric that we should also be exploring is perplexity. It assesses the LLM's internal ability to predict the next word in a sequence.

              </li>
              
              <li>
                What about llms evaluating llms? There's been some good research on whether an LLM can actually evaluate other LLM. The other approach of this is definitely the metrics that you choose. Despite the rise of all of these automated metrics, I believe that we should be also looking at the human aspect of it.

              </li>
              
              <li>
                Public libraries or public frameworks like hugging face eval or lmewal harness is a really good start at first. By leveraging these right metrics, you can now unlock the potential of these models in for your specific use case. As this field grows, there's new, more new research into it.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/anmXNMEaNhg.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:20,840'); seek(20.0)">
              Hi everyone, and thanks for joining me today. I'm excited here to talk about
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:24,646'); seek(24.0)">
              large language models, especially large language models evaluations
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:28,652'); seek(28.0)">
              and how you can evaluate your model in a better way, or how you
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:31,948'); seek(31.0)">
              can use certain frameworks that are available to understand how
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:35,332'); seek(35.0)">
              a particular language model is performing for your specific use case.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,404'); seek(39.0)">
              For those of you who don't know me, I'm Ashwin. I've been working
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:42,996'); seek(42.0)">
              in the field of machine learning, computer vision, and NLP for over three years,
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:47,284'); seek(47.0)">
              and I've also worked in some other domains throughout my
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:50,652'); seek(50.0)">
              career. Today I would like to dive into into a
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:55,164'); seek(55.0)">
              specific aspect of course evaluations, but also
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:58,852'); seek(58.0)">
              why they're necessary and how we can get to
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:02,924'); seek(62.0)">
              that particular evaluation metric. So, to get started,
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:07,404'); seek(67.0)">
              let me just quickly move the screen. Yep. Okay.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:10,540'); seek(70.0)">
              Yeah. So, will the language model speak
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:14,380'); seek(74.0)">
              the truth? I guess that's the question that everyone's been asking.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:17,788'); seek(77.0)">
              Everyone's been really concerned about the whole evaluation flow,
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:21,804'); seek(81.0)">
              or if we can trust these language models into
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:25,484'); seek(85.0)">
              telling us something that it definitely knows versus making things
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:29,476'); seek(89.0)">
              up and telling us something that even we are not sure whether this
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:33,140'); seek(93.0)">
              is the truth or not. So the bigger question that we probably tend
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:36,412'); seek(96.0)">
              to answer today is whether the language model is
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:40,084'); seek(100.0)">
              going to be truthful in answering the questions that we ask them or,
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:43,644'); seek(103.0)">
              you know, getting summaries out of it. So,
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:47,074'); seek(107.0)">
              moving ahead, we are jumping into
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:50,786'); seek(110.0)">
              a particular aspect is why we need these evaluations
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:54,282'); seek(114.0)">
              and why these particular evaluations are necessary. The reason being
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:57,786'); seek(117.0)">
              that these evaluations are important
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:00,994'); seek(120.0)">
              as a part of a measure of your overall large language
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:04,874'); seek(124.0)">
              model development workflow. So think about it on how.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:08,754'); seek(128.0)">
              Think about it as how we can effectively manage or
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:12,826'); seek(132.0)">
              leverage these language models, while also making sure that
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:16,362'); seek(136.0)">
              we are not letting it lose completely and having a
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:20,122'); seek(140.0)">
              bad customer experience in general. So the
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:23,834'); seek(143.0)">
              three aspects that you need to take care of here is the management
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:27,626'); seek(147.0)">
              of these language models. Maybe you're using just a few APIs
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:31,474'); seek(151.0)">
              that are available online and getting the results and just publishing them
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:35,554'); seek(155.0)">
              to your users. Or maybe you're using, or maybe you're hosting
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:39,002'); seek(159.0)">
              your own models using frameworks like B LLM.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:42,824'); seek(162.0)">
              I guess there's one more called Lama CPP or something like
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:46,392'); seek(166.0)">
              that. So these frameworks also allow you to
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:49,760'); seek(169.0)">
              host your own models and also
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:53,576'); seek(173.0)">
              probably understand how you can improve
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:56,952'); seek(176.0)">
              the overall performance of these language models.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:00,008'); seek(180.0)">
              Understanding these models, measuring these models will ultimately lead
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:03,704'); seek(183.0)">
              to how you can improve these models, how you can understand on
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:07,908'); seek(187.0)">
              where these llms fall short, so that we can either refine
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:11,484'); seek(191.0)">
              our training data, we can start thinking about fine tuning these
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:15,644'); seek(195.0)">
              language models, maybe lower adapters or,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:19,164'); seek(199.0)">
              you know, just in general testing out different language models or different specifically
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:23,636'); seek(203.0)">
              publicly available, fine tuned language models.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:27,164'); seek(207.0)">
              Moving ahead, we are concerned
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:30,764'); seek(210.0)">
              about what kind of frameworks or what kind
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:34,188'); seek(214.0)">
              of measurement techniques,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:38,008'); seek(218.0)">
              or maybe let's just call them frameworks,
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:41,752'); seek(221.0)">
              would help us in doing a particular thing.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:45,944'); seek(225.0)">
              So we have three selection criteria, or let's
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:49,480'); seek(229.0)">
              say three evaluation criteria that we can think
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:52,976'); seek(232.0)">
              of, and we can jump right into that.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:56,184'); seek(236.0)">
              But let's seeing that we can have task
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:59,560'); seek(239.0)">
              specific scores that measure the right
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:03,182'); seek(243.0)">
              outcome of a particular language model. Imagine a
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:07,446'); seek(247.0)">
              toolbox where you have specifically designed metrics
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:11,790'); seek(251.0)">
              or specifically designed items that you use to assess
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:15,654'); seek(255.0)">
              llms. And while when you consider the
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:18,894'); seek(258.0)">
              toolbox, your tools would be these three things that we've
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:22,262'); seek(262.0)">
              mentioned are the task specific scores that we talked about
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:26,534'); seek(266.0)">
              here. I must say that a one size fits all approach
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:30,734'); seek(270.0)">
              usually doesn't work. So the ideal framework
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:35,134'); seek(275.0)">
              will offer you the metrics tailored to your different tasks.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:38,622'); seek(278.0)">
              To specific tasks, let's say question answering
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:41,998'); seek(281.0)">
              or summarization. It will help you,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:45,190'); seek(285.0)">
              or it will allow you to evaluate these models on these
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:49,206'); seek(289.0)">
              specific tasks. The other thing that we need to consider
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:52,590'); seek(292.0)">
              for a good evaluation framework is the metric list.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:56,964'); seek(296.0)">
              You know you have the toolbox, you know how you have the toolset.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:00,348'); seek(300.0)">
              But if you don't have a reliable set of metrics that have been
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:03,572'); seek(303.0)">
              proven before, there is no way in really understanding what
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:07,252'); seek(307.0)">
              a particular score or what a particular metric
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:11,412'); seek(311.0)">
              will mean if it is presented to you in an aggregate
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:14,780'); seek(314.0)">
              or a abstracted manner. So having a good list of
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:18,836'); seek(318.0)">
              available metrics that you can easily implement is really crucial when
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:22,252'); seek(322.0)">
              deciding what framework or what library or what general research you're
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:26,108'); seek(326.0)">
              going to follow to evaluate your language models. And the third part is
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:30,060'); seek(330.0)">
              basically, really,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:33,484'); seek(333.0)">
              we could discuss this broadly or narrowly, depending on what the
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:36,860'); seek(336.0)">
              context is. But the framework that we're going to use
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:40,308'); seek(340.0)">
              should be extensible, it should be maintainable,
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:43,972'); seek(343.0)">
              and of course it should provide you an ease of access to the
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:48,356'); seek(348.0)">
              underlying function or the underlying classes of it. The reason for this
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:52,410'); seek(352.0)">
              is because if the framework is adaptable to a particular task,
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:57,330'); seek(357.0)">
              that's public, but your task requires some specific understanding
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:01,362'); seek(361.0)">
              or specific knowledge, or a specific way of loading, maybe loading the model
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:05,402'); seek(365.0)">
              weights. Or maybe if you use a different tokenizer
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:09,562'); seek(369.0)">
              for tokenizing your particular request
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:13,306'); seek(373.0)">
              responses, then this becomes a really crucial
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:17,082'); seek(377.0)">
              aspect in determining whether a particular framework is going to be useful
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:20,914'); seek(380.0)">
              for you. So, for example, the LM eval,
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:24,300'); seek(384.0)">
              the LM evaluation harness framework, a really good framework,
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:27,996'); seek(387.0)">
              a really good design made to evaluate any
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:31,708'); seek(391.0)">
              model that you can think of, any supported support model
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:35,092'); seek(395.0)">
              that you can think of on public datasets. But while working
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:39,684'); seek(399.0)">
              on this particular framework, if you have a task that's
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:43,388'); seek(403.0)">
              specific to your needs, it's a really difficult,
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:48,214'); seek(408.0)">
              how do I say it's a really difficult way of implementing
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:51,886'); seek(411.0)">
              that in this particular library? It's not just about this particularly,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:55,390'); seek(415.0)">
              it's in general, any library that has come up for
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:59,550'); seek(419.0)">
              evaluations which does, which kind of abstract these
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:03,526'); seek(423.0)">
              evaluation metrics for us. So,
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:07,294'); seek(427.0)">
              moving ahead, by incorporating all these elements, we can
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:10,958'); seek(430.0)">
              create a robust, or we can decide
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:14,944'); seek(434.0)">
              on what robust evaluation framework we can use.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:17,992'); seek(437.0)">
              Now, let's dive deeper into the two main approaches
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:22,032'); seek(442.0)">
              for the LM evaluation and why they
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:25,736'); seek(445.0)">
              are necessary. As you can see in this particular diagram,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:29,704'); seek(449.0)">
              you can see that the part where the human evaluation is
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:33,272'); seek(453.0)">
              concerned, it ranks really higher, as opposed
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:36,952'); seek(456.0)">
              to user testing, fine tuning
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:40,848'); seek(460.0)">
              and maybe public data sets, public benchmarks,
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:44,820'); seek(464.0)">
              auto evaluation. And the reason really being for that
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:48,140'); seek(468.0)">
              is the human evaluation aspect really focuses
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:51,732'); seek(471.0)">
              on multiple geographies, multiple languages, and the
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:55,452'); seek(475.0)">
              way people understand a particular response,
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:59,092'); seek(479.0)">
              a particular language, and that really determines a
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:02,756'); seek(482.0)">
              proper metric or a proper score for your language model to be evaluated
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:06,636'); seek(486.0)">
              upon. Because as we know, there's multiple dialects
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:10,998'); seek(490.0)">
              for a particular language, there's multiple people talking or
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:14,830'); seek(494.0)">
              using different style of grammar, that is not a common
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:19,534'); seek(499.0)">
              way of speaking or understanding things in their own
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:22,726'); seek(502.0)">
              countries. And that could really mean a
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:26,030'); seek(506.0)">
              lot of difference. When you're evaluating a framework, let's say,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:29,550'); seek(509.0)">
              for someone in the US, versus if you're evaluating,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:33,238'); seek(513.0)">
              sorry, if you're evaluating model on a specific response
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:36,702'); seek(516.0)">
              for, let's say, for someone in the US, versus for someone who's
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:40,614'); seek(520.0)">
              not a native english speaker, for them, understanding the context,
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:44,990'); seek(524.0)">
              understanding what's going on around a particular
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:48,398'); seek(528.0)">
              response may or may not differ, and they
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:51,934'); seek(531.0)">
              may or may not think that this particular answer suits them well.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:55,254'); seek(535.0)">
              So having a human evaluation framework,
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:58,198'); seek(538.0)">
              that's drug geography, region specific, or, and of course,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:01,710'); seek(541.0)">
              application specific, is a really important aspect
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:05,054'); seek(545.0)">
              of evaluating these models. Now, once we've talked about human
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:09,134'); seek(549.0)">
              evaluators and why
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:12,318'); seek(552.0)">
              those are necessary, we should also consider that it is not
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:15,590'); seek(555.0)">
              always possible to collect all of this feedback. And it
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:19,078'); seek(559.0)">
              is not also always possible to have your customers decide or determine
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:23,974'); seek(563.0)">
              whether a particular answer was good or bad. The customers are,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:27,678'); seek(567.0)">
              the customers are really concerned about the value that
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:30,942'); seek(570.0)">
              your application or your use case is providing. So in
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:36,062'); seek(576.0)">
              general, we can think of these evaluation metrics.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:41,214'); seek(581.0)">
              So in general, these evaluation metrics you can
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:44,334'); seek(584.0)">
              understand from two different perspectives. One is of course,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:47,614'); seek(587.0)">
              the one we discussed, which is the human evaluator part, and one is
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:51,422'); seek(591.0)">
              the frameworks of the libraries that we'll be exploring in this talk,
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:55,342'); seek(595.0)">
              we can call them as auto evaluators or, you know,
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:58,638'); seek(598.0)">
              anything that's non human evaluator. And so
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:03,024'); seek(603.0)">
              previously or traditionally, the way these language models even came
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:06,584'); seek(606.0)">
              into being were based on a
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:09,848'); seek(609.0)">
              large number of data sets, a large number of text or
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:13,472'); seek(613.0)">
              material that was open, that was available publicly.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:17,112'); seek(617.0)">
              And so overall, while these
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:20,888'); seek(620.0)">
              companies are use cases that are trying to test these models,
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:24,704'); seek(624.0)">
              they've made human evaluators a kind of a standard,
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:28,408'); seek(628.0)">
              or how do I say, kind of a stop
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:32,776'); seek(632.0)">
              in the loop on giving users a complete access
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:36,384'); seek(636.0)">
              to the language model use case, versus maybe
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:41,704'); seek(641.0)">
              releasing it as an experiment, or maybe releasing it as a beta,
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:45,184'); seek(645.0)">
              so that when people interact with it and people understand
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:49,288'); seek(649.0)">
              what's going on, and sometimes you get oh no, this answer is totally
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:53,012'); seek(653.0)">
              false, and then people will just bash you for whatever you've
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:56,404'); seek(656.0)">
              done and just give you negative remarks that in turn helps
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:00,012'); seek(660.0)">
              you in better serving the model or
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:03,372'); seek(663.0)">
              better evaluating on what went wrong and where. So the
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:07,324'); seek(667.0)">
              strengths really here are that humans can provide a nuanced
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:11,268'); seek(671.0)">
              feedback, judging whether an outcome is simply right or wrong
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:15,324'); seek(675.0)">
              based on their understanding, but also considering factors
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:18,900'); seek(678.0)">
              like creativity, coherence, and relevance to the task.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:22,780'); seek(682.0)">
              Just as I mentioned before, the same thing that
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:27,204'); seek(687.0)">
              probably would be relevant or coherent or creative to a
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:31,476'); seek(691.0)">
              native english speaker wouldn't be the same as for a non native
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:35,068'); seek(695.0)">
              speaker, just because of how they understand the language.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:39,844'); seek(699.0)">
              There is obviously many challenges with human evaluation,
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:43,636'); seek(703.0)">
              which has its own limitations. The choices, as I said, can be
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:47,152'); seek(707.0)">
              subjective, based on location and defining success
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:50,688'); seek(710.0)">
              matrix, only based on what someone from a particular place
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:54,624'); seek(714.0)">
              said is obviously challenging and may raise
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:58,320'); seek(718.0)">
              questions on how this came out to be. So, to this,
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:03,704'); seek(723.0)">
              adding to the fact that human evaluation will also take
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:07,568'); seek(727.0)">
              time, it is an iterative process and it is also expensive
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:11,880'); seek(731.0)">
              because you will probably be putting this into the
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:16,440'); seek(736.0)">
              hands of your potential customers, who probably would get
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:19,952'); seek(739.0)">
              maybe frustrated, who stop using this app, and then you have to convince
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:23,848'); seek(743.0)">
              them to use it and give feedback and whatever all
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:27,200'); seek(747.0)">
              this, that entire flow costs time,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:30,752'); seek(750.0)">
              costs money, so we can move towards
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:34,152'); seek(754.0)">
              automatic evaluators. Now, when I say automatic evaluators,
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:38,040'); seek(758.0)">
              I don't necessarily mean that everything's happening by itself and
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:41,360'); seek(761.0)">
              you're just calling a simple function and everyone's happy,
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:44,744'); seek(764.0)">
              and all the language models have achieved nirvana or greatness.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:48,400'); seek(768.0)">
              And whenever I say automatic evaluators, it really means that
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:51,912'); seek(771.0)">
              the toolbox that we set up with the three different criteria,
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:55,432'); seek(775.0)">
              that toolbox allows you to evaluate
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:59,152'); seek(779.0)">
              a particular large language model on its own while
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:03,776'); seek(783.0)">
              you're iterating over the use cases and the strengths.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:07,424'); seek(787.0)">
              Basically, here are their fast, they're efficient,
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:10,398'); seek(790.0)">
              and they're objective. They assess how well specific parts
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:14,110'); seek(794.0)">
              of speech or output match your expectations based on the
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:17,990'); seek(797.0)">
              data sets that you have. And choices are based usually
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:21,446'); seek(801.0)">
              on known outcomes and well defined metrics. Now,
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:25,294'); seek(805.0)">
              how do these known outcomes come come into picture? It's the
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:28,782'); seek(808.0)">
              people who are actually serving these models determining what a
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:32,566'); seek(812.0)">
              particular output for a particular, let's say,
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:36,086'); seek(816.0)">
              question or a summary should be, so that whenever you
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:40,596'); seek(820.0)">
              are close to it, like for example, root scores,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:44,348'); seek(824.0)">
              whenever you're really close to it, you think that this is probably a better understand
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:48,500'); seek(828.0)">
              the better understood answer rather than something that's completely
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:52,236'); seek(832.0)">
              made up. However, we can also cannot
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:55,764'); seek(835.0)">
              discount the limitations that they possess.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:58,756'); seek(838.0)">
              They can't replicate what we talked about before,
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:02,364'); seek(842.0)">
              which was a great thing about human evaluator, as well
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:05,860'); seek(845.0)">
              as its limitation, is that the ability to
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:09,610'); seek(849.0)">
              understand the context and nuance of this in a
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:14,154'); seek(854.0)">
              overall sense of what a
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:17,642'); seek(857.0)">
              particular response should be, or what particular answer,
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:22,874'); seek(862.0)">
              or what particular future question can come
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:26,490'); seek(866.0)">
              over based on that particular answer. So,
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:29,498'); seek(869.0)">
              automatic evaluators, they do struggle with creativity and overall quality judgment,
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:34,122'); seek(874.0)">
              but they are a lot better evaluator in terms of metrics and
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:37,860'); seek(877.0)">
              in terms of, let's say, as I said,
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:41,428'); seek(881.0)">
              Google scores, n gram matching. So they somehow
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:45,684'); seek(885.0)">
              work well together. But the real, the golden
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:49,332'); seek(889.0)">
              chance, or the golden opportunity here is
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:52,892'); seek(892.0)">
              to mix these two human evaluators as well
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:56,036'); seek(896.0)">
              as the auto evaluators in having your entire flow
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:59,940'); seek(899.0)">
              is such a way that you leverage the best of
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:04,000'); seek(904.0)">
              these two and you also overcome the bad,
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:08,392'); seek(908.0)">
              I would not say bad parts, but the less best parts,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:12,472'); seek(912.0)">
              I guess, from each of those.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:15,848'); seek(915.0)">
              So I would the takeaway from overall, this is
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:19,168'); seek(919.0)">
              a collaborative option is probably better, and which
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:23,496'); seek(923.0)">
              one to choose really depends on your particular use case.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:27,424'); seek(927.0)">
              And the ideal approach most likely often
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:30,880'); seek(930.0)">
              involves a combination where humans provide valuable
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:35,752'); seek(935.0)">
              feedback on whether this was right or wrong. And the auto evaluators
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:39,664'); seek(939.0)">
              often consistency in checking whether the answer
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:43,536'); seek(943.0)">
              that you're getting for the, let's say, for the same question
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:47,200'); seek(947.0)">
              or for requesting the same summary is always
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:51,424'); seek(951.0)">
              going to be somewhat similar.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:55,434'); seek(955.0)">
              Let shift gears to what we are talking about when we were talking
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:58,954'); seek(958.0)">
              about whole evaluators, and let shift gears
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:02,722'); seek(962.0)">
              on understanding how do these two evaluators function,
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:07,642'); seek(967.0)">
              or how do these two evaluators work with different sorts
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:11,762'); seek(971.0)">
              of data sets. So we have two kind of
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:16,514'); seek(976.0)">
              data set divergence or data set paths here.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:19,754'); seek(979.0)">
              One is using the public benchmarks that are already available. You don't have
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:23,380'); seek(983.0)">
              to do much, you just trust these benchmarks that are
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:26,468'); seek(986.0)">
              available probably on these public leaderboards,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:31,604'); seek(991.0)">
              maybe hugging face or individual competitions.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:37,204'); seek(997.0)">
              And the other way is using golden datasets.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:40,796'); seek(1000.0)">
              Now, whenever I say golden datasets, it doesn't
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:44,044'); seek(1004.0)">
              mean that this is literally the gold standard. It just means
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:47,676'); seek(1007.0)">
              that these are datasets or these are the values
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:52,212'); seek(1012.0)">
              that you control and these are the values that are
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:56,444'); seek(1016.0)">
              definitely, or I should say almost 90%
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:01,764'); seek(1021.0)">
              true to be really effective in giving you an answer.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:05,332'); seek(1025.0)">
              So public benchmarks, these are predefined data sets. You can
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:08,660'); seek(1028.0)">
              easily get that from hugging face. And they are more.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:13,024'); seek(1033.0)">
              The more the research that was put into creating these data
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:16,624'); seek(1036.0)">
              sets, understanding or training a particular model to test on these data
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:20,504'); seek(1040.0)">
              sets, the more fair assessment these public benchmarks
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:24,368'); seek(1044.0)">
              will give you. And they will give you an understanding of the
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:27,864'); seek(1047.0)">
              general capabilities of a model on different sorts of
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:31,360'); seek(1051.0)">
              data sets, like how well a model is,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:35,624'); seek(1055.0)">
              how well a model performs with, let's say, something as
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:39,744'); seek(1059.0)">
              something called, as maybe abstractive summarization,
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:42,696'); seek(1062.0)">
              summarization, question answering, or even giving you
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:46,152'); seek(1066.0)">
              answers to a particular code, debugging or explaining maybe
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:51,224'); seek(1071.0)">
              programming concepts or scientific concepts, or, you know,
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:55,224'); seek(1075.0)">
              any concepts in general. However, these public
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:59,224'); seek(1079.0)">
              benchmarks, given the broad scope of what
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:02,640'); seek(1082.0)">
              kind of data sets they usually have and the formats of these,
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:06,794'); seek(1086.0)">
              they don't necessarily guarantee success, or they don't necessarily
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:10,626'); seek(1090.0)">
              guarantee a yes or no answer whenever you're
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:14,586'); seek(1094.0)">
              looking at a particular model and making a decision whether you should use that model
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:18,562'); seek(1098.0)">
              or not, because your use case is really
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:22,090'); seek(1102.0)">
              a specific use case that's coming out of the model, rather than people
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:26,306'); seek(1106.0)">
              asking travel tips or money saving tips,
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:29,986'); seek(1109.0)">
              which is what we usually see. The most popular use cases
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:34,220'); seek(1114.0)">
              of these language models are so the takeaway on public benchmarks.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:37,844'); seek(1117.0)">
              They do offer valuable starting point, as in,
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:41,084'); seek(1121.0)">
              they do offer something to give you a edge over,
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:45,564'); seek(1125.0)">
              but they shouldn't be the sole measure of what you're trying
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:48,884'); seek(1128.0)">
              to achieve and are trying to test based on the LLM's effectiveness.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:53,508'); seek(1133.0)">
              Moving ahead to the golden data sets, these data sets,
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:56,900'); seek(1136.0)">
              as I already said, are tailored to your specific needs.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:00,298'); seek(1140.0)">
              You control what output you expect, you control
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:04,098'); seek(1144.0)">
              what prompt, or let's say, what metrics or
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:07,978'); seek(1147.0)">
              how to put it in a better way. You control what the exact
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:11,810'); seek(1151.0)">
              result from the large language model that you're expecting
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:15,634'); seek(1155.0)">
              is. Of course, you do not control what the large language model obviously
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:19,474'); seek(1159.0)">
              gives you to a certain extent. But what you know is
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:22,842'); seek(1162.0)">
              that if I refer this to particular,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:27,174'); seek(1167.0)">
              let's say, a particular sentence, I know, the more this sentence
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:31,230'); seek(1171.0)">
              matches with what the LLM has given me. It's more
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:35,190'); seek(1175.0)">
              accurate, or I would assume that it's more accurate and performs well
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:38,790'); seek(1178.0)">
              on the task that I have made it to.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:41,694'); seek(1181.0)">
              So these, let's say golden data
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:45,054'); seek(1185.0)">
              sets are used will allow you to evaluate how well an LLM
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:49,262'); seek(1189.0)">
              performs of the tasks that matter most to you, rather than being
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:53,066'); seek(1193.0)">
              a generic data set of maybe
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:56,418'); seek(1196.0)">
              Reddit comments on maybe people just posting this, this,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:59,802'); seek(1199.0)">
              this in a chain that doesn't make sense to you anymore.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:03,394'); seek(1203.0)">
              But obviously this is a part of the
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:07,130'); seek(1207.0)">
              whole training data set if they weren't clean before.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:11,034'); seek(1211.0)">
              So some examples of golden data
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:14,354'); seek(1214.0)">
              sets would be for a, let's say for
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:17,842'); seek(1217.0)">
              a use case, like checking semantic similarity of the
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:21,864'); seek(1221.0)">
              content that was given out, or measuring perplexity,
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:25,056'); seek(1225.0)">
              or as I said, root scores in summarization
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:28,472'); seek(1228.0)">
              tasks so that you could understand how well a summary was generated,
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:32,104'); seek(1232.0)">
              how short or how long that summary even was. And these are instrumental
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:36,072'); seek(1236.0)">
              in building the rag based workflows,
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:39,880'); seek(1239.0)">
              which is the retrieval augmented generation based workflows.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:43,320'); seek(1243.0)">
              And these will give you a really good idea on how your rag
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:47,400'); seek(1247.0)">
              workflow should be, which is what
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:50,998'); seek(1250.0)">
              we are evaluating or what we are
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:54,158'); seek(1254.0)">
              understanding to evaluate here. So the most effective approach,
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:57,654'); seek(1257.0)">
              again, leverage the as we discussed before,
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:01,190'); seek(1261.0)">
              leverage the public.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:05,654'); seek(1265.0)">
              Leverage the public information, as well as leverage the
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:09,230'); seek(1269.0)">
              data sets that you prepare because they both provide you a
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:12,422'); seek(1272.0)">
              certain benchmark that you can then evaluate and iterate
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:16,026'); seek(1276.0)">
              over. Moving ahead. Now that we understand
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:20,354'); seek(1280.0)">
              what these evaluation methods resources are, what usually
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:23,922'); seek(1283.0)">
              works, let's talk about applying this knowledge to the specific
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:27,610'); seek(1287.0)">
              needs. As I said before, your use case is probably
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:31,474'); seek(1291.0)">
              well defined. You're looking for a model that performs really well
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:35,218'); seek(1295.0)">
              in a particular sector rather than a general model for.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:38,794'); seek(1298.0)">
              Let's assume this Chevrolet case where someone
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:43,554'); seek(1303.0)">
              tried to ask the language model and try to get a brand
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:47,106'); seek(1307.0)">
              new Chevrolet Tahoe for like $1.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:50,394'); seek(1310.0)">
              Let's assume that you are in the scientific research community and your
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:53,962'); seek(1313.0)">
              model is really open to answering
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:57,194'); seek(1317.0)">
              any and all sorts of questions that's not really
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:01,274'); seek(1321.0)">
              good for you, that's not really conducive for you. And the
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:05,122'); seek(1325.0)">
              evaluation metrics when they're actually in progress
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:08,820'); seek(1328.0)">
              or work with these models. These will tell you how close people
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:12,316'); seek(1332.0)">
              are talking about the use case,
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:15,668'); seek(1335.0)">
              how close the topics are, and whether they really make
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:18,836'); seek(1338.0)">
              sense, or whether the user feedback makes sense.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:22,308'); seek(1342.0)">
              So in general, you could consider
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:25,812'); seek(1345.0)">
              this as do you need a particular use case to answer questions?
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:30,076'); seek(1350.0)">
              Do you need to answer summaries? Or do you need particular
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:33,682'); seek(1353.0)">
              use case to provide you citations,
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:36,322'); seek(1356.0)">
              references, or just be a general language model
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:40,058'); seek(1360.0)">
              that really answers the question without any external source
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:43,890'); seek(1363.0)">
              and answers questions from its knowledge database.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:47,466'); seek(1367.0)">
              So the content that goes in and the content that
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:50,802'); seek(1370.0)">
              comes basically, whatever the content that goes in and
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:54,650'); seek(1374.0)">
              whatever the content that LLM interacts with, is it supporting
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:58,898'); seek(1378.0)">
              a document library, a vector database,
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:02,010'); seek(1382.0)">
              or just a vast collection of text data? That's how
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:07,714'); seek(1387.0)">
              your use case will determine what the output,
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:11,010'); seek(1391.0)">
              or how well defined your output should
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:14,906'); seek(1394.0)">
              be. And eventually, once this is defined,
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:18,450'); seek(1398.0)">
              you could really understand on how the model is performing.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:21,922'); seek(1401.0)">
              You could maybe involve some fine tuning for it.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:25,058'); seek(1405.0)">
              You could go on topic modeling and maybe restrict the model on
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:28,810'); seek(1408.0)">
              answering, or even,
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:32,424'); seek(1412.0)">
              or even getting the model to answer particular questions based on
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:35,720'); seek(1415.0)">
              what your use case is. And it's also crucial to establish
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:39,056'); seek(1419.0)">
              certain guardrails, certain input validation,
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:43,272'); seek(1423.0)">
              certain output validation, so that you're not drifting into something that
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:47,704'); seek(1427.0)">
              you shouldn't be doing or you shouldn't be talking about. Of course,
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:51,008'); seek(1431.0)">
              prompt engineering or in general,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:54,016'); seek(1434.0)">
              defining the prompt is also somewhat an
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:57,574'); seek(1437.0)">
              aspect of this particular flow. But once these metrics that
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:01,830'); seek(1441.0)">
              we'll discuss now are defined, you really know
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:05,286'); seek(1445.0)">
              how a particular language model is working for your
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:09,158'); seek(1449.0)">
              particular flow. Moving ahead, let's dive
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:12,574'); seek(1452.0)">
              into the nitty gritty, or, you know, the specifics of
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:16,222'); seek(1456.0)">
              what we were talking about. How do we measure the effectiveness of a tailored
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:20,694'); seek(1460.0)">
              large language model? We could first move
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:24,260'); seek(1464.0)">
              to traditional metrics, the most familiar
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:28,084'); seek(1468.0)">
              how these tools are. These tools are effective
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:32,964'); seek(1472.0)">
              kind of outputs we outputs we get
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:37,604'); seek(1477.0)">
              from flavors of rules of rule scores.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:42,564'); seek(1482.0)">
              More language
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:47,844'); seek(1487.0)">
              language processing language processing approach.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:54,744'); seek(1494.0)">
              How well the LLM in n gram matches,
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:58,832'); seek(1498.0)">
              or in other use cases where
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:02,384'); seek(1502.0)">
              you check other scores, will help
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:06,024'); seek(1506.0)">
              you understand on how better to how
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:09,816'); seek(1509.0)">
              better your model is performing. Also, there's another particular
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:13,648'); seek(1513.0)">
              metric that we should also be exploring is perplexity.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:18,002'); seek(1518.0)">
              It's a metric that takes a slightly different approach.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:21,674'); seek(1521.0)">
              Rather than having a well
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:24,978'); seek(1524.0)">
              put dataset together, having a well put timeline together.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:28,842'); seek(1528.0)">
              It assesses the LLM's internal ability to predict the next word
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:32,970'); seek(1532.0)">
              in a sequence. So it will tell you how confident a particular
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:36,914'); seek(1536.0)">
              LLM was in predicting the next word, and a lower the score.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:41,804'); seek(1541.0)">
              Lower the overall score. It indicates that the LLM is more
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:45,324'); seek(1545.0)">
              confident in its predictions and is less likely to generate
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:49,444'); seek(1549.0)">
              surprising results, or even completely non
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:53,028'); seek(1553.0)">
              essential results. So while these traditional metrics are available,
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:56,972'); seek(1556.0)">
              things like regas
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:00,252'); seek(1560.0)">
              or ragas, I should say, I don't know how it's
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:04,484'); seek(1564.0)">
              actually pronounced, but things like ragas or regas, they are really
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:08,420'); seek(1568.0)">
              good workflows to to treat your retrieval augmented
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:12,786'); seek(1572.0)">
              generation pipelines. And the metrics like faithfulness
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:16,466'); seek(1576.0)">
              or relevance or other aspects of
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:19,850'); seek(1579.0)">
              this particular framework will allow you to understand more better on how
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:24,338'); seek(1584.0)">
              your whole rag pipeline is working.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:27,562'); seek(1587.0)">
              And also another good framework
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:31,346'); seek(1591.0)">
              is the QA Ul by Daniel. It also provides
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:35,274'); seek(1595.0)">
              good insights and it checks whether a particular LLM
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:39,190'); seek(1599.0)">
              captures the key concepts or the key information that
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:42,782'); seek(1602.0)">
              was asked of it. So these are some of the I
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:47,678'); seek(1607.0)">
              guess the next step on this, now that we have
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:51,638'); seek(1611.0)">
              established a benchmark is what about llms evaluating
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:56,006'); seek(1616.0)">
              llms? There's been some good research,
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:59,054'); seek(1619.0)">
              some good findings based on whether an LLM can
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:02,830'); seek(1622.0)">
              actually evaluate other LLM.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:05,922'); seek(1625.0)">
              And this is most likely a trial
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:11,594'); seek(1631.0)">
              and error approach on making sure to be understand the
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:15,770'); seek(1635.0)">
              use case and something like chatbot arena,
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:18,954'); seek(1638.0)">
              which basically you could use the outputs generated from
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:22,906'); seek(1642.0)">
              that from two different models and evaluate and see
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:26,170'); seek(1646.0)">
              whether these two different models could compete with each other in generating
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:30,146'); seek(1650.0)">
              the text. If you ask one model, hey, is this factually correct
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:34,118'); seek(1654.0)">
              based on this answer, and you could iterate
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:37,614'); seek(1657.0)">
              on that, I wouldn't put
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:41,278'); seek(1661.0)">
              much stress on how efficient
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:44,854'); seek(1664.0)">
              or how correct these metrics
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:49,006'); seek(1669.0)">
              are, these judgment would be, but considering
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:52,774'); seek(1672.0)">
              that most models were trained on somewhat similar data
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:57,206'); seek(1677.0)">
              sets, you should expect that the results would be more subjective
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:01,680'); seek(1681.0)">
              and will give you a good insight on how a model
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:05,024'); seek(1685.0)">
              would perform against some other model. The other
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:08,784'); seek(1688.0)">
              approach of this is definitely the metrics that
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:12,600'); seek(1692.0)">
              we discussed. So the metrics that you
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:16,432'); seek(1696.0)">
              choose, your own metrics, you compare those metrics, you have a
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:19,992'); seek(1699.0)">
              definite set of iterative metrics that you've had so far.
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:23,280'); seek(1703.0)">
              You have a data set that you can test on for, and you can
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:26,692'); seek(1706.0)">
              really put that into a number or an understanding
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:30,844'); seek(1710.0)">
              in a perspective that even your customers,
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:34,244'); seek(1714.0)">
              people in your management, or people you're working
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:37,612'); seek(1717.0)">
              with, or even the scientists that you're working with, really have
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:41,980'); seek(1721.0)">
              a good benchmark on where they are right now
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:45,388'); seek(1725.0)">
              and where they are looking to be.
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:48,724'); seek(1728.0)">
              So the human touch, the ultimate judge, what human evaluation
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:53,614'); seek(1733.0)">
              does, what a multifaceted approach will
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:57,446'); seek(1737.0)">
              give you. And despite the rise of all of these automated
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:01,654'); seek(1741.0)">
              metrics, I believe that we
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:05,662'); seek(1745.0)">
              should be also looking at the human aspect of it and be
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:09,494'); seek(1749.0)">
              really sure that we are closing the gap between what we
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:12,998'); seek(1752.0)">
              are evaluating versus what is necessary.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:16,446'); seek(1756.0)">
              So that instead of chasing the next
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:20,194'); seek(1760.0)">
              cool model or the next best model, the next
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:23,874'); seek(1763.0)">
              public best model available, we really make an informed
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:27,674'); seek(1767.0)">
              decision on whether we are falling behind just because
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:32,002'); seek(1772.0)">
              there was a new model launch, or whether we are falling behind because
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:36,058'); seek(1776.0)">
              the data set that we fine tuned on isn't that good.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:39,402'); seek(1779.0)">
              Or maybe we need more of that data set, or maybe we
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:43,098'); seek(1783.0)">
              are good with whatever the metrics that we have so slowly
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:47,200'); seek(1787.0)">
              iterating over that we'll get good at the game and we'll
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:51,400'); seek(1791.0)">
              be able to clearly determine what is essentially required.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:55,824'); seek(1795.0)">
              Moving ahead. These are some available frameworks,
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:59,680'); seek(1799.0)">
              Regas helm, which is a really good benchmark.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:03,104'); seek(1803.0)">
              Again, these benchmarks will tell you how a
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:07,112'); seek(1807.0)">
              particular model was working on a particular large
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:11,512'); seek(1811.0)">
              corpus of data sets. There's also langsmith by Lang chain,
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:15,762'); seek(1815.0)">
              with and without the integration for the weights
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:19,298'); seek(1819.0)">
              and biases for you to eval. There's OpenAI evals
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:23,554'); seek(1823.0)">
              that gives you a good idea on what evaluation frameworks
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:28,162'); seek(1828.0)">
              or what other evaluation metrics are available. There's deep eval,
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:31,922'); seek(1831.0)">
              there's this LM evaluation harness that I've really grown
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:35,898'); seek(1835.0)">
              kind of fond of. They do a really good job at
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:40,554'); seek(1840.0)">
              allowing you to evaluate a particular model on a
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:44,098'); seek(1844.0)">
              particular public dataset with really less overhead.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:47,970'); seek(1847.0)">
              But as I said, there's some
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:52,026'); seek(1852.0)">
              overhead to making it work for your own custom use case.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:56,234'); seek(1856.0)">
              And that's where I found that using simply basic
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:01,042'); seek(1861.0)">
              hugging face functions to load your data set to calculate
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:31:04,938'); seek(1864.0)">
              scores is probably what is beats,
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:09,620'); seek(1869.0)">
              or is more easier to use or is more efficient to use.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:13,468'); seek(1873.0)">
              So that's the frameworks that are available that
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:17,724'); seek(1877.0)">
              we can try and test. And at the end, all you
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:21,284'); seek(1881.0)">
              need is a test eval set,
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:26,164'); seek(1886.0)">
              a multifaceted approach on how
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:29,820'); seek(1889.0)">
              you can use the existing test eval
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:33,370'); seek(1893.0)">
              set, or whatever the existing data set you have, or you
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:37,194'); seek(1897.0)">
              will create, and into understanding really
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:40,818'); seek(1900.0)">
              how you can develop a particular set of metrics
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:44,554'); seek(1904.0)">
              around it. And you can use those. So the foundation is
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:47,890'); seek(1907.0)">
              going to be your test set or evaluation set, and the
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:51,090'); seek(1911.0)">
              properties, some which are internal to the model or which
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:54,338'); seek(1914.0)">
              are internal to the framework that you're using, like perplexity, which can be
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:57,918'); seek(1917.0)">
              called calculated from the outputs that you get, or any
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:01,646'); seek(1921.0)">
              existing implementations for any
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:32:05,078'); seek(1925.0)">
              particular public task, or any particular specific task that you're trying to
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:08,630'); seek(1928.0)">
              look. And the benefits of this
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:11,926'); seek(1931.0)">
              would be that you really control what sort of metrics
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:15,590'); seek(1935.0)">
              are used in particular evaluation, what sort of metrics
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:19,550'); seek(1939.0)">
              you can quantify your application against.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:23,750'); seek(1943.0)">
              And you can also have an established set
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:26,962'); seek(1946.0)">
              of data sets that can help you over the long term in understanding
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:30,954'); seek(1950.0)">
              how the model performed over a certain duration or
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:34,538'); seek(1954.0)">
              a certain time, and what you can do more better after.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:38,514'); seek(1958.0)">
              Let's say you fine tuned the model multiple times,
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:41,618'); seek(1961.0)">
              you've changed the model, so it gives you a good flow of all of
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:45,458'); seek(1965.0)">
              the metrics that you can make the decisions
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:48,722'); seek(1968.0)">
              on. I guess that's probably
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:52,726'); seek(1972.0)">
              it. That's what I want to discuss. And I
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:57,430'); seek(1977.0)">
              would in general say that adapting public libraries or
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:33:00,622'); seek(1980.0)">
              public frameworks like hugging face eval or lmewal
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:33:04,486'); seek(1984.0)">
              harness is a really good start at first to get
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:08,230'); seek(1988.0)">
              any metrics like f one aggregated scores,
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:12,854'); seek(1992.0)">
              blue scores or root scores, blue scores or root
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:17,054'); seek(1997.0)">
              scores, or all of these scores, to decide
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:20,848'); seek(2000.0)">
              or define a particular evaluation framework for
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:24,400'); seek(2004.0)">
              a RNG based flow. And these will work seamlessly
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:27,856'); seek(2007.0)">
              with your chosen data sets. Also, of course,
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:31,176'); seek(2011.0)">
              including human evaluation, human flow into
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:34,560'); seek(2014.0)">
              the application and comparing really on
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:38,048'); seek(2018.0)">
              what human evaluation results are with
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:41,504'); seek(2021.0)">
              what you're getting, as opposed to a certain particular
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:45,224'); seek(2025.0)">
              benchmark, will be a overall
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:48,852'); seek(2028.0)">
              good strategy to evaluate large language models
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:52,324'); seek(2032.0)">
              on. In conclusion, we've really,
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:55,700'); seek(2035.0)">
              in a really abstract manner, explored how
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:59,300'); seek(2039.0)">
              you can evaluate why a particular evaluation type
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:03,308'); seek(2043.0)">
              is necessary. And it's, and at the end, it is not just
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:07,188'); seek(2047.0)">
              about whether you get a score out of it
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:10,580'); seek(2050.0)">
              or not. It's not about establishing a particular metric and,
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:14,116'); seek(2054.0)">
              you know, charting out six
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:17,304'); seek(2057.0)">
              months of metric data and just
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:21,224'); seek(2061.0)">
              saying that, hey, this is the model that works for me. It's about
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:24,672'); seek(2064.0)">
              establishing a foundation so that whenever you're developing
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:28,952'); seek(2068.0)">
              iteratively, whenever you're mark, you're managing
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:33,440'); seek(2073.0)">
              these large language models so that you can continuously
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:37,288'); seek(2077.0)">
              improve on the remarkable research that
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:40,920'); seek(2080.0)">
              has already done into putting these large language models out public with
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:45,131'); seek(2085.0)">
              their weights. And by leveraging these right metrics,
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:48,659'); seek(2088.0)">
              you can now unlock the potential of these models
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:52,019'); seek(2092.0)">
              in for your specific use case and determine
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:55,715'); seek(2095.0)">
              whether a particular model works for you, or if it doesn't
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:59,475'); seek(2099.0)">
              work for you, why does it not work for you?
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:02,699'); seek(2102.0)">
              And in general, understanding or delivering
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:06,707'); seek(2106.0)">
              real world benefits to the user. And as this field
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:11,374'); seek(2111.0)">
              grows, there's new, more new research into
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:14,574'); seek(2114.0)">
              it. We'd probably move ahead, or we've probably already moved
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:18,790'); seek(2118.0)">
              ahead beyond these basic scores and we've gone into more
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:22,582'); seek(2122.0)">
              a complex understanding of context,
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:26,254'); seek(2126.0)">
              whether the particular model understands a particular context grammar
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:30,094'); seek(2130.0)">
              and all of these ideas. And it
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:34,326'); seek(2134.0)">
              is going to be really exciting on what more,
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:37,674'); seek(2137.0)">
              what more metrics or frameworks that come up so
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:41,370'); seek(2141.0)">
              that we could evaluate a large language model better.
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:45,394'); seek(2145.0)">
              So yeah, that's it from me, and I
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:48,642'); seek(2148.0)">
              hope you got a really good starting point. This was meant
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:51,850'); seek(2151.0)">
              to be a good, this was meant to be just an introduction on
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:55,618'); seek(2155.0)">
              what kind of frameworks are available and what you can do with those and which
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:59,434'); seek(2159.0)">
              approaches work really well. So I hope you enjoyed
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:04,080'); seek(2164.0)">
              this, you learned something, or maybe you confirmed
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:07,816'); seek(2167.0)">
              something that you already knew, and I'd be happy to connect
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:11,944'); seek(2171.0)">
              and explore more in depth given the time restraint
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:15,592'); seek(2175.0)">
              that we have. And if you have any questions, or if you want to really
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:18,752'); seek(2178.0)">
              go dive deep into any of these concepts, or why you
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:22,768'); seek(2182.0)">
              should make a particular choice or what my previous experiences
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:26,776'); seek(2186.0)">
              have been. You could connect with me on LinkedIn and we could discuss
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:30,780'); seek(2190.0)">
              that as well. Again, thank you Khan 42 for giving
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:34,060'); seek(2194.0)">
              me this platform explaining this. I've learned a lot while
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:38,284'); seek(2198.0)">
              researching over this particular topic from my previous experience and
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:42,100'); seek(2202.0)">
              I hope you guys learned too.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Ashwin%20Phadke%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Ashwin%20Phadke%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Ashwin%20Phadke_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Ashwin Phadke
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Machine Learning Engineer @ Servient
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/ashwin-phadke1041995/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Ashwin Phadke's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@ashwinphadke1" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Ashwin Phadke's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @ashwinphadke1"
                  data-url="https://www.conf42.com/llms2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Large Language Models"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>