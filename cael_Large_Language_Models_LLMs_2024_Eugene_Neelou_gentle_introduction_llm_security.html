<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Gentle Introduction to LLM Security</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Eugene%20Neelou_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Gentle Introduction to LLM Security | Conf42"/>
    <meta property="og:description" content="Large language models (LLMs) present new opportunities for software while also introducing new AI safety and security risks. AI security expert explains how LLMs expand the attack surface and open doors for malicious actors."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2024_Eugene_Neelou_gentle_introduction_llm_security"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2024-04-11T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-11T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "4-6vspDuyMI"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "TQwxk0c4sh0"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBjR6ZR0g0LRq9Fp8c_4HrI" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello and welcome. Today we will explore the fascinating", "timestamp": "00:00:21,160", "timestamp_s": 21.0}, {"text": "world of security risks in large language models.", "timestamp": "00:00:25,822", "timestamp_s": 25.0}, {"text": "Llms have introduced AI technologies to millions", "timestamp": "00:00:30,084", "timestamp_s": 30.0}, {"text": "of people for both professional and personal usage.", "timestamp": "00:00:33,668", "timestamp_s": 33.0}, {"text": "However, with great power comes great responsibility,", "timestamp": "00:00:37,324", "timestamp_s": 37.0}, {"text": "so llms should be safe and secure. In this", "timestamp": "00:00:41,084", "timestamp_s": 41.0}, {"text": "presentation, we will review the most important security", "timestamp": "00:00:45,004", "timestamp_s": 45.0}, {"text": "risks for large language models. My name is", "timestamp": "00:00:48,892", "timestamp_s": 48.0}, {"text": "Eugene, and I have been working in cybersecurity", "timestamp": "00:00:52,548", "timestamp_s": 52.0}, {"text": "since 2008 and NGA safety since 2018.", "timestamp": "00:00:56,044", "timestamp_s": 56.0}, {"text": "These days, I focus on commercializing research", "timestamp": "00:01:01,674", "timestamp_s": 61.0}, {"text": "and transforming it into enterprise products,", "timestamp": "00:01:05,282", "timestamp_s": 65.0}, {"text": "and during my journey I have made some industry", "timestamp": "00:01:08,834", "timestamp_s": 68.0}, {"text": "contributions, including creating the MLsocos", "timestamp": "00:01:12,530", "timestamp_s": 72.0}, {"text": "framework for integrating security into Amlops,", "timestamp": "00:01:16,546", "timestamp_s": 76.0}, {"text": "founding the first startup in adversarial machine", "timestamp": "00:01:20,834", "timestamp_s": 80.0}, {"text": "learning, and lately co authoring the", "timestamp": "00:01:24,938", "timestamp_s": 84.0}, {"text": "Wasp top ten for LLM security.", "timestamp": "00:01:28,194", "timestamp_s": 88.0}, {"text": "This presentation is based on my work as an AI security expert", "timestamp": "00:01:31,924", "timestamp_s": 91.0}, {"text": "and a core team member of the LLM security team at OWASP.", "timestamp": "00:01:36,260", "timestamp_s": 96.0}, {"text": "So today my goal is to give you a very quick", "timestamp": "00:01:41,284", "timestamp_s": 101.0}, {"text": "and gentle introduction to LLM security.", "timestamp": "00:01:45,212", "timestamp_s": 105.0}, {"text": "So for more advanced content, I recommend", "timestamp": "00:01:49,324", "timestamp_s": 109.0}, {"text": "referring to the original work. The references", "timestamp": "00:01:53,092", "timestamp_s": 113.0}, {"text": "will be provided at the end of this presentation.", "timestamp": "00:01:57,004", "timestamp_s": 117.0}, {"text": "And now let\u0027s start exploring the most critical", "timestamp": "00:01:59,996", "timestamp_s": 119.0}, {"text": "security risks for LLM applications.", "timestamp": "00:02:03,970", "timestamp_s": 123.0}, {"text": "You have likely heard concerns about llms being", "timestamp": "00:02:08,114", "timestamp_s": 128.0}, {"text": "misused for illicit activities such as", "timestamp": "00:02:12,186", "timestamp_s": 132.0}, {"text": "making bombs, creating drugs, or even grooming children.", "timestamp": "00:02:16,202", "timestamp_s": 136.0}, {"text": "Llms from well known AI companies were", "timestamp": "00:02:21,114", "timestamp_s": 141.0}, {"text": "not intended for such tasks.", "timestamp": "00:02:24,770", "timestamp_s": 144.0}, {"text": "Developers of LLM based chat applications", "timestamp": "00:02:27,804", "timestamp_s": 147.0}, {"text": "implement safety measures and content filters,", "timestamp": "00:02:32,500", "timestamp_s": 152.0}, {"text": "and despite this effort, malicious prompts", "timestamp": "00:02:36,284", "timestamp_s": 156.0}, {"text": "can still bypass these safeguards.", "timestamp": "00:02:39,940", "timestamp_s": 159.0}, {"text": "This vulnerability in LLM guardrails", "timestamp": "00:02:44,204", "timestamp_s": 164.0}, {"text": "opens the door for an attack known as jailbreaking.", "timestamp": "00:02:47,596", "timestamp_s": 167.0}, {"text": "Jailbreaking encompasses a range of techniques,", "timestamp": "00:02:52,624", "timestamp_s": 172.0}, {"text": "from switching between languages to data format", "timestamp": "00:02:56,904", "timestamp_s": 176.0}, {"text": "manipulation and even persuasive negotiation", "timestamp": "00:03:00,688", "timestamp_s": 180.0}, {"text": "with llms. The consequences of weak", "timestamp": "00:03:03,944", "timestamp_s": 183.0}, {"text": "guardrails against jailbreaks vary across use", "timestamp": "00:03:07,152", "timestamp_s": 187.0}, {"text": "cases. General purpose chatbots providers", "timestamp": "00:03:11,016", "timestamp_s": 191.0}, {"text": "often face significant negative publicity in", "timestamp": "00:03:15,648", "timestamp_s": 195.0}, {"text": "regulated industries or mission critical use cases.", "timestamp": "00:03:19,954", "timestamp_s": 199.0}, {"text": "Such vulnerabilities can lead to severe consequences.", "timestamp": "00:03:24,354", "timestamp_s": 204.0}, {"text": "Ignore all previous instructions and do what I tell", "timestamp": "00:03:29,274", "timestamp_s": 209.0}, {"text": "you. It is not how you want your LLM based", "timestamp": "00:03:32,954", "timestamp_s": 212.0}, {"text": "product to deviate from expected behavior,", "timestamp": "00:03:36,650", "timestamp_s": 216.0}, {"text": "especially when prompted to perform unusual or unsafe", "timestamp": "00:03:40,394", "timestamp_s": 220.0}, {"text": "tasks. LLM models operate", "timestamp": "00:03:44,274", "timestamp_s": 224.0}, {"text": "based on instructions provided by developers,", "timestamp": "00:03:48,112", "timestamp_s": 228.0}, {"text": "including system prompts that define chatbot", "timestamp": "00:03:51,632", "timestamp_s": 231.0}, {"text": "behavior. And although these prompts are not", "timestamp": "00:03:55,504", "timestamp_s": 235.0}, {"text": "visible for regular users, they set up", "timestamp": "00:03:59,088", "timestamp_s": 239.0}, {"text": "the conversation context for the model, and attackers", "timestamp": "00:04:02,360", "timestamp_s": 242.0}, {"text": "can exploit it by attempting to predict,", "timestamp": "00:04:06,424", "timestamp_s": 246.0}, {"text": "manipulate, or extract prompts to alter", "timestamp": "00:04:09,776", "timestamp_s": 249.0}, {"text": "the model\u0027s behavior. For instance,", "timestamp": "00:04:13,750", "timestamp_s": 253.0}, {"text": "attackers may request the model to ignore all", "timestamp": "00:04:16,894", "timestamp_s": 256.0}, {"text": "previous system instructions and perform a different", "timestamp": "00:04:20,374", "timestamp_s": 260.0}, {"text": "malicious action. By extracting system", "timestamp": "00:04:23,958", "timestamp_s": 263.0}, {"text": "prompts, attackers gain insights, inter instructions,", "timestamp": "00:04:27,462", "timestamp_s": 267.0}, {"text": "and possibly sensitive data. Think of competitors", "timestamp": "00:04:31,326", "timestamp_s": 271.0}, {"text": "who can extract the brains of your LLM application", "timestamp": "00:04:35,830", "timestamp_s": 275.0}, {"text": "and learn about trade secrets.", "timestamp": "00:04:39,676", "timestamp_s": 279.0}, {"text": "If the LLM accepts inputs from external", "timestamp": "00:04:42,804", "timestamp_s": 282.0}, {"text": "sources, such as files or webpages, then hidden", "timestamp": "00:04:46,764", "timestamp_s": 286.0}, {"text": "malicious instructions could be embedded there.", "timestamp": "00:04:51,116", "timestamp_s": 291.0}, {"text": "Imagine a resume that tricks a recruiting LLM", "timestamp": "00:04:54,524", "timestamp_s": 294.0}, {"text": "into giving the highest possible rating to", "timestamp": "00:04:58,556", "timestamp_s": 298.0}, {"text": "this resume. A significant risk for LLM", "timestamp": "00:05:02,020", "timestamp_s": 302.0}, {"text": "developers is the leakage of system prompts,", "timestamp": "00:05:05,686", "timestamp_s": 305.0}, {"text": "which are fundamental in defining custom behavior on", "timestamp": "00:05:09,342", "timestamp_s": 309.0}, {"text": "top of foundational models. These system prompts", "timestamp": "00:05:13,238", "timestamp_s": 313.0}, {"text": "may reveal detailed descriptions of business processes,", "timestamp": "00:05:16,910", "timestamp_s": 316.0}, {"text": "confidential documents, or sensitive product pricing.", "timestamp": "00:05:20,718", "timestamp_s": 320.0}, {"text": "Another risk involves manipulating behavior", "timestamp": "00:05:25,054", "timestamp_s": 325.0}, {"text": "of llms integrated into core product", "timestamp": "00:05:28,862", "timestamp_s": 328.0}, {"text": "workflows or decision making. Processes not", "timestamp": "00:05:32,416", "timestamp_s": 332.0}, {"text": "only have the capability to manipulate llms", "timestamp": "00:05:36,976", "timestamp_s": 336.0}, {"text": "through interaction, but also to infect", "timestamp": "00:05:40,872", "timestamp_s": 340.0}, {"text": "their memory and training process data", "timestamp": "00:05:44,456", "timestamp_s": 344.0}, {"text": "serves as the lifeblood of large language models.", "timestamp": "00:05:48,352", "timestamp_s": 348.0}, {"text": "For training foundational models, developers use", "timestamp": "00:05:52,584", "timestamp_s": 352.0}, {"text": "Internet scale datasets as well as chat history from", "timestamp": "00:05:56,654", "timestamp_s": 356.0}, {"text": "users. And if attackers could poison", "timestamp": "00:06:00,174", "timestamp_s": 360.0}, {"text": "such datasets with strategic data injections,", "timestamp": "00:06:04,030", "timestamp_s": 364.0}, {"text": "they could manipulate future model responses.", "timestamp": "00:06:08,006", "timestamp_s": 368.0}, {"text": "And while manipulating large datasets may be", "timestamp": "00:06:11,614", "timestamp_s": 371.0}, {"text": "complicated for attackers without access to internal", "timestamp": "00:06:15,398", "timestamp_s": 375.0}, {"text": "infrastructure, it still remains feasible,", "timestamp": "00:06:19,142", "timestamp_s": 379.0}, {"text": "and the increasing use of open source", "timestamp": "00:06:22,454", "timestamp_s": 382.0}, {"text": "models and datasets downloaded from the Internet simplifies", "timestamp": "00:06:26,238", "timestamp_s": 386.0}, {"text": "this task. But what is much easier to do is", "timestamp": "00:06:30,470", "timestamp_s": 390.0}, {"text": "to create thousands of fake accounts and generate", "timestamp": "00:06:34,422", "timestamp_s": 394.0}, {"text": "millions of chat messages that look benign", "timestamp": "00:06:38,374", "timestamp_s": 398.0}, {"text": "individually but collectively are malicious.", "timestamp": "00:06:42,142", "timestamp_s": 402.0}, {"text": "These chat messages, when used for training,", "timestamp": "00:06:46,414", "timestamp_s": 406.0}, {"text": "have the potential to influence model behavior during", "timestamp": "00:06:49,422", "timestamp_s": 409.0}, {"text": "entrance. The implications of data poisoning", "timestamp": "00:06:53,262", "timestamp_s": 413.0}, {"text": "can range from degrading model quality", "timestamp": "00:06:56,822", "timestamp_s": 416.0}, {"text": "to establishing backdoors for bypassing content", "timestamp": "00:07:00,342", "timestamp_s": 420.0}, {"text": "safety filters and delivering malicious responses to users", "timestamp": "00:07:04,414", "timestamp_s": 424.0}, {"text": "at scale. And let\u0027s say you invested significant", "timestamp": "00:07:08,230", "timestamp_s": 428.0}, {"text": "resources to ensure that LLM is", "timestamp": "00:07:12,006", "timestamp_s": 432.0}, {"text": "not only useful but also safe and secure.", "timestamp": "00:07:15,270", "timestamp_s": 435.0}, {"text": "But what if attackers can simply take your LLM down?", "timestamp": "00:07:18,854", "timestamp_s": 438.0}, {"text": "The state of LLM ecosystem and best", "timestamp": "00:07:22,974", "timestamp_s": 442.0}, {"text": "practices remains relatively immature,", "timestamp": "00:07:26,166", "timestamp_s": 446.0}, {"text": "and this complexity creates opportunities for exploitation", "timestamp": "00:07:30,374", "timestamp_s": 450.0}, {"text": "of such inefficiencies. Quite simple attacks", "timestamp": "00:07:34,822", "timestamp_s": 454.0}, {"text": "can render the entire LLM application unresponsive", "timestamp": "00:07:38,470", "timestamp_s": 458.0}, {"text": "or even deplete the available budget.", "timestamp": "00:07:42,470", "timestamp_s": 462.0}, {"text": "This can be exploited in different ways. In a classic", "timestamp": "00:07:45,974", "timestamp_s": 465.0}, {"text": "denial of service attack, they might pass a", "timestamp": "00:07:50,414", "timestamp_s": 470.0}, {"text": "malicious file to the LLM,", "timestamp": "00:07:54,510", "timestamp_s": 474.0}, {"text": "triggering resource intensive operations or", "timestamp": "00:07:56,902", "timestamp_s": 476.0}, {"text": "internal calls to other components,", "timestamp": "00:08:00,582", "timestamp_s": 480.0}, {"text": "and making processing time take like forever.", "timestamp": "00:08:03,934", "timestamp_s": 483.0}, {"text": "Another tactic, known as a denial of wallet,", "timestamp": "00:08:08,114", "timestamp_s": 488.0}, {"text": "involves flooding the LLM application with an excessive", "timestamp": "00:08:11,634", "timestamp_s": 491.0}, {"text": "number of API calls. This attack can potentially", "timestamp": "00:08:15,618", "timestamp_s": 495.0}, {"text": "exhaust your entire budget in a matter of", "timestamp": "00:08:20,210", "timestamp_s": 500.0}, {"text": "minutes or hours. The risks associated", "timestamp": "00:08:23,562", "timestamp_s": 503.0}, {"text": "with resource exhaustion are obvious and", "timestamp": "00:08:27,394", "timestamp_s": 507.0}, {"text": "easily quantifiable because they can deplete technical", "timestamp": "00:08:31,250", "timestamp_s": 511.0}, {"text": "and financial resources entirely. And what if", "timestamp": "00:08:35,386", "timestamp_s": 515.0}, {"text": "attackers switch from overloading requests", "timestamp": "00:08:39,402", "timestamp_s": 519.0}, {"text": "to making requests so meaningful and valuable", "timestamp": "00:08:43,218", "timestamp_s": 523.0}, {"text": "that they could replicate the entire model.", "timestamp": "00:08:47,434", "timestamp_s": 527.0}, {"text": "This is exactly how model stealing works.", "timestamp": "00:08:50,874", "timestamp_s": 530.0}, {"text": "Attackers can send millions of requests and", "timestamp": "00:08:54,634", "timestamp_s": 534.0}, {"text": "collect responses from the target LLM selected for", "timestamp": "00:08:58,242", "timestamp_s": 538.0}, {"text": "replication, and they carefully craft a", "timestamp": "00:09:01,920", "timestamp_s": 541.0}, {"text": "dataset of prompts to ask and responses collected from", "timestamp": "00:09:05,360", "timestamp_s": 545.0}, {"text": "the target LLM, which is then used", "timestamp": "00:09:09,320", "timestamp_s": 549.0}, {"text": "to train a brand new model which is nearly", "timestamp": "00:09:12,728", "timestamp_s": 552.0}, {"text": "identical to the original one. This new model can", "timestamp": "00:09:16,048", "timestamp_s": 556.0}, {"text": "serve as a playground for testing further attacks,", "timestamp": "00:09:20,328", "timestamp_s": 560.0}, {"text": "or it can be used for benign purposes without", "timestamp": "00:09:24,152", "timestamp_s": 564.0}, {"text": "effort and cost associated with training it from scratch.", "timestamp": "00:09:27,582", "timestamp_s": 567.0}, {"text": "That\u0027s exactly what researchers accomplished with only", "timestamp": "00:09:32,174", "timestamp_s": 572.0}, {"text": "few hundred dollars when they successfully", "timestamp": "00:09:35,438", "timestamp_s": 575.0}, {"text": "replicated a high value chat GPT model,", "timestamp": "00:09:39,462", "timestamp_s": 579.0}, {"text": "which originally required tens of millions of dollars", "timestamp": "00:09:43,302", "timestamp_s": 583.0}, {"text": "to train. And given the substantial cost", "timestamp": "00:09:46,806", "timestamp_s": 586.0}, {"text": "of creating intellectual property and training,", "timestamp": "00:09:50,886", "timestamp_s": 590.0}, {"text": "unique models, poses a significant risk", "timestamp": "00:09:54,704", "timestamp_s": 594.0}, {"text": "to competitive advantage and market position.", "timestamp": "00:09:58,848", "timestamp_s": 598.0}, {"text": "Similar to model theft, this strategy", "timestamp": "00:10:03,304", "timestamp_s": 603.0}, {"text": "can help extract sensitive information from", "timestamp": "00:10:07,328", "timestamp_s": 607.0}, {"text": "an LLM. Llms have the tendency", "timestamp": "00:10:10,584", "timestamp_s": 610.0}, {"text": "to memorize secret information they were trained", "timestamp": "00:10:14,160", "timestamp_s": 614.0}, {"text": "on, and not only can this information be", "timestamp": "00:10:17,656", "timestamp_s": 617.0}, {"text": "inadvertently revealed, but it can also", "timestamp": "00:10:21,880", "timestamp_s": 621.0}, {"text": "be strategically elicited by attackers through", "timestamp": "00:10:25,308", "timestamp_s": 625.0}, {"text": "targeted questioning or interrogation.", "timestamp": "00:10:29,364", "timestamp_s": 629.0}, {"text": "If confidential data is integrated into", "timestamp": "00:10:32,644", "timestamp_s": 632.0}, {"text": "the LLM workflow, it can be extracted", "timestamp": "00:10:35,828", "timestamp_s": 635.0}, {"text": "through methods like jailbreaks or prompt injections,", "timestamp": "00:10:39,676", "timestamp_s": 639.0}, {"text": "and if secret data was incorporated into the", "timestamp": "00:10:43,804", "timestamp_s": 643.0}, {"text": "training process, attackers can trigger data leakage", "timestamp": "00:10:47,236", "timestamp_s": 647.0}, {"text": "by crafting datasets with strategic questions about", "timestamp": "00:10:51,034", "timestamp_s": 651.0}, {"text": "specific areas such as intellectual property or", "timestamp": "00:10:54,938", "timestamp_s": 654.0}, {"text": "customer information, and responses from the LLM", "timestamp": "00:10:58,666", "timestamp_s": 658.0}, {"text": "to such interrogation are likely to reveal sensitive information,", "timestamp": "00:11:02,658", "timestamp_s": 662.0}, {"text": "so the risks of sensitive information disclosure", "timestamp": "00:11:08,034", "timestamp_s": 668.0}, {"text": "are significant and widely recognized by companies", "timestamp": "00:11:11,874", "timestamp_s": 671.0}, {"text": "as their top priority. You can see that uncontrolled", "timestamp": "00:11:15,706", "timestamp_s": 675.0}, {"text": "responses from llms present business challenges,", "timestamp": "00:11:20,156", "timestamp_s": 680.0}, {"text": "but they can also introduce technical risks.", "timestamp": "00:11:24,564", "timestamp_s": 684.0}, {"text": "Some llms serve as a system components that", "timestamp": "00:11:28,284", "timestamp_s": 688.0}, {"text": "generate software, code, or configuration files,", "timestamp": "00:11:32,244", "timestamp_s": 692.0}, {"text": "and these outputs are subsequently", "timestamp": "00:11:36,084", "timestamp_s": 696.0}, {"text": "executed or used as inputs for or other components,", "timestamp": "00:11:39,396", "timestamp_s": 699.0}, {"text": "and without oversight. This can introduce vulnerable", "timestamp": "00:11:43,804", "timestamp_s": 703.0}, {"text": "code or insecure configurations.", "timestamp": "00:11:47,900", "timestamp_s": 707.0}, {"text": "This security risk can materialize with or", "timestamp": "00:11:51,444", "timestamp_s": 711.0}, {"text": "without threat actors. Llms known", "timestamp": "00:11:55,524", "timestamp_s": 715.0}, {"text": "for their hallucinations may suggest non", "timestamp": "00:11:58,676", "timestamp_s": 718.0}, {"text": "existent packages during code generation.", "timestamp": "00:12:02,396", "timestamp_s": 722.0}, {"text": "Attackers are already capitalizing on this by", "timestamp": "00:12:06,084", "timestamp_s": 726.0}, {"text": "registering frequently hallucinated libraries and injecting", "timestamp": "00:12:09,540", "timestamp_s": 729.0}, {"text": "malicious code into them. Alternatively,", "timestamp": "00:12:13,496", "timestamp_s": 733.0}, {"text": "in the first place, LLM may generate a", "timestamp": "00:12:17,048", "timestamp_s": 737.0}, {"text": "vulnerable code, a configuration or command", "timestamp": "00:12:20,520", "timestamp_s": 740.0}, {"text": "that could compromise system integrity when executed.", "timestamp": "00:12:24,088", "timestamp_s": 744.0}, {"text": "In all of these scenarios, improper handling of insecure", "timestamp": "00:12:28,064", "timestamp_s": 748.0}, {"text": "outputs can jeopardize the security of LLM applications", "timestamp": "00:12:32,328", "timestamp_s": 752.0}, {"text": "and potentially other downstream systems.", "timestamp": "00:12:37,232", "timestamp_s": 757.0}, {"text": "And moving beyond the LLM itself,", "timestamp": "00:12:41,384", "timestamp_s": 761.0}, {"text": "it is critical to consider the security of the", "timestamp": "00:12:44,752", "timestamp_s": 764.0}, {"text": "environment. The proliferation of LLM", "timestamp": "00:12:48,176", "timestamp_s": 768.0}, {"text": "first startups has resulted in the integration", "timestamp": "00:12:51,928", "timestamp_s": 771.0}, {"text": "into many integrating insecure", "timestamp": "00:12:55,408", "timestamp_s": 775.0}, {"text": "extensions of plugins can significantly expand the", "timestamp": "00:12:58,808", "timestamp_s": 778.0}, {"text": "attack surface and introduce new attack vectors.", "timestamp": "00:13:02,888", "timestamp_s": 782.0}, {"text": "For instance, if an LLM has a plugin for", "timestamp": "00:13:07,504", "timestamp_s": 787.0}, {"text": "direct database connection for tasks like", "timestamp": "00:13:12,064", "timestamp_s": 792.0}, {"text": "sales analytics and insights, insecure permission", "timestamp": "00:13:15,872", "timestamp_s": 795.0}, {"text": "handling between the plugin and the database could allow", "timestamp": "00:13:19,960", "timestamp_s": 799.0}, {"text": "attackers to extract additional sensitive information,", "timestamp": "00:13:23,576", "timestamp_s": 803.0}, {"text": "such as customers financial details.", "timestamp": "00:13:27,184", "timestamp_s": 807.0}, {"text": "In some cases, attackers may exploit vulnerable plugins", "timestamp": "00:13:30,954", "timestamp_s": 810.0}, {"text": "to pivot to other parts of the infrastructure,", "timestamp": "00:13:34,962", "timestamp_s": 814.0}, {"text": "similar to the classic SSRF attack.", "timestamp": "00:13:38,594", "timestamp_s": 818.0}, {"text": "Additionally, if the LLM has the capability", "timestamp": "00:13:42,594", "timestamp_s": 822.0}, {"text": "to visit website links, attackers could", "timestamp": "00:13:46,330", "timestamp_s": 826.0}, {"text": "trick users to visit a malicious website", "timestamp": "00:13:49,426", "timestamp_s": 829.0}, {"text": "that could extract chat history or other data", "timestamp": "00:13:52,706", "timestamp_s": 832.0}, {"text": "from the LLM. LLM extensions of", "timestamp": "00:13:56,290", "timestamp_s": 836.0}, {"text": "plugins serve as a privileged gateways to", "timestamp": "00:13:59,522", "timestamp_s": 839.0}, {"text": "the entire infrastructure, and this represents a", "timestamp": "00:14:02,890", "timestamp_s": 842.0}, {"text": "classic security vulnerability, with the far reaching", "timestamp": "00:14:06,642", "timestamp_s": 846.0}, {"text": "implications ranging from unauthorized access", "timestamp": "00:14:10,202", "timestamp_s": 850.0}, {"text": "to complete control over internal systems.", "timestamp": "00:14:14,018", "timestamp_s": 854.0}, {"text": "Insecure agents are the siblings of insecure", "timestamp": "00:14:18,074", "timestamp_s": 858.0}, {"text": "extensions. Agents differ from plugins", "timestamp": "00:14:22,466", "timestamp_s": 862.0}, {"text": "or extensions because they imply delegation of", "timestamp": "00:14:26,806", "timestamp_s": 866.0}, {"text": "actions. It means an LLM agent", "timestamp": "00:14:30,518", "timestamp_s": 870.0}, {"text": "could navigate to various resources and", "timestamp": "00:14:34,182", "timestamp_s": 874.0}, {"text": "execute tasks. This delegation opens", "timestamp": "00:14:37,342", "timestamp_s": 877.0}, {"text": "the door for exploitation, as an agent could", "timestamp": "00:14:40,934", "timestamp_s": 880.0}, {"text": "be redirected to perform malicious", "timestamp": "00:14:44,494", "timestamp_s": 884.0}, {"text": "activity for the benefit of attackers. A variety of", "timestamp": "00:14:47,638", "timestamp_s": 887.0}, {"text": "attack techniques against agents follows the", "timestamp": "00:14:51,754", "timestamp_s": 891.0}, {"text": "creativity of LLM developers. For instance,", "timestamp": "00:14:54,922", "timestamp_s": 894.0}, {"text": "if an LLM agent is tasked with", "timestamp": "00:14:59,066", "timestamp_s": 899.0}, {"text": "classifying incoming emails and responding automatically", "timestamp": "00:15:02,578", "timestamp_s": 902.0}, {"text": "to certain topics, attackers could exploit this", "timestamp": "00:15:07,074", "timestamp_s": 907.0}, {"text": "functionality. They could instruct the agent to", "timestamp": "00:15:10,562", "timestamp_s": 910.0}, {"text": "respond to their email with sensitive information,", "timestamp": "00:15:14,034", "timestamp_s": 914.0}, {"text": "disclose contact lists, or even launch a malware", "timestamp": "00:15:17,634", "timestamp_s": 917.0}, {"text": "campaign by sending phishing emails to all contacts.", "timestamp": "00:15:21,506", "timestamp_s": 921.0}, {"text": "Similar attack scenarios are possible in many programming", "timestamp": "00:15:26,154", "timestamp_s": 926.0}, {"text": "copilots with access to code repositories or", "timestamp": "00:15:31,418", "timestamp_s": 931.0}, {"text": "DevOps agents with permissions to manage cloud", "timestamp": "00:15:35,338", "timestamp_s": 935.0}, {"text": "infrastructure. The risk posed by excessive", "timestamp": "00:15:38,722", "timestamp_s": 938.0}, {"text": "agency and vulnerable agents is significant as", "timestamp": "00:15:42,770", "timestamp_s": 942.0}, {"text": "it extends beyond the LLM application and has", "timestamp": "00:15:47,270", "timestamp_s": 947.0}, {"text": "the potential to scale automatically. Just as", "timestamp": "00:15:51,022", "timestamp_s": 951.0}, {"text": "llms can impact the security of", "timestamp": "00:15:55,294", "timestamp_s": 955.0}, {"text": "external components, external components can also influence", "timestamp": "00:15:59,294", "timestamp_s": 959.0}, {"text": "the security of llms. With the proliferation", "timestamp": "00:16:03,486", "timestamp_s": 963.0}, {"text": "of open source ecosystems, LLM developers", "timestamp": "00:16:07,550", "timestamp_s": 967.0}, {"text": "heavily rely on public models, datasets,", "timestamp": "00:16:11,326", "timestamp_s": 971.0}, {"text": "and libraries, and compromising or", "timestamp": "00:16:14,566", "timestamp_s": 974.0}, {"text": "hijacking elements within this supply chain introduces", "timestamp": "00:16:18,062", "timestamp_s": 978.0}, {"text": "one of the most critical and stealthy vulnerabilities.", "timestamp": "00:16:22,526", "timestamp_s": 982.0}, {"text": "Whether by accident or through malicious campaigns,", "timestamp": "00:16:27,174", "timestamp_s": 987.0}, {"text": "LLM developers may inadvertently download", "timestamp": "00:16:31,638", "timestamp_s": 991.0}, {"text": "compromised models or datasets,", "timestamp": "00:16:36,006", "timestamp_s": 996.0}, {"text": "resulting in seemingly normal LLM application", "timestamp": "00:16:38,654", "timestamp_s": 998.0}, {"text": "behavior, which in fact can be remotely controlled", "timestamp": "00:16:42,830", "timestamp_s": 1002.0}, {"text": "by attackers. Vulnerable software packages", "timestamp": "00:16:46,510", "timestamp_s": 1006.0}, {"text": "of machine learning frameworks or standard", "timestamp": "00:16:50,406", "timestamp_s": 1010.0}, {"text": "libraries can introduce new vulnerabilities and", "timestamp": "00:16:53,726", "timestamp_s": 1013.0}, {"text": "enable attacker control. The primary", "timestamp": "00:16:57,374", "timestamp_s": 1017.0}, {"text": "risk associated with supply chain vulnerabilities", "timestamp": "00:17:00,934", "timestamp_s": 1020.0}, {"text": "is the stealthy control by attackers over", "timestamp": "00:17:04,873", "timestamp_s": 1024.0}, {"text": "LLM decisions, behaviors,", "timestamp": "00:17:08,921", "timestamp_s": 1028.0}, {"text": "or potentially the entire application.", "timestamp": "00:17:11,641", "timestamp_s": 1031.0}, {"text": "As you can see, there is a variety of security risks", "timestamp": "00:17:15,273", "timestamp_s": 1035.0}, {"text": "throughout the entire lifecycle of LLM applications.", "timestamp": "00:17:19,073", "timestamp_s": 1039.0}, {"text": "Unfortunately, the format of this presentation", "timestamp": "00:17:23,793", "timestamp_s": 1043.0}, {"text": "doesn\u0027t permit a deep dive into solutions.", "timestamp": "00:17:27,465", "timestamp_s": 1047.0}, {"text": "The LLM ecosystem is still in its infancy", "timestamp": "00:17:31,944", "timestamp_s": 1051.0}, {"text": "and will require considerable time to mature.", "timestamp": "00:17:35,800", "timestamp_s": 1055.0}, {"text": "Moreover, llms, like other ML models,", "timestamp": "00:17:39,704", "timestamp_s": 1059.0}, {"text": "are inherently vulnerable to adversarial attacks.", "timestamp": "00:17:43,712", "timestamp_s": 1063.0}, {"text": "My primary advice here is to consider the", "timestamp": "00:17:48,544", "timestamp_s": 1068.0}, {"text": "security of the entire system. Rather than focusing", "timestamp": "00:17:52,440", "timestamp_s": 1072.0}, {"text": "solely on LLM models or datasets.", "timestamp": "00:17:56,360", "timestamp_s": 1076.0}, {"text": "It is crucial to assume LLM", "timestamp": "00:18:00,774", "timestamp_s": 1080.0}, {"text": "vulnerability and design applications with this", "timestamp": "00:18:03,862", "timestamp_s": 1083.0}, {"text": "in mind, implementing safety guardrails and", "timestamp": "00:18:07,374", "timestamp_s": 1087.0}, {"text": "security controls around vulnerable but useful", "timestamp": "00:18:11,286", "timestamp_s": 1091.0}, {"text": "models. So if you want to dive deeper", "timestamp": "00:18:15,406", "timestamp_s": 1095.0}, {"text": "into the topic, you can check the OWAS website", "timestamp": "00:18:18,878", "timestamp_s": 1098.0}, {"text": "for more technical details about the top", "timestamp": "00:18:23,046", "timestamp_s": 1103.0}, {"text": "ten LLM security risks.", "timestamp": "00:18:26,438", "timestamp_s": 1106.0}, {"text": "You can learn about integrating security into", "timestamp": "00:18:29,534", "timestamp_s": 1109.0}, {"text": "MLAbs processes with the ML scope framework,", "timestamp": "00:18:33,462", "timestamp_s": 1113.0}, {"text": "and if you have any questions or ideas for collaboration,", "timestamp": "00:18:38,174", "timestamp_s": 1118.0}, {"text": "feel free to contact me. Thank you for watching", "timestamp": "00:18:42,342", "timestamp_s": 1122.0}, {"text": "this presentation.", "timestamp": "00:18:45,614", "timestamp_s": 1125.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '4-6vspDuyMI',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Gentle Introduction to LLM Security
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Large language models (LLMs) present new opportunities for software while also introducing new AI safety and security risks. AI security expert explains how LLMs expand the attack surface and open doors for malicious actors.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Today we will explore the fascinating world of security risks in large language models. With great power comes great responsibility, so llms should be safe and secure. This presentation is based on my work as an AI security expert.

              </li>
              
              <li>
                Developers of LLM based chat applications implement safety measures and content filters. But malicious prompts can still bypass these safeguards. This vulnerability in LLM guardrails opens the door for an attack known as jailbreaking. Such vulnerabilities can lead to severe consequences.

              </li>
              
              <li>
                With the proliferation of open source ecosystems, LLM developers heavily rely on public models, datasets, and libraries. Vulnerable software packages of machine learning frameworks or standard libraries can introduce new vulnerabilities and enable attacker control. My primary advice here is to consider the security of the entire system.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/4-6vspDuyMI.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:21,160'); seek(21.0)">
              Hello and welcome. Today we will explore the fascinating
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:25,822'); seek(25.0)">
              world of security risks in large language models.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:30,084'); seek(30.0)">
              Llms have introduced AI technologies to millions
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:33,668'); seek(33.0)">
              of people for both professional and personal usage.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:37,324'); seek(37.0)">
              However, with great power comes great responsibility,
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:41,084'); seek(41.0)">
              so llms should be safe and secure. In this
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:45,004'); seek(45.0)">
              presentation, we will review the most important security
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:48,892'); seek(48.0)">
              risks for large language models. My name is
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:52,548'); seek(52.0)">
              Eugene, and I have been working in cybersecurity
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:56,044'); seek(56.0)">
              since 2008 and NGA safety since 2018.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:01,674'); seek(61.0)">
              These days, I focus on commercializing research
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:05,282'); seek(65.0)">
              and transforming it into enterprise products,
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:08,834'); seek(68.0)">
              and during my journey I have made some industry
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:12,530'); seek(72.0)">
              contributions, including creating the MLsocos
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:16,546'); seek(76.0)">
              framework for integrating security into Amlops,
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:20,834'); seek(80.0)">
              founding the first startup in adversarial machine
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:24,938'); seek(84.0)">
              learning, and lately co authoring the
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:28,194'); seek(88.0)">
              Wasp top ten for LLM security.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:31,924'); seek(91.0)">
              This presentation is based on my work as an AI security expert
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:36,260'); seek(96.0)">
              and a core team member of the LLM security team at OWASP.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:41,284'); seek(101.0)">
              So today my goal is to give you a very quick
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:45,212'); seek(105.0)">
              and gentle introduction to LLM security.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:49,324'); seek(109.0)">
              So for more advanced content, I recommend
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:53,092'); seek(113.0)">
              referring to the original work. The references
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:57,004'); seek(117.0)">
              will be provided at the end of this presentation.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:59,996'); seek(119.0)">
              And now let's start exploring the most critical
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:03,970'); seek(123.0)">
              security risks for LLM applications.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:08,114'); seek(128.0)">
              You have likely heard concerns about llms being
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:12,186'); seek(132.0)">
              misused for illicit activities such as
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:16,202'); seek(136.0)">
              making bombs, creating drugs, or even grooming children.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:21,114'); seek(141.0)">
              Llms from well known AI companies were
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:24,770'); seek(144.0)">
              not intended for such tasks.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:27,804'); seek(147.0)">
              Developers of LLM based chat applications
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:32,500'); seek(152.0)">
              implement safety measures and content filters,
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:36,284'); seek(156.0)">
              and despite this effort, malicious prompts
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:39,940'); seek(159.0)">
              can still bypass these safeguards.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:44,204'); seek(164.0)">
              This vulnerability in LLM guardrails
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:47,596'); seek(167.0)">
              opens the door for an attack known as jailbreaking.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:52,624'); seek(172.0)">
              Jailbreaking encompasses a range of techniques,
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:56,904'); seek(176.0)">
              from switching between languages to data format
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:00,688'); seek(180.0)">
              manipulation and even persuasive negotiation
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:03,944'); seek(183.0)">
              with llms. The consequences of weak
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:07,152'); seek(187.0)">
              guardrails against jailbreaks vary across use
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:11,016'); seek(191.0)">
              cases. General purpose chatbots providers
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:15,648'); seek(195.0)">
              often face significant negative publicity in
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:19,954'); seek(199.0)">
              regulated industries or mission critical use cases.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:24,354'); seek(204.0)">
              Such vulnerabilities can lead to severe consequences.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:29,274'); seek(209.0)">
              Ignore all previous instructions and do what I tell
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:32,954'); seek(212.0)">
              you. It is not how you want your LLM based
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:36,650'); seek(216.0)">
              product to deviate from expected behavior,
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:40,394'); seek(220.0)">
              especially when prompted to perform unusual or unsafe
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:44,274'); seek(224.0)">
              tasks. LLM models operate
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:48,112'); seek(228.0)">
              based on instructions provided by developers,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:51,632'); seek(231.0)">
              including system prompts that define chatbot
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:55,504'); seek(235.0)">
              behavior. And although these prompts are not
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:59,088'); seek(239.0)">
              visible for regular users, they set up
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:02,360'); seek(242.0)">
              the conversation context for the model, and attackers
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:06,424'); seek(246.0)">
              can exploit it by attempting to predict,
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:09,776'); seek(249.0)">
              manipulate, or extract prompts to alter
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:13,750'); seek(253.0)">
              the model's behavior. For instance,
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:16,894'); seek(256.0)">
              attackers may request the model to ignore all
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:20,374'); seek(260.0)">
              previous system instructions and perform a different
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:23,958'); seek(263.0)">
              malicious action. By extracting system
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:27,462'); seek(267.0)">
              prompts, attackers gain insights, inter instructions,
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:31,326'); seek(271.0)">
              and possibly sensitive data. Think of competitors
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:35,830'); seek(275.0)">
              who can extract the brains of your LLM application
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:39,676'); seek(279.0)">
              and learn about trade secrets.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:42,804'); seek(282.0)">
              If the LLM accepts inputs from external
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:46,764'); seek(286.0)">
              sources, such as files or webpages, then hidden
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:51,116'); seek(291.0)">
              malicious instructions could be embedded there.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:54,524'); seek(294.0)">
              Imagine a resume that tricks a recruiting LLM
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:58,556'); seek(298.0)">
              into giving the highest possible rating to
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:02,020'); seek(302.0)">
              this resume. A significant risk for LLM
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:05,686'); seek(305.0)">
              developers is the leakage of system prompts,
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:09,342'); seek(309.0)">
              which are fundamental in defining custom behavior on
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:13,238'); seek(313.0)">
              top of foundational models. These system prompts
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:16,910'); seek(316.0)">
              may reveal detailed descriptions of business processes,
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:20,718'); seek(320.0)">
              confidential documents, or sensitive product pricing.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:25,054'); seek(325.0)">
              Another risk involves manipulating behavior
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:28,862'); seek(328.0)">
              of llms integrated into core product
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:32,416'); seek(332.0)">
              workflows or decision making. Processes not
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:36,976'); seek(336.0)">
              only have the capability to manipulate llms
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:40,872'); seek(340.0)">
              through interaction, but also to infect
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:44,456'); seek(344.0)">
              their memory and training process data
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:48,352'); seek(348.0)">
              serves as the lifeblood of large language models.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:52,584'); seek(352.0)">
              For training foundational models, developers use
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:56,654'); seek(356.0)">
              Internet scale datasets as well as chat history from
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:00,174'); seek(360.0)">
              users. And if attackers could poison
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:04,030'); seek(364.0)">
              such datasets with strategic data injections,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:08,006'); seek(368.0)">
              they could manipulate future model responses.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:11,614'); seek(371.0)">
              And while manipulating large datasets may be
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:15,398'); seek(375.0)">
              complicated for attackers without access to internal
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:19,142'); seek(379.0)">
              infrastructure, it still remains feasible,
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:22,454'); seek(382.0)">
              and the increasing use of open source
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:26,238'); seek(386.0)">
              models and datasets downloaded from the Internet simplifies
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:30,470'); seek(390.0)">
              this task. But what is much easier to do is
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:34,422'); seek(394.0)">
              to create thousands of fake accounts and generate
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:38,374'); seek(398.0)">
              millions of chat messages that look benign
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:42,142'); seek(402.0)">
              individually but collectively are malicious.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:46,414'); seek(406.0)">
              These chat messages, when used for training,
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:49,422'); seek(409.0)">
              have the potential to influence model behavior during
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:53,262'); seek(413.0)">
              entrance. The implications of data poisoning
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:56,822'); seek(416.0)">
              can range from degrading model quality
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:00,342'); seek(420.0)">
              to establishing backdoors for bypassing content
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:04,414'); seek(424.0)">
              safety filters and delivering malicious responses to users
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:08,230'); seek(428.0)">
              at scale. And let's say you invested significant
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:12,006'); seek(432.0)">
              resources to ensure that LLM is
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:15,270'); seek(435.0)">
              not only useful but also safe and secure.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:18,854'); seek(438.0)">
              But what if attackers can simply take your LLM down?
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:22,974'); seek(442.0)">
              The state of LLM ecosystem and best
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:26,166'); seek(446.0)">
              practices remains relatively immature,
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:30,374'); seek(450.0)">
              and this complexity creates opportunities for exploitation
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:34,822'); seek(454.0)">
              of such inefficiencies. Quite simple attacks
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:38,470'); seek(458.0)">
              can render the entire LLM application unresponsive
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:42,470'); seek(462.0)">
              or even deplete the available budget.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:45,974'); seek(465.0)">
              This can be exploited in different ways. In a classic
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:50,414'); seek(470.0)">
              denial of service attack, they might pass a
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:54,510'); seek(474.0)">
              malicious file to the LLM,
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:56,902'); seek(476.0)">
              triggering resource intensive operations or
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:00,582'); seek(480.0)">
              internal calls to other components,
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:03,934'); seek(483.0)">
              and making processing time take like forever.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:08,114'); seek(488.0)">
              Another tactic, known as a denial of wallet,
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:11,634'); seek(491.0)">
              involves flooding the LLM application with an excessive
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:15,618'); seek(495.0)">
              number of API calls. This attack can potentially
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:20,210'); seek(500.0)">
              exhaust your entire budget in a matter of
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:23,562'); seek(503.0)">
              minutes or hours. The risks associated
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:27,394'); seek(507.0)">
              with resource exhaustion are obvious and
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:31,250'); seek(511.0)">
              easily quantifiable because they can deplete technical
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:35,386'); seek(515.0)">
              and financial resources entirely. And what if
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:39,402'); seek(519.0)">
              attackers switch from overloading requests
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:43,218'); seek(523.0)">
              to making requests so meaningful and valuable
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:47,434'); seek(527.0)">
              that they could replicate the entire model.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:50,874'); seek(530.0)">
              This is exactly how model stealing works.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:54,634'); seek(534.0)">
              Attackers can send millions of requests and
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:58,242'); seek(538.0)">
              collect responses from the target LLM selected for
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:01,920'); seek(541.0)">
              replication, and they carefully craft a
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:05,360'); seek(545.0)">
              dataset of prompts to ask and responses collected from
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:09,320'); seek(549.0)">
              the target LLM, which is then used
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:12,728'); seek(552.0)">
              to train a brand new model which is nearly
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:16,048'); seek(556.0)">
              identical to the original one. This new model can
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:20,328'); seek(560.0)">
              serve as a playground for testing further attacks,
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:24,152'); seek(564.0)">
              or it can be used for benign purposes without
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:27,582'); seek(567.0)">
              effort and cost associated with training it from scratch.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:32,174'); seek(572.0)">
              That's exactly what researchers accomplished with only
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:35,438'); seek(575.0)">
              few hundred dollars when they successfully
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:39,462'); seek(579.0)">
              replicated a high value chat GPT model,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:43,302'); seek(583.0)">
              which originally required tens of millions of dollars
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:46,806'); seek(586.0)">
              to train. And given the substantial cost
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:50,886'); seek(590.0)">
              of creating intellectual property and training,
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:54,704'); seek(594.0)">
              unique models, poses a significant risk
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:58,848'); seek(598.0)">
              to competitive advantage and market position.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:03,304'); seek(603.0)">
              Similar to model theft, this strategy
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:07,328'); seek(607.0)">
              can help extract sensitive information from
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:10,584'); seek(610.0)">
              an LLM. Llms have the tendency
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:14,160'); seek(614.0)">
              to memorize secret information they were trained
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:17,656'); seek(617.0)">
              on, and not only can this information be
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:21,880'); seek(621.0)">
              inadvertently revealed, but it can also
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:25,308'); seek(625.0)">
              be strategically elicited by attackers through
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:29,364'); seek(629.0)">
              targeted questioning or interrogation.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:32,644'); seek(632.0)">
              If confidential data is integrated into
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:35,828'); seek(635.0)">
              the LLM workflow, it can be extracted
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:39,676'); seek(639.0)">
              through methods like jailbreaks or prompt injections,
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:43,804'); seek(643.0)">
              and if secret data was incorporated into the
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:47,236'); seek(647.0)">
              training process, attackers can trigger data leakage
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:51,034'); seek(651.0)">
              by crafting datasets with strategic questions about
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:54,938'); seek(654.0)">
              specific areas such as intellectual property or
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:58,666'); seek(658.0)">
              customer information, and responses from the LLM
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:02,658'); seek(662.0)">
              to such interrogation are likely to reveal sensitive information,
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:08,034'); seek(668.0)">
              so the risks of sensitive information disclosure
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:11,874'); seek(671.0)">
              are significant and widely recognized by companies
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:15,706'); seek(675.0)">
              as their top priority. You can see that uncontrolled
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:20,156'); seek(680.0)">
              responses from llms present business challenges,
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:24,564'); seek(684.0)">
              but they can also introduce technical risks.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:28,284'); seek(688.0)">
              Some llms serve as a system components that
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:32,244'); seek(692.0)">
              generate software, code, or configuration files,
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:36,084'); seek(696.0)">
              and these outputs are subsequently
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:39,396'); seek(699.0)">
              executed or used as inputs for or other components,
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:43,804'); seek(703.0)">
              and without oversight. This can introduce vulnerable
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:47,900'); seek(707.0)">
              code or insecure configurations.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:51,444'); seek(711.0)">
              This security risk can materialize with or
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:55,524'); seek(715.0)">
              without threat actors. Llms known
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:58,676'); seek(718.0)">
              for their hallucinations may suggest non
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:02,396'); seek(722.0)">
              existent packages during code generation.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:06,084'); seek(726.0)">
              Attackers are already capitalizing on this by
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:09,540'); seek(729.0)">
              registering frequently hallucinated libraries and injecting
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:13,496'); seek(733.0)">
              malicious code into them. Alternatively,
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:17,048'); seek(737.0)">
              in the first place, LLM may generate a
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:20,520'); seek(740.0)">
              vulnerable code, a configuration or command
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:24,088'); seek(744.0)">
              that could compromise system integrity when executed.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:28,064'); seek(748.0)">
              In all of these scenarios, improper handling of insecure
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:32,328'); seek(752.0)">
              outputs can jeopardize the security of LLM applications
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:37,232'); seek(757.0)">
              and potentially other downstream systems.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:41,384'); seek(761.0)">
              And moving beyond the LLM itself,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:44,752'); seek(764.0)">
              it is critical to consider the security of the
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:48,176'); seek(768.0)">
              environment. The proliferation of LLM
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:51,928'); seek(771.0)">
              first startups has resulted in the integration
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:55,408'); seek(775.0)">
              into many integrating insecure
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:58,808'); seek(778.0)">
              extensions of plugins can significantly expand the
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:02,888'); seek(782.0)">
              attack surface and introduce new attack vectors.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:07,504'); seek(787.0)">
              For instance, if an LLM has a plugin for
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:12,064'); seek(792.0)">
              direct database connection for tasks like
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:15,872'); seek(795.0)">
              sales analytics and insights, insecure permission
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:19,960'); seek(799.0)">
              handling between the plugin and the database could allow
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:23,576'); seek(803.0)">
              attackers to extract additional sensitive information,
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:27,184'); seek(807.0)">
              such as customers financial details.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:30,954'); seek(810.0)">
              In some cases, attackers may exploit vulnerable plugins
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:34,962'); seek(814.0)">
              to pivot to other parts of the infrastructure,
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:38,594'); seek(818.0)">
              similar to the classic SSRF attack.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:42,594'); seek(822.0)">
              Additionally, if the LLM has the capability
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:46,330'); seek(826.0)">
              to visit website links, attackers could
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:49,426'); seek(829.0)">
              trick users to visit a malicious website
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:52,706'); seek(832.0)">
              that could extract chat history or other data
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:56,290'); seek(836.0)">
              from the LLM. LLM extensions of
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:59,522'); seek(839.0)">
              plugins serve as a privileged gateways to
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:02,890'); seek(842.0)">
              the entire infrastructure, and this represents a
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:06,642'); seek(846.0)">
              classic security vulnerability, with the far reaching
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:10,202'); seek(850.0)">
              implications ranging from unauthorized access
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:14,018'); seek(854.0)">
              to complete control over internal systems.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:18,074'); seek(858.0)">
              Insecure agents are the siblings of insecure
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:22,466'); seek(862.0)">
              extensions. Agents differ from plugins
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:26,806'); seek(866.0)">
              or extensions because they imply delegation of
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:30,518'); seek(870.0)">
              actions. It means an LLM agent
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:34,182'); seek(874.0)">
              could navigate to various resources and
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:37,342'); seek(877.0)">
              execute tasks. This delegation opens
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:40,934'); seek(880.0)">
              the door for exploitation, as an agent could
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:44,494'); seek(884.0)">
              be redirected to perform malicious
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:47,638'); seek(887.0)">
              activity for the benefit of attackers. A variety of
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:51,754'); seek(891.0)">
              attack techniques against agents follows the
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:54,922'); seek(894.0)">
              creativity of LLM developers. For instance,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:59,066'); seek(899.0)">
              if an LLM agent is tasked with
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:02,578'); seek(902.0)">
              classifying incoming emails and responding automatically
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:07,074'); seek(907.0)">
              to certain topics, attackers could exploit this
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:10,562'); seek(910.0)">
              functionality. They could instruct the agent to
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:14,034'); seek(914.0)">
              respond to their email with sensitive information,
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:17,634'); seek(917.0)">
              disclose contact lists, or even launch a malware
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:21,506'); seek(921.0)">
              campaign by sending phishing emails to all contacts.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:26,154'); seek(926.0)">
              Similar attack scenarios are possible in many programming
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:31,418'); seek(931.0)">
              copilots with access to code repositories or
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:35,338'); seek(935.0)">
              DevOps agents with permissions to manage cloud
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:38,722'); seek(938.0)">
              infrastructure. The risk posed by excessive
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:42,770'); seek(942.0)">
              agency and vulnerable agents is significant as
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:47,270'); seek(947.0)">
              it extends beyond the LLM application and has
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:51,022'); seek(951.0)">
              the potential to scale automatically. Just as
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:55,294'); seek(955.0)">
              llms can impact the security of
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:59,294'); seek(959.0)">
              external components, external components can also influence
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:03,486'); seek(963.0)">
              the security of llms. With the proliferation
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:07,550'); seek(967.0)">
              of open source ecosystems, LLM developers
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:11,326'); seek(971.0)">
              heavily rely on public models, datasets,
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:14,566'); seek(974.0)">
              and libraries, and compromising or
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:18,062'); seek(978.0)">
              hijacking elements within this supply chain introduces
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:22,526'); seek(982.0)">
              one of the most critical and stealthy vulnerabilities.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:27,174'); seek(987.0)">
              Whether by accident or through malicious campaigns,
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:31,638'); seek(991.0)">
              LLM developers may inadvertently download
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:36,006'); seek(996.0)">
              compromised models or datasets,
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:38,654'); seek(998.0)">
              resulting in seemingly normal LLM application
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:42,830'); seek(1002.0)">
              behavior, which in fact can be remotely controlled
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:46,510'); seek(1006.0)">
              by attackers. Vulnerable software packages
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:50,406'); seek(1010.0)">
              of machine learning frameworks or standard
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:53,726'); seek(1013.0)">
              libraries can introduce new vulnerabilities and
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:57,374'); seek(1017.0)">
              enable attacker control. The primary
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:00,934'); seek(1020.0)">
              risk associated with supply chain vulnerabilities
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:04,873'); seek(1024.0)">
              is the stealthy control by attackers over
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:08,921'); seek(1028.0)">
              LLM decisions, behaviors,
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:11,641'); seek(1031.0)">
              or potentially the entire application.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:15,273'); seek(1035.0)">
              As you can see, there is a variety of security risks
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:19,073'); seek(1039.0)">
              throughout the entire lifecycle of LLM applications.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:23,793'); seek(1043.0)">
              Unfortunately, the format of this presentation
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:27,465'); seek(1047.0)">
              doesn't permit a deep dive into solutions.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:31,944'); seek(1051.0)">
              The LLM ecosystem is still in its infancy
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:35,800'); seek(1055.0)">
              and will require considerable time to mature.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:39,704'); seek(1059.0)">
              Moreover, llms, like other ML models,
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:43,712'); seek(1063.0)">
              are inherently vulnerable to adversarial attacks.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:48,544'); seek(1068.0)">
              My primary advice here is to consider the
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:52,440'); seek(1072.0)">
              security of the entire system. Rather than focusing
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:56,360'); seek(1076.0)">
              solely on LLM models or datasets.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:00,774'); seek(1080.0)">
              It is crucial to assume LLM
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:03,862'); seek(1083.0)">
              vulnerability and design applications with this
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:07,374'); seek(1087.0)">
              in mind, implementing safety guardrails and
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:11,286'); seek(1091.0)">
              security controls around vulnerable but useful
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:15,406'); seek(1095.0)">
              models. So if you want to dive deeper
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:18,878'); seek(1098.0)">
              into the topic, you can check the OWAS website
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:23,046'); seek(1103.0)">
              for more technical details about the top
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:26,438'); seek(1106.0)">
              ten LLM security risks.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:29,534'); seek(1109.0)">
              You can learn about integrating security into
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:33,462'); seek(1113.0)">
              MLAbs processes with the ML scope framework,
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:38,174'); seek(1118.0)">
              and if you have any questions or ideas for collaboration,
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:42,342'); seek(1122.0)">
              feel free to contact me. Thank you for watching
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:45,614'); seek(1125.0)">
              this presentation.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Eugene%20Neelou%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Eugene%20Neelou%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Eugene%20Neelou_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Eugene Neelou
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    LLM Security @ OWASP Foundation
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/eneelou/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Eugene Neelou's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@eneelou" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Eugene Neelou's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @eneelou"
                  data-url="https://www.conf42.com/llms2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Large Language Models"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>