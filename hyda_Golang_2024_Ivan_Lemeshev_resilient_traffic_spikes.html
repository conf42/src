<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: How to make your service more resilient in case of traffic spikes</title>
    <meta name="description" content="Say hello to the Gophers from outer space!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Ivan%20Lemeshev_golang.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="How to make your service more resilient in case of traffic spikes | Conf42"/>
    <meta property="og:description" content="I want to talk about server overload, why it happens, and what happens with a service in such a situation. I will discuss two main techniques to prevent server overload and make the service more resilient such as rate limiting and load shedding."/>
    <meta property="og:url" content="https://conf42.com/Golang_2024_Ivan_Lemeshev_resilient_traffic_spikes"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/OBS2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Observability 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-06-05
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/obs2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #881E4B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Golang 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Say hello to the Gophers from outer space!
 -->
              <script>
                const event_date = new Date("2024-04-25T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-25T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "H5a6psrN0GM"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "0y_ts8oh36o"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrCPeN0GQy__eEHaihV8TVmY" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everybody. Today I want to talk about techniques", "timestamp": "00:00:20,640", "timestamp_s": 20.0}, {"text": "that allow you to reduce the load on the server", "timestamp": "00:00:25,086", "timestamp_s": 25.0}, {"text": "and keep your service running smoothly,", "timestamp": "00:00:29,334", "timestamp_s": 29.0}, {"text": "preventing server overload in case of traffic bursts.", "timestamp": "00:00:32,694", "timestamp_s": 32.0}, {"text": "In particular, I will be talking about rate", "timestamp": "00:00:37,574", "timestamp_s": 37.0}, {"text": "limiting and load shedding. A little", "timestamp": "00:00:41,166", "timestamp_s": 41.0}, {"text": "disclaimer by service, I mean any", "timestamp": "00:00:44,606", "timestamp_s": 44.0}, {"text": "backend application. It can be a monolithic application", "timestamp": "00:00:48,502", "timestamp_s": 48.0}, {"text": "or an individual microservice in a large distributed", "timestamp": "00:00:53,334", "timestamp_s": 53.0}, {"text": "system. But first, let me", "timestamp": "00:00:57,318", "timestamp_s": 57.0}, {"text": "tell you a little bit about me.", "timestamp": "00:01:01,214", "timestamp_s": 61.0}, {"text": "My name is Ivan Lemeshev. I live", "timestamp": "00:01:04,294", "timestamp_s": 64.0}, {"text": "in Finland. I moved here over three years", "timestamp": "00:01:07,550", "timestamp_s": 67.0}, {"text": "ago, and since then I have been working at", "timestamp": "00:01:10,990", "timestamp_s": 70.0}, {"text": "Unity as a senior software engineer.", "timestamp": "00:01:14,790", "timestamp_s": 74.0}, {"text": "I have been using Golang as my primary programming language", "timestamp": "00:01:18,294", "timestamp_s": 78.0}, {"text": "for many years and I am interested in the development", "timestamp": "00:01:22,054", "timestamp_s": 82.0}, {"text": "of large scale and distributed systems.", "timestamp": "00:01:26,304", "timestamp_s": 86.0}, {"text": "You can find me on LinkedIn or GitHub", "timestamp": "00:01:30,544", "timestamp_s": 90.0}, {"text": "by following the links to begin", "timestamp": "00:01:34,704", "timestamp_s": 94.0}, {"text": "with, let\u0027s look at the agenda for this", "timestamp": "00:01:38,000", "timestamp_s": 98.0}, {"text": "talk. First, I will discuss survey", "timestamp": "00:01:41,776", "timestamp_s": 101.0}, {"text": "overload, why it occurs,", "timestamp": "00:01:45,656", "timestamp_s": 105.0}, {"text": "and how it affects the performance of backend", "timestamp": "00:01:48,664", "timestamp_s": 108.0}, {"text": "services. I\u0027ll give you an example of common", "timestamp": "00:01:52,500", "timestamp_s": 112.0}, {"text": "causes of server overload,", "timestamp": "00:01:56,596", "timestamp_s": 116.0}, {"text": "and then I\u0027ll show you what it looks like", "timestamp": "00:01:59,364", "timestamp_s": 119.0}, {"text": "in the example of a simple HTTP service.", "timestamp": "00:02:03,300", "timestamp_s": 123.0}, {"text": "After that, I\u0027ll consider techniques that", "timestamp": "00:02:07,924", "timestamp_s": 127.0}, {"text": "help prevent server overload.", "timestamp": "00:02:11,964", "timestamp_s": 131.0}, {"text": "I\u0027ll start with rate limiting and review common", "timestamp": "00:02:14,796", "timestamp_s": 134.0}, {"text": "rate limiting algorithms. Then I\u0027ll", "timestamp": "00:02:19,380", "timestamp_s": 139.0}, {"text": "show you a simple implementation of one", "timestamp": "00:02:22,974", "timestamp_s": 142.0}, {"text": "of the algorithms, and you will see how it", "timestamp": "00:02:26,214", "timestamp_s": 146.0}, {"text": "works. Next, I will discuss another technique", "timestamp": "00:02:29,814", "timestamp_s": 149.0}, {"text": "called load shedding and show", "timestamp": "00:02:34,014", "timestamp_s": 154.0}, {"text": "you a simple well, let\u0027s get", "timestamp": "00:02:37,686", "timestamp_s": 157.0}, {"text": "started. When we develop a backend application,", "timestamp": "00:02:41,406", "timestamp_s": 161.0}, {"text": "we deploy it to a server to make it available", "timestamp": "00:02:45,934", "timestamp_s": 165.0}, {"text": "to users. As a server,", "timestamp": "00:02:49,508", "timestamp_s": 169.0}, {"text": "both physical and virtual servers", "timestamp": "00:02:52,980", "timestamp_s": 172.0}, {"text": "can be used. It doesn\u0027t matter.", "timestamp": "00:02:56,980", "timestamp_s": 176.0}, {"text": "Each server always has limited computational or", "timestamp": "00:03:01,484", "timestamp_s": 181.0}, {"text": "system resources, such as cpu or memory.", "timestamp": "00:03:05,532", "timestamp_s": 185.0}, {"text": "The service utilizes some of these resources to", "timestamp": "00:03:10,204", "timestamp_s": 190.0}, {"text": "process each incoming user request,", "timestamp": "00:03:14,620", "timestamp_s": 194.0}, {"text": "including managing multiple tasks,", "timestamp": "00:03:17,964", "timestamp_s": 197.0}, {"text": "switching between them, cleaning up unused memory,", "timestamp": "00:03:21,380", "timestamp_s": 201.0}, {"text": "and waiting for data to come in or go out.", "timestamp": "00:03:25,276", "timestamp_s": 205.0}, {"text": "The server can process only a particular", "timestamp": "00:03:30,204", "timestamp_s": 210.0}, {"text": "number of concurrent user requests simultaneously", "timestamp": "00:03:35,020", "timestamp_s": 215.0}, {"text": "under heavy load. When a system is given", "timestamp": "00:03:41,084", "timestamp_s": 221.0}, {"text": "more work than each resources support,", "timestamp": "00:03:44,476", "timestamp_s": 224.0}, {"text": "it starts experiencing a lack of resources", "timestamp": "00:03:49,004", "timestamp_s": 229.0}, {"text": "and becomes slow,", "timestamp": "00:03:53,212", "timestamp_s": 233.0}, {"text": "which leads to an increase in the processing time", "timestamp": "00:03:56,644", "timestamp_s": 236.0}, {"text": "or latency. For each request. The service reaches", "timestamp": "00:04:00,924", "timestamp_s": 240.0}, {"text": "some threshold where its", "timestamp": "00:04:05,324", "timestamp_s": 245.0}, {"text": "performance degrades rapidly.", "timestamp": "00:04:08,708", "timestamp_s": 248.0}, {"text": "It can keep working even when it", "timestamp": "00:04:12,124", "timestamp_s": 252.0}, {"text": "is overloaded, but it spends amounts", "timestamp": "00:04:16,280", "timestamp_s": 256.0}, {"text": "of time contacts switching and", "timestamp": "00:04:20,648", "timestamp_s": 260.0}, {"text": "becomes too slow to be useful because", "timestamp": "00:04:24,760", "timestamp_s": 264.0}, {"text": "most likely the client has some timeouts", "timestamp": "00:04:28,376", "timestamp_s": 268.0}, {"text": "and can\u0027t wait for the response from the", "timestamp": "00:04:32,416", "timestamp_s": 272.0}, {"text": "service too long. Therefore,", "timestamp": "00:04:36,320", "timestamp_s": 276.0}, {"text": "the service performance and availability of", "timestamp": "00:04:39,848", "timestamp_s": 279.0}, {"text": "your service will be declined because", "timestamp": "00:04:44,148", "timestamp_s": 284.0}, {"text": "almost all requests will fail due", "timestamp": "00:04:47,916", "timestamp_s": 287.0}, {"text": "to high latency and timeouts. In the", "timestamp": "00:04:51,652", "timestamp_s": 291.0}, {"text": "worst case, the server may", "timestamp": "00:04:55,524", "timestamp_s": 295.0}, {"text": "completely crash and stop handling requests", "timestamp": "00:04:58,708", "timestamp_s": 298.0}, {"text": "due to running out of memory or other", "timestamp": "00:05:03,252", "timestamp_s": 303.0}, {"text": "resources. Of course, we can use auto scaling and", "timestamp": "00:05:07,036", "timestamp_s": 307.0}, {"text": "deploy additional service instances,", "timestamp": "00:05:11,238", "timestamp_s": 311.0}, {"text": "but it doesn\u0027t happen instantly if", "timestamp": "00:05:14,294", "timestamp_s": 314.0}, {"text": "the load grows gracefully. Auto scaling works", "timestamp": "00:05:18,278", "timestamp_s": 318.0}, {"text": "well. However, deploying an appropriate", "timestamp": "00:05:21,846", "timestamp_s": 321.0}, {"text": "number of additional instances requires time", "timestamp": "00:05:25,302", "timestamp_s": 325.0}, {"text": "if we have a traffic burst and the load is", "timestamp": "00:05:29,358", "timestamp_s": 329.0}, {"text": "exceptionally high.", "timestamp": "00:05:33,918", "timestamp_s": 333.0}, {"text": "Also, there may be a situation when an", "timestamp": "00:05:36,434", "timestamp_s": 336.0}, {"text": "individual user or a group of users", "timestamp": "00:05:40,538", "timestamp_s": 340.0}, {"text": "may produce so many requests,", "timestamp": "00:05:43,954", "timestamp_s": 343.0}, {"text": "consuming all the system resources, and other service", "timestamp": "00:05:48,434", "timestamp_s": 348.0}, {"text": "users will be unable to use it.", "timestamp": "00:05:52,794", "timestamp_s": 352.0}, {"text": "In this case, auto scaling will not help.", "timestamp": "00:05:55,946", "timestamp_s": 355.0}, {"text": "Now let\u0027s explore situations", "timestamp": "00:05:59,484", "timestamp_s": 359.0}, {"text": "where a surge of traffic can occur.", "timestamp": "00:06:03,140", "timestamp_s": 363.0}, {"text": "Traffic bursts can occur due to various", "timestamp": "00:06:07,084", "timestamp_s": 367.0}, {"text": "reasons, both predictable and unpredictable.", "timestamp": "00:06:10,988", "timestamp_s": 370.0}, {"text": "For predictable reasons, there could be different scheduled", "timestamp": "00:06:15,084", "timestamp_s": 375.0}, {"text": "events or planned events like product launches,", "timestamp": "00:06:19,316", "timestamp_s": 379.0}, {"text": "sales, promotions, marketing campaigns,", "timestamp": "00:06:22,916", "timestamp_s": 382.0}, {"text": "or even regular peak hours can lead", "timestamp": "00:06:26,574", "timestamp_s": 386.0}, {"text": "to a surge in traffic as users try", "timestamp": "00:06:30,614", "timestamp_s": 390.0}, {"text": "to access the service or website simultaneously.", "timestamp": "00:06:33,934", "timestamp_s": 393.0}, {"text": "Another reason is seasonal traffic.", "timestamp": "00:06:39,454", "timestamp_s": 399.0}, {"text": "Businesses in specific industries might experience", "timestamp": "00:06:42,790", "timestamp_s": 402.0}, {"text": "seasonal spikes in traffic. For example,", "timestamp": "00:06:47,494", "timestamp_s": 407.0}, {"text": "e commerce sites might see", "timestamp": "00:06:50,606", "timestamp_s": 410.0}, {"text": "a search during holidays or", "timestamp": "00:06:54,248", "timestamp_s": 414.0}, {"text": "back to school seasons. The next one is", "timestamp": "00:06:57,856", "timestamp_s": 417.0}, {"text": "the time of day or week.", "timestamp": "00:07:01,768", "timestamp_s": 421.0}, {"text": "Traffic patterns can change regularly depending", "timestamp": "00:07:05,024", "timestamp_s": 425.0}, {"text": "on the target audience and service type.", "timestamp": "00:07:09,264", "timestamp_s": 429.0}, {"text": "For example, social media platforms see", "timestamp": "00:07:13,280", "timestamp_s": 433.0}, {"text": "higher traffic during evenings or weekends", "timestamp": "00:07:17,000", "timestamp_s": 437.0}, {"text": "for unpredictable reasons. There could be different", "timestamp": "00:07:21,874", "timestamp_s": 441.0}, {"text": "viral events like social media trends,", "timestamp": "00:07:27,050", "timestamp_s": 447.0}, {"text": "news articles, or influencer mentions can", "timestamp": "00:07:31,562", "timestamp_s": 451.0}, {"text": "drive sudden traffic bursts to a website", "timestamp": "00:07:36,066", "timestamp_s": 456.0}, {"text": "or service. Also, there could be different", "timestamp": "00:07:39,762", "timestamp_s": 459.0}, {"text": "technical issues. For instance,", "timestamp": "00:07:44,354", "timestamp_s": 464.0}, {"text": "system outages on competitor platforms", "timestamp": "00:07:47,014", "timestamp_s": 467.0}, {"text": "can lead to users flocking", "timestamp": "00:07:51,462", "timestamp_s": 471.0}, {"text": "to a service, causing a temporary spike.", "timestamp": "00:07:54,782", "timestamp_s": 474.0}, {"text": "Another very popular reason is denial of service", "timestamp": "00:07:58,054", "timestamp_s": 478.0}, {"text": "attacks. It is when malicious actors might", "timestamp": "00:08:02,030", "timestamp_s": 482.0}, {"text": "attempt to overwhelm a system with traffic,", "timestamp": "00:08:06,310", "timestamp_s": 486.0}, {"text": "causing a spike and potentially disrupting", "timestamp": "00:08:10,566", "timestamp_s": 490.0}, {"text": "functionalities. The next one is bot", "timestamp": "00:08:14,062", "timestamp_s": 494.0}, {"text": "activity. Automated bots or", "timestamp": "00:08:17,336", "timestamp_s": 497.0}, {"text": "scripts can cause unexpected bursts,", "timestamp": "00:08:21,968", "timestamp_s": 501.0}, {"text": "especially if they are scrapping data or attempting", "timestamp": "00:08:25,880", "timestamp_s": 505.0}, {"text": "to exploit vulnerabilities. There could also be", "timestamp": "00:08:30,024", "timestamp_s": 510.0}, {"text": "issues with external dependencies. For instance,", "timestamp": "00:08:34,512", "timestamp_s": 514.0}, {"text": "if your service relies on external", "timestamp": "00:08:38,944", "timestamp_s": 518.0}, {"text": "APIs or services,", "timestamp": "00:08:42,808", "timestamp_s": 522.0}, {"text": "outages or slowdowns on their end can", "timestamp": "00:08:45,464", "timestamp_s": 525.0}, {"text": "lead to a cascading effect and cause traffic", "timestamp": "00:08:49,112", "timestamp_s": 529.0}, {"text": "spikes for your users trying to access features", "timestamp": "00:08:53,488", "timestamp_s": 533.0}, {"text": "that depend on those external services.", "timestamp": "00:08:57,120", "timestamp_s": 537.0}, {"text": "By understanding these potential causes, you can", "timestamp": "00:09:00,944", "timestamp_s": 540.0}, {"text": "better prepare for traffic bursts. Well,", "timestamp": "00:09:04,480", "timestamp_s": 544.0}, {"text": "now let\u0027s look at the example of server", "timestamp": "00:09:07,942", "timestamp_s": 547.0}, {"text": "overload. To demonstrate this,", "timestamp": "00:09:11,814", "timestamp_s": 551.0}, {"text": "I implemented a simple HTTP service in", "timestamp": "00:09:15,694", "timestamp_s": 555.0}, {"text": "go. The main function sets up an", "timestamp": "00:09:18,942", "timestamp_s": 558.0}, {"text": "HTTP server that listens on port 8000.", "timestamp": "00:09:22,574", "timestamp_s": 562.0}, {"text": "It registers a single root", "timestamp": "00:09:27,574", "timestamp_s": 567.0}, {"text": "with a handler function. The handler function attempts", "timestamp": "00:09:31,502", "timestamp_s": 571.0}, {"text": "to extract a path parameter length from", "timestamp": "00:09:35,540", "timestamp_s": 575.0}, {"text": "the requests, convert it to an integer value", "timestamp": "00:09:39,244", "timestamp_s": 579.0}, {"text": "and use it to generate a password.", "timestamp": "00:09:44,724", "timestamp_s": 584.0}, {"text": "If the length parameter cannot be converted to an integer,", "timestamp": "00:09:48,628", "timestamp_s": 588.0}, {"text": "for example, if it\u0027s not a number, the function", "timestamp": "00:09:52,284", "timestamp_s": 592.0}, {"text": "responds with 400 status.", "timestamp": "00:09:55,732", "timestamp_s": 595.0}, {"text": "If the length parameter is successfully", "timestamp": "00:09:59,044", "timestamp_s": 599.0}, {"text": "converted to an integer, the function generates a password", "timestamp": "00:10:02,380", "timestamp_s": 602.0}, {"text": "of that length and then generated password is sent back to", "timestamp": "00:10:06,116", "timestamp_s": 606.0}, {"text": "the client with 200 status.", "timestamp": "00:10:10,380", "timestamp_s": 610.0}, {"text": "I use the docker container to run this service", "timestamp": "00:10:13,364", "timestamp_s": 613.0}, {"text": "because it allows us to simulate limited", "timestamp": "00:10:18,044", "timestamp_s": 618.0}, {"text": "resources. You will see it in the next slide.", "timestamp": "00:10:21,932", "timestamp_s": 621.0}, {"text": "I built and run the service using this", "timestamp": "00:10:25,884", "timestamp_s": 625.0}, {"text": "simple dockerfile, the application using", "timestamp": "00:10:29,644", "timestamp_s": 629.0}, {"text": "the Golang image in the build stage, and then it", "timestamp": "00:10:33,668", "timestamp_s": 633.0}, {"text": "uses the distr less base image from", "timestamp": "00:10:37,492", "timestamp_s": 637.0}, {"text": "Google\u0027s container registry to run the service.", "timestamp": "00:10:40,988", "timestamp_s": 640.0}, {"text": "This image contains only the application and its", "timestamp": "00:10:46,204", "timestamp_s": 646.0}, {"text": "runtime dependencies, and it is", "timestamp": "00:10:50,460", "timestamp_s": 650.0}, {"text": "designed to be as small as possible.", "timestamp": "00:10:54,270", "timestamp_s": 654.0}, {"text": "Then I built a docker image from", "timestamp": "00:10:57,294", "timestamp_s": 657.0}, {"text": "the dockerfile. I set the", "timestamp": "00:11:00,958", "timestamp_s": 660.0}, {"text": "cpu option to one to limit", "timestamp": "00:11:04,526", "timestamp_s": 664.0}, {"text": "the number of cpu cores that also", "timestamp": "00:11:08,246", "timestamp_s": 668.0}, {"text": "I set two options, memory and memory.", "timestamp": "00:11:12,142", "timestamp_s": 672.0}, {"text": "Swap 300 megabytes to limit the", "timestamp": "00:11:15,358", "timestamp_s": 675.0}, {"text": "containers memory. I have to set", "timestamp": "00:11:18,918", "timestamp_s": 678.0}, {"text": "both options to the same value to prevent", "timestamp": "00:11:22,776", "timestamp_s": 682.0}, {"text": "the container from using. When we", "timestamp": "00:11:26,704", "timestamp_s": 686.0}, {"text": "have a running service, we need to test", "timestamp": "00:11:30,160", "timestamp_s": 690.0}, {"text": "for that I use a load testing tool called Grafana", "timestamp": "00:11:33,984", "timestamp_s": 693.0}, {"text": "k six. Here is a script that is", "timestamp": "00:11:38,488", "timestamp_s": 698.0}, {"text": "used by this tool. It is just a simple JavaScript file", "timestamp": "00:11:41,704", "timestamp_s": 701.0}, {"text": "with some configuration for the test.", "timestamp": "00:11:46,404", "timestamp_s": 706.0}, {"text": "The test consists of four stages. In the", "timestamp": "00:11:50,564", "timestamp_s": 710.0}, {"text": "stage one, we gracefully increase the number of virtual", "timestamp": "00:11:54,348", "timestamp_s": 714.0}, {"text": "users from zero to 1000", "timestamp": "00:11:58,140", "timestamp_s": 718.0}, {"text": "for two minutes, and then in stage", "timestamp": "00:12:02,484", "timestamp_s": 722.0}, {"text": "two we keep the number of users at 1000", "timestamp": "00:12:06,380", "timestamp_s": 726.0}, {"text": "for another two minutes. In the stage three,", "timestamp": "00:12:10,484", "timestamp_s": 730.0}, {"text": "we ramp up to 2000", "timestamp": "00:12:14,706", "timestamp_s": 734.0}, {"text": "virtual users for two minutes. And finally in", "timestamp": "00:12:18,626", "timestamp_s": 738.0}, {"text": "stage four we keep the number of users at 2000", "timestamp": "00:12:22,210", "timestamp_s": 742.0}, {"text": "for another two minutes.", "timestamp": "00:12:27,354", "timestamp_s": 747.0}, {"text": "In the default function, we define the user logic.", "timestamp": "00:12:30,234", "timestamp_s": 750.0}, {"text": "Each virtual user makes a get request to", "timestamp": "00:12:35,034", "timestamp_s": 755.0}, {"text": "the service to generate a password. Then the user sleeps", "timestamp": "00:12:38,258", "timestamp_s": 758.0}, {"text": "for 100 milliseconds that", "timestamp": "00:12:42,610", "timestamp_s": 762.0}, {"text": "simulates approximately ten requests per second", "timestamp": "00:12:46,186", "timestamp_s": 766.0}, {"text": "from a single user. After that,", "timestamp": "00:12:49,994", "timestamp_s": 769.0}, {"text": "I just run the test using this command for", "timestamp": "00:12:54,114", "timestamp_s": 774.0}, {"text": "it to end. I also use a web dashboard", "timestamp": "00:12:58,754", "timestamp_s": 778.0}, {"text": "as an output to visualize the test results.", "timestamp": "00:13:02,946", "timestamp_s": 782.0}, {"text": "It produces graphs showing the number", "timestamp": "00:13:06,904", "timestamp_s": 786.0}, {"text": "of requests latency and other", "timestamp": "00:13:10,584", "timestamp_s": 790.0}, {"text": "metrics. In the graph, we can", "timestamp": "00:13:13,976", "timestamp_s": 793.0}, {"text": "see how latency changes depending on", "timestamp": "00:13:17,864", "timestamp_s": 797.0}, {"text": "the number of requests per second.", "timestamp": "00:13:21,400", "timestamp_s": 801.0}, {"text": "Initially, we gracefully increased the number of users and", "timestamp": "00:13:24,304", "timestamp_s": 804.0}, {"text": "the service could handle that load. The latency", "timestamp": "00:13:28,512", "timestamp_s": 808.0}, {"text": "was very low and then after four minutes", "timestamp": "00:13:31,808", "timestamp_s": 811.0}, {"text": "we increased the number of users up to 2000", "timestamp": "00:13:35,538", "timestamp_s": 815.0}, {"text": "and the service started to experience", "timestamp": "00:13:39,322", "timestamp_s": 819.0}, {"text": "a lack of resources. That led to a significant increase", "timestamp": "00:13:42,666", "timestamp_s": 822.0}, {"text": "in latency and the server became overloaded.", "timestamp": "00:13:46,794", "timestamp_s": 826.0}, {"text": "In the following graph we can see the latency distribution", "timestamp": "00:13:51,394", "timestamp_s": 831.0}, {"text": "by percentile. From these results we can understand", "timestamp": "00:13:56,434", "timestamp_s": 836.0}, {"text": "that when we use system resources at maximum,", "timestamp": "00:14:01,564", "timestamp_s": 841.0}, {"text": "the latency significantly increases many times.", "timestamp": "00:14:06,164", "timestamp_s": 846.0}, {"text": "But this is just an artificial example.", "timestamp": "00:14:10,604", "timestamp_s": 850.0}, {"text": "In the actual application the latency", "timestamp": "00:14:13,724", "timestamp_s": 853.0}, {"text": "might be higher and there will", "timestamp": "00:14:17,732", "timestamp_s": 857.0}, {"text": "likely be some timeout on the client side that will", "timestamp": "00:14:21,292", "timestamp_s": 861.0}, {"text": "drop requests and make the service unavailable", "timestamp": "00:14:24,644", "timestamp_s": 864.0}, {"text": "for users. We have discussed server overload", "timestamp": "00:14:28,428", "timestamp_s": 868.0}, {"text": "and its causes. Also we saw what it looks like", "timestamp": "00:14:32,252", "timestamp_s": 872.0}, {"text": "in the example. Now lets look at the first", "timestamp": "00:14:36,188", "timestamp_s": 876.0}, {"text": "technique that can be used in this situation.", "timestamp": "00:14:39,884", "timestamp_s": 879.0}, {"text": "First I want to discuss rate limiting.", "timestamp": "00:14:44,524", "timestamp_s": 884.0}, {"text": "Sometimes it also called throttling,", "timestamp": "00:14:48,164", "timestamp_s": 888.0}, {"text": "so these terms may be used interchangeably.", "timestamp": "00:14:52,044", "timestamp_s": 892.0}, {"text": "Rate limiting is a technique used to control", "timestamp": "00:14:55,994", "timestamp_s": 895.0}, {"text": "the flow of requests to a network,", "timestamp": "00:15:00,354", "timestamp_s": 900.0}, {"text": "resource server or API.", "timestamp": "00:15:04,594", "timestamp_s": 904.0}, {"text": "It essentially sets a limit on how often a user", "timestamp": "00:15:08,234", "timestamp_s": 908.0}, {"text": "or application can perform a specific", "timestamp": "00:15:12,634", "timestamp_s": 912.0}, {"text": "action within a given time frame.", "timestamp": "00:15:16,922", "timestamp_s": 916.0}, {"text": "It protects against malicious activities like denial", "timestamp": "00:15:20,234", "timestamp_s": 920.0}, {"text": "of service attacks where attackers try to overwhelm", "timestamp": "00:15:23,674", "timestamp_s": 923.0}, {"text": "a system with excessive requests,", "timestamp": "00:15:28,308", "timestamp_s": 928.0}, {"text": "making it unavailable to legitimate users.", "timestamp": "00:15:31,972", "timestamp_s": 931.0}, {"text": "Also, it helps ensure fair access", "timestamp": "00:15:35,148", "timestamp_s": 935.0}, {"text": "to resources by preventing single users", "timestamp": "00:15:38,308", "timestamp_s": 938.0}, {"text": "or applications for monopolizing them.", "timestamp": "00:15:42,364", "timestamp_s": 942.0}, {"text": "It is especially important when the", "timestamp": "00:15:45,692", "timestamp_s": 945.0}, {"text": "service for services with limited resources", "timestamp": "00:15:50,284", "timestamp_s": 950.0}, {"text": "by controlling the request rate. Rate limiting prevents", "timestamp": "00:15:54,754", "timestamp_s": 954.0}, {"text": "overloading the server and helps", "timestamp": "00:15:58,882", "timestamp_s": 958.0}, {"text": "maintain optimal performance for all users.", "timestamp": "00:16:02,354", "timestamp_s": 962.0}, {"text": "We can limit the request rate per an IP", "timestamp": "00:16:06,474", "timestamp_s": 966.0}, {"text": "address or a user identifier,", "timestamp": "00:16:10,570", "timestamp_s": 970.0}, {"text": "an API key, or other criteria depending", "timestamp": "00:16:13,738", "timestamp_s": 973.0}, {"text": "on a particular use case. For example,", "timestamp": "00:16:17,994", "timestamp_s": 977.0}, {"text": "we can load ten requests per minute from", "timestamp": "00:16:22,114", "timestamp_s": 982.0}, {"text": "a single IP address, and if the number", "timestamp": "00:16:25,778", "timestamp_s": 985.0}, {"text": "of requests per minute is less or equal to", "timestamp": "00:16:29,370", "timestamp_s": 989.0}, {"text": "that value, we process a request.", "timestamp": "00:16:32,714", "timestamp_s": 992.0}, {"text": "Otherwise, if the limit is exceeded,", "timestamp": "00:16:36,602", "timestamp_s": 996.0}, {"text": "we will drop the request. There are many", "timestamp": "00:16:40,626", "timestamp_s": 1000.0}, {"text": "algorithms and variations of them", "timestamp": "00:16:44,394", "timestamp_s": 1004.0}, {"text": "for implementing rate limiting. I\u0027ll briefly review", "timestamp": "00:16:48,274", "timestamp_s": 1008.0}, {"text": "just the most common of them.", "timestamp": "00:16:52,426", "timestamp_s": 1012.0}, {"text": "One is the fixed window counter algorithm.", "timestamp": "00:16:55,554", "timestamp_s": 1015.0}, {"text": "This algorithm divides time into equal sized", "timestamp": "00:17:00,034", "timestamp_s": 1020.0}, {"text": "time intervals or fixed windows.", "timestamp": "00:17:05,194", "timestamp_s": 1025.0}, {"text": "The window size can be defined in milliseconds,", "timestamp": "00:17:09,554", "timestamp_s": 1029.0}, {"text": "seconds, minutes, or any other irrelevant unit", "timestamp": "00:17:13,578", "timestamp_s": 1033.0}, {"text": "depending on the use case. Each window", "timestamp": "00:17:17,184", "timestamp_s": 1037.0}, {"text": "has a request counter that allows the algorithm", "timestamp": "00:17:20,864", "timestamp_s": 1040.0}, {"text": "to keep track of how many requests occur", "timestamp": "00:17:25,072", "timestamp_s": 1045.0}, {"text": "within each window. As a request arrives,", "timestamp": "00:17:29,400", "timestamp_s": 1049.0}, {"text": "the algorithm checks the current timestamp.", "timestamp": "00:17:33,592", "timestamp_s": 1053.0}, {"text": "It decides which window the timestamp falls", "timestamp": "00:17:37,864", "timestamp_s": 1057.0}, {"text": "into based on the window", "timestamp": "00:17:41,320", "timestamp_s": 1061.0}, {"text": "size and the starting point on the current window.", "timestamp": "00:17:44,906", "timestamp_s": 1064.0}, {"text": "If the request falls within the current window,", "timestamp": "00:17:48,594", "timestamp_s": 1068.0}, {"text": "the counter for that window is incremented by one.", "timestamp": "00:17:52,122", "timestamp_s": 1072.0}, {"text": "Otherwise, a new window starts, the counter is", "timestamp": "00:17:56,514", "timestamp_s": 1076.0}, {"text": "reset to zero and incremented by", "timestamp": "00:18:00,138", "timestamp_s": 1080.0}, {"text": "one, and the start time of the window is updated.", "timestamp": "00:18:03,330", "timestamp_s": 1083.0}, {"text": "Then, if the counter value is less or equal to", "timestamp": "00:18:07,234", "timestamp_s": 1087.0}, {"text": "the limit, the rate limiter allows the request to", "timestamp": "00:18:10,842", "timestamp_s": 1090.0}, {"text": "be processed. Otherwise the request", "timestamp": "00:18:14,660", "timestamp_s": 1094.0}, {"text": "is dropped if the counter value exceeds the limit.", "timestamp": "00:18:17,876", "timestamp_s": 1097.0}, {"text": "The example on the slide shows", "timestamp": "00:18:22,364", "timestamp_s": 1102.0}, {"text": "that we have a 1 minute window size", "timestamp": "00:18:25,756", "timestamp_s": 1105.0}, {"text": "and set the rate limit to five requests", "timestamp": "00:18:29,276", "timestamp_s": 1109.0}, {"text": "per minute in each window. The first five", "timestamp": "00:18:32,788", "timestamp_s": 1112.0}, {"text": "requests were processed, all other requests", "timestamp": "00:18:36,540", "timestamp_s": 1116.0}, {"text": "were dropped. As you can see,", "timestamp": "00:18:40,718", "timestamp_s": 1120.0}, {"text": "this algorithm is quite simple.", "timestamp": "00:18:44,414", "timestamp_s": 1124.0}, {"text": "However, it has a big drawback which", "timestamp": "00:18:47,902", "timestamp_s": 1127.0}, {"text": "you have probably already noticed here.", "timestamp": "00:18:52,022", "timestamp_s": 1132.0}, {"text": "Since the counter is reset when the new window", "timestamp": "00:18:55,854", "timestamp_s": 1135.0}, {"text": "is started, the rate limiter doesn\u0027t know", "timestamp": "00:18:59,814", "timestamp_s": 1139.0}, {"text": "how many requests were", "timestamp": "00:19:03,094", "timestamp_s": 1143.0}, {"text": "made in the previous window. It leads to", "timestamp": "00:19:06,458", "timestamp_s": 1146.0}, {"text": "some issues. For example, in this picture,", "timestamp": "00:19:09,866", "timestamp_s": 1149.0}, {"text": "the total number of requests per minute was more than", "timestamp": "00:19:13,234", "timestamp_s": 1153.0}, {"text": "five because requests burst at", "timestamp": "00:19:17,266", "timestamp_s": 1157.0}, {"text": "the end of the second window and the beginning", "timestamp": "00:19:21,122", "timestamp_s": 1161.0}, {"text": "of the third window. The fixed window counter", "timestamp": "00:19:24,514", "timestamp_s": 1164.0}, {"text": "algorithm is easy to understand and implement because it", "timestamp": "00:19:28,466", "timestamp_s": 1168.0}, {"text": "only requires keeping track of a counter for", "timestamp": "00:19:31,906", "timestamp_s": 1171.0}, {"text": "each window. Also, it is efficient because", "timestamp": "00:19:35,712", "timestamp_s": 1175.0}, {"text": "it requires only basic counter operations and", "timestamp": "00:19:39,952", "timestamp_s": 1179.0}, {"text": "it has low memory usage because it only needs to", "timestamp": "00:19:44,712", "timestamp_s": 1184.0}, {"text": "store the counter value for a window, which is typically", "timestamp": "00:19:47,992", "timestamp_s": 1187.0}, {"text": "a small amount of data. However,", "timestamp": "00:19:51,824", "timestamp_s": 1191.0}, {"text": "request bursts are possible on edgest when", "timestamp": "00:19:55,904", "timestamp_s": 1195.0}, {"text": "switching between windows,", "timestamp": "00:20:01,044", "timestamp_s": 1201.0}, {"text": "and this algorithm is not suitable for", "timestamp": "00:20:04,012", "timestamp_s": 1204.0}, {"text": "identifying frequent requests since the counter is set", "timestamp": "00:20:08,372", "timestamp_s": 1208.0}, {"text": "at each window. The following algorithm", "timestamp": "00:20:12,716", "timestamp_s": 1212.0}, {"text": "is sliding window lock.", "timestamp": "00:20:17,084", "timestamp_s": 1217.0}, {"text": "It also uses a window, but this", "timestamp": "00:20:20,604", "timestamp_s": 1220.0}, {"text": "window slides a long time representing the", "timestamp": "00:20:24,436", "timestamp_s": 1224.0}, {"text": "relevant time frame. For rate limiting,", "timestamp": "00:20:28,316", "timestamp_s": 1228.0}, {"text": "the window size can be also defined", "timestamp": "00:20:32,084", "timestamp_s": 1232.0}, {"text": "in milliseconds, seconds, minutes, or any", "timestamp": "00:20:35,692", "timestamp_s": 1235.0}, {"text": "other relevant unit, depending on the use case.", "timestamp": "00:20:39,164", "timestamp_s": 1239.0}, {"text": "Instead of request counter, this algorithm", "timestamp": "00:20:42,804", "timestamp_s": 1242.0}, {"text": "keeps track of for each incoming request and", "timestamp": "00:20:46,324", "timestamp_s": 1246.0}, {"text": "stores it in the the log can", "timestamp": "00:20:50,692", "timestamp_s": 1250.0}, {"text": "be stored in a data structure like", "timestamp": "00:20:54,646", "timestamp_s": 1254.0}, {"text": "hash table or sorted", "timestamp": "00:20:58,006", "timestamp_s": 1258.0}, {"text": "set for efficient retrieval.", "timestamp": "00:21:01,678", "timestamp_s": 1261.0}, {"text": "As the window slides forward,", "timestamp": "00:21:05,334", "timestamp_s": 1265.0}, {"text": "timestamps outside the current window become", "timestamp": "00:21:08,494", "timestamp_s": 1268.0}, {"text": "irrelevant for rate limiting purposes", "timestamp": "00:21:13,126", "timestamp_s": 1273.0}, {"text": "and removed from the log.", "timestamp": "00:21:17,254", "timestamp_s": 1277.0}, {"text": "A new request arrives. Each timestamp", "timestamp": "00:21:20,464", "timestamp_s": 1280.0}, {"text": "is added to the log. The algorithm", "timestamp": "00:21:24,680", "timestamp_s": 1284.0}, {"text": "calculates the total number of requests within the current window", "timestamp": "00:21:28,384", "timestamp_s": 1288.0}, {"text": "by iterating through the remaining timestamps", "timestamp": "00:21:32,472", "timestamp_s": 1292.0}, {"text": "in the log to decide if the request should be allowed.", "timestamp": "00:21:35,520", "timestamp_s": 1295.0}, {"text": "The request is processed in. The total count", "timestamp": "00:21:40,504", "timestamp_s": 1300.0}, {"text": "within the window is less than", "timestamp": "00:21:44,532", "timestamp_s": 1304.0}, {"text": "or equal to the allowed limit.", "timestamp": "00:21:48,476", "timestamp_s": 1308.0}, {"text": "Otherwise, it\u0027s considered a rate limit", "timestamp": "00:21:52,324", "timestamp_s": 1312.0}, {"text": "violation and might be rejected.", "timestamp": "00:21:55,572", "timestamp_s": 1315.0}, {"text": "Let\u0027s look at the example.", "timestamp": "00:21:58,940", "timestamp_s": 1318.0}, {"text": "In this example, we allow two requests", "timestamp": "00:22:02,524", "timestamp_s": 1322.0}, {"text": "per minute when the first requests when", "timestamp": "00:22:07,252", "timestamp_s": 1327.0}, {"text": "the first request is saved to the lock,", "timestamp": "00:22:11,302", "timestamp_s": 1331.0}, {"text": "there is only one request in the lock at", "timestamp": "00:22:14,862", "timestamp_s": 1334.0}, {"text": "that point in time, so the request is allowed", "timestamp": "00:22:18,350", "timestamp_s": 1338.0}, {"text": "and processed. Then the second", "timestamp": "00:22:22,134", "timestamp_s": 1342.0}, {"text": "request comes and each timestamp is", "timestamp": "00:22:25,566", "timestamp_s": 1345.0}, {"text": "saved to the lock as well. Now there are two", "timestamp": "00:22:29,646", "timestamp_s": 1349.0}, {"text": "requests in the lock. All of them fall within", "timestamp": "00:22:34,054", "timestamp_s": 1354.0}, {"text": "the current window, so the number of requests", "timestamp": "00:22:37,406", "timestamp_s": 1357.0}, {"text": "is equal to the limit and the request can be processed.", "timestamp": "00:22:40,570", "timestamp_s": 1360.0}, {"text": "Then the third request comes and each timestamp", "timestamp": "00:22:45,194", "timestamp_s": 1365.0}, {"text": "is saved to the lock. Now there are three requests", "timestamp": "00:22:49,634", "timestamp_s": 1369.0}, {"text": "that fall into the current window,", "timestamp": "00:22:53,538", "timestamp_s": 1373.0}, {"text": "then the limit, so the request is rejected,", "timestamp": "00:22:57,234", "timestamp_s": 1377.0}, {"text": "and finally the fourth request comes comes.", "timestamp": "00:23:01,578", "timestamp_s": 1381.0}, {"text": "Each timestamp is also saved to the lock.", "timestamp": "00:23:05,704", "timestamp_s": 1385.0}, {"text": "There are only two requests that fall within the", "timestamp": "00:23:10,144", "timestamp_s": 1390.0}, {"text": "current window at that point in time,", "timestamp": "00:23:13,992", "timestamp_s": 1393.0}, {"text": "and there are two all", "timestamp": "00:23:17,432", "timestamp_s": 1397.0}, {"text": "timestamps that do not fall into the current window.", "timestamp": "00:23:21,424", "timestamp_s": 1401.0}, {"text": "The old timestamps are removed from", "timestamp": "00:23:25,384", "timestamp_s": 1405.0}, {"text": "the lock and the new request is allowed and", "timestamp": "00:23:28,752", "timestamp_s": 1408.0}, {"text": "processed. Because the number of requests in", "timestamp": "00:23:33,710", "timestamp_s": 1413.0}, {"text": "the current window equals the limit,", "timestamp": "00:23:37,318", "timestamp_s": 1417.0}, {"text": "the algorithm captures recent surges in requests", "timestamp": "00:23:40,494", "timestamp_s": 1420.0}, {"text": "more accurately than the fixed window counter because", "timestamp": "00:23:46,046", "timestamp_s": 1426.0}, {"text": "it considers only relevant requests within the", "timestamp": "00:23:50,630", "timestamp_s": 1430.0}, {"text": "sliding window can effectively handle bursts", "timestamp": "00:23:54,542", "timestamp_s": 1434.0}, {"text": "of requests. However, storing timestamps", "timestamp": "00:23:58,294", "timestamp_s": 1438.0}, {"text": "for all requests requires", "timestamp": "00:24:02,576", "timestamp_s": 1442.0}, {"text": "a lot of memory and it can be memory", "timestamp": "00:24:06,224", "timestamp_s": 1446.0}, {"text": "intensive, especially for high requests", "timestamp": "00:24:09,824", "timestamp_s": 1449.0}, {"text": "volumes. Also, it\u0027s more complex because it", "timestamp": "00:24:13,496", "timestamp_s": 1453.0}, {"text": "requires maintenance and iteration through the request", "timestamp": "00:24:17,176", "timestamp_s": 1457.0}, {"text": "log following algorithm is", "timestamp": "00:24:20,960", "timestamp_s": 1460.0}, {"text": "called sliding window counter.", "timestamp": "00:24:24,512", "timestamp_s": 1464.0}, {"text": "It offers a balance between simplicity", "timestamp": "00:24:28,804", "timestamp_s": 1468.0}, {"text": "and accuracy compared to fixed window", "timestamp": "00:24:32,740", "timestamp_s": 1472.0}, {"text": "counter and sliding window log algorithms.", "timestamp": "00:24:36,516", "timestamp_s": 1476.0}, {"text": "The algorithm maintains a counter variable", "timestamp": "00:24:39,724", "timestamp_s": 1479.0}, {"text": "and fixit size window duration similar", "timestamp": "00:24:44,092", "timestamp_s": 1484.0}, {"text": "to the fixed window counter, but in addition,", "timestamp": "00:24:47,804", "timestamp_s": 1487.0}, {"text": "it uses a sliding window to represent", "timestamp": "00:24:51,948", "timestamp_s": 1491.0}, {"text": "the relevant time frame for", "timestamp": "00:24:55,602", "timestamp_s": 1495.0}, {"text": "rate limiting. Unlike the sliding window", "timestamp": "00:24:59,266", "timestamp_s": 1499.0}, {"text": "log algorithm, it doesn\u0027t sort for", "timestamp": "00:25:02,738", "timestamp_s": 1502.0}, {"text": "all requests. Instead, it keeps track of", "timestamp": "00:25:06,570", "timestamp_s": 1506.0}, {"text": "the counters for fixed window and calculates a", "timestamp": "00:25:10,594", "timestamp_s": 1510.0}, {"text": "weighted counter for the sliding window.", "timestamp": "00:25:14,202", "timestamp_s": 1514.0}, {"text": "When a new request arrives. The algorithm calculates", "timestamp": "00:25:17,754", "timestamp_s": 1517.0}, {"text": "a weighted counter using the sliding window time frame", "timestamp": "00:25:21,846", "timestamp_s": 1521.0}, {"text": "and request counters for the previous and current", "timestamp": "00:25:25,878", "timestamp_s": 1525.0}, {"text": "windows. For that, it uses a percent", "timestamp": "00:25:29,294", "timestamp_s": 1529.0}, {"text": "of time. The sliding window overlaps with", "timestamp": "00:25:32,822", "timestamp_s": 1532.0}, {"text": "the previous fixit window, the number of requests", "timestamp": "00:25:36,542", "timestamp_s": 1536.0}, {"text": "from the previous fixit window, and the number of requests", "timestamp": "00:25:40,590", "timestamp_s": 1540.0}, {"text": "from the current fixit window. You can see", "timestamp": "00:25:44,790", "timestamp_s": 1544.0}, {"text": "the formula on the slide. The resulting", "timestamp": "00:25:47,980", "timestamp_s": 1547.0}, {"text": "value of these calculations is a", "timestamp": "00:25:51,644", "timestamp_s": 1551.0}, {"text": "weighted counter. Then, the algorithm", "timestamp": "00:25:54,732", "timestamp_s": 1554.0}, {"text": "compares the weighted counter with the limit value.", "timestamp": "00:25:58,196", "timestamp_s": 1558.0}, {"text": "The request is allowed and processed if", "timestamp": "00:26:02,924", "timestamp_s": 1562.0}, {"text": "the counter is less or equal to the limit.", "timestamp": "00:26:06,300", "timestamp_s": 1566.0}, {"text": "Otherwise, the request is dropped.", "timestamp": "00:26:09,964", "timestamp_s": 1569.0}, {"text": "The old counters from previous fixed windows", "timestamp": "00:26:13,214", "timestamp_s": 1573.0}, {"text": "are removed from tracking when they are", "timestamp": "00:26:16,566", "timestamp_s": 1576.0}, {"text": "no longer relevant for a sliding window. The algorithm", "timestamp": "00:26:20,126", "timestamp_s": 1580.0}, {"text": "captures recent requests rate trends", "timestamp": "00:26:24,574", "timestamp_s": 1584.0}, {"text": "more accurately than the fixed window", "timestamp": "00:26:28,158", "timestamp_s": 1588.0}, {"text": "counter as it considers requests that", "timestamp": "00:26:31,542", "timestamp_s": 1591.0}, {"text": "fall within the sliding window. Also, it avoids", "timestamp": "00:26:35,526", "timestamp_s": 1595.0}, {"text": "storing timestamps for all requests,", "timestamp": "00:26:39,590", "timestamp_s": 1599.0}, {"text": "make it more memory efficient and", "timestamp": "00:26:42,962", "timestamp_s": 1602.0}, {"text": "easier to implement than sliding window log", "timestamp": "00:26:46,258", "timestamp_s": 1606.0}, {"text": "algorithm. However, it is", "timestamp": "00:26:50,354", "timestamp_s": 1610.0}, {"text": "less precise than sliding window log algorithm.", "timestamp": "00:26:53,554", "timestamp_s": 1613.0}, {"text": "The next algorithm is as", "timestamp": "00:26:57,874", "timestamp_s": 1617.0}, {"text": "you can see from the name, it uses a concept", "timestamp": "00:27:01,730", "timestamp_s": 1621.0}, {"text": "of a bucket that contains tokens.", "timestamp": "00:27:06,014", "timestamp_s": 1626.0}, {"text": "The bucket has a fixed size", "timestamp": "00:27:10,174", "timestamp_s": 1630.0}, {"text": "representing the maximum number of tokens it can hold.", "timestamp": "00:27:14,134", "timestamp_s": 1634.0}, {"text": "Each token represents a capacity to process", "timestamp": "00:27:19,014", "timestamp_s": 1639.0}, {"text": "a single request. In other words,", "timestamp": "00:27:22,462", "timestamp_s": 1642.0}, {"text": "the bucket size defines a maximum number of requests", "timestamp": "00:27:25,782", "timestamp_s": 1645.0}, {"text": "the system can handle at a time.", "timestamp": "00:27:29,710", "timestamp_s": 1649.0}, {"text": "So the bucket size represents rate limit.", "timestamp": "00:27:33,834", "timestamp_s": 1653.0}, {"text": "The bucket is constantly refilled with new tokens", "timestamp": "00:27:37,994", "timestamp_s": 1657.0}, {"text": "at a constant rate called the refill rate, which defines", "timestamp": "00:27:41,962", "timestamp_s": 1661.0}, {"text": "how quickly the bucket refills", "timestamp": "00:27:46,346", "timestamp_s": 1666.0}, {"text": "with tokens over time, ten tokens per", "timestamp": "00:27:49,626", "timestamp_s": 1669.0}, {"text": "second. Therefore, the refill rate controls", "timestamp": "00:27:53,578", "timestamp_s": 1673.0}, {"text": "the average rate at which request can be processed.", "timestamp": "00:27:57,402", "timestamp_s": 1677.0}, {"text": "Processed when a request arrives, the algorithm", "timestamp": "00:28:01,170", "timestamp_s": 1681.0}, {"text": "checks if there are enough tokens in the bucket.", "timestamp": "00:28:05,650", "timestamp_s": 1685.0}, {"text": "If there are tokens in the bucket, it consumes a token or removes", "timestamp": "00:28:09,242", "timestamp_s": 1689.0}, {"text": "it from the bucket and allows to be", "timestamp": "00:28:13,442", "timestamp_s": 1693.0}, {"text": "processed. Otherwise, if the bucket", "timestamp": "00:28:17,314", "timestamp_s": 1697.0}, {"text": "is empty, the request is dropped.", "timestamp": "00:28:20,562", "timestamp_s": 1700.0}, {"text": "On the one hand, this algorithm is relatively easy to implement.", "timestamp": "00:28:25,194", "timestamp_s": 1705.0}, {"text": "However, it is also slightly more complex", "timestamp": "00:28:29,242", "timestamp_s": 1709.0}, {"text": "due to the token management logic.", "timestamp": "00:28:32,718", "timestamp_s": 1712.0}, {"text": "It is efficient and uses low memory because", "timestamp": "00:28:36,374", "timestamp_s": 1716.0}, {"text": "it keeps tracks of the bucket size, which is typically just", "timestamp": "00:28:39,526", "timestamp_s": 1719.0}, {"text": "a number that is incremented or documented over", "timestamp": "00:28:43,078", "timestamp_s": 1723.0}, {"text": "time. It allows", "timestamp": "00:28:47,326", "timestamp_s": 1727.0}, {"text": "for a smooth distribution of requests,", "timestamp": "00:28:51,070", "timestamp_s": 1731.0}, {"text": "but bursts of requests up to the bucket\u0027s capacitor", "timestamp": "00:28:55,094", "timestamp_s": 1735.0}, {"text": "possible in cases when the bucket", "timestamp": "00:28:59,398", "timestamp_s": 1739.0}, {"text": "is full and a large number of requests arrive", "timestamp": "00:29:02,782", "timestamp_s": 1742.0}, {"text": "simultaneously. And finally, the last", "timestamp": "00:29:06,566", "timestamp_s": 1746.0}, {"text": "algorithm for today is leaky", "timestamp": "00:29:10,078", "timestamp_s": 1750.0}, {"text": "bucket algorithm. It also uses", "timestamp": "00:29:13,294", "timestamp_s": 1753.0}, {"text": "the concept of a bucket, but in a", "timestamp": "00:29:17,358", "timestamp_s": 1757.0}, {"text": "different way. It is like the analogy of", "timestamp": "00:29:20,614", "timestamp_s": 1760.0}, {"text": "a bucket with a hole at", "timestamp": "00:29:25,174", "timestamp_s": 1765.0}, {"text": "the bottom that constantly leaks at a fixed", "timestamp": "00:29:28,840", "timestamp_s": 1768.0}, {"text": "rate. The bucket can hold a", "timestamp": "00:29:32,256", "timestamp_s": 1772.0}, {"text": "specific number of requests representing its", "timestamp": "00:29:36,624", "timestamp_s": 1776.0}, {"text": "maximum capacity. The requests leak", "timestamp": "00:29:40,680", "timestamp_s": 1780.0}, {"text": "out from the bucket at a fixed rate.", "timestamp": "00:29:45,232", "timestamp_s": 1785.0}, {"text": "This leak rate specifies sustain", "timestamp": "00:29:49,584", "timestamp_s": 1789.0}, {"text": "it rate at which the system can process requests.", "timestamp": "00:29:53,024", "timestamp_s": 1793.0}, {"text": "When a request arrives and the bucket", "timestamp": "00:29:57,544", "timestamp_s": 1797.0}, {"text": "is not full, a new request is added to", "timestamp": "00:30:01,312", "timestamp_s": 1801.0}, {"text": "the bucket and processed. If the bucket", "timestamp": "00:30:04,408", "timestamp_s": 1804.0}, {"text": "is full, the request is dropped.", "timestamp": "00:30:07,712", "timestamp_s": 1807.0}, {"text": "The liquor bucket algorithm is good at", "timestamp": "00:30:11,104", "timestamp_s": 1811.0}, {"text": "smoothing out requests because the requests", "timestamp": "00:30:14,704", "timestamp_s": 1814.0}, {"text": "leak out and processed at a controlled", "timestamp": "00:30:18,434", "timestamp_s": 1818.0}, {"text": "rate, preventing surges or bursts", "timestamp": "00:30:22,738", "timestamp_s": 1822.0}, {"text": "of traffic. However, it doesn\u0027t", "timestamp": "00:30:26,858", "timestamp_s": 1826.0}, {"text": "account for the time between requests,", "timestamp": "00:30:30,914", "timestamp_s": 1830.0}, {"text": "which means if a user sends a", "timestamp": "00:30:34,442", "timestamp_s": 1834.0}, {"text": "burst of requests quickly,", "timestamp": "00:30:38,210", "timestamp_s": 1838.0}, {"text": "it all be dropped, even if", "timestamp": "00:30:40,954", "timestamp_s": 1840.0}, {"text": "they are under the overall rate", "timestamp": "00:30:44,326", "timestamp_s": 1844.0}, {"text": "limit. We have reviewed rate", "timestamp": "00:30:47,862", "timestamp_s": 1847.0}, {"text": "limiting algorithms. Each algorithm", "timestamp": "00:30:52,598", "timestamp_s": 1852.0}, {"text": "has pros and cons, so you should consider", "timestamp": "00:30:56,398", "timestamp_s": 1856.0}, {"text": "trade offs based on the particular use", "timestamp": "00:31:01,094", "timestamp_s": 1861.0}, {"text": "case when choosing an algorithm for rate limiting.", "timestamp": "00:31:04,958", "timestamp_s": 1864.0}, {"text": "Also, each algorithm may", "timestamp": "00:31:09,394", "timestamp_s": 1869.0}, {"text": "be implemented differently depending", "timestamp": "00:31:13,290", "timestamp_s": 1873.0}, {"text": "on the requirements. Now let\u0027s look", "timestamp": "00:31:16,954", "timestamp_s": 1876.0}, {"text": "at the simple implementation of a rate limiter based", "timestamp": "00:31:20,530", "timestamp_s": 1880.0}, {"text": "on the token bucket algorithm.", "timestamp": "00:31:24,666", "timestamp_s": 1884.0}, {"text": "For the example, I implemented the", "timestamp": "00:31:27,474", "timestamp_s": 1887.0}, {"text": "rate limiter logic in a separate package.", "timestamp": "00:31:31,586", "timestamp_s": 1891.0}, {"text": "Here I use the bucketstruct as", "timestamp": "00:31:35,134", "timestamp_s": 1895.0}, {"text": "a token bucket. It has two fields, current tokens,", "timestamp": "00:31:39,878", "timestamp_s": 1899.0}, {"text": "which is the number of tokens currently in the bucket and last refill", "timestamp": "00:31:43,998", "timestamp_s": 1903.0}, {"text": "time, which is the last time the bucket was refilled.", "timestamp": "00:31:47,758", "timestamp_s": 1907.0}, {"text": "Then I define the token bucket instruct which", "timestamp": "00:31:52,854", "timestamp_s": 1912.0}, {"text": "represents the rate limiter. It has a mutex", "timestamp": "00:31:56,926", "timestamp_s": 1916.0}, {"text": "for thread safety and map buckets", "timestamp": "00:32:00,654", "timestamp_s": 1920.0}, {"text": "that stores a bucket some", "timestamp": "00:32:06,634", "timestamp_s": 1926.0}, {"text": "key. As a key, I will use the", "timestamp": "00:32:11,442", "timestamp_s": 1931.0}, {"text": "client\u0027s ip addresses.", "timestamp": "00:32:14,754", "timestamp_s": 1934.0}, {"text": "Also, it has two fields bucket size", "timestamp": "00:32:17,754", "timestamp_s": 1937.0}, {"text": "which represents maximum number of tokens, a single bucket hand hold", "timestamp": "00:32:22,290", "timestamp_s": 1942.0}, {"text": "and refill rate, or the rate at which tokens are added", "timestamp": "00:32:26,626", "timestamp_s": 1946.0}, {"text": "to the bucket. Then I define new", "timestamp": "00:32:30,526", "timestamp_s": 1950.0}, {"text": "token bucket function that just", "timestamp": "00:32:34,702", "timestamp_s": 1954.0}, {"text": "creates a new rate limiter with specified bucket", "timestamp": "00:32:38,430", "timestamp_s": 1958.0}, {"text": "size, refill rates, and empty buckets.", "timestamp": "00:32:42,174", "timestamp_s": 1962.0}, {"text": "Map this rate limiter has one method", "timestamp": "00:32:45,110", "timestamp_s": 1965.0}, {"text": "that\u0027s called isallowed. This method", "timestamp": "00:32:49,734", "timestamp_s": 1969.0}, {"text": "checks if a request with the specified key is allowed.", "timestamp": "00:32:53,766", "timestamp_s": 1973.0}, {"text": "If there is no bucket with a", "timestamp": "00:32:59,334", "timestamp_s": 1979.0}, {"text": "given key, it creates a new bucket for the", "timestamp": "00:33:02,670", "timestamp_s": 1982.0}, {"text": "key and allows the request.", "timestamp": "00:33:06,294", "timestamp_s": 1986.0}, {"text": "If the key exists. It refills a bucket.", "timestamp": "00:33:09,414", "timestamp_s": 1989.0}, {"text": "It checks at least one token", "timestamp": "00:33:13,414", "timestamp_s": 1993.0}, {"text": "in the bucket. If there is a token,", "timestamp": "00:33:17,326", "timestamp_s": 1997.0}, {"text": "it decrements number of tokens and", "timestamp": "00:33:20,446", "timestamp_s": 2000.0}, {"text": "allows the request otherwise denies", "timestamp": "00:33:24,860", "timestamp_s": 2004.0}, {"text": "the refill. Method refills the bucket for", "timestamp": "00:33:31,804", "timestamp_s": 2011.0}, {"text": "the specified key. It calculates the number of", "timestamp": "00:33:35,676", "timestamp_s": 2015.0}, {"text": "tokens to add based on the time elapsed since the last", "timestamp": "00:33:39,164", "timestamp_s": 2019.0}, {"text": "refill and the refill rate after", "timestamp": "00:33:43,036", "timestamp_s": 2023.0}, {"text": "that. It adds them to the bucket, up to the bucket", "timestamp": "00:33:46,948", "timestamp_s": 2026.0}, {"text": "size, and updates the last refill time. I also use", "timestamp": "00:33:50,164", "timestamp_s": 2030.0}, {"text": "middleware for that example,", "timestamp": "00:33:55,404", "timestamp_s": 2035.0}, {"text": "I define a middleware to use for rate limiting.", "timestamp": "00:33:58,724", "timestamp_s": 2038.0}, {"text": "I have a simple rate limiter interface that contains only", "timestamp": "00:34:02,508", "timestamp_s": 2042.0}, {"text": "one method is allowed. This interface", "timestamp": "00:34:06,100", "timestamp_s": 2046.0}, {"text": "allows allows us to use", "timestamp": "00:34:10,764", "timestamp_s": 2050.0}, {"text": "different rate limiter implementations depending", "timestamp": "00:34:14,948", "timestamp_s": 2054.0}, {"text": "on our needs and replace them", "timestamp": "00:34:18,708", "timestamp_s": 2058.0}, {"text": "more easily. Then I define rate limiting middleware", "timestamp": "00:34:22,246", "timestamp_s": 2062.0}, {"text": "function. It checks if a request is allowed", "timestamp": "00:34:26,710", "timestamp_s": 2066.0}, {"text": "by calling the isallowed method of the rate", "timestamp": "00:34:30,366", "timestamp_s": 2070.0}, {"text": "limiter with the remote address of the request.", "timestamp": "00:34:33,886", "timestamp_s": 2073.0}, {"text": "If the request is not allowed, it responds with 429", "timestamp": "00:34:37,198", "timestamp_s": 2077.0}, {"text": "status corresponding status text.", "timestamp": "00:34:43,094", "timestamp_s": 2083.0}, {"text": "If the request is allowed, it calls the original handler", "timestamp": "00:34:46,944", "timestamp_s": 2086.0}, {"text": "function. I use the same service", "timestamp": "00:34:51,368", "timestamp_s": 2091.0}, {"text": "as the previous example, but with a few changes.", "timestamp": "00:34:55,184", "timestamp_s": 2095.0}, {"text": "Initialize the rate limiter first with a", "timestamp": "00:34:59,984", "timestamp_s": 2099.0}, {"text": "bucket size of one token and refill rate of one token", "timestamp": "00:35:03,080", "timestamp_s": 2103.0}, {"text": "per second. That means that", "timestamp": "00:35:07,296", "timestamp_s": 2107.0}, {"text": "we allow approximately one request", "timestamp": "00:35:10,576", "timestamp_s": 2110.0}, {"text": "per second from a single user,", "timestamp": "00:35:14,252", "timestamp_s": 2114.0}, {"text": "the handler function with the rate limiter middleware,", "timestamp": "00:35:18,204", "timestamp_s": 2118.0}, {"text": "and pass the rate limiting limiter there", "timestamp": "00:35:21,780", "timestamp_s": 2121.0}, {"text": "I use the same test configuration as previous", "timestamp": "00:35:28,364", "timestamp_s": 2128.0}, {"text": "example and the result test", "timestamp": "00:35:31,764", "timestamp_s": 2131.0}, {"text": "results show that even rate limiter allowed", "timestamp": "00:35:35,372", "timestamp_s": 2135.0}, {"text": "us to decrease the average load on the", "timestamp": "00:35:39,572", "timestamp_s": 2139.0}, {"text": "server and the latest is not as high", "timestamp": "00:35:43,192", "timestamp_s": 2143.0}, {"text": "as before. However, it can\u0027t improve the performance", "timestamp": "00:35:46,632", "timestamp_s": 2146.0}, {"text": "significantly in this case. Because rate limiter is", "timestamp": "00:35:50,760", "timestamp_s": 2150.0}, {"text": "integrated into the service, it also uses the same system", "timestamp": "00:35:54,752", "timestamp_s": 2154.0}, {"text": "resources. You should always remember about it.", "timestamp": "00:35:59,032", "timestamp_s": 2159.0}, {"text": "Using a rate limiter has its overhead", "timestamp": "00:36:02,784", "timestamp_s": 2162.0}, {"text": "and costs as well. You have to", "timestamp": "00:36:06,834", "timestamp_s": 2166.0}, {"text": "consider different trade offs and find", "timestamp": "00:36:10,130", "timestamp_s": 2170.0}, {"text": "a balance between using a rate limiter and the", "timestamp": "00:36:14,218", "timestamp_s": 2174.0}, {"text": "performance of the service. Moreover,", "timestamp": "00:36:18,114", "timestamp_s": 2178.0}, {"text": "you can\u0027t just use the rate limiter from the example", "timestamp": "00:36:21,562", "timestamp_s": 2181.0}, {"text": "in the real production applications because you need some shared", "timestamp": "00:36:25,266", "timestamp_s": 2185.0}, {"text": "state with counters that can be used in all instances", "timestamp": "00:36:29,578", "timestamp_s": 2189.0}, {"text": "of the application. For example, you can use", "timestamp": "00:36:33,274", "timestamp_s": 2193.0}, {"text": "redis to store the counters and get them from redis during rate", "timestamp": "00:36:36,668", "timestamp_s": 2196.0}, {"text": "limiter checks. Also, you will likely need a", "timestamp": "00:36:40,404", "timestamp_s": 2200.0}, {"text": "distributed rate limiter that can be implemented in a separated", "timestamp": "00:36:43,940", "timestamp_s": 2203.0}, {"text": "service, for example in the API,", "timestamp": "00:36:48,012", "timestamp_s": 2208.0}, {"text": "gateway or other solutions.", "timestamp": "00:36:51,356", "timestamp_s": 2211.0}, {"text": "In addition, on this slide I provided the", "timestamp": "00:36:54,884", "timestamp_s": 2214.0}, {"text": "list of different implementations of rate limiters in", "timestamp": "00:36:58,508", "timestamp_s": 2218.0}, {"text": "Golang. You can check these packages, see how", "timestamp": "00:37:02,544", "timestamp_s": 2222.0}, {"text": "different algorithms are implemented,", "timestamp": "00:37:05,928", "timestamp_s": 2225.0}, {"text": "and use one of them in your application if", "timestamp": "00:37:09,376", "timestamp_s": 2229.0}, {"text": "it suits your particular use case.", "timestamp": "00:37:12,960", "timestamp_s": 2232.0}, {"text": "We have considered server overload,", "timestamp": "00:37:16,784", "timestamp_s": 2236.0}, {"text": "the rate limiting technique, and common rate limiting algorithms.", "timestamp": "00:37:20,664", "timestamp_s": 2240.0}, {"text": "Also, we saw it in examples.", "timestamp": "00:37:24,624", "timestamp_s": 2244.0}, {"text": "Now let\u0027s look at another technique", "timestamp": "00:37:27,404", "timestamp_s": 2247.0}, {"text": "called load shedding.", "timestamp": "00:37:31,412", "timestamp_s": 2251.0}, {"text": "Load shedding is another technique that is used", "timestamp": "00:37:34,684", "timestamp_s": 2254.0}, {"text": "to prevent server overload. It is like a controlled", "timestamp": "00:37:38,196", "timestamp_s": 2258.0}, {"text": "shutdown to prevent a total crash during", "timestamp": "00:37:41,964", "timestamp_s": 2261.0}, {"text": "a traffic overload. It can be implemented", "timestamp": "00:37:46,300", "timestamp_s": 2266.0}, {"text": "in different ways. For example, the system can", "timestamp": "00:37:49,756", "timestamp_s": 2269.0}, {"text": "constantly check its resources,", "timestamp": "00:37:54,194", "timestamp_s": 2274.0}, {"text": "such as cpu and memory. If things", "timestamp": "00:37:58,090", "timestamp_s": 2278.0}, {"text": "get overloaded,", "timestamp": "00:38:02,338", "timestamp_s": 2282.0}, {"text": "load shedding kicks in. It might reject", "timestamp": "00:38:06,074", "timestamp_s": 2286.0}, {"text": "random or non critical incoming requests,", "timestamp": "00:38:10,178", "timestamp_s": 2290.0}, {"text": "prioritizing critical ones. Also, the system", "timestamp": "00:38:15,754", "timestamp_s": 2295.0}, {"text": "might slow down process processing for non critical tasks.", "timestamp": "00:38:19,938", "timestamp_s": 2299.0}, {"text": "The system also might redirect some requests", "timestamp": "00:38:24,304", "timestamp_s": 2304.0}, {"text": "to other services if possible.", "timestamp": "00:38:28,424", "timestamp_s": 2308.0}, {"text": "By sacrificing some requests,", "timestamp": "00:38:33,024", "timestamp_s": 2313.0}, {"text": "the system stays operational for", "timestamp": "00:38:37,120", "timestamp_s": 2317.0}, {"text": "the most important ones. Critical requests", "timestamp": "00:38:40,608", "timestamp_s": 2320.0}, {"text": "still get processed within a reasonable time frame.", "timestamp": "00:38:44,608", "timestamp_s": 2324.0}, {"text": "A controlled slowdown is better", "timestamp": "00:38:48,574", "timestamp_s": 2328.0}, {"text": "than a complete system breakdown in this situation.", "timestamp": "00:38:51,878", "timestamp_s": 2331.0}, {"text": "However, as always, there are some trade offs.", "timestamp": "00:38:55,974", "timestamp_s": 2335.0}, {"text": "Users might experience delays", "timestamp": "00:38:59,414", "timestamp_s": 2339.0}, {"text": "or errors for some requests during", "timestamp": "00:39:02,702", "timestamp_s": 2342.0}, {"text": "shedding. Depending on the system, some data", "timestamp": "00:39:07,366", "timestamp_s": 2347.0}, {"text": "processing might be delayed or even lost.", "timestamp": "00:39:12,414", "timestamp_s": 2352.0}, {"text": "So now let\u0027s look at an example.", "timestamp": "00:39:16,434", "timestamp_s": 2356.0}, {"text": "To demonstrate this technique, I implemented a simple", "timestamp": "00:39:20,674", "timestamp_s": 2360.0}, {"text": "algorithm to decide if the system is overloaded", "timestamp": "00:39:24,306", "timestamp_s": 2364.0}, {"text": "and reject random requests.", "timestamp": "00:39:28,730", "timestamp_s": 2368.0}, {"text": "I will use a ticker from the time package,", "timestamp": "00:39:32,994", "timestamp_s": 2372.0}, {"text": "and I assume that if the system is overloaded", "timestamp": "00:39:36,434", "timestamp_s": 2376.0}, {"text": "we will have some delays and the ticker will not work.", "timestamp": "00:39:40,714", "timestamp_s": 2380.0}, {"text": "I strongly do not recommend this algorithm", "timestamp": "00:39:46,264", "timestamp_s": 2386.0}, {"text": "for production applications is just for", "timestamp": "00:39:51,048", "timestamp_s": 2391.0}, {"text": "demonstration purposes. I implemented the", "timestamp": "00:39:55,544", "timestamp_s": 2395.0}, {"text": "logic in a separate package called overload detector.", "timestamp": "00:39:58,880", "timestamp_s": 2398.0}, {"text": "Here I define overload detector struct that will", "timestamp": "00:40:02,944", "timestamp_s": 2402.0}, {"text": "be used to detect if a system is overload", "timestamp": "00:40:06,832", "timestamp_s": 2406.0}, {"text": "based on a specified overload factor", "timestamp": "00:40:10,640", "timestamp_s": 2410.0}, {"text": "structure has three fields.", "timestamp": "00:40:15,284", "timestamp_s": 2415.0}, {"text": "Check interval is the duration between each check", "timestamp": "00:40:18,908", "timestamp_s": 2418.0}, {"text": "for overload. For overload overload", "timestamp": "00:40:22,780", "timestamp_s": 2422.0}, {"text": "factor is a duration that is considered as", "timestamp": "00:40:27,788", "timestamp_s": 2427.0}, {"text": "a threshold for overload and is", "timestamp": "00:40:32,404", "timestamp_s": 2432.0}, {"text": "overloaded flag indicating where", "timestamp": "00:40:35,868", "timestamp_s": 2435.0}, {"text": "the system is overloaded. I use bool", "timestamp": "00:40:39,432", "timestamp_s": 2439.0}, {"text": "from the sync atomic package for thread", "timestamp": "00:40:43,656", "timestamp_s": 2443.0}, {"text": "safety. Then I define the new", "timestamp": "00:40:47,888", "timestamp_s": 2447.0}, {"text": "function which just creates a new overload", "timestamp": "00:40:52,056", "timestamp_s": 2452.0}, {"text": "detector arguments and", "timestamp": "00:40:55,776", "timestamp_s": 2455.0}, {"text": "the overload detector check in the background", "timestamp": "00:41:00,624", "timestamp_s": 2460.0}, {"text": "using the run method. Also, I have", "timestamp": "00:41:05,214", "timestamp_s": 2465.0}, {"text": "isoverloaded method that just returns the", "timestamp": "00:41:08,574", "timestamp_s": 2468.0}, {"text": "value for the flag,", "timestamp": "00:41:12,198", "timestamp_s": 2472.0}, {"text": "and in the run method we", "timestamp": "00:41:15,094", "timestamp_s": 2475.0}, {"text": "do the check if the system is overloaded.", "timestamp": "00:41:20,694", "timestamp_s": 2480.0}, {"text": "First we initialize the ticker that if the system", "timestamp": "00:41:24,430", "timestamp_s": 2484.0}, {"text": "is overloaded every check interval on", "timestamp": "00:41:28,086", "timestamp_s": 2488.0}, {"text": "each tick, it checks. If the time since the last", "timestamp": "00:41:33,034", "timestamp_s": 2493.0}, {"text": "check is greater than the overload factor,", "timestamp": "00:41:36,634", "timestamp_s": 2496.0}, {"text": "it considers the system as overloaded and sets the", "timestamp": "00:41:40,834", "timestamp_s": 2500.0}, {"text": "flag to the true value. If it is not, it sets", "timestamp": "00:41:44,522", "timestamp_s": 2504.0}, {"text": "the flag to false I also define a middleware for", "timestamp": "00:41:47,890", "timestamp_s": 2507.0}, {"text": "load sharing as I have done for rate", "timestamp": "00:41:52,298", "timestamp_s": 2512.0}, {"text": "limit meeting. I have a simple overload detector", "timestamp": "00:41:55,522", "timestamp_s": 2515.0}, {"text": "interface that contains only one method is overloaded.", "timestamp": "00:41:59,390", "timestamp_s": 2519.0}, {"text": "Then I define the overload detecting", "timestamp": "00:42:03,814", "timestamp_s": 2523.0}, {"text": "middleware function. It checks if request", "timestamp": "00:42:07,494", "timestamp_s": 2527.0}, {"text": "is allowed by calling the isoverloaded method,", "timestamp": "00:42:11,190", "timestamp_s": 2531.0}, {"text": "and if the server is overloaded it responds", "timestamp": "00:42:15,614", "timestamp_s": 2535.0}, {"text": "with 500 and", "timestamp": "00:42:19,518", "timestamp_s": 2539.0}, {"text": "if the system is not overloaded,", "timestamp": "00:42:23,922", "timestamp_s": 2543.0}, {"text": "it calls the original handler function.", "timestamp": "00:42:27,914", "timestamp_s": 2547.0}, {"text": "Again, I use the same service as the previous example but", "timestamp": "00:42:32,794", "timestamp_s": 2552.0}, {"text": "with few changes. I initialize the overload", "timestamp": "00:42:36,202", "timestamp_s": 2556.0}, {"text": "detector with a check interval of ten milliseconds", "timestamp": "00:42:39,954", "timestamp_s": 2559.0}, {"text": "and an overload factor of eleven milliseconds.", "timestamp": "00:42:43,954", "timestamp_s": 2563.0}, {"text": "Then I wrap the handler function with the overload", "timestamp": "00:42:47,690", "timestamp_s": 2567.0}, {"text": "detecting middleware and pass the overload", "timestamp": "00:42:52,284", "timestamp_s": 2572.0}, {"text": "detector. There, I use the same", "timestamp": "00:42:56,028", "timestamp_s": 2576.0}, {"text": "test configuration as the previous examples.", "timestamp": "00:42:59,324", "timestamp_s": 2579.0}, {"text": "The test results shows that using the overload shedding", "timestamp": "00:43:03,284", "timestamp_s": 2583.0}, {"text": "allowed us to decrease the average load on the server.", "timestamp": "00:43:07,660", "timestamp_s": 2587.0}, {"text": "Depending on the particular case and requirements,", "timestamp": "00:43:11,924", "timestamp_s": 2591.0}, {"text": "load shedding can be implemented differently in the real production.", "timestamp": "00:43:15,626", "timestamp_s": 2595.0}, {"text": "To understand load shedding better and the", "timestamp": "00:43:20,754", "timestamp_s": 2600.0}, {"text": "approaches for its implementation, I recommend", "timestamp": "00:43:24,994", "timestamp_s": 2604.0}, {"text": "reading this article by a senior principal engineer at", "timestamp": "00:43:29,218", "timestamp_s": 2609.0}, {"text": "Amazon that explains load shedding in more", "timestamp": "00:43:33,298", "timestamp_s": 2613.0}, {"text": "detail. Well, we have explored", "timestamp": "00:43:37,650", "timestamp_s": 2617.0}, {"text": "server overload and how it can", "timestamp": "00:43:42,034", "timestamp_s": 2622.0}, {"text": "affect your services at", "timestamp": "00:43:45,670", "timestamp_s": 2625.0}, {"text": "common reasons for overload and how", "timestamp": "00:43:50,126", "timestamp_s": 2630.0}, {"text": "to identify them.", "timestamp": "00:43:53,950", "timestamp_s": 2633.0}, {"text": "We then reviewed two key techniques to", "timestamp": "00:43:56,894", "timestamp_s": 2636.0}, {"text": "make your systems more resilient, rate limiting,", "timestamp": "00:44:00,702", "timestamp_s": 2640.0}, {"text": "health control incoming traffic and prevent overload", "timestamp": "00:44:04,590", "timestamp_s": 2644.0}, {"text": "before it happens, and load shedding that", "timestamp": "00:44:08,574", "timestamp_s": 2648.0}, {"text": "acts as a safety valve,", "timestamp": "00:44:12,610", "timestamp_s": 2652.0}, {"text": "gracefully degrading service during", "timestamp": "00:44:15,874", "timestamp_s": 2655.0}, {"text": "extreme traffic surges to maintain", "timestamp": "00:44:20,034", "timestamp_s": 2660.0}, {"text": "overall system stability.", "timestamp": "00:44:23,658", "timestamp_s": 2663.0}, {"text": "Understanding and implementing these techniques", "timestamp": "00:44:26,274", "timestamp_s": 2666.0}, {"text": "ensures your services stay healthy", "timestamp": "00:44:29,890", "timestamp_s": 2669.0}, {"text": "and responsive even under heavy", "timestamp": "00:44:33,866", "timestamp_s": 2673.0}, {"text": "load. Remember, a well designed system", "timestamp": "00:44:38,474", "timestamp_s": 2678.0}, {"text": "anticipates traffic spikes and", "timestamp": "00:44:43,714", "timestamp_s": 2683.0}, {"text": "has mechanisms to handle", "timestamp": "00:44:47,818", "timestamp_s": 2687.0}, {"text": "them effectively. So I hope", "timestamp": "00:44:51,578", "timestamp_s": 2691.0}, {"text": "you found this talk helpful. Thanks for", "timestamp": "00:44:55,082", "timestamp_s": 2695.0}, {"text": "your time.", "timestamp": "00:44:58,826", "timestamp_s": 2698.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'H5a6psrN0GM',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              How to make your service more resilient in case of traffic spikes
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>I want to talk about server overload, why it happens, and what happens with a service in such a situation. I will discuss two main techniques to prevent server overload and make the service more resilient such as rate limiting and load shedding.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Ivan Lemeshev will talk about rate limiting and load shedding. He will discuss how to reduce the load on the server and keep your service running smoothly. He is interested in the development of large scale and distributed systems.

              </li>
              
              <li>
                When we develop a backend application, we deploy it to a server to make it available to users. Each server always has limited computational or system resources. When a system is given more work than each resources support, it becomes slow. Of course, we can use auto scaling and deploy additional service instances.

              </li>
              
              <li>
                 traffic bursts can occur due to various reasons, both predictable and unpredictable. For example, social media platforms see higher traffic during evenings or weekends for unpredictable reasons. By understanding these potential causes, you can better prepare for traffic bursts.

              </li>
              
              <li>
                Rate limiting is a technique used to control the flow of requests to a network, resource server or API. It essentially sets a limit on how often a user or application can perform a specific action. There are many algorithms and variations of them for implementing rate limiting.

              </li>
              
              <li>
                The last algorithm for today is leaky bucket algorithm. It also uses the concept of a bucket, but in a different way. The bucket can hold a specific number of requests representing its maximum capacity. Each algorithm has pros and cons, so you should consider trade offs.

              </li>
              
              <li>
                 load shedding is another technique that is used to prevent server overload. It is like a controlled shutdown to prevent a total crash during a traffic overload. Users might experience delays or errors for some requests during shedding. Understanding and implementing these techniques ensures your services stay healthy and responsive even under heavy load.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/H5a6psrN0GM.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:20,640'); seek(20.0)">
              Hi everybody. Today I want to talk about techniques
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:25,086'); seek(25.0)">
              that allow you to reduce the load on the server
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:29,334'); seek(29.0)">
              and keep your service running smoothly,
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,694'); seek(32.0)">
              preventing server overload in case of traffic bursts.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:37,574'); seek(37.0)">
              In particular, I will be talking about rate
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:41,166'); seek(41.0)">
              limiting and load shedding. A little
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:44,606'); seek(44.0)">
              disclaimer by service, I mean any
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:48,502'); seek(48.0)">
              backend application. It can be a monolithic application
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:53,334'); seek(53.0)">
              or an individual microservice in a large distributed
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:57,318'); seek(57.0)">
              system. But first, let me
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:01,214'); seek(61.0)">
              tell you a little bit about me.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:04,294'); seek(64.0)">
              My name is Ivan Lemeshev. I live
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:07,550'); seek(67.0)">
              in Finland. I moved here over three years
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:10,990'); seek(70.0)">
              ago, and since then I have been working at
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:14,790'); seek(74.0)">
              Unity as a senior software engineer.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:18,294'); seek(78.0)">
              I have been using Golang as my primary programming language
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:22,054'); seek(82.0)">
              for many years and I am interested in the development
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:26,304'); seek(86.0)">
              of large scale and distributed systems.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:30,544'); seek(90.0)">
              You can find me on LinkedIn or GitHub
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:34,704'); seek(94.0)">
              by following the links to begin
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:38,000'); seek(98.0)">
              with, let's look at the agenda for this
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,776'); seek(101.0)">
              talk. First, I will discuss survey
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:45,656'); seek(105.0)">
              overload, why it occurs,
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:48,664'); seek(108.0)">
              and how it affects the performance of backend
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:52,500'); seek(112.0)">
              services. I'll give you an example of common
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:56,596'); seek(116.0)">
              causes of server overload,
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:59,364'); seek(119.0)">
              and then I'll show you what it looks like
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:03,300'); seek(123.0)">
              in the example of a simple HTTP service.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:07,924'); seek(127.0)">
              After that, I'll consider techniques that
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:11,964'); seek(131.0)">
              help prevent server overload.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:14,796'); seek(134.0)">
              I'll start with rate limiting and review common
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:19,380'); seek(139.0)">
              rate limiting algorithms. Then I'll
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:22,974'); seek(142.0)">
              show you a simple implementation of one
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:26,214'); seek(146.0)">
              of the algorithms, and you will see how it
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:29,814'); seek(149.0)">
              works. Next, I will discuss another technique
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:34,014'); seek(154.0)">
              called load shedding and show
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:37,686'); seek(157.0)">
              you a simple well, let's get
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:41,406'); seek(161.0)">
              started. When we develop a backend application,
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:45,934'); seek(165.0)">
              we deploy it to a server to make it available
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:49,508'); seek(169.0)">
              to users. As a server,
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:52,980'); seek(172.0)">
              both physical and virtual servers
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:56,980'); seek(176.0)">
              can be used. It doesn't matter.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:01,484'); seek(181.0)">
              Each server always has limited computational or
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:05,532'); seek(185.0)">
              system resources, such as cpu or memory.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:10,204'); seek(190.0)">
              The service utilizes some of these resources to
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:14,620'); seek(194.0)">
              process each incoming user request,
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:17,964'); seek(197.0)">
              including managing multiple tasks,
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:21,380'); seek(201.0)">
              switching between them, cleaning up unused memory,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:25,276'); seek(205.0)">
              and waiting for data to come in or go out.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:30,204'); seek(210.0)">
              The server can process only a particular
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:35,020'); seek(215.0)">
              number of concurrent user requests simultaneously
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:41,084'); seek(221.0)">
              under heavy load. When a system is given
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:44,476'); seek(224.0)">
              more work than each resources support,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:49,004'); seek(229.0)">
              it starts experiencing a lack of resources
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:53,212'); seek(233.0)">
              and becomes slow,
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:56,644'); seek(236.0)">
              which leads to an increase in the processing time
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:00,924'); seek(240.0)">
              or latency. For each request. The service reaches
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:05,324'); seek(245.0)">
              some threshold where its
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:08,708'); seek(248.0)">
              performance degrades rapidly.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:12,124'); seek(252.0)">
              It can keep working even when it
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:16,280'); seek(256.0)">
              is overloaded, but it spends amounts
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:20,648'); seek(260.0)">
              of time contacts switching and
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:24,760'); seek(264.0)">
              becomes too slow to be useful because
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:28,376'); seek(268.0)">
              most likely the client has some timeouts
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:32,416'); seek(272.0)">
              and can't wait for the response from the
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:36,320'); seek(276.0)">
              service too long. Therefore,
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:39,848'); seek(279.0)">
              the service performance and availability of
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:44,148'); seek(284.0)">
              your service will be declined because
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:47,916'); seek(287.0)">
              almost all requests will fail due
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:51,652'); seek(291.0)">
              to high latency and timeouts. In the
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:55,524'); seek(295.0)">
              worst case, the server may
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:58,708'); seek(298.0)">
              completely crash and stop handling requests
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:03,252'); seek(303.0)">
              due to running out of memory or other
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:07,036'); seek(307.0)">
              resources. Of course, we can use auto scaling and
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:11,238'); seek(311.0)">
              deploy additional service instances,
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:14,294'); seek(314.0)">
              but it doesn't happen instantly if
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:18,278'); seek(318.0)">
              the load grows gracefully. Auto scaling works
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:21,846'); seek(321.0)">
              well. However, deploying an appropriate
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:25,302'); seek(325.0)">
              number of additional instances requires time
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:29,358'); seek(329.0)">
              if we have a traffic burst and the load is
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:33,918'); seek(333.0)">
              exceptionally high.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:36,434'); seek(336.0)">
              Also, there may be a situation when an
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:40,538'); seek(340.0)">
              individual user or a group of users
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:43,954'); seek(343.0)">
              may produce so many requests,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:48,434'); seek(348.0)">
              consuming all the system resources, and other service
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:52,794'); seek(352.0)">
              users will be unable to use it.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:55,946'); seek(355.0)">
              In this case, auto scaling will not help.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:59,484'); seek(359.0)">
              Now let's explore situations
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:03,140'); seek(363.0)">
              where a surge of traffic can occur.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:07,084'); seek(367.0)">
              Traffic bursts can occur due to various
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:10,988'); seek(370.0)">
              reasons, both predictable and unpredictable.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:15,084'); seek(375.0)">
              For predictable reasons, there could be different scheduled
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:19,316'); seek(379.0)">
              events or planned events like product launches,
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:22,916'); seek(382.0)">
              sales, promotions, marketing campaigns,
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:26,574'); seek(386.0)">
              or even regular peak hours can lead
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:30,614'); seek(390.0)">
              to a surge in traffic as users try
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:33,934'); seek(393.0)">
              to access the service or website simultaneously.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:39,454'); seek(399.0)">
              Another reason is seasonal traffic.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:42,790'); seek(402.0)">
              Businesses in specific industries might experience
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:47,494'); seek(407.0)">
              seasonal spikes in traffic. For example,
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:50,606'); seek(410.0)">
              e commerce sites might see
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:54,248'); seek(414.0)">
              a search during holidays or
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:57,856'); seek(417.0)">
              back to school seasons. The next one is
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:01,768'); seek(421.0)">
              the time of day or week.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:05,024'); seek(425.0)">
              Traffic patterns can change regularly depending
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:09,264'); seek(429.0)">
              on the target audience and service type.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:13,280'); seek(433.0)">
              For example, social media platforms see
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:17,000'); seek(437.0)">
              higher traffic during evenings or weekends
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:21,874'); seek(441.0)">
              for unpredictable reasons. There could be different
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:27,050'); seek(447.0)">
              viral events like social media trends,
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:31,562'); seek(451.0)">
              news articles, or influencer mentions can
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:36,066'); seek(456.0)">
              drive sudden traffic bursts to a website
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:39,762'); seek(459.0)">
              or service. Also, there could be different
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:44,354'); seek(464.0)">
              technical issues. For instance,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:47,014'); seek(467.0)">
              system outages on competitor platforms
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:51,462'); seek(471.0)">
              can lead to users flocking
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:54,782'); seek(474.0)">
              to a service, causing a temporary spike.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:58,054'); seek(478.0)">
              Another very popular reason is denial of service
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:02,030'); seek(482.0)">
              attacks. It is when malicious actors might
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:06,310'); seek(486.0)">
              attempt to overwhelm a system with traffic,
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:10,566'); seek(490.0)">
              causing a spike and potentially disrupting
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:14,062'); seek(494.0)">
              functionalities. The next one is bot
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:17,336'); seek(497.0)">
              activity. Automated bots or
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:21,968'); seek(501.0)">
              scripts can cause unexpected bursts,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:25,880'); seek(505.0)">
              especially if they are scrapping data or attempting
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:30,024'); seek(510.0)">
              to exploit vulnerabilities. There could also be
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:34,512'); seek(514.0)">
              issues with external dependencies. For instance,
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:38,944'); seek(518.0)">
              if your service relies on external
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:42,808'); seek(522.0)">
              APIs or services,
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:45,464'); seek(525.0)">
              outages or slowdowns on their end can
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:49,112'); seek(529.0)">
              lead to a cascading effect and cause traffic
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:53,488'); seek(533.0)">
              spikes for your users trying to access features
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:57,120'); seek(537.0)">
              that depend on those external services.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:00,944'); seek(540.0)">
              By understanding these potential causes, you can
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:04,480'); seek(544.0)">
              better prepare for traffic bursts. Well,
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:07,942'); seek(547.0)">
              now let's look at the example of server
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:11,814'); seek(551.0)">
              overload. To demonstrate this,
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:15,694'); seek(555.0)">
              I implemented a simple HTTP service in
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:18,942'); seek(558.0)">
              go. The main function sets up an
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:22,574'); seek(562.0)">
              HTTP server that listens on port 8000.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:27,574'); seek(567.0)">
              It registers a single root
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:31,502'); seek(571.0)">
              with a handler function. The handler function attempts
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:35,540'); seek(575.0)">
              to extract a path parameter length from
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:39,244'); seek(579.0)">
              the requests, convert it to an integer value
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:44,724'); seek(584.0)">
              and use it to generate a password.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:48,628'); seek(588.0)">
              If the length parameter cannot be converted to an integer,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:52,284'); seek(592.0)">
              for example, if it's not a number, the function
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:55,732'); seek(595.0)">
              responds with 400 status.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:59,044'); seek(599.0)">
              If the length parameter is successfully
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:02,380'); seek(602.0)">
              converted to an integer, the function generates a password
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:06,116'); seek(606.0)">
              of that length and then generated password is sent back to
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:10,380'); seek(610.0)">
              the client with 200 status.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:13,364'); seek(613.0)">
              I use the docker container to run this service
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:18,044'); seek(618.0)">
              because it allows us to simulate limited
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:21,932'); seek(621.0)">
              resources. You will see it in the next slide.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:25,884'); seek(625.0)">
              I built and run the service using this
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:29,644'); seek(629.0)">
              simple dockerfile, the application using
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:33,668'); seek(633.0)">
              the Golang image in the build stage, and then it
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:37,492'); seek(637.0)">
              uses the distr less base image from
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:40,988'); seek(640.0)">
              Google's container registry to run the service.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:46,204'); seek(646.0)">
              This image contains only the application and its
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:50,460'); seek(650.0)">
              runtime dependencies, and it is
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:54,270'); seek(654.0)">
              designed to be as small as possible.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:57,294'); seek(657.0)">
              Then I built a docker image from
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:00,958'); seek(660.0)">
              the dockerfile. I set the
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:04,526'); seek(664.0)">
              cpu option to one to limit
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:08,246'); seek(668.0)">
              the number of cpu cores that also
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:12,142'); seek(672.0)">
              I set two options, memory and memory.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:15,358'); seek(675.0)">
              Swap 300 megabytes to limit the
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:18,918'); seek(678.0)">
              containers memory. I have to set
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:22,776'); seek(682.0)">
              both options to the same value to prevent
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:26,704'); seek(686.0)">
              the container from using. When we
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:30,160'); seek(690.0)">
              have a running service, we need to test
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:33,984'); seek(693.0)">
              for that I use a load testing tool called Grafana
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:38,488'); seek(698.0)">
              k six. Here is a script that is
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:41,704'); seek(701.0)">
              used by this tool. It is just a simple JavaScript file
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:46,404'); seek(706.0)">
              with some configuration for the test.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:50,564'); seek(710.0)">
              The test consists of four stages. In the
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:54,348'); seek(714.0)">
              stage one, we gracefully increase the number of virtual
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:58,140'); seek(718.0)">
              users from zero to 1000
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:02,484'); seek(722.0)">
              for two minutes, and then in stage
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:06,380'); seek(726.0)">
              two we keep the number of users at 1000
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:10,484'); seek(730.0)">
              for another two minutes. In the stage three,
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:14,706'); seek(734.0)">
              we ramp up to 2000
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:18,626'); seek(738.0)">
              virtual users for two minutes. And finally in
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:22,210'); seek(742.0)">
              stage four we keep the number of users at 2000
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:27,354'); seek(747.0)">
              for another two minutes.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:30,234'); seek(750.0)">
              In the default function, we define the user logic.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:35,034'); seek(755.0)">
              Each virtual user makes a get request to
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:38,258'); seek(758.0)">
              the service to generate a password. Then the user sleeps
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:42,610'); seek(762.0)">
              for 100 milliseconds that
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:46,186'); seek(766.0)">
              simulates approximately ten requests per second
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:49,994'); seek(769.0)">
              from a single user. After that,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:54,114'); seek(774.0)">
              I just run the test using this command for
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:58,754'); seek(778.0)">
              it to end. I also use a web dashboard
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:02,946'); seek(782.0)">
              as an output to visualize the test results.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:06,904'); seek(786.0)">
              It produces graphs showing the number
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:10,584'); seek(790.0)">
              of requests latency and other
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:13,976'); seek(793.0)">
              metrics. In the graph, we can
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:17,864'); seek(797.0)">
              see how latency changes depending on
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:21,400'); seek(801.0)">
              the number of requests per second.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:24,304'); seek(804.0)">
              Initially, we gracefully increased the number of users and
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:28,512'); seek(808.0)">
              the service could handle that load. The latency
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:31,808'); seek(811.0)">
              was very low and then after four minutes
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:35,538'); seek(815.0)">
              we increased the number of users up to 2000
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:39,322'); seek(819.0)">
              and the service started to experience
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:42,666'); seek(822.0)">
              a lack of resources. That led to a significant increase
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:46,794'); seek(826.0)">
              in latency and the server became overloaded.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:51,394'); seek(831.0)">
              In the following graph we can see the latency distribution
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:56,434'); seek(836.0)">
              by percentile. From these results we can understand
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:01,564'); seek(841.0)">
              that when we use system resources at maximum,
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:06,164'); seek(846.0)">
              the latency significantly increases many times.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:10,604'); seek(850.0)">
              But this is just an artificial example.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:13,724'); seek(853.0)">
              In the actual application the latency
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:17,732'); seek(857.0)">
              might be higher and there will
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:21,292'); seek(861.0)">
              likely be some timeout on the client side that will
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:24,644'); seek(864.0)">
              drop requests and make the service unavailable
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:28,428'); seek(868.0)">
              for users. We have discussed server overload
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:32,252'); seek(872.0)">
              and its causes. Also we saw what it looks like
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:36,188'); seek(876.0)">
              in the example. Now lets look at the first
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:39,884'); seek(879.0)">
              technique that can be used in this situation.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:44,524'); seek(884.0)">
              First I want to discuss rate limiting.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:48,164'); seek(888.0)">
              Sometimes it also called throttling,
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:52,044'); seek(892.0)">
              so these terms may be used interchangeably.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:55,994'); seek(895.0)">
              Rate limiting is a technique used to control
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:00,354'); seek(900.0)">
              the flow of requests to a network,
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:04,594'); seek(904.0)">
              resource server or API.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:08,234'); seek(908.0)">
              It essentially sets a limit on how often a user
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:12,634'); seek(912.0)">
              or application can perform a specific
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:16,922'); seek(916.0)">
              action within a given time frame.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:20,234'); seek(920.0)">
              It protects against malicious activities like denial
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:23,674'); seek(923.0)">
              of service attacks where attackers try to overwhelm
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:28,308'); seek(928.0)">
              a system with excessive requests,
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:31,972'); seek(931.0)">
              making it unavailable to legitimate users.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:35,148'); seek(935.0)">
              Also, it helps ensure fair access
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:38,308'); seek(938.0)">
              to resources by preventing single users
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:42,364'); seek(942.0)">
              or applications for monopolizing them.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:45,692'); seek(945.0)">
              It is especially important when the
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:50,284'); seek(950.0)">
              service for services with limited resources
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:54,754'); seek(954.0)">
              by controlling the request rate. Rate limiting prevents
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:58,882'); seek(958.0)">
              overloading the server and helps
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:02,354'); seek(962.0)">
              maintain optimal performance for all users.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:06,474'); seek(966.0)">
              We can limit the request rate per an IP
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:10,570'); seek(970.0)">
              address or a user identifier,
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:13,738'); seek(973.0)">
              an API key, or other criteria depending
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:17,994'); seek(977.0)">
              on a particular use case. For example,
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:22,114'); seek(982.0)">
              we can load ten requests per minute from
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:25,778'); seek(985.0)">
              a single IP address, and if the number
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:29,370'); seek(989.0)">
              of requests per minute is less or equal to
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:32,714'); seek(992.0)">
              that value, we process a request.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:36,602'); seek(996.0)">
              Otherwise, if the limit is exceeded,
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:40,626'); seek(1000.0)">
              we will drop the request. There are many
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:44,394'); seek(1004.0)">
              algorithms and variations of them
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:48,274'); seek(1008.0)">
              for implementing rate limiting. I'll briefly review
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:52,426'); seek(1012.0)">
              just the most common of them.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:55,554'); seek(1015.0)">
              One is the fixed window counter algorithm.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:00,034'); seek(1020.0)">
              This algorithm divides time into equal sized
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:05,194'); seek(1025.0)">
              time intervals or fixed windows.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:09,554'); seek(1029.0)">
              The window size can be defined in milliseconds,
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:13,578'); seek(1033.0)">
              seconds, minutes, or any other irrelevant unit
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:17,184'); seek(1037.0)">
              depending on the use case. Each window
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:20,864'); seek(1040.0)">
              has a request counter that allows the algorithm
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:25,072'); seek(1045.0)">
              to keep track of how many requests occur
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:29,400'); seek(1049.0)">
              within each window. As a request arrives,
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:33,592'); seek(1053.0)">
              the algorithm checks the current timestamp.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:37,864'); seek(1057.0)">
              It decides which window the timestamp falls
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:41,320'); seek(1061.0)">
              into based on the window
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:44,906'); seek(1064.0)">
              size and the starting point on the current window.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:48,594'); seek(1068.0)">
              If the request falls within the current window,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:52,122'); seek(1072.0)">
              the counter for that window is incremented by one.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:56,514'); seek(1076.0)">
              Otherwise, a new window starts, the counter is
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:00,138'); seek(1080.0)">
              reset to zero and incremented by
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:03,330'); seek(1083.0)">
              one, and the start time of the window is updated.
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:07,234'); seek(1087.0)">
              Then, if the counter value is less or equal to
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:10,842'); seek(1090.0)">
              the limit, the rate limiter allows the request to
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:14,660'); seek(1094.0)">
              be processed. Otherwise the request
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:17,876'); seek(1097.0)">
              is dropped if the counter value exceeds the limit.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:22,364'); seek(1102.0)">
              The example on the slide shows
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:25,756'); seek(1105.0)">
              that we have a 1 minute window size
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:29,276'); seek(1109.0)">
              and set the rate limit to five requests
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:32,788'); seek(1112.0)">
              per minute in each window. The first five
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:36,540'); seek(1116.0)">
              requests were processed, all other requests
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:40,718'); seek(1120.0)">
              were dropped. As you can see,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:44,414'); seek(1124.0)">
              this algorithm is quite simple.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:47,902'); seek(1127.0)">
              However, it has a big drawback which
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:52,022'); seek(1132.0)">
              you have probably already noticed here.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:55,854'); seek(1135.0)">
              Since the counter is reset when the new window
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:59,814'); seek(1139.0)">
              is started, the rate limiter doesn't know
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:03,094'); seek(1143.0)">
              how many requests were
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:06,458'); seek(1146.0)">
              made in the previous window. It leads to
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:09,866'); seek(1149.0)">
              some issues. For example, in this picture,
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:13,234'); seek(1153.0)">
              the total number of requests per minute was more than
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:17,266'); seek(1157.0)">
              five because requests burst at
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:21,122'); seek(1161.0)">
              the end of the second window and the beginning
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:24,514'); seek(1164.0)">
              of the third window. The fixed window counter
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:28,466'); seek(1168.0)">
              algorithm is easy to understand and implement because it
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:31,906'); seek(1171.0)">
              only requires keeping track of a counter for
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:35,712'); seek(1175.0)">
              each window. Also, it is efficient because
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:39,952'); seek(1179.0)">
              it requires only basic counter operations and
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:44,712'); seek(1184.0)">
              it has low memory usage because it only needs to
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:47,992'); seek(1187.0)">
              store the counter value for a window, which is typically
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:51,824'); seek(1191.0)">
              a small amount of data. However,
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:55,904'); seek(1195.0)">
              request bursts are possible on edgest when
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:01,044'); seek(1201.0)">
              switching between windows,
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:04,012'); seek(1204.0)">
              and this algorithm is not suitable for
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:08,372'); seek(1208.0)">
              identifying frequent requests since the counter is set
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:12,716'); seek(1212.0)">
              at each window. The following algorithm
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:17,084'); seek(1217.0)">
              is sliding window lock.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:20,604'); seek(1220.0)">
              It also uses a window, but this
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:24,436'); seek(1224.0)">
              window slides a long time representing the
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:28,316'); seek(1228.0)">
              relevant time frame. For rate limiting,
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:32,084'); seek(1232.0)">
              the window size can be also defined
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:35,692'); seek(1235.0)">
              in milliseconds, seconds, minutes, or any
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:39,164'); seek(1239.0)">
              other relevant unit, depending on the use case.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:42,804'); seek(1242.0)">
              Instead of request counter, this algorithm
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:46,324'); seek(1246.0)">
              keeps track of for each incoming request and
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:50,692'); seek(1250.0)">
              stores it in the the log can
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:54,646'); seek(1254.0)">
              be stored in a data structure like
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:58,006'); seek(1258.0)">
              hash table or sorted
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:01,678'); seek(1261.0)">
              set for efficient retrieval.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:05,334'); seek(1265.0)">
              As the window slides forward,
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:08,494'); seek(1268.0)">
              timestamps outside the current window become
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:13,126'); seek(1273.0)">
              irrelevant for rate limiting purposes
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:17,254'); seek(1277.0)">
              and removed from the log.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:20,464'); seek(1280.0)">
              A new request arrives. Each timestamp
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:24,680'); seek(1284.0)">
              is added to the log. The algorithm
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:28,384'); seek(1288.0)">
              calculates the total number of requests within the current window
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:32,472'); seek(1292.0)">
              by iterating through the remaining timestamps
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:35,520'); seek(1295.0)">
              in the log to decide if the request should be allowed.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:40,504'); seek(1300.0)">
              The request is processed in. The total count
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:44,532'); seek(1304.0)">
              within the window is less than
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:48,476'); seek(1308.0)">
              or equal to the allowed limit.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:52,324'); seek(1312.0)">
              Otherwise, it's considered a rate limit
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:55,572'); seek(1315.0)">
              violation and might be rejected.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:58,940'); seek(1318.0)">
              Let's look at the example.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:02,524'); seek(1322.0)">
              In this example, we allow two requests
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:07,252'); seek(1327.0)">
              per minute when the first requests when
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:11,302'); seek(1331.0)">
              the first request is saved to the lock,
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:14,862'); seek(1334.0)">
              there is only one request in the lock at
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:18,350'); seek(1338.0)">
              that point in time, so the request is allowed
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:22,134'); seek(1342.0)">
              and processed. Then the second
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:25,566'); seek(1345.0)">
              request comes and each timestamp is
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:29,646'); seek(1349.0)">
              saved to the lock as well. Now there are two
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:34,054'); seek(1354.0)">
              requests in the lock. All of them fall within
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:37,406'); seek(1357.0)">
              the current window, so the number of requests
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:40,570'); seek(1360.0)">
              is equal to the limit and the request can be processed.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:45,194'); seek(1365.0)">
              Then the third request comes and each timestamp
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:49,634'); seek(1369.0)">
              is saved to the lock. Now there are three requests
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:53,538'); seek(1373.0)">
              that fall into the current window,
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:57,234'); seek(1377.0)">
              then the limit, so the request is rejected,
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:01,578'); seek(1381.0)">
              and finally the fourth request comes comes.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:05,704'); seek(1385.0)">
              Each timestamp is also saved to the lock.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:10,144'); seek(1390.0)">
              There are only two requests that fall within the
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:13,992'); seek(1393.0)">
              current window at that point in time,
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:17,432'); seek(1397.0)">
              and there are two all
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:21,424'); seek(1401.0)">
              timestamps that do not fall into the current window.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:25,384'); seek(1405.0)">
              The old timestamps are removed from
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:28,752'); seek(1408.0)">
              the lock and the new request is allowed and
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:33,710'); seek(1413.0)">
              processed. Because the number of requests in
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:37,318'); seek(1417.0)">
              the current window equals the limit,
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:40,494'); seek(1420.0)">
              the algorithm captures recent surges in requests
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:46,046'); seek(1426.0)">
              more accurately than the fixed window counter because
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:50,630'); seek(1430.0)">
              it considers only relevant requests within the
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:54,542'); seek(1434.0)">
              sliding window can effectively handle bursts
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:58,294'); seek(1438.0)">
              of requests. However, storing timestamps
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:02,576'); seek(1442.0)">
              for all requests requires
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:06,224'); seek(1446.0)">
              a lot of memory and it can be memory
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:09,824'); seek(1449.0)">
              intensive, especially for high requests
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:13,496'); seek(1453.0)">
              volumes. Also, it's more complex because it
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:17,176'); seek(1457.0)">
              requires maintenance and iteration through the request
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:20,960'); seek(1460.0)">
              log following algorithm is
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:24,512'); seek(1464.0)">
              called sliding window counter.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:28,804'); seek(1468.0)">
              It offers a balance between simplicity
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:32,740'); seek(1472.0)">
              and accuracy compared to fixed window
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:36,516'); seek(1476.0)">
              counter and sliding window log algorithms.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:39,724'); seek(1479.0)">
              The algorithm maintains a counter variable
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:44,092'); seek(1484.0)">
              and fixit size window duration similar
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:47,804'); seek(1487.0)">
              to the fixed window counter, but in addition,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:51,948'); seek(1491.0)">
              it uses a sliding window to represent
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:55,602'); seek(1495.0)">
              the relevant time frame for
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:59,266'); seek(1499.0)">
              rate limiting. Unlike the sliding window
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:02,738'); seek(1502.0)">
              log algorithm, it doesn't sort for
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:06,570'); seek(1506.0)">
              all requests. Instead, it keeps track of
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:10,594'); seek(1510.0)">
              the counters for fixed window and calculates a
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:14,202'); seek(1514.0)">
              weighted counter for the sliding window.
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:17,754'); seek(1517.0)">
              When a new request arrives. The algorithm calculates
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:21,846'); seek(1521.0)">
              a weighted counter using the sliding window time frame
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:25,878'); seek(1525.0)">
              and request counters for the previous and current
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:29,294'); seek(1529.0)">
              windows. For that, it uses a percent
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:32,822'); seek(1532.0)">
              of time. The sliding window overlaps with
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:36,542'); seek(1536.0)">
              the previous fixit window, the number of requests
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:40,590'); seek(1540.0)">
              from the previous fixit window, and the number of requests
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:44,790'); seek(1544.0)">
              from the current fixit window. You can see
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:47,980'); seek(1547.0)">
              the formula on the slide. The resulting
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:51,644'); seek(1551.0)">
              value of these calculations is a
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:54,732'); seek(1554.0)">
              weighted counter. Then, the algorithm
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:58,196'); seek(1558.0)">
              compares the weighted counter with the limit value.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:02,924'); seek(1562.0)">
              The request is allowed and processed if
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:06,300'); seek(1566.0)">
              the counter is less or equal to the limit.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:09,964'); seek(1569.0)">
              Otherwise, the request is dropped.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:13,214'); seek(1573.0)">
              The old counters from previous fixed windows
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:16,566'); seek(1576.0)">
              are removed from tracking when they are
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:20,126'); seek(1580.0)">
              no longer relevant for a sliding window. The algorithm
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:24,574'); seek(1584.0)">
              captures recent requests rate trends
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:28,158'); seek(1588.0)">
              more accurately than the fixed window
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:31,542'); seek(1591.0)">
              counter as it considers requests that
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:35,526'); seek(1595.0)">
              fall within the sliding window. Also, it avoids
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:39,590'); seek(1599.0)">
              storing timestamps for all requests,
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:42,962'); seek(1602.0)">
              make it more memory efficient and
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:46,258'); seek(1606.0)">
              easier to implement than sliding window log
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:50,354'); seek(1610.0)">
              algorithm. However, it is
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:53,554'); seek(1613.0)">
              less precise than sliding window log algorithm.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:57,874'); seek(1617.0)">
              The next algorithm is as
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:01,730'); seek(1621.0)">
              you can see from the name, it uses a concept
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:06,014'); seek(1626.0)">
              of a bucket that contains tokens.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:10,174'); seek(1630.0)">
              The bucket has a fixed size
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:14,134'); seek(1634.0)">
              representing the maximum number of tokens it can hold.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:19,014'); seek(1639.0)">
              Each token represents a capacity to process
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:27:22,462'); seek(1642.0)">
              a single request. In other words,
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:27:25,782'); seek(1645.0)">
              the bucket size defines a maximum number of requests
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:29,710'); seek(1649.0)">
              the system can handle at a time.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:33,834'); seek(1653.0)">
              So the bucket size represents rate limit.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:37,994'); seek(1657.0)">
              The bucket is constantly refilled with new tokens
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:41,962'); seek(1661.0)">
              at a constant rate called the refill rate, which defines
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:46,346'); seek(1666.0)">
              how quickly the bucket refills
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:49,626'); seek(1669.0)">
              with tokens over time, ten tokens per
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:53,578'); seek(1673.0)">
              second. Therefore, the refill rate controls
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:57,402'); seek(1677.0)">
              the average rate at which request can be processed.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:01,170'); seek(1681.0)">
              Processed when a request arrives, the algorithm
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:05,650'); seek(1685.0)">
              checks if there are enough tokens in the bucket.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:09,242'); seek(1689.0)">
              If there are tokens in the bucket, it consumes a token or removes
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:28:13,442'); seek(1693.0)">
              it from the bucket and allows to be
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:28:17,314'); seek(1697.0)">
              processed. Otherwise, if the bucket
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:28:20,562'); seek(1700.0)">
              is empty, the request is dropped.
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:25,194'); seek(1705.0)">
              On the one hand, this algorithm is relatively easy to implement.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:29,242'); seek(1709.0)">
              However, it is also slightly more complex
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:32,718'); seek(1712.0)">
              due to the token management logic.
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:36,374'); seek(1716.0)">
              It is efficient and uses low memory because
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:39,526'); seek(1719.0)">
              it keeps tracks of the bucket size, which is typically just
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:43,078'); seek(1723.0)">
              a number that is incremented or documented over
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:47,326'); seek(1727.0)">
              time. It allows
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:51,070'); seek(1731.0)">
              for a smooth distribution of requests,
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:55,094'); seek(1735.0)">
              but bursts of requests up to the bucket's capacitor
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:59,398'); seek(1739.0)">
              possible in cases when the bucket
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:02,782'); seek(1742.0)">
              is full and a large number of requests arrive
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:06,566'); seek(1746.0)">
              simultaneously. And finally, the last
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:10,078'); seek(1750.0)">
              algorithm for today is leaky
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:29:13,294'); seek(1753.0)">
              bucket algorithm. It also uses
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:29:17,358'); seek(1757.0)">
              the concept of a bucket, but in a
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:29:20,614'); seek(1760.0)">
              different way. It is like the analogy of
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:25,174'); seek(1765.0)">
              a bucket with a hole at
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:28,840'); seek(1768.0)">
              the bottom that constantly leaks at a fixed
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:32,256'); seek(1772.0)">
              rate. The bucket can hold a
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:36,624'); seek(1776.0)">
              specific number of requests representing its
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:40,680'); seek(1780.0)">
              maximum capacity. The requests leak
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:45,232'); seek(1785.0)">
              out from the bucket at a fixed rate.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:49,584'); seek(1789.0)">
              This leak rate specifies sustain
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:53,024'); seek(1793.0)">
              it rate at which the system can process requests.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:57,544'); seek(1797.0)">
              When a request arrives and the bucket
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:01,312'); seek(1801.0)">
              is not full, a new request is added to
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:04,408'); seek(1804.0)">
              the bucket and processed. If the bucket
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:07,712'); seek(1807.0)">
              is full, the request is dropped.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:11,104'); seek(1811.0)">
              The liquor bucket algorithm is good at
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:30:14,704'); seek(1814.0)">
              smoothing out requests because the requests
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:30:18,434'); seek(1818.0)">
              leak out and processed at a controlled
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:30:22,738'); seek(1822.0)">
              rate, preventing surges or bursts
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:26,858'); seek(1826.0)">
              of traffic. However, it doesn't
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:30,914'); seek(1830.0)">
              account for the time between requests,
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:34,442'); seek(1834.0)">
              which means if a user sends a
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:38,210'); seek(1838.0)">
              burst of requests quickly,
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:40,954'); seek(1840.0)">
              it all be dropped, even if
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:44,326'); seek(1844.0)">
              they are under the overall rate
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:47,862'); seek(1847.0)">
              limit. We have reviewed rate
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:52,598'); seek(1852.0)">
              limiting algorithms. Each algorithm
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:56,398'); seek(1856.0)">
              has pros and cons, so you should consider
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:01,094'); seek(1861.0)">
              trade offs based on the particular use
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:04,958'); seek(1864.0)">
              case when choosing an algorithm for rate limiting.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:09,394'); seek(1869.0)">
              Also, each algorithm may
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:13,290'); seek(1873.0)">
              be implemented differently depending
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:31:16,954'); seek(1876.0)">
              on the requirements. Now let's look
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:20,530'); seek(1880.0)">
              at the simple implementation of a rate limiter based
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:24,666'); seek(1884.0)">
              on the token bucket algorithm.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:27,474'); seek(1887.0)">
              For the example, I implemented the
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:31:31,586'); seek(1891.0)">
              rate limiter logic in a separate package.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:35,134'); seek(1895.0)">
              Here I use the bucketstruct as
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:39,878'); seek(1899.0)">
              a token bucket. It has two fields, current tokens,
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:43,998'); seek(1903.0)">
              which is the number of tokens currently in the bucket and last refill
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:47,758'); seek(1907.0)">
              time, which is the last time the bucket was refilled.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:52,854'); seek(1912.0)">
              Then I define the token bucket instruct which
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:56,926'); seek(1916.0)">
              represents the rate limiter. It has a mutex
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:00,654'); seek(1920.0)">
              for thread safety and map buckets
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:06,634'); seek(1926.0)">
              that stores a bucket some
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:11,442'); seek(1931.0)">
              key. As a key, I will use the
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:32:14,754'); seek(1934.0)">
              client's ip addresses.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:32:17,754'); seek(1937.0)">
              Also, it has two fields bucket size
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:22,290'); seek(1942.0)">
              which represents maximum number of tokens, a single bucket hand hold
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:26,626'); seek(1946.0)">
              and refill rate, or the rate at which tokens are added
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:32:30,526'); seek(1950.0)">
              to the bucket. Then I define new
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:34,702'); seek(1954.0)">
              token bucket function that just
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:32:38,430'); seek(1958.0)">
              creates a new rate limiter with specified bucket
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:42,174'); seek(1962.0)">
              size, refill rates, and empty buckets.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:45,110'); seek(1965.0)">
              Map this rate limiter has one method
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:49,734'); seek(1969.0)">
              that's called isallowed. This method
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:53,766'); seek(1973.0)">
              checks if a request with the specified key is allowed.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:59,334'); seek(1979.0)">
              If there is no bucket with a
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:33:02,670'); seek(1982.0)">
              given key, it creates a new bucket for the
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:33:06,294'); seek(1986.0)">
              key and allows the request.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:33:09,414'); seek(1989.0)">
              If the key exists. It refills a bucket.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:33:13,414'); seek(1993.0)">
              It checks at least one token
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:33:17,326'); seek(1997.0)">
              in the bucket. If there is a token,
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:20,446'); seek(2000.0)">
              it decrements number of tokens and
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:24,860'); seek(2004.0)">
              allows the request otherwise denies
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:31,804'); seek(2011.0)">
              the refill. Method refills the bucket for
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:35,676'); seek(2015.0)">
              the specified key. It calculates the number of
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:33:39,164'); seek(2019.0)">
              tokens to add based on the time elapsed since the last
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:33:43,036'); seek(2023.0)">
              refill and the refill rate after
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:46,948'); seek(2026.0)">
              that. It adds them to the bucket, up to the bucket
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:50,164'); seek(2030.0)">
              size, and updates the last refill time. I also use
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:55,404'); seek(2035.0)">
              middleware for that example,
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:58,724'); seek(2038.0)">
              I define a middleware to use for rate limiting.
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:34:02,508'); seek(2042.0)">
              I have a simple rate limiter interface that contains only
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:34:06,100'); seek(2046.0)">
              one method is allowed. This interface
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:34:10,764'); seek(2050.0)">
              allows allows us to use
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:34:14,948'); seek(2054.0)">
              different rate limiter implementations depending
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:34:18,708'); seek(2058.0)">
              on our needs and replace them
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:34:22,246'); seek(2062.0)">
              more easily. Then I define rate limiting middleware
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:34:26,710'); seek(2066.0)">
              function. It checks if a request is allowed
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:34:30,366'); seek(2070.0)">
              by calling the isallowed method of the rate
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:33,886'); seek(2073.0)">
              limiter with the remote address of the request.
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:34:37,198'); seek(2077.0)">
              If the request is not allowed, it responds with 429
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:34:43,094'); seek(2083.0)">
              status corresponding status text.
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:46,944'); seek(2086.0)">
              If the request is allowed, it calls the original handler
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:51,368'); seek(2091.0)">
              function. I use the same service
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:55,184'); seek(2095.0)">
              as the previous example, but with a few changes.
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:59,984'); seek(2099.0)">
              Initialize the rate limiter first with a
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:35:03,080'); seek(2103.0)">
              bucket size of one token and refill rate of one token
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:35:07,296'); seek(2107.0)">
              per second. That means that
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:35:10,576'); seek(2110.0)">
              we allow approximately one request
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:35:14,252'); seek(2114.0)">
              per second from a single user,
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:35:18,204'); seek(2118.0)">
              the handler function with the rate limiter middleware,
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:35:21,780'); seek(2121.0)">
              and pass the rate limiting limiter there
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:35:28,364'); seek(2128.0)">
              I use the same test configuration as previous
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:35:31,764'); seek(2131.0)">
              example and the result test
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:35:35,372'); seek(2135.0)">
              results show that even rate limiter allowed
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:35:39,572'); seek(2139.0)">
              us to decrease the average load on the
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:35:43,192'); seek(2143.0)">
              server and the latest is not as high
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:35:46,632'); seek(2146.0)">
              as before. However, it can't improve the performance
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:50,760'); seek(2150.0)">
              significantly in this case. Because rate limiter is
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:54,752'); seek(2154.0)">
              integrated into the service, it also uses the same system
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:59,032'); seek(2159.0)">
              resources. You should always remember about it.
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:36:02,784'); seek(2162.0)">
              Using a rate limiter has its overhead
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:36:06,834'); seek(2166.0)">
              and costs as well. You have to
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:36:10,130'); seek(2170.0)">
              consider different trade offs and find
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:36:14,218'); seek(2174.0)">
              a balance between using a rate limiter and the
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:36:18,114'); seek(2178.0)">
              performance of the service. Moreover,
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:36:21,562'); seek(2181.0)">
              you can't just use the rate limiter from the example
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:36:25,266'); seek(2185.0)">
              in the real production applications because you need some shared
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:36:29,578'); seek(2189.0)">
              state with counters that can be used in all instances
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:36:33,274'); seek(2193.0)">
              of the application. For example, you can use
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:36:36,668'); seek(2196.0)">
              redis to store the counters and get them from redis during rate
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:36:40,404'); seek(2200.0)">
              limiter checks. Also, you will likely need a
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:36:43,940'); seek(2203.0)">
              distributed rate limiter that can be implemented in a separated
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:36:48,012'); seek(2208.0)">
              service, for example in the API,
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:51,356'); seek(2211.0)">
              gateway or other solutions.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:54,884'); seek(2214.0)">
              In addition, on this slide I provided the
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:58,508'); seek(2218.0)">
              list of different implementations of rate limiters in
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:37:02,544'); seek(2222.0)">
              Golang. You can check these packages, see how
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:37:05,928'); seek(2225.0)">
              different algorithms are implemented,
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:37:09,376'); seek(2229.0)">
              and use one of them in your application if
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:37:12,960'); seek(2232.0)">
              it suits your particular use case.
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:37:16,784'); seek(2236.0)">
              We have considered server overload,
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:37:20,664'); seek(2240.0)">
              the rate limiting technique, and common rate limiting algorithms.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:37:24,624'); seek(2244.0)">
              Also, we saw it in examples.
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:37:27,404'); seek(2247.0)">
              Now let's look at another technique
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:37:31,412'); seek(2251.0)">
              called load shedding.
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:37:34,684'); seek(2254.0)">
              Load shedding is another technique that is used
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:37:38,196'); seek(2258.0)">
              to prevent server overload. It is like a controlled
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:37:41,964'); seek(2261.0)">
              shutdown to prevent a total crash during
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:37:46,300'); seek(2266.0)">
              a traffic overload. It can be implemented
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:37:49,756'); seek(2269.0)">
              in different ways. For example, the system can
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:37:54,194'); seek(2274.0)">
              constantly check its resources,
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:37:58,090'); seek(2278.0)">
              such as cpu and memory. If things
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:38:02,338'); seek(2282.0)">
              get overloaded,
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:38:06,074'); seek(2286.0)">
              load shedding kicks in. It might reject
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:38:10,178'); seek(2290.0)">
              random or non critical incoming requests,
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:38:15,754'); seek(2295.0)">
              prioritizing critical ones. Also, the system
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:38:19,938'); seek(2299.0)">
              might slow down process processing for non critical tasks.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:38:24,304'); seek(2304.0)">
              The system also might redirect some requests
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:38:28,424'); seek(2308.0)">
              to other services if possible.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:38:33,024'); seek(2313.0)">
              By sacrificing some requests,
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:38:37,120'); seek(2317.0)">
              the system stays operational for
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:38:40,608'); seek(2320.0)">
              the most important ones. Critical requests
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:38:44,608'); seek(2324.0)">
              still get processed within a reasonable time frame.
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:38:48,574'); seek(2328.0)">
              A controlled slowdown is better
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:38:51,878'); seek(2331.0)">
              than a complete system breakdown in this situation.
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:38:55,974'); seek(2335.0)">
              However, as always, there are some trade offs.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:38:59,414'); seek(2339.0)">
              Users might experience delays
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:39:02,702'); seek(2342.0)">
              or errors for some requests during
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:39:07,366'); seek(2347.0)">
              shedding. Depending on the system, some data
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:39:12,414'); seek(2352.0)">
              processing might be delayed or even lost.
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:39:16,434'); seek(2356.0)">
              So now let's look at an example.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:39:20,674'); seek(2360.0)">
              To demonstrate this technique, I implemented a simple
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:39:24,306'); seek(2364.0)">
              algorithm to decide if the system is overloaded
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:39:28,730'); seek(2368.0)">
              and reject random requests.
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:39:32,994'); seek(2372.0)">
              I will use a ticker from the time package,
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:39:36,434'); seek(2376.0)">
              and I assume that if the system is overloaded
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:39:40,714'); seek(2380.0)">
              we will have some delays and the ticker will not work.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:39:46,264'); seek(2386.0)">
              I strongly do not recommend this algorithm
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:39:51,048'); seek(2391.0)">
              for production applications is just for
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:39:55,544'); seek(2395.0)">
              demonstration purposes. I implemented the
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:39:58,880'); seek(2398.0)">
              logic in a separate package called overload detector.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:40:02,944'); seek(2402.0)">
              Here I define overload detector struct that will
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:40:06,832'); seek(2406.0)">
              be used to detect if a system is overload
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:40:10,640'); seek(2410.0)">
              based on a specified overload factor
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:40:15,284'); seek(2415.0)">
              structure has three fields.
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:40:18,908'); seek(2418.0)">
              Check interval is the duration between each check
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:40:22,780'); seek(2422.0)">
              for overload. For overload overload
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:40:27,788'); seek(2427.0)">
              factor is a duration that is considered as
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:40:32,404'); seek(2432.0)">
              a threshold for overload and is
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:40:35,868'); seek(2435.0)">
              overloaded flag indicating where
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:40:39,432'); seek(2439.0)">
              the system is overloaded. I use bool
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:40:43,656'); seek(2443.0)">
              from the sync atomic package for thread
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:40:47,888'); seek(2447.0)">
              safety. Then I define the new
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:40:52,056'); seek(2452.0)">
              function which just creates a new overload
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:40:55,776'); seek(2455.0)">
              detector arguments and
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:41:00,624'); seek(2460.0)">
              the overload detector check in the background
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:41:05,214'); seek(2465.0)">
              using the run method. Also, I have
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:41:08,574'); seek(2468.0)">
              isoverloaded method that just returns the
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:41:12,198'); seek(2472.0)">
              value for the flag,
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:41:15,094'); seek(2475.0)">
              and in the run method we
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:41:20,694'); seek(2480.0)">
              do the check if the system is overloaded.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:41:24,430'); seek(2484.0)">
              First we initialize the ticker that if the system
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:41:28,086'); seek(2488.0)">
              is overloaded every check interval on
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:41:33,034'); seek(2493.0)">
              each tick, it checks. If the time since the last
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:41:36,634'); seek(2496.0)">
              check is greater than the overload factor,
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:41:40,834'); seek(2500.0)">
              it considers the system as overloaded and sets the
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:41:44,522'); seek(2504.0)">
              flag to the true value. If it is not, it sets
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:41:47,890'); seek(2507.0)">
              the flag to false I also define a middleware for
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:41:52,298'); seek(2512.0)">
              load sharing as I have done for rate
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:41:55,522'); seek(2515.0)">
              limit meeting. I have a simple overload detector
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:41:59,390'); seek(2519.0)">
              interface that contains only one method is overloaded.
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:42:03,814'); seek(2523.0)">
              Then I define the overload detecting
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:42:07,494'); seek(2527.0)">
              middleware function. It checks if request
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:42:11,190'); seek(2531.0)">
              is allowed by calling the isoverloaded method,
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:42:15,614'); seek(2535.0)">
              and if the server is overloaded it responds
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:42:19,518'); seek(2539.0)">
              with 500 and
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:42:23,922'); seek(2543.0)">
              if the system is not overloaded,
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:42:27,914'); seek(2547.0)">
              it calls the original handler function.
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:42:32,794'); seek(2552.0)">
              Again, I use the same service as the previous example but
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:42:36,202'); seek(2556.0)">
              with few changes. I initialize the overload
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:42:39,954'); seek(2559.0)">
              detector with a check interval of ten milliseconds
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:42:43,954'); seek(2563.0)">
              and an overload factor of eleven milliseconds.
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:42:47,690'); seek(2567.0)">
              Then I wrap the handler function with the overload
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:42:52,284'); seek(2572.0)">
              detecting middleware and pass the overload
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:42:56,028'); seek(2576.0)">
              detector. There, I use the same
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:42:59,324'); seek(2579.0)">
              test configuration as the previous examples.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:43:03,284'); seek(2583.0)">
              The test results shows that using the overload shedding
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:43:07,660'); seek(2587.0)">
              allowed us to decrease the average load on the server.
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:43:11,924'); seek(2591.0)">
              Depending on the particular case and requirements,
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:43:15,626'); seek(2595.0)">
              load shedding can be implemented differently in the real production.
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:43:20,754'); seek(2600.0)">
              To understand load shedding better and the
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:43:24,994'); seek(2604.0)">
              approaches for its implementation, I recommend
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:43:29,218'); seek(2609.0)">
              reading this article by a senior principal engineer at
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:43:33,298'); seek(2613.0)">
              Amazon that explains load shedding in more
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:43:37,650'); seek(2617.0)">
              detail. Well, we have explored
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:43:42,034'); seek(2622.0)">
              server overload and how it can
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:43:45,670'); seek(2625.0)">
              affect your services at
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:43:50,126'); seek(2630.0)">
              common reasons for overload and how
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:43:53,950'); seek(2633.0)">
              to identify them.
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:43:56,894'); seek(2636.0)">
              We then reviewed two key techniques to
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:44:00,702'); seek(2640.0)">
              make your systems more resilient, rate limiting,
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:44:04,590'); seek(2644.0)">
              health control incoming traffic and prevent overload
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:44:08,574'); seek(2648.0)">
              before it happens, and load shedding that
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:44:12,610'); seek(2652.0)">
              acts as a safety valve,
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:44:15,874'); seek(2655.0)">
              gracefully degrading service during
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:44:20,034'); seek(2660.0)">
              extreme traffic surges to maintain
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:44:23,658'); seek(2663.0)">
              overall system stability.
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:44:26,274'); seek(2666.0)">
              Understanding and implementing these techniques
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:44:29,890'); seek(2669.0)">
              ensures your services stay healthy
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:44:33,866'); seek(2673.0)">
              and responsive even under heavy
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:44:38,474'); seek(2678.0)">
              load. Remember, a well designed system
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:44:43,714'); seek(2683.0)">
              anticipates traffic spikes and
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:44:47,818'); seek(2687.0)">
              has mechanisms to handle
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:44:51,578'); seek(2691.0)">
              them effectively. So I hope
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:44:55,082'); seek(2695.0)">
              you found this talk helpful. Thanks for
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:44:58,826'); seek(2698.0)">
              your time.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Ivan%20Lemeshev%20-%20Conf42%20Golang%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Ivan%20Lemeshev%20-%20Conf42%20Golang%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #881E4B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/golang2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #881E4B;">
                <i class="fe fe-grid me-2"></i>
                See all 21 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Ivan%20Lemeshev_golang.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Ivan Lemeshev
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Software Engineer, International Team @ Unity
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/ivanlemeshev/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Ivan Lemeshev's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Ivan Lemeshev"
                  data-url="https://www.conf42.com/golang2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/golang2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Golang"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>