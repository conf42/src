<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Techniques for SLOs and Error Budgets at Scale</title>
    <meta name="description" content="See the unseen, go beyond the code!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/fred%20moyer_obser.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Techniques for SLOs and Error Budgets at Scale | Conf42"/>
    <meta property="og:description" content="What tactics can you use to implement service level objectives and error budgets to operate enterprise-level services with a thousand (or more) engineers? Fred Moyer takes you through approaches heâ€™s developed working with teams in a large production ecosystem where service reliability was a nonnegotiable business requirement. Engineers and operations folks who are putting SLIs, SLOs, and error budgets into practice in high-scale production environments with diverse service architectures should come away with an understanding of how to democratize SLOs, what objectives they should target for enterprise-level reliability, and how to communicate and implement error budgets across multiple teams."/>
    <meta property="og:url" content="https://conf42.com/Observability_2023_Fred_Moyer_slos_error_budgets_scale"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/LLM2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Large Language Models (LLMs) 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-04-11
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/aiml2024">
                            Artificial Intelligence & Machine Learning (AI & ML)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/olly2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday London
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/DnyHgrC7jC" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #A8AC51;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Observability 2023 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- See the unseen, go beyond the code!
 -->
              <script>
                const event_date = new Date("2023-06-08T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2023-06-08T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "c8Tjbmq66UU"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "PjHH2JiND0o"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrBCCwdUZP57C0rqM6HmC3GD" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hey folks, welcome to my talk about techniques for slos", "timestamp": "00:00:23,050", "timestamp_s": 23.0}, {"text": "and air budgets at scale. I\u0027m proud to be presenting here at", "timestamp": "00:00:27,042", "timestamp_s": 27.0}, {"text": "Conf 42 observability in 2023. I\u0027ve been talking a lot", "timestamp": "00:00:30,540", "timestamp_s": 30.0}, {"text": "about slos and air budgets over the past six or so years, and over that", "timestamp": "00:00:34,028", "timestamp_s": 34.0}, {"text": "time I\u0027ve given variations of this talk in different", "timestamp": "00:00:37,996", "timestamp_s": 37.0}, {"text": "online conferences and also a couple in person. So I\u0027m", "timestamp": "00:00:41,516", "timestamp_s": 41.0}, {"text": "pleased to be presenting some of my learnings over the past couple of years.", "timestamp": "00:00:45,394", "timestamp_s": 45.0}, {"text": "This is basically the greatest its version of the previous talks I\u0027ve", "timestamp": "00:00:48,604", "timestamp_s": 48.0}, {"text": "given on the subject. Let\u0027s get started. But first, I know", "timestamp": "00:00:52,042", "timestamp_s": 52.0}, {"text": "this is an online conference, but let\u0027s do a little survey.", "timestamp": "00:00:55,588", "timestamp_s": 55.0}, {"text": "Raise your hand. I know you\u0027re sitting there just at home by yourself,", "timestamp": "00:00:59,130", "timestamp_s": 59.0}, {"text": "but raise your hand if you know what this graph is. And this is one", "timestamp": "00:01:02,196", "timestamp_s": 62.0}, {"text": "of those graphs that if you know, you know. We\u0027re all here today", "timestamp": "00:01:05,524", "timestamp_s": 65.0}, {"text": "in part because of this thing. And if you don\u0027t know what this is,", "timestamp": "00:01:09,000", "timestamp_s": 69.0}, {"text": "that\u0027s okay. We\u0027ll go ahead and come back to that a little bit later.", "timestamp": "00:01:12,504", "timestamp_s": 72.0}, {"text": "So, hi, I\u0027m Fred. I\u0027m a observability", "timestamp": "00:01:15,944", "timestamp_s": 75.0}, {"text": "engineer at a large public company, and this talk is", "timestamp": "00:01:19,250", "timestamp_s": 79.0}, {"text": "my own opinions, not those my employers. Basic disclaimer", "timestamp": "00:01:23,676", "timestamp_s": 83.0}, {"text": "and so I\u0027ve been working on", "timestamp": "00:01:27,554", "timestamp_s": 87.0}, {"text": "monitoring observability for about as long as the graph on the previous slide,", "timestamp": "00:01:31,740", "timestamp_s": 91.0}, {"text": "but focusing on it heavily over the past ten or so years.", "timestamp": "00:01:35,478", "timestamp_s": 95.0}, {"text": "I like to think about slos, Slis and air budgets,", "timestamp": "00:01:38,704", "timestamp_s": 98.0}, {"text": "hence the SLOS Jason term, I think that was coined in the original", "timestamp": "00:01:42,154", "timestamp_s": 102.0}, {"text": "Google SlO paper. I like to hack on", "timestamp": "00:01:45,482", "timestamp_s": 105.0}, {"text": "histograms, metrics, logs and traces. Been programming", "timestamp": "00:01:48,930", "timestamp_s": 108.0}, {"text": "a lot of stuff for the past 20 years, and I\u0027ve got two young kids,", "timestamp": "00:01:52,442", "timestamp_s": 112.0}, {"text": "so I definitely am in need of more sleep and coffee. But let\u0027s go", "timestamp": "00:01:56,584", "timestamp_s": 116.0}, {"text": "ahead and kick this off. So how", "timestamp": "00:01:59,768", "timestamp_s": 119.0}, {"text": "do you implement slos for 1000 plus engineers?", "timestamp": "00:02:03,320", "timestamp_s": 123.0}, {"text": "And this was a challenge I encountered about four years", "timestamp": "00:02:06,782", "timestamp_s": 126.0}, {"text": "ago when I started a role at a company called Zendesk.", "timestamp": "00:02:10,812", "timestamp_s": 130.0}, {"text": "And I got tasked with a project to bring slos to an engineering", "timestamp": "00:02:14,178", "timestamp_s": 134.0}, {"text": "organization that had over a thousand engineers, which was", "timestamp": "00:02:17,602", "timestamp_s": 137.0}, {"text": "quite a few. And there was a big push to make the product", "timestamp": "00:02:21,548", "timestamp_s": 141.0}, {"text": "as reliable as possible. We called reliability our number one feature.", "timestamp": "00:02:24,736", "timestamp_s": 144.0}, {"text": "So I had to come up with a way to roll out slos and air", "timestamp": "00:02:28,742", "timestamp_s": 148.0}, {"text": "budgets across all those engineers. And to", "timestamp": "00:02:31,572", "timestamp_s": 151.0}, {"text": "do that effectively, I really had to understand what", "timestamp": "00:02:35,716", "timestamp_s": 155.0}, {"text": "slis and slos, and hence air budgets were programmatically.", "timestamp": "00:02:39,572", "timestamp_s": 159.0}, {"text": "So I really dove in and started to research the subject a lot to kind", "timestamp": "00:02:43,898", "timestamp_s": 163.0}, {"text": "of go back to the basics.", "timestamp": "00:02:47,288", "timestamp_s": 167.0}, {"text": "And speaking of basics, I started off by reading the original Google SRE", "timestamp": "00:02:50,470", "timestamp_s": 170.0}, {"text": "book, followed that up with the SRE workbook,", "timestamp": "00:02:54,126", "timestamp_s": 174.0}, {"text": "watched Liz Fong Jones and Seth Fargo\u0027s", "timestamp": "00:02:57,858", "timestamp_s": 177.0}, {"text": "Google Cloud presentation on slos titled slis,", "timestamp": "00:03:01,346", "timestamp_s": 181.0}, {"text": "slos, slos. Oh my. Which was an inspiration to me.", "timestamp": "00:03:04,802", "timestamp_s": 184.0}, {"text": "And I\u0027ve given a number of SLO talks previously, most notably", "timestamp": "00:03:08,316", "timestamp_s": 188.0}, {"text": "one called Latency SLos done right, which was also given at", "timestamp": "00:03:11,846", "timestamp_s": 191.0}, {"text": "Srecon by Theo Schlossnagel and Heinrich Hartman,", "timestamp": "00:03:15,728", "timestamp_s": 195.0}, {"text": "who\u0027ve written a lot on the subject. And even", "timestamp": "00:03:19,142", "timestamp_s": 199.0}, {"text": "looking back at that talk I gave, I can spot the errors in it,", "timestamp": "00:03:22,976", "timestamp_s": 202.0}, {"text": "which were kind of subtle. But what I found researching this topic", "timestamp": "00:03:26,756", "timestamp_s": 206.0}, {"text": "here is there wasn\u0027t really a prescription for slis and slos.", "timestamp": "00:03:30,122", "timestamp_s": 210.0}, {"text": "The Google books talked a lot about slis, but were vague on the", "timestamp": "00:03:34,010", "timestamp_s": 214.0}, {"text": "subject as far as specific examples were concerned. And even working through some", "timestamp": "00:03:37,288", "timestamp_s": 217.0}, {"text": "of the examples in the workbook, I either found subtle", "timestamp": "00:03:41,064", "timestamp_s": 221.0}, {"text": "omissions or places where the examples weren\u0027t completely", "timestamp": "00:03:45,118", "timestamp_s": 225.0}, {"text": "flushed out and tested. Liz and Seth\u0027s Google Cloud video", "timestamp": "00:03:49,370", "timestamp_s": 229.0}, {"text": "had some concise definitions, so I took those as a base and expanded", "timestamp": "00:03:53,196", "timestamp_s": 233.0}, {"text": "on them, and those are in use by some of the major SLO vendors out", "timestamp": "00:03:56,658", "timestamp_s": 236.0}, {"text": "there now. And over the next few years,", "timestamp": "00:04:00,048", "timestamp_s": 240.0}, {"text": "there was kind of what I call a cambrian SLO explosion.", "timestamp": "00:04:03,184", "timestamp_s": 243.0}, {"text": "Get it? Slo explosion. Little dad joke there.", "timestamp": "00:04:07,030", "timestamp_s": 247.0}, {"text": "But there was this explosion in SLO material with SLO", "timestamp": "00:04:10,656", "timestamp_s": 250.0}, {"text": "specific conferences and also Alex Sedalgo\u0027s book on implementing slos.", "timestamp": "00:04:14,362", "timestamp_s": 254.0}, {"text": "So I got to work creating formulas that can be shared across a large organization,", "timestamp": "00:04:18,682", "timestamp_s": 258.0}, {"text": "which would leave little room for creativity and variance because I wanted everyone", "timestamp": "00:04:23,274", "timestamp_s": 263.0}, {"text": "on the same page, I wanted to be able to give prescriptive formulas", "timestamp": "00:04:27,016", "timestamp_s": 267.0}, {"text": "that could be implemented at broad scale.", "timestamp": "00:04:30,862", "timestamp_s": 270.0}, {"text": "So this is what I came up with. The definition", "timestamp": "00:04:35,430", "timestamp_s": 275.0}, {"text": "of an SLI is what I use to put examples together.", "timestamp": "00:04:39,138", "timestamp_s": 279.0}, {"text": "Now, there\u0027s two major SLI opinionations, though the difference between them", "timestamp": "00:04:43,020", "timestamp_s": 283.0}, {"text": "is a bit subtle at first glance. The first is from the Google", "timestamp": "00:04:47,052", "timestamp_s": 287.0}, {"text": "SRE book, which describes an SLI,", "timestamp": "00:04:50,400", "timestamp_s": 290.0}, {"text": "pardon me, as a measurement of system performance. The second,", "timestamp": "00:04:54,006", "timestamp_s": 294.0}, {"text": "which I found first in Liz and Seth\u0027s video,", "timestamp": "00:04:58,128", "timestamp_s": 298.0}, {"text": "describes an SLI as something that delineates good requests from bad requests.", "timestamp": "00:05:01,920", "timestamp_s": 301.0}, {"text": "And that second opinion is really one that resonated well with me.", "timestamp": "00:05:06,058", "timestamp_s": 306.0}, {"text": "So in know, both opinionations did", "timestamp": "00:05:10,052", "timestamp_s": 310.0}, {"text": "service at Google, even though they\u0027re", "timestamp": "00:05:13,592", "timestamp_s": 313.0}, {"text": "somewhat conflicting. But the second, as I mentioned, is implemented", "timestamp": "00:05:17,070", "timestamp_s": 317.0}, {"text": "more broadly by practitioners and vendors that I found.", "timestamp": "00:05:20,990", "timestamp_s": 320.0}, {"text": "And I decided to base my example on that second opinionation,", "timestamp": "00:05:24,360", "timestamp_s": 324.0}, {"text": "not only because it had wider acceptance because intuitively it made more sense", "timestamp": "00:05:28,654", "timestamp_s": 328.0}, {"text": "to me. I spent quite a bit of time dissecting", "timestamp": "00:05:32,492", "timestamp_s": 332.0}, {"text": "those examples in the Google SRE book and the SRE workbook,", "timestamp": "00:05:35,602", "timestamp_s": 335.0}, {"text": "and they were good.", "timestamp": "00:05:39,350", "timestamp_s": 339.0}, {"text": "But I think the evolution of slis", "timestamp": "00:05:42,480", "timestamp_s": 342.0}, {"text": "and slos at Google probably bifurcated because they", "timestamp": "00:05:46,614", "timestamp_s": 346.0}, {"text": "have a lot of teams there. And that\u0027s not a criticism of the book or", "timestamp": "00:05:50,368", "timestamp_s": 350.0}, {"text": "the organization. But the definitions that I came across seemed to", "timestamp": "00:05:53,828", "timestamp_s": 353.0}, {"text": "be more abstract than what I was looking for. And so here are", "timestamp": "00:05:57,428", "timestamp_s": 357.0}, {"text": "three examples of slis for the second SLI opinionation", "timestamp": "00:06:01,028", "timestamp_s": 361.0}, {"text": "that I moved forward with. They each consist of three things.", "timestamp": "00:06:05,402", "timestamp_s": 365.0}, {"text": "A metric identifier, a metric operator, and a metric value.", "timestamp": "00:06:08,552", "timestamp_s": 368.0}, {"text": "This approach is one that is straightforward for a human being to understand,", "timestamp": "00:06:12,744", "timestamp_s": 372.0}, {"text": "but also fits easily into most of the open source", "timestamp": "00:06:16,072", "timestamp_s": 376.0}, {"text": "and commercial monitoring and observability software out there.", "timestamp": "00:06:19,778", "timestamp_s": 379.0}, {"text": "The part of the SLI definition which requires the most consideration is what", "timestamp": "00:06:22,876", "timestamp_s": 382.0}, {"text": "that metric value should be. And that\u0027s one that is often tuned", "timestamp": "00:06:26,428", "timestamp_s": 386.0}, {"text": "or calibrated by an engineering team, either for latency,", "timestamp": "00:06:30,710", "timestamp_s": 390.0}, {"text": "most often, sometimes with error", "timestamp": "00:06:34,326", "timestamp_s": 394.0}, {"text": "response codes, like a five, xx. That\u0027s pretty clear that that\u0027s a bad", "timestamp": "00:06:38,374", "timestamp_s": 398.0}, {"text": "request, but it\u0027s going to be up to engineering teams to determine,", "timestamp": "00:06:41,552", "timestamp_s": 401.0}, {"text": "like, is a 404 a bad request, or is", "timestamp": "00:06:45,322", "timestamp_s": 405.0}, {"text": "that just clients thinking that they\u0027re going to the right place?", "timestamp": "00:06:49,108", "timestamp_s": 409.0}, {"text": "Because really, all of this stuff is about feeling customer", "timestamp": "00:06:52,856", "timestamp_s": 412.0}, {"text": "pain and wanting to make sure that they have a great experience.", "timestamp": "00:06:56,744", "timestamp_s": 416.0}, {"text": "And so I kind of cemented this", "timestamp": "00:07:01,510", "timestamp_s": 421.0}, {"text": "example so that I could socialize widely", "timestamp": "00:07:05,160", "timestamp_s": 425.0}, {"text": "within the engineering of what an SLI was,", "timestamp": "00:07:08,466", "timestamp_s": 428.0}, {"text": "which teams to what\u0027s an slO?", "timestamp": "00:07:11,770", "timestamp_s": 431.0}, {"text": "And that definition came", "timestamp": "00:07:14,498", "timestamp_s": 434.0}, {"text": "down to the number of good requests divided by the number of bad requests", "timestamp": "00:07:18,092", "timestamp_s": 438.0}, {"text": "over a time range. And this is often called a", "timestamp": "00:07:21,542", "timestamp_s": 441.0}, {"text": "request based slos, where you count up the number of requests and see if", "timestamp": "00:07:25,088", "timestamp_s": 445.0}, {"text": "you got 99% of them right over a certain time range.", "timestamp": "00:07:29,168", "timestamp_s": 449.0}, {"text": "And I called the", "timestamp": "00:07:32,430", "timestamp_s": 452.0}, {"text": "three different components here a little bit different. In the red, we have the", "timestamp": "00:07:36,292", "timestamp_s": 456.0}, {"text": "success objective, which is your typical how many nines?", "timestamp": "00:07:39,572", "timestamp_s": 459.0}, {"text": "And then we drop the SLI in, which works really well for a lot of", "timestamp": "00:07:42,794", "timestamp_s": 462.0}, {"text": "the tooling out there. Then we have a period. And if you don\u0027t have a", "timestamp": "00:07:46,104", "timestamp_s": 466.0}, {"text": "time period here, you don\u0027t really have an slO,", "timestamp": "00:07:49,768", "timestamp_s": 469.0}, {"text": "because it\u0027s really important to specify this so that", "timestamp": "00:07:52,686", "timestamp_s": 472.0}, {"text": "you\u0027re evaluating it over something that\u0027s meaningful to the customer.", "timestamp": "00:07:56,008", "timestamp_s": 476.0}, {"text": "And one question that has come up is, how do I", "timestamp": "00:08:00,570", "timestamp_s": 480.0}, {"text": "know how many nines to choose for this success objective? When I was at Zenesk,", "timestamp": "00:08:03,884", "timestamp_s": 483.0}, {"text": "we had an engineering vp named Jason Smale, who was very", "timestamp": "00:08:07,794", "timestamp_s": 487.0}, {"text": "technical and engineers had him highly regarded.", "timestamp": "00:08:11,392", "timestamp_s": 491.0}, {"text": "And so he said, we need to hit three and a half", "timestamp": "00:08:14,838", "timestamp_s": 494.0}, {"text": "nines. And so that 99.95%", "timestamp": "00:08:17,952", "timestamp_s": 497.0}, {"text": "number became known as Smale\u0027s number. And if reliability dipped", "timestamp": "00:08:22,224", "timestamp_s": 502.0}, {"text": "below that number, it usually meant that a customer somewhere was feeling pain.", "timestamp": "00:08:25,818", "timestamp_s": 505.0}, {"text": "And this is really, if you want to get into enterprise software,", "timestamp": "00:08:29,076", "timestamp_s": 509.0}, {"text": "this is kind of, you must meet this criteria to", "timestamp": "00:08:32,522", "timestamp_s": 512.0}, {"text": "get on the ride. And so now", "timestamp": "00:08:36,040", "timestamp_s": 516.0}, {"text": "that you realize you\u0027re dealing with enterprise customers and you need three and a half", "timestamp": "00:08:40,472", "timestamp_s": 520.0}, {"text": "nines, how do you pick an appropriate metric value for your SLI,", "timestamp": "00:08:43,448", "timestamp_s": 523.0}, {"text": "since that\u0027s the only dependent variable? Now that you fix the objective at 99.95,", "timestamp": "00:08:46,734", "timestamp_s": 526.0}, {"text": "and this is essentially what I call calibrating your slO. Take a", "timestamp": "00:08:52,172", "timestamp_s": 532.0}, {"text": "time period of known good performance, set your objective at 99.95,", "timestamp": "00:08:55,788", "timestamp_s": 535.0}, {"text": "and iterate across your SLI to figure out what", "timestamp": "00:08:59,804", "timestamp_s": 539.0}, {"text": "latency value gives you that 99.95%.", "timestamp": "00:09:03,008", "timestamp_s": 543.0}, {"text": "In this example, it could be 100 milliseconds. And I was able to develop", "timestamp": "00:09:06,960", "timestamp_s": 546.0}, {"text": "some simple tooling to do that, or use", "timestamp": "00:09:10,896", "timestamp_s": 550.0}, {"text": "our commercial monitoring tooling to do that, and developed a dashboard", "timestamp": "00:09:14,404", "timestamp_s": 554.0}, {"text": "where engineers could set their objective at 99 and", "timestamp": "00:09:18,138", "timestamp_s": 558.0}, {"text": "a half and then iterate over their latency to see kind of", "timestamp": "00:09:21,588", "timestamp_s": 561.0}, {"text": "what latency value was it that the customers were getting these three", "timestamp": "00:09:25,750", "timestamp_s": 565.0}, {"text": "and a half nines performance. And just", "timestamp": "00:09:28,984", "timestamp_s": 568.0}, {"text": "to reiterate, the time period here is very important,", "timestamp": "00:09:32,408", "timestamp_s": 572.0}, {"text": "and this is a common oversight that I\u0027ve seen in most of the literature.", "timestamp": "00:09:35,352", "timestamp_s": 575.0}, {"text": "They\u0027ll say, take an slo of 100 milliseconds at 99.9%,", "timestamp": "00:09:38,478", "timestamp_s": 578.0}, {"text": "but what time period is that over? Is it over a minute,", "timestamp": "00:09:43,388", "timestamp_s": 583.0}, {"text": "an hour, a week? And you", "timestamp": "00:09:46,194", "timestamp_s": 586.0}, {"text": "can, and you probably should have slos which use the same success objective in", "timestamp": "00:09:49,948", "timestamp_s": 589.0}, {"text": "SLI but different time operations. Depending on the stakeholder, an engineers", "timestamp": "00:09:53,808", "timestamp_s": 593.0}, {"text": "manager might want to know the reliability Moyer a week so they", "timestamp": "00:09:58,054", "timestamp_s": 598.0}, {"text": "can schedule reliability work. A director might want to know it", "timestamp": "00:10:01,584", "timestamp_s": 601.0}, {"text": "over a month, and a vp might want to know how reliable the service was", "timestamp": "00:10:04,944", "timestamp_s": 604.0}, {"text": "over a quarter for reporting to c staff or putting the direction of technical", "timestamp": "00:10:08,612", "timestamp_s": 608.0}, {"text": "efforts. And the purpose of", "timestamp": "00:10:12,186", "timestamp_s": 612.0}, {"text": "slos is often to prioritize reliability work.", "timestamp": "00:10:15,672", "timestamp_s": 615.0}, {"text": "That is, if you aren\u0027t meeting your slos, you want to deprioritize", "timestamp": "00:10:19,160", "timestamp_s": 619.0}, {"text": "feature work in favor of reliability engineering.", "timestamp": "00:10:22,622", "timestamp_s": 622.0}, {"text": "And we want to do this. We want to", "timestamp": "00:10:25,550", "timestamp_s": 625.0}, {"text": "use these operations to do this because we want to be accurate. If we reprioritize", "timestamp": "00:10:29,080", "timestamp_s": 629.0}, {"text": "engineering resources, that is expensive. So we want to make sure that we\u0027re", "timestamp": "00:10:33,282", "timestamp_s": 633.0}, {"text": "doing that based off data that\u0027s correct and precise.", "timestamp": "00:10:37,058", "timestamp_s": 637.0}, {"text": "Now let\u0027s take a quick look at error budgets.", "timestamp": "00:10:40,582", "timestamp_s": 640.0}, {"text": "So an error budget is essentially just an inverted slO.", "timestamp": "00:10:43,630", "timestamp_s": 643.0}, {"text": "You subtract your success objective from one and you get your allowed failure", "timestamp": "00:10:46,950", "timestamp_s": 646.0}, {"text": "rate. For user requests like a financial budget, you have a certain amount of", "timestamp": "00:10:50,838", "timestamp_s": 650.0}, {"text": "errors that you can spend over a time period, and ideally", "timestamp": "00:10:54,628", "timestamp_s": 654.0}, {"text": "this is an amount that does not make your customers think that your service is", "timestamp": "00:10:57,978", "timestamp_s": 657.0}, {"text": "unreliable. You can create monitors for this with most of", "timestamp": "00:11:01,252", "timestamp_s": 661.0}, {"text": "the tooling out there and perhaps alert when, say, 80% of your", "timestamp": "00:11:04,948", "timestamp_s": 664.0}, {"text": "error budget has been used up for a given time period, which will let", "timestamp": "00:11:08,168", "timestamp_s": 668.0}, {"text": "your engineering teams know that it\u0027s time to work on reliability.", "timestamp": "00:11:11,928", "timestamp_s": 671.0}, {"text": "You can also alert when the rate of an error budget burn", "timestamp": "00:11:16,390", "timestamp_s": 676.0}, {"text": "predicts that you will exhaust your error budget before the time period has", "timestamp": "00:11:20,402", "timestamp_s": 680.0}, {"text": "elapsed. And tooling. A lot of the tooling out there has functionality", "timestamp": "00:11:23,852", "timestamp_s": 683.0}, {"text": "for that. So there are really two conditions that your error budget should", "timestamp": "00:11:27,922", "timestamp_s": 687.0}, {"text": "spur action. First, if it\u0027s being used up too quickly and is in danger", "timestamp": "00:11:31,648", "timestamp_s": 691.0}, {"text": "of being exhausted for that period, that should prioritize", "timestamp": "00:11:35,414", "timestamp_s": 695.0}, {"text": "reliability focused work. The second is if your air budget is", "timestamp": "00:11:38,726", "timestamp_s": 698.0}, {"text": "not being used up at all, that could indicate an improperly", "timestamp": "00:11:42,288", "timestamp_s": 702.0}, {"text": "calibrated slo. Or it might mean that your service is normally so reliable", "timestamp": "00:11:46,266", "timestamp_s": 706.0}, {"text": "that you\u0027re not prioritizing enough feature work, or that you should embark", "timestamp": "00:11:50,186", "timestamp_s": 710.0}, {"text": "on controlled error budgets. Burns Google did that and mentioned", "timestamp": "00:11:53,738", "timestamp_s": 713.0}, {"text": "it in the SRE book. With their chubby service, which was the distributed lock", "timestamp": "00:11:57,272", "timestamp_s": 717.0}, {"text": "service, they introduced artificial air budget burn into", "timestamp": "00:12:00,878", "timestamp_s": 720.0}, {"text": "their consumption into the service so that", "timestamp": "00:12:04,616", "timestamp_s": 724.0}, {"text": "consumers of chubby would have to", "timestamp": "00:12:08,252", "timestamp_s": 728.0}, {"text": "make their services be able to tolerate those chubby failures and", "timestamp": "00:12:12,410", "timestamp_s": 732.0}, {"text": "hence become more reliable. And again, like slos,", "timestamp": "00:12:15,932", "timestamp_s": 735.0}, {"text": "air budgets should reflect the mindset of the customer as much as", "timestamp": "00:12:19,330", "timestamp_s": 739.0}, {"text": "possible. If the air budget is not exhausted but your customer is on", "timestamp": "00:12:22,752", "timestamp_s": 742.0}, {"text": "the phone with your vp, go take a look at what you are measuring and", "timestamp": "00:12:26,544", "timestamp_s": 746.0}, {"text": "if it really reflects what the customer is experiencing.", "timestamp": "00:12:30,272", "timestamp_s": 750.0}, {"text": "So, to sum up what I\u0027ve showed you so far, there\u0027s a few points on", "timestamp": "00:12:34,030", "timestamp_s": 754.0}, {"text": "getting thousands of engineers on the same page for slos and air budgets.", "timestamp": "00:12:37,588", "timestamp_s": 757.0}, {"text": "First, you need real world examples. Most of the published", "timestamp": "00:12:41,418", "timestamp_s": 761.0}, {"text": "books out there are a bit abstract and hand wavy and", "timestamp": "00:12:44,954", "timestamp_s": 764.0}, {"text": "don\u0027t really give you complete examples, so you need to have those to show", "timestamp": "00:12:48,648", "timestamp_s": 768.0}, {"text": "folks. Second, present formulas for each of those entities", "timestamp": "00:12:52,312", "timestamp_s": 772.0}, {"text": "which can be read easily both by humans and machines, and I\u0027ve", "timestamp": "00:12:56,446", "timestamp_s": 776.0}, {"text": "shown you what I used at scale there. Third, you have to be", "timestamp": "00:13:00,354", "timestamp_s": 780.0}, {"text": "detailed and consistent. I see so many slos out there", "timestamp": "00:13:04,028", "timestamp_s": 784.0}, {"text": "that leave off the time period, you might say well, the time range can", "timestamp": "00:13:07,292", "timestamp_s": 787.0}, {"text": "be whatever you want, but then it\u0027s not can actual", "timestamp": "00:13:10,688", "timestamp_s": 790.0}, {"text": "or actionable slos or air budget without a time range.", "timestamp": "00:13:15,632", "timestamp_s": 795.0}, {"text": "So we\u0027ve looked at some example slos", "timestamp": "00:13:20,190", "timestamp_s": 800.0}, {"text": "that most engineers can parse and memorize, and which engineering managers and product managers", "timestamp": "00:13:23,322", "timestamp_s": 803.0}, {"text": "can use to correlate user happiness with. In most cases,", "timestamp": "00:13:27,674", "timestamp_s": 807.0}, {"text": "that happiness means your service is available and it\u0027s running fast.", "timestamp": "00:13:31,370", "timestamp_s": 811.0}, {"text": "We can take the formulas I just showed and extend them to cover both conditions", "timestamp": "00:13:35,352", "timestamp_s": 815.0}, {"text": "at once. So here we\u0027re talking about not only availability,", "timestamp": "00:13:39,278", "timestamp_s": 819.0}, {"text": "but also latency and both of those. You need to", "timestamp": "00:13:43,470", "timestamp_s": 823.0}, {"text": "have both of those. So here\u0027s an example SLI SLO", "timestamp": "00:13:47,004", "timestamp_s": 827.0}, {"text": "and error budget, which covers both latency and availability. So if", "timestamp": "00:13:51,442", "timestamp_s": 831.0}, {"text": "the page response is not a five xx or request was", "timestamp": "00:13:55,388", "timestamp_s": 835.0}, {"text": "served in under 100 milliseconds, that request can be considered to", "timestamp": "00:13:58,956", "timestamp_s": 838.0}, {"text": "be a good request. That\u0027s our slis to which we", "timestamp": "00:14:02,848", "timestamp_s": 842.0}, {"text": "can add a success objective of three and a half nines and a time", "timestamp": "00:14:06,048", "timestamp_s": 846.0}, {"text": "range of seven days to be evaluated on. To get the", "timestamp": "00:14:09,232", "timestamp_s": 849.0}, {"text": "error budget, we can subtract a success objective of 99.95%", "timestamp": "00:14:12,788", "timestamp_s": 852.0}, {"text": "from one, which gives us can error budget of zero 5%.", "timestamp": "00:14:17,796", "timestamp_s": 857.0}, {"text": "It\u0027s easy to understand and you can also easily create multiple", "timestamp": "00:14:22,404", "timestamp_s": 862.0}, {"text": "slos and error budgets from the base SLI just by extending the time range.", "timestamp": "00:14:26,222", "timestamp_s": 866.0}, {"text": "Now, on the point of the success objective here I", "timestamp": "00:14:30,670", "timestamp_s": 870.0}, {"text": "have 99.95% listed.", "timestamp": "00:14:33,848", "timestamp_s": 873.0}, {"text": "It\u0027s three and a half nine. Realistically, this is what enterprise", "timestamp": "00:14:36,958", "timestamp_s": 876.0}, {"text": "customers demand these days. That means out of a million requests,", "timestamp": "00:14:40,722", "timestamp_s": 880.0}, {"text": "you only get 500 requests that are slow or", "timestamp": "00:14:44,786", "timestamp_s": 884.0}, {"text": "return what we also known was a fail or the 500", "timestamp": "00:14:48,572", "timestamp_s": 888.0}, {"text": "internal server error as an example. And so if you\u0027re at scale,", "timestamp": "00:14:52,896", "timestamp_s": 892.0}, {"text": "this should be your success objective. And I go into this in depth", "timestamp": "00:14:56,966", "timestamp_s": 896.0}, {"text": "a little bit in the presentation shown below on the link for my Srecon", "timestamp": "00:15:00,838", "timestamp_s": 900.0}, {"text": "presentation. So at this point we\u0027ve", "timestamp": "00:15:04,506", "timestamp_s": 904.0}, {"text": "got example formulas for slis, slos and air budgets that should", "timestamp": "00:15:08,042", "timestamp_s": 908.0}, {"text": "be easy for folks to understand and also straightforward to implement", "timestamp": "00:15:11,828", "timestamp_s": 911.0}, {"text": "with most monitoring and observability tooling out there,", "timestamp": "00:15:15,422", "timestamp_s": 915.0}, {"text": "both open source and commercial. Of the two components of latency", "timestamp": "00:15:18,376", "timestamp_s": 918.0}, {"text": "and availability, availability is generally pretty easy to measure.", "timestamp": "00:15:22,046", "timestamp_s": 922.0}, {"text": "The most simple example is a 500 response.", "timestamp": "00:15:25,950", "timestamp_s": 925.0}, {"text": "You see the sorry a problem occurred. Web page latency,", "timestamp": "00:15:29,450", "timestamp_s": 929.0}, {"text": "however, is more difficult to get right at scale. And when I say", "timestamp": "00:15:33,458", "timestamp_s": 933.0}, {"text": "get it right, there are two aspects of being right. First,", "timestamp": "00:15:37,420", "timestamp_s": 937.0}, {"text": "does your measurement have the right precision for your scale?", "timestamp": "00:15:41,152", "timestamp_s": 941.0}, {"text": "That is, if I have 1 million user requests, can you generate", "timestamp": "00:15:45,150", "timestamp_s": 945.0}, {"text": "a latency aggregate which means you aren\u0027t leaving more than a few dozen users", "timestamp": "00:15:48,758", "timestamp_s": 948.0}, {"text": "off precision. Here is the number of decimal places.", "timestamp": "00:15:52,618", "timestamp_s": 952.0}, {"text": "The other aspect is accuracy. Is your latency aggregate", "timestamp": "00:15:56,874", "timestamp_s": 956.0}, {"text": "for an SLO or a monitor actually correct? In many cases I\u0027ve seen", "timestamp": "00:16:00,458", "timestamp_s": 960.0}, {"text": "that answer is no to both and precision", "timestamp": "00:16:04,232", "timestamp_s": 964.0}, {"text": "versus accuracy. Precision is the number of decimal places.", "timestamp": "00:16:08,702", "timestamp_s": 968.0}, {"text": "Accuracy is are the values in those decimal places correct?", "timestamp": "00:16:12,270", "timestamp_s": 972.0}, {"text": "So let\u0027s dive in. So coming", "timestamp": "00:16:16,108", "timestamp_s": 976.0}, {"text": "back to this chart. This chart is an", "timestamp": "00:16:19,996", "timestamp_s": 979.0}, {"text": "RRD graph, and it measures network usage and calculates the 95th", "timestamp": "00:16:23,900", "timestamp_s": 983.0}, {"text": "percentile over a time period. And at the", "timestamp": "00:16:27,458", "timestamp_s": 987.0}, {"text": "time of the.com boom, you saw a lot of these RRD", "timestamp": "00:16:30,848", "timestamp_s": 990.0}, {"text": "graphs, and these were mostly used for", "timestamp": "00:16:34,102", "timestamp_s": 994.0}, {"text": "metering bandwidth. Bandwidth was built on something like five megabits at", "timestamp": "00:16:38,192", "timestamp_s": 998.0}, {"text": "95th percentile, meaning that if you took all your five minute bandwidth", "timestamp": "00:16:41,760", "timestamp_s": 1001.0}, {"text": "usage measurement slices and ordered them, and took the 95th percentile,", "timestamp": "00:16:45,898", "timestamp_s": 1005.0}, {"text": "if that number was above five megabits, you incur", "timestamp": "00:16:50,330", "timestamp_s": 1010.0}, {"text": "overage charges. And this first popularized the", "timestamp": "00:16:53,966", "timestamp_s": 1013.0}, {"text": "approach of using percentiles. And that would really", "timestamp": "00:16:57,672", "timestamp_s": 1017.0}, {"text": "notably be seen about ten years later in 2011 with the", "timestamp": "00:17:02,136", "timestamp_s": 1022.0}, {"text": "advent of the statSD protocol developed by Etsy, which provided", "timestamp": "00:17:05,768", "timestamp_s": 1025.0}, {"text": "the p 95 was a latency aggregation metric. And I wrote more", "timestamp": "00:17:09,198", "timestamp_s": 1029.0}, {"text": "about this in a blog post I published last year, and I\u0027ll go into some", "timestamp": "00:17:12,748", "timestamp_s": 1032.0}, {"text": "of the content in the next slides, but this is the historical", "timestamp": "00:17:15,868", "timestamp_s": 1035.0}, {"text": "significance of this graph.", "timestamp": "00:17:20,310", "timestamp_s": 1040.0}, {"text": "So let\u0027s talk about percentiles. This is a slide", "timestamp": "00:17:23,310", "timestamp_s": 1043.0}, {"text": "from an SLO presentation I gave at Srecon 2019.", "timestamp": "00:17:26,950", "timestamp_s": 1046.0}, {"text": "It illustrates two latency distribution profiles, which are meant to", "timestamp": "00:17:30,662", "timestamp_s": 1050.0}, {"text": "represent service nodes that are behaving differently.", "timestamp": "00:17:33,908", "timestamp_s": 1053.0}, {"text": "The blue distribution represents a bimodal latency", "timestamp": "00:17:36,858", "timestamp_s": 1056.0}, {"text": "profile with lower latencies than the single mode red latency distribution.", "timestamp": "00:17:40,602", "timestamp_s": 1060.0}, {"text": "Basically, this could be two web servers, one performing well and", "timestamp": "00:17:44,990", "timestamp_s": 1064.0}, {"text": "one performing not as well. The red server is not performing as", "timestamp": "00:17:48,760", "timestamp_s": 1068.0}, {"text": "well, and if we take the p 95", "timestamp": "00:17:52,392", "timestamp_s": 1072.0}, {"text": "values for latency for each server, and we average those, we could", "timestamp": "00:17:56,232", "timestamp_s": 1076.0}, {"text": "get an indicator of around 430 milliseconds,", "timestamp": "00:17:59,932", "timestamp_s": 1079.0}, {"text": "and we might think that hes that\u0027s the performance of our service.", "timestamp": "00:18:03,538", "timestamp_s": 1083.0}, {"text": "But if we combine the raw latency values from each of these distribution", "timestamp": "00:18:07,450", "timestamp_s": 1087.0}, {"text": "sets and calculate the aggregate p 95 from those,", "timestamp": "00:18:11,586", "timestamp_s": 1091.0}, {"text": "we\u0027ll get 230 milliseconds, and the error there", "timestamp": "00:18:15,104", "timestamp_s": 1095.0}, {"text": "is almost 100%. And many,", "timestamp": "00:18:18,656", "timestamp_s": 1098.0}, {"text": "if not all, of the monitoring and observability tools out there will happily", "timestamp": "00:18:22,420", "timestamp_s": 1102.0}, {"text": "let you use an averaging function for percentiles generated from", "timestamp": "00:18:26,362", "timestamp_s": 1106.0}, {"text": "different hosts, nodes or clusters. If your distribution", "timestamp": "00:18:29,972", "timestamp_s": 1109.0}, {"text": "profiles are the same, no problem. That works great. But it\u0027s when", "timestamp": "00:18:33,482", "timestamp_s": 1113.0}, {"text": "your services are behaving asymmetrically that you\u0027ll encounter large errors with", "timestamp": "00:18:37,048", "timestamp_s": 1117.0}, {"text": "this approach, and this is a problem with percentiles.", "timestamp": "00:18:40,888", "timestamp_s": 1120.0}, {"text": "And I talked about that in depth in that presentation.", "timestamp": "00:18:44,414", "timestamp_s": 1124.0}, {"text": "So beware of using percentiles.", "timestamp": "00:18:47,906", "timestamp_s": 1127.0}, {"text": "I\u0027ve talked about this and ranted about this,", "timestamp": "00:18:51,138", "timestamp_s": 1131.0}, {"text": "and this kind of illustrates the", "timestamp": "00:18:54,410", "timestamp_s": 1134.0}, {"text": "prime condition where that\u0027s can issue. And again, if everything\u0027s running", "timestamp": "00:18:59,212", "timestamp_s": 1139.0}, {"text": "smoothly or if you have a single node, percentiles work just great.", "timestamp": "00:19:02,496", "timestamp_s": 1142.0}, {"text": "But it\u0027s the real world scenarios where we have different", "timestamp": "00:19:05,808", "timestamp_s": 1145.0}, {"text": "node performance profiles and possibly hundreds", "timestamp": "00:19:09,680", "timestamp_s": 1149.0}, {"text": "or thousands of nodes services requests that we want to be", "timestamp": "00:19:13,498", "timestamp_s": 1153.0}, {"text": "able to handle and evaluate how our service", "timestamp": "00:19:16,948", "timestamp_s": 1156.0}, {"text": "is performing accurately that teams into histograms", "timestamp": "00:19:20,676", "timestamp_s": 1160.0}, {"text": "for measuring web service latency.", "timestamp": "00:19:24,398", "timestamp_s": 1164.0}, {"text": "And I give an internal", "timestamp": "00:19:28,230", "timestamp_s": 1168.0}, {"text": "talk. I called Dr. Histogram how I learned to stop worrying and", "timestamp": "00:19:32,142", "timestamp_s": 1172.0}, {"text": "love latency bands at Zendesk a few years ago,", "timestamp": "00:19:35,704", "timestamp_s": 1175.0}, {"text": "and I went into more depth on the intricacies of", "timestamp": "00:19:39,370", "timestamp_s": 1179.0}, {"text": "these three different types of histograms in the SLO comp link below.", "timestamp": "00:19:43,308", "timestamp_s": 1183.0}, {"text": "But in short,", "timestamp": "00:19:46,924", "timestamp_s": 1186.0}, {"text": "there\u0027s a couple of different approaches you can use for measuring latency with histogram.", "timestamp": "00:19:51,070", "timestamp_s": 1191.0}, {"text": "And this involves essentially collecting a latency sample and fitting", "timestamp": "00:19:55,718", "timestamp_s": 1195.0}, {"text": "it into what we call a bucket or a bin.", "timestamp": "00:19:59,318", "timestamp_s": 1199.0}, {"text": "And you\u0027ll see the gray and blue", "timestamp": "00:20:02,342", "timestamp_s": 1202.0}, {"text": "bars here. Those are your buckets or bins. And so let\u0027s", "timestamp": "00:20:06,122", "timestamp_s": 1206.0}, {"text": "take a look at how these are implemented differently. First, we could have", "timestamp": "00:20:09,258", "timestamp_s": 1209.0}, {"text": "a log linear histogram, which you", "timestamp": "00:20:13,044", "timestamp_s": 1213.0}, {"text": "can see the details of at openhistogram IO.", "timestamp": "00:20:16,328", "timestamp_s": 1216.0}, {"text": "And if we have a latency value here of 125 milliseconds,", "timestamp": "00:20:19,566", "timestamp_s": 1219.0}, {"text": "we could say like, oh, we\u0027ll just slot that sample into", "timestamp": "00:20:23,918", "timestamp_s": 1223.0}, {"text": "the greater than 100 millisecond, but less than 200 millisecond", "timestamp": "00:20:28,172", "timestamp_s": 1228.0}, {"text": "bucket. And so this is a data structure", "timestamp": "00:20:31,698", "timestamp_s": 1231.0}, {"text": "that is fairly easy to represent, because all you have is an", "timestamp": "00:20:34,978", "timestamp_s": 1234.0}, {"text": "array representing different histogram buckets,", "timestamp": "00:20:38,668", "timestamp_s": 1238.0}, {"text": "and then you increase the value of that array, essentially a counter", "timestamp": "00:20:42,182", "timestamp_s": 1242.0}, {"text": "for each of those. And this is a volume invariant way", "timestamp": "00:20:45,702", "timestamp_s": 1245.0}, {"text": "of storing large amounts of latency data that you", "timestamp": "00:20:49,232", "timestamp_s": 1249.0}, {"text": "can also use to generate highly accurate aggregates", "timestamp": "00:20:52,628", "timestamp_s": 1252.0}, {"text": "for an entire cluster or any set of hosts.", "timestamp": "00:20:56,650", "timestamp_s": 1256.0}, {"text": "And folks might also be familiar with the middle structure. That\u0027s the cumulative", "timestamp": "00:21:01,650", "timestamp_s": 1261.0}, {"text": "histogram which prometheus uses.", "timestamp": "00:21:05,822", "timestamp_s": 1265.0}, {"text": "So if I have a latency value of 125 milliseconds,", "timestamp": "00:21:09,390", "timestamp_s": 1269.0}, {"text": "it will assign labels starting at less than", "timestamp": "00:21:12,638", "timestamp_s": 1272.0}, {"text": "infinity all the way down to less than 200.", "timestamp": "00:21:16,200", "timestamp_s": 1276.0}, {"text": "So this takes a few more data structures", "timestamp": "00:21:19,532", "timestamp_s": 1279.0}, {"text": "or a few more counter values to implement, and it\u0027s not quite as", "timestamp": "00:21:22,898", "timestamp_s": 1282.0}, {"text": "efficient as the logged linear histogram. And at Zendesk, I flipped that", "timestamp": "00:21:26,252", "timestamp_s": 1286.0}, {"text": "on its head and came up what was called an inverse cumulative histogram,", "timestamp": "00:21:29,948", "timestamp_s": 1289.0}, {"text": "where, for an example, if we have 125 milliseconds, I could", "timestamp": "00:21:34,406", "timestamp_s": 1294.0}, {"text": "have a counter data structure, bump the counter and assign", "timestamp": "00:21:37,728", "timestamp_s": 1297.0}, {"text": "these labels to it, which are often known as metric tags.", "timestamp": "00:21:41,654", "timestamp_s": 1301.0}, {"text": "I could assign greater than ten, greater than 50, greater than 100 milliseconds,", "timestamp": "00:21:45,322", "timestamp_s": 1305.0}, {"text": "but not greater than 200 milliseconds. And this approach", "timestamp": "00:21:48,938", "timestamp_s": 1308.0}, {"text": "made my head hurt for a little bit. But it has some advantages", "timestamp": "00:21:53,050", "timestamp_s": 1313.0}, {"text": "in terms of operator efficiency and ease of use of implementing with a", "timestamp": "00:21:56,718", "timestamp_s": 1316.0}, {"text": "lot of the tooling out there and all", "timestamp": "00:22:00,584", "timestamp_s": 1320.0}, {"text": "these buckets that can also be referred to as latency bands.", "timestamp": "00:22:04,888", "timestamp_s": 1324.0}, {"text": "So you can kind of take a look at each of these different types of", "timestamp": "00:22:08,830", "timestamp_s": 1328.0}, {"text": "histograms and decide, I might want to try to use histograms for", "timestamp": "00:22:11,948", "timestamp_s": 1331.0}, {"text": "storing latency. So one of these should give you", "timestamp": "00:22:15,932", "timestamp_s": 1335.0}, {"text": "some good results. And you might ask,", "timestamp": "00:22:19,388", "timestamp_s": 1339.0}, {"text": "well, okay, well, now I know how to capture latency in a histogram at", "timestamp": "00:22:22,972", "timestamp_s": 1342.0}, {"text": "scale. How do I generate an SLO from it? Well, let\u0027s go back to our", "timestamp": "00:22:26,592", "timestamp_s": 1346.0}, {"text": "definition. It\u0027s the number of good requests divided by the number of bad", "timestamp": "00:22:30,112", "timestamp_s": 1350.0}, {"text": "requests over a time range. And so in this case,", "timestamp": "00:22:33,652", "timestamp_s": 1353.0}, {"text": "we can use a histogram data for the SLI.", "timestamp": "00:22:37,908", "timestamp_s": 1357.0}, {"text": "We can sum up the number of requests below 100 milliseconds,", "timestamp": "00:22:41,626", "timestamp_s": 1361.0}, {"text": "and we can divide that by the total number of requests, which would just be", "timestamp": "00:22:45,418", "timestamp_s": 1365.0}, {"text": "the count sum of all the bands, and we can multiply that", "timestamp": "00:22:49,064", "timestamp_s": 1369.0}, {"text": "by 100. In the case of the", "timestamp": "00:22:52,488", "timestamp_s": 1372.0}, {"text": "number of requests under 100 milliseconds,", "timestamp": "00:22:55,756", "timestamp_s": 1375.0}, {"text": "with the inverse cumulative histogram,", "timestamp": "00:22:59,058", "timestamp_s": 1379.0}, {"text": "we add up the counts of the blue bars.", "timestamp": "00:23:03,450", "timestamp_s": 1383.0}, {"text": "With the log linear histogram,", "timestamp": "00:23:07,290", "timestamp_s": 1387.0}, {"text": "we just add up all those, the counts of the three bars to", "timestamp": "00:23:10,562", "timestamp_s": 1390.0}, {"text": "the left of the three gray bars to the left of the blue bar.", "timestamp": "00:23:14,048", "timestamp_s": 1394.0}, {"text": "So, mathematically, this is very simple to implement,", "timestamp": "00:23:17,088", "timestamp_s": 1397.0}, {"text": "and it\u0027s fast, it works quickly with all monitoring solutions", "timestamp": "00:23:20,022", "timestamp_s": 1400.0}, {"text": "out there. And it\u0027s also extremely accurate because you\u0027re adding", "timestamp": "00:23:23,658", "timestamp_s": 1403.0}, {"text": "up counts of essentially raw data,", "timestamp": "00:23:27,018", "timestamp_s": 1407.0}, {"text": "and it also gives you essentially arbitrary precision.", "timestamp": "00:23:30,610", "timestamp_s": 1410.0}, {"text": "So this is a very robust and accurate approach,", "timestamp": "00:23:34,510", "timestamp_s": 1414.0}, {"text": "and I highly recommend this because this will give you some great numbers", "timestamp": "00:23:38,590", "timestamp_s": 1418.0}, {"text": "at scale. Now, you might", "timestamp": "00:23:42,376", "timestamp_s": 1422.0}, {"text": "say, like, well, this is a lot of work to do, but again, it goes", "timestamp": "00:23:46,152", "timestamp_s": 1426.0}, {"text": "back to prioritizing reliability work. So we want to make sure that our", "timestamp": "00:23:49,052", "timestamp_s": 1429.0}, {"text": "data about, if we\u0027re hitting our slos is accurate,", "timestamp": "00:23:52,668", "timestamp_s": 1432.0}, {"text": "because we\u0027re spending, likely spending hundreds of thousands or millions of dollars", "timestamp": "00:23:56,098", "timestamp_s": 1436.0}, {"text": "on shifting this engineering work. Now,", "timestamp": "00:23:59,616", "timestamp_s": 1439.0}, {"text": "I showed some raw histograms there,", "timestamp": "00:24:05,630", "timestamp_s": 1445.0}, {"text": "where we keep count of a number of samples in each bin,", "timestamp": "00:24:09,550", "timestamp_s": 1449.0}, {"text": "and that way we can sum them up. But there\u0027s some approximate", "timestamp": "00:24:12,774", "timestamp_s": 1452.0}, {"text": "structures out there which you can use,", "timestamp": "00:24:16,602", "timestamp_s": 1456.0}, {"text": "and some of the vendors provide to do the same things. And they\u0027re", "timestamp": "00:24:19,508", "timestamp_s": 1459.0}, {"text": "often called sketches, like the GK sketch or the DD", "timestamp": "00:24:23,770", "timestamp_s": 1463.0}, {"text": "sketch structure by one of the vendors. And there\u0027s also approximate", "timestamp": "00:24:27,262", "timestamp_s": 1467.0}, {"text": "histograms such as t Digest, made by Ted Dunning, which stores", "timestamp": "00:24:31,278", "timestamp_s": 1471.0}, {"text": "approximations of distributions. And these", "timestamp": "00:24:35,374", "timestamp_s": 1475.0}, {"text": "two charts here were taken from the log linear circ", "timestamp": "00:24:38,972", "timestamp_s": 1478.0}, {"text": "Slis paper for open histogram, and they represent error", "timestamp": "00:24:43,298", "timestamp_s": 1483.0}, {"text": "percentages for two different takes of workloads across different", "timestamp": "00:24:47,442", "timestamp_s": 1487.0}, {"text": "p nine x values on the x axis. And you", "timestamp": "00:24:51,328", "timestamp_s": 1491.0}, {"text": "can see the red line here, which is the open histogram implementation", "timestamp": "00:24:54,688", "timestamp_s": 1494.0}, {"text": "that\u0027s got very low errors. But then you look at like the T Digest", "timestamp": "00:24:58,326", "timestamp_s": 1498.0}, {"text": "DD sketch and HDR histogram, which do relatively well", "timestamp": "00:25:02,278", "timestamp_s": 1502.0}, {"text": "in terms of errors. However, there\u0027s a detail that is not in these", "timestamp": "00:25:06,052", "timestamp_s": 1506.0}, {"text": "charts. These errors are for single node evaluations only,", "timestamp": "00:25:09,812", "timestamp_s": 1509.0}, {"text": "say for one web server. Now, how do approximate histograms", "timestamp": "00:25:13,240", "timestamp_s": 1513.0}, {"text": "and sketches behave across asymmetric node workloads of", "timestamp": "00:25:16,734", "timestamp_s": 1516.0}, {"text": "hundreds of web servers or arbitrary time windows? And that\u0027s", "timestamp": "00:25:21,384", "timestamp_s": 1521.0}, {"text": "a very difficult question to answer. But by and large, the errors are likely", "timestamp": "00:25:25,038", "timestamp_s": 1525.0}, {"text": "to be unbounded and using histograms which", "timestamp": "00:25:28,338", "timestamp_s": 1528.0}, {"text": "store the exact sample counts, as I termed raw histograms", "timestamp": "00:25:31,628", "timestamp_s": 1531.0}, {"text": "on the previous slide, those avoid that problem entirely,", "timestamp": "00:25:35,266", "timestamp_s": 1535.0}, {"text": "ensuring that any aggregates generated for them", "timestamp": "00:25:39,446", "timestamp_s": 1539.0}, {"text": "for slos are highly accurate and precise.", "timestamp": "00:25:43,104", "timestamp_s": 1543.0}, {"text": "So the sketches are good", "timestamp": "00:25:46,262", "timestamp_s": 1546.0}, {"text": "to a certain extent, but they don\u0027t really hit", "timestamp": "00:25:49,392", "timestamp_s": 1549.0}, {"text": "the same level of precision as these raw", "timestamp": "00:25:52,468", "timestamp_s": 1552.0}, {"text": "histograms. Now, while we\u0027re on", "timestamp": "00:25:55,898", "timestamp_s": 1555.0}, {"text": "the subject of histograms, I want to highlight some recent work in this area by", "timestamp": "00:25:59,284", "timestamp_s": 1559.0}, {"text": "Adrian Cockroft. Adrian published a medium post titled percentiles", "timestamp": "00:26:02,628", "timestamp_s": 1562.0}, {"text": "don\u0027t work. I think he coined them as wrong,", "timestamp": "00:26:07,054", "timestamp_s": 1567.0}, {"text": "but useful analyzing the distribution of response times for web", "timestamp": "00:26:10,840", "timestamp_s": 1570.0}, {"text": "services. A few months ago,", "timestamp": "00:26:14,872", "timestamp_s": 1574.0}, {"text": "hes started doing some work here, where he", "timestamp": "00:26:18,810", "timestamp_s": 1578.0}, {"text": "looked at operational telemetry, which is usually latency, and using some", "timestamp": "00:26:22,012", "timestamp_s": 1582.0}, {"text": "r based tooling to decompose it into component normalish", "timestamp": "00:26:25,772", "timestamp_s": 1585.0}, {"text": "distributions. So this image here was taken from his blog post, where he was", "timestamp": "00:26:29,842", "timestamp_s": 1589.0}, {"text": "able to take a bimodal histogram here and decompose it into", "timestamp": "00:26:33,888", "timestamp_s": 1593.0}, {"text": "two normal distributions using the mixed tools r package.", "timestamp": "00:26:37,632", "timestamp_s": 1597.0}, {"text": "Now why is this important and what does this have to do", "timestamp": "00:26:41,790", "timestamp_s": 1601.0}, {"text": "with slos? We just took a look at what magnitude of errors", "timestamp": "00:26:45,268", "timestamp_s": 1605.0}, {"text": "can arise from using percentiles for latency measurements. So we", "timestamp": "00:26:48,794", "timestamp_s": 1608.0}, {"text": "follow that up with looking at histograms to measure latency distributions.", "timestamp": "00:26:52,548", "timestamp_s": 1612.0}, {"text": "So with something like this,", "timestamp": "00:26:57,510", "timestamp_s": 1617.0}, {"text": "we can pull out these normal distributions.", "timestamp": "00:27:02,470", "timestamp_s": 1622.0}, {"text": "And this could be relevant if we wanted to make an SLO for something like", "timestamp": "00:27:05,614", "timestamp_s": 1625.0}, {"text": "disk writes, where you might have writing to a block device,", "timestamp": "00:27:09,292", "timestamp_s": 1629.0}, {"text": "versus just writing to cache or reading", "timestamp": "00:27:13,234", "timestamp_s": 1633.0}, {"text": "from the block device, as opposed to reading to cache. We can use these", "timestamp": "00:27:16,834", "timestamp_s": 1636.0}, {"text": "to implement fine grained slos for each of the different", "timestamp": "00:27:20,752", "timestamp_s": 1640.0}, {"text": "moyer of kind of the physical manifestations", "timestamp": "00:27:24,350", "timestamp_s": 1644.0}, {"text": "of the system in the cloud. It could be like writing to s three or", "timestamp": "00:27:28,870", "timestamp_s": 1648.0}, {"text": "different storage levels there. And so there\u0027s some really promising", "timestamp": "00:27:33,090", "timestamp_s": 1653.0}, {"text": "work here. And I think that this", "timestamp": "00:27:36,938", "timestamp_s": 1656.0}, {"text": "is definitely something to follow going ahead, because if you", "timestamp": "00:27:40,932", "timestamp_s": 1660.0}, {"text": "really want to get fine grained with, say, a system that", "timestamp": "00:27:44,888", "timestamp_s": 1664.0}, {"text": "has a few different modes at very large scale, this approach", "timestamp": "00:27:48,328", "timestamp_s": 1668.0}, {"text": "would allow you to do that.", "timestamp": "00:27:52,510", "timestamp_s": 1672.0}, {"text": "Now, one common question I\u0027ve gotten about slos and", "timestamp": "00:27:55,270", "timestamp_s": 1675.0}, {"text": "error budgets is how do you implement them across a distributed service architectures?", "timestamp": "00:27:58,684", "timestamp_s": 1678.0}, {"text": "Now, one approach is to use an SLO and error budget for each service,", "timestamp": "00:28:03,506", "timestamp_s": 1683.0}, {"text": "and this includes third party vendor services, as shown", "timestamp": "00:28:07,116", "timestamp_s": 1687.0}, {"text": "in blue here. Now, the error rates I\u0027ve shown", "timestamp": "00:28:10,454", "timestamp_s": 1690.0}, {"text": "here and documented in red are error", "timestamp": "00:28:13,782", "timestamp_s": 1693.0}, {"text": "rates across these different services. So you can have a", "timestamp": "00:28:17,878", "timestamp_s": 1697.0}, {"text": "different error rate contribution from the third party service, the mid tier and the edge", "timestamp": "00:28:21,408", "timestamp_s": 1701.0}, {"text": "tier. And you can take those and you", "timestamp": "00:28:25,338", "timestamp_s": 1705.0}, {"text": "can add those up and essentially get a compound or", "timestamp": "00:28:28,628", "timestamp_s": 1708.0}, {"text": "composite error rate for what the customer is seeing. So in this", "timestamp": "00:28:31,908", "timestamp_s": 1711.0}, {"text": "case, you might see that, hey, our in house back", "timestamp": "00:28:35,332", "timestamp_s": 1715.0}, {"text": "end service has a 0.1% error rate.", "timestamp": "00:28:38,888", "timestamp_s": 1718.0}, {"text": "But then if you roll that up to the mid tier,", "timestamp": "00:28:42,150", "timestamp_s": 1722.0}, {"text": "now you\u0027ve got 1% error", "timestamp": "00:28:45,518", "timestamp_s": 1725.0}, {"text": "rate also from the third party, which exceeds your mid tier", "timestamp": "00:28:49,378", "timestamp_s": 1729.0}, {"text": "error budget of 1%. And so", "timestamp": "00:28:52,626", "timestamp_s": 1732.0}, {"text": "you can kind of put these diagrams together, and it", "timestamp": "00:28:57,050", "timestamp_s": 1737.0}, {"text": "will help you understand where you need to focus reliability", "timestamp": "00:29:00,444", "timestamp_s": 1740.0}, {"text": "work. In this case, you need to focus reliability work on the", "timestamp": "00:29:03,910", "timestamp_s": 1743.0}, {"text": "third party and either pull that in house or do", "timestamp": "00:29:07,504", "timestamp_s": 1747.0}, {"text": "some sort of interface around", "timestamp": "00:29:10,752", "timestamp_s": 1750.0}, {"text": "it to make it more reliable. And the goal here is not to assign blames", "timestamp": "00:29:14,132", "timestamp_s": 1754.0}, {"text": "to teams or to different services. It\u0027s to", "timestamp": "00:29:17,226", "timestamp_s": 1757.0}, {"text": "prioritize reliability work. And that\u0027s", "timestamp": "00:29:20,452", "timestamp_s": 1760.0}, {"text": "really what this is all about. Because for", "timestamp": "00:29:24,458", "timestamp_s": 1764.0}, {"text": "most of almost, I would say almost all of you out there, you\u0027re using some", "timestamp": "00:29:28,824", "timestamp_s": 1768.0}, {"text": "sort of distributed system like this, and you\u0027re going to say like,", "timestamp": "00:29:32,008", "timestamp_s": 1772.0}, {"text": "well, how do we use slos across that?", "timestamp": "00:29:35,532", "timestamp_s": 1775.0}, {"text": "Remember to be customer centric, and you can roll", "timestamp": "00:29:38,876", "timestamp_s": 1778.0}, {"text": "those error budgets up, starting from,", "timestamp": "00:29:42,258", "timestamp_s": 1782.0}, {"text": "I\u0027ll call it upstream, which is further away from the client. You can roll", "timestamp": "00:29:46,090", "timestamp_s": 1786.0}, {"text": "those error rates up and get a composite error", "timestamp": "00:29:49,414", "timestamp_s": 1789.0}, {"text": "rate fairly simply and see", "timestamp": "00:29:52,918", "timestamp_s": 1792.0}, {"text": "what the client is seeing. And that\u0027s it.", "timestamp": "00:29:56,288", "timestamp_s": 1796.0}, {"text": "My tour through techniques for slos", "timestamp": "00:30:00,128", "timestamp_s": 1800.0}, {"text": "and air budgets at scale I hope you enjoyed this presentation. Feel free", "timestamp": "00:30:04,186", "timestamp_s": 1804.0}, {"text": "to reach out to me on LinkedIn or Twitter.", "timestamp": "00:30:08,372", "timestamp_s": 1808.0}, {"text": "And that Twitter handle also works across Mastodon and", "timestamp": "00:30:12,026", "timestamp_s": 1812.0}, {"text": "a couple of the other news sites popping up. I\u0027d love to hear about your", "timestamp": "00:30:15,444", "timestamp_s": 1815.0}, {"text": "experiences and talk about how you\u0027re using", "timestamp": "00:30:18,692", "timestamp_s": 1818.0}, {"text": "slos and air budgets at scale. Thanks 42.", "timestamp": "00:30:22,420", "timestamp_s": 1822.0}, {"text": "We\u0027ll see you next time.", "timestamp": "00:30:25,676", "timestamp_s": 1825.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'c8Tjbmq66UU',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Techniques for SLOs and Error Budgets at Scale
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>What tactics can you use to implement service level objectives and
error budgets to operate enterprise-level services with a thousand (or
more) engineers? Fred Moyer takes you through approaches heâ€™s
developed working with teams in a large production ecosystem where
service reliability was a nonnegotiable business requirement.
Engineers and operations folks who are putting SLIs, SLOs, and error
budgets into practice in high-scale production environments with
diverse service architectures should come away with an understanding
of how to democratize SLOs, what objectives they should target for
enterprise-level reliability, and how to communicate and implement
error budgets across multiple teams.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                I'm proud to be presenting here at Conf 42 observability in 2023. This talk is about techniques for slos and air budgets at scale. This is basically the greatest its version of the previous talks I've given on the subject.

              </li>
              
              <li>
                Fred: I'm a observability engineer at a large public company. This talk is my own opinions, not those my employers. Raise your hand if you know what this graph is. We're all here today in part because of this thing.

              </li>
              
              <li>
                How do you implement slos for 1000 plus engineers? There wasn't really a prescription for slis and slos. So I got to work creating formulas that can be shared across a large organization. Here is what I came up with.

              </li>
              
              <li>
                You need real world examples. Present formulas for each of those entities which can be read easily both by humans and machines. Third, you have to be detailed and consistent. This is what enterprise customers demand these days.

              </li>
              
              <li>
                Of the two components of latency and availability, availability is generally pretty easy to measure. Web page latency is more difficult to get right at scale. There are two aspects of being right. First, does your measurement have the right precision for your scale?

              </li>
              
              <li>
                There's a couple of different approaches you can use for measuring latency with histogram. Many tools will happily let you use an averaging function for percentiles generated from different hosts, nodes or clusters. But when your services are behaving asymmetrically, you'll encounter errors with this approach.

              </li>
              
              <li>
                A recent blog post highlights some recent work in this area. Using r based tooling to decompose telemetry into component normalish distributions. These can be used to implement fine grained slos for each of the different moyer of the system in the cloud.

              </li>
              
              <li>
                One approach is to use an SLO and error budget for each service. This includes third party vendor services, as shown in blue here. You can roll those error rates up and get a composite error rate. The goal here is not to assign blames to teams or to different services. It's to prioritize reliability work.

              </li>
              
              <li>
                My tour through techniques for slos and air budgets at scale. Feel free to reach out to me on LinkedIn or Twitter. I'd love to hear about your experiences.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/assemblyai/c8Tjbmq66UU.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:23,050'); seek(23.0)">
              Hey folks, welcome to my talk about techniques for slos
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:27,042'); seek(27.0)">
              and air budgets at scale. I'm proud to be presenting here at
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:30,540'); seek(30.0)">
              Conf 42 observability in 2023. I've been talking a lot
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:34,028'); seek(34.0)">
              about slos and air budgets over the past six or so years, and over that
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:37,996'); seek(37.0)">
              time I've given variations of this talk in different
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:41,516'); seek(41.0)">
              online conferences and also a couple in person. So I'm
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:45,394'); seek(45.0)">
              pleased to be presenting some of my learnings over the past couple of years.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:48,604'); seek(48.0)">
              This is basically the greatest its version of the previous talks I've
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:52,042'); seek(52.0)">
              given on the subject. Let's get started. But first, I know
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:55,588'); seek(55.0)">
              this is an online conference, but let's do a little survey.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:59,130'); seek(59.0)">
              Raise your hand. I know you're sitting there just at home by yourself,
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:02,196'); seek(62.0)">
              but raise your hand if you know what this graph is. And this is one
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:05,524'); seek(65.0)">
              of those graphs that if you know, you know. We're all here today
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:09,000'); seek(69.0)">
              in part because of this thing. And if you don't know what this is,
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:12,504'); seek(72.0)">
              that's okay. We'll go ahead and come back to that a little bit later.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:15,944'); seek(75.0)">
              So, hi, I'm Fred. I'm a observability
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:19,250'); seek(79.0)">
              engineer at a large public company, and this talk is
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:23,676'); seek(83.0)">
              my own opinions, not those my employers. Basic disclaimer
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:27,554'); seek(87.0)">
              and so I've been working on
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:31,740'); seek(91.0)">
              monitoring observability for about as long as the graph on the previous slide,
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:35,478'); seek(95.0)">
              but focusing on it heavily over the past ten or so years.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:38,704'); seek(98.0)">
              I like to think about slos, Slis and air budgets,
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:42,154'); seek(102.0)">
              hence the SLOS Jason term, I think that was coined in the original
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:45,482'); seek(105.0)">
              Google SlO paper. I like to hack on
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:48,930'); seek(108.0)">
              histograms, metrics, logs and traces. Been programming
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:52,442'); seek(112.0)">
              a lot of stuff for the past 20 years, and I've got two young kids,
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:56,584'); seek(116.0)">
              so I definitely am in need of more sleep and coffee. But let's go
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:59,768'); seek(119.0)">
              ahead and kick this off. So how
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:03,320'); seek(123.0)">
              do you implement slos for 1000 plus engineers?
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:06,782'); seek(126.0)">
              And this was a challenge I encountered about four years
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:10,812'); seek(130.0)">
              ago when I started a role at a company called Zendesk.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:14,178'); seek(134.0)">
              And I got tasked with a project to bring slos to an engineering
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:17,602'); seek(137.0)">
              organization that had over a thousand engineers, which was
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:21,548'); seek(141.0)">
              quite a few. And there was a big push to make the product
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:24,736'); seek(144.0)">
              as reliable as possible. We called reliability our number one feature.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:28,742'); seek(148.0)">
              So I had to come up with a way to roll out slos and air
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:31,572'); seek(151.0)">
              budgets across all those engineers. And to
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:35,716'); seek(155.0)">
              do that effectively, I really had to understand what
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:39,572'); seek(159.0)">
              slis and slos, and hence air budgets were programmatically.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:43,898'); seek(163.0)">
              So I really dove in and started to research the subject a lot to kind
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:47,288'); seek(167.0)">
              of go back to the basics.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:50,470'); seek(170.0)">
              And speaking of basics, I started off by reading the original Google SRE
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:54,126'); seek(174.0)">
              book, followed that up with the SRE workbook,
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:57,858'); seek(177.0)">
              watched Liz Fong Jones and Seth Fargo's
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:01,346'); seek(181.0)">
              Google Cloud presentation on slos titled slis,
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:04,802'); seek(184.0)">
              slos, slos. Oh my. Which was an inspiration to me.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:08,316'); seek(188.0)">
              And I've given a number of SLO talks previously, most notably
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:11,846'); seek(191.0)">
              one called Latency SLos done right, which was also given at
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:15,728'); seek(195.0)">
              Srecon by Theo Schlossnagel and Heinrich Hartman,
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:19,142'); seek(199.0)">
              who've written a lot on the subject. And even
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:22,976'); seek(202.0)">
              looking back at that talk I gave, I can spot the errors in it,
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:26,756'); seek(206.0)">
              which were kind of subtle. But what I found researching this topic
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:30,122'); seek(210.0)">
              here is there wasn't really a prescription for slis and slos.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:34,010'); seek(214.0)">
              The Google books talked a lot about slis, but were vague on the
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:37,288'); seek(217.0)">
              subject as far as specific examples were concerned. And even working through some
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:41,064'); seek(221.0)">
              of the examples in the workbook, I either found subtle
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:45,118'); seek(225.0)">
              omissions or places where the examples weren't completely
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:49,370'); seek(229.0)">
              flushed out and tested. Liz and Seth's Google Cloud video
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:53,196'); seek(233.0)">
              had some concise definitions, so I took those as a base and expanded
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:56,658'); seek(236.0)">
              on them, and those are in use by some of the major SLO vendors out
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:00,048'); seek(240.0)">
              there now. And over the next few years,
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:03,184'); seek(243.0)">
              there was kind of what I call a cambrian SLO explosion.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:07,030'); seek(247.0)">
              Get it? Slo explosion. Little dad joke there.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:10,656'); seek(250.0)">
              But there was this explosion in SLO material with SLO
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:14,362'); seek(254.0)">
              specific conferences and also Alex Sedalgo's book on implementing slos.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:18,682'); seek(258.0)">
              So I got to work creating formulas that can be shared across a large organization,
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:23,274'); seek(263.0)">
              which would leave little room for creativity and variance because I wanted everyone
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:27,016'); seek(267.0)">
              on the same page, I wanted to be able to give prescriptive formulas
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:30,862'); seek(270.0)">
              that could be implemented at broad scale.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:35,430'); seek(275.0)">
              So this is what I came up with. The definition
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:39,138'); seek(279.0)">
              of an SLI is what I use to put examples together.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:43,020'); seek(283.0)">
              Now, there's two major SLI opinionations, though the difference between them
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:47,052'); seek(287.0)">
              is a bit subtle at first glance. The first is from the Google
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:50,400'); seek(290.0)">
              SRE book, which describes an SLI,
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:54,006'); seek(294.0)">
              pardon me, as a measurement of system performance. The second,
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:58,128'); seek(298.0)">
              which I found first in Liz and Seth's video,
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:01,920'); seek(301.0)">
              describes an SLI as something that delineates good requests from bad requests.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:06,058'); seek(306.0)">
              And that second opinion is really one that resonated well with me.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:10,052'); seek(310.0)">
              So in know, both opinionations did
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:13,592'); seek(313.0)">
              service at Google, even though they're
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:17,070'); seek(317.0)">
              somewhat conflicting. But the second, as I mentioned, is implemented
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:20,990'); seek(320.0)">
              more broadly by practitioners and vendors that I found.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:24,360'); seek(324.0)">
              And I decided to base my example on that second opinionation,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:28,654'); seek(328.0)">
              not only because it had wider acceptance because intuitively it made more sense
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:32,492'); seek(332.0)">
              to me. I spent quite a bit of time dissecting
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:35,602'); seek(335.0)">
              those examples in the Google SRE book and the SRE workbook,
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:39,350'); seek(339.0)">
              and they were good.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:42,480'); seek(342.0)">
              But I think the evolution of slis
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:46,614'); seek(346.0)">
              and slos at Google probably bifurcated because they
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:50,368'); seek(350.0)">
              have a lot of teams there. And that's not a criticism of the book or
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:53,828'); seek(353.0)">
              the organization. But the definitions that I came across seemed to
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:57,428'); seek(357.0)">
              be more abstract than what I was looking for. And so here are
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:01,028'); seek(361.0)">
              three examples of slis for the second SLI opinionation
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:05,402'); seek(365.0)">
              that I moved forward with. They each consist of three things.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:08,552'); seek(368.0)">
              A metric identifier, a metric operator, and a metric value.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:12,744'); seek(372.0)">
              This approach is one that is straightforward for a human being to understand,
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:16,072'); seek(376.0)">
              but also fits easily into most of the open source
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:19,778'); seek(379.0)">
              and commercial monitoring and observability software out there.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:22,876'); seek(382.0)">
              The part of the SLI definition which requires the most consideration is what
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:26,428'); seek(386.0)">
              that metric value should be. And that's one that is often tuned
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:30,710'); seek(390.0)">
              or calibrated by an engineering team, either for latency,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:34,326'); seek(394.0)">
              most often, sometimes with error
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:38,374'); seek(398.0)">
              response codes, like a five, xx. That's pretty clear that that's a bad
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:41,552'); seek(401.0)">
              request, but it's going to be up to engineering teams to determine,
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:45,322'); seek(405.0)">
              like, is a 404 a bad request, or is
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:49,108'); seek(409.0)">
              that just clients thinking that they're going to the right place?
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:52,856'); seek(412.0)">
              Because really, all of this stuff is about feeling customer
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:56,744'); seek(416.0)">
              pain and wanting to make sure that they have a great experience.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:01,510'); seek(421.0)">
              And so I kind of cemented this
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:05,160'); seek(425.0)">
              example so that I could socialize widely
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:08,466'); seek(428.0)">
              within the engineering of what an SLI was,
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:11,770'); seek(431.0)">
              which teams to what's an slO?
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:14,498'); seek(434.0)">
              And that definition came
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:18,092'); seek(438.0)">
              down to the number of good requests divided by the number of bad requests
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:21,542'); seek(441.0)">
              over a time range. And this is often called a
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:25,088'); seek(445.0)">
              request based slos, where you count up the number of requests and see if
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:29,168'); seek(449.0)">
              you got 99% of them right over a certain time range.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:32,430'); seek(452.0)">
              And I called the
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:36,292'); seek(456.0)">
              three different components here a little bit different. In the red, we have the
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:39,572'); seek(459.0)">
              success objective, which is your typical how many nines?
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:42,794'); seek(462.0)">
              And then we drop the SLI in, which works really well for a lot of
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:46,104'); seek(466.0)">
              the tooling out there. Then we have a period. And if you don't have a
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:49,768'); seek(469.0)">
              time period here, you don't really have an slO,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:52,686'); seek(472.0)">
              because it's really important to specify this so that
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:56,008'); seek(476.0)">
              you're evaluating it over something that's meaningful to the customer.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:00,570'); seek(480.0)">
              And one question that has come up is, how do I
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:03,884'); seek(483.0)">
              know how many nines to choose for this success objective? When I was at Zenesk,
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:07,794'); seek(487.0)">
              we had an engineering vp named Jason Smale, who was very
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:11,392'); seek(491.0)">
              technical and engineers had him highly regarded.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:14,838'); seek(494.0)">
              And so he said, we need to hit three and a half
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:17,952'); seek(497.0)">
              nines. And so that 99.95%
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:22,224'); seek(502.0)">
              number became known as Smale's number. And if reliability dipped
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:25,818'); seek(505.0)">
              below that number, it usually meant that a customer somewhere was feeling pain.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:29,076'); seek(509.0)">
              And this is really, if you want to get into enterprise software,
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:32,522'); seek(512.0)">
              this is kind of, you must meet this criteria to
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:36,040'); seek(516.0)">
              get on the ride. And so now
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:40,472'); seek(520.0)">
              that you realize you're dealing with enterprise customers and you need three and a half
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:43,448'); seek(523.0)">
              nines, how do you pick an appropriate metric value for your SLI,
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:46,734'); seek(526.0)">
              since that's the only dependent variable? Now that you fix the objective at 99.95,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:52,172'); seek(532.0)">
              and this is essentially what I call calibrating your slO. Take a
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:55,788'); seek(535.0)">
              time period of known good performance, set your objective at 99.95,
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:59,804'); seek(539.0)">
              and iterate across your SLI to figure out what
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:03,008'); seek(543.0)">
              latency value gives you that 99.95%.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:06,960'); seek(546.0)">
              In this example, it could be 100 milliseconds. And I was able to develop
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:10,896'); seek(550.0)">
              some simple tooling to do that, or use
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:14,404'); seek(554.0)">
              our commercial monitoring tooling to do that, and developed a dashboard
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:18,138'); seek(558.0)">
              where engineers could set their objective at 99 and
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:21,588'); seek(561.0)">
              a half and then iterate over their latency to see kind of
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:25,750'); seek(565.0)">
              what latency value was it that the customers were getting these three
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:28,984'); seek(568.0)">
              and a half nines performance. And just
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:32,408'); seek(572.0)">
              to reiterate, the time period here is very important,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:35,352'); seek(575.0)">
              and this is a common oversight that I've seen in most of the literature.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:38,478'); seek(578.0)">
              They'll say, take an slo of 100 milliseconds at 99.9%,
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:43,388'); seek(583.0)">
              but what time period is that over? Is it over a minute,
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:46,194'); seek(586.0)">
              an hour, a week? And you
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:49,948'); seek(589.0)">
              can, and you probably should have slos which use the same success objective in
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:53,808'); seek(593.0)">
              SLI but different time operations. Depending on the stakeholder, an engineers
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:58,054'); seek(598.0)">
              manager might want to know the reliability Moyer a week so they
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:01,584'); seek(601.0)">
              can schedule reliability work. A director might want to know it
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:04,944'); seek(604.0)">
              over a month, and a vp might want to know how reliable the service was
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:08,612'); seek(608.0)">
              over a quarter for reporting to c staff or putting the direction of technical
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:12,186'); seek(612.0)">
              efforts. And the purpose of
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:15,672'); seek(615.0)">
              slos is often to prioritize reliability work.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:19,160'); seek(619.0)">
              That is, if you aren't meeting your slos, you want to deprioritize
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:22,622'); seek(622.0)">
              feature work in favor of reliability engineering.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:25,550'); seek(625.0)">
              And we want to do this. We want to
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:29,080'); seek(629.0)">
              use these operations to do this because we want to be accurate. If we reprioritize
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:33,282'); seek(633.0)">
              engineering resources, that is expensive. So we want to make sure that we're
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:37,058'); seek(637.0)">
              doing that based off data that's correct and precise.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:40,582'); seek(640.0)">
              Now let's take a quick look at error budgets.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:43,630'); seek(643.0)">
              So an error budget is essentially just an inverted slO.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:46,950'); seek(646.0)">
              You subtract your success objective from one and you get your allowed failure
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:50,838'); seek(650.0)">
              rate. For user requests like a financial budget, you have a certain amount of
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:54,628'); seek(654.0)">
              errors that you can spend over a time period, and ideally
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:57,978'); seek(657.0)">
              this is an amount that does not make your customers think that your service is
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:01,252'); seek(661.0)">
              unreliable. You can create monitors for this with most of
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:04,948'); seek(664.0)">
              the tooling out there and perhaps alert when, say, 80% of your
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:08,168'); seek(668.0)">
              error budget has been used up for a given time period, which will let
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:11,928'); seek(671.0)">
              your engineering teams know that it's time to work on reliability.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:16,390'); seek(676.0)">
              You can also alert when the rate of an error budget burn
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:20,402'); seek(680.0)">
              predicts that you will exhaust your error budget before the time period has
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:23,852'); seek(683.0)">
              elapsed. And tooling. A lot of the tooling out there has functionality
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:27,922'); seek(687.0)">
              for that. So there are really two conditions that your error budget should
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:31,648'); seek(691.0)">
              spur action. First, if it's being used up too quickly and is in danger
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:35,414'); seek(695.0)">
              of being exhausted for that period, that should prioritize
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:38,726'); seek(698.0)">
              reliability focused work. The second is if your air budget is
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:42,288'); seek(702.0)">
              not being used up at all, that could indicate an improperly
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:46,266'); seek(706.0)">
              calibrated slo. Or it might mean that your service is normally so reliable
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:50,186'); seek(710.0)">
              that you're not prioritizing enough feature work, or that you should embark
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:53,738'); seek(713.0)">
              on controlled error budgets. Burns Google did that and mentioned
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:57,272'); seek(717.0)">
              it in the SRE book. With their chubby service, which was the distributed lock
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:00,878'); seek(720.0)">
              service, they introduced artificial air budget burn into
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:04,616'); seek(724.0)">
              their consumption into the service so that
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:08,252'); seek(728.0)">
              consumers of chubby would have to
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:12,410'); seek(732.0)">
              make their services be able to tolerate those chubby failures and
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:15,932'); seek(735.0)">
              hence become more reliable. And again, like slos,
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:19,330'); seek(739.0)">
              air budgets should reflect the mindset of the customer as much as
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:22,752'); seek(742.0)">
              possible. If the air budget is not exhausted but your customer is on
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:26,544'); seek(746.0)">
              the phone with your vp, go take a look at what you are measuring and
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:30,272'); seek(750.0)">
              if it really reflects what the customer is experiencing.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:34,030'); seek(754.0)">
              So, to sum up what I've showed you so far, there's a few points on
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:37,588'); seek(757.0)">
              getting thousands of engineers on the same page for slos and air budgets.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:41,418'); seek(761.0)">
              First, you need real world examples. Most of the published
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:44,954'); seek(764.0)">
              books out there are a bit abstract and hand wavy and
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:48,648'); seek(768.0)">
              don't really give you complete examples, so you need to have those to show
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:52,312'); seek(772.0)">
              folks. Second, present formulas for each of those entities
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:56,446'); seek(776.0)">
              which can be read easily both by humans and machines, and I've
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:00,354'); seek(780.0)">
              shown you what I used at scale there. Third, you have to be
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:04,028'); seek(784.0)">
              detailed and consistent. I see so many slos out there
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:07,292'); seek(787.0)">
              that leave off the time period, you might say well, the time range can
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:10,688'); seek(790.0)">
              be whatever you want, but then it's not can actual
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:15,632'); seek(795.0)">
              or actionable slos or air budget without a time range.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:20,190'); seek(800.0)">
              So we've looked at some example slos
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:23,322'); seek(803.0)">
              that most engineers can parse and memorize, and which engineering managers and product managers
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:27,674'); seek(807.0)">
              can use to correlate user happiness with. In most cases,
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:31,370'); seek(811.0)">
              that happiness means your service is available and it's running fast.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:35,352'); seek(815.0)">
              We can take the formulas I just showed and extend them to cover both conditions
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:39,278'); seek(819.0)">
              at once. So here we're talking about not only availability,
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:43,470'); seek(823.0)">
              but also latency and both of those. You need to
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:47,004'); seek(827.0)">
              have both of those. So here's an example SLI SLO
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:51,442'); seek(831.0)">
              and error budget, which covers both latency and availability. So if
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:55,388'); seek(835.0)">
              the page response is not a five xx or request was
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:58,956'); seek(838.0)">
              served in under 100 milliseconds, that request can be considered to
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:02,848'); seek(842.0)">
              be a good request. That's our slis to which we
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:06,048'); seek(846.0)">
              can add a success objective of three and a half nines and a time
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:09,232'); seek(849.0)">
              range of seven days to be evaluated on. To get the
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:12,788'); seek(852.0)">
              error budget, we can subtract a success objective of 99.95%
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:17,796'); seek(857.0)">
              from one, which gives us can error budget of zero 5%.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:22,404'); seek(862.0)">
              It's easy to understand and you can also easily create multiple
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:26,222'); seek(866.0)">
              slos and error budgets from the base SLI just by extending the time range.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:30,670'); seek(870.0)">
              Now, on the point of the success objective here I
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:33,848'); seek(873.0)">
              have 99.95% listed.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:36,958'); seek(876.0)">
              It's three and a half nine. Realistically, this is what enterprise
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:40,722'); seek(880.0)">
              customers demand these days. That means out of a million requests,
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:44,786'); seek(884.0)">
              you only get 500 requests that are slow or
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:48,572'); seek(888.0)">
              return what we also known was a fail or the 500
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:52,896'); seek(892.0)">
              internal server error as an example. And so if you're at scale,
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:56,966'); seek(896.0)">
              this should be your success objective. And I go into this in depth
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:00,838'); seek(900.0)">
              a little bit in the presentation shown below on the link for my Srecon
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:04,506'); seek(904.0)">
              presentation. So at this point we've
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:08,042'); seek(908.0)">
              got example formulas for slis, slos and air budgets that should
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:11,828'); seek(911.0)">
              be easy for folks to understand and also straightforward to implement
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:15,422'); seek(915.0)">
              with most monitoring and observability tooling out there,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:18,376'); seek(918.0)">
              both open source and commercial. Of the two components of latency
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:22,046'); seek(922.0)">
              and availability, availability is generally pretty easy to measure.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:25,950'); seek(925.0)">
              The most simple example is a 500 response.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:29,450'); seek(929.0)">
              You see the sorry a problem occurred. Web page latency,
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:33,458'); seek(933.0)">
              however, is more difficult to get right at scale. And when I say
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:37,420'); seek(937.0)">
              get it right, there are two aspects of being right. First,
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:41,152'); seek(941.0)">
              does your measurement have the right precision for your scale?
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:45,150'); seek(945.0)">
              That is, if I have 1 million user requests, can you generate
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:48,758'); seek(948.0)">
              a latency aggregate which means you aren't leaving more than a few dozen users
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:52,618'); seek(952.0)">
              off precision. Here is the number of decimal places.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:56,874'); seek(956.0)">
              The other aspect is accuracy. Is your latency aggregate
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:00,458'); seek(960.0)">
              for an SLO or a monitor actually correct? In many cases I've seen
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:04,232'); seek(964.0)">
              that answer is no to both and precision
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:08,702'); seek(968.0)">
              versus accuracy. Precision is the number of decimal places.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:12,270'); seek(972.0)">
              Accuracy is are the values in those decimal places correct?
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:16,108'); seek(976.0)">
              So let's dive in. So coming
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:19,996'); seek(979.0)">
              back to this chart. This chart is an
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:23,900'); seek(983.0)">
              RRD graph, and it measures network usage and calculates the 95th
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:27,458'); seek(987.0)">
              percentile over a time period. And at the
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:30,848'); seek(990.0)">
              time of the.com boom, you saw a lot of these RRD
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:34,102'); seek(994.0)">
              graphs, and these were mostly used for
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:38,192'); seek(998.0)">
              metering bandwidth. Bandwidth was built on something like five megabits at
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:41,760'); seek(1001.0)">
              95th percentile, meaning that if you took all your five minute bandwidth
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:45,898'); seek(1005.0)">
              usage measurement slices and ordered them, and took the 95th percentile,
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:50,330'); seek(1010.0)">
              if that number was above five megabits, you incur
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:53,966'); seek(1013.0)">
              overage charges. And this first popularized the
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:57,672'); seek(1017.0)">
              approach of using percentiles. And that would really
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:02,136'); seek(1022.0)">
              notably be seen about ten years later in 2011 with the
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:05,768'); seek(1025.0)">
              advent of the statSD protocol developed by Etsy, which provided
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:09,198'); seek(1029.0)">
              the p 95 was a latency aggregation metric. And I wrote more
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:12,748'); seek(1032.0)">
              about this in a blog post I published last year, and I'll go into some
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:15,868'); seek(1035.0)">
              of the content in the next slides, but this is the historical
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:20,310'); seek(1040.0)">
              significance of this graph.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:23,310'); seek(1043.0)">
              So let's talk about percentiles. This is a slide
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:26,950'); seek(1046.0)">
              from an SLO presentation I gave at Srecon 2019.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:30,662'); seek(1050.0)">
              It illustrates two latency distribution profiles, which are meant to
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:33,908'); seek(1053.0)">
              represent service nodes that are behaving differently.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:36,858'); seek(1056.0)">
              The blue distribution represents a bimodal latency
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:40,602'); seek(1060.0)">
              profile with lower latencies than the single mode red latency distribution.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:44,990'); seek(1064.0)">
              Basically, this could be two web servers, one performing well and
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:48,760'); seek(1068.0)">
              one performing not as well. The red server is not performing as
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:52,392'); seek(1072.0)">
              well, and if we take the p 95
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:56,232'); seek(1076.0)">
              values for latency for each server, and we average those, we could
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:17:59,932'); seek(1079.0)">
              get an indicator of around 430 milliseconds,
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:03,538'); seek(1083.0)">
              and we might think that hes that's the performance of our service.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:07,450'); seek(1087.0)">
              But if we combine the raw latency values from each of these distribution
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:11,586'); seek(1091.0)">
              sets and calculate the aggregate p 95 from those,
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:15,104'); seek(1095.0)">
              we'll get 230 milliseconds, and the error there
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:18,656'); seek(1098.0)">
              is almost 100%. And many,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:22,420'); seek(1102.0)">
              if not all, of the monitoring and observability tools out there will happily
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:26,362'); seek(1106.0)">
              let you use an averaging function for percentiles generated from
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:29,972'); seek(1109.0)">
              different hosts, nodes or clusters. If your distribution
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:33,482'); seek(1113.0)">
              profiles are the same, no problem. That works great. But it's when
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:37,048'); seek(1117.0)">
              your services are behaving asymmetrically that you'll encounter large errors with
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:40,888'); seek(1120.0)">
              this approach, and this is a problem with percentiles.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:44,414'); seek(1124.0)">
              And I talked about that in depth in that presentation.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:47,906'); seek(1127.0)">
              So beware of using percentiles.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:51,138'); seek(1131.0)">
              I've talked about this and ranted about this,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:54,410'); seek(1134.0)">
              and this kind of illustrates the
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:18:59,212'); seek(1139.0)">
              prime condition where that's can issue. And again, if everything's running
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:02,496'); seek(1142.0)">
              smoothly or if you have a single node, percentiles work just great.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:05,808'); seek(1145.0)">
              But it's the real world scenarios where we have different
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:09,680'); seek(1149.0)">
              node performance profiles and possibly hundreds
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:13,498'); seek(1153.0)">
              or thousands of nodes services requests that we want to be
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:16,948'); seek(1156.0)">
              able to handle and evaluate how our service
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:20,676'); seek(1160.0)">
              is performing accurately that teams into histograms
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:24,398'); seek(1164.0)">
              for measuring web service latency.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:28,230'); seek(1168.0)">
              And I give an internal
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:32,142'); seek(1172.0)">
              talk. I called Dr. Histogram how I learned to stop worrying and
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:35,704'); seek(1175.0)">
              love latency bands at Zendesk a few years ago,
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:39,370'); seek(1179.0)">
              and I went into more depth on the intricacies of
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:43,308'); seek(1183.0)">
              these three different types of histograms in the SLO comp link below.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:46,924'); seek(1186.0)">
              But in short,
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:51,070'); seek(1191.0)">
              there's a couple of different approaches you can use for measuring latency with histogram.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:55,718'); seek(1195.0)">
              And this involves essentially collecting a latency sample and fitting
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:19:59,318'); seek(1199.0)">
              it into what we call a bucket or a bin.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:02,342'); seek(1202.0)">
              And you'll see the gray and blue
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:06,122'); seek(1206.0)">
              bars here. Those are your buckets or bins. And so let's
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:09,258'); seek(1209.0)">
              take a look at how these are implemented differently. First, we could have
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:13,044'); seek(1213.0)">
              a log linear histogram, which you
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:16,328'); seek(1216.0)">
              can see the details of at openhistogram IO.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:19,566'); seek(1219.0)">
              And if we have a latency value here of 125 milliseconds,
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:23,918'); seek(1223.0)">
              we could say like, oh, we'll just slot that sample into
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:28,172'); seek(1228.0)">
              the greater than 100 millisecond, but less than 200 millisecond
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:31,698'); seek(1231.0)">
              bucket. And so this is a data structure
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:34,978'); seek(1234.0)">
              that is fairly easy to represent, because all you have is an
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:38,668'); seek(1238.0)">
              array representing different histogram buckets,
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:42,182'); seek(1242.0)">
              and then you increase the value of that array, essentially a counter
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:45,702'); seek(1245.0)">
              for each of those. And this is a volume invariant way
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:49,232'); seek(1249.0)">
              of storing large amounts of latency data that you
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:52,628'); seek(1252.0)">
              can also use to generate highly accurate aggregates
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:20:56,650'); seek(1256.0)">
              for an entire cluster or any set of hosts.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:01,650'); seek(1261.0)">
              And folks might also be familiar with the middle structure. That's the cumulative
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:05,822'); seek(1265.0)">
              histogram which prometheus uses.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:09,390'); seek(1269.0)">
              So if I have a latency value of 125 milliseconds,
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:12,638'); seek(1272.0)">
              it will assign labels starting at less than
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:16,200'); seek(1276.0)">
              infinity all the way down to less than 200.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:19,532'); seek(1279.0)">
              So this takes a few more data structures
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:22,898'); seek(1282.0)">
              or a few more counter values to implement, and it's not quite as
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:26,252'); seek(1286.0)">
              efficient as the logged linear histogram. And at Zendesk, I flipped that
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:29,948'); seek(1289.0)">
              on its head and came up what was called an inverse cumulative histogram,
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:34,406'); seek(1294.0)">
              where, for an example, if we have 125 milliseconds, I could
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:37,728'); seek(1297.0)">
              have a counter data structure, bump the counter and assign
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:41,654'); seek(1301.0)">
              these labels to it, which are often known as metric tags.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:45,322'); seek(1305.0)">
              I could assign greater than ten, greater than 50, greater than 100 milliseconds,
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:48,938'); seek(1308.0)">
              but not greater than 200 milliseconds. And this approach
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:53,050'); seek(1313.0)">
              made my head hurt for a little bit. But it has some advantages
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:56,718'); seek(1316.0)">
              in terms of operator efficiency and ease of use of implementing with a
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:00,584'); seek(1320.0)">
              lot of the tooling out there and all
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:04,888'); seek(1324.0)">
              these buckets that can also be referred to as latency bands.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:08,830'); seek(1328.0)">
              So you can kind of take a look at each of these different types of
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:11,948'); seek(1331.0)">
              histograms and decide, I might want to try to use histograms for
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:15,932'); seek(1335.0)">
              storing latency. So one of these should give you
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:19,388'); seek(1339.0)">
              some good results. And you might ask,
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:22,972'); seek(1342.0)">
              well, okay, well, now I know how to capture latency in a histogram at
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:26,592'); seek(1346.0)">
              scale. How do I generate an SLO from it? Well, let's go back to our
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:30,112'); seek(1350.0)">
              definition. It's the number of good requests divided by the number of bad
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:33,652'); seek(1353.0)">
              requests over a time range. And so in this case,
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:37,908'); seek(1357.0)">
              we can use a histogram data for the SLI.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:41,626'); seek(1361.0)">
              We can sum up the number of requests below 100 milliseconds,
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:45,418'); seek(1365.0)">
              and we can divide that by the total number of requests, which would just be
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:49,064'); seek(1369.0)">
              the count sum of all the bands, and we can multiply that
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:52,488'); seek(1372.0)">
              by 100. In the case of the
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:55,756'); seek(1375.0)">
              number of requests under 100 milliseconds,
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:22:59,058'); seek(1379.0)">
              with the inverse cumulative histogram,
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:03,450'); seek(1383.0)">
              we add up the counts of the blue bars.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:07,290'); seek(1387.0)">
              With the log linear histogram,
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:10,562'); seek(1390.0)">
              we just add up all those, the counts of the three bars to
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:14,048'); seek(1394.0)">
              the left of the three gray bars to the left of the blue bar.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:17,088'); seek(1397.0)">
              So, mathematically, this is very simple to implement,
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:20,022'); seek(1400.0)">
              and it's fast, it works quickly with all monitoring solutions
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:23,658'); seek(1403.0)">
              out there. And it's also extremely accurate because you're adding
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:27,018'); seek(1407.0)">
              up counts of essentially raw data,
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:30,610'); seek(1410.0)">
              and it also gives you essentially arbitrary precision.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:34,510'); seek(1414.0)">
              So this is a very robust and accurate approach,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:38,590'); seek(1418.0)">
              and I highly recommend this because this will give you some great numbers
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:42,376'); seek(1422.0)">
              at scale. Now, you might
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:46,152'); seek(1426.0)">
              say, like, well, this is a lot of work to do, but again, it goes
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:49,052'); seek(1429.0)">
              back to prioritizing reliability work. So we want to make sure that our
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:23:52,668'); seek(1432.0)">
              data about, if we're hitting our slos is accurate,
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:23:56,098'); seek(1436.0)">
              because we're spending, likely spending hundreds of thousands or millions of dollars
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:23:59,616'); seek(1439.0)">
              on shifting this engineering work. Now,
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:05,630'); seek(1445.0)">
              I showed some raw histograms there,
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:09,550'); seek(1449.0)">
              where we keep count of a number of samples in each bin,
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:12,774'); seek(1452.0)">
              and that way we can sum them up. But there's some approximate
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:16,602'); seek(1456.0)">
              structures out there which you can use,
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:19,508'); seek(1459.0)">
              and some of the vendors provide to do the same things. And they're
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:23,770'); seek(1463.0)">
              often called sketches, like the GK sketch or the DD
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:27,262'); seek(1467.0)">
              sketch structure by one of the vendors. And there's also approximate
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:31,278'); seek(1471.0)">
              histograms such as t Digest, made by Ted Dunning, which stores
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:35,374'); seek(1475.0)">
              approximations of distributions. And these
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:38,972'); seek(1478.0)">
              two charts here were taken from the log linear circ
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:43,298'); seek(1483.0)">
              Slis paper for open histogram, and they represent error
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:47,442'); seek(1487.0)">
              percentages for two different takes of workloads across different
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:51,328'); seek(1491.0)">
              p nine x values on the x axis. And you
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:54,688'); seek(1494.0)">
              can see the red line here, which is the open histogram implementation
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:24:58,326'); seek(1498.0)">
              that's got very low errors. But then you look at like the T Digest
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:02,278'); seek(1502.0)">
              DD sketch and HDR histogram, which do relatively well
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:06,052'); seek(1506.0)">
              in terms of errors. However, there's a detail that is not in these
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:09,812'); seek(1509.0)">
              charts. These errors are for single node evaluations only,
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:13,240'); seek(1513.0)">
              say for one web server. Now, how do approximate histograms
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:16,734'); seek(1516.0)">
              and sketches behave across asymmetric node workloads of
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:21,384'); seek(1521.0)">
              hundreds of web servers or arbitrary time windows? And that's
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:25,038'); seek(1525.0)">
              a very difficult question to answer. But by and large, the errors are likely
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:28,338'); seek(1528.0)">
              to be unbounded and using histograms which
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:31,628'); seek(1531.0)">
              store the exact sample counts, as I termed raw histograms
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:35,266'); seek(1535.0)">
              on the previous slide, those avoid that problem entirely,
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:39,446'); seek(1539.0)">
              ensuring that any aggregates generated for them
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:43,104'); seek(1543.0)">
              for slos are highly accurate and precise.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:46,262'); seek(1546.0)">
              So the sketches are good
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:49,392'); seek(1549.0)">
              to a certain extent, but they don't really hit
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:52,468'); seek(1552.0)">
              the same level of precision as these raw
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:25:55,898'); seek(1555.0)">
              histograms. Now, while we're on
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:25:59,284'); seek(1559.0)">
              the subject of histograms, I want to highlight some recent work in this area by
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:02,628'); seek(1562.0)">
              Adrian Cockroft. Adrian published a medium post titled percentiles
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:07,054'); seek(1567.0)">
              don't work. I think he coined them as wrong,
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:10,840'); seek(1570.0)">
              but useful analyzing the distribution of response times for web
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:14,872'); seek(1574.0)">
              services. A few months ago,
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:18,810'); seek(1578.0)">
              hes started doing some work here, where he
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:22,012'); seek(1582.0)">
              looked at operational telemetry, which is usually latency, and using some
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:25,772'); seek(1585.0)">
              r based tooling to decompose it into component normalish
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:29,842'); seek(1589.0)">
              distributions. So this image here was taken from his blog post, where he was
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:33,888'); seek(1593.0)">
              able to take a bimodal histogram here and decompose it into
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:37,632'); seek(1597.0)">
              two normal distributions using the mixed tools r package.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:41,790'); seek(1601.0)">
              Now why is this important and what does this have to do
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:45,268'); seek(1605.0)">
              with slos? We just took a look at what magnitude of errors
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:26:48,794'); seek(1608.0)">
              can arise from using percentiles for latency measurements. So we
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:26:52,548'); seek(1612.0)">
              follow that up with looking at histograms to measure latency distributions.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:26:57,510'); seek(1617.0)">
              So with something like this,
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:02,470'); seek(1622.0)">
              we can pull out these normal distributions.
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:05,614'); seek(1625.0)">
              And this could be relevant if we wanted to make an SLO for something like
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:09,292'); seek(1629.0)">
              disk writes, where you might have writing to a block device,
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:13,234'); seek(1633.0)">
              versus just writing to cache or reading
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:16,834'); seek(1636.0)">
              from the block device, as opposed to reading to cache. We can use these
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:20,752'); seek(1640.0)">
              to implement fine grained slos for each of the different
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:24,350'); seek(1644.0)">
              moyer of kind of the physical manifestations
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:28,870'); seek(1648.0)">
              of the system in the cloud. It could be like writing to s three or
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:33,090'); seek(1653.0)">
              different storage levels there. And so there's some really promising
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:36,938'); seek(1656.0)">
              work here. And I think that this
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:40,932'); seek(1660.0)">
              is definitely something to follow going ahead, because if you
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:44,888'); seek(1664.0)">
              really want to get fine grained with, say, a system that
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:48,328'); seek(1668.0)">
              has a few different modes at very large scale, this approach
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:52,510'); seek(1672.0)">
              would allow you to do that.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:27:55,270'); seek(1675.0)">
              Now, one common question I've gotten about slos and
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:27:58,684'); seek(1678.0)">
              error budgets is how do you implement them across a distributed service architectures?
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:03,506'); seek(1683.0)">
              Now, one approach is to use an SLO and error budget for each service,
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:07,116'); seek(1687.0)">
              and this includes third party vendor services, as shown
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:10,454'); seek(1690.0)">
              in blue here. Now, the error rates I've shown
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:13,782'); seek(1693.0)">
              here and documented in red are error
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:17,878'); seek(1697.0)">
              rates across these different services. So you can have a
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:21,408'); seek(1701.0)">
              different error rate contribution from the third party service, the mid tier and the edge
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:25,338'); seek(1705.0)">
              tier. And you can take those and you
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:28,628'); seek(1708.0)">
              can add those up and essentially get a compound or
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:31,908'); seek(1711.0)">
              composite error rate for what the customer is seeing. So in this
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:35,332'); seek(1715.0)">
              case, you might see that, hey, our in house back
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:38,888'); seek(1718.0)">
              end service has a 0.1% error rate.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:42,150'); seek(1722.0)">
              But then if you roll that up to the mid tier,
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:45,518'); seek(1725.0)">
              now you've got 1% error
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:49,378'); seek(1729.0)">
              rate also from the third party, which exceeds your mid tier
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:28:52,626'); seek(1732.0)">
              error budget of 1%. And so
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:28:57,050'); seek(1737.0)">
              you can kind of put these diagrams together, and it
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:00,444'); seek(1740.0)">
              will help you understand where you need to focus reliability
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:03,910'); seek(1743.0)">
              work. In this case, you need to focus reliability work on the
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:07,504'); seek(1747.0)">
              third party and either pull that in house or do
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:10,752'); seek(1750.0)">
              some sort of interface around
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:14,132'); seek(1754.0)">
              it to make it more reliable. And the goal here is not to assign blames
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:17,226'); seek(1757.0)">
              to teams or to different services. It's to
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:20,452'); seek(1760.0)">
              prioritize reliability work. And that's
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:24,458'); seek(1764.0)">
              really what this is all about. Because for
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:28,824'); seek(1768.0)">
              most of almost, I would say almost all of you out there, you're using some
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:32,008'); seek(1772.0)">
              sort of distributed system like this, and you're going to say like,
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:35,532'); seek(1775.0)">
              well, how do we use slos across that?
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:38,876'); seek(1778.0)">
              Remember to be customer centric, and you can roll
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:42,258'); seek(1782.0)">
              those error budgets up, starting from,
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:46,090'); seek(1786.0)">
              I'll call it upstream, which is further away from the client. You can roll
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:29:49,414'); seek(1789.0)">
              those error rates up and get a composite error
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:29:52,918'); seek(1792.0)">
              rate fairly simply and see
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:29:56,288'); seek(1796.0)">
              what the client is seeing. And that's it.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:00,128'); seek(1800.0)">
              My tour through techniques for slos
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:04,186'); seek(1804.0)">
              and air budgets at scale I hope you enjoyed this presentation. Feel free
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:08,372'); seek(1808.0)">
              to reach out to me on LinkedIn or Twitter.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:12,026'); seek(1812.0)">
              And that Twitter handle also works across Mastodon and
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:15,444'); seek(1815.0)">
              a couple of the other news sites popping up. I'd love to hear about your
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:18,692'); seek(1818.0)">
              experiences and talk about how you're using
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:22,420'); seek(1822.0)">
              slos and air budgets at scale. Thanks 42.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:25,676'); seek(1825.0)">
              We'll see you next time.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Observability%202023%20-%20Fred%20Moyer.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Observability%202023%20-%20Fred%20Moyer.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #A8AC51;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/obs2023" class="btn btn-sm btn-danger shadow lift" style="background-color: #A8AC51;">
                <i class="fe fe-grid me-2"></i>
                See all 16 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/fred%20moyer_obser.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Fred Moyer
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    SRE Observability Engineer 
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/redhotpenguin/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Fred Moyer's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@phredmoyer" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Fred Moyer's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @phredmoyer"
                  data-url="https://www.conf42.com/obs2023"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/obs2023"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Observability"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/aiml2024">
                  Artificial Intelligence & Machine Learning (AI & ML) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/olly2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday London 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

  </body>
</html>