<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Prompt Engineering Simplified</title>
    <meta name="description" content="Master your prompt-fu!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Dan%20Cleary_prompt.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Prompt Engineering Simplified | Conf42"/>
    <meta property="og:description" content="Everything is going well until a prompt that usually works suddenly goes off the rails. Sound familiar? Prompts can be tricky, and models are non-deterministic, but with a few prompt engineering basics, you can regain control, improve consistency, and achieve more reliable outputs with AI."/>
    <meta property="og:url" content="https://conf42.com/Prompt_Engineering_2024_Dan_Cleary_promptengineering_ai_simplified"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #749BC2;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Prompt Engineering 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Master your prompt-fu!
 -->
              <script>
                const event_date = new Date("2024-11-14T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-11-14T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "g84JA7Czshs"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrAVCqb1r_qSxiIxgr09QRvk" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hey everyone.", "timestamp": "00:00:00,100", "timestamp_s": 0.0}, {"text": "How\u0027s it going?", "timestamp": "00:00:00,600", "timestamp_s": 0.0}, {"text": "My name is Dan Cleary.", "timestamp": "00:00:01,510", "timestamp_s": 1.0}, {"text": "I\u0027m the co founder of PromptHub and today we will be talking", "timestamp": "00:00:03,200", "timestamp_s": 3.0}, {"text": "all about prompt engineering.", "timestamp": "00:00:06,000", "timestamp_s": 6.0}, {"text": "We\u0027ll talk about why prompt engineering, is it dead?", "timestamp": "00:00:07,970", "timestamp_s": 7.0}, {"text": "system message versus prompt or user message, how different models", "timestamp": "00:00:11,005", "timestamp_s": 11.0}, {"text": "require different types of prompt and prompting methods, a variety of", "timestamp": "00:00:15,525", "timestamp_s": 15.0}, {"text": "different ways that you can try to get better outputs through prompt", "timestamp": "00:00:18,975", "timestamp_s": 18.0}, {"text": "engineering methods, best practices.", "timestamp": "00:00:21,964", "timestamp_s": 21.0}, {"text": "Does persona prompting even work?", "timestamp": "00:00:25,095", "timestamp_s": 25.0}, {"text": "Meta prompting and a whole bunch of templates and takeaways throughout.", "timestamp": "00:00:26,834", "timestamp_s": 26.0}, {"text": "So I like to start with this question of like, why prompt engineering?", "timestamp": "00:00:30,355", "timestamp_s": 30.0}, {"text": "this was a pretty popular opinion.", "timestamp": "00:00:34,035", "timestamp_s": 34.0}, {"text": "I\u0027d say early on that prompt engineering wasn\u0027t really a thing, but I think Over", "timestamp": "00:00:35,355", "timestamp_s": 35.0}, {"text": "the months and years since ChatGPT came out, I think people have found that", "timestamp": "00:00:39,510", "timestamp_s": 39.0}, {"text": "it actually can be quite hard to get the type of output that you\u0027re looking", "timestamp": "00:00:43,300", "timestamp_s": 43.0}, {"text": "to get from a model consistently.", "timestamp": "00:00:46,350", "timestamp_s": 46.0}, {"text": "and that\u0027s where kind of prompt engineering comes into play.", "timestamp": "00:00:48,210", "timestamp_s": 48.0}, {"text": "And small changes just end up making a big difference here, because", "timestamp": "00:00:51,290", "timestamp_s": 51.0}, {"text": "of how models latent space works.", "timestamp": "00:00:54,669", "timestamp_s": 54.0}, {"text": "So if you say, write a code to render this image.", "timestamp": "00:00:56,359", "timestamp_s": 56.0}, {"text": "write secure code as if you were John Carmack, which is", "timestamp": "00:00:59,454", "timestamp_s": 59.0}, {"text": "like a famous software engineer.", "timestamp": "00:01:01,504", "timestamp_s": 61.0}, {"text": "You\u0027ll get drastically different outputs just by those small tweaks.", "timestamp": "00:01:04,024", "timestamp_s": 64.0}, {"text": "And I think that will always be there in some capacity.", "timestamp": "00:01:07,494", "timestamp_s": 67.0}, {"text": "you maybe have to do less of the engineering and method type work", "timestamp": "00:01:11,784", "timestamp_s": 71.0}, {"text": "in the future, potentially, but I think there\u0027s always going to be", "timestamp": "00:01:16,544", "timestamp_s": 76.0}, {"text": "a small place for this, at least.", "timestamp": "00:01:19,084", "timestamp_s": 79.0}, {"text": "Another reason why it\u0027s important is that it\u0027s one of the three major", "timestamp": "00:01:21,004", "timestamp_s": 81.0}, {"text": "ways to get Better outputs from LLMs.", "timestamp": "00:01:23,684", "timestamp_s": 83.0}, {"text": "and it\u0027s the starting point.", "timestamp": "00:01:26,344", "timestamp_s": 86.0}, {"text": "So you do a bunch of prompt engineering, you see where you\u0027re at, what problems", "timestamp": "00:01:27,974", "timestamp_s": 87.0}, {"text": "you\u0027re running into and whether you need to turn to other methods", "timestamp": "00:01:31,034", "timestamp_s": 91.0}, {"text": "to solve those remaining problems.", "timestamp": "00:01:34,404", "timestamp_s": 94.0}, {"text": "It\u0027s just a starting point for a lot of teams and it\u0027s very accessible.", "timestamp": "00:01:36,844", "timestamp_s": 96.0}, {"text": "You can be technical, you can be non technical, and you can", "timestamp": "00:01:40,279", "timestamp_s": 100.0}, {"text": "get your, up and running very quickly with prompt engineering.", "timestamp": "00:01:42,579", "timestamp_s": 102.0}, {"text": "And so lastly, you really can\u0027t avoid it.", "timestamp": "00:01:45,199", "timestamp_s": 105.0}, {"text": "And so for all those reasons, that\u0027s why I believe it\u0027s important, at", "timestamp": "00:01:47,749", "timestamp_s": 107.0}, {"text": "least for the time being, and I think into the near future here.", "timestamp": "00:01:51,239", "timestamp_s": 111.0}, {"text": "And lastly, in the same way that having good UI UX product experience", "timestamp": "00:01:54,969", "timestamp_s": 114.0}, {"text": "is a competitive advantage.", "timestamp": "00:01:59,979", "timestamp_s": 119.0}, {"text": "Having prompts that work well is a similarly important", "timestamp": "00:02:01,339", "timestamp_s": 121.0}, {"text": "competitive advantage for AI teams.", "timestamp": "00:02:04,599", "timestamp_s": 124.0}, {"text": "So now we\u0027ll talk about the different types of messages that models can", "timestamp": "00:02:06,859", "timestamp_s": 126.0}, {"text": "support, namely system versus user.", "timestamp": "00:02:11,014", "timestamp_s": 131.0}, {"text": "So system message, as you can see here, you are helpful assistant.", "timestamp": "00:02:14,024", "timestamp_s": 134.0}, {"text": "Then we have a user message, which is like the prompt where you\u0027re", "timestamp": "00:02:18,554", "timestamp_s": 138.0}, {"text": "sending to the model to get an output.", "timestamp": "00:02:21,164", "timestamp_s": 141.0}, {"text": "So on and so forth.", "timestamp": "00:02:23,014", "timestamp_s": 143.0}, {"text": "System message is optional.", "timestamp": "00:02:24,364", "timestamp_s": 144.0}, {"text": "Like when you\u0027re doing these things via the API.", "timestamp": "00:02:25,914", "timestamp_s": 145.0}, {"text": "so this is the stuff that you are, is behind chat GPT\u0027s interface in terms", "timestamp": "00:02:27,974", "timestamp_s": 147.0}, {"text": "of what open AI has programmed, the.", "timestamp": "00:02:33,014", "timestamp_s": 153.0}, {"text": "Chatbot to sound like and think and so it\u0027s optional when", "timestamp": "00:02:35,784", "timestamp_s": 155.0}, {"text": "you\u0027re sending it via the API.", "timestamp": "00:02:38,614", "timestamp_s": 158.0}, {"text": "It\u0027s used to set context and rules, so just the higher level things", "timestamp": "00:02:39,364", "timestamp_s": 159.0}, {"text": "versus low level instructions.", "timestamp": "00:02:43,274", "timestamp_s": 163.0}, {"text": "So setting the role, context, guiding the model behavior, controlling", "timestamp": "00:02:45,254", "timestamp_s": 165.0}, {"text": "format, things like that, versus the prompt is where you get more", "timestamp": "00:02:49,024", "timestamp_s": 169.0}, {"text": "specific, more of the contextual info.", "timestamp": "00:02:51,974", "timestamp_s": 171.0}, {"text": "The focus, so on and so forth.", "timestamp": "00:02:54,429", "timestamp_s": 174.0}, {"text": "And we have a couple of examples in the wild here from companies like OpenAI.", "timestamp": "00:02:56,369", "timestamp_s": 176.0}, {"text": "Anthropic also published theirs, on their documentation.", "timestamp": "00:03:01,689", "timestamp_s": 181.0}, {"text": "So you could see the system messages that power their Claude, chatbots.", "timestamp": "00:03:04,929", "timestamp_s": 184.0}, {"text": "And so now we\u0027ll talk about how different models require different prompts.", "timestamp": "00:03:08,529", "timestamp_s": 188.0}, {"text": "So if you\u0027re interchanging between providers and even models within the", "timestamp": "00:03:11,769", "timestamp_s": 191.0}, {"text": "same provider, you\u0027ve probably run into this experience where each of", "timestamp": "00:03:16,299", "timestamp_s": 196.0}, {"text": "them has their own differences in the way they handle tasks and the", "timestamp": "00:03:18,889", "timestamp_s": 198.0}, {"text": "way that they sound and respond.", "timestamp": "00:03:22,049", "timestamp_s": 202.0}, {"text": "so for example, we\u0027ll take a chain of thought.", "timestamp": "00:03:24,064", "timestamp_s": 204.0}, {"text": "so this is thinking step by step, prompting the model to do some", "timestamp": "00:03:26,544", "timestamp_s": 206.0}, {"text": "reasoning before giving an output.", "timestamp": "00:03:30,124", "timestamp_s": 210.0}, {"text": "There\u0027s an experiment ran where they found that chain of thought actually reduced", "timestamp": "00:03:33,094", "timestamp_s": 213.0}, {"text": "the performance of Palm two, which is, an older Google model at this point, but just", "timestamp": "00:03:37,674", "timestamp_s": 217.0}, {"text": "goes to show that doing what is considered a best practice didn\u0027t help performance.", "timestamp": "00:03:42,744", "timestamp_s": 222.0}, {"text": "In this case, it actually made things worse.", "timestamp": "00:03:47,864", "timestamp_s": 227.0}, {"text": "And That just goes to show that one size is really not going to fit all, which is", "timestamp": "00:03:50,224", "timestamp_s": 230.0}, {"text": "the second paper we\u0027ll talk about, which is from VMware, where they basically", "timestamp": "00:03:53,784", "timestamp_s": 233.0}, {"text": "tested a wide variety of different prompt openers, descriptions, and closers.", "timestamp": "00:03:58,044", "timestamp_s": 238.0}, {"text": "They put all these prompts together using all of these different parts here.", "timestamp": "00:04:03,514", "timestamp_s": 243.0}, {"text": "Here are a couple examples of a math dataset with the", "timestamp": "00:04:07,384", "timestamp_s": 247.0}, {"text": "various system messages here.", "timestamp": "00:04:10,694", "timestamp_s": 250.0}, {"text": "Some have a role, some don\u0027t, so on and so forth.", "timestamp": "00:04:13,294", "timestamp_s": 253.0}, {"text": "And what they did was they had the model generate the best prompt.", "timestamp": "00:04:16,734", "timestamp_s": 256.0}, {"text": "for that specific task.", "timestamp": "00:04:22,614", "timestamp_s": 262.0}, {"text": "And so they, they let the model decide and do its own metaprompting based", "timestamp": "00:04:24,294", "timestamp_s": 264.0}, {"text": "on the task and the outputs that it was receiving and so on and so forth.", "timestamp": "00:04:27,524", "timestamp_s": 267.0}, {"text": "This was what Llama 2 created and you could see, it\u0027s including kind", "timestamp": "00:04:31,474", "timestamp_s": 271.0}, {"text": "of some Star Trek language here.", "timestamp": "00:04:35,944", "timestamp_s": 275.0}, {"text": "So this is after running hundreds of prompts, doing hundreds of metaprompting", "timestamp": "00:04:38,104", "timestamp_s": 278.0}, {"text": "in like an experimental way.", "timestamp": "00:04:40,934", "timestamp_s": 280.0}, {"text": "setting where there is, a high degree of statistical significance.", "timestamp": "00:04:42,639", "timestamp_s": 282.0}, {"text": "Versus Llama 2, 13b, so same family, same provider, doesn\u0027t know", "timestamp": "00:04:48,199", "timestamp_s": 288.0}, {"text": "mention of any Star Trek things, like it\u0027s all very cut and dry.", "timestamp": "00:04:52,419", "timestamp_s": 292.0}, {"text": "And then this was pretty popular last year, this kind of take a deep breath", "timestamp": "00:04:56,249", "timestamp_s": 296.0}, {"text": "and work on this problem step by step.", "timestamp": "00:04:59,099", "timestamp_s": 299.0}, {"text": "This was a similar experiment where they had the model figure out a top instruction", "timestamp": "00:05:00,529", "timestamp_s": 300.0}, {"text": "for itself, and they ran a bunch of tests to see which one goes to the top here.", "timestamp": "00:05:05,539", "timestamp_s": 305.0}, {"text": "And so they were, this is the top instruction for the A variety", "timestamp": "00:05:09,059", "timestamp_s": 309.0}, {"text": "of different models here, and we can see GPT\u0027s fours is You know,", "timestamp": "00:05:11,539", "timestamp_s": 311.0}, {"text": "five times larger than palm twos.", "timestamp": "00:05:16,219", "timestamp_s": 316.0}, {"text": "And so it just goes to show that everything is going to be a little", "timestamp": "00:05:18,439", "timestamp_s": 318.0}, {"text": "bit different depending on the model.", "timestamp": "00:05:22,179", "timestamp_s": 322.0}, {"text": "And that\u0027s why it\u0027s important to test these things.", "timestamp": "00:05:23,529", "timestamp_s": 323.0}, {"text": "And if you\u0027re looking for more information on models like max tokens,", "timestamp": "00:05:25,689", "timestamp_s": 325.0}, {"text": "context, windows, costs, features, and functionalities, we have a, directory", "timestamp": "00:05:29,929", "timestamp_s": 329.0}, {"text": "that we just launched that has all the information for basically all the model", "timestamp": "00:05:33,709", "timestamp_s": 333.0}, {"text": "providers that are the most popular.", "timestamp": "00:05:36,299", "timestamp_s": 336.0}, {"text": "All right So moving on to My two favorite prompt engineering practices and the", "timestamp": "00:05:38,049", "timestamp_s": 338.0}, {"text": "one that we tell the teams that we work with to focus on is you know giving the", "timestamp": "00:05:42,309", "timestamp_s": 342.0}, {"text": "model room to think this is a popular one and kind of relays into Chain of", "timestamp": "00:05:46,509", "timestamp_s": 346.0}, {"text": "thought to a degree you want to let the model think you don\u0027t want to force it", "timestamp": "00:05:51,239", "timestamp_s": 351.0}, {"text": "to give an answer Or overly constrain it.", "timestamp": "00:05:54,759", "timestamp_s": 354.0}, {"text": "You want it to go through some sort of reasoning process and", "timestamp": "00:05:57,819", "timestamp_s": 357.0}, {"text": "come to an answer on its own.", "timestamp": "00:06:00,779", "timestamp_s": 360.0}, {"text": "And then using delimiters or some way to better structure your prompt.", "timestamp": "00:06:02,229", "timestamp_s": 362.0}, {"text": "I can\u0027t tell you how many times I\u0027ve had a team say, Hey, we\u0027re", "timestamp": "00:06:05,419", "timestamp_s": 365.0}, {"text": "struggling with this prompt.", "timestamp": "00:06:08,029", "timestamp_s": 368.0}, {"text": "Can you look at it?", "timestamp": "00:06:08,819", "timestamp_s": 368.0}, {"text": "I look at it and I can\u0027t even.", "timestamp": "00:06:09,429", "timestamp_s": 369.0}, {"text": "See what\u0027s going on.", "timestamp": "00:06:10,919", "timestamp_s": 370.0}, {"text": "And so that\u0027s a good litmus test is have someone else look at your", "timestamp": "00:06:12,179", "timestamp_s": 372.0}, {"text": "prompts, see if they can organize it or understand your organization.", "timestamp": "00:06:14,529", "timestamp_s": 374.0}, {"text": "And if not start to provide some of that via, delimiters, backticks,", "timestamp": "00:06:18,219", "timestamp_s": 378.0}, {"text": "quotes, whatever is going to help structure the prompt better.", "timestamp": "00:06:23,219", "timestamp_s": 383.0}, {"text": "Now we\u0027ll look at a few.", "timestamp": "00:06:27,029", "timestamp_s": 387.0}, {"text": "So just to set the stage, a zero shot prompt is just a normal prompt.", "timestamp": "00:06:29,129", "timestamp_s": 389.0}, {"text": "So if you hear that ever referenced, it\u0027s basically just a typical prompt like this.", "timestamp": "00:06:33,409", "timestamp_s": 393.0}, {"text": "A few shot prompt is when you include examples inside of your prompt.", "timestamp": "00:06:37,699", "timestamp_s": 397.0}, {"text": "So this would be all one prompt sent, but we\u0027re going to say,", "timestamp": "00:06:41,669", "timestamp_s": 401.0}, {"text": "show It\u0027s examples in line.", "timestamp": "00:06:44,869", "timestamp_s": 404.0}, {"text": "So we\u0027re classifying the sentiment of this feedback.", "timestamp": "00:06:47,034", "timestamp_s": 407.0}, {"text": "So this person\u0027s positive, then negative, then positive.", "timestamp": "00:06:49,754", "timestamp_s": 409.0}, {"text": "And then we\u0027re going to let the model kind of fill in the, the blank here.", "timestamp": "00:06:52,384", "timestamp_s": 412.0}, {"text": "And you could do this via multiple messages.", "timestamp": "00:06:55,804", "timestamp_s": 415.0}, {"text": "So like sending an array of messages from the API.", "timestamp": "00:06:59,204", "timestamp_s": 419.0}, {"text": "And that\u0027s typically, I think, technically what few shop really is rather than", "timestamp": "00:07:01,384", "timestamp_s": 421.0}, {"text": "having it all be in one message.", "timestamp": "00:07:05,124", "timestamp_s": 425.0}, {"text": "Because the model will handle it different if it has it in its history", "timestamp": "00:07:07,474", "timestamp_s": 427.0}, {"text": "versus reading it all in a prompt.", "timestamp": "00:07:10,184", "timestamp_s": 430.0}, {"text": "Both ways are effective.", "timestamp": "00:07:11,874", "timestamp_s": 431.0}, {"text": "Both ways are worth testing.", "timestamp": "00:07:13,074", "timestamp_s": 433.0}, {"text": "SureShot Prompting is really helpful in a variety of domains.", "timestamp": "00:07:14,664", "timestamp_s": 434.0}, {"text": "It can help with structure.", "timestamp": "00:07:18,084", "timestamp_s": 438.0}, {"text": "format, content, style, and tone, and those are really the really big", "timestamp": "00:07:20,619", "timestamp_s": 440.0}, {"text": "areas that I\u0027ve seen it be helpful.", "timestamp": "00:07:26,199", "timestamp_s": 446.0}, {"text": "How many examples?", "timestamp": "00:07:28,079", "timestamp_s": 448.0}, {"text": "The great benefit here is that you get a lot of the gains from", "timestamp": "00:07:29,079", "timestamp_s": 449.0}, {"text": "just having one or two examples.", "timestamp": "00:07:32,929", "timestamp_s": 452.0}, {"text": "And then it plateaus and can even degrade in a lot of situations.", "timestamp": "00:07:36,019", "timestamp_s": 456.0}, {"text": "we say, hey, start with, Anywhere from two to five examples, if you\u0027re still", "timestamp": "00:07:38,779", "timestamp_s": 458.0}, {"text": "not getting the performance you\u0027re looking for, you might need to look", "timestamp": "00:07:42,424", "timestamp_s": 462.0}, {"text": "elsewhere because you have the chance of it starting to degrade, the performance.", "timestamp": "00:07:44,624", "timestamp_s": 464.0}, {"text": "A couple of other important, best practices here.", "timestamp": "00:07:49,154", "timestamp_s": 469.0}, {"text": "Use diverse examples.", "timestamp": "00:07:51,664", "timestamp_s": 471.0}, {"text": "So if you\u0027re doing a sentiment analysis, don\u0027t use only positive ones.", "timestamp": "00:07:53,324", "timestamp_s": 473.0}, {"text": "Use a combination.", "timestamp": "00:07:56,684", "timestamp_s": 476.0}, {"text": "Have them cover a wide range of what you are going to be", "timestamp": "00:07:57,744", "timestamp_s": 477.0}, {"text": "expecting in your application.", "timestamp": "00:08:00,434", "timestamp_s": 480.0}, {"text": "So cover those edge cases.", "timestamp": "00:08:02,304", "timestamp_s": 482.0}, {"text": "Random, randomly order them so you wouldn\u0027t have all the positives in one", "timestamp": "00:08:04,074", "timestamp_s": 484.0}, {"text": "section and then all the negatives.", "timestamp": "00:08:07,064", "timestamp_s": 487.0}, {"text": "And then make sure they follow a common format so the model can", "timestamp": "00:08:08,604", "timestamp_s": 488.0}, {"text": "better learn, in context there.", "timestamp": "00:08:11,424", "timestamp_s": 491.0}, {"text": "And we have a whole guide on this as well, with lots of examples and templates.", "timestamp": "00:08:14,094", "timestamp_s": 494.0}, {"text": "Alright, next up is according to prompting, which is basically", "timestamp": "00:08:17,454", "timestamp_s": 497.0}, {"text": "just trying to ground the model in a specific set of information.", "timestamp": "00:08:19,914", "timestamp_s": 499.0}, {"text": "so you can see in this original prompt, it\u0027s asking a question, and then it just", "timestamp": "00:08:25,184", "timestamp_s": 505.0}, {"text": "has, adds in according to Wikipedia.", "timestamp": "00:08:28,814", "timestamp_s": 508.0}, {"text": "So it\u0027s trying to guide the model to the type of answer that you are looking for.", "timestamp": "00:08:31,894", "timestamp_s": 511.0}, {"text": "are looking to.", "timestamp": "00:08:36,254", "timestamp_s": 516.0}, {"text": "And this can be helpful, especially if you\u0027ve done like some fine tuning.", "timestamp": "00:08:36,784", "timestamp_s": 516.0}, {"text": "And here\u0027s an example of that.", "timestamp": "00:08:40,154", "timestamp_s": 520.0}, {"text": "Again, all the templates are available in PromptTab under", "timestamp": "00:08:41,254", "timestamp_s": 521.0}, {"text": "the templates tab for free too.", "timestamp": "00:08:44,394", "timestamp_s": 524.0}, {"text": "And then last one I believe is called step back prompting.", "timestamp": "00:08:46,394", "timestamp_s": 526.0}, {"text": "So this is a very similar kind of, I say, variant of chain of thought prompting,", "timestamp": "00:08:48,724", "timestamp_s": 528.0}, {"text": "where you send a question, you have the model kind of think step by step", "timestamp": "00:08:53,324", "timestamp_s": 533.0}, {"text": "in first kind of abstract concepts, and then Use those abstractions to reason", "timestamp": "00:08:56,774", "timestamp_s": 536.0}, {"text": "through the question or the task.", "timestamp": "00:09:03,474", "timestamp_s": 543.0}, {"text": "And so you prompted to do this thinking first, and this is what you see with a", "timestamp": "00:09:05,044", "timestamp_s": 545.0}, {"text": "one preview and a one mini where it thinks about the step that reasons about them.", "timestamp": "00:09:08,294", "timestamp_s": 548.0}, {"text": "And then it solves the problem.", "timestamp": "00:09:12,734", "timestamp_s": 552.0}, {"text": "So again, yeah, these are all linked in prompt up.", "timestamp": "00:09:14,804", "timestamp_s": 554.0}, {"text": "So app dot prompt dot U S slash templates.", "timestamp": "00:09:17,824", "timestamp_s": 557.0}, {"text": "Last up.", "timestamp": "00:09:21,744", "timestamp_s": 561.0}, {"text": "And my favorite one is persona prompting.", "timestamp": "00:09:22,224", "timestamp_s": 562.0}, {"text": "So this is like very popular for a long time now.", "timestamp": "00:09:25,234", "timestamp_s": 565.0}, {"text": "so this is like giving the.", "timestamp": "00:09:28,454", "timestamp_s": 568.0}, {"text": "the model, a persona to solve a certain task.", "timestamp": "00:09:30,759", "timestamp_s": 570.0}, {"text": "And there are a lot of papers on both sides of this in", "timestamp": "00:09:33,539", "timestamp_s": 573.0}, {"text": "terms of how effective it is.", "timestamp": "00:09:37,839", "timestamp_s": 577.0}, {"text": "I have come out to the other side to thinking it\u0027s actually not that", "timestamp": "00:09:39,639", "timestamp_s": 579.0}, {"text": "effective in certain use cases.", "timestamp": "00:09:42,669", "timestamp_s": 582.0}, {"text": "And the main reason comes from a learn prompting.", "timestamp": "00:09:44,059", "timestamp_s": 584.0}, {"text": "org paper, which is linked here.", "timestamp": "00:09:48,239", "timestamp_s": 588.0}, {"text": "I had this intuition that it wasn\u0027t great for doing accuracy based tasks,", "timestamp": "00:09:50,549", "timestamp_s": 590.0}, {"text": "and this really reinforced that.", "timestamp": "00:09:55,969", "timestamp_s": 595.0}, {"text": "So basically they set up an experiment.", "timestamp": "00:09:57,994", "timestamp_s": 597.0}, {"text": "They ran 2000 prompts, and it was a MMLU case, so like a knowledge based, task, and", "timestamp": "00:10:00,134", "timestamp_s": 600.0}, {"text": "they gave a bunch of different roles here.", "timestamp": "00:10:08,014", "timestamp_s": 608.0}, {"text": "And really the kind of long and short of it is that.", "timestamp": "00:10:10,434", "timestamp_s": 610.0}, {"text": "The genius when they were told the model, it was a genius.", "timestamp": "00:10:12,759", "timestamp_s": 612.0}, {"text": "It got a lower percentage than when it told it, it was like an", "timestamp": "00:10:15,589", "timestamp_s": 615.0}, {"text": "idiot or something like that.", "timestamp": "00:10:17,829", "timestamp_s": 617.0}, {"text": "Yeah.", "timestamp": "00:10:18,969", "timestamp_s": 618.0}, {"text": "The genius was actually the worst performing one here.", "timestamp": "00:10:19,609", "timestamp_s": 619.0}, {"text": "And so how can you reconcile that and still think that role prompting works?", "timestamp": "00:10:21,489", "timestamp_s": 621.0}, {"text": "I don\u0027t know.", "timestamp": "00:10:26,579", "timestamp_s": 626.0}, {"text": "we have to look at other data, but this seems just pretty strong to rule out", "timestamp": "00:10:27,329", "timestamp_s": 627.0}, {"text": "that conclusion and everything else.", "timestamp": "00:10:30,569", "timestamp_s": 630.0}, {"text": "I would say it may just be anecdotal, but it is helpful in terms of,", "timestamp": "00:10:31,959", "timestamp_s": 631.0}, {"text": "I would say, Tone and style.", "timestamp": "00:10:35,979", "timestamp_s": 635.0}, {"text": "So if you\u0027re doing content generation, things like that, but not for increasing", "timestamp": "00:10:38,049", "timestamp_s": 638.0}, {"text": "accuracy, last up, we\u0027ll talk a little bit about meta prompting.", "timestamp": "00:10:42,229", "timestamp_s": 642.0}, {"text": "So what\u0027s meta prompting.", "timestamp": "00:10:45,639", "timestamp_s": 645.0}, {"text": "It\u0027s a prompt engineering method that uses the LLM to help you write your prompt.", "timestamp": "00:10:47,299", "timestamp_s": 647.0}, {"text": "So using chat GPT to help write your prompt.", "timestamp": "00:10:50,729", "timestamp_s": 650.0}, {"text": "And we are big proponents of this.", "timestamp": "00:10:53,329", "timestamp_s": 653.0}, {"text": "We think this is how prompt engineering should really be done alongside", "timestamp": "00:10:55,959", "timestamp_s": 655.0}, {"text": "the model that you\u0027re working with.", "timestamp": "00:10:59,979", "timestamp_s": 659.0}, {"text": "And the same way they use, AI and LLMs for writing and coding, you should", "timestamp": "00:11:01,599", "timestamp_s": 661.0}, {"text": "do it for prompt engineering as well.", "timestamp": "00:11:05,949", "timestamp_s": 665.0}, {"text": "work together to form a good prompt for your use case, and then go and test", "timestamp": "00:11:07,549", "timestamp_s": 667.0}, {"text": "that, and continue that iterative loop.", "timestamp": "00:11:11,149", "timestamp_s": 671.0}, {"text": "And there\u0027s a bunch of tools out there to do this.", "timestamp": "00:11:13,699", "timestamp_s": 673.0}, {"text": "We have one that we launched, and specifically, we will run a different,", "timestamp": "00:11:15,089", "timestamp_s": 675.0}, {"text": "Prompt to generate your prompt.", "timestamp": "00:11:19,979", "timestamp_s": 679.0}, {"text": "So that meta prompt based on whatever provider you\u0027re using, because as we", "timestamp": "00:11:21,269", "timestamp_s": 681.0}, {"text": "saw before, every provider is different.", "timestamp": "00:11:24,429", "timestamp_s": 684.0}, {"text": "So we\u0027ve baked in those differences into the meta prompt", "timestamp": "00:11:26,519", "timestamp_s": 686.0}, {"text": "for each one of the providers.", "timestamp": "00:11:28,579", "timestamp_s": 688.0}, {"text": "Leverages best practices.", "timestamp": "00:11:30,489", "timestamp_s": 690.0}, {"text": "It\u0027s free.", "timestamp": "00:11:31,569", "timestamp_s": 691.0}, {"text": "You can use it in our app without any account.", "timestamp": "00:11:32,129", "timestamp_s": 692.0}, {"text": "so that\u0027s good to go.", "timestamp": "00:11:33,989", "timestamp_s": 693.0}, {"text": "Anthropic was one of the first ones to do this, and I think they have a really great", "timestamp": "00:11:35,239", "timestamp_s": 695.0}, {"text": "grasp on prompt engineering in general.", "timestamp": "00:11:39,129", "timestamp_s": 699.0}, {"text": "So you can use this in the Anthropic console.", "timestamp": "00:11:41,229", "timestamp_s": 701.0}, {"text": "A bunch of best practices built in.", "timestamp": "00:11:42,934", "timestamp_s": 702.0}, {"text": "It\u0027s open source.", "timestamp": "00:11:44,394", "timestamp_s": 704.0}, {"text": "it does charge.", "timestamp": "00:11:45,324", "timestamp_s": 705.0}, {"text": "that\u0027s nominal.", "timestamp": "00:11:46,604", "timestamp_s": 706.0}, {"text": "And then OPI actually just released one, past month or so.", "timestamp": "00:11:48,314", "timestamp_s": 708.0}, {"text": "You can use it in the playground and it generates system messages only.", "timestamp": "00:11:51,604", "timestamp_s": 711.0}, {"text": "but it\u0027s still usable and fun.", "timestamp": "00:11:54,754", "timestamp_s": 714.0}, {"text": "And we did a little bit of prompt injections to get the prompt behind", "timestamp": "00:11:56,144", "timestamp_s": 716.0}, {"text": "that because it wasn\u0027t open source.", "timestamp": "00:12:00,404", "timestamp_s": 720.0}, {"text": "And so that was really cool to see.", "timestamp": "00:12:01,394", "timestamp_s": 721.0}, {"text": "It\u0027s always interesting to see how The model providers are writing prompts.", "timestamp": "00:12:02,844", "timestamp_s": 722.0}, {"text": "So that\u0027s available in prompt as well.", "timestamp": "00:12:07,024", "timestamp_s": 727.0}, {"text": "Wrapping up four things you can do today, structuring your prompts with headers,", "timestamp": "00:12:08,914", "timestamp_s": 728.0}, {"text": "delimiters, that\u0027s going to be a big help.", "timestamp": "00:12:11,714", "timestamp_s": 731.0}, {"text": "The more specific you are in your instructions, the", "timestamp": "00:12:14,734", "timestamp_s": 734.0}, {"text": "better your prompt will be.", "timestamp": "00:12:16,724", "timestamp_s": 736.0}, {"text": "You can throw out all the other methods.", "timestamp": "00:12:18,044", "timestamp_s": 738.0}, {"text": "if you can just nail that part, that\u0027s great.", "timestamp": "00:12:19,504", "timestamp_s": 739.0}, {"text": "And if you don\u0027t nail it, all the other stuff really isn\u0027t going to help you.", "timestamp": "00:12:22,214", "timestamp_s": 742.0}, {"text": "Examples of VFU shop prompting is a great way.", "timestamp": "00:12:25,684", "timestamp_s": 745.0}, {"text": "I think metaprompting plus a few shot plus chain of thought is like really going", "timestamp": "00:12:28,229", "timestamp_s": 748.0}, {"text": "to be the winning formula going forward.", "timestamp": "00:12:31,879", "timestamp_s": 751.0}, {"text": "and then don\u0027t overly constrain the model.", "timestamp": "00:12:33,559", "timestamp_s": 753.0}, {"text": "And thank you.", "timestamp": "00:12:35,799", "timestamp_s": 755.0}, {"text": "I hope you enjoy this.", "timestamp": "00:12:36,339", "timestamp_s": 756.0}, {"text": "If you want to talk about this, feel free to reach out.", "timestamp": "00:12:37,349", "timestamp_s": 757.0}, {"text": "we\u0027re active on LinkedIn, and yeah, have a great rest of your day.", "timestamp": "00:12:40,009", "timestamp_s": 760.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'g84JA7Czshs',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Prompt Engineering Simplified
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Everything is going well until a prompt that usually works suddenly goes off the rails. Sound familiar? Prompts can be tricky, and models are non-deterministic, but with a few prompt engineering basics, you can regain control, improve consistency, and achieve more reliable outputs with AI.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/prompt2024_Dan_Cleary.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,100'); seek(0.0)">
              Hey everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:00,600'); seek(0.0)">
              How's it going?
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:01,510'); seek(1.0)">
              My name is Dan Cleary.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:03,200'); seek(3.0)">
              I'm the co founder of PromptHub and today we will be talking
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:06,000'); seek(6.0)">
              all about prompt engineering.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:07,970'); seek(7.0)">
              We'll talk about why prompt engineering, is it dead?
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:11,005'); seek(11.0)">
              system message versus prompt or user message, how different models
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:15,525'); seek(15.0)">
              require different types of prompt and prompting methods, a variety of
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:18,975'); seek(18.0)">
              different ways that you can try to get better outputs through prompt
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:21,964'); seek(21.0)">
              engineering methods, best practices.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:25,095'); seek(25.0)">
              Does persona prompting even work?
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:26,834'); seek(26.0)">
              Meta prompting and a whole bunch of templates and takeaways throughout.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:30,355'); seek(30.0)">
              So I like to start with this question of like, why prompt engineering?
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:34,035'); seek(34.0)">
              this was a pretty popular opinion.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:35,355'); seek(35.0)">
              I'd say early on that prompt engineering wasn't really a thing, but I think Over
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:39,510'); seek(39.0)">
              the months and years since ChatGPT came out, I think people have found that
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:43,300'); seek(43.0)">
              it actually can be quite hard to get the type of output that you're looking
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:46,350'); seek(46.0)">
              to get from a model consistently.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:00:48,210'); seek(48.0)">
              and that's where kind of prompt engineering comes into play.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:00:51,290'); seek(51.0)">
              And small changes just end up making a big difference here, because
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:00:54,669'); seek(54.0)">
              of how models latent space works.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:00:56,359'); seek(56.0)">
              So if you say, write a code to render this image.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:00:59,454'); seek(59.0)">
              write secure code as if you were John Carmack, which is
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:01,504'); seek(61.0)">
              like a famous software engineer.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:04,024'); seek(64.0)">
              You'll get drastically different outputs just by those small tweaks.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:07,494'); seek(67.0)">
              And I think that will always be there in some capacity.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:11,784'); seek(71.0)">
              you maybe have to do less of the engineering and method type work
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:16,544'); seek(76.0)">
              in the future, potentially, but I think there's always going to be
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:19,084'); seek(79.0)">
              a small place for this, at least.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:21,004'); seek(81.0)">
              Another reason why it's important is that it's one of the three major
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:23,684'); seek(83.0)">
              ways to get Better outputs from LLMs.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:26,344'); seek(86.0)">
              and it's the starting point.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:27,974'); seek(87.0)">
              So you do a bunch of prompt engineering, you see where you're at, what problems
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:01:31,034'); seek(91.0)">
              you're running into and whether you need to turn to other methods
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:01:34,404'); seek(94.0)">
              to solve those remaining problems.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:01:36,844'); seek(96.0)">
              It's just a starting point for a lot of teams and it's very accessible.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:01:40,279'); seek(100.0)">
              You can be technical, you can be non technical, and you can
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:01:42,579'); seek(102.0)">
              get your, up and running very quickly with prompt engineering.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:01:45,199'); seek(105.0)">
              And so lastly, you really can't avoid it.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:01:47,749'); seek(107.0)">
              And so for all those reasons, that's why I believe it's important, at
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:01:51,239'); seek(111.0)">
              least for the time being, and I think into the near future here.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:01:54,969'); seek(114.0)">
              And lastly, in the same way that having good UI UX product experience
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:01:59,979'); seek(119.0)">
              is a competitive advantage.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:01,339'); seek(121.0)">
              Having prompts that work well is a similarly important
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:04,599'); seek(124.0)">
              competitive advantage for AI teams.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:06,859'); seek(126.0)">
              So now we'll talk about the different types of messages that models can
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:11,014'); seek(131.0)">
              support, namely system versus user.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:02:14,024'); seek(134.0)">
              So system message, as you can see here, you are helpful assistant.
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:02:18,554'); seek(138.0)">
              Then we have a user message, which is like the prompt where you're
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:02:21,164'); seek(141.0)">
              sending to the model to get an output.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:02:23,014'); seek(143.0)">
              So on and so forth.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:02:24,364'); seek(144.0)">
              System message is optional.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:02:25,914'); seek(145.0)">
              Like when you're doing these things via the API.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:02:27,974'); seek(147.0)">
              so this is the stuff that you are, is behind chat GPT's interface in terms
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:02:33,014'); seek(153.0)">
              of what open AI has programmed, the.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:02:35,784'); seek(155.0)">
              Chatbot to sound like and think and so it's optional when
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:02:38,614'); seek(158.0)">
              you're sending it via the API.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:02:39,364'); seek(159.0)">
              It's used to set context and rules, so just the higher level things
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:02:43,274'); seek(163.0)">
              versus low level instructions.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:02:45,254'); seek(165.0)">
              So setting the role, context, guiding the model behavior, controlling
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:02:49,024'); seek(169.0)">
              format, things like that, versus the prompt is where you get more
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:02:51,974'); seek(171.0)">
              specific, more of the contextual info.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:02:54,429'); seek(174.0)">
              The focus, so on and so forth.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:02:56,369'); seek(176.0)">
              And we have a couple of examples in the wild here from companies like OpenAI.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:03:01,689'); seek(181.0)">
              Anthropic also published theirs, on their documentation.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:03:04,929'); seek(184.0)">
              So you could see the system messages that power their Claude, chatbots.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:03:08,529'); seek(188.0)">
              And so now we'll talk about how different models require different prompts.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:03:11,769'); seek(191.0)">
              So if you're interchanging between providers and even models within the
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:03:16,299'); seek(196.0)">
              same provider, you've probably run into this experience where each of
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:03:18,889'); seek(198.0)">
              them has their own differences in the way they handle tasks and the
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:03:22,049'); seek(202.0)">
              way that they sound and respond.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:03:24,064'); seek(204.0)">
              so for example, we'll take a chain of thought.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:03:26,544'); seek(206.0)">
              so this is thinking step by step, prompting the model to do some
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:03:30,124'); seek(210.0)">
              reasoning before giving an output.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:03:33,094'); seek(213.0)">
              There's an experiment ran where they found that chain of thought actually reduced
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:03:37,674'); seek(217.0)">
              the performance of Palm two, which is, an older Google model at this point, but just
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:03:42,744'); seek(222.0)">
              goes to show that doing what is considered a best practice didn't help performance.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:03:47,864'); seek(227.0)">
              In this case, it actually made things worse.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:03:50,224'); seek(230.0)">
              And That just goes to show that one size is really not going to fit all, which is
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:03:53,784'); seek(233.0)">
              the second paper we'll talk about, which is from VMware, where they basically
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:03:58,044'); seek(238.0)">
              tested a wide variety of different prompt openers, descriptions, and closers.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:04:03,514'); seek(243.0)">
              They put all these prompts together using all of these different parts here.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:04:07,384'); seek(247.0)">
              Here are a couple examples of a math dataset with the
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:04:10,694'); seek(250.0)">
              various system messages here.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:04:13,294'); seek(253.0)">
              Some have a role, some don't, so on and so forth.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:04:16,734'); seek(256.0)">
              And what they did was they had the model generate the best prompt.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:04:22,614'); seek(262.0)">
              for that specific task.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:04:24,294'); seek(264.0)">
              And so they, they let the model decide and do its own metaprompting based
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:04:27,524'); seek(267.0)">
              on the task and the outputs that it was receiving and so on and so forth.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:04:31,474'); seek(271.0)">
              This was what Llama 2 created and you could see, it's including kind
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:04:35,944'); seek(275.0)">
              of some Star Trek language here.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:04:38,104'); seek(278.0)">
              So this is after running hundreds of prompts, doing hundreds of metaprompting
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:04:40,934'); seek(280.0)">
              in like an experimental way.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:04:42,639'); seek(282.0)">
              setting where there is, a high degree of statistical significance.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:04:48,199'); seek(288.0)">
              Versus Llama 2, 13b, so same family, same provider, doesn't know
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:04:52,419'); seek(292.0)">
              mention of any Star Trek things, like it's all very cut and dry.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:04:56,249'); seek(296.0)">
              And then this was pretty popular last year, this kind of take a deep breath
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:04:59,099'); seek(299.0)">
              and work on this problem step by step.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:05:00,529'); seek(300.0)">
              This was a similar experiment where they had the model figure out a top instruction
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:05:05,539'); seek(305.0)">
              for itself, and they ran a bunch of tests to see which one goes to the top here.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:05:09,059'); seek(309.0)">
              And so they were, this is the top instruction for the A variety
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:05:11,539'); seek(311.0)">
              of different models here, and we can see GPT's fours is You know,
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:05:16,219'); seek(316.0)">
              five times larger than palm twos.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:05:18,439'); seek(318.0)">
              And so it just goes to show that everything is going to be a little
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:05:22,179'); seek(322.0)">
              bit different depending on the model.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:05:23,529'); seek(323.0)">
              And that's why it's important to test these things.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:05:25,689'); seek(325.0)">
              And if you're looking for more information on models like max tokens,
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:05:29,929'); seek(329.0)">
              context, windows, costs, features, and functionalities, we have a, directory
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:05:33,709'); seek(333.0)">
              that we just launched that has all the information for basically all the model
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:05:36,299'); seek(336.0)">
              providers that are the most popular.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:05:38,049'); seek(338.0)">
              All right So moving on to My two favorite prompt engineering practices and the
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:05:42,309'); seek(342.0)">
              one that we tell the teams that we work with to focus on is you know giving the
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:05:46,509'); seek(346.0)">
              model room to think this is a popular one and kind of relays into Chain of
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:05:51,239'); seek(351.0)">
              thought to a degree you want to let the model think you don't want to force it
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:05:54,759'); seek(354.0)">
              to give an answer Or overly constrain it.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:05:57,819'); seek(357.0)">
              You want it to go through some sort of reasoning process and
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:06:00,779'); seek(360.0)">
              come to an answer on its own.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:06:02,229'); seek(362.0)">
              And then using delimiters or some way to better structure your prompt.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:06:05,419'); seek(365.0)">
              I can't tell you how many times I've had a team say, Hey, we're
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:06:08,029'); seek(368.0)">
              struggling with this prompt.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:06:08,819'); seek(368.0)">
              Can you look at it?
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:06:09,429'); seek(369.0)">
              I look at it and I can't even.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:06:10,919'); seek(370.0)">
              See what's going on.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:06:12,179'); seek(372.0)">
              And so that's a good litmus test is have someone else look at your
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:06:14,529'); seek(374.0)">
              prompts, see if they can organize it or understand your organization.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:06:18,219'); seek(378.0)">
              And if not start to provide some of that via, delimiters, backticks,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:06:23,219'); seek(383.0)">
              quotes, whatever is going to help structure the prompt better.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:06:27,029'); seek(387.0)">
              Now we'll look at a few.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:06:29,129'); seek(389.0)">
              So just to set the stage, a zero shot prompt is just a normal prompt.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:06:33,409'); seek(393.0)">
              So if you hear that ever referenced, it's basically just a typical prompt like this.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:06:37,699'); seek(397.0)">
              A few shot prompt is when you include examples inside of your prompt.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:06:41,669'); seek(401.0)">
              So this would be all one prompt sent, but we're going to say,
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:06:44,869'); seek(404.0)">
              show It's examples in line.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:06:47,034'); seek(407.0)">
              So we're classifying the sentiment of this feedback.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:06:49,754'); seek(409.0)">
              So this person's positive, then negative, then positive.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:06:52,384'); seek(412.0)">
              And then we're going to let the model kind of fill in the, the blank here.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:06:55,804'); seek(415.0)">
              And you could do this via multiple messages.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:06:59,204'); seek(419.0)">
              So like sending an array of messages from the API.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:07:01,384'); seek(421.0)">
              And that's typically, I think, technically what few shop really is rather than
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:07:05,124'); seek(425.0)">
              having it all be in one message.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:07:07,474'); seek(427.0)">
              Because the model will handle it different if it has it in its history
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:07:10,184'); seek(430.0)">
              versus reading it all in a prompt.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:07:11,874'); seek(431.0)">
              Both ways are effective.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:07:13,074'); seek(433.0)">
              Both ways are worth testing.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:07:14,664'); seek(434.0)">
              SureShot Prompting is really helpful in a variety of domains.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:07:18,084'); seek(438.0)">
              It can help with structure.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:07:20,619'); seek(440.0)">
              format, content, style, and tone, and those are really the really big
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:07:26,199'); seek(446.0)">
              areas that I've seen it be helpful.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:07:28,079'); seek(448.0)">
              How many examples?
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:07:29,079'); seek(449.0)">
              The great benefit here is that you get a lot of the gains from
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:07:32,929'); seek(452.0)">
              just having one or two examples.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:07:36,019'); seek(456.0)">
              And then it plateaus and can even degrade in a lot of situations.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:07:38,779'); seek(458.0)">
              we say, hey, start with, Anywhere from two to five examples, if you're still
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:07:42,424'); seek(462.0)">
              not getting the performance you're looking for, you might need to look
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:07:44,624'); seek(464.0)">
              elsewhere because you have the chance of it starting to degrade, the performance.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:07:49,154'); seek(469.0)">
              A couple of other important, best practices here.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:07:51,664'); seek(471.0)">
              Use diverse examples.
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:07:53,324'); seek(473.0)">
              So if you're doing a sentiment analysis, don't use only positive ones.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:07:56,684'); seek(476.0)">
              Use a combination.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:07:57,744'); seek(477.0)">
              Have them cover a wide range of what you are going to be
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:08:00,434'); seek(480.0)">
              expecting in your application.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:08:02,304'); seek(482.0)">
              So cover those edge cases.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:08:04,074'); seek(484.0)">
              Random, randomly order them so you wouldn't have all the positives in one
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:08:07,064'); seek(487.0)">
              section and then all the negatives.
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:08:08,604'); seek(488.0)">
              And then make sure they follow a common format so the model can
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:08:11,424'); seek(491.0)">
              better learn, in context there.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:08:14,094'); seek(494.0)">
              And we have a whole guide on this as well, with lots of examples and templates.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:08:17,454'); seek(497.0)">
              Alright, next up is according to prompting, which is basically
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:08:19,914'); seek(499.0)">
              just trying to ground the model in a specific set of information.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:08:25,184'); seek(505.0)">
              so you can see in this original prompt, it's asking a question, and then it just
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:08:28,814'); seek(508.0)">
              has, adds in according to Wikipedia.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:08:31,894'); seek(511.0)">
              So it's trying to guide the model to the type of answer that you are looking for.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:08:36,254'); seek(516.0)">
              are looking to.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:08:36,784'); seek(516.0)">
              And this can be helpful, especially if you've done like some fine tuning.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:08:40,154'); seek(520.0)">
              And here's an example of that.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:08:41,254'); seek(521.0)">
              Again, all the templates are available in PromptTab under
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:08:44,394'); seek(524.0)">
              the templates tab for free too.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:08:46,394'); seek(526.0)">
              And then last one I believe is called step back prompting.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:08:48,724'); seek(528.0)">
              So this is a very similar kind of, I say, variant of chain of thought prompting,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:08:53,324'); seek(533.0)">
              where you send a question, you have the model kind of think step by step
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:08:56,774'); seek(536.0)">
              in first kind of abstract concepts, and then Use those abstractions to reason
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:09:03,474'); seek(543.0)">
              through the question or the task.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:09:05,044'); seek(545.0)">
              And so you prompted to do this thinking first, and this is what you see with a
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:09:08,294'); seek(548.0)">
              one preview and a one mini where it thinks about the step that reasons about them.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:09:12,734'); seek(552.0)">
              And then it solves the problem.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:09:14,804'); seek(554.0)">
              So again, yeah, these are all linked in prompt up.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:09:17,824'); seek(557.0)">
              So app dot prompt dot U S slash templates.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:09:21,744'); seek(561.0)">
              Last up.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:09:22,224'); seek(562.0)">
              And my favorite one is persona prompting.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:09:25,234'); seek(565.0)">
              So this is like very popular for a long time now.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:09:28,454'); seek(568.0)">
              so this is like giving the.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:09:30,759'); seek(570.0)">
              the model, a persona to solve a certain task.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:09:33,539'); seek(573.0)">
              And there are a lot of papers on both sides of this in
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:09:37,839'); seek(577.0)">
              terms of how effective it is.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:09:39,639'); seek(579.0)">
              I have come out to the other side to thinking it's actually not that
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:09:42,669'); seek(582.0)">
              effective in certain use cases.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:09:44,059'); seek(584.0)">
              And the main reason comes from a learn prompting.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:09:48,239'); seek(588.0)">
              org paper, which is linked here.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:09:50,549'); seek(590.0)">
              I had this intuition that it wasn't great for doing accuracy based tasks,
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:09:55,969'); seek(595.0)">
              and this really reinforced that.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:09:57,994'); seek(597.0)">
              So basically they set up an experiment.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:10:00,134'); seek(600.0)">
              They ran 2000 prompts, and it was a MMLU case, so like a knowledge based, task, and
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:10:08,014'); seek(608.0)">
              they gave a bunch of different roles here.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:10:10,434'); seek(610.0)">
              And really the kind of long and short of it is that.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:10:12,759'); seek(612.0)">
              The genius when they were told the model, it was a genius.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:10:15,589'); seek(615.0)">
              It got a lower percentage than when it told it, it was like an
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:10:17,829'); seek(617.0)">
              idiot or something like that.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:10:18,969'); seek(618.0)">
              Yeah.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:10:19,609'); seek(619.0)">
              The genius was actually the worst performing one here.
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:10:21,489'); seek(621.0)">
              And so how can you reconcile that and still think that role prompting works?
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:10:26,579'); seek(626.0)">
              I don't know.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:10:27,329'); seek(627.0)">
              we have to look at other data, but this seems just pretty strong to rule out
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:10:30,569'); seek(630.0)">
              that conclusion and everything else.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:10:31,959'); seek(631.0)">
              I would say it may just be anecdotal, but it is helpful in terms of,
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:10:35,979'); seek(635.0)">
              I would say, Tone and style.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:10:38,049'); seek(638.0)">
              So if you're doing content generation, things like that, but not for increasing
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:10:42,229'); seek(642.0)">
              accuracy, last up, we'll talk a little bit about meta prompting.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:10:45,639'); seek(645.0)">
              So what's meta prompting.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:10:47,299'); seek(647.0)">
              It's a prompt engineering method that uses the LLM to help you write your prompt.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:10:50,729'); seek(650.0)">
              So using chat GPT to help write your prompt.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:10:53,329'); seek(653.0)">
              And we are big proponents of this.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:10:55,959'); seek(655.0)">
              We think this is how prompt engineering should really be done alongside
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:10:59,979'); seek(659.0)">
              the model that you're working with.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:11:01,599'); seek(661.0)">
              And the same way they use, AI and LLMs for writing and coding, you should
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:11:05,949'); seek(665.0)">
              do it for prompt engineering as well.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:11:07,549'); seek(667.0)">
              work together to form a good prompt for your use case, and then go and test
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:11:11,149'); seek(671.0)">
              that, and continue that iterative loop.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:11:13,699'); seek(673.0)">
              And there's a bunch of tools out there to do this.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:11:15,089'); seek(675.0)">
              We have one that we launched, and specifically, we will run a different,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:11:19,979'); seek(679.0)">
              Prompt to generate your prompt.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:11:21,269'); seek(681.0)">
              So that meta prompt based on whatever provider you're using, because as we
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:11:24,429'); seek(684.0)">
              saw before, every provider is different.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:11:26,519'); seek(686.0)">
              So we've baked in those differences into the meta prompt
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:11:28,579'); seek(688.0)">
              for each one of the providers.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:11:30,489'); seek(690.0)">
              Leverages best practices.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:11:31,569'); seek(691.0)">
              It's free.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:11:32,129'); seek(692.0)">
              You can use it in our app without any account.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:11:33,989'); seek(693.0)">
              so that's good to go.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:11:35,239'); seek(695.0)">
              Anthropic was one of the first ones to do this, and I think they have a really great
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:11:39,129'); seek(699.0)">
              grasp on prompt engineering in general.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:11:41,229'); seek(701.0)">
              So you can use this in the Anthropic console.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:11:42,934'); seek(702.0)">
              A bunch of best practices built in.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:11:44,394'); seek(704.0)">
              It's open source.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:11:45,324'); seek(705.0)">
              it does charge.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:11:46,604'); seek(706.0)">
              that's nominal.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:11:48,314'); seek(708.0)">
              And then OPI actually just released one, past month or so.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:11:51,604'); seek(711.0)">
              You can use it in the playground and it generates system messages only.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:11:54,754'); seek(714.0)">
              but it's still usable and fun.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:11:56,144'); seek(716.0)">
              And we did a little bit of prompt injections to get the prompt behind
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:12:00,404'); seek(720.0)">
              that because it wasn't open source.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:12:01,394'); seek(721.0)">
              And so that was really cool to see.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:12:02,844'); seek(722.0)">
              It's always interesting to see how The model providers are writing prompts.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:12:07,024'); seek(727.0)">
              So that's available in prompt as well.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:12:08,914'); seek(728.0)">
              Wrapping up four things you can do today, structuring your prompts with headers,
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:12:11,714'); seek(731.0)">
              delimiters, that's going to be a big help.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:12:14,734'); seek(734.0)">
              The more specific you are in your instructions, the
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:12:16,724'); seek(736.0)">
              better your prompt will be.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:12:18,044'); seek(738.0)">
              You can throw out all the other methods.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:12:19,504'); seek(739.0)">
              if you can just nail that part, that's great.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:12:22,214'); seek(742.0)">
              And if you don't nail it, all the other stuff really isn't going to help you.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:12:25,684'); seek(745.0)">
              Examples of VFU shop prompting is a great way.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:12:28,229'); seek(748.0)">
              I think metaprompting plus a few shot plus chain of thought is like really going
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:12:31,879'); seek(751.0)">
              to be the winning formula going forward.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:12:33,559'); seek(753.0)">
              and then don't overly constrain the model.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:12:35,799'); seek(755.0)">
              And thank you.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:12:36,339'); seek(756.0)">
              I hope you enjoy this.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:12:37,349'); seek(757.0)">
              If you want to talk about this, feel free to reach out.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:12:40,009'); seek(760.0)">
              we're active on LinkedIn, and yeah, have a great rest of your day.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Dan%20Cleary%20-%20Conf42%20Prompt%20Engineering%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Dan%20Cleary%20-%20Conf42%20Prompt%20Engineering%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #749BC2;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #749BC2;">
                <i class="fe fe-grid me-2"></i>
                See all 40 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Dan%20Cleary_prompt.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Dan Cleary
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Co-founder @ PromptHub
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/dan-cleary-06b754123/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Dan Cleary's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Dan Cleary"
                  data-url="https://www.conf42.com/prompt2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/prompt2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Prompt Engineering"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>