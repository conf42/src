<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: From idea to production: Automate your machine learning workflows with pipelines</title>
    <meta name="description" content="Like the Machines need our help to take over the world">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/ml_antje.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="From idea to production: Automate your machine learning workflows with pipelines | Conf42"/>
    <meta property="og:description" content="Developing high-quality machine learning models involve many steps. We typically start with exploring and preparing our data. We experiment with different algorithms and parameters. We spend time training and tuning our model until the model meets our quality metrics, and is ready to be deployed into production. Orchestrating and automating workflows across each step of this model development process can take months of coding.  In this session, I show you how to create, automate, and manage machine learning workflows using Amazon SageMaker Pipelines. We will create a reusable NLP model training pipeline to prepare data, store the features in a feature store, fine-tune a BERT model, and deploy the model into production if it passes our defined quality metrics. "/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2021_Antje_Barth_Automate_workflows_pipelines"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/INCIDENT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Incident Management 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-10-17
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/im2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2021 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2021-07-29">July 29 2021</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Like the Machines need our help to take over the world
 -->
              <script>
                const event_date = new Date("2021-07-29T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2021-07-29T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "dTP4J0GcXxg"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "h6kzwaBwrCY"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrD02X7IKNNxFMy_K8oEejAu" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Welcome. In this session I will discuss as", "timestamp": "00:00:22,250", "timestamp_s": 22.0}, {"text": "how you can take your data science and machine learning projects", "timestamp": "00:00:25,484", "timestamp_s": 25.0}, {"text": "from idea to production by automating your machine", "timestamp": "00:00:29,298", "timestamp_s": 29.0}, {"text": "learning workflows with pipelines.", "timestamp": "00:00:32,658", "timestamp_s": 32.0}, {"text": "Before I start, I want to point out two great learning resources", "timestamp": "00:00:35,770", "timestamp_s": 35.0}, {"text": "to follow up on this topic after today\u0027s session.", "timestamp": "00:00:39,986", "timestamp_s": 39.0}, {"text": "Besides working as a developer advocate, I\u0027m also an O\u0027Reilly author", "timestamp": "00:00:43,690", "timestamp_s": 43.0}, {"text": "and coursera instructor. The O\u0027Reilly book data", "timestamp": "00:00:47,506", "timestamp_s": 47.0}, {"text": "Science on AWS, which I coauthored, discusses in", "timestamp": "00:00:51,236", "timestamp_s": 51.0}, {"text": "over 500 pages and hundreds of code samples", "timestamp": "00:00:54,932", "timestamp_s": 54.0}, {"text": "how to implement endtoend, continuous AI and machine learning", "timestamp": "00:00:58,298", "timestamp_s": 58.0}, {"text": "pipelines. Another great resource is the newly", "timestamp": "00:01:01,796", "timestamp_s": 61.0}, {"text": "launched practical data science specialization.", "timestamp": "00:01:05,838", "timestamp_s": 65.0}, {"text": "In partnership with deep Learning AI and Casera,", "timestamp": "00:01:09,038", "timestamp_s": 69.0}, {"text": "this three core specialization teaches you practical", "timestamp": "00:01:13,190", "timestamp_s": 73.0}, {"text": "skills in how to take your data science and ML projects", "timestamp": "00:01:16,546", "timestamp_s": 76.0}, {"text": "from idea to production using purpose build tools in", "timestamp": "00:01:20,162", "timestamp_s": 80.0}, {"text": "the AWS cloud, and it also includes on demand,", "timestamp": "00:01:24,108", "timestamp_s": 84.0}, {"text": "hands on labs for you to practice.", "timestamp": "00:01:28,246", "timestamp_s": 88.0}, {"text": "So we\u0027re talking about automating machine learning.", "timestamp": "00:01:32,670", "timestamp_s": 92.0}, {"text": "Hmm. I have an idea.", "timestamp": "00:01:36,910", "timestamp_s": 96.0}, {"text": "Alexa deploy my model.", "timestamp": "00:01:41,490", "timestamp_s": 101.0}, {"text": "Which multi armed bandit strategy would you like to use?", "timestamp": "00:01:45,650", "timestamp_s": 105.0}, {"text": "Thompson sampling Epsilon Greedy or online cover?", "timestamp": "00:01:49,140", "timestamp_s": 109.0}, {"text": "Well, I\u0027m pretty sure someone already thought about developing", "timestamp": "00:01:54,710", "timestamp_s": 114.0}, {"text": "this Alexa skill, but unfortunately,", "timestamp": "00:01:58,318", "timestamp_s": 118.0}, {"text": "getting your machine learning projects ready for production is", "timestamp": "00:02:01,662", "timestamp_s": 121.0}, {"text": "not just about technology. A term you", "timestamp": "00:02:05,228", "timestamp_s": 125.0}, {"text": "will likely hear in this context of getting your ML applications", "timestamp": "00:02:09,388", "timestamp_s": 129.0}, {"text": "ready for production is mlops.", "timestamp": "00:02:12,722", "timestamp_s": 132.0}, {"text": "MLOPs builds on DevOps practices that encompasses", "timestamp": "00:02:16,170", "timestamp_s": 136.0}, {"text": "people, process and technology.", "timestamp": "00:02:20,214", "timestamp_s": 140.0}, {"text": "However, MLOPs also includes considerations", "timestamp": "00:02:23,710", "timestamp_s": 143.0}, {"text": "and practices that are really unique to machine learning", "timestamp": "00:02:27,478", "timestamp_s": 147.0}, {"text": "workflows. So while most of the time we", "timestamp": "00:02:31,280", "timestamp_s": 151.0}, {"text": "tend to focus on the technology, people and process", "timestamp": "00:02:35,012", "timestamp_s": 155.0}, {"text": "are equally, if not more important.", "timestamp": "00:02:38,868", "timestamp_s": 158.0}, {"text": "Let\u0027s take a look at a few key considerations in ensuring", "timestamp": "00:02:42,390", "timestamp_s": 162.0}, {"text": "your models and machine learning workloads have", "timestamp": "00:02:46,510", "timestamp_s": 166.0}, {"text": "a path to production.", "timestamp": "00:02:49,752", "timestamp_s": 169.0}, {"text": "First of all, the machine learning development lifecycle is very", "timestamp": "00:02:53,750", "timestamp_s": 173.0}, {"text": "different from a software development lifecycle.", "timestamp": "00:02:57,580", "timestamp_s": 177.0}, {"text": "For example, model development includes longer experimentation", "timestamp": "00:03:01,290", "timestamp_s": 181.0}, {"text": "cycles compared to what you would typically see", "timestamp": "00:03:05,362", "timestamp_s": 185.0}, {"text": "in an agile software development process.", "timestamp": "00:03:08,688", "timestamp_s": 188.0}, {"text": "You need to consider choosing the right data meets,", "timestamp": "00:03:12,350", "timestamp_s": 192.0}, {"text": "perform data transformations, and feature engineering.", "timestamp": "00:03:15,382", "timestamp_s": 195.0}, {"text": "So besides the actual model training code, you also", "timestamp": "00:03:19,890", "timestamp_s": 199.0}, {"text": "need to develop the data processing code.", "timestamp": "00:03:23,556", "timestamp_s": 203.0}, {"text": "Next. The model is typically only a small part", "timestamp": "00:03:27,570", "timestamp_s": 207.0}, {"text": "of an overall machine learning solution, and there are often", "timestamp": "00:03:31,140", "timestamp_s": 211.0}, {"text": "more components that need to be built or integrated.", "timestamp": "00:03:34,760", "timestamp_s": 214.0}, {"text": "For example, maybe the model needs to be integrated into an existing", "timestamp": "00:03:39,110", "timestamp_s": 219.0}, {"text": "application to trigger further process developing on", "timestamp": "00:03:43,262", "timestamp_s": 223.0}, {"text": "production results. This leads to the next", "timestamp": "00:03:46,988", "timestamp_s": 226.0}, {"text": "consideration.", "timestamp": "00:03:50,492", "timestamp_s": 230.0}, {"text": "There are typically multiple personas involved in the", "timestamp": "00:03:53,930", "timestamp_s": 233.0}, {"text": "machine learning development lifecycle, often with competing needs and", "timestamp": "00:03:57,532", "timestamp_s": 237.0}, {"text": "priorities. A data scientist might feel comfortable", "timestamp": "00:04:01,776", "timestamp_s": 241.0}, {"text": "in building a models that meets the expected", "timestamp": "00:04:06,246", "timestamp_s": 246.0}, {"text": "model performance metrics, but might not know how", "timestamp": "00:04:09,382", "timestamp_s": 249.0}, {"text": "to host that model in a way that it can be consumed", "timestamp": "00:04:13,172", "timestamp_s": 253.0}, {"text": "by another system or application.", "timestamp": "00:04:16,458", "timestamp_s": 256.0}, {"text": "This part might require a DevOps engineer or the infrastructure", "timestamp": "00:04:19,570", "timestamp_s": 259.0}, {"text": "team. You also need to integrate", "timestamp": "00:04:23,742", "timestamp_s": 263.0}, {"text": "the projects with existing it systems and", "timestamp": "00:04:27,342", "timestamp_s": 267.0}, {"text": "practices, such as change management,", "timestamp": "00:04:30,808", "timestamp_s": 270.0}, {"text": "for example. This could mean that as part of", "timestamp": "00:04:34,550", "timestamp_s": 274.0}, {"text": "the pipelines, you automatically open a change ticket", "timestamp": "00:04:38,476", "timestamp_s": 278.0}, {"text": "anytime a new model is ready to get deployed", "timestamp": "00:04:42,970", "timestamp_s": 282.0}, {"text": "into production. Or you might want to", "timestamp": "00:04:46,706", "timestamp_s": 286.0}, {"text": "add a manual approval steps in your pipeline before deploying", "timestamp": "00:04:50,208", "timestamp_s": 290.0}, {"text": "any model into your production.", "timestamp": "00:04:54,182", "timestamp_s": 294.0}, {"text": "If we look at the goal of mlops, you want to move away", "timestamp": "00:04:57,710", "timestamp_s": 297.0}, {"text": "from manually building models, which is often still", "timestamp": "00:05:01,204", "timestamp_s": 301.0}, {"text": "the status quo. In the first phase,", "timestamp": "00:05:04,532", "timestamp_s": 304.0}, {"text": "you can accelerate the path to production by instead of building and", "timestamp": "00:05:08,458", "timestamp_s": 308.0}, {"text": "managing individual models, start building and managing", "timestamp": "00:05:12,452", "timestamp_s": 312.0}, {"text": "pipelines. You also want", "timestamp": "00:05:16,206", "timestamp_s": 316.0}, {"text": "to improve the quality of deployed models. To do", "timestamp": "00:05:19,608", "timestamp_s": 319.0}, {"text": "this, you need to be able to detect model decay,", "timestamp": "00:05:23,432", "timestamp_s": 323.0}, {"text": "maybe due to a drift in the statistical changes in", "timestamp": "00:05:27,530", "timestamp_s": 327.0}, {"text": "data distributions. You should also monitor", "timestamp": "00:05:30,892", "timestamp_s": 330.0}, {"text": "the models for any drifts in bias or explainability", "timestamp": "00:05:34,802", "timestamp_s": 334.0}, {"text": "from a set baseline. This can be accomplished", "timestamp": "00:05:38,678", "timestamp_s": 338.0}, {"text": "in a second phase, and ultimately", "timestamp": "00:05:42,726", "timestamp_s": 342.0}, {"text": "this should lead into building AI ML solutions", "timestamp": "00:05:48,110", "timestamp_s": 348.0}, {"text": "that are resilient, secure, performant,", "timestamp": "00:05:51,770", "timestamp_s": 351.0}, {"text": "operationally efficient, and cost optimized.", "timestamp": "00:05:55,130", "timestamp_s": 355.0}, {"text": "Let\u0027s have a close look at each phase.", "timestamp": "00:05:59,730", "timestamp_s": 359.0}, {"text": "Today we often still manually build and manage individual", "timestamp": "00:06:04,310", "timestamp_s": 364.0}, {"text": "models. We also execute", "timestamp": "00:06:08,488", "timestamp_s": 368.0}, {"text": "each step in the model development workflow individually.", "timestamp": "00:06:11,902", "timestamp_s": 371.0}, {"text": "Here is an example workflow where a data engineer may create", "timestamp": "00:06:16,090", "timestamp_s": 376.0}, {"text": "a raw data set and manually send it to a data scientist.", "timestamp": "00:06:19,996", "timestamp_s": 379.0}, {"text": "Then the data scientist iteratively performs", "timestamp": "00:06:25,130", "timestamp_s": 385.0}, {"text": "data preparation and features. Engineering performs", "timestamp": "00:06:29,126", "timestamp_s": 389.0}, {"text": "multiple experiments until a training model", "timestamp": "00:06:33,382", "timestamp_s": 393.0}, {"text": "is actually performing well according to the objective", "timestamp": "00:06:36,736", "timestamp_s": 396.0}, {"text": "metrics. Then the data scientist", "timestamp": "00:06:40,118", "timestamp_s": 400.0}, {"text": "may hand it off to a deployment team or an", "timestamp": "00:06:44,170", "timestamp_s": 404.0}, {"text": "ML engineer who is then responsible for deploying the model.", "timestamp": "00:06:47,332", "timestamp_s": 407.0}, {"text": "If there has been limited communication between teams,", "timestamp": "00:06:52,690", "timestamp_s": 412.0}, {"text": "this part could result in a lot of delays because the model is", "timestamp": "00:06:56,430", "timestamp_s": 416.0}, {"text": "essentially intransparent to the deployment engineer or", "timestamp": "00:07:00,312", "timestamp_s": 420.0}, {"text": "the DevOps team, meaning there is limited visibility into", "timestamp": "00:07:03,768", "timestamp_s": 423.0}, {"text": "how the model is built or how you consume that model.", "timestamp": "00:07:07,868", "timestamp_s": 427.0}, {"text": "Then a software engineer potentially needs to make", "timestamp": "00:07:12,490", "timestamp_s": 432.0}, {"text": "changes to the application, which consumes that", "timestamp": "00:07:16,412", "timestamp_s": 436.0}, {"text": "model for prediction. And finally,", "timestamp": "00:07:19,888", "timestamp_s": 439.0}, {"text": "someone ultimately needs to operate the model in production,", "timestamp": "00:07:23,440", "timestamp_s": 443.0}, {"text": "which includes making sure the right level of monitoring is", "timestamp": "00:07:26,934", "timestamp_s": 446.0}, {"text": "set up. We can see the challenges", "timestamp": "00:07:30,852", "timestamp_s": 450.0}, {"text": "in this setup. The workflows includes multiple handoffs", "timestamp": "00:07:34,906", "timestamp_s": 454.0}, {"text": "between teams and personas who might not", "timestamp": "00:07:38,698", "timestamp_s": 458.0}, {"text": "all be familiar with machine learning workloads.", "timestamp": "00:07:42,052", "timestamp_s": 462.0}, {"text": "A limited cross team collaboration could lead to limited visibility", "timestamp": "00:07:45,910", "timestamp_s": 465.0}, {"text": "and transparency using increased code", "timestamp": "00:07:50,190", "timestamp_s": 470.0}, {"text": "rework, and ultimately slows down the ability to", "timestamp": "00:07:53,928", "timestamp_s": 473.0}, {"text": "get the model to production quickly. So what", "timestamp": "00:07:57,772", "timestamp_s": 477.0}, {"text": "can we do in a first", "timestamp": "00:08:01,452", "timestamp_s": 481.0}, {"text": "phase, we should improve the situation by orchestrating", "timestamp": "00:08:04,940", "timestamp_s": 484.0}, {"text": "the individual steps. As a pipeline,", "timestamp": "00:08:08,646", "timestamp_s": 488.0}, {"text": "we can also look at automating tasks in each", "timestamp": "00:08:12,270", "timestamp_s": 492.0}, {"text": "step. For example,", "timestamp": "00:08:15,456", "timestamp_s": 495.0}, {"text": "we can build a model training pipeline that orchestrating", "timestamp": "00:08:19,344", "timestamp_s": 499.0}, {"text": "the data preparation, model training, and model evaluation", "timestamp": "00:08:23,162", "timestamp_s": 503.0}, {"text": "steps. We could also build a deployed", "timestamp": "00:08:27,210", "timestamp_s": 507.0}, {"text": "pipeline which grabs a model from a model registry and", "timestamp": "00:08:31,306", "timestamp_s": 511.0}, {"text": "deploys it into a staging environment.", "timestamp": "00:08:35,176", "timestamp_s": 515.0}, {"text": "The software engineers could then use this model to", "timestamp": "00:08:38,630", "timestamp_s": 518.0}, {"text": "run unit or integration tests before approving", "timestamp": "00:08:42,168", "timestamp_s": 522.0}, {"text": "the model for production deployment.", "timestamp": "00:08:45,538", "timestamp_s": 525.0}, {"text": "Let\u0027s see a demo of a model training pipeline.", "timestamp": "00:08:49,610", "timestamp_s": 529.0}, {"text": "All right, here I am in my AWS demo account,", "timestamp": "00:08:54,090", "timestamp_s": 534.0}, {"text": "and I want to show you how you can leverage Amazon Sagemaker", "timestamp": "00:08:58,430", "timestamp_s": 538.0}, {"text": "pipelines to automate the individual steps", "timestamp": "00:09:02,502", "timestamp_s": 542.0}, {"text": "of building a machine learning model. Amazon Sagemaker is", "timestamp": "00:09:05,766", "timestamp_s": 545.0}, {"text": "a fully managed service that helps you build, train,", "timestamp": "00:09:09,632", "timestamp_s": 549.0}, {"text": "tune, and deploy your machine learning models.", "timestamp": "00:09:13,044", "timestamp_s": 553.0}, {"text": "All right, so the use case we\u0027re going to build is", "timestamp": "00:09:17,090", "timestamp_s": 557.0}, {"text": "I want to train a natural language process model to", "timestamp": "00:09:21,170", "timestamp_s": 561.0}, {"text": "classify product reviews. So I\u0027m going to pass in", "timestamp": "00:09:25,576", "timestamp_s": 565.0}, {"text": "raw text product review text. For example,", "timestamp": "00:09:29,192", "timestamp_s": 569.0}, {"text": "I really enjoyed reading this book, and my NLP", "timestamp": "00:09:32,040", "timestamp_s": 572.0}, {"text": "model should classify this into a star rating. So in this case,", "timestamp": "00:09:36,302", "timestamp_s": 576.0}, {"text": "hopefully a star rating of a five the best, or a star", "timestamp": "00:09:40,188", "timestamp_s": 580.0}, {"text": "rating of 4321, with one being the worst.", "timestamp": "00:09:43,692", "timestamp_s": 583.0}, {"text": "And the way we\u0027re doing this, I\u0027m going to use a pretrained", "timestamp": "00:09:47,930", "timestamp_s": 587.0}, {"text": "bird model. Bird is a very popular model architecture in", "timestamp": "00:09:52,162", "timestamp_s": 592.0}, {"text": "the NLP states, and what you can leverage is actually", "timestamp": "00:09:55,888", "timestamp_s": 595.0}, {"text": "pre trained models that have been trained on millions of documents", "timestamp": "00:09:59,456", "timestamp_s": 599.0}, {"text": "already, for example the Wikipedia. And then you can fine tune it", "timestamp": "00:10:03,382", "timestamp_s": 603.0}, {"text": "to your specific data set, which I will do in the training step in", "timestamp": "00:10:07,108", "timestamp_s": 607.0}, {"text": "this pipelines, fine tuning it to my specific product reviews text.", "timestamp": "00:10:10,564", "timestamp_s": 610.0}, {"text": "So the DAC we\u0027re going to build here is first process", "timestamp": "00:10:16,470", "timestamp_s": 616.0}, {"text": "the raw text data to generate the embeddings that", "timestamp": "00:10:20,328", "timestamp_s": 620.0}, {"text": "the bird model expects as inputs.", "timestamp": "00:10:23,672", "timestamp_s": 623.0}, {"text": "Then in the training step, I\u0027m going to fine tune the model to", "timestamp": "00:10:26,730", "timestamp_s": 626.0}, {"text": "my data set, and I\u0027m also evaluating", "timestamp": "00:10:30,332", "timestamp_s": 630.0}, {"text": "the model performance. So in this case, I\u0027m coding the", "timestamp": "00:10:34,466", "timestamp_s": 634.0}, {"text": "validation accuracy of my model and", "timestamp": "00:10:37,872", "timestamp_s": 637.0}, {"text": "I\u0027m defining a threshold, a condition. And if my", "timestamp": "00:10:41,536", "timestamp_s": 641.0}, {"text": "model performs above this threshold,", "timestamp": "00:10:45,584", "timestamp_s": 645.0}, {"text": "then I\u0027m going to register it to a model registry. Think of", "timestamp": "00:10:48,790", "timestamp_s": 648.0}, {"text": "it as a catalog of your models to compare the different versions.", "timestamp": "00:10:52,068", "timestamp_s": 652.0}, {"text": "And I\u0027m also preparing for deployment by creating a model object", "timestamp": "00:10:55,674", "timestamp_s": 655.0}, {"text": "here in Sagemaker. All right,", "timestamp": "00:10:59,620", "timestamp_s": 659.0}, {"text": "so let\u0027s see how we can build this.", "timestamp": "00:11:03,288", "timestamp_s": 663.0}, {"text": "First of all, here I\u0027m importing a couple of sdks", "timestamp": "00:11:06,630", "timestamp_s": 666.0}, {"text": "and libraries. One of them is the Sagemaker Python SDK", "timestamp": "00:11:10,510", "timestamp_s": 670.0}, {"text": "and a couple of additional libraries used here in the", "timestamp": "00:11:15,102", "timestamp_s": 675.0}, {"text": "AWS environment. All right, first of all,", "timestamp": "00:11:18,652", "timestamp_s": 678.0}, {"text": "I\u0027m going to import or set the location of the raw data", "timestamp": "00:11:21,996", "timestamp_s": 681.0}, {"text": "set, which is my reviews data here", "timestamp": "00:11:25,452", "timestamp_s": 685.0}, {"text": "hosted in public s three bucket.", "timestamp": "00:11:28,956", "timestamp_s": 688.0}, {"text": "And what I\u0027m going to do here is I\u0027m pulling a subset of the", "timestamp": "00:11:32,270", "timestamp_s": 692.0}, {"text": "data just for demo purposes here into my own AWS account.", "timestamp": "00:11:35,808", "timestamp_s": 695.0}, {"text": "So I\u0027m setting a path here to my own bucket,", "timestamp": "00:11:40,016", "timestamp_s": 700.0}, {"text": "and I\u0027m going to pull in just a subset here so the model training doesn\u0027t", "timestamp": "00:11:43,890", "timestamp_s": 703.0}, {"text": "run for too long, and I\u0027m just pulling in three different categories", "timestamp": "00:11:47,658", "timestamp_s": 707.0}, {"text": "of the product reviews data.", "timestamp": "00:11:51,834", "timestamp_s": 711.0}, {"text": "All right, let\u0027s start building the actual pipeline.", "timestamp": "00:11:55,430", "timestamp_s": 715.0}, {"text": "So first of all, I\u0027m creating a name for the pipeline.", "timestamp": "00:11:59,110", "timestamp_s": 719.0}, {"text": "Let\u0027s call this my Bird pipeline, and a timestamp.", "timestamp": "00:12:02,974", "timestamp_s": 722.0}, {"text": "And then one nice thing about pipelines is that you", "timestamp": "00:12:08,090", "timestamp_s": 728.0}, {"text": "can define parameters to parameterize individual executions.", "timestamp": "00:12:11,388", "timestamp_s": 731.0}, {"text": "And now let\u0027s start with building the first step, which is the", "timestamp": "00:12:16,810", "timestamp_s": 736.0}, {"text": "feature engineering. Here\u0027s a little bit", "timestamp": "00:12:20,048", "timestamp_s": 740.0}, {"text": "of explanation what we\u0027re going to do. So my raw data set", "timestamp": "00:12:23,776", "timestamp_s": 743.0}, {"text": "here on the left has star ratings", "timestamp": "00:12:27,856", "timestamp_s": 747.0}, {"text": "and the review meets. So for example, this is", "timestamp": "00:12:31,366", "timestamp_s": 751.0}, {"text": "a great item, or I love this book, and the corresponding label,", "timestamp": "00:12:34,788", "timestamp_s": 754.0}, {"text": "which is the star rating. And what I\u0027m going", "timestamp": "00:12:38,266", "timestamp_s": 758.0}, {"text": "to do in this first features engineering step is I\u0027m using a sagemaker", "timestamp": "00:12:41,428", "timestamp_s": 761.0}, {"text": "processing job, which helps me to execute code", "timestamp": "00:12:45,598", "timestamp_s": 765.0}, {"text": "on data, so it\u0027s specifically suited if you want to run feature", "timestamp": "00:12:49,208", "timestamp_s": 769.0}, {"text": "engineering. And I\u0027m converting this raw input data", "timestamp": "00:12:52,686", "timestamp_s": 772.0}, {"text": "into embeddings that the bird model expects as", "timestamp": "00:12:56,716", "timestamp_s": 776.0}, {"text": "inputs. All right, so what", "timestamp": "00:13:00,108", "timestamp_s": 780.0}, {"text": "I\u0027m going to do here again, I\u0027m making sure I have access", "timestamp": "00:13:03,788", "timestamp_s": 783.0}, {"text": "to my input data, which is now in my own bucket.", "timestamp": "00:13:07,900", "timestamp_s": 787.0}, {"text": "And I start by preparing a couple of those parameters which I", "timestamp": "00:13:12,110", "timestamp_s": 792.0}, {"text": "want to be able to parameterize. So one", "timestamp": "00:13:15,408", "timestamp_s": 795.0}, {"text": "is definitely where to find the input data in case the location changes,", "timestamp": "00:13:18,896", "timestamp_s": 798.0}, {"text": "or I want to use a different data set.", "timestamp": "00:13:22,500", "timestamp_s": 802.0}, {"text": "I\u0027m also specifying the processing job instance count.", "timestamp": "00:13:25,410", "timestamp_s": 805.0}, {"text": "So what I could do, depending on how much data I need to process,", "timestamp": "00:13:29,876", "timestamp_s": 809.0}, {"text": "I can run this distributed, so I can run it across one", "timestamp": "00:13:33,524", "timestamp_s": 813.0}, {"text": "AWS cloud instance. I could run it across two instances, five instances,", "timestamp": "00:13:37,590", "timestamp_s": 817.0}, {"text": "et cetera. And it\u0027s as easy as just setting the value to one", "timestamp": "00:13:41,502", "timestamp_s": 821.0}, {"text": "or five or ten. And the processing job will make sure to", "timestamp": "00:13:45,272", "timestamp_s": 825.0}, {"text": "distribute the data across the instances and work in parallel.", "timestamp": "00:13:49,148", "timestamp_s": 829.0}, {"text": "In this case, I have a small subset of the data, so I\u0027ll stick to", "timestamp": "00:13:53,850", "timestamp_s": 833.0}, {"text": "one instance. I can also specify here", "timestamp": "00:13:57,068", "timestamp_s": 837.0}, {"text": "the instance type. So this is the AWS easy two instance type", "timestamp": "00:14:01,344", "timestamp_s": 841.0}, {"text": "managed by Sagemaker to run this processing job,", "timestamp": "00:14:05,456", "timestamp_s": 845.0}, {"text": "and I\u0027m just specifying one particular instance type here.", "timestamp": "00:14:09,168", "timestamp_s": 849.0}, {"text": "Then I\u0027m also defining a couple of parameters, which my feature", "timestamp": "00:14:13,890", "timestamp_s": 853.0}, {"text": "engineering script requires.", "timestamp": "00:14:17,626", "timestamp_s": 857.0}, {"text": "Then I could set parameters such as do I want to balance the", "timestamp": "00:14:21,090", "timestamp_s": 861.0}, {"text": "data set before and percentages how to", "timestamp": "00:14:24,968", "timestamp_s": 864.0}, {"text": "split the data into a training set, validation and test data set.", "timestamp": "00:14:28,968", "timestamp_s": 868.0}, {"text": "So in this case, I\u0027m taking 90% for my training data,", "timestamp": "00:14:33,510", "timestamp_s": 873.0}, {"text": "and I keep a split of 5% for validation and", "timestamp": "00:14:37,484", "timestamp_s": 877.0}, {"text": "another 5% for test.", "timestamp": "00:14:40,892", "timestamp_s": 880.0}, {"text": "All right, then the step actually needs to perform the", "timestamp": "00:14:44,570", "timestamp_s": 884.0}, {"text": "feature engineering. So what I\u0027ve done in preparation is", "timestamp": "00:14:48,348", "timestamp_s": 888.0}, {"text": "I wrote a Python script which performs the actual transformations,", "timestamp": "00:14:51,552", "timestamp_s": 891.0}, {"text": "and this is here in this Python file.", "timestamp": "00:14:55,958", "timestamp_s": 895.0}, {"text": "So I\u0027m not going to go into all of the glory details. If you\u0027re curious", "timestamp": "00:14:58,966", "timestamp_s": 898.0}, {"text": "how to do this, have a look at the GitHub repo.", "timestamp": "00:15:02,682", "timestamp_s": 902.0}, {"text": "All right, then I can start creating this", "timestamp": "00:15:06,370", "timestamp_s": 906.0}, {"text": "processing job, and for that I\u0027ll", "timestamp": "00:15:09,908", "timestamp_s": 909.0}, {"text": "define a processor. Here I\u0027m using a prebuilt process based", "timestamp": "00:15:13,258", "timestamp_s": 913.0}, {"text": "on scikit learn. I\u0027m defining the framework", "timestamp": "00:15:17,576", "timestamp_s": 917.0}, {"text": "version passing in my IAM role the instance", "timestamp": "00:15:20,926", "timestamp_s": 920.0}, {"text": "type and the instance count, and also the region I\u0027m operating", "timestamp": "00:15:24,606", "timestamp_s": 924.0}, {"text": "in. And I need one more thing,", "timestamp": "00:15:28,546", "timestamp_s": 928.0}, {"text": "because before I wrap it into the official workflow and", "timestamp": "00:15:32,156", "timestamp_s": 932.0}, {"text": "pipelines step, I need to define the inputs", "timestamp": "00:15:35,468", "timestamp_s": 935.0}, {"text": "for the job and the outputs. The inputs here", "timestamp": "00:15:39,270", "timestamp_s": 939.0}, {"text": "is the raw input data,", "timestamp": "00:15:43,120", "timestamp_s": 943.0}, {"text": "and the outputs are s three folders", "timestamp": "00:15:46,350", "timestamp_s": 946.0}, {"text": "where to store the generated features.", "timestamp": "00:15:51,194", "timestamp_s": 951.0}, {"text": "And I\u0027m also going to split this again by training,", "timestamp": "00:15:55,050", "timestamp_s": 955.0}, {"text": "validation, and test data meets. So I\u0027m putting here the", "timestamp": "00:15:57,940", "timestamp_s": 957.0}, {"text": "three locations where the data will be written to,", "timestamp": "00:16:01,252", "timestamp_s": 961.0}, {"text": "and those internal container paths will get mapped to", "timestamp": "00:16:05,030", "timestamp_s": 965.0}, {"text": "an s relocation later. All right,", "timestamp": "00:16:08,568", "timestamp_s": 968.0}, {"text": "and with that I can define the official step as part of", "timestamp": "00:16:12,232", "timestamp_s": 972.0}, {"text": "my pipeline. So here you can see I\u0027m defining a", "timestamp": "00:16:15,848", "timestamp_s": 975.0}, {"text": "processing step. I\u0027ll give it a name. This is what you", "timestamp": "00:16:19,452", "timestamp_s": 979.0}, {"text": "saw in the DAC. I point to", "timestamp": "00:16:22,732", "timestamp_s": 982.0}, {"text": "the actual Python code to execute my feature engineering,", "timestamp": "00:16:25,868", "timestamp_s": 985.0}, {"text": "and then I\u0027m passing in the scikitlearn processor, which I defined", "timestamp": "00:16:29,870", "timestamp_s": 989.0}, {"text": "the inputs and the outputs. And here I\u0027m passing", "timestamp": "00:16:33,750", "timestamp_s": 993.0}, {"text": "the specific job arguments that my script requires.", "timestamp": "00:16:37,974", "timestamp_s": 997.0}, {"text": "So for example, the training, validation test,", "timestamp": "00:16:41,738", "timestamp_s": 1001.0}, {"text": "split percentages, et cetera.", "timestamp": "00:16:44,756", "timestamp_s": 1004.0}, {"text": "All right, this defines my processing step.", "timestamp": "00:16:47,490", "timestamp_s": 1007.0}, {"text": "Now let\u0027s move on to the second steps, which is fine tuning", "timestamp": "00:16:52,290", "timestamp_s": 1012.0}, {"text": "the model with the help of a sagemaker training job.", "timestamp": "00:16:55,982", "timestamp_s": 1015.0}, {"text": "And this is pretty similar. So here you can see again I\u0027m defining", "timestamp": "00:17:00,390", "timestamp_s": 1020.0}, {"text": "parameters, for example, the training instance type and count", "timestamp": "00:17:04,158", "timestamp_s": 1024.0}, {"text": "again. And then I\u0027m setting up parameters,", "timestamp": "00:17:07,580", "timestamp_s": 1027.0}, {"text": "the hyperparameters will depend on the models you\u0027re using", "timestamp": "00:17:12,410", "timestamp_s": 1032.0}, {"text": "the use case. So in my case, some general parameters,", "timestamp": "00:17:16,060", "timestamp_s": 1036.0}, {"text": "number of epics runs throughout the whole data set.", "timestamp": "00:17:20,054", "timestamp_s": 1040.0}, {"text": "And I\u0027m just going to keep this here to one. For this demo purpose,", "timestamp": "00:17:23,376", "timestamp_s": 1043.0}, {"text": "I\u0027m setting a learning rate and then additional values,", "timestamp": "00:17:27,318", "timestamp_s": 1047.0}, {"text": "for example, the Epsilon value train, batch sizes,", "timestamp": "00:17:31,258", "timestamp_s": 1051.0}, {"text": "validation batch sizes, et cetera. Again, this will highly", "timestamp": "00:17:34,426", "timestamp_s": 1054.0}, {"text": "depend on the type of model and use case you are", "timestamp": "00:17:38,378", "timestamp_s": 1058.0}, {"text": "training. All right,", "timestamp": "00:17:42,788", "timestamp_s": 1062.0}, {"text": "next, what I\u0027m going to do is I\u0027m also going to capture", "timestamp": "00:17:45,670", "timestamp_s": 1065.0}, {"text": "the performance of my model during training.", "timestamp": "00:17:48,910", "timestamp_s": 1068.0}, {"text": "So I can specify here regex expressions", "timestamp": "00:17:52,232", "timestamp_s": 1072.0}, {"text": "that the model training code will output in the logs.", "timestamp": "00:17:56,330", "timestamp_s": 1076.0}, {"text": "So for example, my script that I use will put validation loss", "timestamp": "00:18:00,258", "timestamp_s": 1080.0}, {"text": "and validation accuracy as an output. And I\u0027m", "timestamp": "00:18:04,098", "timestamp_s": 1084.0}, {"text": "using here those regex expressions to capture them from", "timestamp": "00:18:07,778", "timestamp_s": 1087.0}, {"text": "the locks and then also are available in the UI and", "timestamp": "00:18:11,568", "timestamp_s": 1091.0}, {"text": "for me to check later on in the evaluation step.", "timestamp": "00:18:15,552", "timestamp_s": 1095.0}, {"text": "All right, and I\u0027ve talked about the training script.", "timestamp": "00:18:20,030", "timestamp_s": 1100.0}, {"text": "So again, I\u0027ve prepared a Python file which contains the", "timestamp": "00:18:23,290", "timestamp_s": 1103.0}, {"text": "code to train my model. This is here in the Tfbirdreviews", "timestamp": "00:18:26,628", "timestamp_s": 1106.0}, {"text": "py file. And again, I\u0027m not going into details. If you\u0027re", "timestamp": "00:18:30,666", "timestamp_s": 1110.0}, {"text": "interested in seeing how to do this, in particular,", "timestamp": "00:18:34,058", "timestamp_s": 1114.0}, {"text": "how to use this pretrained hugging phase", "timestamp": "00:18:37,288", "timestamp_s": 1117.0}, {"text": "model and then just fine tune it to the data, please check out", "timestamp": "00:18:40,430", "timestamp_s": 1120.0}, {"text": "the code in the GitHub repo. All right,", "timestamp": "00:18:44,168", "timestamp_s": 1124.0}, {"text": "so we can now prepare the training estimator and", "timestamp": "00:18:47,820", "timestamp_s": 1127.0}, {"text": "then build the model training step. So first", "timestamp": "00:18:51,868", "timestamp_s": 1131.0}, {"text": "of all, I actually need to define the estimator which performs", "timestamp": "00:18:55,068", "timestamp_s": 1135.0}, {"text": "the training. And I\u0027m using", "timestamp": "00:18:58,518", "timestamp_s": 1138.0}, {"text": "a built in Tensorflow estimator with Sagemaker, which has", "timestamp": "00:19:02,704", "timestamp_s": 1142.0}, {"text": "optimizations to run Tensorflow on AWS. And as", "timestamp": "00:19:06,192", "timestamp_s": 1146.0}, {"text": "you can see here, I\u0027m defining this Tensorflow estimator,", "timestamp": "00:19:10,064", "timestamp_s": 1150.0}, {"text": "pointing to the training script, which I just highlighted,", "timestamp": "00:19:13,338", "timestamp_s": 1153.0}, {"text": "and also passing in the additional parameters, the role,", "timestamp": "00:19:17,514", "timestamp_s": 1157.0}, {"text": "instance count and type, python version,", "timestamp": "00:19:21,402", "timestamp_s": 1161.0}, {"text": "tensorflow framework version I want to use. And again,", "timestamp": "00:19:24,814", "timestamp_s": 1164.0}, {"text": "my hyperparameters, which I defined earlier.", "timestamp": "00:19:28,200", "timestamp_s": 1168.0}, {"text": "One more step actually, that I\u0027m coding to do is activating", "timestamp": "00:19:32,230", "timestamp_s": 1172.0}, {"text": "step caching with steps caching. What you", "timestamp": "00:19:36,490", "timestamp_s": 1176.0}, {"text": "can do is make sure if you\u0027re rerunning", "timestamp": "00:19:39,948", "timestamp_s": 1179.0}, {"text": "the pipeline and individual steps might have not have changed to", "timestamp": "00:19:43,314", "timestamp_s": 1183.0}, {"text": "reuse the previous results. So Sagemaker will apply", "timestamp": "00:19:47,452", "timestamp_s": 1187.0}, {"text": "this caching to help you accelerate and", "timestamp": "00:19:51,376", "timestamp_s": 1191.0}, {"text": "run the different executions more efficient.", "timestamp": "00:19:54,496", "timestamp_s": 1194.0}, {"text": "All right? And with that, I can define the training step.", "timestamp": "00:19:57,710", "timestamp_s": 1197.0}, {"text": "So here you can see I define", "timestamp": "00:20:01,310", "timestamp_s": 1201.0}, {"text": "the official training step. Give it a train. Again, this name,", "timestamp": "00:20:04,778", "timestamp_s": 1204.0}, {"text": "the train will appear in the DAG as you could see before then I\u0027m passing", "timestamp": "00:20:08,180", "timestamp_s": 1208.0}, {"text": "in this estimator that has all of the tensorflow and training script", "timestamp": "00:20:12,138", "timestamp_s": 1212.0}, {"text": "configuration, and I\u0027m also training the inputs.", "timestamp": "00:20:16,382", "timestamp_s": 1216.0}, {"text": "And here you can see I\u0027m referring to", "timestamp": "00:20:20,222", "timestamp_s": 1220.0}, {"text": "the previous process step output and using it", "timestamp": "00:20:23,528", "timestamp_s": 1223.0}, {"text": "as an input for the training. So those are the features that I generated for", "timestamp": "00:20:27,320", "timestamp_s": 1227.0}, {"text": "bird training, for bird validation, and for bird test.", "timestamp": "00:20:31,052", "timestamp_s": 1231.0}, {"text": "All right, after the training, there comes the model evaluation.", "timestamp": "00:20:35,450", "timestamp_s": 1235.0}, {"text": "So let\u0027s see how I can do this.", "timestamp": "00:20:40,190", "timestamp_s": 1240.0}, {"text": "The model evaluation I can also execute as a processing", "timestamp": "00:20:43,710", "timestamp_s": 1243.0}, {"text": "job again. So I\u0027m going to use this scikitlearn processor", "timestamp": "00:20:47,302", "timestamp_s": 1247.0}, {"text": "again specifying the framework version instance", "timestamp": "00:20:50,694", "timestamp_s": 1250.0}, {"text": "types and counts. The difference here is that I", "timestamp": "00:20:54,122", "timestamp_s": 1254.0}, {"text": "do have another script to execute. So instead of the feature", "timestamp": "00:20:57,508", "timestamp_s": 1257.0}, {"text": "engineering, I\u0027ve now written a script that evaluates the model performance.", "timestamp": "00:21:00,746", "timestamp_s": 1260.0}, {"text": "And again, here is a link to the python script.", "timestamp": "00:21:05,910", "timestamp_s": 1265.0}, {"text": "Basically what I\u0027m going to do is I\u0027m using the pretrained", "timestamp": "00:21:09,270", "timestamp_s": 1269.0}, {"text": "and fine tuned model from the previous step, and I\u0027m", "timestamp": "00:21:13,262", "timestamp_s": 1273.0}, {"text": "running some test predictions and see", "timestamp": "00:21:16,818", "timestamp_s": 1276.0}, {"text": "how the performance is. So in this case, I\u0027m specifically", "timestamp": "00:21:20,730", "timestamp_s": 1280.0}, {"text": "looking for the validation performance of my model.", "timestamp": "00:21:24,786", "timestamp_s": 1284.0}, {"text": "All right, and the results get written into JSON", "timestamp": "00:21:28,830", "timestamp_s": 1288.0}, {"text": "file, which I call the evaluation JSON, which is the official evaluation", "timestamp": "00:21:33,222", "timestamp_s": 1293.0}, {"text": "report from the step. And here\u0027s the official", "timestamp": "00:21:37,510", "timestamp_s": 1297.0}, {"text": "definition. So this is actually implemented as another processing step.", "timestamp": "00:21:41,562", "timestamp_s": 1301.0}, {"text": "In this case I call it evaluate the model.", "timestamp": "00:21:45,236", "timestamp_s": 1305.0}, {"text": "I\u0027m pointing to this new script which runs the validation.", "timestamp": "00:21:48,050", "timestamp_s": 1308.0}, {"text": "And again I\u0027m pointing it here to inputs, which in this case", "timestamp": "00:21:53,010", "timestamp_s": 1313.0}, {"text": "is the fine tuned model, the model artifact from the training", "timestamp": "00:21:56,856", "timestamp_s": 1316.0}, {"text": "step, and also again, input data", "timestamp": "00:22:00,120", "timestamp_s": 1320.0}, {"text": "which I could use to run validation.", "timestamp": "00:22:03,944", "timestamp_s": 1323.0}, {"text": "And I\u0027m also pointing out an output location to store", "timestamp": "00:22:07,050", "timestamp_s": 1327.0}, {"text": "the evaluation results.", "timestamp": "00:22:10,796", "timestamp_s": 1330.0}, {"text": "All right, the official model metrics are defined in an", "timestamp": "00:22:13,930", "timestamp_s": 1333.0}, {"text": "object, which I do here, which contain the evaluation", "timestamp": "00:22:17,228", "timestamp_s": 1337.0}, {"text": "JSON file. All right,", "timestamp": "00:22:21,030", "timestamp_s": 1341.0}, {"text": "and the last part now is to define the", "timestamp": "00:22:24,192", "timestamp_s": 1344.0}, {"text": "condition step. So, checking whether my model meets", "timestamp": "00:22:27,712", "timestamp_s": 1347.0}, {"text": "the expected highquality gate. And if yes,", "timestamp": "00:22:31,498", "timestamp_s": 1351.0}, {"text": "then register the model to the model registry and also prepare", "timestamp": "00:22:35,124", "timestamp_s": 1355.0}, {"text": "for deployment. And what I\u0027m going to do here is first", "timestamp": "00:22:39,018", "timestamp_s": 1359.0}, {"text": "create those steps afterwards, and then I can reference them", "timestamp": "00:22:42,836", "timestamp_s": 1362.0}, {"text": "in the actual condition step. So let\u0027s see this.", "timestamp": "00:22:46,632", "timestamp_s": 1366.0}, {"text": "And one nice thing that you can do with sagemaker pipelines", "timestamp": "00:22:51,030", "timestamp_s": 1371.0}, {"text": "is to actually set a model approval status.", "timestamp": "00:22:54,878", "timestamp_s": 1374.0}, {"text": "So when you get a model, you evaluate it. You can specify", "timestamp": "00:22:58,466", "timestamp_s": 1378.0}, {"text": "whether this has a pending, for example, manual approval.", "timestamp": "00:23:02,650", "timestamp_s": 1382.0}, {"text": "So somebody has to look at the metrics and then approve", "timestamp": "00:23:06,130", "timestamp_s": 1386.0}, {"text": "it for deployment. You can set it to always approve,", "timestamp": "00:23:09,398", "timestamp_s": 1389.0}, {"text": "but in this case, I want to show you I keep it to manual approval", "timestamp": "00:23:13,046", "timestamp_s": 1393.0}, {"text": "only. All right, then I\u0027m", "timestamp": "00:23:16,438", "timestamp_s": 1396.0}, {"text": "going to define again the instance types and counts, where to later", "timestamp": "00:23:20,374", "timestamp_s": 1400.0}, {"text": "deploy my model and host it for live predictions.", "timestamp": "00:23:23,700", "timestamp_s": 1403.0}, {"text": "And I\u0027m also specifying the model package group, which is", "timestamp": "00:23:28,050", "timestamp_s": 1408.0}, {"text": "registered in the model registry. And I\u0027m", "timestamp": "00:23:31,860", "timestamp_s": 1411.0}, {"text": "defining an image that is used to later deploy", "timestamp": "00:23:35,598", "timestamp_s": 1415.0}, {"text": "the endpoint and then run the model and the", "timestamp": "00:23:39,678", "timestamp_s": 1419.0}, {"text": "inference code. So in this case it\u0027s going to be a tensorflow based docker image", "timestamp": "00:23:42,808", "timestamp_s": 1422.0}, {"text": "again. All right, so here is the step that registers", "timestamp": "00:23:46,834", "timestamp_s": 1426.0}, {"text": "the model. It\u0027s taking the estimator object and", "timestamp": "00:23:50,962", "timestamp_s": 1430.0}, {"text": "the information about the inference image to use.", "timestamp": "00:23:55,116", "timestamp_s": 1435.0}, {"text": "It actually points to the s three location of the fine tuned", "timestamp": "00:23:58,490", "timestamp_s": 1438.0}, {"text": "model, and it also defines specific input", "timestamp": "00:24:01,958", "timestamp_s": 1441.0}, {"text": "format types. For example, you know that your model expects JSON lines", "timestamp": "00:24:05,398", "timestamp_s": 1445.0}, {"text": "as input, and also response is going to", "timestamp": "00:24:09,174", "timestamp_s": 1449.0}, {"text": "be in JSON lines. Then this might vary, of course, depending on your model.", "timestamp": "00:24:12,404", "timestamp_s": 1452.0}, {"text": "And you also set here the model package group, where to register", "timestamp": "00:24:17,170", "timestamp_s": 1457.0}, {"text": "it with, and the approval status. This one will be pending manual approval.", "timestamp": "00:24:21,402", "timestamp_s": 1461.0}, {"text": "All right, then what I\u0027m also going to do here is create a", "timestamp": "00:24:26,710", "timestamp_s": 1466.0}, {"text": "step to prepare the model for deployment later.", "timestamp": "00:24:30,920", "timestamp_s": 1470.0}, {"text": "So I\u0027m preparing a model object in sagemaker,", "timestamp": "00:24:34,470", "timestamp_s": 1474.0}, {"text": "again, pass in the inference image and also the artifact.", "timestamp": "00:24:38,570", "timestamp_s": 1478.0}, {"text": "All right, and then I define here", "timestamp": "00:24:44,410", "timestamp_s": 1484.0}, {"text": "the official create model steps for the pipeline", "timestamp": "00:24:47,868", "timestamp_s": 1487.0}, {"text": "and pass in the model which I just created.", "timestamp": "00:24:51,390", "timestamp_s": 1491.0}, {"text": "So now we can start in creating this condition check that", "timestamp": "00:24:54,670", "timestamp_s": 1494.0}, {"text": "comes before. So what", "timestamp": "00:24:58,192", "timestamp_s": 1498.0}, {"text": "I\u0027m going to do here is I\u0027m importing the conditions", "timestamp": "00:25:02,388", "timestamp_s": 1502.0}, {"text": "and corresponding functions that are available. For example,", "timestamp": "00:25:06,074", "timestamp_s": 1506.0}, {"text": "a condition greater than or equal to, and I\u0027m", "timestamp": "00:25:09,540", "timestamp_s": 1509.0}, {"text": "defining a minimum accuracy value I want to check", "timestamp": "00:25:13,162", "timestamp_s": 1513.0}, {"text": "against. As this is a demo and I\u0027m just training on a little bit of", "timestamp": "00:25:16,632", "timestamp_s": 1516.0}, {"text": "data, I\u0027ll keep this low so all the model training runs will actually", "timestamp": "00:25:20,248", "timestamp_s": 1520.0}, {"text": "pass. But obviously in other use cases,", "timestamp": "00:25:23,896", "timestamp_s": 1523.0}, {"text": "you definitely want to bump up the accuracy threshold. In this case, I\u0027m using", "timestamp": "00:25:27,298", "timestamp_s": 1527.0}, {"text": "20% as my minimum accuracy to check against.", "timestamp": "00:25:30,972", "timestamp_s": 1530.0}, {"text": "Then here is the definition. So it\u0027s going to execute", "timestamp": "00:25:36,330", "timestamp_s": 1536.0}, {"text": "this check condition greater or equal to.", "timestamp": "00:25:39,526", "timestamp_s": 1539.0}, {"text": "And here is my evaluation step.", "timestamp": "00:25:43,152", "timestamp_s": 1543.0}, {"text": "And I\u0027m also pointing to this report file to generate and", "timestamp": "00:25:46,640", "timestamp_s": 1546.0}, {"text": "set to this value I created.", "timestamp": "00:25:51,348", "timestamp_s": 1551.0}, {"text": "And the additional official step is then tuning this", "timestamp": "00:25:54,690", "timestamp_s": 1554.0}, {"text": "condition. And if I meet the condition.", "timestamp": "00:25:58,756", "timestamp_s": 1558.0}, {"text": "So if I\u0027m passing my quality threshold, I\u0027m going to register", "timestamp": "00:26:02,442", "timestamp_s": 1562.0}, {"text": "the model, and I\u0027m also going to create the model in preparation for", "timestamp": "00:26:06,670", "timestamp_s": 1566.0}, {"text": "later deployment. In the out step you can say,", "timestamp": "00:26:10,168", "timestamp_s": 1570.0}, {"text": "what else? If I fail the test, right, send a message", "timestamp": "00:26:13,816", "timestamp_s": 1573.0}, {"text": "to the data scientist or whatever you want to do. In my case, I\u0027m just", "timestamp": "00:26:17,750", "timestamp_s": 1577.0}, {"text": "keeping it empty so it will fail and end the pipeline.", "timestamp": "00:26:21,388", "timestamp_s": 1581.0}, {"text": "So what we\u0027ve done now is defining each and every step from", "timestamp": "00:26:25,370", "timestamp_s": 1585.0}, {"text": "the preprocessing, to the training, to the", "timestamp": "00:26:28,988", "timestamp_s": 1588.0}, {"text": "condition and preparation for deployment, if I pass my quality threshold.", "timestamp": "00:26:32,272", "timestamp_s": 1592.0}, {"text": "So now I can wrap this in the end to end pipelines definition.", "timestamp": "00:26:37,046", "timestamp_s": 1597.0}, {"text": "First of all, again, I\u0027m importing some of the functions here needed and", "timestamp": "00:26:41,970", "timestamp_s": 1601.0}, {"text": "objects from the SDK. And as you can see here,", "timestamp": "00:26:45,812", "timestamp_s": 1605.0}, {"text": "I\u0027m now creating the official pipeline object passing", "timestamp": "00:26:49,252", "timestamp_s": 1609.0}, {"text": "in the name that we created, and all of the parameters which", "timestamp": "00:26:53,098", "timestamp_s": 1613.0}, {"text": "I specified in the above code. And then the", "timestamp": "00:26:57,032", "timestamp_s": 1617.0}, {"text": "steps here will actually line up the individual steps in", "timestamp": "00:27:00,792", "timestamp_s": 1620.0}, {"text": "this stack. So let\u0027s start with the processing, then move", "timestamp": "00:27:04,488", "timestamp_s": 1624.0}, {"text": "to the training step, do the evaluation step,", "timestamp": "00:27:08,092", "timestamp_s": 1628.0}, {"text": "and then you have this condition step to evaluate the models,", "timestamp": "00:27:11,276", "timestamp_s": 1631.0}, {"text": "which will in itself trigger the two different", "timestamp": "00:27:15,050", "timestamp_s": 1635.0}, {"text": "path depending on if I pass the quality check.", "timestamp": "00:27:19,150", "timestamp_s": 1639.0}, {"text": "I\u0027m also adding this to an official experiment tracking, so I", "timestamp": "00:27:22,990", "timestamp_s": 1642.0}, {"text": "can keep track of my pipeline runs, and that\u0027s the definition", "timestamp": "00:27:26,384", "timestamp_s": 1646.0}, {"text": "of my pipelines. And then I can submit the pipeline for execution.", "timestamp": "00:27:30,278", "timestamp_s": 1650.0}, {"text": "So I\u0027m calling the pipeline create passing a role that has", "timestamp": "00:27:34,290", "timestamp_s": 1654.0}, {"text": "the permissions to execute everything. And then what I", "timestamp": "00:27:37,748", "timestamp_s": 1657.0}, {"text": "can do is I can call the pipelines start,", "timestamp": "00:27:41,188", "timestamp_s": 1661.0}, {"text": "which will start an individual execution run of this pipeline.", "timestamp": "00:27:44,630", "timestamp_s": 1664.0}, {"text": "And you can see here also you can pass in", "timestamp": "00:27:49,190", "timestamp_s": 1669.0}, {"text": "now your parameter values,", "timestamp": "00:27:52,408", "timestamp_s": 1672.0}, {"text": "and that will kick off the pipelines in the background.", "timestamp": "00:27:55,294", "timestamp_s": 1675.0}, {"text": "But this will run now on AWS with the sagemaker processing", "timestamp": "00:27:58,786", "timestamp_s": 1678.0}, {"text": "job, the training job, and also run the model evaluation.", "timestamp": "00:28:02,978", "timestamp_s": 1682.0}, {"text": "And what I also want to show you is that Sagemaker", "timestamp": "00:28:06,650", "timestamp_s": 1686.0}, {"text": "keeps track of the individual artifacts that are generated in each step.", "timestamp": "00:28:10,198", "timestamp_s": 1690.0}, {"text": "So what I\u0027m doing here is I\u0027m listing all artifacts", "timestamp": "00:28:14,208", "timestamp_s": 1694.0}, {"text": "generated by this pipelines. And this is super helpful", "timestamp": "00:28:17,382", "timestamp_s": 1697.0}, {"text": "if you want to keep track of the individual steps.", "timestamp": "00:28:21,302", "timestamp_s": 1701.0}, {"text": "And for example, what were the inputs in this case for", "timestamp": "00:28:24,554", "timestamp_s": 1704.0}, {"text": "the processing job, I do have the raw data. I do", "timestamp": "00:28:27,908", "timestamp_s": 1707.0}, {"text": "have the docker image that\u0027s used to process the data.", "timestamp": "00:28:31,252", "timestamp_s": 1711.0}, {"text": "And the output is the generated features, and you", "timestamp": "00:28:35,190", "timestamp_s": 1715.0}, {"text": "can see here contributed to or production.", "timestamp": "00:28:38,984", "timestamp_s": 1718.0}, {"text": "Then in the training step, you have the generated features,", "timestamp": "00:28:43,510", "timestamp_s": 1723.0}, {"text": "training features as the input and the image to", "timestamp": "00:28:46,622", "timestamp_s": 1726.0}, {"text": "execute the training job. And the output here would be", "timestamp": "00:28:49,948", "timestamp_s": 1729.0}, {"text": "the model artifact. So really nice to keep track of", "timestamp": "00:28:53,388", "timestamp_s": 1733.0}, {"text": "those artifacts for each step. And with that,", "timestamp": "00:28:56,988", "timestamp_s": 1736.0}, {"text": "we can come back to actually checking on our pipeline.", "timestamp": "00:29:00,816", "timestamp_s": 1740.0}, {"text": "So I\u0027m going to go back here in the pipelines.", "timestamp": "00:29:04,662", "timestamp_s": 1744.0}, {"text": "You can check on the graph, and this is the overall graph that we defined", "timestamp": "00:29:08,342", "timestamp_s": 1748.0}, {"text": "so it matches our steps.", "timestamp": "00:29:12,250", "timestamp_s": 1752.0}, {"text": "You can check the parameters. Again, you set the settings,", "timestamp": "00:29:16,850", "timestamp_s": 1756.0}, {"text": "you can click into the individual graph, and the color coding", "timestamp": "00:29:20,554", "timestamp_s": 1760.0}, {"text": "here shows green means it completed successfully. You can", "timestamp": "00:29:24,622", "timestamp_s": 1764.0}, {"text": "click into each step and again see the parameters here", "timestamp": "00:29:28,632", "timestamp_s": 1768.0}, {"text": "that were used to run and execute the step.", "timestamp": "00:29:32,344", "timestamp_s": 1772.0}, {"text": "All right, what I also want to show you is the model registry.", "timestamp": "00:29:36,390", "timestamp_s": 1776.0}, {"text": "So let me go here in the navigation also to the model", "timestamp": "00:29:40,730", "timestamp_s": 1780.0}, {"text": "registry. And we do see here our model group,", "timestamp": "00:29:44,076", "timestamp_s": 1784.0}, {"text": "the bird reviews and here is my model", "timestamp": "00:29:47,950", "timestamp_s": 1787.0}, {"text": "version. And again, I\u0027ve set this", "timestamp": "00:29:52,096", "timestamp_s": 1792.0}, {"text": "to manual approval. So this one here", "timestamp": "00:29:55,312", "timestamp_s": 1795.0}, {"text": "will still need my approval to be deployed into", "timestamp": "00:29:58,672", "timestamp_s": 1798.0}, {"text": "production. I can update the status", "timestamp": "00:30:02,436", "timestamp_s": 1802.0}, {"text": "and set it here to approved and", "timestamp": "00:30:06,842", "timestamp_s": 1806.0}, {"text": "say this is good for", "timestamp": "00:30:10,276", "timestamp_s": 1810.0}, {"text": "deployment into staging", "timestamp": "00:30:14,728", "timestamp_s": 1814.0}, {"text": "update. And with that the", "timestamp": "00:30:19,350", "timestamp_s": 1819.0}, {"text": "model is now approved for deployments and", "timestamp": "00:30:22,968", "timestamp_s": 1822.0}, {"text": "this completes the first demo.", "timestamp": "00:30:26,668", "timestamp_s": 1826.0}, {"text": "In the second phase, we could automatically run pipelines", "timestamp": "00:30:30,650", "timestamp_s": 1830.0}, {"text": "and include automated quality gates.", "timestamp": "00:30:34,834", "timestamp_s": 1834.0}, {"text": "So here the model training pipeline could automatically", "timestamp": "00:30:38,030", "timestamp_s": 1838.0}, {"text": "evaluate the model in terms of model performance", "timestamp": "00:30:41,990", "timestamp_s": 1841.0}, {"text": "or bias metrics and thresholds.", "timestamp": "00:30:45,478", "timestamp_s": 1845.0}, {"text": "Only models that fall into acceptable performance", "timestamp": "00:30:48,990", "timestamp_s": 1848.0}, {"text": "metrics get registered in the model registry and", "timestamp": "00:30:52,938", "timestamp_s": 1852.0}, {"text": "approved for deployment. The deployment pipeline", "timestamp": "00:30:56,996", "timestamp_s": 1856.0}, {"text": "could leverage deployment strategies such as a b testing", "timestamp": "00:31:00,746", "timestamp_s": 1860.0}, {"text": "or bandits to evaluate the model in comparison", "timestamp": "00:31:04,926", "timestamp_s": 1864.0}, {"text": "to existing models. The software engineer can", "timestamp": "00:31:08,846", "timestamp_s": 1868.0}, {"text": "automate the integration tests with pass fail", "timestamp": "00:31:12,920", "timestamp_s": 1872.0}, {"text": "highquality gates, and only models that passes", "timestamp": "00:31:16,626", "timestamp_s": 1876.0}, {"text": "get deployed into production. And finally,", "timestamp": "00:31:19,874", "timestamp_s": 1879.0}, {"text": "the operation team sets up model monitoring and analyzes", "timestamp": "00:31:23,596", "timestamp_s": 1883.0}, {"text": "for any data drift or models drift.", "timestamp": "00:31:27,842", "timestamp_s": 1887.0}, {"text": "If the drift is violating defined threshold values,", "timestamp": "00:31:31,230", "timestamp_s": 1891.0}, {"text": "this could actually trigger a model retraining pipeline.", "timestamp": "00:31:35,030", "timestamp_s": 1895.0}, {"text": "Again, another trigger to rerun a model", "timestamp": "00:31:38,326", "timestamp_s": 1898.0}, {"text": "training and deployment pipeline could be code changes", "timestamp": "00:31:42,516", "timestamp_s": 1902.0}, {"text": "as part of a continuous integrations and continuous", "timestamp": "00:31:46,052", "timestamp_s": 1906.0}, {"text": "delivery. Short CI CD automation let\u0027s", "timestamp": "00:31:49,722", "timestamp_s": 1909.0}, {"text": "see another demo of a code change triggered pipelines", "timestamp": "00:31:54,798", "timestamp_s": 1914.0}, {"text": "run all right, I\u0027m back in", "timestamp": "00:31:58,622", "timestamp_s": 1918.0}, {"text": "my AWS demo account. Now I want to", "timestamp": "00:32:02,088", "timestamp_s": 1922.0}, {"text": "show you how you can leverage Sagemaker projects", "timestamp": "00:32:05,788", "timestamp_s": 1925.0}, {"text": "to automate workflows. Pipelines runs Sagemaker", "timestamp": "00:32:09,698", "timestamp_s": 1929.0}, {"text": "projects helps you to set up all of the automation", "timestamp": "00:32:13,682", "timestamp_s": 1933.0}, {"text": "needed in the AWS account to build a", "timestamp": "00:32:17,474", "timestamp_s": 1937.0}, {"text": "continuous integration, continuous deployed workflow.", "timestamp": "00:32:20,704", "timestamp_s": 1940.0}, {"text": "The easiest way to get started is if you navigate here", "timestamp": "00:32:25,150", "timestamp_s": 1945.0}, {"text": "in the menu to projects and then", "timestamp": "00:32:28,656", "timestamp_s": 1948.0}, {"text": "create project. You can see that it already comes with a", "timestamp": "00:32:32,240", "timestamp_s": 1952.0}, {"text": "couple of prebuilt templates which you can use.", "timestamp": "00:32:36,084", "timestamp_s": 1956.0}, {"text": "So one template will set up all of the automation", "timestamp": "00:32:39,252", "timestamp_s": 1959.0}, {"text": "for a model building and training pipeline and automation.", "timestamp": "00:32:42,874", "timestamp_s": 1962.0}, {"text": "The other one is for model deployment. And what I\u0027ve pre provisioned", "timestamp": "00:32:47,270", "timestamp_s": 1967.0}, {"text": "here is a CI CD environment for", "timestamp": "00:32:51,182", "timestamp_s": 1971.0}, {"text": "model building, training and the actual model deployment.", "timestamp": "00:32:55,032", "timestamp_s": 1975.0}, {"text": "I\u0027ve already pre built everything, so let me walk you", "timestamp": "00:32:58,898", "timestamp_s": 1978.0}, {"text": "through the steps here. Programmatically,", "timestamp": "00:33:02,636", "timestamp_s": 1982.0}, {"text": "Sagemaker project is based on an AWS service", "timestamp": "00:33:05,690", "timestamp_s": 1985.0}, {"text": "catalog product. So the first step is to reusable sagemaker", "timestamp": "00:33:08,960", "timestamp_s": 1988.0}, {"text": "projects here in the studio environment.", "timestamp": "00:33:13,254", "timestamp_s": 1993.0}, {"text": "Then I\u0027m again importing all of the needed sdks and", "timestamp": "00:33:16,990", "timestamp_s": 1996.0}, {"text": "libraries and set the clients, and I\u0027m", "timestamp": "00:33:20,612", "timestamp_s": 2000.0}, {"text": "coding it here programmatically. But again, if you\u0027re coding the template", "timestamp": "00:33:24,698", "timestamp_s": 2004.0}, {"text": "through the UI, this is done for you. I\u0027ve provisioned the service", "timestamp": "00:33:28,458", "timestamp_s": 2008.0}, {"text": "catalog item and the template here programmatically through my notebook.", "timestamp": "00:33:32,660", "timestamp_s": 2012.0}, {"text": "Once the project is created,", "timestamp": "00:33:37,430", "timestamp_s": 2017.0}, {"text": "you can see here on the left that I do have this entry. Now for", "timestamp": "00:33:40,302", "timestamp_s": 2020.0}, {"text": "projects, I can select it. And what", "timestamp": "00:33:43,992", "timestamp_s": 2023.0}, {"text": "will happen here in the first step is that sagemaker projects", "timestamp": "00:33:47,612", "timestamp_s": 2027.0}, {"text": "will create two code commit repos for", "timestamp": "00:33:51,426", "timestamp_s": 2031.0}, {"text": "you in this AWS account you\u0027re using. So here", "timestamp": "00:33:54,572", "timestamp_s": 2034.0}, {"text": "you can see I do have two repos,", "timestamp": "00:33:58,032", "timestamp_s": 2038.0}, {"text": "one for the model build and training pipelines,", "timestamp": "00:34:00,910", "timestamp_s": 2040.0}, {"text": "and one for the model deployment pipeline.", "timestamp": "00:34:04,486", "timestamp_s": 2044.0}, {"text": "And all of the automation is set up. So whenever I", "timestamp": "00:34:08,350", "timestamp_s": 2048.0}, {"text": "commit code, push code to those repos, that will actually", "timestamp": "00:34:12,148", "timestamp_s": 2052.0}, {"text": "trigger a pipeline execution. And I\u0027ll show you", "timestamp": "00:34:16,164", "timestamp_s": 2056.0}, {"text": "how this looks like. So, back here in", "timestamp": "00:34:19,268", "timestamp_s": 2059.0}, {"text": "my main notebook, the first thing I\u0027m also doing in this", "timestamp": "00:34:22,980", "timestamp_s": 2062.0}, {"text": "notebook here is to clone those code commit repos", "timestamp": "00:34:26,328", "timestamp_s": 2066.0}, {"text": "locally into my sagemaker studio environment.", "timestamp": "00:34:30,350", "timestamp_s": 2070.0}, {"text": "So this is what I\u0027m running here for both code repos.", "timestamp": "00:34:33,998", "timestamp_s": 2073.0}, {"text": "I\u0027m also removing one of the sample repos", "timestamp": "00:34:39,050", "timestamp_s": 2079.0}, {"text": "encode that are in here. And I\u0027m", "timestamp": "00:34:42,450", "timestamp_s": 2082.0}, {"text": "triggering the first execution of the pipeline by", "timestamp": "00:34:46,178", "timestamp_s": 2086.0}, {"text": "actually copying over my sample pipeline that I\u0027ve", "timestamp": "00:34:50,176", "timestamp_s": 2090.0}, {"text": "built before in the demo. So if I go to the file", "timestamp": "00:34:54,118", "timestamp_s": 2094.0}, {"text": "browser here on the left, you can see", "timestamp": "00:34:57,718", "timestamp_s": 2097.0}, {"text": "I\u0027ve cloned down those model, build and model, deploy code,", "timestamp": "00:35:01,056", "timestamp_s": 2101.0}, {"text": "commit repos, and I can click into those.", "timestamp": "00:35:04,692", "timestamp_s": 2104.0}, {"text": "And I do have all of the needed code already set up", "timestamp": "00:35:08,132", "timestamp_s": 2108.0}, {"text": "all of the triggers in the AWS account. So what I", "timestamp": "00:35:11,540", "timestamp_s": 2111.0}, {"text": "can do here is in pipelines, I just need", "timestamp": "00:35:15,048", "timestamp_s": 2115.0}, {"text": "to add my own pipeline execution code that I want to run", "timestamp": "00:35:18,648", "timestamp_s": 2118.0}, {"text": "on the code change. So if I go in here,", "timestamp": "00:35:22,296", "timestamp_s": 2122.0}, {"text": "you will see I\u0027m using the exact same Python scripts for pre", "timestamp": "00:35:25,432", "timestamp_s": 2125.0}, {"text": "processing, for model training, and for entrance that I\u0027ve showed", "timestamp": "00:35:29,272", "timestamp_s": 2129.0}, {"text": "you before when I was manually building this pipelines. So especially", "timestamp": "00:35:32,914", "timestamp_s": 2132.0}, {"text": "the pipeline py file. If I open this one, this should", "timestamp": "00:35:37,068", "timestamp_s": 2137.0}, {"text": "look pretty familiar to you. Hopefully this contains exactly", "timestamp": "00:35:41,088", "timestamp_s": 2141.0}, {"text": "the code that I\u0027ve been showing you before when I", "timestamp": "00:35:45,024", "timestamp_s": 2145.0}, {"text": "was building the pipeline in the notebook. The only difference", "timestamp": "00:35:48,544", "timestamp_s": 2148.0}, {"text": "here is that I\u0027m now tuning this in the", "timestamp": "00:35:52,148", "timestamp_s": 2152.0}, {"text": "Python file. Programmatically, when I trigger the pipeline,", "timestamp": "00:35:55,636", "timestamp_s": 2155.0}, {"text": "run back to my notebook", "timestamp": "00:35:59,338", "timestamp_s": 2159.0}, {"text": "here. So what I\u0027ve done is I\u0027ve cloned", "timestamp": "00:36:03,166", "timestamp_s": 2163.0}, {"text": "the repos here, and I\u0027m coding over my", "timestamp": "00:36:07,198", "timestamp_s": 2167.0}, {"text": "sample code into those repos,", "timestamp": "00:36:10,952", "timestamp_s": 2170.0}, {"text": "and then I\u0027m committing them into the code commit.", "timestamp": "00:36:14,230", "timestamp_s": 2174.0}, {"text": "And you can see here it detected that I have removed some sample code.", "timestamp": "00:36:18,322", "timestamp_s": 2178.0}, {"text": "And I\u0027ve also added my own pipeline", "timestamp": "00:36:21,964", "timestamp_s": 2181.0}, {"text": "code. So that should be enough changes hopefully, to the repo.", "timestamp": "00:36:25,842", "timestamp_s": 2185.0}, {"text": "I\u0027m making sure I keep track of all the variables I\u0027m using here.", "timestamp": "00:36:30,830", "timestamp_s": 2190.0}, {"text": "And again, here\u0027s the pipeline py file, which I just showed you,", "timestamp": "00:36:35,070", "timestamp_s": 2195.0}, {"text": "which contains the pipeline code to run. And this is", "timestamp": "00:36:38,352", "timestamp_s": 2198.0}, {"text": "exactly what I have set up before.", "timestamp": "00:36:42,048", "timestamp_s": 2202.0}, {"text": "And when I was doing the code commit", "timestamp": "00:36:45,090", "timestamp_s": 2205.0}, {"text": "and the code push to the repo, this set up all", "timestamp": "00:36:48,890", "timestamp_s": 2208.0}, {"text": "of the CI CD automation that the template set up for you in the AWS", "timestamp": "00:36:52,468", "timestamp_s": 2212.0}, {"text": "account and started the pipeline run. So if I", "timestamp": "00:36:56,606", "timestamp_s": 2216.0}, {"text": "go down here into my projects again and", "timestamp": "00:37:00,328", "timestamp_s": 2220.0}, {"text": "click on pipelines, I can actually see", "timestamp": "00:37:04,520", "timestamp_s": 2224.0}, {"text": "that here is a pipeline that got started and", "timestamp": "00:37:07,964", "timestamp_s": 2227.0}, {"text": "I can select it and it has a succeeded execution", "timestamp": "00:37:12,108", "timestamp_s": 2232.0}, {"text": "run already. So I\u0027ve started this sometime before", "timestamp": "00:37:15,586", "timestamp_s": 2235.0}, {"text": "the session. All right, so let me show", "timestamp": "00:37:20,750", "timestamp_s": 2240.0}, {"text": "you how this automation works. So what happens", "timestamp": "00:37:24,288", "timestamp_s": 2244.0}, {"text": "is that projects integrate with the", "timestamp": "00:37:28,192", "timestamp_s": 2248.0}, {"text": "developer tools, for example with code pipelines and", "timestamp": "00:37:32,468", "timestamp_s": 2252.0}, {"text": "has this automation built in. So the first step, as you can see here,", "timestamp": "00:37:36,500", "timestamp_s": 2256.0}, {"text": "is creating the source code needed,", "timestamp": "00:37:40,356", "timestamp_s": 2260.0}, {"text": "and then it\u0027s going to build and start the pipelines execution", "timestamp": "00:37:44,168", "timestamp_s": 2264.0}, {"text": "run. And this is done with code", "timestamp": "00:37:48,526", "timestamp_s": 2268.0}, {"text": "build. So if I now jump into the build projects,", "timestamp": "00:37:51,816", "timestamp_s": 2271.0}, {"text": "you can see here that our build projects", "timestamp": "00:37:55,990", "timestamp_s": 2275.0}, {"text": "already in place. And the first one is", "timestamp": "00:37:59,106", "timestamp_s": 2279.0}, {"text": "the model training pipelines, which just succeeded. You can", "timestamp": "00:38:02,348", "timestamp_s": 2282.0}, {"text": "also see that the model deploy is currently in a failed state,", "timestamp": "00:38:05,932", "timestamp_s": 2285.0}, {"text": "and this is because it doesn\u0027t have an approved model yet", "timestamp": "00:38:09,120", "timestamp_s": 2289.0}, {"text": "to actually deploy. This template is", "timestamp": "00:38:12,768", "timestamp_s": 2292.0}, {"text": "also set up to have a two phase deployed.", "timestamp": "00:38:16,192", "timestamp_s": 2296.0}, {"text": "Phase one is deploying in a staging environment,", "timestamp": "00:38:19,046", "timestamp_s": 2299.0}, {"text": "which for example a data scientist could approve after", "timestamp": "00:38:22,234", "timestamp_s": 2302.0}, {"text": "evaluating the model. And then also it comes with a", "timestamp": "00:38:26,116", "timestamp_s": 2306.0}, {"text": "second stage to deploy into a production environment,", "timestamp": "00:38:29,412", "timestamp_s": 2309.0}, {"text": "which would most likely be another team to approve.", "timestamp": "00:38:32,906", "timestamp_s": 2312.0}, {"text": "For example, the integrations team, the DevOps team, the infrastructure", "timestamp": "00:38:36,078", "timestamp_s": 2316.0}, {"text": "teams. So I can click here into the code", "timestamp": "00:38:39,982", "timestamp_s": 2319.0}, {"text": "pipeline and I can see that my latest run here succeeded.", "timestamp": "00:38:43,656", "timestamp_s": 2323.0}, {"text": "The first one is the one I stopped and deployed from the sample", "timestamp": "00:38:47,666", "timestamp_s": 2327.0}, {"text": "code. So let\u0027s go back", "timestamp": "00:38:51,538", "timestamp_s": 2331.0}, {"text": "here to my environment.", "timestamp": "00:38:55,004", "timestamp_s": 2335.0}, {"text": "So what I need to do once the pipeline has", "timestamp": "00:38:58,850", "timestamp_s": 2338.0}, {"text": "executed, I can list the steps again here.", "timestamp": "00:39:02,528", "timestamp_s": 2342.0}, {"text": "I can see everything looks good. I can also list", "timestamp": "00:39:05,552", "timestamp_s": 2345.0}, {"text": "the artifacts again. And this looks familiar to", "timestamp": "00:39:09,088", "timestamp_s": 2349.0}, {"text": "the one I showed before. It\u0027s the exact same pipeline,", "timestamp": "00:39:13,028", "timestamp_s": 2353.0}, {"text": "all the artifacts that contributed to each steps.", "timestamp": "00:39:16,530", "timestamp_s": 2356.0}, {"text": "What I do have here now is a last step.", "timestamp": "00:39:19,810", "timestamp_s": 2359.0}, {"text": "That is an approval that is needed to actually deploy", "timestamp": "00:39:23,412", "timestamp_s": 2363.0}, {"text": "this model into the staging environment.", "timestamp": "00:39:27,342", "timestamp_s": 2367.0}, {"text": "And if you can remember in the previous demo, I showed you how to", "timestamp": "00:39:30,470", "timestamp_s": 2370.0}, {"text": "approve the model here through the studio UI.", "timestamp": "00:39:34,872", "timestamp_s": 2374.0}, {"text": "What I can do now here as well is to approve it", "timestamp": "00:39:38,730", "timestamp_s": 2378.0}, {"text": "through the API programmatically. And this is what I\u0027m", "timestamp": "00:39:42,316", "timestamp_s": 2382.0}, {"text": "going to do here. So, in here, I\u0027m looking for", "timestamp": "00:39:45,714", "timestamp_s": 2385.0}, {"text": "the executions and I\u0027m grabbing", "timestamp": "00:39:49,520", "timestamp_s": 2389.0}, {"text": "the model package arn where we registered the", "timestamp": "00:39:53,430", "timestamp_s": 2393.0}, {"text": "model. And then I\u0027m going to update", "timestamp": "00:39:57,008", "timestamp_s": 2397.0}, {"text": "the model package here and approve it for deployment", "timestamp": "00:40:00,278", "timestamp_s": 2400.0}, {"text": "into this first stage, which is the staging environment.", "timestamp": "00:40:04,090", "timestamp_s": 2404.0}, {"text": "So here I\u0027m going to update the model package. I\u0027m setting the", "timestamp": "00:40:08,450", "timestamp_s": 2408.0}, {"text": "status to approved, and then I can check", "timestamp": "00:40:12,452", "timestamp_s": 2412.0}, {"text": "here for the model name, and we\u0027ll", "timestamp": "00:40:15,832", "timestamp_s": 2415.0}, {"text": "see that the model starts to get deployed into the staging", "timestamp": "00:40:19,118", "timestamp_s": 2419.0}, {"text": "environment. Let\u0027s see the", "timestamp": "00:40:22,942", "timestamp_s": 2422.0}, {"text": "deployed pipeline. So what happens here is", "timestamp": "00:40:26,396", "timestamp_s": 2426.0}, {"text": "once I\u0027ve approved the model for staging,", "timestamp": "00:40:30,476", "timestamp_s": 2430.0}, {"text": "it actually started the second pipelines", "timestamp": "00:40:33,714", "timestamp_s": 2433.0}, {"text": "here, which is the model deploy.", "timestamp": "00:40:38,166", "timestamp_s": 2438.0}, {"text": "And you can see here it started building the source, and it\u0027s", "timestamp": "00:40:41,390", "timestamp_s": 2441.0}, {"text": "currently in progress deploying the model into the defined staging environment.", "timestamp": "00:40:44,998", "timestamp_s": 2444.0}, {"text": "I can also have a look here. So I\u0027m looking", "timestamp": "00:40:50,610", "timestamp_s": 2450.0}, {"text": "at the endpoint that this pipelines will set up.", "timestamp": "00:40:54,580", "timestamp_s": 2454.0}, {"text": "So if I click here,", "timestamp": "00:40:58,484", "timestamp_s": 2458.0}, {"text": "I will see now that here is an endpoint being created on", "timestamp": "00:41:01,970", "timestamp_s": 2461.0}, {"text": "Sagemaker for the staging environment. So this", "timestamp": "00:41:05,752", "timestamp_s": 2465.0}, {"text": "will take a few minutes for the endpoint to be", "timestamp": "00:41:09,688", "timestamp_s": 2469.0}, {"text": "ready. All right, the endpoint is", "timestamp": "00:41:13,224", "timestamp_s": 2473.0}, {"text": "now in service. And if I click in here, I can see", "timestamp": "00:41:16,972", "timestamp_s": 2476.0}, {"text": "the rest API I could call to get", "timestamp": "00:41:21,164", "timestamp_s": 2481.0}, {"text": "predictions from my model. Now, let\u0027s check", "timestamp": "00:41:24,700", "timestamp_s": 2484.0}, {"text": "this. In the notebook here, you can see the endpoint is in", "timestamp": "00:41:28,332", "timestamp_s": 2488.0}, {"text": "service. And what I do here is I pull in", "timestamp": "00:41:32,192", "timestamp_s": 2492.0}, {"text": "a Tensorflow predictor object, which I can create,", "timestamp": "00:41:35,664", "timestamp_s": 2495.0}, {"text": "and then I\u0027m going to pass in some sample reviews.", "timestamp": "00:41:39,550", "timestamp_s": 2499.0}, {"text": "Let\u0027s say this is great, and I can run this,", "timestamp": "00:41:43,462", "timestamp_s": 2503.0}, {"text": "pass it to the predictor, and you can see I get a prediction result", "timestamp": "00:41:46,692", "timestamp_s": 2506.0}, {"text": "back from my model deployed in the staging environment.", "timestamp": "00:41:50,740", "timestamp_s": 2510.0}, {"text": "Predicting this is a five star rating. Let\u0027s have a look at", "timestamp": "00:41:53,582", "timestamp_s": 2513.0}, {"text": "the code pipeline that we executed.", "timestamp": "00:41:57,560", "timestamp_s": 2517.0}, {"text": "So you can see here that the staging", "timestamp": "00:42:02,230", "timestamp_s": 2522.0}, {"text": "succeeded. But there is one more approval", "timestamp": "00:42:06,658", "timestamp_s": 2526.0}, {"text": "needed here for the actual deployment into a", "timestamp": "00:42:10,562", "timestamp_s": 2530.0}, {"text": "production environment. So this could really be something", "timestamp": "00:42:14,188", "timestamp_s": 2534.0}, {"text": "that another team handles. So if I\u0027m the DevOps", "timestamp": "00:42:17,500", "timestamp_s": 2537.0}, {"text": "engineer, the integration engineer, I could make sure I\u0027m running all", "timestamp": "00:42:21,222", "timestamp_s": 2541.0}, {"text": "of the tests that I need with this model. Now that is hosted in the", "timestamp": "00:42:24,848", "timestamp_s": 2544.0}, {"text": "staging environment. And if I agree", "timestamp": "00:42:28,464", "timestamp_s": 2548.0}, {"text": "that it\u0027s good to be deployed into production, I could", "timestamp": "00:42:32,148", "timestamp_s": 2552.0}, {"text": "either use here the code pipelines to", "timestamp": "00:42:35,812", "timestamp_s": 2555.0}, {"text": "approve the model and deploy to production,", "timestamp": "00:42:39,860", "timestamp_s": 2559.0}, {"text": "or I can also obviously do this programmatically,", "timestamp": "00:42:43,934", "timestamp_s": 2563.0}, {"text": "which is what I\u0027m doing here now in the notebook. So again,", "timestamp": "00:42:47,670", "timestamp_s": 2567.0}, {"text": "I review the pipelines and what I\u0027m doing here,", "timestamp": "00:42:52,008", "timestamp_s": 2572.0}, {"text": "exact same thing is that I\u0027m programmatically approving", "timestamp": "00:42:56,028", "timestamp_s": 2576.0}, {"text": "this for deployment in production.", "timestamp": "00:42:59,490", "timestamp_s": 2579.0}, {"text": "You can see this succeeded. Let\u0027s actually check our", "timestamp": "00:43:03,122", "timestamp_s": 2583.0}, {"text": "pipelines and there we go.", "timestamp": "00:43:06,636", "timestamp_s": 2586.0}, {"text": "You can see it took the approval and is currently now", "timestamp": "00:43:09,888", "timestamp_s": 2589.0}, {"text": "working on deploying this model into the production", "timestamp": "00:43:13,728", "timestamp_s": 2593.0}, {"text": "environment. As pointed out earlier,", "timestamp": "00:43:17,062", "timestamp_s": 2597.0}, {"text": "the ultimate goal is to build AI ML solutions that are", "timestamp": "00:43:20,794", "timestamp_s": 2600.0}, {"text": "secure, resilient, cost optimized,", "timestamp": "00:43:24,292", "timestamp_s": 2604.0}, {"text": "performant and operationally efficient.", "timestamp": "00:43:27,322", "timestamp_s": 2607.0}, {"text": "So in addition to the operational excellence which we discussed in", "timestamp": "00:43:31,010", "timestamp_s": 2611.0}, {"text": "the context of mlops, you also need to incorporate standard", "timestamp": "00:43:34,968", "timestamp_s": 2614.0}, {"text": "practices in each of these areas.", "timestamp": "00:43:38,824", "timestamp_s": 2618.0}, {"text": "Here are a few links to get you started. First,", "timestamp": "00:43:42,870", "timestamp_s": 2622.0}, {"text": "a link to the data science on AWS resources and", "timestamp": "00:43:46,392", "timestamp_s": 2626.0}, {"text": "the GitHub repo which contains all of the code samples I\u0027ve showed.", "timestamp": "00:43:50,012", "timestamp_s": 2630.0}, {"text": "Also here are links to the Amazon Sagemaker pipelines", "timestamp": "00:43:54,570", "timestamp_s": 2634.0}, {"text": "and the great blog post.", "timestamp": "00:43:58,326", "timestamp_s": 2638.0}, {"text": "Again, if you are looking for more comprehensive learning resources,", "timestamp": "00:44:01,470", "timestamp_s": 2641.0}, {"text": "check out the O\u0027Reilly book data Science on AWS, which covers", "timestamp": "00:44:06,118", "timestamp_s": 2646.0}, {"text": "how to implement endtoend, continuous AI and machine learning pipelines", "timestamp": "00:44:10,570", "timestamp_s": 2650.0}, {"text": "in over twelve chapters, 500 pages, and hundreds of additional", "timestamp": "00:44:14,698", "timestamp_s": 2654.0}, {"text": "code samples. Another great", "timestamp": "00:44:18,986", "timestamp_s": 2658.0}, {"text": "training resource is our newly launched practical data science", "timestamp": "00:44:22,676", "timestamp_s": 2662.0}, {"text": "specialization in partnership with deep learning AI and Coursera.", "timestamp": "00:44:26,266", "timestamp_s": 2666.0}, {"text": "This three course specialization teaches you practicals", "timestamp": "00:44:31,650", "timestamp_s": 2671.0}, {"text": "skills in how to take your data science and machine learning projects", "timestamp": "00:44:35,034", "timestamp_s": 2675.0}, {"text": "from idea to production using purpose built tools in the", "timestamp": "00:44:38,850", "timestamp_s": 2678.0}, {"text": "AWS cloud. This also includes on", "timestamp": "00:44:42,668", "timestamp_s": 2682.0}, {"text": "demand, hands on labs for you to practice.", "timestamp": "00:44:46,028", "timestamp_s": 2686.0}, {"text": "This concludes the session. Thanks for watching.", "timestamp": "00:44:50,250", "timestamp_s": 2690.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'dTP4J0GcXxg',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              From idea to production: Automate your machine learning workflows with pipelines
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Developing high-quality machine learning models involve many steps. We typically start with exploring and preparing our data. We experiment with different algorithms and parameters. We spend time training and tuning our model until the model meets our quality metrics, and is ready to be deployed into production. Orchestrating and automating workflows across each step of this model development process can take months of coding.</p>
<p>In this session, I show you how to create, automate, and manage machine learning workflows using Amazon SageMaker Pipelines. We will create a reusable NLP model training pipeline to prepare data, store the features in a feature store, fine-tune a BERT model, and deploy the model into production if it passes our defined quality metrics. </p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                In this session I will discuss how you can take your data science and machine learning projects from idea to production by automating your machine learning workflows with pipelines. While most of the time we tend to focus on the technology, people and process are equally, if not more important.

              </li>
              
              <li>
                Today we often still manually build and manage individual models. We also execute each step in the model development workflow individually. A limited cross team collaboration could lead to limited visibility and transparency. We can also look at automating tasks in each step.

              </li>
              
              <li>
                Amazon Sagemaker is a fully managed service that helps you build, train, tune, and deploy your machine learning models. This demo shows how you can leverage Amazon Sagemaker pipelines to automate the individual steps of building a machine learning model.

              </li>
              
              <li>
                All right, and with that I can define the official step as part of my pipeline. Now let's move on to the second steps, which is fine tuning the model with the help of a sagemaker training job. If you're interested in seeing how to do this, in particular, how to use this pretrained hugging phase model and then just fine tune it to the data.

              </li>
              
              <li>
                I'm using a built in Tensorflow estimator with Sagemaker, which has optimizations to run TensorFlow on AWS. One more step actually, that I'm coding to do is activating step caching with steps caching. This will help you accelerate and run the different executions more efficient.

              </li>
              
              <li>
                A sagemaker pipeline can be used to train and validate models. It can also prepare the model for deployment later. One nice thing is that you can set a model approval status. This demo shows how to do this.

              </li>
              
              <li>
                In the second phase, we could automatically run pipelines and include automated quality gates. Only models that fall into acceptable performance metrics get registered in the model registry and approved for deployment. Another trigger to rerun a model training and deployment pipeline could be code changes.

              </li>
              
              <li>
                Pipelines runs Sagemaker projects helps you to set up all of the automation needed in the AWS account to build a continuous integration, continuous deployed workflow. Let me walk you through the steps here.

              </li>
              
              <li>
                All right, so let me show you how this automation works. Projects integrate with the developer tools and has this automation built in. This template is also set up to have a two phase deployed. Phase one is deploying in a staging environment, and second stage is deploying into a production environment.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/dTP4J0GcXxg.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:22,250'); seek(22.0)">
              Welcome. In this session I will discuss as
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:25,484'); seek(25.0)">
              how you can take your data science and machine learning projects
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:29,298'); seek(29.0)">
              from idea to production by automating your machine
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,658'); seek(32.0)">
              learning workflows with pipelines.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:35,770'); seek(35.0)">
              Before I start, I want to point out two great learning resources
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,986'); seek(39.0)">
              to follow up on this topic after today's session.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:43,690'); seek(43.0)">
              Besides working as a developer advocate, I'm also an O'Reilly author
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:47,506'); seek(47.0)">
              and coursera instructor. The O'Reilly book data
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:51,236'); seek(51.0)">
              Science on AWS, which I coauthored, discusses in
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:54,932'); seek(54.0)">
              over 500 pages and hundreds of code samples
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:58,298'); seek(58.0)">
              how to implement endtoend, continuous AI and machine learning
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:01,796'); seek(61.0)">
              pipelines. Another great resource is the newly
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:05,838'); seek(65.0)">
              launched practical data science specialization.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:09,038'); seek(69.0)">
              In partnership with deep Learning AI and Casera,
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:13,190'); seek(73.0)">
              this three core specialization teaches you practical
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:16,546'); seek(76.0)">
              skills in how to take your data science and ML projects
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:20,162'); seek(80.0)">
              from idea to production using purpose build tools in
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:24,108'); seek(84.0)">
              the AWS cloud, and it also includes on demand,
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:28,246'); seek(88.0)">
              hands on labs for you to practice.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:32,670'); seek(92.0)">
              So we're talking about automating machine learning.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:36,910'); seek(96.0)">
              Hmm. I have an idea.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,490'); seek(101.0)">
              Alexa deploy my model.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:45,650'); seek(105.0)">
              Which multi armed bandit strategy would you like to use?
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:49,140'); seek(109.0)">
              Thompson sampling Epsilon Greedy or online cover?
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:54,710'); seek(114.0)">
              Well, I'm pretty sure someone already thought about developing
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:58,318'); seek(118.0)">
              this Alexa skill, but unfortunately,
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:01,662'); seek(121.0)">
              getting your machine learning projects ready for production is
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:05,228'); seek(125.0)">
              not just about technology. A term you
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:09,388'); seek(129.0)">
              will likely hear in this context of getting your ML applications
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:12,722'); seek(132.0)">
              ready for production is mlops.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:16,170'); seek(136.0)">
              MLOPs builds on DevOps practices that encompasses
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:20,214'); seek(140.0)">
              people, process and technology.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:23,710'); seek(143.0)">
              However, MLOPs also includes considerations
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:27,478'); seek(147.0)">
              and practices that are really unique to machine learning
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:31,280'); seek(151.0)">
              workflows. So while most of the time we
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:35,012'); seek(155.0)">
              tend to focus on the technology, people and process
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:38,868'); seek(158.0)">
              are equally, if not more important.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:42,390'); seek(162.0)">
              Let's take a look at a few key considerations in ensuring
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:46,510'); seek(166.0)">
              your models and machine learning workloads have
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:49,752'); seek(169.0)">
              a path to production.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:53,750'); seek(173.0)">
              First of all, the machine learning development lifecycle is very
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:57,580'); seek(177.0)">
              different from a software development lifecycle.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:01,290'); seek(181.0)">
              For example, model development includes longer experimentation
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:05,362'); seek(185.0)">
              cycles compared to what you would typically see
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:08,688'); seek(188.0)">
              in an agile software development process.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:12,350'); seek(192.0)">
              You need to consider choosing the right data meets,
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:15,382'); seek(195.0)">
              perform data transformations, and feature engineering.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:19,890'); seek(199.0)">
              So besides the actual model training code, you also
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:23,556'); seek(203.0)">
              need to develop the data processing code.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:27,570'); seek(207.0)">
              Next. The model is typically only a small part
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:31,140'); seek(211.0)">
              of an overall machine learning solution, and there are often
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:34,760'); seek(214.0)">
              more components that need to be built or integrated.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:39,110'); seek(219.0)">
              For example, maybe the model needs to be integrated into an existing
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:43,262'); seek(223.0)">
              application to trigger further process developing on
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:46,988'); seek(226.0)">
              production results. This leads to the next
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:50,492'); seek(230.0)">
              consideration.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:53,930'); seek(233.0)">
              There are typically multiple personas involved in the
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:57,532'); seek(237.0)">
              machine learning development lifecycle, often with competing needs and
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:01,776'); seek(241.0)">
              priorities. A data scientist might feel comfortable
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:06,246'); seek(246.0)">
              in building a models that meets the expected
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:09,382'); seek(249.0)">
              model performance metrics, but might not know how
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:13,172'); seek(253.0)">
              to host that model in a way that it can be consumed
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:16,458'); seek(256.0)">
              by another system or application.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:19,570'); seek(259.0)">
              This part might require a DevOps engineer or the infrastructure
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:23,742'); seek(263.0)">
              team. You also need to integrate
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:27,342'); seek(267.0)">
              the projects with existing it systems and
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:30,808'); seek(270.0)">
              practices, such as change management,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:34,550'); seek(274.0)">
              for example. This could mean that as part of
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:38,476'); seek(278.0)">
              the pipelines, you automatically open a change ticket
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:42,970'); seek(282.0)">
              anytime a new model is ready to get deployed
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:46,706'); seek(286.0)">
              into production. Or you might want to
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:50,208'); seek(290.0)">
              add a manual approval steps in your pipeline before deploying
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:54,182'); seek(294.0)">
              any model into your production.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:57,710'); seek(297.0)">
              If we look at the goal of mlops, you want to move away
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:01,204'); seek(301.0)">
              from manually building models, which is often still
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:04,532'); seek(304.0)">
              the status quo. In the first phase,
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:08,458'); seek(308.0)">
              you can accelerate the path to production by instead of building and
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:12,452'); seek(312.0)">
              managing individual models, start building and managing
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:16,206'); seek(316.0)">
              pipelines. You also want
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:19,608'); seek(319.0)">
              to improve the quality of deployed models. To do
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:23,432'); seek(323.0)">
              this, you need to be able to detect model decay,
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:27,530'); seek(327.0)">
              maybe due to a drift in the statistical changes in
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:30,892'); seek(330.0)">
              data distributions. You should also monitor
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:34,802'); seek(334.0)">
              the models for any drifts in bias or explainability
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:38,678'); seek(338.0)">
              from a set baseline. This can be accomplished
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:42,726'); seek(342.0)">
              in a second phase, and ultimately
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:48,110'); seek(348.0)">
              this should lead into building AI ML solutions
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:51,770'); seek(351.0)">
              that are resilient, secure, performant,
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:55,130'); seek(355.0)">
              operationally efficient, and cost optimized.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:59,730'); seek(359.0)">
              Let's have a close look at each phase.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:04,310'); seek(364.0)">
              Today we often still manually build and manage individual
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:08,488'); seek(368.0)">
              models. We also execute
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:11,902'); seek(371.0)">
              each step in the model development workflow individually.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:16,090'); seek(376.0)">
              Here is an example workflow where a data engineer may create
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:19,996'); seek(379.0)">
              a raw data set and manually send it to a data scientist.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:25,130'); seek(385.0)">
              Then the data scientist iteratively performs
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:29,126'); seek(389.0)">
              data preparation and features. Engineering performs
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:33,382'); seek(393.0)">
              multiple experiments until a training model
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:36,736'); seek(396.0)">
              is actually performing well according to the objective
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:40,118'); seek(400.0)">
              metrics. Then the data scientist
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:44,170'); seek(404.0)">
              may hand it off to a deployment team or an
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:47,332'); seek(407.0)">
              ML engineer who is then responsible for deploying the model.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:52,690'); seek(412.0)">
              If there has been limited communication between teams,
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:56,430'); seek(416.0)">
              this part could result in a lot of delays because the model is
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:00,312'); seek(420.0)">
              essentially intransparent to the deployment engineer or
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:03,768'); seek(423.0)">
              the DevOps team, meaning there is limited visibility into
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:07,868'); seek(427.0)">
              how the model is built or how you consume that model.
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:12,490'); seek(432.0)">
              Then a software engineer potentially needs to make
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:16,412'); seek(436.0)">
              changes to the application, which consumes that
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:19,888'); seek(439.0)">
              model for prediction. And finally,
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:23,440'); seek(443.0)">
              someone ultimately needs to operate the model in production,
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:26,934'); seek(446.0)">
              which includes making sure the right level of monitoring is
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:30,852'); seek(450.0)">
              set up. We can see the challenges
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:34,906'); seek(454.0)">
              in this setup. The workflows includes multiple handoffs
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:38,698'); seek(458.0)">
              between teams and personas who might not
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:42,052'); seek(462.0)">
              all be familiar with machine learning workloads.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:45,910'); seek(465.0)">
              A limited cross team collaboration could lead to limited visibility
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:50,190'); seek(470.0)">
              and transparency using increased code
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:53,928'); seek(473.0)">
              rework, and ultimately slows down the ability to
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:57,772'); seek(477.0)">
              get the model to production quickly. So what
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:01,452'); seek(481.0)">
              can we do in a first
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:04,940'); seek(484.0)">
              phase, we should improve the situation by orchestrating
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:08,646'); seek(488.0)">
              the individual steps. As a pipeline,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:12,270'); seek(492.0)">
              we can also look at automating tasks in each
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:15,456'); seek(495.0)">
              step. For example,
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:19,344'); seek(499.0)">
              we can build a model training pipeline that orchestrating
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:23,162'); seek(503.0)">
              the data preparation, model training, and model evaluation
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:27,210'); seek(507.0)">
              steps. We could also build a deployed
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:31,306'); seek(511.0)">
              pipeline which grabs a model from a model registry and
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:35,176'); seek(515.0)">
              deploys it into a staging environment.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:38,630'); seek(518.0)">
              The software engineers could then use this model to
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:42,168'); seek(522.0)">
              run unit or integration tests before approving
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:45,538'); seek(525.0)">
              the model for production deployment.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:49,610'); seek(529.0)">
              Let's see a demo of a model training pipeline.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:54,090'); seek(534.0)">
              All right, here I am in my AWS demo account,
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:58,430'); seek(538.0)">
              and I want to show you how you can leverage Amazon Sagemaker
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:02,502'); seek(542.0)">
              pipelines to automate the individual steps
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:05,766'); seek(545.0)">
              of building a machine learning model. Amazon Sagemaker is
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:09,632'); seek(549.0)">
              a fully managed service that helps you build, train,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:13,044'); seek(553.0)">
              tune, and deploy your machine learning models.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:17,090'); seek(557.0)">
              All right, so the use case we're going to build is
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:21,170'); seek(561.0)">
              I want to train a natural language process model to
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:25,576'); seek(565.0)">
              classify product reviews. So I'm going to pass in
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:29,192'); seek(569.0)">
              raw text product review text. For example,
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:32,040'); seek(572.0)">
              I really enjoyed reading this book, and my NLP
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:36,302'); seek(576.0)">
              model should classify this into a star rating. So in this case,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:40,188'); seek(580.0)">
              hopefully a star rating of a five the best, or a star
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:43,692'); seek(583.0)">
              rating of 4321, with one being the worst.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:47,930'); seek(587.0)">
              And the way we're doing this, I'm going to use a pretrained
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:52,162'); seek(592.0)">
              bird model. Bird is a very popular model architecture in
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:55,888'); seek(595.0)">
              the NLP states, and what you can leverage is actually
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:59,456'); seek(599.0)">
              pre trained models that have been trained on millions of documents
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:03,382'); seek(603.0)">
              already, for example the Wikipedia. And then you can fine tune it
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:07,108'); seek(607.0)">
              to your specific data set, which I will do in the training step in
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:10,564'); seek(610.0)">
              this pipelines, fine tuning it to my specific product reviews text.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:16,470'); seek(616.0)">
              So the DAC we're going to build here is first process
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:20,328'); seek(620.0)">
              the raw text data to generate the embeddings that
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:23,672'); seek(623.0)">
              the bird model expects as inputs.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:26,730'); seek(626.0)">
              Then in the training step, I'm going to fine tune the model to
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:30,332'); seek(630.0)">
              my data set, and I'm also evaluating
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:34,466'); seek(634.0)">
              the model performance. So in this case, I'm coding the
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:37,872'); seek(637.0)">
              validation accuracy of my model and
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:41,536'); seek(641.0)">
              I'm defining a threshold, a condition. And if my
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:45,584'); seek(645.0)">
              model performs above this threshold,
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:48,790'); seek(648.0)">
              then I'm going to register it to a model registry. Think of
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:52,068'); seek(652.0)">
              it as a catalog of your models to compare the different versions.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:55,674'); seek(655.0)">
              And I'm also preparing for deployment by creating a model object
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:59,620'); seek(659.0)">
              here in Sagemaker. All right,
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:03,288'); seek(663.0)">
              so let's see how we can build this.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:06,630'); seek(666.0)">
              First of all, here I'm importing a couple of sdks
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:10,510'); seek(670.0)">
              and libraries. One of them is the Sagemaker Python SDK
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:15,102'); seek(675.0)">
              and a couple of additional libraries used here in the
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:18,652'); seek(678.0)">
              AWS environment. All right, first of all,
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:21,996'); seek(681.0)">
              I'm going to import or set the location of the raw data
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:25,452'); seek(685.0)">
              set, which is my reviews data here
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:28,956'); seek(688.0)">
              hosted in public s three bucket.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:32,270'); seek(692.0)">
              And what I'm going to do here is I'm pulling a subset of the
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:35,808'); seek(695.0)">
              data just for demo purposes here into my own AWS account.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:40,016'); seek(700.0)">
              So I'm setting a path here to my own bucket,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:43,890'); seek(703.0)">
              and I'm going to pull in just a subset here so the model training doesn't
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:47,658'); seek(707.0)">
              run for too long, and I'm just pulling in three different categories
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:51,834'); seek(711.0)">
              of the product reviews data.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:55,430'); seek(715.0)">
              All right, let's start building the actual pipeline.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:59,110'); seek(719.0)">
              So first of all, I'm creating a name for the pipeline.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:02,974'); seek(722.0)">
              Let's call this my Bird pipeline, and a timestamp.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:08,090'); seek(728.0)">
              And then one nice thing about pipelines is that you
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:11,388'); seek(731.0)">
              can define parameters to parameterize individual executions.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:16,810'); seek(736.0)">
              And now let's start with building the first step, which is the
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:20,048'); seek(740.0)">
              feature engineering. Here's a little bit
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:23,776'); seek(743.0)">
              of explanation what we're going to do. So my raw data set
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:27,856'); seek(747.0)">
              here on the left has star ratings
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:31,366'); seek(751.0)">
              and the review meets. So for example, this is
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:34,788'); seek(754.0)">
              a great item, or I love this book, and the corresponding label,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:38,266'); seek(758.0)">
              which is the star rating. And what I'm going
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:41,428'); seek(761.0)">
              to do in this first features engineering step is I'm using a sagemaker
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:45,598'); seek(765.0)">
              processing job, which helps me to execute code
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:49,208'); seek(769.0)">
              on data, so it's specifically suited if you want to run feature
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:52,686'); seek(772.0)">
              engineering. And I'm converting this raw input data
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:56,716'); seek(776.0)">
              into embeddings that the bird model expects as
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:00,108'); seek(780.0)">
              inputs. All right, so what
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:03,788'); seek(783.0)">
              I'm going to do here again, I'm making sure I have access
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:07,900'); seek(787.0)">
              to my input data, which is now in my own bucket.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:12,110'); seek(792.0)">
              And I start by preparing a couple of those parameters which I
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:15,408'); seek(795.0)">
              want to be able to parameterize. So one
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:18,896'); seek(798.0)">
              is definitely where to find the input data in case the location changes,
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:22,500'); seek(802.0)">
              or I want to use a different data set.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:25,410'); seek(805.0)">
              I'm also specifying the processing job instance count.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:29,876'); seek(809.0)">
              So what I could do, depending on how much data I need to process,
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:33,524'); seek(813.0)">
              I can run this distributed, so I can run it across one
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:37,590'); seek(817.0)">
              AWS cloud instance. I could run it across two instances, five instances,
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:41,502'); seek(821.0)">
              et cetera. And it's as easy as just setting the value to one
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:45,272'); seek(825.0)">
              or five or ten. And the processing job will make sure to
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:49,148'); seek(829.0)">
              distribute the data across the instances and work in parallel.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:53,850'); seek(833.0)">
              In this case, I have a small subset of the data, so I'll stick to
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:57,068'); seek(837.0)">
              one instance. I can also specify here
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:01,344'); seek(841.0)">
              the instance type. So this is the AWS easy two instance type
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:05,456'); seek(845.0)">
              managed by Sagemaker to run this processing job,
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:09,168'); seek(849.0)">
              and I'm just specifying one particular instance type here.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:13,890'); seek(853.0)">
              Then I'm also defining a couple of parameters, which my feature
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:17,626'); seek(857.0)">
              engineering script requires.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:21,090'); seek(861.0)">
              Then I could set parameters such as do I want to balance the
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:24,968'); seek(864.0)">
              data set before and percentages how to
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:28,968'); seek(868.0)">
              split the data into a training set, validation and test data set.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:33,510'); seek(873.0)">
              So in this case, I'm taking 90% for my training data,
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:37,484'); seek(877.0)">
              and I keep a split of 5% for validation and
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:40,892'); seek(880.0)">
              another 5% for test.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:44,570'); seek(884.0)">
              All right, then the step actually needs to perform the
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:48,348'); seek(888.0)">
              feature engineering. So what I've done in preparation is
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:51,552'); seek(891.0)">
              I wrote a Python script which performs the actual transformations,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:55,958'); seek(895.0)">
              and this is here in this Python file.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:58,966'); seek(898.0)">
              So I'm not going to go into all of the glory details. If you're curious
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:02,682'); seek(902.0)">
              how to do this, have a look at the GitHub repo.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:06,370'); seek(906.0)">
              All right, then I can start creating this
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:09,908'); seek(909.0)">
              processing job, and for that I'll
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:13,258'); seek(913.0)">
              define a processor. Here I'm using a prebuilt process based
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:17,576'); seek(917.0)">
              on scikit learn. I'm defining the framework
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:20,926'); seek(920.0)">
              version passing in my IAM role the instance
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:24,606'); seek(924.0)">
              type and the instance count, and also the region I'm operating
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:28,546'); seek(928.0)">
              in. And I need one more thing,
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:32,156'); seek(932.0)">
              because before I wrap it into the official workflow and
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:35,468'); seek(935.0)">
              pipelines step, I need to define the inputs
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:39,270'); seek(939.0)">
              for the job and the outputs. The inputs here
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:43,120'); seek(943.0)">
              is the raw input data,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:46,350'); seek(946.0)">
              and the outputs are s three folders
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:51,194'); seek(951.0)">
              where to store the generated features.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:55,050'); seek(955.0)">
              And I'm also going to split this again by training,
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:57,940'); seek(957.0)">
              validation, and test data meets. So I'm putting here the
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:01,252'); seek(961.0)">
              three locations where the data will be written to,
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:05,030'); seek(965.0)">
              and those internal container paths will get mapped to
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:08,568'); seek(968.0)">
              an s relocation later. All right,
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:12,232'); seek(972.0)">
              and with that I can define the official step as part of
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:15,848'); seek(975.0)">
              my pipeline. So here you can see I'm defining a
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:19,452'); seek(979.0)">
              processing step. I'll give it a name. This is what you
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:22,732'); seek(982.0)">
              saw in the DAC. I point to
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:25,868'); seek(985.0)">
              the actual Python code to execute my feature engineering,
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:29,870'); seek(989.0)">
              and then I'm passing in the scikitlearn processor, which I defined
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:33,750'); seek(993.0)">
              the inputs and the outputs. And here I'm passing
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:37,974'); seek(997.0)">
              the specific job arguments that my script requires.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:41,738'); seek(1001.0)">
              So for example, the training, validation test,
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:44,756'); seek(1004.0)">
              split percentages, et cetera.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:47,490'); seek(1007.0)">
              All right, this defines my processing step.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:52,290'); seek(1012.0)">
              Now let's move on to the second steps, which is fine tuning
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:55,982'); seek(1015.0)">
              the model with the help of a sagemaker training job.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:00,390'); seek(1020.0)">
              And this is pretty similar. So here you can see again I'm defining
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:04,158'); seek(1024.0)">
              parameters, for example, the training instance type and count
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:07,580'); seek(1027.0)">
              again. And then I'm setting up parameters,
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:12,410'); seek(1032.0)">
              the hyperparameters will depend on the models you're using
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:16,060'); seek(1036.0)">
              the use case. So in my case, some general parameters,
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:20,054'); seek(1040.0)">
              number of epics runs throughout the whole data set.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:23,376'); seek(1043.0)">
              And I'm just going to keep this here to one. For this demo purpose,
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:27,318'); seek(1047.0)">
              I'm setting a learning rate and then additional values,
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:31,258'); seek(1051.0)">
              for example, the Epsilon value train, batch sizes,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:34,426'); seek(1054.0)">
              validation batch sizes, et cetera. Again, this will highly
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:38,378'); seek(1058.0)">
              depend on the type of model and use case you are
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:42,788'); seek(1062.0)">
              training. All right,
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:45,670'); seek(1065.0)">
              next, what I'm going to do is I'm also going to capture
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:48,910'); seek(1068.0)">
              the performance of my model during training.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:52,232'); seek(1072.0)">
              So I can specify here regex expressions
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:56,330'); seek(1076.0)">
              that the model training code will output in the logs.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:00,258'); seek(1080.0)">
              So for example, my script that I use will put validation loss
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:04,098'); seek(1084.0)">
              and validation accuracy as an output. And I'm
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:07,778'); seek(1087.0)">
              using here those regex expressions to capture them from
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:11,568'); seek(1091.0)">
              the locks and then also are available in the UI and
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:15,552'); seek(1095.0)">
              for me to check later on in the evaluation step.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:20,030'); seek(1100.0)">
              All right, and I've talked about the training script.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:23,290'); seek(1103.0)">
              So again, I've prepared a Python file which contains the
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:26,628'); seek(1106.0)">
              code to train my model. This is here in the Tfbirdreviews
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:30,666'); seek(1110.0)">
              py file. And again, I'm not going into details. If you're
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:34,058'); seek(1114.0)">
              interested in seeing how to do this, in particular,
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:37,288'); seek(1117.0)">
              how to use this pretrained hugging phase
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:40,430'); seek(1120.0)">
              model and then just fine tune it to the data, please check out
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:44,168'); seek(1124.0)">
              the code in the GitHub repo. All right,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:47,820'); seek(1127.0)">
              so we can now prepare the training estimator and
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:51,868'); seek(1131.0)">
              then build the model training step. So first
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:55,068'); seek(1135.0)">
              of all, I actually need to define the estimator which performs
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:58,518'); seek(1138.0)">
              the training. And I'm using
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:02,704'); seek(1142.0)">
              a built in Tensorflow estimator with Sagemaker, which has
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:06,192'); seek(1146.0)">
              optimizations to run Tensorflow on AWS. And as
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:10,064'); seek(1150.0)">
              you can see here, I'm defining this Tensorflow estimator,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:13,338'); seek(1153.0)">
              pointing to the training script, which I just highlighted,
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:17,514'); seek(1157.0)">
              and also passing in the additional parameters, the role,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:21,402'); seek(1161.0)">
              instance count and type, python version,
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:24,814'); seek(1164.0)">
              tensorflow framework version I want to use. And again,
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:28,200'); seek(1168.0)">
              my hyperparameters, which I defined earlier.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:32,230'); seek(1172.0)">
              One more step actually, that I'm coding to do is activating
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:36,490'); seek(1176.0)">
              step caching with steps caching. What you
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:39,948'); seek(1179.0)">
              can do is make sure if you're rerunning
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:43,314'); seek(1183.0)">
              the pipeline and individual steps might have not have changed to
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:47,452'); seek(1187.0)">
              reuse the previous results. So Sagemaker will apply
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:51,376'); seek(1191.0)">
              this caching to help you accelerate and
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:54,496'); seek(1194.0)">
              run the different executions more efficient.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:57,710'); seek(1197.0)">
              All right? And with that, I can define the training step.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:01,310'); seek(1201.0)">
              So here you can see I define
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:04,778'); seek(1204.0)">
              the official training step. Give it a train. Again, this name,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:08,180'); seek(1208.0)">
              the train will appear in the DAG as you could see before then I'm passing
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:12,138'); seek(1212.0)">
              in this estimator that has all of the tensorflow and training script
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:16,382'); seek(1216.0)">
              configuration, and I'm also training the inputs.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:20,222'); seek(1220.0)">
              And here you can see I'm referring to
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:23,528'); seek(1223.0)">
              the previous process step output and using it
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:27,320'); seek(1227.0)">
              as an input for the training. So those are the features that I generated for
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:31,052'); seek(1231.0)">
              bird training, for bird validation, and for bird test.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:35,450'); seek(1235.0)">
              All right, after the training, there comes the model evaluation.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:40,190'); seek(1240.0)">
              So let's see how I can do this.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:43,710'); seek(1243.0)">
              The model evaluation I can also execute as a processing
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:47,302'); seek(1247.0)">
              job again. So I'm going to use this scikitlearn processor
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:50,694'); seek(1250.0)">
              again specifying the framework version instance
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:54,122'); seek(1254.0)">
              types and counts. The difference here is that I
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:57,508'); seek(1257.0)">
              do have another script to execute. So instead of the feature
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:00,746'); seek(1260.0)">
              engineering, I've now written a script that evaluates the model performance.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:05,910'); seek(1265.0)">
              And again, here is a link to the python script.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:09,270'); seek(1269.0)">
              Basically what I'm going to do is I'm using the pretrained
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:13,262'); seek(1273.0)">
              and fine tuned model from the previous step, and I'm
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:16,818'); seek(1276.0)">
              running some test predictions and see
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:20,730'); seek(1280.0)">
              how the performance is. So in this case, I'm specifically
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:24,786'); seek(1284.0)">
              looking for the validation performance of my model.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:28,830'); seek(1288.0)">
              All right, and the results get written into JSON
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:33,222'); seek(1293.0)">
              file, which I call the evaluation JSON, which is the official evaluation
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:37,510'); seek(1297.0)">
              report from the step. And here's the official
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:41,562'); seek(1301.0)">
              definition. So this is actually implemented as another processing step.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:45,236'); seek(1305.0)">
              In this case I call it evaluate the model.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:48,050'); seek(1308.0)">
              I'm pointing to this new script which runs the validation.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:53,010'); seek(1313.0)">
              And again I'm pointing it here to inputs, which in this case
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:56,856'); seek(1316.0)">
              is the fine tuned model, the model artifact from the training
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:00,120'); seek(1320.0)">
              step, and also again, input data
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:03,944'); seek(1323.0)">
              which I could use to run validation.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:07,050'); seek(1327.0)">
              And I'm also pointing out an output location to store
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:10,796'); seek(1330.0)">
              the evaluation results.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:13,930'); seek(1333.0)">
              All right, the official model metrics are defined in an
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:17,228'); seek(1337.0)">
              object, which I do here, which contain the evaluation
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:21,030'); seek(1341.0)">
              JSON file. All right,
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:24,192'); seek(1344.0)">
              and the last part now is to define the
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:27,712'); seek(1347.0)">
              condition step. So, checking whether my model meets
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:31,498'); seek(1351.0)">
              the expected highquality gate. And if yes,
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:35,124'); seek(1355.0)">
              then register the model to the model registry and also prepare
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:39,018'); seek(1359.0)">
              for deployment. And what I'm going to do here is first
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:42,836'); seek(1362.0)">
              create those steps afterwards, and then I can reference them
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:46,632'); seek(1366.0)">
              in the actual condition step. So let's see this.
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:51,030'); seek(1371.0)">
              And one nice thing that you can do with sagemaker pipelines
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:54,878'); seek(1374.0)">
              is to actually set a model approval status.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:58,466'); seek(1378.0)">
              So when you get a model, you evaluate it. You can specify
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:02,650'); seek(1382.0)">
              whether this has a pending, for example, manual approval.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:06,130'); seek(1386.0)">
              So somebody has to look at the metrics and then approve
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:09,398'); seek(1389.0)">
              it for deployment. You can set it to always approve,
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:13,046'); seek(1393.0)">
              but in this case, I want to show you I keep it to manual approval
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:16,438'); seek(1396.0)">
              only. All right, then I'm
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:20,374'); seek(1400.0)">
              going to define again the instance types and counts, where to later
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:23,700'); seek(1403.0)">
              deploy my model and host it for live predictions.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:28,050'); seek(1408.0)">
              And I'm also specifying the model package group, which is
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:31,860'); seek(1411.0)">
              registered in the model registry. And I'm
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:35,598'); seek(1415.0)">
              defining an image that is used to later deploy
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:39,678'); seek(1419.0)">
              the endpoint and then run the model and the
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:42,808'); seek(1422.0)">
              inference code. So in this case it's going to be a tensorflow based docker image
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:46,834'); seek(1426.0)">
              again. All right, so here is the step that registers
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:50,962'); seek(1430.0)">
              the model. It's taking the estimator object and
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:55,116'); seek(1435.0)">
              the information about the inference image to use.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:58,490'); seek(1438.0)">
              It actually points to the s three location of the fine tuned
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:01,958'); seek(1441.0)">
              model, and it also defines specific input
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:05,398'); seek(1445.0)">
              format types. For example, you know that your model expects JSON lines
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:09,174'); seek(1449.0)">
              as input, and also response is going to
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:12,404'); seek(1452.0)">
              be in JSON lines. Then this might vary, of course, depending on your model.
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:17,170'); seek(1457.0)">
              And you also set here the model package group, where to register
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:21,402'); seek(1461.0)">
              it with, and the approval status. This one will be pending manual approval.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:26,710'); seek(1466.0)">
              All right, then what I'm also going to do here is create a
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:30,920'); seek(1470.0)">
              step to prepare the model for deployment later.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:34,470'); seek(1474.0)">
              So I'm preparing a model object in sagemaker,
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:38,570'); seek(1478.0)">
              again, pass in the inference image and also the artifact.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:44,410'); seek(1484.0)">
              All right, and then I define here
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:47,868'); seek(1487.0)">
              the official create model steps for the pipeline
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:51,390'); seek(1491.0)">
              and pass in the model which I just created.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:54,670'); seek(1494.0)">
              So now we can start in creating this condition check that
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:58,192'); seek(1498.0)">
              comes before. So what
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:02,388'); seek(1502.0)">
              I'm going to do here is I'm importing the conditions
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:06,074'); seek(1506.0)">
              and corresponding functions that are available. For example,
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:09,540'); seek(1509.0)">
              a condition greater than or equal to, and I'm
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:13,162'); seek(1513.0)">
              defining a minimum accuracy value I want to check
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:16,632'); seek(1516.0)">
              against. As this is a demo and I'm just training on a little bit of
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:20,248'); seek(1520.0)">
              data, I'll keep this low so all the model training runs will actually
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:23,896'); seek(1523.0)">
              pass. But obviously in other use cases,
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:27,298'); seek(1527.0)">
              you definitely want to bump up the accuracy threshold. In this case, I'm using
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:30,972'); seek(1530.0)">
              20% as my minimum accuracy to check against.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:36,330'); seek(1536.0)">
              Then here is the definition. So it's going to execute
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:39,526'); seek(1539.0)">
              this check condition greater or equal to.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:43,152'); seek(1543.0)">
              And here is my evaluation step.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:46,640'); seek(1546.0)">
              And I'm also pointing to this report file to generate and
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:51,348'); seek(1551.0)">
              set to this value I created.
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:54,690'); seek(1554.0)">
              And the additional official step is then tuning this
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:58,756'); seek(1558.0)">
              condition. And if I meet the condition.
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:02,442'); seek(1562.0)">
              So if I'm passing my quality threshold, I'm going to register
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:06,670'); seek(1566.0)">
              the model, and I'm also going to create the model in preparation for
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:10,168'); seek(1570.0)">
              later deployment. In the out step you can say,
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:13,816'); seek(1573.0)">
              what else? If I fail the test, right, send a message
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:17,750'); seek(1577.0)">
              to the data scientist or whatever you want to do. In my case, I'm just
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:21,388'); seek(1581.0)">
              keeping it empty so it will fail and end the pipeline.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:25,370'); seek(1585.0)">
              So what we've done now is defining each and every step from
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:28,988'); seek(1588.0)">
              the preprocessing, to the training, to the
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:32,272'); seek(1592.0)">
              condition and preparation for deployment, if I pass my quality threshold.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:37,046'); seek(1597.0)">
              So now I can wrap this in the end to end pipelines definition.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:41,970'); seek(1601.0)">
              First of all, again, I'm importing some of the functions here needed and
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:45,812'); seek(1605.0)">
              objects from the SDK. And as you can see here,
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:49,252'); seek(1609.0)">
              I'm now creating the official pipeline object passing
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:53,098'); seek(1613.0)">
              in the name that we created, and all of the parameters which
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:57,032'); seek(1617.0)">
              I specified in the above code. And then the
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:00,792'); seek(1620.0)">
              steps here will actually line up the individual steps in
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:04,488'); seek(1624.0)">
              this stack. So let's start with the processing, then move
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:08,092'); seek(1628.0)">
              to the training step, do the evaluation step,
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:11,276'); seek(1631.0)">
              and then you have this condition step to evaluate the models,
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:15,050'); seek(1635.0)">
              which will in itself trigger the two different
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:19,150'); seek(1639.0)">
              path depending on if I pass the quality check.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:22,990'); seek(1642.0)">
              I'm also adding this to an official experiment tracking, so I
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:26,384'); seek(1646.0)">
              can keep track of my pipeline runs, and that's the definition
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:30,278'); seek(1650.0)">
              of my pipelines. And then I can submit the pipeline for execution.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:34,290'); seek(1654.0)">
              So I'm calling the pipeline create passing a role that has
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:37,748'); seek(1657.0)">
              the permissions to execute everything. And then what I
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:41,188'); seek(1661.0)">
              can do is I can call the pipelines start,
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:44,630'); seek(1664.0)">
              which will start an individual execution run of this pipeline.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:49,190'); seek(1669.0)">
              And you can see here also you can pass in
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:52,408'); seek(1672.0)">
              now your parameter values,
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:55,294'); seek(1675.0)">
              and that will kick off the pipelines in the background.
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:58,786'); seek(1678.0)">
              But this will run now on AWS with the sagemaker processing
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:02,978'); seek(1682.0)">
              job, the training job, and also run the model evaluation.
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:06,650'); seek(1686.0)">
              And what I also want to show you is that Sagemaker
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:10,198'); seek(1690.0)">
              keeps track of the individual artifacts that are generated in each step.
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:14,208'); seek(1694.0)">
              So what I'm doing here is I'm listing all artifacts
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:17,382'); seek(1697.0)">
              generated by this pipelines. And this is super helpful
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:21,302'); seek(1701.0)">
              if you want to keep track of the individual steps.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:24,554'); seek(1704.0)">
              And for example, what were the inputs in this case for
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:27,908'); seek(1707.0)">
              the processing job, I do have the raw data. I do
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:31,252'); seek(1711.0)">
              have the docker image that's used to process the data.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:35,190'); seek(1715.0)">
              And the output is the generated features, and you
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:38,984'); seek(1718.0)">
              can see here contributed to or production.
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:43,510'); seek(1723.0)">
              Then in the training step, you have the generated features,
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:46,622'); seek(1726.0)">
              training features as the input and the image to
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:49,948'); seek(1729.0)">
              execute the training job. And the output here would be
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:53,388'); seek(1733.0)">
              the model artifact. So really nice to keep track of
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:56,988'); seek(1736.0)">
              those artifacts for each step. And with that,
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:00,816'); seek(1740.0)">
              we can come back to actually checking on our pipeline.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:04,662'); seek(1744.0)">
              So I'm going to go back here in the pipelines.
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:08,342'); seek(1748.0)">
              You can check on the graph, and this is the overall graph that we defined
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:12,250'); seek(1752.0)">
              so it matches our steps.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:16,850'); seek(1756.0)">
              You can check the parameters. Again, you set the settings,
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:20,554'); seek(1760.0)">
              you can click into the individual graph, and the color coding
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:24,622'); seek(1764.0)">
              here shows green means it completed successfully. You can
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:28,632'); seek(1768.0)">
              click into each step and again see the parameters here
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:32,344'); seek(1772.0)">
              that were used to run and execute the step.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:36,390'); seek(1776.0)">
              All right, what I also want to show you is the model registry.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:40,730'); seek(1780.0)">
              So let me go here in the navigation also to the model
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:44,076'); seek(1784.0)">
              registry. And we do see here our model group,
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:47,950'); seek(1787.0)">
              the bird reviews and here is my model
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:52,096'); seek(1792.0)">
              version. And again, I've set this
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:55,312'); seek(1795.0)">
              to manual approval. So this one here
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:58,672'); seek(1798.0)">
              will still need my approval to be deployed into
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:02,436'); seek(1802.0)">
              production. I can update the status
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:06,842'); seek(1806.0)">
              and set it here to approved and
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:10,276'); seek(1810.0)">
              say this is good for
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:14,728'); seek(1814.0)">
              deployment into staging
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:19,350'); seek(1819.0)">
              update. And with that the
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:22,968'); seek(1822.0)">
              model is now approved for deployments and
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:26,668'); seek(1826.0)">
              this completes the first demo.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:30,650'); seek(1830.0)">
              In the second phase, we could automatically run pipelines
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:34,834'); seek(1834.0)">
              and include automated quality gates.
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:38,030'); seek(1838.0)">
              So here the model training pipeline could automatically
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:41,990'); seek(1841.0)">
              evaluate the model in terms of model performance
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:45,478'); seek(1845.0)">
              or bias metrics and thresholds.
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:48,990'); seek(1848.0)">
              Only models that fall into acceptable performance
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:52,938'); seek(1852.0)">
              metrics get registered in the model registry and
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:56,996'); seek(1856.0)">
              approved for deployment. The deployment pipeline
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:00,746'); seek(1860.0)">
              could leverage deployment strategies such as a b testing
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:04,926'); seek(1864.0)">
              or bandits to evaluate the model in comparison
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:08,846'); seek(1868.0)">
              to existing models. The software engineer can
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:12,920'); seek(1872.0)">
              automate the integration tests with pass fail
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:16,626'); seek(1876.0)">
              highquality gates, and only models that passes
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:19,874'); seek(1879.0)">
              get deployed into production. And finally,
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:23,596'); seek(1883.0)">
              the operation team sets up model monitoring and analyzes
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:27,842'); seek(1887.0)">
              for any data drift or models drift.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:31,230'); seek(1891.0)">
              If the drift is violating defined threshold values,
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:35,030'); seek(1895.0)">
              this could actually trigger a model retraining pipeline.
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:38,326'); seek(1898.0)">
              Again, another trigger to rerun a model
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:42,516'); seek(1902.0)">
              training and deployment pipeline could be code changes
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:46,052'); seek(1906.0)">
              as part of a continuous integrations and continuous
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:49,722'); seek(1909.0)">
              delivery. Short CI CD automation let's
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:54,798'); seek(1914.0)">
              see another demo of a code change triggered pipelines
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:58,622'); seek(1918.0)">
              run all right, I'm back in
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:02,088'); seek(1922.0)">
              my AWS demo account. Now I want to
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:05,788'); seek(1925.0)">
              show you how you can leverage Sagemaker projects
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:09,698'); seek(1929.0)">
              to automate workflows. Pipelines runs Sagemaker
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:13,682'); seek(1933.0)">
              projects helps you to set up all of the automation
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:17,474'); seek(1937.0)">
              needed in the AWS account to build a
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:20,704'); seek(1940.0)">
              continuous integration, continuous deployed workflow.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:25,150'); seek(1945.0)">
              The easiest way to get started is if you navigate here
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:28,656'); seek(1948.0)">
              in the menu to projects and then
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:32,240'); seek(1952.0)">
              create project. You can see that it already comes with a
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:36,084'); seek(1956.0)">
              couple of prebuilt templates which you can use.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:39,252'); seek(1959.0)">
              So one template will set up all of the automation
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:42,874'); seek(1962.0)">
              for a model building and training pipeline and automation.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:47,270'); seek(1967.0)">
              The other one is for model deployment. And what I've pre provisioned
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:51,182'); seek(1971.0)">
              here is a CI CD environment for
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:55,032'); seek(1975.0)">
              model building, training and the actual model deployment.
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:58,898'); seek(1978.0)">
              I've already pre built everything, so let me walk you
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:02,636'); seek(1982.0)">
              through the steps here. Programmatically,
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:05,690'); seek(1985.0)">
              Sagemaker project is based on an AWS service
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:08,960'); seek(1988.0)">
              catalog product. So the first step is to reusable sagemaker
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:13,254'); seek(1993.0)">
              projects here in the studio environment.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:16,990'); seek(1996.0)">
              Then I'm again importing all of the needed sdks and
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:20,612'); seek(2000.0)">
              libraries and set the clients, and I'm
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:24,698'); seek(2004.0)">
              coding it here programmatically. But again, if you're coding the template
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:28,458'); seek(2008.0)">
              through the UI, this is done for you. I've provisioned the service
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:32,660'); seek(2012.0)">
              catalog item and the template here programmatically through my notebook.
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:37,430'); seek(2017.0)">
              Once the project is created,
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:40,302'); seek(2020.0)">
              you can see here on the left that I do have this entry. Now for
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:43,992'); seek(2023.0)">
              projects, I can select it. And what
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:47,612'); seek(2027.0)">
              will happen here in the first step is that sagemaker projects
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:51,426'); seek(2031.0)">
              will create two code commit repos for
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:33:54,572'); seek(2034.0)">
              you in this AWS account you're using. So here
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:33:58,032'); seek(2038.0)">
              you can see I do have two repos,
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:00,910'); seek(2040.0)">
              one for the model build and training pipelines,
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:04,486'); seek(2044.0)">
              and one for the model deployment pipeline.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:08,350'); seek(2048.0)">
              And all of the automation is set up. So whenever I
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:12,148'); seek(2052.0)">
              commit code, push code to those repos, that will actually
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:16,164'); seek(2056.0)">
              trigger a pipeline execution. And I'll show you
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:19,268'); seek(2059.0)">
              how this looks like. So, back here in
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:22,980'); seek(2062.0)">
              my main notebook, the first thing I'm also doing in this
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:26,328'); seek(2066.0)">
              notebook here is to clone those code commit repos
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:30,350'); seek(2070.0)">
              locally into my sagemaker studio environment.
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:33,998'); seek(2073.0)">
              So this is what I'm running here for both code repos.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:39,050'); seek(2079.0)">
              I'm also removing one of the sample repos
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:42,450'); seek(2082.0)">
              encode that are in here. And I'm
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:46,178'); seek(2086.0)">
              triggering the first execution of the pipeline by
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:34:50,176'); seek(2090.0)">
              actually copying over my sample pipeline that I've
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:34:54,118'); seek(2094.0)">
              built before in the demo. So if I go to the file
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:34:57,718'); seek(2097.0)">
              browser here on the left, you can see
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:01,056'); seek(2101.0)">
              I've cloned down those model, build and model, deploy code,
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:04,692'); seek(2104.0)">
              commit repos, and I can click into those.
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:08,132'); seek(2108.0)">
              And I do have all of the needed code already set up
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:11,540'); seek(2111.0)">
              all of the triggers in the AWS account. So what I
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:15,048'); seek(2115.0)">
              can do here is in pipelines, I just need
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:18,648'); seek(2118.0)">
              to add my own pipeline execution code that I want to run
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:22,296'); seek(2122.0)">
              on the code change. So if I go in here,
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:25,432'); seek(2125.0)">
              you will see I'm using the exact same Python scripts for pre
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:29,272'); seek(2129.0)">
              processing, for model training, and for entrance that I've showed
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:32,914'); seek(2132.0)">
              you before when I was manually building this pipelines. So especially
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:37,068'); seek(2137.0)">
              the pipeline py file. If I open this one, this should
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:41,088'); seek(2141.0)">
              look pretty familiar to you. Hopefully this contains exactly
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:45,024'); seek(2145.0)">
              the code that I've been showing you before when I
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:35:48,544'); seek(2148.0)">
              was building the pipeline in the notebook. The only difference
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:35:52,148'); seek(2152.0)">
              here is that I'm now tuning this in the
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:35:55,636'); seek(2155.0)">
              Python file. Programmatically, when I trigger the pipeline,
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:35:59,338'); seek(2159.0)">
              run back to my notebook
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:03,166'); seek(2163.0)">
              here. So what I've done is I've cloned
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:07,198'); seek(2167.0)">
              the repos here, and I'm coding over my
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:10,952'); seek(2170.0)">
              sample code into those repos,
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:14,230'); seek(2174.0)">
              and then I'm committing them into the code commit.
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:18,322'); seek(2178.0)">
              And you can see here it detected that I have removed some sample code.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:21,964'); seek(2181.0)">
              And I've also added my own pipeline
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:25,842'); seek(2185.0)">
              code. So that should be enough changes hopefully, to the repo.
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:30,830'); seek(2190.0)">
              I'm making sure I keep track of all the variables I'm using here.
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:35,070'); seek(2195.0)">
              And again, here's the pipeline py file, which I just showed you,
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:38,352'); seek(2198.0)">
              which contains the pipeline code to run. And this is
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:42,048'); seek(2202.0)">
              exactly what I have set up before.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:45,090'); seek(2205.0)">
              And when I was doing the code commit
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:36:48,890'); seek(2208.0)">
              and the code push to the repo, this set up all
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:36:52,468'); seek(2212.0)">
              of the CI CD automation that the template set up for you in the AWS
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:36:56,606'); seek(2216.0)">
              account and started the pipeline run. So if I
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:37:00,328'); seek(2220.0)">
              go down here into my projects again and
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:37:04,520'); seek(2224.0)">
              click on pipelines, I can actually see
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:37:07,964'); seek(2227.0)">
              that here is a pipeline that got started and
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:37:12,108'); seek(2232.0)">
              I can select it and it has a succeeded execution
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:37:15,586'); seek(2235.0)">
              run already. So I've started this sometime before
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:20,750'); seek(2240.0)">
              the session. All right, so let me show
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:24,288'); seek(2244.0)">
              you how this automation works. So what happens
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:28,192'); seek(2248.0)">
              is that projects integrate with the
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:32,468'); seek(2252.0)">
              developer tools, for example with code pipelines and
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:36,500'); seek(2256.0)">
              has this automation built in. So the first step, as you can see here,
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:40,356'); seek(2260.0)">
              is creating the source code needed,
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:44,168'); seek(2264.0)">
              and then it's going to build and start the pipelines execution
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:37:48,526'); seek(2268.0)">
              run. And this is done with code
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:37:51,816'); seek(2271.0)">
              build. So if I now jump into the build projects,
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:37:55,990'); seek(2275.0)">
              you can see here that our build projects
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:37:59,106'); seek(2279.0)">
              already in place. And the first one is
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:38:02,348'); seek(2282.0)">
              the model training pipelines, which just succeeded. You can
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:38:05,932'); seek(2285.0)">
              also see that the model deploy is currently in a failed state,
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:38:09,120'); seek(2289.0)">
              and this is because it doesn't have an approved model yet
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:38:12,768'); seek(2292.0)">
              to actually deploy. This template is
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:16,192'); seek(2296.0)">
              also set up to have a two phase deployed.
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:19,046'); seek(2299.0)">
              Phase one is deploying in a staging environment,
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:22,234'); seek(2302.0)">
              which for example a data scientist could approve after
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:38:26,116'); seek(2306.0)">
              evaluating the model. And then also it comes with a
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:38:29,412'); seek(2309.0)">
              second stage to deploy into a production environment,
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:38:32,906'); seek(2312.0)">
              which would most likely be another team to approve.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:38:36,078'); seek(2316.0)">
              For example, the integrations team, the DevOps team, the infrastructure
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:38:39,982'); seek(2319.0)">
              teams. So I can click here into the code
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:38:43,656'); seek(2323.0)">
              pipeline and I can see that my latest run here succeeded.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:38:47,666'); seek(2327.0)">
              The first one is the one I stopped and deployed from the sample
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:38:51,538'); seek(2331.0)">
              code. So let's go back
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:38:55,004'); seek(2335.0)">
              here to my environment.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:38:58,850'); seek(2338.0)">
              So what I need to do once the pipeline has
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:39:02,528'); seek(2342.0)">
              executed, I can list the steps again here.
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:39:05,552'); seek(2345.0)">
              I can see everything looks good. I can also list
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:39:09,088'); seek(2349.0)">
              the artifacts again. And this looks familiar to
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:39:13,028'); seek(2353.0)">
              the one I showed before. It's the exact same pipeline,
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:39:16,530'); seek(2356.0)">
              all the artifacts that contributed to each steps.
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:39:19,810'); seek(2359.0)">
              What I do have here now is a last step.
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:39:23,412'); seek(2363.0)">
              That is an approval that is needed to actually deploy
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:39:27,342'); seek(2367.0)">
              this model into the staging environment.
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:39:30,470'); seek(2370.0)">
              And if you can remember in the previous demo, I showed you how to
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:39:34,872'); seek(2374.0)">
              approve the model here through the studio UI.
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:39:38,730'); seek(2378.0)">
              What I can do now here as well is to approve it
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:39:42,316'); seek(2382.0)">
              through the API programmatically. And this is what I'm
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:39:45,714'); seek(2385.0)">
              going to do here. So, in here, I'm looking for
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:39:49,520'); seek(2389.0)">
              the executions and I'm grabbing
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:39:53,430'); seek(2393.0)">
              the model package arn where we registered the
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:39:57,008'); seek(2397.0)">
              model. And then I'm going to update
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:40:00,278'); seek(2400.0)">
              the model package here and approve it for deployment
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:40:04,090'); seek(2404.0)">
              into this first stage, which is the staging environment.
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:40:08,450'); seek(2408.0)">
              So here I'm going to update the model package. I'm setting the
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:40:12,452'); seek(2412.0)">
              status to approved, and then I can check
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:40:15,832'); seek(2415.0)">
              here for the model name, and we'll
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:40:19,118'); seek(2419.0)">
              see that the model starts to get deployed into the staging
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:40:22,942'); seek(2422.0)">
              environment. Let's see the
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:40:26,396'); seek(2426.0)">
              deployed pipeline. So what happens here is
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:40:30,476'); seek(2430.0)">
              once I've approved the model for staging,
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:40:33,714'); seek(2433.0)">
              it actually started the second pipelines
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:40:38,166'); seek(2438.0)">
              here, which is the model deploy.
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:40:41,390'); seek(2441.0)">
              And you can see here it started building the source, and it's
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:40:44,998'); seek(2444.0)">
              currently in progress deploying the model into the defined staging environment.
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:40:50,610'); seek(2450.0)">
              I can also have a look here. So I'm looking
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:40:54,580'); seek(2454.0)">
              at the endpoint that this pipelines will set up.
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:40:58,484'); seek(2458.0)">
              So if I click here,
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:41:01,970'); seek(2461.0)">
              I will see now that here is an endpoint being created on
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:41:05,752'); seek(2465.0)">
              Sagemaker for the staging environment. So this
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:41:09,688'); seek(2469.0)">
              will take a few minutes for the endpoint to be
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:41:13,224'); seek(2473.0)">
              ready. All right, the endpoint is
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:41:16,972'); seek(2476.0)">
              now in service. And if I click in here, I can see
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:41:21,164'); seek(2481.0)">
              the rest API I could call to get
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:41:24,700'); seek(2484.0)">
              predictions from my model. Now, let's check
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:41:28,332'); seek(2488.0)">
              this. In the notebook here, you can see the endpoint is in
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:41:32,192'); seek(2492.0)">
              service. And what I do here is I pull in
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:41:35,664'); seek(2495.0)">
              a Tensorflow predictor object, which I can create,
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:41:39,550'); seek(2499.0)">
              and then I'm going to pass in some sample reviews.
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:41:43,462'); seek(2503.0)">
              Let's say this is great, and I can run this,
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:41:46,692'); seek(2506.0)">
              pass it to the predictor, and you can see I get a prediction result
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:41:50,740'); seek(2510.0)">
              back from my model deployed in the staging environment.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:41:53,582'); seek(2513.0)">
              Predicting this is a five star rating. Let's have a look at
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:41:57,560'); seek(2517.0)">
              the code pipeline that we executed.
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:42:02,230'); seek(2522.0)">
              So you can see here that the staging
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:42:06,658'); seek(2526.0)">
              succeeded. But there is one more approval
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:42:10,562'); seek(2530.0)">
              needed here for the actual deployment into a
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:42:14,188'); seek(2534.0)">
              production environment. So this could really be something
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:42:17,500'); seek(2537.0)">
              that another team handles. So if I'm the DevOps
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:42:21,222'); seek(2541.0)">
              engineer, the integration engineer, I could make sure I'm running all
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:42:24,848'); seek(2544.0)">
              of the tests that I need with this model. Now that is hosted in the
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:42:28,464'); seek(2548.0)">
              staging environment. And if I agree
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:42:32,148'); seek(2552.0)">
              that it's good to be deployed into production, I could
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:42:35,812'); seek(2555.0)">
              either use here the code pipelines to
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:42:39,860'); seek(2559.0)">
              approve the model and deploy to production,
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:42:43,934'); seek(2563.0)">
              or I can also obviously do this programmatically,
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:42:47,670'); seek(2567.0)">
              which is what I'm doing here now in the notebook. So again,
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:42:52,008'); seek(2572.0)">
              I review the pipelines and what I'm doing here,
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:42:56,028'); seek(2576.0)">
              exact same thing is that I'm programmatically approving
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:42:59,490'); seek(2579.0)">
              this for deployment in production.
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:43:03,122'); seek(2583.0)">
              You can see this succeeded. Let's actually check our
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:43:06,636'); seek(2586.0)">
              pipelines and there we go.
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:43:09,888'); seek(2589.0)">
              You can see it took the approval and is currently now
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:43:13,728'); seek(2593.0)">
              working on deploying this model into the production
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:43:17,062'); seek(2597.0)">
              environment. As pointed out earlier,
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:43:20,794'); seek(2600.0)">
              the ultimate goal is to build AI ML solutions that are
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:43:24,292'); seek(2604.0)">
              secure, resilient, cost optimized,
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:43:27,322'); seek(2607.0)">
              performant and operationally efficient.
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:43:31,010'); seek(2611.0)">
              So in addition to the operational excellence which we discussed in
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:43:34,968'); seek(2614.0)">
              the context of mlops, you also need to incorporate standard
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:43:38,824'); seek(2618.0)">
              practices in each of these areas.
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:43:42,870'); seek(2622.0)">
              Here are a few links to get you started. First,
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:43:46,392'); seek(2626.0)">
              a link to the data science on AWS resources and
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:43:50,012'); seek(2630.0)">
              the GitHub repo which contains all of the code samples I've showed.
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:43:54,570'); seek(2634.0)">
              Also here are links to the Amazon Sagemaker pipelines
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:43:58,326'); seek(2638.0)">
              and the great blog post.
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:44:01,470'); seek(2641.0)">
              Again, if you are looking for more comprehensive learning resources,
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:44:06,118'); seek(2646.0)">
              check out the O'Reilly book data Science on AWS, which covers
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:44:10,570'); seek(2650.0)">
              how to implement endtoend, continuous AI and machine learning pipelines
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:44:14,698'); seek(2654.0)">
              in over twelve chapters, 500 pages, and hundreds of additional
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:44:18,986'); seek(2658.0)">
              code samples. Another great
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:44:22,676'); seek(2662.0)">
              training resource is our newly launched practical data science
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:44:26,266'); seek(2666.0)">
              specialization in partnership with deep learning AI and Coursera.
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:44:31,650'); seek(2671.0)">
              This three course specialization teaches you practicals
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:44:35,034'); seek(2675.0)">
              skills in how to take your data science and machine learning projects
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:44:38,850'); seek(2678.0)">
              from idea to production using purpose built tools in the
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:44:42,668'); seek(2682.0)">
              AWS cloud. This also includes on
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:44:46,028'); seek(2686.0)">
              demand, hands on labs for you to practice.
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:44:50,250'); seek(2690.0)">
              This concludes the session. Thanks for watching.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Machine%20Learning%202021%20Slides%20-%20Antje%20Barth.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Machine%20Learning%202021%20Slides%20-%20Antje%20Barth.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2021" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 23 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/ml_antje.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Antje Barth
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Developer Advocate - AI & ML @ Amazon Web Services
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/antje-barth/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Antje Barth's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@anbarth" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Antje Barth's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @anbarth"
                  data-url="https://www.conf42.com/ml2021"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2021"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Machine Learning"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>