<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Build cloud native open format data lakehouse</title>
    <meta name="description" content="Everything Cloud Native and Cloud Security. It came from the Cloud!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/cloud_satish_mane_rajeev_jaiiswal.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Build cloud native open format data lakehouse | Conf42"/>
    <meta property="og:description" content="As data lakes are growing and getting notoriously messy, companies struggle to change data in order to implement GDPR,CCPA data regulations as to how customer data can be used. So this session covers journey to data lake house architecture using open source table format and cloud native services"/>
    <meta property="og:url" content="https://conf42.com/Cloud_Native_2023_Satish_Mane_Rajeev_Jaiiswal_build_open_format_data_lakehouse"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #7B2726;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Cloud Native 2023 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Everything Cloud Native and Cloud Security. It came from the Cloud!
 -->
              <script>
                const event_date = new Date("2023-03-30T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2023-03-30T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "znNHrHKKmXE"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "gjU-X6YnV1A"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrAzg7Gi1KUCWAq8xF2rE53-" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, my name is Satish Mane. I will talk about data lake table", "timestamp": "00:00:34,530", "timestamp_s": 34.0}, {"text": "formats and their integration with AWS Analytics Services to", "timestamp": "00:00:38,082", "timestamp_s": 38.0}, {"text": "build cloud native data lake house on AWS Cloud.", "timestamp": "00:00:41,772", "timestamp_s": 41.0}, {"text": "Hi, my name is Rajeev Jaiiswal. In this session I\u0027ll take", "timestamp": "00:00:45,004", "timestamp_s": 45.0}, {"text": "you on a journey to Data Lake. Thanks for joining in.", "timestamp": "00:00:48,892", "timestamp_s": 48.0}, {"text": "Before we dive further, let\u0027s first understand couple of trends we", "timestamp": "00:00:52,900", "timestamp_s": 52.0}, {"text": "see in businesses. The first one is expectation of the customers.", "timestamp": "00:00:56,868", "timestamp_s": 56.0}, {"text": "In the digital era, customers expect the kind of", "timestamp": "00:01:01,028", "timestamp_s": 61.0}, {"text": "experience they get from Airbnb, Uber and all", "timestamp": "00:01:04,328", "timestamp_s": 64.0}, {"text": "these technologies. Apart from these experiences, the BDI is", "timestamp": "00:01:07,672", "timestamp_s": 67.0}, {"text": "personalized, demonstrating a true understanding", "timestamp": "00:01:11,688", "timestamp_s": 71.0}, {"text": "of a customer and their context. People\u0027s expectations", "timestamp": "00:01:14,862", "timestamp_s": 74.0}, {"text": "vary from industry to industry as we offer contextually.", "timestamp": "00:01:18,798", "timestamp_s": 78.0}, {"text": "The second trend is new data volume.", "timestamp": "00:01:23,290", "timestamp_s": 83.0}, {"text": "Data is growing at an unprecedented rate,", "timestamp": "00:01:26,730", "timestamp_s": 86.0}, {"text": "exploiting from terabyte to petabyte and sometimes exabytes.", "timestamp": "00:01:29,904", "timestamp_s": 89.0}, {"text": "Traditional on premise data analytics approaches do not scale", "timestamp": "00:01:35,470", "timestamp_s": 95.0}, {"text": "well and are too expensive to handle these volumes of data.", "timestamp": "00:01:38,902", "timestamp_s": 98.0}, {"text": "We often hear from businesses that they are trying to", "timestamp": "00:01:43,490", "timestamp_s": 103.0}, {"text": "extract more value from their data, but are struggling to capture,", "timestamp": "00:01:46,612", "timestamp_s": 106.0}, {"text": "store and analyze all the data generated by today\u0027s modern", "timestamp": "00:01:50,266", "timestamp_s": 110.0}, {"text": "digital business. Data grow exponentially.", "timestamp": "00:01:53,902", "timestamp_s": 113.0}, {"text": "They come from new sources, are becoming more diverse, and need to", "timestamp": "00:01:57,934", "timestamp_s": 117.0}, {"text": "be securedly accessed and analyzed by any number of applications", "timestamp": "00:02:01,544", "timestamp_s": 121.0}, {"text": "and people. All this brings us", "timestamp": "00:02:05,970", "timestamp_s": 125.0}, {"text": "to the subject of technology. Before diving into the broader analytics", "timestamp": "00:02:09,532", "timestamp_s": 129.0}, {"text": "architecture, let\u0027s first understand how legacy or traditional on", "timestamp": "00:02:13,842", "timestamp_s": 133.0}, {"text": "premise data analytics stacks up. There is typically", "timestamp": "00:02:17,308", "timestamp_s": 137.0}, {"text": "an operating system and database for storing customer records", "timestamp": "00:02:21,222", "timestamp_s": 141.0}, {"text": "and transactions, followed by a reporting", "timestamp": "00:02:24,886", "timestamp_s": 144.0}, {"text": "database for data Mart and data lakehouse. Type use cases there", "timestamp": "00:02:28,550", "timestamp_s": 148.0}, {"text": "are four main problems with the type of architecture.", "timestamp": "00:02:33,188", "timestamp_s": 153.0}, {"text": "First, the analytics implementation cycle is too long,", "timestamp": "00:02:36,210", "timestamp_s": 156.0}, {"text": "as moving data sets and building dashboard can take weeks or", "timestamp": "00:02:39,940", "timestamp_s": 159.0}, {"text": "even months. The second issue is scalability,", "timestamp": "00:02:43,288", "timestamp_s": 163.0}, {"text": "higher cost because you always have to plan ahead to", "timestamp": "00:02:47,750", "timestamp_s": 167.0}, {"text": "buy more hardware and pay for more licenses.", "timestamp": "00:02:51,048", "timestamp_s": 171.0}, {"text": "Third, this architecture is not suitable for modern analytics use cases", "timestamp": "00:02:54,158", "timestamp_s": 174.0}, {"text": "such as machine learning adapt queries for data sciences use cases.", "timestamp": "00:02:58,018", "timestamp_s": 178.0}, {"text": "Finally, organizations struggle to keep up with the", "timestamp": "00:03:02,410", "timestamp_s": 182.0}, {"text": "pace of changing business needs.", "timestamp": "00:03:05,564", "timestamp_s": 185.0}, {"text": "Now, how you can solve all these problems?", "timestamp": "00:03:09,710", "timestamp_s": 189.0}, {"text": "The answer is data lake. A data lake makes it easier to", "timestamp": "00:03:13,470", "timestamp_s": 193.0}, {"text": "derive insights from all your data by providing a single place", "timestamp": "00:03:17,072", "timestamp_s": 197.0}, {"text": "to access structured data, semi structured data", "timestamp": "00:03:21,092", "timestamp_s": 201.0}, {"text": "and unstructured data. Customers need highly", "timestamp": "00:03:24,308", "timestamp_s": 204.0}, {"text": "scalable, highly available, secure and flexible data", "timestamp": "00:03:27,738", "timestamp_s": 207.0}, {"text": "store that can handle very large data sets at a reasonable", "timestamp": "00:03:30,996", "timestamp_s": 210.0}, {"text": "cost. Therefore, three key points are important for data lakes", "timestamp": "00:03:35,182", "timestamp_s": 215.0}, {"text": "data in its original form and format, no matter how much,", "timestamp": "00:03:39,830", "timestamp_s": 219.0}, {"text": "what kind, and how fast it is generated.", "timestamp": "00:03:43,784", "timestamp_s": 223.0}, {"text": "Structures and processing rules should be defined only when", "timestamp": "00:03:47,130", "timestamp_s": 227.0}, {"text": "necessary. Also, known as reading schema. As data", "timestamp": "00:03:50,492", "timestamp_s": 230.0}, {"text": "is used by large community, we need to democratize data.", "timestamp": "00:03:54,396", "timestamp_s": 234.0}, {"text": "What you are seeing is a high level architecture of data lake in the cloud", "timestamp": "00:04:01,610", "timestamp_s": 241.0}, {"text": "as a low cost, durable and scalable storage. Amazon S", "timestamp": "00:04:06,670", "timestamp_s": 246.0}, {"text": "three provides storage layer that is completely decoupled from", "timestamp": "00:04:10,288", "timestamp_s": 250.0}, {"text": "data processing and various big data tools and has a zero", "timestamp": "00:04:13,972", "timestamp_s": 253.0}, {"text": "operation over it. Customer can choose a data lake file format such", "timestamp": "00:04:17,876", "timestamp_s": 257.0}, {"text": "as Apache, Parquet, spark powered AWS services", "timestamp": "00:04:21,444", "timestamp_s": 261.0}, {"text": "such as AWS, Glow, Amazon, EMR and Athena enables", "timestamp": "00:04:25,384", "timestamp_s": 265.0}, {"text": "access and compute at scale. The meta level stores metadata", "timestamp": "00:04:29,598", "timestamp_s": 269.0}, {"text": "about tables, columns and partitions in the AWS glue catalog.", "timestamp": "00:04:34,398", "timestamp_s": 274.0}, {"text": "To keep the data in its original form and format, you need the ability to", "timestamp": "00:04:40,490", "timestamp_s": 280.0}, {"text": "handle various file formats such as JSON, CSV, Parquet,", "timestamp": "00:04:44,108", "timestamp_s": 284.0}, {"text": "Avro and more. Each format is suitable for", "timestamp": "00:04:47,602", "timestamp_s": 287.0}, {"text": "different use cases. For example,", "timestamp": "00:04:51,168", "timestamp_s": 291.0}, {"text": "CSV is popular for its low volume and human readable format.", "timestamp": "00:04:53,710", "timestamp_s": 293.0}, {"text": "CSV is what we call the line storage parquet", "timestamp": "00:04:57,654", "timestamp_s": 297.0}, {"text": "file. Organize data into column column store files", "timestamp": "00:05:02,074", "timestamp_s": 302.0}, {"text": "are more optimized because you can perform better compression on", "timestamp": "00:05:05,802", "timestamp_s": 305.0}, {"text": "each column. Parquet is well suited for bulk processing", "timestamp": "00:05:09,172", "timestamp_s": 309.0}, {"text": "of complex data.", "timestamp": "00:05:13,226", "timestamp_s": 313.0}, {"text": "Now you understand the data lake component.", "timestamp": "00:05:16,710", "timestamp_s": 316.0}, {"text": "As such, if you\u0027re creating your own data lake, there are some companies", "timestamp": "00:05:20,310", "timestamp_s": 320.0}, {"text": "that you will most likely need to create and maintain for your data lake.", "timestamp": "00:05:24,638", "timestamp_s": 324.0}, {"text": "Now data need to be collected and must be scalable", "timestamp": "00:05:29,218", "timestamp_s": 329.0}, {"text": "storage. Without ETL transformation,", "timestamp": "00:05:32,610", "timestamp_s": 332.0}, {"text": "all data must be cataloged because without a catalog you cannot", "timestamp": "00:05:36,970", "timestamp_s": 336.0}, {"text": "manage data, find data and organize access control.", "timestamp": "00:05:40,422", "timestamp_s": 340.0}, {"text": "All kind of analytics are needed including patch", "timestamp": "00:05:45,070", "timestamp_s": 345.0}, {"text": "analytics, stream analytics and advanced analytics", "timestamp": "00:05:48,342", "timestamp_s": 348.0}, {"text": "like machine learning. Therefore endtoend data ingestion and analysis.", "timestamp": "00:05:51,722", "timestamp_s": 351.0}, {"text": "Processes need to be coordinated.", "timestamp": "00:05:55,882", "timestamp_s": 355.0}, {"text": "Data should be available to all kind of people,", "timestamp": "00:05:59,410", "timestamp_s": 359.0}, {"text": "users and roles. Most importantly,", "timestamp": "00:06:02,516", "timestamp_s": 362.0}, {"text": "you need a framework for managing analytics and data.", "timestamp": "00:06:06,206", "timestamp_s": 366.0}, {"text": "Without governance, finding good solution is impossible.", "timestamp": "00:06:10,230", "timestamp_s": 370.0}, {"text": "Data analysts can query data lakes directly using fast", "timestamp": "00:06:13,830", "timestamp_s": 373.0}, {"text": "compute engines such as redshift and their preferred language SQL.", "timestamp": "00:06:18,028", "timestamp_s": 378.0}, {"text": "Data scientists then have all the data they need to", "timestamp": "00:06:22,330", "timestamp_s": 382.0}, {"text": "build robust models. Data engineers can also", "timestamp": "00:06:25,468", "timestamp_s": 385.0}, {"text": "easily simplify data and focus on infrastructure.", "timestamp": "00:06:28,832", "timestamp_s": 388.0}, {"text": "So let\u0027s understand benefit of serverless data lakes services", "timestamp": "00:06:33,230", "timestamp_s": 393.0}, {"text": "is a native architecture of the cloud, allowing you to offload more operational", "timestamp": "00:06:37,462", "timestamp_s": 397.0}, {"text": "responsibilities to AWS. Increase agility", "timestamp": "00:06:41,546", "timestamp_s": 401.0}, {"text": "and innovation by allowing you to focus on writing the business", "timestamp": "00:06:45,162", "timestamp_s": 405.0}, {"text": "logic and services. Your customer services", "timestamp": "00:06:48,740", "timestamp_s": 408.0}, {"text": "technology offers automatic scaling, built in, high availability,", "timestamp": "00:06:52,378", "timestamp_s": 412.0}, {"text": "and a consumption based billing model for cost optimization.", "timestamp": "00:06:55,662", "timestamp_s": 415.0}, {"text": "Serverless allow you to build and run applications and services without", "timestamp": "00:06:59,510", "timestamp_s": 419.0}, {"text": "worrying about infrastructure. Eliminate infrastructure management tasks", "timestamp": "00:07:03,096", "timestamp_s": 423.0}, {"text": "such as server or cluster provisioning, patching,", "timestamp": "00:07:06,674", "timestamp_s": 426.0}, {"text": "operating system maintenance and capacity provisioning.", "timestamp": "00:07:10,274", "timestamp_s": 430.0}, {"text": "AWS offers many other serverless services which I won\u0027t cover here", "timestamp": "00:07:13,530", "timestamp_s": 433.0}, {"text": "such as DynamoDB and Redshift, serverless etc.", "timestamp": "00:07:17,228", "timestamp_s": 437.0}, {"text": "Now I\u0027m going to hand over the call to Satish who is going to deep", "timestamp": "00:07:20,482", "timestamp_s": 440.0}, {"text": "dive Lake house architecture. Thank you Rajiv. Now that you understand", "timestamp": "00:07:23,318", "timestamp_s": 443.0}, {"text": "regular data lake, let me explain the building blocks of lake House architecture", "timestamp": "00:07:27,264", "timestamp_s": 447.0}, {"text": "data lakes have become default repository for all kinds of data.", "timestamp": "00:07:32,190", "timestamp_s": 452.0}, {"text": "A data lake services as a single source of truth for a large number of", "timestamp": "00:07:36,064", "timestamp_s": 456.0}, {"text": "users querying from a variety of analytics and machine learning tools.", "timestamp": "00:07:39,572", "timestamp_s": 459.0}, {"text": "Is your data lake getting unmanageable? Do you want to build", "timestamp": "00:07:43,650", "timestamp_s": 463.0}, {"text": "a highly scalable, cost effective data lakes with transactional capabilities?", "timestamp": "00:07:47,112", "timestamp_s": 467.0}, {"text": "Are you struggling to comply with data regulations as to how customer", "timestamp": "00:07:51,438", "timestamp_s": 471.0}, {"text": "data in data lakes can be used? If you are facing these challenges", "timestamp": "00:07:55,080", "timestamp_s": 475.0}, {"text": "then this session talks about how lake house architecture solves", "timestamp": "00:07:59,218", "timestamp_s": 479.0}, {"text": "those challenges.", "timestamp": "00:08:03,122", "timestamp_s": 483.0}, {"text": "What challenges do typical data lake face?", "timestamp": "00:08:08,510", "timestamp_s": 488.0}, {"text": "Regular data lakes provide scalable and cost effective storage.", "timestamp": "00:08:12,110", "timestamp_s": 492.0}, {"text": "However, this is not possible with regular data lakes when", "timestamp": "00:08:15,782", "timestamp_s": 495.0}, {"text": "continuously ingesting data and using transactional capabilities", "timestamp": "00:08:19,632", "timestamp_s": 499.0}, {"text": "to query from many analytics tools. At same time,", "timestamp": "00:08:23,370", "timestamp_s": 503.0}, {"text": "under CCPA and GDPR regulations,", "timestamp": "00:08:27,170", "timestamp_s": 507.0}, {"text": "businesses must change or delete all of customers\u0027data", "timestamp": "00:08:30,154", "timestamp_s": 510.0}, {"text": "upon request to comply with customer\u0027s right to be", "timestamp": "00:08:33,898", "timestamp_s": 513.0}, {"text": "forgotten or change of data. Change of consent to the use", "timestamp": "00:08:37,448", "timestamp_s": 517.0}, {"text": "of data it is difficult to make these kind of record level", "timestamp": "00:08:41,192", "timestamp_s": 521.0}, {"text": "changes in regular data lakes. Some customers find", "timestamp": "00:08:45,192", "timestamp_s": 525.0}, {"text": "change data capture pipeline difficult to handle.", "timestamp": "00:08:48,956", "timestamp_s": 528.0}, {"text": "This is especially true for recent data or erroneous data", "timestamp": "00:08:52,146", "timestamp_s": 532.0}, {"text": "that needs to be rewritten. A typical data lake would", "timestamp": "00:08:56,188", "timestamp_s": 536.0}, {"text": "have to reprocess missing or corrupted data due to job", "timestamp": "00:08:59,728", "timestamp_s": 539.0}, {"text": "failures, which can be a big problem.", "timestamp": "00:09:03,456", "timestamp_s": 543.0}, {"text": "Regular data lake do not enforce schema when writing", "timestamp": "00:09:06,670", "timestamp_s": 546.0}, {"text": "so you cannot avoid ingesting low quality data.", "timestamp": "00:09:10,486", "timestamp_s": 550.0}, {"text": "Also, one should know the partition or table structure", "timestamp": "00:09:13,810", "timestamp_s": 553.0}, {"text": "to avoid full table scan and listing files from", "timestamp": "00:09:18,122", "timestamp_s": 558.0}, {"text": "all partitions.", "timestamp": "00:09:21,332", "timestamp_s": 561.0}, {"text": "So let\u0027s see how a open table format can be used", "timestamp": "00:09:24,790", "timestamp_s": 564.0}, {"text": "to address these challenges mentioned on previous slide one of", "timestamp": "00:09:28,200", "timestamp_s": 568.0}, {"text": "the key characteristics expected of lake house architecture", "timestamp": "00:09:32,008", "timestamp_s": 572.0}, {"text": "is transactional or acid properties.", "timestamp": "00:09:35,858", "timestamp_s": 575.0}, {"text": "You do not have to write any code in the transactional or", "timestamp": "00:09:38,978", "timestamp_s": 578.0}, {"text": "data lake format which I will cover in next", "timestamp": "00:09:42,268", "timestamp_s": 582.0}, {"text": "few slides. Transactions are automatically written to the log presenting", "timestamp": "00:09:45,692", "timestamp_s": 585.0}, {"text": "a single source of truth. Advanced features such as", "timestamp": "00:09:49,718", "timestamp_s": 589.0}, {"text": "time travel, data transformation with DML, and concurrent", "timestamp": "00:09:53,264", "timestamp_s": 593.0}, {"text": "read and writes are also expected in data lake to handle use", "timestamp": "00:09:57,158", "timestamp_s": 597.0}, {"text": "cases such as change data capture and late arriving streaming", "timestamp": "00:10:00,612", "timestamp_s": 600.0}, {"text": "data over time. You can also expect data lake to have", "timestamp": "00:10:04,442", "timestamp_s": 604.0}, {"text": "features such AWS, schema evolution and schema enforcement.", "timestamp": "00:10:08,372", "timestamp_s": 608.0}, {"text": "These features allow you to update your schema over time to", "timestamp": "00:10:13,110", "timestamp_s": 613.0}, {"text": "ensure data quality during ingestion.", "timestamp": "00:10:16,968", "timestamp_s": 616.0}, {"text": "Engine neutrality is also expected in future of", "timestamp": "00:10:20,390", "timestamp_s": 620.0}, {"text": "data architecture. Today you use a compute engine to process data,", "timestamp": "00:10:23,768", "timestamp_s": 623.0}, {"text": "but tomorrow you can use different engine for new needs", "timestamp": "00:10:28,076", "timestamp_s": 628.0}, {"text": "for time travel data lake table format", "timestamp": "00:10:32,730", "timestamp_s": 632.0}, {"text": "versions, the big data that you store in the data lake.", "timestamp": "00:10:36,594", "timestamp_s": 636.0}, {"text": "You can access any historical versions of the data,", "timestamp": "00:10:40,134", "timestamp_s": 640.0}, {"text": "simplifying data management with easy to audit rollback", "timestamp": "00:10:43,472", "timestamp_s": 643.0}, {"text": "data in case of accidental bad writes or deletes and reproduce", "timestamp": "00:10:46,998", "timestamp_s": 646.0}, {"text": "experiments and reports.", "timestamp": "00:10:51,690", "timestamp_s": 651.0}, {"text": "Time travel enables reproducible queries by allowing two", "timestamp": "00:10:54,690", "timestamp_s": 654.0}, {"text": "different versions to be queried at same time.", "timestamp": "00:10:58,308", "timestamp_s": 658.0}, {"text": "Opentable format work at scale by automatically checkpointing", "timestamp": "00:11:01,490", "timestamp_s": 661.0}, {"text": "and summarizing large amounts of data, many files and their", "timestamp": "00:11:05,342", "timestamp_s": 665.0}, {"text": "metadata.", "timestamp": "00:11:09,192", "timestamp_s": 669.0}, {"text": "So what are your options for creating a data lake house", "timestamp": "00:11:12,550", "timestamp_s": 672.0}, {"text": "architecture to solve those regular data lake challenges?", "timestamp": "00:11:16,268", "timestamp_s": 676.0}, {"text": "Customers often face a dilemma when it covers to choosing right", "timestamp": "00:11:20,490", "timestamp_s": 680.0}, {"text": "data architecture for building data lake house. As such,", "timestamp": "00:11:24,332", "timestamp_s": 684.0}, {"text": "some customers use data warehouse to", "timestamp": "00:11:28,124", "timestamp_s": 688.0}, {"text": "eliminate the need of data lakes and the complexity", "timestamp": "00:11:31,712", "timestamp_s": 691.0}, {"text": "that comes with the data lake. However, a new pattern that", "timestamp": "00:11:35,510", "timestamp_s": 695.0}, {"text": "is emerging as a popular pattern for implementing", "timestamp": "00:11:38,784", "timestamp_s": 698.0}, {"text": "data lake house on AWS is to combine both", "timestamp": "00:11:42,458", "timestamp_s": 702.0}, {"text": "data lake and data warehousing capabilities.", "timestamp": "00:11:46,164", "timestamp_s": 706.0}, {"text": "This pattern is known as lake House architectural pattern.", "timestamp": "00:11:49,434", "timestamp_s": 709.0}, {"text": "There are two options for creating lakes House on AWS,", "timestamp": "00:11:54,126", "timestamp_s": 714.0}, {"text": "which I will talk about in next few slides.", "timestamp": "00:11:58,414", "timestamp_s": 718.0}, {"text": "So before diving into each data lake table format and", "timestamp": "00:12:03,510", "timestamp_s": 723.0}, {"text": "the lake house architectural options on AWS,", "timestamp": "00:12:07,468", "timestamp_s": 727.0}, {"text": "let me quickly compare the building blocks", "timestamp": "00:12:11,410", "timestamp_s": 731.0}, {"text": "that we discussed on or I discussed on previous slide.", "timestamp": "00:12:14,658", "timestamp_s": 734.0}, {"text": "So depending on your needs, a typical organization will", "timestamp": "00:12:19,550", "timestamp_s": 739.0}, {"text": "need both a data warehouse and", "timestamp": "00:12:23,056", "timestamp_s": 743.0}, {"text": "data lake that serve different needs and use cases.", "timestamp": "00:12:26,816", "timestamp_s": 746.0}, {"text": "Data lakes store both structured and unstructured", "timestamp": "00:12:30,770", "timestamp_s": 750.0}, {"text": "data from various other data sources such as", "timestamp": "00:12:34,602", "timestamp_s": 754.0}, {"text": "mobile apps, IoT devices, and social media.", "timestamp": "00:12:37,732", "timestamp_s": 757.0}, {"text": "The structure of the data or schema is not defined at", "timestamp": "00:12:41,428", "timestamp_s": 761.0}, {"text": "the time of data collection. This means you can store", "timestamp": "00:12:44,808", "timestamp_s": 764.0}, {"text": "all your data without having to plan carefully", "timestamp": "00:12:48,520", "timestamp_s": 768.0}, {"text": "or know what questions you will need to answer in the future.", "timestamp": "00:12:52,670", "timestamp_s": 772.0}, {"text": "A data warehouse is a database optimized for analyzing", "timestamp": "00:12:57,210", "timestamp_s": 777.0}, {"text": "relational data from transactional systems. Data structures and", "timestamp": "00:13:00,786", "timestamp_s": 780.0}, {"text": "schemas are predefined to optimize fast SQL queries,", "timestamp": "00:13:04,716", "timestamp_s": 784.0}, {"text": "the result of which are typically used for operational reporting", "timestamp": "00:13:08,950", "timestamp_s": 788.0}, {"text": "and analysis. Data is cleaned, enriched, and transformed", "timestamp": "00:13:12,966", "timestamp_s": 792.0}, {"text": "so that it can serve as a single source of truth that users", "timestamp": "00:13:17,334", "timestamp_s": 797.0}, {"text": "can rely on. However, once organizations", "timestamp": "00:13:20,794", "timestamp_s": 800.0}, {"text": "with data warehouse recognize the benefits of data lakes", "timestamp": "00:13:24,426", "timestamp_s": 804.0}, {"text": "house that provide the functionality of both data lake", "timestamp": "00:13:28,282", "timestamp_s": 808.0}, {"text": "and data warehouse, they can evolve their data warehouse", "timestamp": "00:13:32,154", "timestamp_s": 812.0}, {"text": "to include data lake house and enable various", "timestamp": "00:13:35,566", "timestamp_s": 815.0}, {"text": "query capabilities.", "timestamp": "00:13:39,310", "timestamp_s": 819.0}, {"text": "So the first lake house architecture option is ready to", "timestamp": "00:13:43,430", "timestamp_s": 823.0}, {"text": "use platform on AWS. This approach", "timestamp": "00:13:47,068", "timestamp_s": 827.0}, {"text": "allows for separate data warehouse with transactional capabilities", "timestamp": "00:13:51,106", "timestamp_s": 831.0}, {"text": "such as Amazon, Redshift, and a cost effective", "timestamp": "00:13:55,074", "timestamp_s": 835.0}, {"text": "scalable data lake on Amazon s three technologies", "timestamp": "00:13:58,358", "timestamp_s": 838.0}, {"text": "such as Amazon Redshift spectrum can then be used to", "timestamp": "00:14:02,614", "timestamp_s": 842.0}, {"text": "integrate strategically distributed data in both data", "timestamp": "00:14:05,952", "timestamp_s": 845.0}, {"text": "warehouse and data lake. This approach definitely", "timestamp": "00:14:09,392", "timestamp_s": 849.0}, {"text": "simplifies the engineering effort free developers", "timestamp": "00:14:12,724", "timestamp_s": 852.0}, {"text": "to focus on feature development and leave the infrastructure to the cloud to harness", "timestamp": "00:14:16,794", "timestamp_s": 856.0}, {"text": "the power of serverless technology from storage to processing", "timestamp": "00:14:20,906", "timestamp_s": 860.0}, {"text": "and to presentation layer. In this pattern,", "timestamp": "00:14:24,862", "timestamp_s": 864.0}, {"text": "data from various data sources is aggregated", "timestamp": "00:14:28,510", "timestamp_s": 868.0}, {"text": "into Amazon s three before transformation or loading", "timestamp": "00:14:31,886", "timestamp_s": 871.0}, {"text": "into data warehouse. This pattern is useful if", "timestamp": "00:14:35,758", "timestamp_s": 875.0}, {"text": "you want to keep the raw data in the data lake and process data in", "timestamp": "00:14:39,068", "timestamp_s": 879.0}, {"text": "the data warehouse to avoid scaling cost. With this option,", "timestamp": "00:14:42,748", "timestamp_s": 882.0}, {"text": "you can take advantage of Amazon Redshift\u0027s transactional", "timestamp": "00:14:47,390", "timestamp_s": 887.0}, {"text": "capabilities and also run low latency analytical queries.", "timestamp": "00:14:51,254", "timestamp_s": 891.0}, {"text": "The second option is do it yourself option for creating", "timestamp": "00:14:58,270", "timestamp_s": 898.0}, {"text": "a larger data lakes house. Why do it", "timestamp": "00:15:01,498", "timestamp_s": 901.0}, {"text": "yourself? This pattern is growing in popularity because", "timestamp": "00:15:04,868", "timestamp_s": 904.0}, {"text": "of three table formats, Apache hoodie, Delta Lake,", "timestamp": "00:15:08,692", "timestamp_s": 908.0}, {"text": "and Iceberg, that have emerged over the past few", "timestamp": "00:15:12,762", "timestamp_s": 912.0}, {"text": "years to power data lake house that", "timestamp": "00:15:15,976", "timestamp_s": 915.0}, {"text": "support acid transactions, time travel,", "timestamp": "00:15:19,432", "timestamp_s": 919.0}, {"text": "granular access control, and deliver a very good", "timestamp": "00:15:22,376", "timestamp_s": 922.0}, {"text": "performance compared to regular data lake. These open table", "timestamp": "00:15:25,912", "timestamp_s": 925.0}, {"text": "data lake formats combines the scalability and", "timestamp": "00:15:29,822", "timestamp_s": 929.0}, {"text": "cost effectiveness of data lake on Amazon s", "timestamp": "00:15:33,484", "timestamp_s": 933.0}, {"text": "three and transactional capabilities, reliability and", "timestamp": "00:15:37,068", "timestamp_s": 937.0}, {"text": "performance of data warehouse to ensure greater scale.", "timestamp": "00:15:40,416", "timestamp_s": 940.0}, {"text": "Table formats or data lake table formats are instrumental for", "timestamp": "00:15:44,710", "timestamp_s": 944.0}, {"text": "getting the scalability benefits of data lake and the underlying", "timestamp": "00:15:48,512", "timestamp_s": 948.0}, {"text": "Amazon s three object store, while at the same time getting the data", "timestamp": "00:15:52,634", "timestamp_s": 952.0}, {"text": "quality and governance associated with data warehouses.", "timestamp": "00:15:56,612", "timestamp_s": 956.0}, {"text": "These data lake table format framework also", "timestamp": "00:16:00,610", "timestamp_s": 960.0}, {"text": "add additional governance compared to regular data lake.", "timestamp": "00:16:04,120", "timestamp_s": 964.0}, {"text": "Optionally, you can connect Amazon redshift for", "timestamp": "00:16:08,286", "timestamp_s": 968.0}, {"text": "low latency OLAP access to business ready data.", "timestamp": "00:16:12,390", "timestamp_s": 972.0}, {"text": "Now I will quickly walk through three popular table formats.", "timestamp": "00:16:19,130", "timestamp_s": 979.0}, {"text": "First one is Apache hoodie. Apache Hoodie follows", "timestamp": "00:16:22,834", "timestamp_s": 982.0}, {"text": "timeline based transaction model. A timeline", "timestamp": "00:16:27,370", "timestamp_s": 987.0}, {"text": "contains all actions performed on the table at different instance", "timestamp": "00:16:30,806", "timestamp_s": 990.0}, {"text": "of time. The time could provide instantaneous views", "timestamp": "00:16:34,582", "timestamp_s": 994.0}, {"text": "of table and support to get data in the order of arrival.", "timestamp": "00:16:38,038", "timestamp_s": 998.0}, {"text": "Apache Hoodie offers both multi", "timestamp": "00:16:42,170", "timestamp_s": 1002.0}, {"text": "version concurrency control and optimistic concurrency control.", "timestamp": "00:16:46,138", "timestamp_s": 1006.0}, {"text": "Using multi version concurrency control, Hoodie provides", "timestamp": "00:16:50,020", "timestamp_s": 1010.0}, {"text": "snapshot isolation between an ingestion writer and", "timestamp": "00:16:53,502", "timestamp_s": 1013.0}, {"text": "multiple concurrent readers. It also apply", "timestamp": "00:16:57,176", "timestamp_s": 1017.0}, {"text": "optimistic concurrency control for a reader and writer.", "timestamp": "00:17:01,208", "timestamp_s": 1021.0}, {"text": "Hoodie supports file level optimistic", "timestamp": "00:17:04,382", "timestamp_s": 1024.0}, {"text": "concurrency control, that is, for any two commits or writers", "timestamp": "00:17:07,922", "timestamp_s": 1027.0}, {"text": "happening to the same table. If they do not have rights", "timestamp": "00:17:11,794", "timestamp_s": 1031.0}, {"text": "to overlapping files being changed, both writers", "timestamp": "00:17:15,346", "timestamp_s": 1035.0}, {"text": "are allowed to succeed. The next one is time", "timestamp": "00:17:19,190", "timestamp_s": 1039.0}, {"text": "travel. You could also do a time travel. According to hoodie,", "timestamp": "00:17:22,832", "timestamp_s": 1042.0}, {"text": "commit time hoodie supports schema evolution to", "timestamp": "00:17:26,438", "timestamp_s": 1046.0}, {"text": "add, delete, modify, and move columns, but it does not", "timestamp": "00:17:30,048", "timestamp_s": 1050.0}, {"text": "support partition evolution. You cannot change partition", "timestamp": "00:17:33,412", "timestamp_s": 1053.0}, {"text": "column when it comes to storage optimization.", "timestamp": "00:17:36,906", "timestamp_s": 1056.0}, {"text": "Auto file sizing and auto companies is great for ensuring", "timestamp": "00:17:40,330", "timestamp_s": 1060.0}, {"text": "storage optimization by avoiding small files in", "timestamp": "00:17:44,254", "timestamp_s": 1064.0}, {"text": "Apache hoodie, and the last one is indexing. By default.", "timestamp": "00:17:48,152", "timestamp_s": 1068.0}, {"text": "Hoodie uses index that stores mapping between record", "timestamp": "00:17:52,702", "timestamp_s": 1072.0}, {"text": "key and file group id it belongs to. When modeling,", "timestamp": "00:17:56,204", "timestamp_s": 1076.0}, {"text": "use record key that is monotonically increasing.", "timestamp": "00:18:00,386", "timestamp_s": 1080.0}, {"text": "For example timestamp prefix for best index performance", "timestamp": "00:18:03,650", "timestamp_s": 1083.0}, {"text": "by range pruning to filter out the files.", "timestamp": "00:18:07,810", "timestamp_s": 1087.0}, {"text": "The second option is a table format is Apache iceberg.", "timestamp": "00:18:15,070", "timestamp_s": 1095.0}, {"text": "Apache Iceberg follows snapshot based transaction", "timestamp": "00:18:18,486", "timestamp_s": 1098.0}, {"text": "model. A snapshot is a complete list of files in", "timestamp": "00:18:22,298", "timestamp_s": 1102.0}, {"text": "the table. The table state is maintained in metadata", "timestamp": "00:18:25,764", "timestamp_s": 1105.0}, {"text": "files. All changes to table state create a new metadata file", "timestamp": "00:18:29,018", "timestamp_s": 1109.0}, {"text": "and they replace old metadata file. With atomic swap,", "timestamp": "00:18:33,390", "timestamp_s": 1113.0}, {"text": "iceberg follows optimistic concurrency control.", "timestamp": "00:18:37,590", "timestamp_s": 1117.0}, {"text": "The writers create a table metadata files optimistically assuming", "timestamp": "00:18:41,832", "timestamp_s": 1121.0}, {"text": "that current version will not be changed before the writers commit.", "timestamp": "00:18:45,998", "timestamp_s": 1125.0}, {"text": "Once writer has created can update, it commits", "timestamp": "00:18:50,306", "timestamp_s": 1130.0}, {"text": "by swapping the table\u0027s metadata file pointer from the base version", "timestamp": "00:18:54,242", "timestamp_s": 1134.0}, {"text": "to the new version. If the snapshot on which update is", "timestamp": "00:18:58,354", "timestamp_s": 1138.0}, {"text": "based is no longer current, the writer must retry", "timestamp": "00:19:01,872", "timestamp_s": 1141.0}, {"text": "the update based on the new version current the", "timestamp": "00:19:05,862", "timestamp_s": 1145.0}, {"text": "new version time", "timestamp": "00:19:09,296", "timestamp_s": 1149.0}, {"text": "travel user could also do time travel using according", "timestamp": "00:19:12,772", "timestamp_s": 1152.0}, {"text": "to snapshot id and timestamp. When it", "timestamp": "00:19:16,618", "timestamp_s": 1156.0}, {"text": "comes to storage optimization, you can clean up unused older", "timestamp": "00:19:20,564", "timestamp_s": 1160.0}, {"text": "snapshots by marking them as expired based on certain time period", "timestamp": "00:19:24,318", "timestamp_s": 1164.0}, {"text": "and then manually run spark job to delete them.", "timestamp": "00:19:28,958", "timestamp_s": 1168.0}, {"text": "To optimize files into larger files, you need", "timestamp": "00:19:33,640", "timestamp_s": 1173.0}, {"text": "to run spark job in background manually", "timestamp": "00:19:37,068", "timestamp_s": 1177.0}, {"text": "and the last one is indexing. Apache iceberg uses", "timestamp": "00:19:40,770", "timestamp_s": 1180.0}, {"text": "value range for columns to skip data files", "timestamp": "00:19:44,226", "timestamp_s": 1184.0}, {"text": "and partition fields to skip manifest files", "timestamp": "00:19:47,986", "timestamp_s": 1187.0}, {"text": "when executing query.", "timestamp": "00:19:52,518", "timestamp_s": 1192.0}, {"text": "Delta Lake Delta Lake has a transaction model", "timestamp": "00:19:58,190", "timestamp_s": 1198.0}, {"text": "based on transaction log. It logs the file operations", "timestamp": "00:20:01,860", "timestamp_s": 1201.0}, {"text": "in JSON file and then commit to the table using", "timestamp": "00:20:06,154", "timestamp_s": 1206.0}, {"text": "atomic operations. Delta Lake automatically generates checkpoint", "timestamp": "00:20:10,612", "timestamp_s": 1210.0}, {"text": "files every ten commits into parquet file.", "timestamp": "00:20:14,778", "timestamp_s": 1214.0}, {"text": "Delta Lake employs optimistic concurrency control optimistic", "timestamp": "00:20:18,390", "timestamp_s": 1218.0}, {"text": "concurrency control is a method of dealing with concurrent transactions that", "timestamp": "00:20:22,238", "timestamp_s": 1222.0}, {"text": "assume that transactions or changes made to", "timestamp": "00:20:26,236", "timestamp_s": 1226.0}, {"text": "table by different users can complete without conflicting with one another.", "timestamp": "00:20:30,012", "timestamp_s": 1230.0}, {"text": "User cloud also do time travel query according to the timestamp", "timestamp": "00:20:35,210", "timestamp_s": 1235.0}, {"text": "or version number deltax supports", "timestamp": "00:20:39,362", "timestamp_s": 1239.0}, {"text": "or lets you update schema by a schema of", "timestamp": "00:20:43,378", "timestamp_s": 1243.0}, {"text": "a table by adding new column or reordering existing column.", "timestamp": "00:20:46,944", "timestamp_s": 1246.0}, {"text": "And when it comes to storage optimization, delta Lake", "timestamp": "00:20:50,826", "timestamp_s": 1250.0}, {"text": "does not have companies as it follows copy", "timestamp": "00:20:54,442", "timestamp_s": 1254.0}, {"text": "and write. Hence file sizing is manual.", "timestamp": "00:20:58,602", "timestamp_s": 1258.0}, {"text": "You need to run vacuum and optimize file size", "timestamp": "00:21:02,710", "timestamp_s": 1262.0}, {"text": "command to convert small files into large files.", "timestamp": "00:21:05,976", "timestamp_s": 1265.0}, {"text": "Delta Lake collects column sets for", "timestamp": "00:21:10,710", "timestamp_s": 1270.0}, {"text": "data skipping index during query so it takes", "timestamp": "00:21:15,130", "timestamp_s": 1275.0}, {"text": "advantage of this information, the minimum maximum values", "timestamp": "00:21:18,876", "timestamp_s": 1278.0}, {"text": "of each column to add query time to provide faster queries.", "timestamp": "00:21:22,274", "timestamp_s": 1282.0}, {"text": "The zorder index technique it uses", "timestamp": "00:21:26,610", "timestamp_s": 1286.0}, {"text": "to colocate the data skipping information in same file", "timestamp": "00:21:30,102", "timestamp_s": 1290.0}, {"text": "for a particular column to be used in Z order.", "timestamp": "00:21:33,958", "timestamp_s": 1293.0}, {"text": "So this is a quick snapshot of how these table", "timestamp": "00:21:40,530", "timestamp_s": 1300.0}, {"text": "formats are integrated with AWS analytics", "timestamp": "00:21:44,330", "timestamp_s": 1304.0}, {"text": "services. Amazon Athena has better integration with", "timestamp": "00:21:48,442", "timestamp_s": 1308.0}, {"text": "Apache Iceberg in terms of read write operations, whereas it", "timestamp": "00:21:51,812", "timestamp_s": 1311.0}, {"text": "supports only read operations on Apache hoodie", "timestamp": "00:21:55,512", "timestamp_s": 1315.0}, {"text": "and Delta Lake. Amazon redshift spectrum supports", "timestamp": "00:21:58,638", "timestamp_s": 1318.0}, {"text": "both Apache hoodie and Delta Lake for reading data.", "timestamp": "00:22:02,382", "timestamp_s": 1322.0}, {"text": "EMR and glue supports both read write", "timestamp": "00:22:06,810", "timestamp_s": 1326.0}, {"text": "against these table formats. These three table formats", "timestamp": "00:22:10,524", "timestamp_s": 1330.0}, {"text": "you can also manage permissions in Amazon Athena", "timestamp": "00:22:15,370", "timestamp_s": 1335.0}, {"text": "using AWS Lake formation for Apache hoodie and Apache iceberg", "timestamp": "00:22:18,582", "timestamp_s": 1338.0}, {"text": "table format. Similarly, you can manage permissions in", "timestamp": "00:22:22,774", "timestamp_s": 1342.0}, {"text": "Amazon redshift spectrum using AWS Lake formation for", "timestamp": "00:22:26,512", "timestamp_s": 1346.0}, {"text": "Delta Lake and Apache Hoodie.", "timestamp": "00:22:30,516", "timestamp_s": 1350.0}, {"text": "To conclude, here are final thoughts on choosing data", "timestamp": "00:22:35,650", "timestamp_s": 1355.0}, {"text": "Lake table format for building lake House architecture on AWS", "timestamp": "00:22:39,252", "timestamp_s": 1359.0}, {"text": "based on your use case as well as integration with AWS", "timestamp": "00:22:43,034", "timestamp_s": 1363.0}, {"text": "analytics services. Apache hoodie is considered", "timestamp": "00:22:46,782", "timestamp_s": 1366.0}, {"text": "suitable for streaming use cases whether it\u0027s IoT data or", "timestamp": "00:22:50,398", "timestamp_s": 1370.0}, {"text": "change data capture from database. Hoodie provides highly", "timestamp": "00:22:53,832", "timestamp_s": 1373.0}, {"text": "flexible three types of indexes for optimizing", "timestamp": "00:22:57,378", "timestamp_s": 1377.0}, {"text": "query performance and also optimizing data storage.", "timestamp": "00:23:00,418", "timestamp_s": 1380.0}, {"text": "Because of autofile sizing and clustering optimization feature", "timestamp": "00:23:03,970", "timestamp_s": 1383.0}, {"text": "backed by index lookup, it is great for streaming use cases.", "timestamp": "00:23:08,054", "timestamp_s": 1388.0}, {"text": "It comes with managed data ingestion tool called delta", "timestamp": "00:23:12,262", "timestamp_s": 1392.0}, {"text": "Streamer unlike other two table formats.", "timestamp": "00:23:16,038", "timestamp_s": 1396.0}, {"text": "Second option is Apache Iceberg. If you\u0027re looking for", "timestamp": "00:23:19,470", "timestamp_s": 1399.0}, {"text": "easy management of schema and partition evolution,", "timestamp": "00:23:22,884", "timestamp_s": 1402.0}, {"text": "then Apache Iceberg is suitable table format. One of", "timestamp": "00:23:25,914", "timestamp_s": 1405.0}, {"text": "the advantage of Apache iceberg is how it handles partitions.", "timestamp": "00:23:29,124", "timestamp_s": 1409.0}, {"text": "Basically IT services partition value from data fields used", "timestamp": "00:23:33,226", "timestamp_s": 1413.0}, {"text": "in a SQL where condition.", "timestamp": "00:23:37,000", "timestamp_s": 1417.0}, {"text": "One does not need to specify exact partition key in", "timestamp": "00:23:39,854", "timestamp_s": 1419.0}, {"text": "the SQL query. Unlike Hoodie", "timestamp": "00:23:43,224", "timestamp_s": 1423.0}, {"text": "and Delta Lake, Iceberg allows easily to change", "timestamp": "00:23:47,218", "timestamp_s": 1427.0}, {"text": "partition column on table. It simply starts writing to", "timestamp": "00:23:50,428", "timestamp_s": 1430.0}, {"text": "new partition. Third option is Delta", "timestamp": "00:23:54,604", "timestamp_s": 1434.0}, {"text": "Lake. This table format is suitable if your data platform is", "timestamp": "00:23:58,354", "timestamp_s": 1438.0}, {"text": "built around spark framework with deep integration of spark features.", "timestamp": "00:24:02,172", "timestamp_s": 1442.0}, {"text": "AWS Delta Lake stores all metadata state information in", "timestamp": "00:24:05,618", "timestamp_s": 1445.0}, {"text": "transaction log and checkpoint files instead of metastore.", "timestamp": "00:24:09,292", "timestamp_s": 1449.0}, {"text": "You can use separate spark cluster to build table", "timestamp": "00:24:12,746", "timestamp_s": 1452.0}, {"text": "state independently without relying on central Metastore", "timestamp": "00:24:16,682", "timestamp_s": 1456.0}, {"text": "and this really helps to scale and meet the performance requirements", "timestamp": "00:24:20,314", "timestamp_s": 1460.0}, {"text": "depending on your spark cluster size. Thank you for listening. Me and my", "timestamp": "00:24:24,250", "timestamp_s": 1464.0}, {"text": "colleague hope you all enjoyed this session.", "timestamp": "00:24:28,068", "timestamp_s": 1468.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'znNHrHKKmXE',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Build cloud native open format data lakehouse
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>As data lakes are growing and getting notoriously messy, companies struggle to change data in order to implement GDPR,CCPA data regulations as to how customer data can be used. So this session covers journey to data lake house architecture using open source table format and cloud native services</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Businesses are struggling to capture, store and analyze all the data generated by today's modern digital business. Traditional on premise data analytics approaches do not scale well and are too expensive to handle these volumes of data. Data grow exponentially. They need to be securedly accessed and analyzed by any number of applications and people.

              </li>
              
              <li>
                A data lake makes it easier to derive insights from all your data. Customers need highly scalable, highly available, secure and flexible data store. What you are seeing is a high level architecture of data lake in the cloud as a low cost, durable and scalable storage.

              </li>
              
              <li>
                There are some companies that you will most likely need to create and maintain for your data lake. Data need to be collected and must be scalable storage. Most importantly, you need a framework for managing analytics and data. Without governance, finding good solution is impossible.

              </li>
              
              <li>
                Data lakes have become default repository for all kinds of data. Is your data lake getting unmanageable? Do you want to build a highly scalable, cost effective data lakes with transactional capabilities? There are two options for creating lakes House on AWS, which I will talk about in next few slides.

              </li>
              
              <li>
                A typical organization will need both a data warehouse and data lake. Data lakes store both structured and unstructured data from various other data sources. The second option is do it yourself option for creating a larger data lakes house.

              </li>
              
              <li>
                Apache Hoodie follows timeline based transaction model. Apache Iceberg follows snapshot based transaction models. Delta Lake employs optimistic concurrency control. You could also do time travel using according to snapshot id and timestamp. These table formats are integrated with AWS analytics services.

              </li>
              
              <li>
                Apache hoodie is considered suitable for streaming use cases whether it's IoT data or change data capture from database. Third option is Delta Lake which is suitable if your data platform is built around spark framework. Here are final thoughts on choosing data Lake table format for building lake House architecture on AWS.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/znNHrHKKmXE.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:34,530'); seek(34.0)">
              Hi, my name is Satish Mane. I will talk about data lake table
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:38,082'); seek(38.0)">
              formats and their integration with AWS Analytics Services to
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:41,772'); seek(41.0)">
              build cloud native data lake house on AWS Cloud.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:45,004'); seek(45.0)">
              Hi, my name is Rajeev Jaiiswal. In this session I'll take
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:48,892'); seek(48.0)">
              you on a journey to Data Lake. Thanks for joining in.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:52,900'); seek(52.0)">
              Before we dive further, let's first understand couple of trends we
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:56,868'); seek(56.0)">
              see in businesses. The first one is expectation of the customers.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:01:01,028'); seek(61.0)">
              In the digital era, customers expect the kind of
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:01:04,328'); seek(64.0)">
              experience they get from Airbnb, Uber and all
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:01:07,672'); seek(67.0)">
              these technologies. Apart from these experiences, the BDI is
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:11,688'); seek(71.0)">
              personalized, demonstrating a true understanding
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:14,862'); seek(74.0)">
              of a customer and their context. People's expectations
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:18,798'); seek(78.0)">
              vary from industry to industry as we offer contextually.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:23,290'); seek(83.0)">
              The second trend is new data volume.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:26,730'); seek(86.0)">
              Data is growing at an unprecedented rate,
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:29,904'); seek(89.0)">
              exploiting from terabyte to petabyte and sometimes exabytes.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:35,470'); seek(95.0)">
              Traditional on premise data analytics approaches do not scale
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:38,902'); seek(98.0)">
              well and are too expensive to handle these volumes of data.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:43,490'); seek(103.0)">
              We often hear from businesses that they are trying to
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:46,612'); seek(106.0)">
              extract more value from their data, but are struggling to capture,
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:50,266'); seek(110.0)">
              store and analyze all the data generated by today's modern
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:53,902'); seek(113.0)">
              digital business. Data grow exponentially.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:57,934'); seek(117.0)">
              They come from new sources, are becoming more diverse, and need to
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:02:01,544'); seek(121.0)">
              be securedly accessed and analyzed by any number of applications
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:02:05,970'); seek(125.0)">
              and people. All this brings us
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:02:09,532'); seek(129.0)">
              to the subject of technology. Before diving into the broader analytics
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:13,842'); seek(133.0)">
              architecture, let's first understand how legacy or traditional on
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:17,308'); seek(137.0)">
              premise data analytics stacks up. There is typically
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:21,222'); seek(141.0)">
              an operating system and database for storing customer records
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:24,886'); seek(144.0)">
              and transactions, followed by a reporting
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:28,550'); seek(148.0)">
              database for data Mart and data lakehouse. Type use cases there
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:33,188'); seek(153.0)">
              are four main problems with the type of architecture.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:36,210'); seek(156.0)">
              First, the analytics implementation cycle is too long,
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:39,940'); seek(159.0)">
              as moving data sets and building dashboard can take weeks or
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:43,288'); seek(163.0)">
              even months. The second issue is scalability,
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:47,750'); seek(167.0)">
              higher cost because you always have to plan ahead to
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:51,048'); seek(171.0)">
              buy more hardware and pay for more licenses.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:54,158'); seek(174.0)">
              Third, this architecture is not suitable for modern analytics use cases
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:58,018'); seek(178.0)">
              such as machine learning adapt queries for data sciences use cases.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:03:02,410'); seek(182.0)">
              Finally, organizations struggle to keep up with the
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:05,564'); seek(185.0)">
              pace of changing business needs.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:09,710'); seek(189.0)">
              Now, how you can solve all these problems?
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:13,470'); seek(193.0)">
              The answer is data lake. A data lake makes it easier to
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:17,072'); seek(197.0)">
              derive insights from all your data by providing a single place
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:21,092'); seek(201.0)">
              to access structured data, semi structured data
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:24,308'); seek(204.0)">
              and unstructured data. Customers need highly
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:27,738'); seek(207.0)">
              scalable, highly available, secure and flexible data
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:30,996'); seek(210.0)">
              store that can handle very large data sets at a reasonable
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:35,182'); seek(215.0)">
              cost. Therefore, three key points are important for data lakes
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:39,830'); seek(219.0)">
              data in its original form and format, no matter how much,
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:43,784'); seek(223.0)">
              what kind, and how fast it is generated.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:47,130'); seek(227.0)">
              Structures and processing rules should be defined only when
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:50,492'); seek(230.0)">
              necessary. Also, known as reading schema. As data
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:54,396'); seek(234.0)">
              is used by large community, we need to democratize data.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:04:01,610'); seek(241.0)">
              What you are seeing is a high level architecture of data lake in the cloud
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:04:06,670'); seek(246.0)">
              as a low cost, durable and scalable storage. Amazon S
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:10,288'); seek(250.0)">
              three provides storage layer that is completely decoupled from
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:13,972'); seek(253.0)">
              data processing and various big data tools and has a zero
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:17,876'); seek(257.0)">
              operation over it. Customer can choose a data lake file format such
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:21,444'); seek(261.0)">
              as Apache, Parquet, spark powered AWS services
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:25,384'); seek(265.0)">
              such as AWS, Glow, Amazon, EMR and Athena enables
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:29,598'); seek(269.0)">
              access and compute at scale. The meta level stores metadata
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:34,398'); seek(274.0)">
              about tables, columns and partitions in the AWS glue catalog.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:40,490'); seek(280.0)">
              To keep the data in its original form and format, you need the ability to
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:44,108'); seek(284.0)">
              handle various file formats such as JSON, CSV, Parquet,
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:47,602'); seek(287.0)">
              Avro and more. Each format is suitable for
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:51,168'); seek(291.0)">
              different use cases. For example,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:53,710'); seek(293.0)">
              CSV is popular for its low volume and human readable format.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:57,654'); seek(297.0)">
              CSV is what we call the line storage parquet
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:05:02,074'); seek(302.0)">
              file. Organize data into column column store files
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:05:05,802'); seek(305.0)">
              are more optimized because you can perform better compression on
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:05:09,172'); seek(309.0)">
              each column. Parquet is well suited for bulk processing
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:13,226'); seek(313.0)">
              of complex data.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:16,710'); seek(316.0)">
              Now you understand the data lake component.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:20,310'); seek(320.0)">
              As such, if you're creating your own data lake, there are some companies
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:24,638'); seek(324.0)">
              that you will most likely need to create and maintain for your data lake.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:29,218'); seek(329.0)">
              Now data need to be collected and must be scalable
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:32,610'); seek(332.0)">
              storage. Without ETL transformation,
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:36,970'); seek(336.0)">
              all data must be cataloged because without a catalog you cannot
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:40,422'); seek(340.0)">
              manage data, find data and organize access control.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:45,070'); seek(345.0)">
              All kind of analytics are needed including patch
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:48,342'); seek(348.0)">
              analytics, stream analytics and advanced analytics
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:51,722'); seek(351.0)">
              like machine learning. Therefore endtoend data ingestion and analysis.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:55,882'); seek(355.0)">
              Processes need to be coordinated.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:59,410'); seek(359.0)">
              Data should be available to all kind of people,
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:06:02,516'); seek(362.0)">
              users and roles. Most importantly,
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:06:06,206'); seek(366.0)">
              you need a framework for managing analytics and data.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:10,230'); seek(370.0)">
              Without governance, finding good solution is impossible.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:13,830'); seek(373.0)">
              Data analysts can query data lakes directly using fast
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:18,028'); seek(378.0)">
              compute engines such as redshift and their preferred language SQL.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:22,330'); seek(382.0)">
              Data scientists then have all the data they need to
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:25,468'); seek(385.0)">
              build robust models. Data engineers can also
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:28,832'); seek(388.0)">
              easily simplify data and focus on infrastructure.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:33,230'); seek(393.0)">
              So let's understand benefit of serverless data lakes services
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:37,462'); seek(397.0)">
              is a native architecture of the cloud, allowing you to offload more operational
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:41,546'); seek(401.0)">
              responsibilities to AWS. Increase agility
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:45,162'); seek(405.0)">
              and innovation by allowing you to focus on writing the business
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:48,740'); seek(408.0)">
              logic and services. Your customer services
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:52,378'); seek(412.0)">
              technology offers automatic scaling, built in, high availability,
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:55,662'); seek(415.0)">
              and a consumption based billing model for cost optimization.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:59,510'); seek(419.0)">
              Serverless allow you to build and run applications and services without
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:07:03,096'); seek(423.0)">
              worrying about infrastructure. Eliminate infrastructure management tasks
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:07:06,674'); seek(426.0)">
              such as server or cluster provisioning, patching,
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:10,274'); seek(430.0)">
              operating system maintenance and capacity provisioning.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:13,530'); seek(433.0)">
              AWS offers many other serverless services which I won't cover here
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:17,228'); seek(437.0)">
              such as DynamoDB and Redshift, serverless etc.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:20,482'); seek(440.0)">
              Now I'm going to hand over the call to Satish who is going to deep
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:23,318'); seek(443.0)">
              dive Lake house architecture. Thank you Rajiv. Now that you understand
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:27,264'); seek(447.0)">
              regular data lake, let me explain the building blocks of lake House architecture
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:32,190'); seek(452.0)">
              data lakes have become default repository for all kinds of data.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:36,064'); seek(456.0)">
              A data lake services as a single source of truth for a large number of
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:39,572'); seek(459.0)">
              users querying from a variety of analytics and machine learning tools.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:43,650'); seek(463.0)">
              Is your data lake getting unmanageable? Do you want to build
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:47,112'); seek(467.0)">
              a highly scalable, cost effective data lakes with transactional capabilities?
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:51,438'); seek(471.0)">
              Are you struggling to comply with data regulations as to how customer
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:55,080'); seek(475.0)">
              data in data lakes can be used? If you are facing these challenges
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:59,218'); seek(479.0)">
              then this session talks about how lake house architecture solves
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:03,122'); seek(483.0)">
              those challenges.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:08,510'); seek(488.0)">
              What challenges do typical data lake face?
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:12,110'); seek(492.0)">
              Regular data lakes provide scalable and cost effective storage.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:15,782'); seek(495.0)">
              However, this is not possible with regular data lakes when
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:19,632'); seek(499.0)">
              continuously ingesting data and using transactional capabilities
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:23,370'); seek(503.0)">
              to query from many analytics tools. At same time,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:27,170'); seek(507.0)">
              under CCPA and GDPR regulations,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:30,154'); seek(510.0)">
              businesses must change or delete all of customers'data
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:33,898'); seek(513.0)">
              upon request to comply with customer's right to be
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:37,448'); seek(517.0)">
              forgotten or change of data. Change of consent to the use
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:41,192'); seek(521.0)">
              of data it is difficult to make these kind of record level
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:45,192'); seek(525.0)">
              changes in regular data lakes. Some customers find
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:48,956'); seek(528.0)">
              change data capture pipeline difficult to handle.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:52,146'); seek(532.0)">
              This is especially true for recent data or erroneous data
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:56,188'); seek(536.0)">
              that needs to be rewritten. A typical data lake would
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:59,728'); seek(539.0)">
              have to reprocess missing or corrupted data due to job
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:03,456'); seek(543.0)">
              failures, which can be a big problem.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:06,670'); seek(546.0)">
              Regular data lake do not enforce schema when writing
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:10,486'); seek(550.0)">
              so you cannot avoid ingesting low quality data.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:13,810'); seek(553.0)">
              Also, one should know the partition or table structure
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:18,122'); seek(558.0)">
              to avoid full table scan and listing files from
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:21,332'); seek(561.0)">
              all partitions.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:24,790'); seek(564.0)">
              So let's see how a open table format can be used
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:28,200'); seek(568.0)">
              to address these challenges mentioned on previous slide one of
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:32,008'); seek(572.0)">
              the key characteristics expected of lake house architecture
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:35,858'); seek(575.0)">
              is transactional or acid properties.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:38,978'); seek(578.0)">
              You do not have to write any code in the transactional or
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:42,268'); seek(582.0)">
              data lake format which I will cover in next
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:45,692'); seek(585.0)">
              few slides. Transactions are automatically written to the log presenting
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:49,718'); seek(589.0)">
              a single source of truth. Advanced features such as
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:53,264'); seek(593.0)">
              time travel, data transformation with DML, and concurrent
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:57,158'); seek(597.0)">
              read and writes are also expected in data lake to handle use
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:00,612'); seek(600.0)">
              cases such as change data capture and late arriving streaming
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:04,442'); seek(604.0)">
              data over time. You can also expect data lake to have
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:08,372'); seek(608.0)">
              features such AWS, schema evolution and schema enforcement.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:13,110'); seek(613.0)">
              These features allow you to update your schema over time to
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:16,968'); seek(616.0)">
              ensure data quality during ingestion.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:20,390'); seek(620.0)">
              Engine neutrality is also expected in future of
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:23,768'); seek(623.0)">
              data architecture. Today you use a compute engine to process data,
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:28,076'); seek(628.0)">
              but tomorrow you can use different engine for new needs
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:32,730'); seek(632.0)">
              for time travel data lake table format
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:36,594'); seek(636.0)">
              versions, the big data that you store in the data lake.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:40,134'); seek(640.0)">
              You can access any historical versions of the data,
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:43,472'); seek(643.0)">
              simplifying data management with easy to audit rollback
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:46,998'); seek(646.0)">
              data in case of accidental bad writes or deletes and reproduce
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:51,690'); seek(651.0)">
              experiments and reports.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:54,690'); seek(654.0)">
              Time travel enables reproducible queries by allowing two
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:58,308'); seek(658.0)">
              different versions to be queried at same time.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:01,490'); seek(661.0)">
              Opentable format work at scale by automatically checkpointing
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:05,342'); seek(665.0)">
              and summarizing large amounts of data, many files and their
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:09,192'); seek(669.0)">
              metadata.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:12,550'); seek(672.0)">
              So what are your options for creating a data lake house
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:16,268'); seek(676.0)">
              architecture to solve those regular data lake challenges?
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:20,490'); seek(680.0)">
              Customers often face a dilemma when it covers to choosing right
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:24,332'); seek(684.0)">
              data architecture for building data lake house. As such,
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:28,124'); seek(688.0)">
              some customers use data warehouse to
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:31,712'); seek(691.0)">
              eliminate the need of data lakes and the complexity
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:35,510'); seek(695.0)">
              that comes with the data lake. However, a new pattern that
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:38,784'); seek(698.0)">
              is emerging as a popular pattern for implementing
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:42,458'); seek(702.0)">
              data lake house on AWS is to combine both
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:46,164'); seek(706.0)">
              data lake and data warehousing capabilities.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:49,434'); seek(709.0)">
              This pattern is known as lake House architectural pattern.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:54,126'); seek(714.0)">
              There are two options for creating lakes House on AWS,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:58,414'); seek(718.0)">
              which I will talk about in next few slides.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:03,510'); seek(723.0)">
              So before diving into each data lake table format and
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:07,468'); seek(727.0)">
              the lake house architectural options on AWS,
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:11,410'); seek(731.0)">
              let me quickly compare the building blocks
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:14,658'); seek(734.0)">
              that we discussed on or I discussed on previous slide.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:19,550'); seek(739.0)">
              So depending on your needs, a typical organization will
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:23,056'); seek(743.0)">
              need both a data warehouse and
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:26,816'); seek(746.0)">
              data lake that serve different needs and use cases.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:30,770'); seek(750.0)">
              Data lakes store both structured and unstructured
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:34,602'); seek(754.0)">
              data from various other data sources such as
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:37,732'); seek(757.0)">
              mobile apps, IoT devices, and social media.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:41,428'); seek(761.0)">
              The structure of the data or schema is not defined at
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:44,808'); seek(764.0)">
              the time of data collection. This means you can store
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:48,520'); seek(768.0)">
              all your data without having to plan carefully
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:52,670'); seek(772.0)">
              or know what questions you will need to answer in the future.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:57,210'); seek(777.0)">
              A data warehouse is a database optimized for analyzing
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:00,786'); seek(780.0)">
              relational data from transactional systems. Data structures and
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:04,716'); seek(784.0)">
              schemas are predefined to optimize fast SQL queries,
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:08,950'); seek(788.0)">
              the result of which are typically used for operational reporting
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:12,966'); seek(792.0)">
              and analysis. Data is cleaned, enriched, and transformed
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:17,334'); seek(797.0)">
              so that it can serve as a single source of truth that users
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:20,794'); seek(800.0)">
              can rely on. However, once organizations
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:24,426'); seek(804.0)">
              with data warehouse recognize the benefits of data lakes
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:28,282'); seek(808.0)">
              house that provide the functionality of both data lake
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:32,154'); seek(812.0)">
              and data warehouse, they can evolve their data warehouse
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:35,566'); seek(815.0)">
              to include data lake house and enable various
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:39,310'); seek(819.0)">
              query capabilities.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:43,430'); seek(823.0)">
              So the first lake house architecture option is ready to
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:47,068'); seek(827.0)">
              use platform on AWS. This approach
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:51,106'); seek(831.0)">
              allows for separate data warehouse with transactional capabilities
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:55,074'); seek(835.0)">
              such as Amazon, Redshift, and a cost effective
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:58,358'); seek(838.0)">
              scalable data lake on Amazon s three technologies
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:02,614'); seek(842.0)">
              such as Amazon Redshift spectrum can then be used to
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:05,952'); seek(845.0)">
              integrate strategically distributed data in both data
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:09,392'); seek(849.0)">
              warehouse and data lake. This approach definitely
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:12,724'); seek(852.0)">
              simplifies the engineering effort free developers
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:16,794'); seek(856.0)">
              to focus on feature development and leave the infrastructure to the cloud to harness
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:20,906'); seek(860.0)">
              the power of serverless technology from storage to processing
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:24,862'); seek(864.0)">
              and to presentation layer. In this pattern,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:28,510'); seek(868.0)">
              data from various data sources is aggregated
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:31,886'); seek(871.0)">
              into Amazon s three before transformation or loading
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:35,758'); seek(875.0)">
              into data warehouse. This pattern is useful if
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:39,068'); seek(879.0)">
              you want to keep the raw data in the data lake and process data in
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:42,748'); seek(882.0)">
              the data warehouse to avoid scaling cost. With this option,
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:47,390'); seek(887.0)">
              you can take advantage of Amazon Redshift's transactional
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:51,254'); seek(891.0)">
              capabilities and also run low latency analytical queries.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:58,270'); seek(898.0)">
              The second option is do it yourself option for creating
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:01,498'); seek(901.0)">
              a larger data lakes house. Why do it
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:04,868'); seek(904.0)">
              yourself? This pattern is growing in popularity because
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:08,692'); seek(908.0)">
              of three table formats, Apache hoodie, Delta Lake,
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:12,762'); seek(912.0)">
              and Iceberg, that have emerged over the past few
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:15,976'); seek(915.0)">
              years to power data lake house that
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:19,432'); seek(919.0)">
              support acid transactions, time travel,
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:22,376'); seek(922.0)">
              granular access control, and deliver a very good
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:25,912'); seek(925.0)">
              performance compared to regular data lake. These open table
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:29,822'); seek(929.0)">
              data lake formats combines the scalability and
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:33,484'); seek(933.0)">
              cost effectiveness of data lake on Amazon s
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:37,068'); seek(937.0)">
              three and transactional capabilities, reliability and
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:40,416'); seek(940.0)">
              performance of data warehouse to ensure greater scale.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:44,710'); seek(944.0)">
              Table formats or data lake table formats are instrumental for
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:48,512'); seek(948.0)">
              getting the scalability benefits of data lake and the underlying
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:52,634'); seek(952.0)">
              Amazon s three object store, while at the same time getting the data
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:56,612'); seek(956.0)">
              quality and governance associated with data warehouses.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:00,610'); seek(960.0)">
              These data lake table format framework also
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:04,120'); seek(964.0)">
              add additional governance compared to regular data lake.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:08,286'); seek(968.0)">
              Optionally, you can connect Amazon redshift for
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:12,390'); seek(972.0)">
              low latency OLAP access to business ready data.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:19,130'); seek(979.0)">
              Now I will quickly walk through three popular table formats.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:22,834'); seek(982.0)">
              First one is Apache hoodie. Apache Hoodie follows
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:27,370'); seek(987.0)">
              timeline based transaction model. A timeline
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:30,806'); seek(990.0)">
              contains all actions performed on the table at different instance
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:34,582'); seek(994.0)">
              of time. The time could provide instantaneous views
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:38,038'); seek(998.0)">
              of table and support to get data in the order of arrival.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:42,170'); seek(1002.0)">
              Apache Hoodie offers both multi
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:46,138'); seek(1006.0)">
              version concurrency control and optimistic concurrency control.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:50,020'); seek(1010.0)">
              Using multi version concurrency control, Hoodie provides
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:53,502'); seek(1013.0)">
              snapshot isolation between an ingestion writer and
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:57,176'); seek(1017.0)">
              multiple concurrent readers. It also apply
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:01,208'); seek(1021.0)">
              optimistic concurrency control for a reader and writer.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:04,382'); seek(1024.0)">
              Hoodie supports file level optimistic
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:07,922'); seek(1027.0)">
              concurrency control, that is, for any two commits or writers
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:11,794'); seek(1031.0)">
              happening to the same table. If they do not have rights
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:15,346'); seek(1035.0)">
              to overlapping files being changed, both writers
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:19,190'); seek(1039.0)">
              are allowed to succeed. The next one is time
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:22,832'); seek(1042.0)">
              travel. You could also do a time travel. According to hoodie,
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:26,438'); seek(1046.0)">
              commit time hoodie supports schema evolution to
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:30,048'); seek(1050.0)">
              add, delete, modify, and move columns, but it does not
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:33,412'); seek(1053.0)">
              support partition evolution. You cannot change partition
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:36,906'); seek(1056.0)">
              column when it comes to storage optimization.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:40,330'); seek(1060.0)">
              Auto file sizing and auto companies is great for ensuring
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:44,254'); seek(1064.0)">
              storage optimization by avoiding small files in
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:48,152'); seek(1068.0)">
              Apache hoodie, and the last one is indexing. By default.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:52,702'); seek(1072.0)">
              Hoodie uses index that stores mapping between record
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:56,204'); seek(1076.0)">
              key and file group id it belongs to. When modeling,
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:00,386'); seek(1080.0)">
              use record key that is monotonically increasing.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:03,650'); seek(1083.0)">
              For example timestamp prefix for best index performance
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:07,810'); seek(1087.0)">
              by range pruning to filter out the files.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:15,070'); seek(1095.0)">
              The second option is a table format is Apache iceberg.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:18,486'); seek(1098.0)">
              Apache Iceberg follows snapshot based transaction
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:22,298'); seek(1102.0)">
              model. A snapshot is a complete list of files in
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:25,764'); seek(1105.0)">
              the table. The table state is maintained in metadata
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:29,018'); seek(1109.0)">
              files. All changes to table state create a new metadata file
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:33,390'); seek(1113.0)">
              and they replace old metadata file. With atomic swap,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:37,590'); seek(1117.0)">
              iceberg follows optimistic concurrency control.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:41,832'); seek(1121.0)">
              The writers create a table metadata files optimistically assuming
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:45,998'); seek(1125.0)">
              that current version will not be changed before the writers commit.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:50,306'); seek(1130.0)">
              Once writer has created can update, it commits
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:54,242'); seek(1134.0)">
              by swapping the table's metadata file pointer from the base version
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:58,354'); seek(1138.0)">
              to the new version. If the snapshot on which update is
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:01,872'); seek(1141.0)">
              based is no longer current, the writer must retry
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:05,862'); seek(1145.0)">
              the update based on the new version current the
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:09,296'); seek(1149.0)">
              new version time
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:12,772'); seek(1152.0)">
              travel user could also do time travel using according
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:16,618'); seek(1156.0)">
              to snapshot id and timestamp. When it
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:20,564'); seek(1160.0)">
              comes to storage optimization, you can clean up unused older
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:24,318'); seek(1164.0)">
              snapshots by marking them as expired based on certain time period
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:28,958'); seek(1168.0)">
              and then manually run spark job to delete them.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:33,640'); seek(1173.0)">
              To optimize files into larger files, you need
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:37,068'); seek(1177.0)">
              to run spark job in background manually
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:40,770'); seek(1180.0)">
              and the last one is indexing. Apache iceberg uses
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:44,226'); seek(1184.0)">
              value range for columns to skip data files
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:47,986'); seek(1187.0)">
              and partition fields to skip manifest files
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:52,518'); seek(1192.0)">
              when executing query.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:58,190'); seek(1198.0)">
              Delta Lake Delta Lake has a transaction model
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:01,860'); seek(1201.0)">
              based on transaction log. It logs the file operations
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:06,154'); seek(1206.0)">
              in JSON file and then commit to the table using
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:10,612'); seek(1210.0)">
              atomic operations. Delta Lake automatically generates checkpoint
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:14,778'); seek(1214.0)">
              files every ten commits into parquet file.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:18,390'); seek(1218.0)">
              Delta Lake employs optimistic concurrency control optimistic
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:22,238'); seek(1222.0)">
              concurrency control is a method of dealing with concurrent transactions that
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:26,236'); seek(1226.0)">
              assume that transactions or changes made to
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:30,012'); seek(1230.0)">
              table by different users can complete without conflicting with one another.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:35,210'); seek(1235.0)">
              User cloud also do time travel query according to the timestamp
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:39,362'); seek(1239.0)">
              or version number deltax supports
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:43,378'); seek(1243.0)">
              or lets you update schema by a schema of
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:46,944'); seek(1246.0)">
              a table by adding new column or reordering existing column.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:50,826'); seek(1250.0)">
              And when it comes to storage optimization, delta Lake
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:54,442'); seek(1254.0)">
              does not have companies as it follows copy
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:58,602'); seek(1258.0)">
              and write. Hence file sizing is manual.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:02,710'); seek(1262.0)">
              You need to run vacuum and optimize file size
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:05,976'); seek(1265.0)">
              command to convert small files into large files.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:10,710'); seek(1270.0)">
              Delta Lake collects column sets for
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:15,130'); seek(1275.0)">
              data skipping index during query so it takes
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:18,876'); seek(1278.0)">
              advantage of this information, the minimum maximum values
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:22,274'); seek(1282.0)">
              of each column to add query time to provide faster queries.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:26,610'); seek(1286.0)">
              The zorder index technique it uses
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:30,102'); seek(1290.0)">
              to colocate the data skipping information in same file
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:33,958'); seek(1293.0)">
              for a particular column to be used in Z order.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:40,530'); seek(1300.0)">
              So this is a quick snapshot of how these table
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:44,330'); seek(1304.0)">
              formats are integrated with AWS analytics
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:48,442'); seek(1308.0)">
              services. Amazon Athena has better integration with
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:51,812'); seek(1311.0)">
              Apache Iceberg in terms of read write operations, whereas it
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:55,512'); seek(1315.0)">
              supports only read operations on Apache hoodie
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:58,638'); seek(1318.0)">
              and Delta Lake. Amazon redshift spectrum supports
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:02,382'); seek(1322.0)">
              both Apache hoodie and Delta Lake for reading data.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:06,810'); seek(1326.0)">
              EMR and glue supports both read write
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:10,524'); seek(1330.0)">
              against these table formats. These three table formats
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:15,370'); seek(1335.0)">
              you can also manage permissions in Amazon Athena
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:18,582'); seek(1338.0)">
              using AWS Lake formation for Apache hoodie and Apache iceberg
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:22,774'); seek(1342.0)">
              table format. Similarly, you can manage permissions in
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:26,512'); seek(1346.0)">
              Amazon redshift spectrum using AWS Lake formation for
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:30,516'); seek(1350.0)">
              Delta Lake and Apache Hoodie.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:35,650'); seek(1355.0)">
              To conclude, here are final thoughts on choosing data
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:39,252'); seek(1359.0)">
              Lake table format for building lake House architecture on AWS
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:43,034'); seek(1363.0)">
              based on your use case as well as integration with AWS
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:46,782'); seek(1366.0)">
              analytics services. Apache hoodie is considered
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:50,398'); seek(1370.0)">
              suitable for streaming use cases whether it's IoT data or
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:53,832'); seek(1373.0)">
              change data capture from database. Hoodie provides highly
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:57,378'); seek(1377.0)">
              flexible three types of indexes for optimizing
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:00,418'); seek(1380.0)">
              query performance and also optimizing data storage.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:03,970'); seek(1383.0)">
              Because of autofile sizing and clustering optimization feature
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:08,054'); seek(1388.0)">
              backed by index lookup, it is great for streaming use cases.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:12,262'); seek(1392.0)">
              It comes with managed data ingestion tool called delta
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:16,038'); seek(1396.0)">
              Streamer unlike other two table formats.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:19,470'); seek(1399.0)">
              Second option is Apache Iceberg. If you're looking for
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:22,884'); seek(1402.0)">
              easy management of schema and partition evolution,
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:25,914'); seek(1405.0)">
              then Apache Iceberg is suitable table format. One of
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:29,124'); seek(1409.0)">
              the advantage of Apache iceberg is how it handles partitions.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:33,226'); seek(1413.0)">
              Basically IT services partition value from data fields used
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:37,000'); seek(1417.0)">
              in a SQL where condition.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:39,854'); seek(1419.0)">
              One does not need to specify exact partition key in
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:43,224'); seek(1423.0)">
              the SQL query. Unlike Hoodie
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:47,218'); seek(1427.0)">
              and Delta Lake, Iceberg allows easily to change
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:50,428'); seek(1430.0)">
              partition column on table. It simply starts writing to
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:54,604'); seek(1434.0)">
              new partition. Third option is Delta
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:58,354'); seek(1438.0)">
              Lake. This table format is suitable if your data platform is
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:02,172'); seek(1442.0)">
              built around spark framework with deep integration of spark features.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:05,618'); seek(1445.0)">
              AWS Delta Lake stores all metadata state information in
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:09,292'); seek(1449.0)">
              transaction log and checkpoint files instead of metastore.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:12,746'); seek(1452.0)">
              You can use separate spark cluster to build table
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:16,682'); seek(1456.0)">
              state independently without relying on central Metastore
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:20,314'); seek(1460.0)">
              and this really helps to scale and meet the performance requirements
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:24,250'); seek(1464.0)">
              depending on your spark cluster size. Thank you for listening. Me and my
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:28,068'); seek(1468.0)">
              colleague hope you all enjoyed this session.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Cloud%20Native%202023%20-%20Satish%20Mane%20_%20Rajeev%20Jahswal_.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Cloud%20Native%202023%20-%20Satish%20Mane%20_%20Rajeev%20Jahswal_.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #7B2726;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/cloud2023" class="btn btn-sm btn-danger shadow lift" style="background-color: #7B2726;">
                <i class="fe fe-grid me-2"></i>
                See all 54 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/cloud_satish_mane_rajeev_jaiiswal.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Satish Mane
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Solutions Architect @ AWS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/satish-mane-216b2661/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Satish Mane's LinkedIn account" />
                  </a>
                  
                  
                </p>
                
                <!-- Author 2 -->
                <h2 class="me-2">
                  Rajeev Jaiiswal
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Solutions Architect @ AWS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-8">
                  
                  <a href="https://www.linkedin.com/in/rajeevjaiiswal/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Rajeev Jaiiswal's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Satish Mane"
                  data-url="https://www.conf42.com/cloud2023"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/cloud2023"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Cloud Native"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>