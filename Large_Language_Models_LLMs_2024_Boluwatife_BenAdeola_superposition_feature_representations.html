<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Superposition in LLM Feature Representations</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Boluwatife%20Ben-Adeola_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Superposition in LLM Feature Representations | Conf42"/>
    <meta property="og:description" content="Dive into the quantum realm of LLMs! Join me as we unravel the superposition in LLM feature representations, exploring the intersection of finance, technology, and AI interpretability. Unearth insights from my journey at Bloomberg, Palantir, and my pursuit of mechanistic interpretability."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2024_Boluwatife_BenAdeola_superposition_feature_representations"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/ML2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Machine Learning 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-05-30
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ml2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday San Francisco
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday London
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2024 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2024-04-11">April 11 2024</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2024-04-11T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-11T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "0xpgLo4-cX4"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "TQwxk0c4sh0"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBjR6ZR0g0LRq9Fp8c_4HrI" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi there. My name is Bolu, and today I\u0027m going to talk about superposition", "timestamp": "00:00:20,720", "timestamp_s": 20.0}, {"text": "in neural network representations. So I guess it motivates that", "timestamp": "00:00:24,350", "timestamp_s": 24.0}, {"text": "a bit. I\u0027ll share some context about where this hypothesis comes", "timestamp": "00:00:28,280", "timestamp_s": 28.0}, {"text": "from or the field of neural network research.", "timestamp": "00:00:31,960", "timestamp_s": 31.0}, {"text": "This field is called mechanistic interpretability, and basically it", "timestamp": "00:00:35,624", "timestamp_s": 35.0}, {"text": "follows from the following reasoning. Okay, so we all understand that neural", "timestamp": "00:00:40,696", "timestamp_s": 40.0}, {"text": "networks solve an increasing number of important tasks really well,", "timestamp": "00:00:44,024", "timestamp_s": 44.0}, {"text": "and it would be at least interesting and probably important to understand", "timestamp": "00:00:47,864", "timestamp_s": 47.0}, {"text": "how they do that. So mechanrap is basically a subfield that tackled", "timestamp": "00:00:51,536", "timestamp_s": 51.0}, {"text": "this problem by seeking granular mechanistic", "timestamp": "00:00:55,692", "timestamp_s": 55.0}, {"text": "explanations for different observed behaviors in neural networks.", "timestamp": "00:00:59,052", "timestamp_s": 59.0}, {"text": "It\u0027s basically pushing back on the idea that neural networks are just these black", "timestamp": "00:01:03,460", "timestamp_s": 63.0}, {"text": "boxes that are completely inscrutable and just do magic", "timestamp": "00:01:06,884", "timestamp_s": 66.0}, {"text": "with linear algebra. So it pairs into a given network", "timestamp": "00:01:10,596", "timestamp_s": 70.0}, {"text": "at a granular level to investigate some very isolated behavior.", "timestamp": "00:01:14,500", "timestamp_s": 74.0}, {"text": "At the same time, it also has very broad hypotheses and", "timestamp": "00:01:19,354", "timestamp_s": 79.0}, {"text": "theories about how neural networks do things. And one of these", "timestamp": "00:01:23,210", "timestamp_s": 83.0}, {"text": "is about representation learning.", "timestamp": "00:01:26,626", "timestamp_s": 86.0}, {"text": "That is, how do neural networks learn which representations to use for inputs,", "timestamp": "00:01:30,074", "timestamp_s": 90.0}, {"text": "and how are these inputs, how these representations passed around in", "timestamp": "00:01:34,610", "timestamp_s": 94.0}, {"text": "the computation? That\u0027s what this", "timestamp": "00:01:38,378", "timestamp_s": 98.0}, {"text": "is basically understanding what a model sees and how it does.", "timestamp": "00:01:41,850", "timestamp_s": 101.0}, {"text": "So what informations have model found important to look for?", "timestamp": "00:01:45,146", "timestamp_s": 105.0}, {"text": "And how is information propagated and I guess represented", "timestamp": "00:01:48,572", "timestamp_s": 108.0}, {"text": "and propagated internally in the network? I guess to", "timestamp": "00:01:52,012", "timestamp_s": 112.0}, {"text": "paint a picture of what we mean by representations and propagation.", "timestamp": "00:01:55,916", "timestamp_s": 115.0}, {"text": "So basically, at the bottom left, on the bottom left here, we have,", "timestamp": "00:01:59,364", "timestamp_s": 119.0}, {"text": "let\u0027s just say this is like a simple tokenized version of", "timestamp": "00:02:03,484", "timestamp_s": 123.0}, {"text": "input you\u0027re going to pass on to based on a", "timestamp": "00:02:07,164", "timestamp_s": 127.0}, {"text": "transformer, right? So you have like on colon, off wet colon,", "timestamp": "00:02:10,428", "timestamp_s": 130.0}, {"text": "dry old colon. And I guess, as any of us would,", "timestamp": "00:02:13,644", "timestamp_s": 133.0}, {"text": "would attest to from using something like chat JPT,", "timestamp": "00:02:17,156", "timestamp_s": 137.0}, {"text": "these neural networks are definitely able to predict that old. I figure", "timestamp": "00:02:20,204", "timestamp_s": 140.0}, {"text": "that the next thing is going to be old colon, new, right,", "timestamp": "00:02:24,204", "timestamp_s": 144.0}, {"text": "since you can figure out what you were in opposite. So the idea is,", "timestamp": "00:02:27,916", "timestamp_s": 147.0}, {"text": "between this entry of our text and the prediction", "timestamp": "00:02:31,484", "timestamp_s": 151.0}, {"text": "on the other side, entire network has to have", "timestamp": "00:02:35,020", "timestamp_s": 155.0}, {"text": "encoded certain information and done computations", "timestamp": "00:02:38,972", "timestamp_s": 158.0}, {"text": "in the process to get this output of, oh, the next thing to", "timestamp": "00:02:42,428", "timestamp_s": 162.0}, {"text": "come after this column is new. So basically", "timestamp": "00:02:46,050", "timestamp_s": 166.0}, {"text": "what we\u0027re trying to ask is, okay, just what do we know and what can", "timestamp": "00:02:49,522", "timestamp_s": 169.0}, {"text": "we investigate about how this information", "timestamp": "00:02:52,650", "timestamp_s": 172.0}, {"text": "is encoded? Right? So, because in the beginning, all it knows is that I\u0027m a", "timestamp": "00:02:56,210", "timestamp_s": 176.0}, {"text": "column again. After going through just the embedded network of mapping the column", "timestamp": "00:02:58,978", "timestamp_s": 178.0}, {"text": "character to a collection", "timestamp": "00:03:02,554", "timestamp_s": 182.0}, {"text": "of numbers are just called vectors of ordered vectors, as you can see there in", "timestamp": "00:03:07,370", "timestamp_s": 187.0}, {"text": "the column. So the question is summer between entry on", "timestamp": "00:03:10,226", "timestamp_s": 190.0}, {"text": "I\u0027m a column to exiting on, my next is new,", "timestamp": "00:03:13,930", "timestamp_s": 193.0}, {"text": "which is again the result of", "timestamp": "00:03:17,666", "timestamp_s": 197.0}, {"text": "this vector going through an unembedding layer and the softmax, and again the", "timestamp": "00:03:21,282", "timestamp_s": 201.0}, {"text": "highest probability weight being attributed to as.", "timestamp": "00:03:25,290", "timestamp_s": 205.0}, {"text": "Again, just for simplicity, let\u0027s assume the word new is", "timestamp": "00:03:28,602", "timestamp_s": 208.0}, {"text": "its own token, because as we know, prediction is done on a token basis.", "timestamp": "00:03:32,330", "timestamp_s": 212.0}, {"text": "So, right, so somewhere between signing with M and Colin and my next is new", "timestamp": "00:03:37,294", "timestamp_s": 217.0}, {"text": "is a bunch of stuff. So what do we know about", "timestamp": "00:03:40,894", "timestamp_s": 220.0}, {"text": "what these representations look like internally? All right,", "timestamp": "00:03:45,126", "timestamp_s": 225.0}, {"text": "so here are a couple qualities of these representations", "timestamp": "00:03:49,078", "timestamp_s": 229.0}, {"text": "that the starting school of mechanistic", "timestamp": "00:03:52,854", "timestamp_s": 232.0}, {"text": "interpretability posits. Basically, it says", "timestamp": "00:03:56,118", "timestamp_s": 236.0}, {"text": "that there are discrete features that a model", "timestamp": "00:03:59,718", "timestamp_s": 239.0}, {"text": "has learned to look for in an input, and these discrete features", "timestamp": "00:04:03,736", "timestamp_s": 243.0}, {"text": "basically compose into giving any given representation, right?", "timestamp": "00:04:07,280", "timestamp_s": 247.0}, {"text": "So if we looked at any layer or at any component in the architecture,", "timestamp": "00:04:10,784", "timestamp_s": 250.0}, {"text": "all the information the model has at that stage is basically going to be", "timestamp": "00:04:16,224", "timestamp_s": 256.0}, {"text": "some composition of discrete things.", "timestamp": "00:04:20,120", "timestamp_s": 260.0}, {"text": "And the second is linearity. And so this", "timestamp": "00:04:23,584", "timestamp_s": 263.0}, {"text": "basically takes the composite, the decomposability statement, a bit further to say", "timestamp": "00:04:27,288", "timestamp_s": 267.0}, {"text": "that not only are these discrete components composed", "timestamp": "00:04:31,280", "timestamp_s": 271.0}, {"text": "together, they\u0027re composed linearly. And again, we\u0027ll discuss a bit", "timestamp": "00:04:35,158", "timestamp_s": 275.0}, {"text": "later what exactly that means. And the third basically just says", "timestamp": "00:04:38,774", "timestamp_s": 278.0}, {"text": "we can think of these discrete qualities as something called features. And again,", "timestamp": "00:04:43,374", "timestamp_s": 283.0}, {"text": "the precise time code definition for what features are comes", "timestamp": "00:04:47,166", "timestamp_s": 287.0}, {"text": "later. So I guess maybe to summarize, maybe this, like one", "timestamp": "00:04:50,422", "timestamp_s": 290.0}, {"text": "single line or tagline, it probably, like summarizes the school", "timestamp": "00:04:53,974", "timestamp_s": 293.0}, {"text": "of thought that says language model. Again, you can replace your neural network", "timestamp": "00:04:57,262", "timestamp_s": 297.0}, {"text": "representation that basically have similar architectures.", "timestamp": "00:05:00,766", "timestamp_s": 300.0}, {"text": "Language model representations are linearly decomposable", "timestamp": "00:05:04,694", "timestamp_s": 304.0}, {"text": "in two features, right? So we\u0027re going to pick apart each one", "timestamp": "00:05:09,630", "timestamp_s": 309.0}, {"text": "of those, of those items in the course of this talk.", "timestamp": "00:05:13,086", "timestamp_s": 313.0}, {"text": "The first, again, is this is kind of a weak statement.", "timestamp": "00:05:18,694", "timestamp_s": 318.0}, {"text": "It\u0027s not that strong. And I\u0027ll explain why. In isolation,", "timestamp": "00:05:22,550", "timestamp_s": 322.0}, {"text": "decomposability just basically means that, well, we assume", "timestamp": "00:05:25,926", "timestamp_s": 325.0}, {"text": "that neural networks learn different things. That is,", "timestamp": "00:05:29,814", "timestamp_s": 329.0}, {"text": "giving a neural network doesn\u0027t just basically", "timestamp": "00:05:33,982", "timestamp_s": 333.0}, {"text": "memorize every simple potential input.", "timestamp": "00:05:37,790", "timestamp_s": 337.0}, {"text": "It learns to abstract certain features", "timestamp": "00:05:41,318", "timestamp_s": 341.0}, {"text": "like blueness or redness, or perhaps even more general,", "timestamp": "00:05:45,734", "timestamp_s": 345.0}, {"text": "to color. Right? If it has a general abstraction for", "timestamp": "00:05:49,038", "timestamp_s": 349.0}, {"text": "color representations. Again, in this simple case,", "timestamp": "00:05:53,134", "timestamp_s": 353.0}, {"text": "we have a neural network that may be trained to identify colors", "timestamp": "00:05:56,608", "timestamp_s": 356.0}, {"text": "and shapes like. So let\u0027s just say maybe this is like some classification", "timestamp": "00:06:00,944", "timestamp_s": 360.0}, {"text": "neural network, right? And the idea is that, okay, somewhere in, you know,", "timestamp": "00:06:05,664", "timestamp_s": 365.0}, {"text": "all linear network weights are", "timestamp": "00:06:09,584", "timestamp_s": 369.0}, {"text": "basically transformations that are able to extract certain", "timestamp": "00:06:14,312", "timestamp_s": 374.0}, {"text": "discrete qualities such as the center shape or", "timestamp": "00:06:19,736", "timestamp_s": 379.0}, {"text": "the background color. Right here simplify this. We just look for blueness or", "timestamp": "00:06:23,540", "timestamp_s": 383.0}, {"text": "redness on the left. But the interesting thing is, well, this is kind", "timestamp": "00:06:27,420", "timestamp_s": 387.0}, {"text": "of just saying sometimes neural networks don\u0027t overfit, which is why", "timestamp": "00:06:30,708", "timestamp_s": 390.0}, {"text": "I say this is kind of a weak statement because like, sure, like it\u0027s pretty", "timestamp": "00:06:33,996", "timestamp_s": 393.0}, {"text": "obvious that, yes, I mean, or at least like anyone", "timestamp": "00:06:36,364", "timestamp_s": 396.0}, {"text": "that has training neural network can demonstrate in", "timestamp": "00:06:39,572", "timestamp_s": 399.0}, {"text": "with like a test set to show that yes, indeed,", "timestamp": "00:06:43,684", "timestamp_s": 403.0}, {"text": "these neural networks can generalize and not everything is overfitting or memorizing.", "timestamp": "00:06:46,724", "timestamp_s": 406.0}, {"text": "So on the right there, if we have something like a purple triangle", "timestamp": "00:06:50,324", "timestamp_s": 410.0}, {"text": "that supposedly this neural network has not seen in training before,", "timestamp": "00:06:54,972", "timestamp_s": 414.0}, {"text": "it could depend on its previous, previously learned features to", "timestamp": "00:06:58,500", "timestamp_s": 418.0}, {"text": "say that, well, even though it doesn\u0027t quite have the conception of purple as a", "timestamp": "00:07:02,380", "timestamp_s": 422.0}, {"text": "distinct thing, it could compose of the color purple as being", "timestamp": "00:07:05,828", "timestamp_s": 425.0}, {"text": "perhaps reading the RGB values, being equally composed of", "timestamp": "00:07:11,364", "timestamp_s": 431.0}, {"text": "red and blue values.", "timestamp": "00:07:16,284", "timestamp_s": 436.0}, {"text": "So. Right, so at this day, like all, that\u0027s all decomposability is saying,", "timestamp": "00:07:20,174", "timestamp_s": 440.0}, {"text": "there\u0027s certain things in this diagram that are quite strong assumptions.", "timestamp": "00:07:24,270", "timestamp_s": 444.0}, {"text": "Again, this whole idea that, oh, there\u0027s one thing called a blue neuron,", "timestamp": "00:07:27,814", "timestamp_s": 447.0}, {"text": "as we\u0027ll see, that\u0027s a pretty strong thing to say. And it\u0027s not obvious at", "timestamp": "00:07:31,102", "timestamp_s": 451.0}, {"text": "all that this is how things play out in reality. But again, at this stage,", "timestamp": "00:07:34,270", "timestamp_s": 454.0}, {"text": "decomposability just says irreproentation is composed", "timestamp": "00:07:38,070", "timestamp_s": 458.0}, {"text": "of a bunch of little stuff. Because in your own work,", "timestamp": "00:07:41,550", "timestamp_s": 461.0}, {"text": "again, demonstrably does not just generalize all the time. Right?", "timestamp": "00:07:44,654", "timestamp_s": 464.0}, {"text": "Again, for sufficient size for spatially small problem set.", "timestamp": "00:07:48,126", "timestamp_s": 468.0}, {"text": "The second is linearity. So this again takes the decomposability", "timestamp": "00:07:52,894", "timestamp_s": 472.0}, {"text": "property a bit further. You say, okay, cool. Not only are these different", "timestamp": "00:07:57,654", "timestamp_s": 477.0}, {"text": "properties, well, distinct or different, they combine", "timestamp": "00:08:00,934", "timestamp_s": 480.0}, {"text": "linear sums quite simply,", "timestamp": "00:08:06,454", "timestamp_s": 486.0}, {"text": "which basically just says, if you can imagine a vector", "timestamp": "00:08:09,494", "timestamp_s": 489.0}, {"text": "representing a certain vector direction representing", "timestamp": "00:08:13,998", "timestamp_s": 493.0}, {"text": "some feature. And again,", "timestamp": "00:08:17,974", "timestamp_s": 497.0}, {"text": "this is an as contrived. Remember looking at this", "timestamp": "00:08:22,214", "timestamp_s": 502.0}, {"text": "diagram, the inputs are", "timestamp": "00:08:25,566", "timestamp_s": 505.0}, {"text": "already ordered collectible numbers. So again, everything that\u0027s for a colon is already inherently", "timestamp": "00:08:28,750", "timestamp_s": 508.0}, {"text": "having this vector format. I should mention though, just because a thing", "timestamp": "00:08:33,494", "timestamp_s": 513.0}, {"text": "is an order to collection of numbers, it doesn\u0027t mean it has to be linear,", "timestamp": "00:08:37,702", "timestamp_s": 517.0}, {"text": "right? So it\u0027s a bit confusing, obviously, because it has this like", "timestamp": "00:08:40,886", "timestamp_s": 520.0}, {"text": "vector formatting of, again, an order to collection of numbers", "timestamp": "00:08:45,954", "timestamp_s": 525.0}, {"text": "relating to one entity, then surely it was obviously mini direction.", "timestamp": "00:08:49,546", "timestamp_s": 529.0}, {"text": "That is not obvious. And again, I\u0027ll show you examples of what that", "timestamp": "00:08:53,274", "timestamp_s": 533.0}, {"text": "looks like when it\u0027s not the case. Okay, so again, the larynx", "timestamp": "00:08:57,874", "timestamp_s": 537.0}, {"text": "says these decomposable sub vectors", "timestamp": "00:09:01,458", "timestamp_s": 541.0}, {"text": "basically, literally just add together to give you", "timestamp": "00:09:05,538", "timestamp_s": 545.0}, {"text": "the representation for something, right? So here we have how the,", "timestamp": "00:09:09,250", "timestamp_s": 549.0}, {"text": "some other neural network that cares about size and", "timestamp": "00:09:13,644", "timestamp_s": 553.0}, {"text": "redness in the abstract has", "timestamp": "00:09:17,324", "timestamp_s": 557.0}, {"text": "two different directions. Again, given it only has two", "timestamp": "00:09:21,556", "timestamp_s": 561.0}, {"text": "features or qualities it cares about, it can dedicate two different directions to", "timestamp": "00:09:25,100", "timestamp_s": 565.0}, {"text": "it, right? And then these directions can simply combine to represent", "timestamp": "00:09:29,108", "timestamp_s": 569.0}, {"text": "any one given input. And again, like, how do", "timestamp": "00:09:33,164", "timestamp_s": 573.0}, {"text": "we have any evidence for this in practice? Is that. Yes, I guess", "timestamp": "00:09:36,908", "timestamp_s": 576.0}, {"text": "this is a bit of a popular example", "timestamp": "00:09:40,874", "timestamp_s": 580.0}, {"text": "by now, but there was a paper that came out a couple years ago that", "timestamp": "00:09:44,034", "timestamp_s": 584.0}, {"text": "basically showed regularities in the differences", "timestamp": "00:09:47,810", "timestamp_s": 587.0}, {"text": "between pairs of vectors. So the difference between the", "timestamp": "00:09:51,082", "timestamp_s": 591.0}, {"text": "man and woman, again, this is like the man and woman, let\u0027s say", "timestamp": "00:09:54,842", "timestamp_s": 594.0}, {"text": "word representation in certain language", "timestamp": "00:09:58,378", "timestamp_s": 598.0}, {"text": "model architectures was consistent. So if you do something", "timestamp": "00:10:02,954", "timestamp_s": 602.0}, {"text": "as silly as, let\u0027s say, subtracted the vector, again, just the ordered collection", "timestamp": "00:10:06,658", "timestamp_s": 606.0}, {"text": "of numbers for, of uncle from the vector for", "timestamp": "00:10:10,370", "timestamp_s": 610.0}, {"text": "aunt, and you simply just impose that on, let\u0027s say,", "timestamp": "00:10:14,234", "timestamp_s": 614.0}, {"text": "some other pair on something like", "timestamp": "00:10:17,810", "timestamp_s": 617.0}, {"text": "man, you would end up with precisely the", "timestamp": "00:10:22,794", "timestamp_s": 622.0}, {"text": "vector called woman, right? And you have a bit of this like vector algebra", "timestamp": "00:10:27,234", "timestamp_s": 627.0}, {"text": "here on the right with the card. Again, let\u0027s assume this is like another relationship", "timestamp": "00:10:30,554", "timestamp_s": 630.0}, {"text": "of plurals, again of", "timestamp": "00:10:33,882", "timestamp_s": 633.0}, {"text": "like cars, the vector recognition for cars. If you subtract the", "timestamp": "00:10:37,628", "timestamp_s": 637.0}, {"text": "singular recognition for car and add to apple,", "timestamp": "00:10:41,820", "timestamp_s": 641.0}, {"text": "you get something like apples, right? So this kind of behavior of literal,", "timestamp": "00:10:45,180", "timestamp_s": 645.0}, {"text": "like ordered subtraction of", "timestamp": "00:10:48,380", "timestamp_s": 648.0}, {"text": "values is what you would see in a linear", "timestamp": "00:10:52,140", "timestamp_s": 652.0}, {"text": "system, right? A system where the masculine,", "timestamp": "00:10:56,116", "timestamp_s": 656.0}, {"text": "you know, this abstract feature of this is referring", "timestamp": "00:11:01,084", "timestamp_s": 661.0}, {"text": "to a masculine entity is encoded with all", "timestamp": "00:11:04,488", "timestamp_s": 664.0}, {"text": "the other stuff that has to do with royalty in king, or has to do", "timestamp": "00:11:08,168", "timestamp_s": 668.0}, {"text": "with relatives or relatives of siblings,", "timestamp": "00:11:12,048", "timestamp_s": 672.0}, {"text": "of your parents, an uncle and aunt, or just again, in the literal", "timestamp": "00:11:16,080", "timestamp_s": 676.0}, {"text": "world, man and woman. Effectively,", "timestamp": "00:11:19,792", "timestamp_s": 679.0}, {"text": "if these two, if these multiple things are composed in a linear fashion,", "timestamp": "00:11:23,568", "timestamp_s": 683.0}, {"text": "then you can get it. We\u0027ll be doing things like this, vector subtraction", "timestamp": "00:11:27,352", "timestamp_s": 687.0}, {"text": "and arithmetic as we\u0027re seeing here, right? But again,", "timestamp": "00:11:31,620", "timestamp_s": 691.0}, {"text": "this doesn\u0027t mean everything completely is indeed, right. So this is part,", "timestamp": "00:11:34,596", "timestamp_s": 694.0}, {"text": "this is just for the embedding layer. And again, to remind us what the embedding", "timestamp": "00:11:38,276", "timestamp_s": 698.0}, {"text": "layer is, it is the very bottom of this, right? It\u0027s,", "timestamp": "00:11:41,660", "timestamp_s": 701.0}, {"text": "there\u0027s still a lot of uncertainty as to sure, if maybe for", "timestamp": "00:11:45,804", "timestamp_s": 705.0}, {"text": "simple things like embedding a word, you get this vector", "timestamp": "00:11:49,372", "timestamp_s": 709.0}, {"text": "algebra, does that mean like for everything? And all the layers in the network,", "timestamp": "00:11:53,156", "timestamp_s": 713.0}, {"text": "all the information that it has to encode is in fact", "timestamp": "00:11:56,900", "timestamp_s": 716.0}, {"text": "composed in this linear fashion. Right. So that is why there\u0027s still a mystery,", "timestamp": "00:12:01,420", "timestamp_s": 721.0}, {"text": "even though we have seen some evidence. I guess, as I mentioned,", "timestamp": "00:12:04,452", "timestamp_s": 724.0}, {"text": "it would be worth noting that again, just because a thing is an ordered", "timestamp": "00:12:08,180", "timestamp_s": 728.0}, {"text": "collection of numbers, again, which is how neural networks tend to", "timestamp": "00:12:12,404", "timestamp_s": 732.0}, {"text": "be like represented or simply just how they are, this kind of,", "timestamp": "00:12:15,788", "timestamp_s": 735.0}, {"text": "this meme around how neural networks are just linear algebra", "timestamp": "00:12:19,068", "timestamp_s": 739.0}, {"text": "scaled up. Well, just because things aren\u0027t auto collection numbers doesn\u0027t", "timestamp": "00:12:23,210", "timestamp_s": 743.0}, {"text": "necessarily mean that they are linear, right? Linearity is a very particular", "timestamp": "00:12:27,002", "timestamp_s": 747.0}, {"text": "statement about how different entities interact. Right?", "timestamp": "00:12:30,482", "timestamp_s": 750.0}, {"text": "So here\u0027s an example of, again on, we can imagine a different", "timestamp": "00:12:33,682", "timestamp_s": 753.0}, {"text": "regime where we had a neural network that again", "timestamp": "00:12:37,250", "timestamp_s": 757.0}, {"text": "was able to extract a discrete component for redness and another", "timestamp": "00:12:42,218", "timestamp_s": 762.0}, {"text": "for blueness, but then join", "timestamp": "00:12:45,506", "timestamp_s": 765.0}, {"text": "them together. It did something like, well, maybe just exploited the", "timestamp": "00:12:49,054", "timestamp_s": 769.0}, {"text": "simple precision", "timestamp": "00:12:53,814", "timestamp_s": 773.0}, {"text": "decimal places. Again, how it does this,", "timestamp": "00:12:57,302", "timestamp_s": 777.0}, {"text": "again, special edition, is by simply just taking the first", "timestamp": "00:13:00,630", "timestamp_s": 780.0}, {"text": "thing on the left and then making it the value to one decimal", "timestamp": "00:13:03,982", "timestamp_s": 783.0}, {"text": "place and taking the other thing. And here you have an algorithm to", "timestamp": "00:13:07,630", "timestamp_s": 787.0}, {"text": "do this. Again, this is an example of a non web winner expression.", "timestamp": "00:13:11,686", "timestamp_s": 791.0}, {"text": "Um, and again, like the component of this that makes it nonlinear is,", "timestamp": "00:13:16,522", "timestamp_s": 796.0}, {"text": "you see, it relies on the floor operation. Again, this is like from,", "timestamp": "00:13:19,562", "timestamp_s": 799.0}, {"text": "like from a python, except that like math or floor, it basically just", "timestamp": "00:13:23,690", "timestamp_s": 803.0}, {"text": "like tries to do, do the rounding. That\u0027s basically how they exploit this like,", "timestamp": "00:13:27,370", "timestamp_s": 807.0}, {"text": "um, precision and placement to basically like squish", "timestamp": "00:13:30,762", "timestamp_s": 810.0}, {"text": "these two different values together. Right? So again, so this is just like one,", "timestamp": "00:13:35,154", "timestamp_s": 815.0}, {"text": "I guess like dummy example of showing that, well, yes,", "timestamp": "00:13:37,978", "timestamp_s": 817.0}, {"text": "things ordered collection of numbers can act in", "timestamp": "00:13:41,498", "timestamp_s": 821.0}, {"text": "ways that are not quite vector like or don\u0027t quite simply just", "timestamp": "00:13:44,938", "timestamp_s": 824.0}, {"text": "do addition. Right? You do have other compression schemes,", "timestamp": "00:13:48,810", "timestamp_s": 828.0}, {"text": "right? And so what the linear representation is saying is that actually", "timestamp": "00:13:53,714", "timestamp_s": 833.0}, {"text": "on the journey from, again, the input of I am a column,", "timestamp": "00:13:58,914", "timestamp_s": 838.0}, {"text": "which is what like the embedding does to the output.", "timestamp": "00:14:02,498", "timestamp_s": 842.0}, {"text": "All the information it has at that point. Again, all the information at this", "timestamp": "00:14:06,314", "timestamp_s": 846.0}, {"text": "single um, column and the input has maintained as it", "timestamp": "00:14:09,962", "timestamp_s": 849.0}, {"text": "went through all the layers were simply just", "timestamp": "00:14:13,666", "timestamp_s": 853.0}, {"text": "added to each other. Right? There\u0027s one vector that represents, oh, there\u0027s something,", "timestamp": "00:14:16,858", "timestamp_s": 856.0}, {"text": "there\u0027s a bit of like a word and opposite game going on. And there was", "timestamp": "00:14:20,866", "timestamp_s": 860.0}, {"text": "an interesting paper that, that showed up to say that actually, yes,", "timestamp": "00:14:24,426", "timestamp_s": 864.0}, {"text": "not just nouns or discrete informations about inputs", "timestamp": "00:14:27,746", "timestamp_s": 867.0}, {"text": "can be encoded, but also abstract things like functions. Right? Again, this whole idea", "timestamp": "00:14:31,602", "timestamp_s": 871.0}, {"text": "of, oh, this is a word and opposite game that\u0027s been played here between", "timestamp": "00:14:35,522", "timestamp_s": 875.0}, {"text": "wet and dry, old and new, etc. That itself is", "timestamp": "00:14:38,954", "timestamp_s": 878.0}, {"text": "one vector and yet another vector. Again, this,", "timestamp": "00:14:42,298", "timestamp_s": 882.0}, {"text": "this is something that attention can give us, right? Being able", "timestamp": "00:14:45,570", "timestamp_s": 885.0}, {"text": "to basically like, look at previous inputs. So again,", "timestamp": "00:14:48,962", "timestamp_s": 888.0}, {"text": "the colon token is able to like, look behind,", "timestamp": "00:14:52,698", "timestamp_s": 892.0}, {"text": "immediately behind it. See that all the thing that came before me is old and", "timestamp": "00:14:55,898", "timestamp_s": 895.0}, {"text": "also is able to look maybe further back to other", "timestamp": "00:14:59,098", "timestamp_s": 899.0}, {"text": "things to like glean the pattern of words and opposites, right? All these different", "timestamp": "00:15:02,354", "timestamp_s": 902.0}, {"text": "bits of information are literally just different vectors or different", "timestamp": "00:15:06,538", "timestamp_s": 906.0}, {"text": "directions that compose as", "timestamp": "00:15:10,176", "timestamp_s": 910.0}, {"text": "simple additions to end with the conclusion", "timestamp": "00:15:13,488", "timestamp_s": 913.0}, {"text": "of. Okay, surely my next thing is new.", "timestamp": "00:15:16,832", "timestamp_s": 916.0}, {"text": "Again, the representations aren\u0027t really concerned with how the", "timestamp": "00:15:20,184", "timestamp_s": 920.0}, {"text": "network is doing combination that is like, like, what are the mechanics inside of", "timestamp": "00:15:24,336", "timestamp_s": 924.0}, {"text": "it that know how to do that? Okay, giving this vector for work opposite this", "timestamp": "00:15:27,896", "timestamp_s": 927.0}, {"text": "vector for this. How does it do that? Like, again, there\u0027s another body of work", "timestamp": "00:15:30,920", "timestamp_s": 930.0}, {"text": "that explores basically this, like, algorithmic interpretability.", "timestamp": "00:15:33,952", "timestamp_s": 933.0}, {"text": "This is just saying, um, basically the variables that is being used for these", "timestamp": "00:15:37,128", "timestamp_s": 937.0}, {"text": "computations, what do you look like and how are the variables that composed?", "timestamp": "00:15:40,800", "timestamp_s": 940.0}, {"text": "Again, by how? I mean, like how in a sense of, like,", "timestamp": "00:15:46,224", "timestamp_s": 946.0}, {"text": "are they saying, like, do you have weird stuff like this going on where", "timestamp": "00:15:49,760", "timestamp_s": 949.0}, {"text": "it\u0027s like, in the c, in the space of all potential transformations,", "timestamp": "00:15:53,488", "timestamp_s": 953.0}, {"text": "of taking redness and blueness together to get purpleness?", "timestamp": "00:15:57,888", "timestamp_s": 957.0}, {"text": "Um, is it like some unknown arbitrary thing which would be messy", "timestamp": "00:16:00,832", "timestamp_s": 960.0}, {"text": "and hard, or is it just literally symbol vector addition?", "timestamp": "00:16:04,098", "timestamp_s": 964.0}, {"text": "Um, so that\u0027s what recommendation is as being like,", "timestamp": "00:16:07,530", "timestamp_s": 967.0}, {"text": "distinct to like, algorithmic, um, interpretation, interpretability.", "timestamp": "00:16:10,882", "timestamp_s": 970.0}, {"text": "Um, right. So again, as we see here, um, again,", "timestamp": "00:16:15,474", "timestamp_s": 975.0}, {"text": "just think of the linear composition as just a compression scheme for", "timestamp": "00:16:18,586", "timestamp_s": 978.0}, {"text": "how all this information is packed together. Okay? So linearity", "timestamp": "00:16:22,346", "timestamp_s": 982.0}, {"text": "is great because it basically helps us narrow down, again, as I said, like one", "timestamp": "00:16:25,802", "timestamp_s": 985.0}, {"text": "compression algorithm in a very large function space. So there are many things, again,", "timestamp": "00:16:29,552", "timestamp_s": 989.0}, {"text": "these are the giant networks to be doing in their, like, typical inscrutable fashion.", "timestamp": "00:16:33,072", "timestamp_s": 993.0}, {"text": "So linearity is pretty helpful in that actually kind of narrows it", "timestamp": "00:16:37,776", "timestamp_s": 997.0}, {"text": "down to one like,", "timestamp": "00:16:41,240", "timestamp_s": 1001.0}, {"text": "well known, unstudied,", "timestamp": "00:16:44,544", "timestamp_s": 1004.0}, {"text": "basically like compression scheme, right? Which is the entire field of linear algebra.", "timestamp": "00:16:47,624", "timestamp_s": 1007.0}, {"text": "Right? If it happens to be linear. And also the other things that", "timestamp": "00:16:52,184", "timestamp_s": 1012.0}, {"text": "this gives us as well, which is, it aids in", "timestamp": "00:16:56,204", "timestamp_s": 1016.0}, {"text": "diagnostics and helps improve our", "timestamp": "00:17:00,428", "timestamp_s": 1020.0}, {"text": "understanding of the models in ways that, again, if there were some,", "timestamp": "00:17:04,812", "timestamp_s": 1024.0}, {"text": "if, for example, in every single representation or every single layer,", "timestamp": "00:17:07,996", "timestamp_s": 1027.0}, {"text": "use a different type of arbitrary algorithm, will be hard.", "timestamp": "00:17:11,836", "timestamp_s": 1031.0}, {"text": "So, yeah, it basically would be very convenient if", "timestamp": "00:17:15,260", "timestamp_s": 1035.0}, {"text": "this was the case. Right? And again, we have seen some evidence for it.", "timestamp": "00:17:20,256", "timestamp_s": 1040.0}, {"text": "Right? So this is just an important point to make where to", "timestamp": "00:17:22,960", "timestamp_s": 1042.0}, {"text": "state that this is a combination of having some evidence, but also there\u0027s a", "timestamp": "00:17:27,512", "timestamp_s": 1047.0}, {"text": "bit of a motivated inquiry into this. Right? Again,", "timestamp": "00:17:31,136", "timestamp_s": 1051.0}, {"text": "if this wasn\u0027t something we cared about, there are many things about neural networks that", "timestamp": "00:17:34,944", "timestamp_s": 1054.0}, {"text": "seem to be interesting, but people just haven\u0027t really dug", "timestamp": "00:17:37,728", "timestamp_s": 1057.0}, {"text": "into. But the fact that they seem to have inner behavior has", "timestamp": "00:17:41,376", "timestamp_s": 1061.0}, {"text": "drawn a very large community of researchers to study just", "timestamp": "00:17:45,596", "timestamp_s": 1065.0}, {"text": "why. Because, again, it makes the problem a lot more tractable", "timestamp": "00:17:49,364", "timestamp_s": 1069.0}, {"text": "than if it wasn\u0027t the case. Right? And yes,", "timestamp": "00:17:52,916", "timestamp_s": 1072.0}, {"text": "I guess I put here effectively mind control being like, they\u0027re a bit of like.", "timestamp": "00:17:56,012", "timestamp_s": 1076.0}, {"text": "As these tools become more mature to understand what\u0027s happening, we get", "timestamp": "00:17:59,508", "timestamp_s": 1079.0}, {"text": "to do different things, like everything from mind reading to mind control.", "timestamp": "00:18:02,820", "timestamp_s": 1082.0}, {"text": "That is like, again, if you get to run your strand", "timestamp": "00:18:06,628", "timestamp_s": 1086.0}, {"text": "brain on a computer and you have access to all the numbers and you understand", "timestamp": "00:18:10,204", "timestamp_s": 1090.0}, {"text": "the general, both the algorithms for how the information is", "timestamp": "00:18:13,156", "timestamp_s": 1093.0}, {"text": "represented and how the information is transformed, then you can eventually, like,", "timestamp": "00:18:16,700", "timestamp_s": 1096.0}, {"text": "intervene and or at least just like, you know,", "timestamp": "00:18:19,884", "timestamp_s": 1099.0}, {"text": "have a log stream on what\u0027s going on.", "timestamp": "00:18:23,612", "timestamp_s": 1103.0}, {"text": "Cool. So that\u0027s the motivation for why linear composability is great,", "timestamp": "00:18:27,084", "timestamp_s": 1107.0}, {"text": "right? Because again, it\u0027s a algorithm for", "timestamp": "00:18:30,716", "timestamp_s": 1110.0}, {"text": "these transformers to use for understanding.", "timestamp": "00:18:34,772", "timestamp_s": 1114.0}, {"text": "Okay, here is a bit of the downside,", "timestamp": "00:18:38,004", "timestamp_s": 1118.0}, {"text": "is that linearity is kind of demanding in", "timestamp": "00:18:40,888", "timestamp_s": 1120.0}, {"text": "that it basically says that to have", "timestamp": "00:18:44,000", "timestamp_s": 1124.0}, {"text": "a lossless compression scheme that composes linearly,", "timestamp": "00:18:48,056", "timestamp_s": 1128.0}, {"text": "it requires as many dimensions, that is, as many of those different", "timestamp": "00:18:52,432", "timestamp_s": 1132.0}, {"text": "boxes, as many, like, of the. As many", "timestamp": "00:18:55,856", "timestamp_s": 1135.0}, {"text": "distinct ordered numbers in the collected set as", "timestamp": "00:18:59,848", "timestamp_s": 1139.0}, {"text": "you have qualities you want to encode. Right. As you can see here,", "timestamp": "00:19:04,784", "timestamp_s": 1144.0}, {"text": "again, we have something for redness, for blueness, for squareness, for triangles. And then,", "timestamp": "00:19:09,834", "timestamp_s": 1149.0}, {"text": "like, as you see, basically, you have this like, one hot vector kind of", "timestamp": "00:19:13,090", "timestamp_s": 1153.0}, {"text": "situation going where the thing that makes one of these", "timestamp": "00:19:17,234", "timestamp_s": 1157.0}, {"text": "directions and code for the property", "timestamp": "00:19:20,906", "timestamp_s": 1160.0}, {"text": "of redness is that it is only the first cell", "timestamp": "00:19:24,050", "timestamp_s": 1164.0}, {"text": "that activates for it. Now, I do want to point out that there\u0027s", "timestamp": "00:19:27,738", "timestamp_s": 1167.0}, {"text": "a slight difference between just the dimensions and, uh,", "timestamp": "00:19:31,018", "timestamp_s": 1171.0}, {"text": "like, the number of dimensions is the requirement.", "timestamp": "00:19:34,480", "timestamp_s": 1174.0}, {"text": "It doesn\u0027t necessarily mean, though, that you would always have this perfect idea of,", "timestamp": "00:19:37,440", "timestamp_s": 1177.0}, {"text": "uh, one cell coordinating to", "timestamp": "00:19:41,960", "timestamp_s": 1181.0}, {"text": "one thing, right? You. You could basically have, like, there are,", "timestamp": "00:19:45,200", "timestamp_s": 1185.0}, {"text": "you know, infinite many, um, orthogonal bases", "timestamp": "00:19:49,024", "timestamp_s": 1189.0}, {"text": "that are able to achieve this. Basically, all you just want is that for,", "timestamp": "00:19:53,312", "timestamp_s": 1193.0}, {"text": "you want to have as many orthogonal, um, directions as", "timestamp": "00:19:56,600", "timestamp_s": 1196.0}, {"text": "you have features, right? Again, just for the sake of,", "timestamp": "00:20:00,268", "timestamp_s": 1200.0}, {"text": "like, easier understanding, we just focus on the", "timestamp": "00:20:03,772", "timestamp_s": 1203.0}, {"text": "one in this very large, this infinite set of orthogonal", "timestamp": "00:20:07,084", "timestamp_s": 1207.0}, {"text": "bases that happens to be one hot encoded,", "timestamp": "00:20:10,652", "timestamp_s": 1210.0}, {"text": "right? So just going for. Just imagine", "timestamp": "00:20:14,620", "timestamp_s": 1214.0}, {"text": "that every time I talk about a neuron", "timestamp": "00:20:18,132", "timestamp_s": 1218.0}, {"text": "or a dimension. I just literally mean one neuron, but that\u0027s not necessarily the case.", "timestamp": "00:20:21,660", "timestamp_s": 1221.0}, {"text": "Cool. So why is this a problem? Okay,", "timestamp": "00:20:26,404", "timestamp_s": 1226.0}, {"text": "so let\u0027s just like, again, to remind ourselves of, like, where we\u0027re at right now.", "timestamp": "00:20:30,364", "timestamp_s": 1230.0}, {"text": "Again, this certain hypothesis for how representation is done says that", "timestamp": "00:20:33,428", "timestamp_s": 1233.0}, {"text": "language model, large language model representations are linearly decomposable,", "timestamp": "00:20:37,588", "timestamp_s": 1237.0}, {"text": "composable into features. Okay, this brings", "timestamp": "00:20:41,484", "timestamp_s": 1241.0}, {"text": "us to the linear organizational puzzle. Why is this a puzzle?", "timestamp": "00:20:45,500", "timestamp_s": 1245.0}, {"text": "So basically, in a couple steps, first, we have", "timestamp": "00:20:48,924", "timestamp_s": 1248.0}, {"text": "some evidence that indeed we LLMs do represent stuff linearly.", "timestamp": "00:20:52,628", "timestamp_s": 1252.0}, {"text": "Right? Again, so, like, meaning this,", "timestamp": "00:20:55,828", "timestamp_s": 1255.0}, {"text": "this claim has, you know, some basis in reality,", "timestamp": "00:20:58,604", "timestamp_s": 1258.0}, {"text": "right? And again, there are several other arguments in research to suggest", "timestamp": "00:21:02,212", "timestamp_s": 1262.0}, {"text": "that, like, this behavior is more likely, or like,", "timestamp": "00:21:05,836", "timestamp_s": 1265.0}, {"text": "or has either from, or can be observed", "timestamp": "00:21:09,940", "timestamp_s": 1269.0}, {"text": "either from, like, looking at the number of flops that are dedicated to the transformations", "timestamp": "00:21:13,468", "timestamp_s": 1273.0}, {"text": "versus not, etc. Cool. So linear", "timestamp": "00:21:16,500", "timestamp_s": 1276.0}, {"text": "stuff is happening. Linear combinations", "timestamp": "00:21:20,632", "timestamp_s": 1280.0}, {"text": "require as many dimensions or neurons,", "timestamp": "00:21:24,336", "timestamp_s": 1284.0}, {"text": "again, which is, again, a subset of the case of", "timestamp": "00:21:27,344", "timestamp_s": 1287.0}, {"text": "orthogonal basis as features. If you want to encode for redness,", "timestamp": "00:21:30,496", "timestamp_s": 1290.0}, {"text": "blueness, triangle ness and squareness,", "timestamp": "00:21:34,496", "timestamp_s": 1294.0}, {"text": "you need literally four different things. Again, if you want to encode these things distinctly", "timestamp": "00:21:38,128", "timestamp_s": 1298.0}, {"text": "as being different things, you need four different", "timestamp": "00:21:42,024", "timestamp_s": 1302.0}, {"text": "directions. However, and this is", "timestamp": "00:21:45,144", "timestamp_s": 1305.0}, {"text": "where the puzzle comes in experience, it seems", "timestamp": "00:21:48,668", "timestamp_s": 1308.0}, {"text": "that these networks are able to represent way more stuff", "timestamp": "00:21:53,092", "timestamp_s": 1313.0}, {"text": "than they have neurons for. Right? And again, I have a bit of a back", "timestamp": "00:21:57,068", "timestamp_s": 1317.0}, {"text": "of the envelope calculation here, where GPT-2 has an order of hundreds of thousands", "timestamp": "00:22:00,268", "timestamp_s": 1320.0}, {"text": "of neurons. Again, the exact numbers might vary on the architecture,", "timestamp": "00:22:04,068", "timestamp_s": 1324.0}, {"text": "basically, but if you look at the number of attention heads, MLP layers,", "timestamp": "00:22:08,548", "timestamp_s": 1328.0}, {"text": "and the dimensions that these architecture", "timestamp": "00:22:12,292", "timestamp_s": 1332.0}, {"text": "components operate with, um, you, you\u0027re in the order of a couple", "timestamp": "00:22:15,842", "timestamp_s": 1335.0}, {"text": "hundred thousands of neurons. Uh, and the assumption", "timestamp": "00:22:19,906", "timestamp_s": 1339.0}, {"text": "is that these models encode a lot more than that. And if", "timestamp": "00:22:23,842", "timestamp_s": 1343.0}, {"text": "you\u0027re finding hard to wrap your hand around, what about how 100,000,", "timestamp": "00:22:27,106", "timestamp_s": 1347.0}, {"text": "a couple hundred thousand, um, features is not enough. Remember that,", "timestamp": "00:22:31,994", "timestamp_s": 1351.0}, {"text": "again, this is encoding all of the english language, right?", "timestamp": "00:22:35,706", "timestamp_s": 1355.0}, {"text": "Or all of language, if you recall how", "timestamp": "00:22:38,762", "timestamp_s": 1358.0}, {"text": "well GBD two was able to perform, it is plausible to that, yes, it probably", "timestamp": "00:22:42,810", "timestamp_s": 1362.0}, {"text": "encodes a lot more than a couple hundred thousand features,", "timestamp": "00:22:46,434", "timestamp_s": 1366.0}, {"text": "because again, this is all of language itself.", "timestamp": "00:22:50,306", "timestamp_s": 1370.0}, {"text": "The question is, how is that possible? Again, we know that linear.", "timestamp": "00:22:53,794", "timestamp_s": 1373.0}, {"text": "So basically, we seem to have conflicting or contradicting evidence when", "timestamp": "00:22:57,842", "timestamp_s": 1377.0}, {"text": "we have evidence of linearity, but at the same time,", "timestamp": "00:23:01,210", "timestamp_s": 1381.0}, {"text": "we have all needs, which is as many", "timestamp": "00:23:04,034", "timestamp_s": 1384.0}, {"text": "neurons as it has features. But at the same time, we have models in", "timestamp": "00:23:07,762", "timestamp_s": 1387.0}, {"text": "production, we have external models that seem to do quite", "timestamp": "00:23:12,630", "timestamp_s": 1392.0}, {"text": "well without having as many neurons", "timestamp": "00:23:16,174", "timestamp_s": 1396.0}, {"text": "as they seem to have features. Right. Again,", "timestamp": "00:23:20,358", "timestamp_s": 1400.0}, {"text": "to appreciate why this is a puzzle, you just have to depend on your", "timestamp": "00:23:25,054", "timestamp_s": 1405.0}, {"text": "gut feeling of there are probably more than 200,000 things that", "timestamp": "00:23:28,302", "timestamp_s": 1408.0}, {"text": "you need to be looking for in. In any given standards.", "timestamp": "00:23:32,318", "timestamp_s": 1412.0}, {"text": "Remember how open ended all of language is?", "timestamp": "00:23:35,330", "timestamp_s": 1415.0}, {"text": "And again, this is one of the difficulties in describing what exactly a", "timestamp": "00:23:39,674", "timestamp_s": 1419.0}, {"text": "feature is. A feature,", "timestamp": "00:23:43,330", "timestamp_s": 1423.0}, {"text": "I think, of a feature is one helpful definition. Feature is a", "timestamp": "00:23:46,154", "timestamp_s": 1426.0}, {"text": "thing that a neuron would be dedicated to in a sufficiently", "timestamp": "00:23:50,874", "timestamp_s": 1430.0}, {"text": "large language model. But again,", "timestamp": "00:23:54,426", "timestamp_s": 1434.0}, {"text": "we get to that shortly. Okay, cool. So this is our puzzle. How is this", "timestamp": "00:23:57,890", "timestamp_s": 1437.0}, {"text": "happening? There\u0027s a great paper that came from a team at", "timestamp": "00:24:01,362", "timestamp_s": 1441.0}, {"text": "Anthropoc that basically tries to. Basically building off of", "timestamp": "00:24:04,710", "timestamp_s": 1444.0}, {"text": "previous work. Exploring this puzzle suggests", "timestamp": "00:24:08,294", "timestamp_s": 1448.0}, {"text": "a way forward on tackling what exactly", "timestamp": "00:24:12,070", "timestamp_s": 1452.0}, {"text": "is going on and basically being able to.", "timestamp": "00:24:15,550", "timestamp_s": 1455.0}, {"text": "Being able to disentangle all the mess that seems to", "timestamp": "00:24:19,094", "timestamp_s": 1459.0}, {"text": "be happening, because, again, something strange. But I guess basically,", "timestamp": "00:24:22,606", "timestamp_s": 1462.0}, {"text": "before this paper came out, the same team introduced", "timestamp": "00:24:26,134", "timestamp_s": 1466.0}, {"text": "the idea of superposition.", "timestamp": "00:24:29,686", "timestamp_s": 1469.0}, {"text": "And superposition is basically a hypothesis that attempts", "timestamp": "00:24:33,190", "timestamp_s": 1473.0}, {"text": "to answer the puzzle the riddle of how can a model do more represent", "timestamp": "00:24:37,286", "timestamp_s": 1477.0}, {"text": "more features than it has neurons?", "timestamp": "00:24:41,462", "timestamp_s": 1481.0}, {"text": "Now, it effectively says that neural networks are", "timestamp": "00:24:44,534", "timestamp_s": 1484.0}, {"text": "able to do this because they exploit", "timestamp": "00:24:47,998", "timestamp_s": 1487.0}, {"text": "feature sparsity and the relative feature importance.", "timestamp": "00:24:51,470", "timestamp_s": 1491.0}, {"text": "It basically just says that, like, the model does not, in fact,", "timestamp": "00:24:56,694", "timestamp_s": 1496.0}, {"text": "do perfectly lossless compression, but it", "timestamp": "00:25:00,478", "timestamp_s": 1500.0}, {"text": "trades that off in exchange for representing more features,", "timestamp": "00:25:03,702", "timestamp_s": 1503.0}, {"text": "because of a property called like", "timestamp": "00:25:08,534", "timestamp_s": 1508.0}, {"text": "feature sparsity, which basically means that, again, even though the english language,", "timestamp": "00:25:11,990", "timestamp_s": 1511.0}, {"text": "or like any arbitrary text in english language, or like, in the set of all", "timestamp": "00:25:15,222", "timestamp_s": 1515.0}, {"text": "possible texts of coherent english language sentences,", "timestamp": "00:25:18,470", "timestamp_s": 1518.0}, {"text": "or perhaps not even coherent,", "timestamp": "00:25:22,062", "timestamp_s": 1522.0}, {"text": "even though those contain a very large number of features,", "timestamp": "00:25:24,974", "timestamp_s": 1524.0}, {"text": "it turns out not all those features are active at the same time.", "timestamp": "00:25:29,134", "timestamp_s": 1529.0}, {"text": "And there\u0027s a great. And this provides an opportunity for a", "timestamp": "00:25:32,854", "timestamp_s": 1532.0}, {"text": "trade off where we can say, okay, what if I choose a", "timestamp": "00:25:36,238", "timestamp_s": 1536.0}, {"text": "not perfectly orthogonal set of", "timestamp": "00:25:40,118", "timestamp_s": 1540.0}, {"text": "vectors to represent my features, which, again, is the requirement for", "timestamp": "00:25:43,390", "timestamp_s": 1543.0}, {"text": "that to be a lossless compression. What if,", "timestamp": "00:25:47,342", "timestamp_s": 1547.0}, {"text": "instead, I chose n plus", "timestamp": "00:25:50,102", "timestamp_s": 1550.0}, {"text": "m, actually a bit more than this ideal", "timestamp": "00:25:54,102", "timestamp_s": 1554.0}, {"text": "set of perfectly orthogonal vectors, and in exchange,", "timestamp": "00:25:57,334", "timestamp_s": 1557.0}, {"text": "basically, each additional direct feature direction that I", "timestamp": "00:26:01,214", "timestamp_s": 1561.0}, {"text": "add basically adds some noise.", "timestamp": "00:26:05,278", "timestamp_s": 1565.0}, {"text": "Again, using the compression analogy, add some noise.", "timestamp": "00:26:08,678", "timestamp_s": 1568.0}, {"text": "Basically, I trade off a little bit of noise for", "timestamp": "00:26:11,502", "timestamp_s": 1571.0}, {"text": "having a much wider set of features that can", "timestamp": "00:26:16,120", "timestamp_s": 1576.0}, {"text": "represent. And again, this only works if all features are not present", "timestamp": "00:26:19,400", "timestamp_s": 1579.0}, {"text": "together, because, again, if all features are present all the time,", "timestamp": "00:26:22,616", "timestamp_s": 1582.0}, {"text": "that, again, if you have no sparsity, you will", "timestamp": "00:26:26,168", "timestamp_s": 1586.0}, {"text": "have noise in all your outputs.", "timestamp": "00:26:29,472", "timestamp_s": 1589.0}, {"text": "And, yeah, this is actually what this is saying, right?", "timestamp": "00:26:33,664", "timestamp_s": 1593.0}, {"text": "So in the top and the top three boxes you have", "timestamp": "00:26:37,024", "timestamp_s": 1597.0}, {"text": "there is basically saying, okay, you have,", "timestamp": "00:26:40,720", "timestamp_s": 1600.0}, {"text": "again, all the different dots are meant to be different features", "timestamp": "00:26:44,194", "timestamp_s": 1604.0}, {"text": "that your model cares about. Again, maybe one of them is redness, one of them", "timestamp": "00:26:48,090", "timestamp_s": 1608.0}, {"text": "is blue nest, one of them is square nest, etc.", "timestamp": "00:26:50,586", "timestamp_s": 1610.0}, {"text": "And you can see you have like a two dimensional surface. You have", "timestamp": "00:26:54,194", "timestamp_s": 1614.0}, {"text": "a two dimensional surface. In the case where there\u0027s", "timestamp": "00:26:57,658", "timestamp_s": 1617.0}, {"text": "no sparsity, where every feature is as likely to be important", "timestamp": "00:27:01,218", "timestamp_s": 1621.0}, {"text": "as the other, you effectively have,", "timestamp": "00:27:05,354", "timestamp_s": 1625.0}, {"text": "um, what we, what we expect that is", "timestamp": "00:27:08,458", "timestamp_s": 1628.0}, {"text": "like the neural network indeed only has two directions to represent the", "timestamp": "00:27:12,070", "timestamp_s": 1632.0}, {"text": "two things. Um, most important thing it cares about. Okay? And again,", "timestamp": "00:27:15,798", "timestamp_s": 1635.0}, {"text": "let\u0027s just imagine right now that they\u0027re all equally important. So you just like,", "timestamp": "00:27:19,254", "timestamp_s": 1639.0}, {"text": "randomly chooses two features. Again, maybe it only cares about,", "timestamp": "00:27:22,302", "timestamp_s": 1642.0}, {"text": "um, having a distinction between redness and.", "timestamp": "00:27:25,470", "timestamp_s": 1645.0}, {"text": "And it\u0027s unable to have a distinction between squareness", "timestamp": "00:27:29,734", "timestamp_s": 1649.0}, {"text": "and triangle nest, for example. Right? It basically just chooses like, one pair.", "timestamp": "00:27:33,910", "timestamp_s": 1653.0}, {"text": "That is, you know, is the best it can do", "timestamp": "00:27:37,890", "timestamp_s": 1657.0}, {"text": "to like, get a good classification loss on", "timestamp": "00:27:41,802", "timestamp_s": 1661.0}, {"text": "the problem set. Okay? But it turns out that as", "timestamp": "00:27:46,346", "timestamp_s": 1666.0}, {"text": "you increase sparsity, right, as you maybe make redness", "timestamp": "00:27:49,610", "timestamp_s": 1669.0}, {"text": "and circleness not as common. For example,", "timestamp": "00:27:55,882", "timestamp_s": 1675.0}, {"text": "let\u0027s say you had a case whereby sometimes", "timestamp": "00:27:59,362", "timestamp_s": 1679.0}, {"text": "the image has no shape in the middle. That is, sometimes it\u0027s", "timestamp": "00:28:03,266", "timestamp_s": 1683.0}, {"text": "just color that matters, and sometimes you have a completely colorless input,", "timestamp": "00:28:06,950", "timestamp_s": 1686.0}, {"text": "but it\u0027s just the shape in the middle. Right? And that\u0027s what sparsity means,", "timestamp": "00:28:10,710", "timestamp_s": 1690.0}, {"text": "right? Where you have like, two different. In this", "timestamp": "00:28:13,606", "timestamp_s": 1693.0}, {"text": "case, you have like more than two different properties", "timestamp": "00:28:17,390", "timestamp_s": 1697.0}, {"text": "that don\u0027t always coincide together, right? It turns out that", "timestamp": "00:28:21,494", "timestamp_s": 1701.0}, {"text": "in the 80% sparsity example, as you see here, it actually", "timestamp": "00:28:26,494", "timestamp_s": 1706.0}, {"text": "chooses to represent more features than it should be", "timestamp": "00:28:30,644", "timestamp_s": 1710.0}, {"text": "able to, right? Again, this is consistent with what we see in the experience.", "timestamp": "00:28:33,868", "timestamp_s": 1713.0}, {"text": "And on the right here, you see 90% sparsity case. It basically", "timestamp": "00:28:37,404", "timestamp_s": 1717.0}, {"text": "has that direction showing that, okay, that\u0027s what spark, that\u0027s what indifference means.", "timestamp": "00:28:41,228", "timestamp_s": 1721.0}, {"text": "Because the whole point of having an orthogonal basis is that if", "timestamp": "00:28:45,404", "timestamp_s": 1725.0}, {"text": "you try to extract the component feature, that, again, you have some vector,", "timestamp": "00:28:49,540", "timestamp_s": 1729.0}, {"text": "and then you have only, again, two potential orthogonal,", "timestamp": "00:28:53,340", "timestamp_s": 1733.0}, {"text": "um, features. If you do a dot product against each", "timestamp": "00:28:56,924", "timestamp_s": 1736.0}, {"text": "of these, each value you get is, um,", "timestamp": "00:29:00,276", "timestamp_s": 1740.0}, {"text": "basically saying how much this giving vector", "timestamp": "00:29:04,444", "timestamp_s": 1744.0}, {"text": "is composed of", "timestamp": "00:29:08,748", "timestamp_s": 1748.0}, {"text": "each of those directions. So basically, if you have, again, some direction", "timestamp": "00:29:12,348", "timestamp_s": 1752.0}, {"text": "for some representation of a red", "timestamp": "00:29:16,476", "timestamp_s": 1756.0}, {"text": "square, basically if you take a dot product of that against the", "timestamp": "00:29:20,908", "timestamp_s": 1760.0}, {"text": "redness direction, it gives you, oh, this is either really red or", "timestamp": "00:29:24,980", "timestamp_s": 1764.0}, {"text": "not that much red. And take a dot product of that against the", "timestamp": "00:29:28,316", "timestamp_s": 1768.0}, {"text": "squared direction. It says, oh, how much of it does", "timestamp": "00:29:33,812", "timestamp_s": 1773.0}, {"text": "this look like? A square? Right. So basically, so that\u0027s why these needs to be", "timestamp": "00:29:36,980", "timestamp_s": 1776.0}, {"text": "orthogonal. Like they shouldn\u0027t interfere with each other. Like the quality of redness", "timestamp": "00:29:39,716", "timestamp_s": 1779.0}, {"text": "should only interfere with the quality of squareness, if that makes sense.", "timestamp": "00:29:43,412", "timestamp_s": 1783.0}, {"text": "So that\u0027s why orthogonality is important. However,", "timestamp": "00:29:47,604", "timestamp_s": 1787.0}, {"text": "again, if sometimes you basically just", "timestamp": "00:29:51,156", "timestamp_s": 1791.0}, {"text": "get a colorless square or, or you get a", "timestamp": "00:29:54,276", "timestamp_s": 1794.0}, {"text": "shapeless color, basically you just have any potential color. There\u0027s a", "timestamp": "00:29:58,804", "timestamp_s": 1798.0}, {"text": "shape at either sparsity where you don\u0027t always have cases where these two show", "timestamp": "00:30:02,028", "timestamp_s": 1802.0}, {"text": "up together. And again, for your problem set,", "timestamp": "00:30:06,740", "timestamp_s": 1806.0}, {"text": "you only need to care about these in isolation. That is, you only need to", "timestamp": "00:30:10,628", "timestamp_s": 1810.0}, {"text": "be really good at detecting color sometimes or detecting shape sometimes.", "timestamp": "00:30:13,788", "timestamp_s": 1813.0}, {"text": "It turns out that you actually be fine if", "timestamp": "00:30:18,092", "timestamp_s": 1818.0}, {"text": "you chose directions for squareness and redness", "timestamp": "00:30:21,844", "timestamp_s": 1821.0}, {"text": "that interfered with that is what the bottom example", "timestamp": "00:30:25,012", "timestamp_s": 1825.0}, {"text": "is trying to show. Okay? So on the bottom left square,", "timestamp": "00:30:28,580", "timestamp_s": 1828.0}, {"text": "you, our, let\u0027s say our orange vector is the thing that we actually", "timestamp": "00:30:32,052", "timestamp_s": 1832.0}, {"text": "want to observe. Again, it\u0027s our red square, right?", "timestamp": "00:30:36,212", "timestamp_s": 1836.0}, {"text": "It\u0027s a thing, it\u0027s the input is the true", "timestamp": "00:30:39,612", "timestamp_s": 1839.0}, {"text": "input vector, right? And you", "timestamp": "00:30:43,156", "timestamp_s": 1843.0}, {"text": "see that, again, we have five different directions, five different features.", "timestamp": "00:30:47,124", "timestamp_s": 1847.0}, {"text": "There\u0027s this, if you take a dot product of this value against all the different,", "timestamp": "00:30:52,304", "timestamp_s": 1852.0}, {"text": "five different vectors to see, like, how much it,", "timestamp": "00:30:56,192", "timestamp_s": 1856.0}, {"text": "it has a value with all of them. So you see it is along one", "timestamp": "00:30:59,952", "timestamp_s": 1859.0}, {"text": "direction, for example, right? So that direction would have is given value, right? Let\u0027s say", "timestamp": "00:31:03,632", "timestamp_s": 1863.0}, {"text": "that direction means how red it is. However,", "timestamp": "00:31:07,128", "timestamp_s": 1867.0}, {"text": "because there\u0027s interference. It has tiny little vectors that", "timestamp": "00:31:09,912", "timestamp_s": 1869.0}, {"text": "are going in along the other features that it actually", "timestamp": "00:31:13,488", "timestamp_s": 1873.0}, {"text": "doesn\u0027t have. Again, work. Let\u0027s imagine that in this case, we have", "timestamp": "00:31:17,040", "timestamp_s": 1877.0}, {"text": "a simple case of where, oh, this input is simply just, again,", "timestamp": "00:31:20,478", "timestamp_s": 1880.0}, {"text": "a very red input, right? It\u0027s just like a red blob or like a red", "timestamp": "00:31:24,150", "timestamp_s": 1884.0}, {"text": "square, right? Sorry, not a red square, like, I mean, just like a red image.", "timestamp": "00:31:27,958", "timestamp_s": 1887.0}, {"text": "There\u0027s nothing else in it. So indeed it is aligns perfectly with one of", "timestamp": "00:31:31,534", "timestamp_s": 1891.0}, {"text": "the features. But again, but because in this representation, again,", "timestamp": "00:31:35,366", "timestamp_s": 1895.0}, {"text": "you have only two dimensions, two pure dimensions, but then", "timestamp": "00:31:38,558", "timestamp_s": 1898.0}, {"text": "you\u0027re trying to squish five different things inside. Um,", "timestamp": "00:31:41,918", "timestamp_s": 1901.0}, {"text": "you would actually have a little bit of, it would pick up a", "timestamp": "00:31:45,226", "timestamp_s": 1905.0}, {"text": "little bit of a component along other features that", "timestamp": "00:31:48,650", "timestamp_s": 1908.0}, {"text": "it actually doesn\u0027t have. So that\u0027s what interference is.", "timestamp": "00:31:52,386", "timestamp_s": 1912.0}, {"text": "Um, and however, why this works is that neural", "timestamp": "00:31:56,034", "timestamp_s": 1916.0}, {"text": "networks have non linearities. Um, basically, like the activation", "timestamp": "00:31:59,754", "timestamp_s": 1919.0}, {"text": "functions, um, are non linearies that are able to basically", "timestamp": "00:32:03,794", "timestamp_s": 1923.0}, {"text": "turn off these, um, tiny,", "timestamp": "00:32:08,538", "timestamp_s": 1928.0}, {"text": "tiny bits of noise, right. If they didn\u0027t", "timestamp": "00:32:12,524", "timestamp_s": 1932.0}, {"text": "have that, then the bits of noise become quite annoying and", "timestamp": "00:32:15,812", "timestamp_s": 1935.0}, {"text": "would actually, like, count more towards your errors. But because again, in a", "timestamp": "00:32:19,300", "timestamp_s": 1939.0}, {"text": "case whereby there\u0027s actually is very little annoyance", "timestamp": "00:32:22,628", "timestamp_s": 1942.0}, {"text": "coming from the other values in the dot product, these are able", "timestamp": "00:32:27,756", "timestamp_s": 1947.0}, {"text": "to be tuned off effectively. Right, so now let\u0027s imagine", "timestamp": "00:32:31,172", "timestamp_s": 1951.0}, {"text": "now on the bottom right. In this case, let\u0027s imagine", "timestamp": "00:32:35,108", "timestamp_s": 1955.0}, {"text": "that the true input, again, like this thing we care about,", "timestamp": "00:32:38,350", "timestamp_s": 1958.0}, {"text": "the two blue vectors. Again, that is, you have something", "timestamp": "00:32:43,534", "timestamp_s": 1963.0}, {"text": "that is a really big square and", "timestamp": "00:32:47,118", "timestamp_s": 1967.0}, {"text": "also a really yellow background.", "timestamp": "00:32:50,446", "timestamp_s": 1970.0}, {"text": "Okay? So again, you have squareness and you have yellowness.", "timestamp": "00:32:54,126", "timestamp_s": 1974.0}, {"text": "If you can observe this vector", "timestamp": "00:32:58,534", "timestamp_s": 1978.0}, {"text": "addition of these two, again, remember, were operating in like a linear combination", "timestamp": "00:33:02,086", "timestamp_s": 1982.0}, {"text": "regime. This is exactly the", "timestamp": "00:33:05,804", "timestamp_s": 1985.0}, {"text": "same thing as we get on the left. This is why interference", "timestamp": "00:33:09,788", "timestamp_s": 1989.0}, {"text": "is important, because interference requires that, like, for it to work. There should be only", "timestamp": "00:33:13,268", "timestamp_s": 1993.0}, {"text": "very few number of things in this case, like, just say like, for interference to", "timestamp": "00:33:16,876", "timestamp_s": 1996.0}, {"text": "have no impact here, it should only be one feature", "timestamp": "00:33:20,100", "timestamp_s": 2000.0}, {"text": "that is truly trying to be detected at a time. But in a case whereby", "timestamp": "00:33:23,540", "timestamp_s": 2003.0}, {"text": "the two blue directions are trying to be,", "timestamp": "00:33:27,108", "timestamp_s": 2007.0}, {"text": "um, it would look to our system,", "timestamp": "00:33:29,756", "timestamp_s": 2009.0}, {"text": "our neural network, as if it was actually this case", "timestamp": "00:33:33,408", "timestamp_s": 2013.0}, {"text": "on the left. And in. And as we\u0027ve seen, it is going to end", "timestamp": "00:33:36,704", "timestamp_s": 2016.0}, {"text": "up chipping away those two different values to nothing because", "timestamp": "00:33:40,312", "timestamp_s": 2020.0}, {"text": "of the non linearities. I\u0027m going to think that, oh, actually, instead of", "timestamp": "00:33:43,672", "timestamp_s": 2023.0}, {"text": "seeing a square, a yellow square, it\u0027s just going to see", "timestamp": "00:33:47,280", "timestamp_s": 2027.0}, {"text": "a circle. Maybe that\u0027s what that third direction represents, which is", "timestamp": "00:33:51,024", "timestamp_s": 2031.0}, {"text": "complete noise, isn\u0027t it? Which is completely wrong, so to", "timestamp": "00:33:54,272", "timestamp_s": 2034.0}, {"text": "speak. Right. This is basically going to end up ignoring the components of this vector", "timestamp": "00:33:57,718", "timestamp_s": 2037.0}, {"text": "along those two as just being noise, which is really", "timestamp": "00:34:01,550", "timestamp_s": 2041.0}, {"text": "bad, which is really why, in the case where there\u0027s no sparsity, where, like,", "timestamp": "00:34:04,694", "timestamp_s": 2044.0}, {"text": "again, all the features are likely to be active, the neural network doesn\u0027t even", "timestamp": "00:34:08,030", "timestamp_s": 2048.0}, {"text": "bother trying to do anything funny. It doesn\u0027t try any funny", "timestamp": "00:34:12,022", "timestamp_s": 2052.0}, {"text": "business asset in the top left square. It simply just", "timestamp": "00:34:15,150", "timestamp_s": 2055.0}, {"text": "represents, you know, again, an arbitrary two features.", "timestamp": "00:34:19,734", "timestamp_s": 2059.0}, {"text": "Or in a case whereby it\u0027s able to have a sense of relative importance", "timestamp": "00:34:22,806", "timestamp_s": 2062.0}, {"text": "of features, maybe, like, one feature is way more important in", "timestamp": "00:34:27,504", "timestamp_s": 2067.0}, {"text": "determining. To give you an example, let\u0027s say", "timestamp": "00:34:31,824", "timestamp_s": 2071.0}, {"text": "one feature of language is, well, what language is it", "timestamp": "00:34:35,360", "timestamp_s": 2075.0}, {"text": "in? That is like, is it English or Spanish? Is it English or Chinese?", "timestamp": "00:34:38,600", "timestamp_s": 2078.0}, {"text": "Another feature is the sentence referring", "timestamp": "00:34:41,856", "timestamp_s": 2081.0}, {"text": "to in the past tense or present tense. Right.", "timestamp": "00:34:46,032", "timestamp_s": 2086.0}, {"text": "This past or present tense feature, you know, helps you avoid", "timestamp": "00:34:49,133", "timestamp_s": 2089.0}, {"text": "grammatical mistakes, but it\u0027s fair enough to assume that the", "timestamp": "00:34:52,605", "timestamp_s": 2092.0}, {"text": "feature of at least knowing what language the question or the", "timestamp": "00:34:56,229", "timestamp_s": 2096.0}, {"text": "query is in is probably way more", "timestamp": "00:34:59,781", "timestamp_s": 2099.0}, {"text": "important in terms of, like, having you avoid errors", "timestamp": "00:35:03,109", "timestamp_s": 2103.0}, {"text": "than detecting if it\u0027s past tense or present tense.", "timestamp": "00:35:07,197", "timestamp_s": 2107.0}, {"text": "Right? So again, that\u0027s just like one abstract idea of", "timestamp": "00:35:10,933", "timestamp_s": 2110.0}, {"text": "the model. So again, if the model only had like two different features, like one,", "timestamp": "00:35:15,694", "timestamp_s": 2115.0}, {"text": "let\u0027s like just one, like, or like on the margin.", "timestamp": "00:35:19,134", "timestamp_s": 2119.0}, {"text": "If the model has to represent one more thing and it has to choose between", "timestamp": "00:35:22,326", "timestamp_s": 2122.0}, {"text": "the language detection and the past or", "timestamp": "00:35:25,606", "timestamp_s": 2125.0}, {"text": "present tense, it will most likely prioritize choosing to represent, using that one extra", "timestamp": "00:35:29,670", "timestamp_s": 2129.0}, {"text": "feature to represent language and language type, that is this,", "timestamp": "00:35:33,662", "timestamp_s": 2133.0}, {"text": "English or French or Chinese, as that probably has way more predictive power.", "timestamp": "00:35:36,750", "timestamp_s": 2136.0}, {"text": "Like, we\u0027ll have it have way less error than if it was instead", "timestamp": "00:35:40,894", "timestamp_s": 2140.0}, {"text": "of trying to predict the correct tense,", "timestamp": "00:35:44,670", "timestamp_s": 2144.0}, {"text": "but in the wrong language. Again, this bit", "timestamp": "00:35:47,518", "timestamp_s": 2147.0}, {"text": "of a toy example. Okay, so how do we solve this?", "timestamp": "00:35:51,278", "timestamp_s": 2151.0}, {"text": "Right. Again, giving this, we suspect this is what models are doing. Or again,", "timestamp": "00:35:54,854", "timestamp_s": 2154.0}, {"text": "we suspect this is why they\u0027re able to do it. This is why they\u0027re", "timestamp": "00:35:58,710", "timestamp_s": 2158.0}, {"text": "able to get away with it. Again, they\u0027re trying to exploit sparsity by compressing", "timestamp": "00:36:01,966", "timestamp_s": 2161.0}, {"text": "stuff. So the paper I shared basically tries to", "timestamp": "00:36:05,510", "timestamp_s": 2165.0}, {"text": "do this, um, by tackling a smaller", "timestamp": "00:36:08,878", "timestamp_s": 2168.0}, {"text": "model, right? So the tackle a one layer transformer, and they pick out one", "timestamp": "00:36:12,752", "timestamp_s": 2172.0}, {"text": "component of the architecture. Again, as I explained in", "timestamp": "00:36:16,696", "timestamp_s": 2176.0}, {"text": "this, in our typical large transformer, yeah. Every single component", "timestamp": "00:36:20,648", "timestamp_s": 2180.0}, {"text": "is doing some version of this, right? Since this information is", "timestamp": "00:36:25,120", "timestamp_s": 2185.0}, {"text": "flowing through our entire network, each discrete component is going to need to", "timestamp": "00:36:28,848", "timestamp_s": 2188.0}, {"text": "have to do some version of this, right? So they focus on the MLP", "timestamp": "00:36:32,792", "timestamp_s": 2192.0}, {"text": "layer, which is what comes the attention heads. And in", "timestamp": "00:36:36,656", "timestamp_s": 2196.0}, {"text": "the model, they use the dimensions of that,", "timestamp": "00:36:40,896", "timestamp_s": 2200.0}, {"text": "basically, like how many vectors or how many neurons it has.", "timestamp": "00:36:44,376", "timestamp_s": 2204.0}, {"text": "So how many dimensions of each vector has or how many neuron,", "timestamp": "00:36:47,776", "timestamp_s": 2207.0}, {"text": "how many neurons that layer has is 512. And what they do", "timestamp": "00:36:52,144", "timestamp_s": 2212.0}, {"text": "is, as seen here on the right, they use something called a", "timestamp": "00:36:55,640", "timestamp_s": 2215.0}, {"text": "sparse overcomplete order encoder. Obviously,", "timestamp": "00:36:58,920", "timestamp_s": 2218.0}, {"text": "I\u0027ll describe what that means, starting from the right. Okay, so what does that mean?", "timestamp": "00:37:02,040", "timestamp_s": 2222.0}, {"text": "And autoencoder and a BSN. Autoencoder is basically a neural", "timestamp": "00:37:05,280", "timestamp_s": 2225.0}, {"text": "network whose primary purpose is reconstruction. So basically", "timestamp": "00:37:09,160", "timestamp_s": 2229.0}, {"text": "you have some input, you have something in", "timestamp": "00:37:12,680", "timestamp_s": 2232.0}, {"text": "the middle, which is like, again, your network. And the job of", "timestamp": "00:37:16,136", "timestamp_s": 2236.0}, {"text": "that network is to try to replicate, to reproduce the output.", "timestamp": "00:37:19,608", "timestamp_s": 2239.0}, {"text": "That seems kind of silly. Like why just bother with this density transform?", "timestamp": "00:37:24,024", "timestamp_s": 2244.0}, {"text": "Because, well, in some cases, you might want to do something like,", "timestamp": "00:37:27,584", "timestamp_s": 2247.0}, {"text": "okay, compressed dimensions, right? So let\u0027s say you have this very like,", "timestamp": "00:37:31,328", "timestamp_s": 2251.0}, {"text": "large input you want to find interesting.", "timestamp": "00:37:34,756", "timestamp_s": 2254.0}, {"text": "You want to find the most important critical features by compressing it", "timestamp": "00:37:39,228", "timestamp_s": 2259.0}, {"text": "in the middle and seeing how. Well, okay, like,", "timestamp": "00:37:42,628", "timestamp_s": 2262.0}, {"text": "again, let\u0027s say something needs five dimensions to this", "timestamp": "00:37:45,988", "timestamp_s": 2265.0}, {"text": "input is five dimensions. What are the two most important", "timestamp": "00:37:49,684", "timestamp_s": 2269.0}, {"text": "dimensions of this or two most important, like representations of these five", "timestamp": "00:37:53,340", "timestamp_s": 2273.0}, {"text": "dimensions I can take that would have me still", "timestamp": "00:37:56,652", "timestamp_s": 2276.0}, {"text": "do well on reconstructing with", "timestamp": "00:38:00,588", "timestamp_s": 2280.0}, {"text": "this. That basically has this property", "timestamp": "00:38:05,412", "timestamp_s": 2285.0}, {"text": "of feature discovery by compression.", "timestamp": "00:38:08,844", "timestamp_s": 2288.0}, {"text": "That\u0027s what auto encoders do.", "timestamp": "00:38:12,380", "timestamp_s": 2292.0}, {"text": "Overcomplete. Again, starting from the right to left, describe overcomplete,", "timestamp": "00:38:14,564", "timestamp_s": 2294.0}, {"text": "basically does the slightly opposite version of that,", "timestamp": "00:38:18,460", "timestamp_s": 2298.0}, {"text": "which is, instead of compressing, you\u0027re basically trying to expand.", "timestamp": "00:38:21,572", "timestamp_s": 2301.0}, {"text": "You basically try to give the", "timestamp": "00:38:24,660", "timestamp_s": 2304.0}, {"text": "order encoder in the middle again between the input and your", "timestamp": "00:38:28,002", "timestamp_s": 2308.0}, {"text": "construction of the input is much larger than as you\u0027re saying. If this", "timestamp": "00:38:31,666", "timestamp_s": 2311.0}, {"text": "neural network representation had way more room", "timestamp": "00:38:35,274", "timestamp_s": 2315.0}, {"text": "to represent stuff, what would it look", "timestamp": "00:38:39,154", "timestamp_s": 2319.0}, {"text": "like? Right? And remember, the whole", "timestamp": "00:38:42,362", "timestamp_s": 2322.0}, {"text": "point of our store", "timestamp": "00:38:46,066", "timestamp_s": 2326.0}, {"text": "position is that we\u0027re assuming that the model we see is actually trying", "timestamp": "00:38:49,218", "timestamp_s": 2329.0}, {"text": "to simulate a much larger model. Again, remember, that\u0027s the", "timestamp": "00:38:52,862", "timestamp_s": 2332.0}, {"text": "whole point of superposition, right? So by using this", "timestamp": "00:38:55,958", "timestamp_s": 2335.0}, {"text": "overcompleted encoder, we\u0027re trying to say that, cool, whatever representation", "timestamp": "00:38:59,982", "timestamp_s": 2339.0}, {"text": "this MLP node has for some input,", "timestamp": "00:39:03,830", "timestamp_s": 2343.0}, {"text": "what if we gave it way more neurons to work with?", "timestamp": "00:39:08,214", "timestamp_s": 2348.0}, {"text": "What would you do with it? That\u0027s the overcomplete section.", "timestamp": "00:39:12,494", "timestamp_s": 2352.0}, {"text": "Then the sparse component of that description is", "timestamp": "00:39:16,302", "timestamp_s": 2356.0}, {"text": "saying, like, sure, what if we just go from like, you know,", "timestamp": "00:39:19,908", "timestamp_s": 2359.0}, {"text": "a five dimensional,", "timestamp": "00:39:23,548", "timestamp_s": 2363.0}, {"text": "inscrutable, compressed complex thing to", "timestamp": "00:39:26,844", "timestamp_s": 2366.0}, {"text": "a hundred dimension inscrutable complex thing, right?", "timestamp": "00:39:30,108", "timestamp_s": 2370.0}, {"text": "We\u0027re not much better than we started, right? And again, neural networks, just like,", "timestamp": "00:39:33,324", "timestamp_s": 2373.0}, {"text": "don\u0027t really have any incentives to just make things explainable to us. So the sparse", "timestamp": "00:39:36,428", "timestamp_s": 2376.0}, {"text": "component says, okay, in addition to giving you the", "timestamp": "00:39:40,060", "timestamp_s": 2380.0}, {"text": "network, more room to work with, to like, expand, to like, see what you learned,", "timestamp": "00:39:43,540", "timestamp_s": 2383.0}, {"text": "we want to force you to narrow your", "timestamp": "00:39:46,932", "timestamp_s": 2386.0}, {"text": "learnings, your features, to being", "timestamp": "00:39:50,758", "timestamp_s": 2390.0}, {"text": "active in one node at a time. Right. I think I", "timestamp": "00:39:55,366", "timestamp_s": 2395.0}, {"text": "explained before how just because I", "timestamp": "00:39:59,118", "timestamp_s": 2399.0}, {"text": "think it was, in this example, just going to jump quickly. So just because", "timestamp": "00:40:02,646", "timestamp_s": 2402.0}, {"text": "I say that, oh, like, linearity says you must have as", "timestamp": "00:40:06,654", "timestamp_s": 2406.0}, {"text": "many dimensions as you want features, it doesn\u0027t necessarily mean that it", "timestamp": "00:40:10,222", "timestamp_s": 2410.0}, {"text": "will always be one. Hot, right? You might have a case whereby there\u0027s several,", "timestamp": "00:40:13,326", "timestamp_s": 2413.0}, {"text": "you know, there are infinite, many orthogonal,", "timestamp": "00:40:16,724", "timestamp_s": 2416.0}, {"text": "four orthogonal vectors, like four vectors that form an orthogonal basis", "timestamp": "00:40:21,004", "timestamp_s": 2421.0}, {"text": "that aren\u0027t one. Hot. Right. It\u0027s kind of like smeared between all the different values.", "timestamp": "00:40:24,796", "timestamp_s": 2424.0}, {"text": "But again, from our, for our convenience to like say that,", "timestamp": "00:40:28,196", "timestamp_s": 2428.0}, {"text": "that neuron is like firing a lot when it sees redness,", "timestamp": "00:40:31,324", "timestamp_s": 2431.0}, {"text": "we want to impose an extra basic", "timestamp": "00:40:35,684", "timestamp_s": 2435.0}, {"text": "constraint on the auto encoder to say that,", "timestamp": "00:40:39,428", "timestamp_s": 2439.0}, {"text": "cool. Don\u0027t just try to find representations", "timestamp": "00:40:42,722", "timestamp_s": 2442.0}, {"text": "with more nodes to work with when you do this,", "timestamp": "00:40:46,578", "timestamp_s": 2446.0}, {"text": "narrow down your learnings or try to isolate your learnings", "timestamp": "00:40:50,306", "timestamp_s": 2450.0}, {"text": "for one feature to like, one node at a time, right?", "timestamp": "00:40:53,930", "timestamp_s": 2453.0}, {"text": "That\u0027s basically just for our interpretability benefit.", "timestamp": "00:40:56,906", "timestamp_s": 2456.0}, {"text": "And yet that is what a sparse overcomplete order code is.", "timestamp": "00:41:00,754", "timestamp_s": 2460.0}, {"text": "Or usually they usually just ignore the overcomplete", "timestamp": "00:41:03,930", "timestamp_s": 2463.0}, {"text": "part part and just call it a sparse or encoder and basically", "timestamp": "00:41:07,482", "timestamp_s": 2467.0}, {"text": "just says, cool. We want to give neural", "timestamp": "00:41:10,710", "timestamp_s": 2470.0}, {"text": "networks opportunity to want to extract what they\u0027ve learned by", "timestamp": "00:41:15,542", "timestamp_s": 2475.0}, {"text": "trying to reconstruct representations using more dimensions.", "timestamp": "00:41:19,766", "timestamp_s": 2479.0}, {"text": "And we want this new like extraction", "timestamp": "00:41:24,334", "timestamp_s": 2484.0}, {"text": "to be sparse in such a way that only one node", "timestamp": "00:41:27,726", "timestamp_s": 2487.0}, {"text": "is activated at a time for a given feature that is applied and", "timestamp": "00:41:31,518", "timestamp_s": 2491.0}, {"text": "effectively that looks like this. So they ran", "timestamp": "00:41:37,264", "timestamp_s": 2497.0}, {"text": "this, this training, this training", "timestamp": "00:41:40,712", "timestamp_s": 2500.0}, {"text": "process for the sparse auto encoder on their one layer network for the", "timestamp": "00:41:44,496", "timestamp_s": 2504.0}, {"text": "MLP layer. And again, if you see here, they describe on", "timestamp": "00:41:47,928", "timestamp_s": 2507.0}, {"text": "the left there you see this like the act 512,", "timestamp": "00:41:51,928", "timestamp_s": 2511.0}, {"text": "which is like the activation of MLP layer, typically should have 500,", "timestamp": "00:41:55,912", "timestamp_s": 2515.0}, {"text": "1212 dimensions. Again, that would just mean instead of 1", "timestamp": "00:41:59,312", "timestamp_s": 2519.0}, {"text": "second, instead of like four different blocks here,", "timestamp": "00:42:03,332", "timestamp_s": 2523.0}, {"text": "that\u0027ll be 512, right? That\u0027s like how big the vector is.", "timestamp": "00:42:06,836", "timestamp_s": 2526.0}, {"text": "So they went from 512 and expanded all the RAN", "timestamp": "00:42:10,404", "timestamp_s": 2530.0}, {"text": "different versions, but the largest ones went up to 131k.", "timestamp": "00:42:13,908", "timestamp_s": 2533.0}, {"text": "So basically that would mean if again, with the", "timestamp": "00:42:20,524", "timestamp_s": 2540.0}, {"text": "network of the quarter on the right, if the,", "timestamp": "00:42:23,948", "timestamp_s": 2543.0}, {"text": "on the input and output was 512 different like", "timestamp": "00:42:27,828", "timestamp_s": 2547.0}, {"text": "neurons. And in the middle you had this giant", "timestamp": "00:42:31,764", "timestamp_s": 2551.0}, {"text": "130K node network,", "timestamp": "00:42:36,004", "timestamp_s": 2556.0}, {"text": "or a node like layer, basically that was trying", "timestamp": "00:42:39,460", "timestamp_s": 2559.0}, {"text": "to reconstruct the input into the output.", "timestamp": "00:42:42,852", "timestamp_s": 2562.0}, {"text": "And they learned a bunch of stuff. They have a very", "timestamp": "00:42:47,124", "timestamp_s": 2567.0}, {"text": "nice interactive, um, application that", "timestamp": "00:42:50,548", "timestamp_s": 2570.0}, {"text": "I encourage you all to check out that basically shows the", "timestamp": "00:42:54,144", "timestamp_s": 2574.0}, {"text": "model learning really interesting things. So one of the,", "timestamp": "00:42:58,552", "timestamp_s": 2578.0}, {"text": "um, the neurons I discovered, again, neuron simply means like,", "timestamp": "00:43:00,904", "timestamp_s": 2580.0}, {"text": "because of this like, um, constraint of sparsity, the,", "timestamp": "00:43:04,472", "timestamp_s": 2584.0}, {"text": "the model learns like isolate some abstract", "timestamp": "00:43:07,744", "timestamp_s": 2587.0}, {"text": "feature. So literally one of these 130K nodes,", "timestamp": "00:43:11,824", "timestamp_s": 2591.0}, {"text": "basically, like once this feature is present an input, it just like fires", "timestamp": "00:43:15,624", "timestamp_s": 2595.0}, {"text": "and screams a lot. You see like this input is really here. And these features", "timestamp": "00:43:19,160", "timestamp_s": 2599.0}, {"text": "are like so like wide and varied. When,", "timestamp": "00:43:22,888", "timestamp_s": 2602.0}, {"text": "for example, detects, the,", "timestamp": "00:43:26,608", "timestamp_s": 2606.0}, {"text": "detects arabic characters in input,", "timestamp": "00:43:30,064", "timestamp_s": 2610.0}, {"text": "another of them, as you see here, detects if a sequence", "timestamp": "00:43:33,472", "timestamp_s": 2613.0}, {"text": "of text is probably like a DNA", "timestamp": "00:43:37,672", "timestamp_s": 2617.0}, {"text": "sequence which I think was pretty wild because, like, this could also be gibberish,", "timestamp": "00:43:41,280", "timestamp_s": 2621.0}, {"text": "but there are certain patterns and", "timestamp": "00:43:44,712", "timestamp_s": 2624.0}, {"text": "I guess the actual letters, for example, that is used for DNA encoding.", "timestamp": "00:43:48,280", "timestamp_s": 2628.0}, {"text": "That seems like such an arbitrary thing that a model will learn. But it did", "timestamp": "00:43:52,016", "timestamp_s": 2632.0}, {"text": "learn this. And you can check out other esoteric ones that you learned", "timestamp": "00:43:54,560", "timestamp_s": 2634.0}, {"text": "in this reconstruction. And again, feature was present in", "timestamp": "00:43:59,984", "timestamp_s": 2639.0}, {"text": "the 512 mlp.", "timestamp": "00:44:03,936", "timestamp_s": 2643.0}, {"text": "But because it was coked up and", "timestamp": "00:44:07,960", "timestamp_s": 2647.0}, {"text": "all cooped up together with the superposition,", "timestamp": "00:44:11,308", "timestamp_s": 2651.0}, {"text": "in the superposition phase, it was hard to basically discern. The whole point of", "timestamp": "00:44:16,164", "timestamp_s": 2656.0}, {"text": "the recorder is basically to extract these features out there.", "timestamp": "00:44:19,796", "timestamp_s": 2659.0}, {"text": "So now they become one isolated thing, which kind", "timestamp": "00:44:22,548", "timestamp_s": 2662.0}, {"text": "of brings us full circle to the definition of what a feature is. So again,", "timestamp": "00:44:27,068", "timestamp_s": 2667.0}, {"text": "I\u0027ve been throwing around the idea of feature as just a distinct", "timestamp": "00:44:30,684", "timestamp_s": 2670.0}, {"text": "thing. Model find to be interesting, right. As basically", "timestamp": "00:44:34,580", "timestamp_s": 2674.0}, {"text": "one perhaps more narrow", "timestamp": "00:44:39,592", "timestamp_s": 2679.0}, {"text": "definition of it. I guess I don\u0027t want to say formal, but just like,", "timestamp": "00:44:43,752", "timestamp_s": 2683.0}, {"text": "one more particular definition of it, based on this paradigm that", "timestamp": "00:44:46,952", "timestamp_s": 2686.0}, {"text": "we\u0027ve described, is like a feature is basically a property that", "timestamp": "00:44:50,296", "timestamp_s": 2690.0}, {"text": "a model would encode.", "timestamp": "00:44:54,064", "timestamp_s": 2694.0}, {"text": "Would dedicate an entire neuron to. Would encode using an.", "timestamp": "00:44:57,744", "timestamp_s": 2697.0}, {"text": "Using one neuron if it had enough neurons, right?", "timestamp": "00:45:00,776", "timestamp_s": 2700.0}, {"text": "So basically, if there\u0027s such a thing that if a model was sufficiently", "timestamp": "00:45:03,730", "timestamp_s": 2703.0}, {"text": "large, would it get one neuron to it? That thing is a feature,", "timestamp": "00:45:08,074", "timestamp_s": 2708.0}, {"text": "right? But if there\u0027s a thing that no matter how many neurons", "timestamp": "00:45:11,586", "timestamp_s": 2711.0}, {"text": "it had, this thing wouldn\u0027t have a neuron,", "timestamp": "00:45:15,114", "timestamp_s": 2715.0}, {"text": "it perhaps would be like a part of some other neuron, then that thing\u0027s not", "timestamp": "00:45:18,682", "timestamp_s": 2718.0}, {"text": "a feature, right. It seems kind of circular, but it", "timestamp": "00:45:21,786", "timestamp_s": 2721.0}, {"text": "turns about. Yeah. The precise definition of, like, futures can be kind of gnarly.", "timestamp": "00:45:25,906", "timestamp_s": 2725.0}, {"text": "Um, but, like, for all practical purposes, you know, think of, again, features in the", "timestamp": "00:45:28,938", "timestamp_s": 2728.0}, {"text": "colloquial sense of just like, you know, a thing that the model finds", "timestamp": "00:45:32,498", "timestamp_s": 2732.0}, {"text": "to be interesting, like squareness or bonus or whatever. Um,", "timestamp": "00:45:35,738", "timestamp_s": 2735.0}, {"text": "and but the interesting thing, I guess, is that, again, like,", "timestamp": "00:45:39,474", "timestamp_s": 2739.0}, {"text": "part of the things. Part of the ways, like, a more powerful model is more", "timestamp": "00:45:42,546", "timestamp_s": 2742.0}, {"text": "powerful is because it can indeed encode for more", "timestamp": "00:45:45,890", "timestamp_s": 2745.0}, {"text": "stuff than a small one can. And again, as a proposition suggest", "timestamp": "00:45:49,282", "timestamp_s": 2749.0}, {"text": "the smaller ones actually encode a lot more than they might than", "timestamp": "00:45:53,474", "timestamp_s": 2753.0}, {"text": "their size alone might suggest, right? Because, again, the whole point of this is if", "timestamp": "00:45:57,090", "timestamp_s": 2757.0}, {"text": "indeed there was no superposition, or like, if indeed there was nothing", "timestamp": "00:46:02,058", "timestamp_s": 2762.0}, {"text": "weird happening, then this MLP layer would actually only have 512,", "timestamp": "00:46:05,474", "timestamp_s": 2765.0}, {"text": "but they were able to extract way over 100,000", "timestamp": "00:46:09,322", "timestamp_s": 2769.0}, {"text": "reasonable features. So something for sure where", "timestamp": "00:46:13,794", "timestamp_s": 2773.0}, {"text": "it is happening. And, like. And these features, like, were consistent with", "timestamp": "00:46:17,370", "timestamp_s": 2777.0}, {"text": "experimental validation for.", "timestamp": "00:46:21,130", "timestamp_s": 2781.0}, {"text": "Again like they had different evaluation methods that you can check out in the paper", "timestamp": "00:46:24,254", "timestamp_s": 2784.0}, {"text": "to show like how much confidence they have for it. But basically the features like", "timestamp": "00:46:27,822", "timestamp_s": 2787.0}, {"text": "very confidence or incoherence or at least in like explainability", "timestamp": "00:46:30,542", "timestamp_s": 2790.0}, {"text": "to like it\u0027s a real human being human. But I feel like the", "timestamp": "00:46:34,334", "timestamp_s": 2794.0}, {"text": "number of explainable features, high quality feature definitely exceeds 512.", "timestamp": "00:46:37,638", "timestamp_s": 2797.0}, {"text": "So indeed this compression is happening for sure and", "timestamp": "00:46:41,158", "timestamp_s": 2801.0}, {"text": "this is like the proof for it. And yeah the future of this", "timestamp": "00:46:44,534", "timestamp_s": 2804.0}, {"text": "work could basically look like scaling up this auto encoders to work", "timestamp": "00:46:47,958", "timestamp_s": 2807.0}, {"text": "on much larger models and uncover more useful features going forward.", "timestamp": "00:46:51,030", "timestamp_s": 2811.0}, {"text": "Awesome and that is the talk. Thanks for", "timestamp": "00:46:55,334", "timestamp_s": 2815.0}, {"text": "joining here and I encourage you to read more of the", "timestamp": "00:46:58,918", "timestamp_s": 2818.0}, {"text": "papers out there. I think the anthropic blog", "timestamp": "00:47:02,598", "timestamp_s": 2822.0}, {"text": "posts and paper, informal papers and formal papers are a great place to", "timestamp": "00:47:07,374", "timestamp_s": 2827.0}, {"text": "start as that basically represents", "timestamp": "00:47:10,758", "timestamp_s": 2830.0}, {"text": "where the frontiers right now. Awesome,", "timestamp": "00:47:14,158", "timestamp_s": 2834.0}, {"text": "thank you for the time and see you later.", "timestamp": "00:47:17,294", "timestamp_s": 2837.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '0xpgLo4-cX4',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Superposition in LLM Feature Representations
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Dive into the quantum realm of LLMs! Join me as we unravel the superposition in LLM feature representations, exploring the intersection of finance, technology, and AI interpretability. Unearth insights from my journey at Bloomberg, Palantir, and my pursuit of mechanistic interpretability.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Bolu: Today I'm going to talk about superposition in neural network representations. How do neural networks learn which representations to use for inputs? And how are these inputs passed around in the computation?

              </li>
              
              <li>
                Just because things aren't auto collection numbers doesn't necessarily mean that they are linear, right? Linearity is a very particular statement about how different entities interact. And there was an interesting paper that showed up to say that actually, yes, abstract things like functions can be encoded.

              </li>
              
              <li>
                The recommendation is distinct to algorithmic interpretation, interpretability. Think of the linear composition as just a compression scheme for how all this information is packed together. As these tools become more mature to understand what's happening, we get to do different things, like everything from mind reading to mind control.

              </li>
              
              <li>
                Neural networks are able to do this because they exploit feature sparsity and the relative feature importance. Exploring this puzzle suggests a way forward on tackling what exactly is going on.

              </li>
              
              <li>
                The paper I shared basically tries to do this by tackling a smaller model. They use something called a sparse encoder and a BSN Autoencoder. Since this information is flowing through our entire network, each discrete component is going to need to do some version of this.

              </li>
              
              <li>
                So basically that would mean if again, with the network of the quarter on the right, if the, on the input and output was 512 different like neurons. They were able to extract way over 100,000 reasonable features. And the future of this work could basically look like scaling up larger models and uncover more useful features.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/assemblyai/0xpgLo4-cX4.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:20,720'); seek(20.0)">
              Hi there. My name is Bolu, and today I'm going to talk about superposition
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:24,350'); seek(24.0)">
              in neural network representations. So I guess it motivates that
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:28,280'); seek(28.0)">
              a bit. I'll share some context about where this hypothesis comes
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:31,960'); seek(31.0)">
              from or the field of neural network research.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:35,624'); seek(35.0)">
              This field is called mechanistic interpretability, and basically it
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:40,696'); seek(40.0)">
              follows from the following reasoning. Okay, so we all understand that neural
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:44,024'); seek(44.0)">
              networks solve an increasing number of important tasks really well,
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:47,864'); seek(47.0)">
              and it would be at least interesting and probably important to understand
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:51,536'); seek(51.0)">
              how they do that. So mechanrap is basically a subfield that tackled
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:55,692'); seek(55.0)">
              this problem by seeking granular mechanistic
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:59,052'); seek(59.0)">
              explanations for different observed behaviors in neural networks.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:03,460'); seek(63.0)">
              It's basically pushing back on the idea that neural networks are just these black
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:06,884'); seek(66.0)">
              boxes that are completely inscrutable and just do magic
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:10,596'); seek(70.0)">
              with linear algebra. So it pairs into a given network
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:14,500'); seek(74.0)">
              at a granular level to investigate some very isolated behavior.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:19,354'); seek(79.0)">
              At the same time, it also has very broad hypotheses and
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:23,210'); seek(83.0)">
              theories about how neural networks do things. And one of these
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:26,626'); seek(86.0)">
              is about representation learning.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:30,074'); seek(90.0)">
              That is, how do neural networks learn which representations to use for inputs,
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:34,610'); seek(94.0)">
              and how are these inputs, how these representations passed around in
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:38,378'); seek(98.0)">
              the computation? That's what this
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,850'); seek(101.0)">
              is basically understanding what a model sees and how it does.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:45,146'); seek(105.0)">
              So what informations have model found important to look for?
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:48,572'); seek(108.0)">
              And how is information propagated and I guess represented
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:52,012'); seek(112.0)">
              and propagated internally in the network? I guess to
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:55,916'); seek(115.0)">
              paint a picture of what we mean by representations and propagation.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:59,364'); seek(119.0)">
              So basically, at the bottom left, on the bottom left here, we have,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:03,484'); seek(123.0)">
              let's just say this is like a simple tokenized version of
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:07,164'); seek(127.0)">
              input you're going to pass on to based on a
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:10,428'); seek(130.0)">
              transformer, right? So you have like on colon, off wet colon,
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:13,644'); seek(133.0)">
              dry old colon. And I guess, as any of us would,
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:17,156'); seek(137.0)">
              would attest to from using something like chat JPT,
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:20,204'); seek(140.0)">
              these neural networks are definitely able to predict that old. I figure
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:24,204'); seek(144.0)">
              that the next thing is going to be old colon, new, right,
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:27,916'); seek(147.0)">
              since you can figure out what you were in opposite. So the idea is,
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:31,484'); seek(151.0)">
              between this entry of our text and the prediction
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:35,020'); seek(155.0)">
              on the other side, entire network has to have
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:38,972'); seek(158.0)">
              encoded certain information and done computations
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:42,428'); seek(162.0)">
              in the process to get this output of, oh, the next thing to
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:46,050'); seek(166.0)">
              come after this column is new. So basically
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:49,522'); seek(169.0)">
              what we're trying to ask is, okay, just what do we know and what can
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:52,650'); seek(172.0)">
              we investigate about how this information
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:56,210'); seek(176.0)">
              is encoded? Right? So, because in the beginning, all it knows is that I'm a
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:58,978'); seek(178.0)">
              column again. After going through just the embedded network of mapping the column
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:02,554'); seek(182.0)">
              character to a collection
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:07,370'); seek(187.0)">
              of numbers are just called vectors of ordered vectors, as you can see there in
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:10,226'); seek(190.0)">
              the column. So the question is summer between entry on
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:13,930'); seek(193.0)">
              I'm a column to exiting on, my next is new,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:17,666'); seek(197.0)">
              which is again the result of
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:21,282'); seek(201.0)">
              this vector going through an unembedding layer and the softmax, and again the
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:25,290'); seek(205.0)">
              highest probability weight being attributed to as.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:28,602'); seek(208.0)">
              Again, just for simplicity, let's assume the word new is
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:32,330'); seek(212.0)">
              its own token, because as we know, prediction is done on a token basis.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:37,294'); seek(217.0)">
              So, right, so somewhere between signing with M and Colin and my next is new
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:40,894'); seek(220.0)">
              is a bunch of stuff. So what do we know about
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:45,126'); seek(225.0)">
              what these representations look like internally? All right,
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:49,078'); seek(229.0)">
              so here are a couple qualities of these representations
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:52,854'); seek(232.0)">
              that the starting school of mechanistic
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:56,118'); seek(236.0)">
              interpretability posits. Basically, it says
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:59,718'); seek(239.0)">
              that there are discrete features that a model
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:03,736'); seek(243.0)">
              has learned to look for in an input, and these discrete features
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:07,280'); seek(247.0)">
              basically compose into giving any given representation, right?
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:10,784'); seek(250.0)">
              So if we looked at any layer or at any component in the architecture,
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:16,224'); seek(256.0)">
              all the information the model has at that stage is basically going to be
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:20,120'); seek(260.0)">
              some composition of discrete things.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:23,584'); seek(263.0)">
              And the second is linearity. And so this
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:27,288'); seek(267.0)">
              basically takes the composite, the decomposability statement, a bit further to say
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:31,280'); seek(271.0)">
              that not only are these discrete components composed
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:35,158'); seek(275.0)">
              together, they're composed linearly. And again, we'll discuss a bit
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:38,774'); seek(278.0)">
              later what exactly that means. And the third basically just says
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:43,374'); seek(283.0)">
              we can think of these discrete qualities as something called features. And again,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:47,166'); seek(287.0)">
              the precise time code definition for what features are comes
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:50,422'); seek(290.0)">
              later. So I guess maybe to summarize, maybe this, like one
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:53,974'); seek(293.0)">
              single line or tagline, it probably, like summarizes the school
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:57,262'); seek(297.0)">
              of thought that says language model. Again, you can replace your neural network
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:00,766'); seek(300.0)">
              representation that basically have similar architectures.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:04,694'); seek(304.0)">
              Language model representations are linearly decomposable
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:09,630'); seek(309.0)">
              in two features, right? So we're going to pick apart each one
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:13,086'); seek(313.0)">
              of those, of those items in the course of this talk.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:18,694'); seek(318.0)">
              The first, again, is this is kind of a weak statement.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:22,550'); seek(322.0)">
              It's not that strong. And I'll explain why. In isolation,
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:25,926'); seek(325.0)">
              decomposability just basically means that, well, we assume
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:29,814'); seek(329.0)">
              that neural networks learn different things. That is,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:33,982'); seek(333.0)">
              giving a neural network doesn't just basically
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:37,790'); seek(337.0)">
              memorize every simple potential input.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:41,318'); seek(341.0)">
              It learns to abstract certain features
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:45,734'); seek(345.0)">
              like blueness or redness, or perhaps even more general,
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:49,038'); seek(349.0)">
              to color. Right? If it has a general abstraction for
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:53,134'); seek(353.0)">
              color representations. Again, in this simple case,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:56,608'); seek(356.0)">
              we have a neural network that may be trained to identify colors
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:00,944'); seek(360.0)">
              and shapes like. So let's just say maybe this is like some classification
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:05,664'); seek(365.0)">
              neural network, right? And the idea is that, okay, somewhere in, you know,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:09,584'); seek(369.0)">
              all linear network weights are
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:14,312'); seek(374.0)">
              basically transformations that are able to extract certain
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:19,736'); seek(379.0)">
              discrete qualities such as the center shape or
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:23,540'); seek(383.0)">
              the background color. Right here simplify this. We just look for blueness or
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:27,420'); seek(387.0)">
              redness on the left. But the interesting thing is, well, this is kind
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:30,708'); seek(390.0)">
              of just saying sometimes neural networks don't overfit, which is why
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:33,996'); seek(393.0)">
              I say this is kind of a weak statement because like, sure, like it's pretty
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:36,364'); seek(396.0)">
              obvious that, yes, I mean, or at least like anyone
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:39,572'); seek(399.0)">
              that has training neural network can demonstrate in
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:43,684'); seek(403.0)">
              with like a test set to show that yes, indeed,
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:46,724'); seek(406.0)">
              these neural networks can generalize and not everything is overfitting or memorizing.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:50,324'); seek(410.0)">
              So on the right there, if we have something like a purple triangle
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:54,972'); seek(414.0)">
              that supposedly this neural network has not seen in training before,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:58,500'); seek(418.0)">
              it could depend on its previous, previously learned features to
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:02,380'); seek(422.0)">
              say that, well, even though it doesn't quite have the conception of purple as a
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:05,828'); seek(425.0)">
              distinct thing, it could compose of the color purple as being
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:11,364'); seek(431.0)">
              perhaps reading the RGB values, being equally composed of
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:16,284'); seek(436.0)">
              red and blue values.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:20,174'); seek(440.0)">
              So. Right, so at this day, like all, that's all decomposability is saying,
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:24,270'); seek(444.0)">
              there's certain things in this diagram that are quite strong assumptions.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:27,814'); seek(447.0)">
              Again, this whole idea that, oh, there's one thing called a blue neuron,
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:31,102'); seek(451.0)">
              as we'll see, that's a pretty strong thing to say. And it's not obvious at
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:34,270'); seek(454.0)">
              all that this is how things play out in reality. But again, at this stage,
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:38,070'); seek(458.0)">
              decomposability just says irreproentation is composed
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:41,550'); seek(461.0)">
              of a bunch of little stuff. Because in your own work,
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:44,654'); seek(464.0)">
              again, demonstrably does not just generalize all the time. Right?
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:48,126'); seek(468.0)">
              Again, for sufficient size for spatially small problem set.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:52,894'); seek(472.0)">
              The second is linearity. So this again takes the decomposability
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:57,654'); seek(477.0)">
              property a bit further. You say, okay, cool. Not only are these different
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:00,934'); seek(480.0)">
              properties, well, distinct or different, they combine
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:06,454'); seek(486.0)">
              linear sums quite simply,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:09,494'); seek(489.0)">
              which basically just says, if you can imagine a vector
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:13,998'); seek(493.0)">
              representing a certain vector direction representing
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:17,974'); seek(497.0)">
              some feature. And again,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:22,214'); seek(502.0)">
              this is an as contrived. Remember looking at this
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:25,566'); seek(505.0)">
              diagram, the inputs are
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:28,750'); seek(508.0)">
              already ordered collectible numbers. So again, everything that's for a colon is already inherently
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:33,494'); seek(513.0)">
              having this vector format. I should mention though, just because a thing
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:37,702'); seek(517.0)">
              is an order to collection of numbers, it doesn't mean it has to be linear,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:40,886'); seek(520.0)">
              right? So it's a bit confusing, obviously, because it has this like
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:45,954'); seek(525.0)">
              vector formatting of, again, an order to collection of numbers
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:49,546'); seek(529.0)">
              relating to one entity, then surely it was obviously mini direction.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:53,274'); seek(533.0)">
              That is not obvious. And again, I'll show you examples of what that
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:57,874'); seek(537.0)">
              looks like when it's not the case. Okay, so again, the larynx
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:01,458'); seek(541.0)">
              says these decomposable sub vectors
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:05,538'); seek(545.0)">
              basically, literally just add together to give you
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:09,250'); seek(549.0)">
              the representation for something, right? So here we have how the,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:13,644'); seek(553.0)">
              some other neural network that cares about size and
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:17,324'); seek(557.0)">
              redness in the abstract has
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:21,556'); seek(561.0)">
              two different directions. Again, given it only has two
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:25,100'); seek(565.0)">
              features or qualities it cares about, it can dedicate two different directions to
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:29,108'); seek(569.0)">
              it, right? And then these directions can simply combine to represent
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:33,164'); seek(573.0)">
              any one given input. And again, like, how do
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:36,908'); seek(576.0)">
              we have any evidence for this in practice? Is that. Yes, I guess
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:40,874'); seek(580.0)">
              this is a bit of a popular example
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:44,034'); seek(584.0)">
              by now, but there was a paper that came out a couple years ago that
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:47,810'); seek(587.0)">
              basically showed regularities in the differences
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:51,082'); seek(591.0)">
              between pairs of vectors. So the difference between the
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:54,842'); seek(594.0)">
              man and woman, again, this is like the man and woman, let's say
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:58,378'); seek(598.0)">
              word representation in certain language
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:02,954'); seek(602.0)">
              model architectures was consistent. So if you do something
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:06,658'); seek(606.0)">
              as silly as, let's say, subtracted the vector, again, just the ordered collection
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:10,370'); seek(610.0)">
              of numbers for, of uncle from the vector for
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:14,234'); seek(614.0)">
              aunt, and you simply just impose that on, let's say,
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:17,810'); seek(617.0)">
              some other pair on something like
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:22,794'); seek(622.0)">
              man, you would end up with precisely the
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:27,234'); seek(627.0)">
              vector called woman, right? And you have a bit of this like vector algebra
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:30,554'); seek(630.0)">
              here on the right with the card. Again, let's assume this is like another relationship
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:33,882'); seek(633.0)">
              of plurals, again of
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:37,628'); seek(637.0)">
              like cars, the vector recognition for cars. If you subtract the
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:41,820'); seek(641.0)">
              singular recognition for car and add to apple,
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:45,180'); seek(645.0)">
              you get something like apples, right? So this kind of behavior of literal,
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:48,380'); seek(648.0)">
              like ordered subtraction of
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:52,140'); seek(652.0)">
              values is what you would see in a linear
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:56,116'); seek(656.0)">
              system, right? A system where the masculine,
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:01,084'); seek(661.0)">
              you know, this abstract feature of this is referring
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:04,488'); seek(664.0)">
              to a masculine entity is encoded with all
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:08,168'); seek(668.0)">
              the other stuff that has to do with royalty in king, or has to do
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:12,048'); seek(672.0)">
              with relatives or relatives of siblings,
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:16,080'); seek(676.0)">
              of your parents, an uncle and aunt, or just again, in the literal
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:19,792'); seek(679.0)">
              world, man and woman. Effectively,
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:23,568'); seek(683.0)">
              if these two, if these multiple things are composed in a linear fashion,
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:27,352'); seek(687.0)">
              then you can get it. We'll be doing things like this, vector subtraction
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:31,620'); seek(691.0)">
              and arithmetic as we're seeing here, right? But again,
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:34,596'); seek(694.0)">
              this doesn't mean everything completely is indeed, right. So this is part,
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:38,276'); seek(698.0)">
              this is just for the embedding layer. And again, to remind us what the embedding
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:41,660'); seek(701.0)">
              layer is, it is the very bottom of this, right? It's,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:45,804'); seek(705.0)">
              there's still a lot of uncertainty as to sure, if maybe for
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:49,372'); seek(709.0)">
              simple things like embedding a word, you get this vector
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:53,156'); seek(713.0)">
              algebra, does that mean like for everything? And all the layers in the network,
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:56,900'); seek(716.0)">
              all the information that it has to encode is in fact
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:01,420'); seek(721.0)">
              composed in this linear fashion. Right. So that is why there's still a mystery,
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:04,452'); seek(724.0)">
              even though we have seen some evidence. I guess, as I mentioned,
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:08,180'); seek(728.0)">
              it would be worth noting that again, just because a thing is an ordered
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:12,404'); seek(732.0)">
              collection of numbers, again, which is how neural networks tend to
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:15,788'); seek(735.0)">
              be like represented or simply just how they are, this kind of,
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:19,068'); seek(739.0)">
              this meme around how neural networks are just linear algebra
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:23,210'); seek(743.0)">
              scaled up. Well, just because things aren't auto collection numbers doesn't
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:27,002'); seek(747.0)">
              necessarily mean that they are linear, right? Linearity is a very particular
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:30,482'); seek(750.0)">
              statement about how different entities interact. Right?
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:33,682'); seek(753.0)">
              So here's an example of, again on, we can imagine a different
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:37,250'); seek(757.0)">
              regime where we had a neural network that again
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:42,218'); seek(762.0)">
              was able to extract a discrete component for redness and another
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:45,506'); seek(765.0)">
              for blueness, but then join
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:49,054'); seek(769.0)">
              them together. It did something like, well, maybe just exploited the
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:53,814'); seek(773.0)">
              simple precision
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:57,302'); seek(777.0)">
              decimal places. Again, how it does this,
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:00,630'); seek(780.0)">
              again, special edition, is by simply just taking the first
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:03,982'); seek(783.0)">
              thing on the left and then making it the value to one decimal
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:07,630'); seek(787.0)">
              place and taking the other thing. And here you have an algorithm to
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:11,686'); seek(791.0)">
              do this. Again, this is an example of a non web winner expression.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:16,522'); seek(796.0)">
              Um, and again, like the component of this that makes it nonlinear is,
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:19,562'); seek(799.0)">
              you see, it relies on the floor operation. Again, this is like from,
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:23,690'); seek(803.0)">
              like from a python, except that like math or floor, it basically just
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:27,370'); seek(807.0)">
              like tries to do, do the rounding. That's basically how they exploit this like,
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:30,762'); seek(810.0)">
              um, precision and placement to basically like squish
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:35,154'); seek(815.0)">
              these two different values together. Right? So again, so this is just like one,
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:37,978'); seek(817.0)">
              I guess like dummy example of showing that, well, yes,
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:41,498'); seek(821.0)">
              things ordered collection of numbers can act in
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:44,938'); seek(824.0)">
              ways that are not quite vector like or don't quite simply just
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:48,810'); seek(828.0)">
              do addition. Right? You do have other compression schemes,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:53,714'); seek(833.0)">
              right? And so what the linear representation is saying is that actually
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:58,914'); seek(838.0)">
              on the journey from, again, the input of I am a column,
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:02,498'); seek(842.0)">
              which is what like the embedding does to the output.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:06,314'); seek(846.0)">
              All the information it has at that point. Again, all the information at this
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:09,962'); seek(849.0)">
              single um, column and the input has maintained as it
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:13,666'); seek(853.0)">
              went through all the layers were simply just
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:16,858'); seek(856.0)">
              added to each other. Right? There's one vector that represents, oh, there's something,
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:20,866'); seek(860.0)">
              there's a bit of like a word and opposite game going on. And there was
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:24,426'); seek(864.0)">
              an interesting paper that, that showed up to say that actually, yes,
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:27,746'); seek(867.0)">
              not just nouns or discrete informations about inputs
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:31,602'); seek(871.0)">
              can be encoded, but also abstract things like functions. Right? Again, this whole idea
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:35,522'); seek(875.0)">
              of, oh, this is a word and opposite game that's been played here between
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:38,954'); seek(878.0)">
              wet and dry, old and new, etc. That itself is
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:42,298'); seek(882.0)">
              one vector and yet another vector. Again, this,
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:45,570'); seek(885.0)">
              this is something that attention can give us, right? Being able
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:48,962'); seek(888.0)">
              to basically like, look at previous inputs. So again,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:52,698'); seek(892.0)">
              the colon token is able to like, look behind,
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:55,898'); seek(895.0)">
              immediately behind it. See that all the thing that came before me is old and
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:59,098'); seek(899.0)">
              also is able to look maybe further back to other
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:02,354'); seek(902.0)">
              things to like glean the pattern of words and opposites, right? All these different
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:06,538'); seek(906.0)">
              bits of information are literally just different vectors or different
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:10,176'); seek(910.0)">
              directions that compose as
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:13,488'); seek(913.0)">
              simple additions to end with the conclusion
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:16,832'); seek(916.0)">
              of. Okay, surely my next thing is new.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:20,184'); seek(920.0)">
              Again, the representations aren't really concerned with how the
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:24,336'); seek(924.0)">
              network is doing combination that is like, like, what are the mechanics inside of
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:27,896'); seek(927.0)">
              it that know how to do that? Okay, giving this vector for work opposite this
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:30,920'); seek(930.0)">
              vector for this. How does it do that? Like, again, there's another body of work
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:33,952'); seek(933.0)">
              that explores basically this, like, algorithmic interpretability.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:37,128'); seek(937.0)">
              This is just saying, um, basically the variables that is being used for these
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:40,800'); seek(940.0)">
              computations, what do you look like and how are the variables that composed?
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:46,224'); seek(946.0)">
              Again, by how? I mean, like how in a sense of, like,
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:49,760'); seek(949.0)">
              are they saying, like, do you have weird stuff like this going on where
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:53,488'); seek(953.0)">
              it's like, in the c, in the space of all potential transformations,
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:57,888'); seek(957.0)">
              of taking redness and blueness together to get purpleness?
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:00,832'); seek(960.0)">
              Um, is it like some unknown arbitrary thing which would be messy
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:04,098'); seek(964.0)">
              and hard, or is it just literally symbol vector addition?
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:07,530'); seek(967.0)">
              Um, so that's what recommendation is as being like,
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:10,882'); seek(970.0)">
              distinct to like, algorithmic, um, interpretation, interpretability.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:15,474'); seek(975.0)">
              Um, right. So again, as we see here, um, again,
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:18,586'); seek(978.0)">
              just think of the linear composition as just a compression scheme for
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:22,346'); seek(982.0)">
              how all this information is packed together. Okay? So linearity
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:25,802'); seek(985.0)">
              is great because it basically helps us narrow down, again, as I said, like one
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:29,552'); seek(989.0)">
              compression algorithm in a very large function space. So there are many things, again,
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:33,072'); seek(993.0)">
              these are the giant networks to be doing in their, like, typical inscrutable fashion.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:37,776'); seek(997.0)">
              So linearity is pretty helpful in that actually kind of narrows it
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:41,240'); seek(1001.0)">
              down to one like,
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:44,544'); seek(1004.0)">
              well known, unstudied,
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:47,624'); seek(1007.0)">
              basically like compression scheme, right? Which is the entire field of linear algebra.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:52,184'); seek(1012.0)">
              Right? If it happens to be linear. And also the other things that
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:56,204'); seek(1016.0)">
              this gives us as well, which is, it aids in
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:00,428'); seek(1020.0)">
              diagnostics and helps improve our
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:04,812'); seek(1024.0)">
              understanding of the models in ways that, again, if there were some,
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:07,996'); seek(1027.0)">
              if, for example, in every single representation or every single layer,
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:11,836'); seek(1031.0)">
              use a different type of arbitrary algorithm, will be hard.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:15,260'); seek(1035.0)">
              So, yeah, it basically would be very convenient if
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:20,256'); seek(1040.0)">
              this was the case. Right? And again, we have seen some evidence for it.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:22,960'); seek(1042.0)">
              Right? So this is just an important point to make where to
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:27,512'); seek(1047.0)">
              state that this is a combination of having some evidence, but also there's a
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:31,136'); seek(1051.0)">
              bit of a motivated inquiry into this. Right? Again,
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:34,944'); seek(1054.0)">
              if this wasn't something we cared about, there are many things about neural networks that
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:37,728'); seek(1057.0)">
              seem to be interesting, but people just haven't really dug
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:41,376'); seek(1061.0)">
              into. But the fact that they seem to have inner behavior has
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:45,596'); seek(1065.0)">
              drawn a very large community of researchers to study just
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:49,364'); seek(1069.0)">
              why. Because, again, it makes the problem a lot more tractable
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:52,916'); seek(1072.0)">
              than if it wasn't the case. Right? And yes,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:56,012'); seek(1076.0)">
              I guess I put here effectively mind control being like, they're a bit of like.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:59,508'); seek(1079.0)">
              As these tools become more mature to understand what's happening, we get
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:02,820'); seek(1082.0)">
              to do different things, like everything from mind reading to mind control.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:06,628'); seek(1086.0)">
              That is like, again, if you get to run your strand
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:10,204'); seek(1090.0)">
              brain on a computer and you have access to all the numbers and you understand
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:13,156'); seek(1093.0)">
              the general, both the algorithms for how the information is
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:16,700'); seek(1096.0)">
              represented and how the information is transformed, then you can eventually, like,
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:19,884'); seek(1099.0)">
              intervene and or at least just like, you know,
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:23,612'); seek(1103.0)">
              have a log stream on what's going on.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:27,084'); seek(1107.0)">
              Cool. So that's the motivation for why linear composability is great,
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:30,716'); seek(1110.0)">
              right? Because again, it's a algorithm for
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:34,772'); seek(1114.0)">
              these transformers to use for understanding.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:38,004'); seek(1118.0)">
              Okay, here is a bit of the downside,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:40,888'); seek(1120.0)">
              is that linearity is kind of demanding in
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:44,000'); seek(1124.0)">
              that it basically says that to have
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:48,056'); seek(1128.0)">
              a lossless compression scheme that composes linearly,
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:52,432'); seek(1132.0)">
              it requires as many dimensions, that is, as many of those different
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:55,856'); seek(1135.0)">
              boxes, as many, like, of the. As many
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:59,848'); seek(1139.0)">
              distinct ordered numbers in the collected set as
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:04,784'); seek(1144.0)">
              you have qualities you want to encode. Right. As you can see here,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:09,834'); seek(1149.0)">
              again, we have something for redness, for blueness, for squareness, for triangles. And then,
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:13,090'); seek(1153.0)">
              like, as you see, basically, you have this like, one hot vector kind of
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:17,234'); seek(1157.0)">
              situation going where the thing that makes one of these
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:20,906'); seek(1160.0)">
              directions and code for the property
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:24,050'); seek(1164.0)">
              of redness is that it is only the first cell
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:27,738'); seek(1167.0)">
              that activates for it. Now, I do want to point out that there's
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:31,018'); seek(1171.0)">
              a slight difference between just the dimensions and, uh,
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:34,480'); seek(1174.0)">
              like, the number of dimensions is the requirement.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:37,440'); seek(1177.0)">
              It doesn't necessarily mean, though, that you would always have this perfect idea of,
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:41,960'); seek(1181.0)">
              uh, one cell coordinating to
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:45,200'); seek(1185.0)">
              one thing, right? You. You could basically have, like, there are,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:49,024'); seek(1189.0)">
              you know, infinite many, um, orthogonal bases
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:53,312'); seek(1193.0)">
              that are able to achieve this. Basically, all you just want is that for,
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:56,600'); seek(1196.0)">
              you want to have as many orthogonal, um, directions as
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:00,268'); seek(1200.0)">
              you have features, right? Again, just for the sake of,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:03,772'); seek(1203.0)">
              like, easier understanding, we just focus on the
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:07,084'); seek(1207.0)">
              one in this very large, this infinite set of orthogonal
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:10,652'); seek(1210.0)">
              bases that happens to be one hot encoded,
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:14,620'); seek(1214.0)">
              right? So just going for. Just imagine
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:18,132'); seek(1218.0)">
              that every time I talk about a neuron
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:21,660'); seek(1221.0)">
              or a dimension. I just literally mean one neuron, but that's not necessarily the case.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:26,404'); seek(1226.0)">
              Cool. So why is this a problem? Okay,
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:30,364'); seek(1230.0)">
              so let's just like, again, to remind ourselves of, like, where we're at right now.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:33,428'); seek(1233.0)">
              Again, this certain hypothesis for how representation is done says that
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:37,588'); seek(1237.0)">
              language model, large language model representations are linearly decomposable,
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:41,484'); seek(1241.0)">
              composable into features. Okay, this brings
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:45,500'); seek(1245.0)">
              us to the linear organizational puzzle. Why is this a puzzle?
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:48,924'); seek(1248.0)">
              So basically, in a couple steps, first, we have
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:52,628'); seek(1252.0)">
              some evidence that indeed we LLMs do represent stuff linearly.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:55,828'); seek(1255.0)">
              Right? Again, so, like, meaning this,
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:58,604'); seek(1258.0)">
              this claim has, you know, some basis in reality,
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:02,212'); seek(1262.0)">
              right? And again, there are several other arguments in research to suggest
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:05,836'); seek(1265.0)">
              that, like, this behavior is more likely, or like,
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:09,940'); seek(1269.0)">
              or has either from, or can be observed
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:13,468'); seek(1273.0)">
              either from, like, looking at the number of flops that are dedicated to the transformations
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:16,500'); seek(1276.0)">
              versus not, etc. Cool. So linear
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:20,632'); seek(1280.0)">
              stuff is happening. Linear combinations
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:24,336'); seek(1284.0)">
              require as many dimensions or neurons,
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:27,344'); seek(1287.0)">
              again, which is, again, a subset of the case of
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:30,496'); seek(1290.0)">
              orthogonal basis as features. If you want to encode for redness,
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:34,496'); seek(1294.0)">
              blueness, triangle ness and squareness,
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:38,128'); seek(1298.0)">
              you need literally four different things. Again, if you want to encode these things distinctly
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:42,024'); seek(1302.0)">
              as being different things, you need four different
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:45,144'); seek(1305.0)">
              directions. However, and this is
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:48,668'); seek(1308.0)">
              where the puzzle comes in experience, it seems
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:53,092'); seek(1313.0)">
              that these networks are able to represent way more stuff
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:57,068'); seek(1317.0)">
              than they have neurons for. Right? And again, I have a bit of a back
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:00,268'); seek(1320.0)">
              of the envelope calculation here, where GPT-2 has an order of hundreds of thousands
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:04,068'); seek(1324.0)">
              of neurons. Again, the exact numbers might vary on the architecture,
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:08,548'); seek(1328.0)">
              basically, but if you look at the number of attention heads, MLP layers,
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:12,292'); seek(1332.0)">
              and the dimensions that these architecture
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:15,842'); seek(1335.0)">
              components operate with, um, you, you're in the order of a couple
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:19,906'); seek(1339.0)">
              hundred thousands of neurons. Uh, and the assumption
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:23,842'); seek(1343.0)">
              is that these models encode a lot more than that. And if
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:27,106'); seek(1347.0)">
              you're finding hard to wrap your hand around, what about how 100,000,
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:31,994'); seek(1351.0)">
              a couple hundred thousand, um, features is not enough. Remember that,
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:35,706'); seek(1355.0)">
              again, this is encoding all of the english language, right?
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:38,762'); seek(1358.0)">
              Or all of language, if you recall how
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:42,810'); seek(1362.0)">
              well GBD two was able to perform, it is plausible to that, yes, it probably
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:46,434'); seek(1366.0)">
              encodes a lot more than a couple hundred thousand features,
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:50,306'); seek(1370.0)">
              because again, this is all of language itself.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:53,794'); seek(1373.0)">
              The question is, how is that possible? Again, we know that linear.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:57,842'); seek(1377.0)">
              So basically, we seem to have conflicting or contradicting evidence when
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:01,210'); seek(1381.0)">
              we have evidence of linearity, but at the same time,
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:04,034'); seek(1384.0)">
              we have all needs, which is as many
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:07,762'); seek(1387.0)">
              neurons as it has features. But at the same time, we have models in
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:12,630'); seek(1392.0)">
              production, we have external models that seem to do quite
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:16,174'); seek(1396.0)">
              well without having as many neurons
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:20,358'); seek(1400.0)">
              as they seem to have features. Right. Again,
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:25,054'); seek(1405.0)">
              to appreciate why this is a puzzle, you just have to depend on your
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:28,302'); seek(1408.0)">
              gut feeling of there are probably more than 200,000 things that
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:32,318'); seek(1412.0)">
              you need to be looking for in. In any given standards.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:35,330'); seek(1415.0)">
              Remember how open ended all of language is?
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:39,674'); seek(1419.0)">
              And again, this is one of the difficulties in describing what exactly a
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:43,330'); seek(1423.0)">
              feature is. A feature,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:46,154'); seek(1426.0)">
              I think, of a feature is one helpful definition. Feature is a
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:50,874'); seek(1430.0)">
              thing that a neuron would be dedicated to in a sufficiently
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:54,426'); seek(1434.0)">
              large language model. But again,
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:57,890'); seek(1437.0)">
              we get to that shortly. Okay, cool. So this is our puzzle. How is this
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:01,362'); seek(1441.0)">
              happening? There's a great paper that came from a team at
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:04,710'); seek(1444.0)">
              Anthropoc that basically tries to. Basically building off of
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:08,294'); seek(1448.0)">
              previous work. Exploring this puzzle suggests
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:12,070'); seek(1452.0)">
              a way forward on tackling what exactly
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:15,550'); seek(1455.0)">
              is going on and basically being able to.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:19,094'); seek(1459.0)">
              Being able to disentangle all the mess that seems to
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:22,606'); seek(1462.0)">
              be happening, because, again, something strange. But I guess basically,
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:26,134'); seek(1466.0)">
              before this paper came out, the same team introduced
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:29,686'); seek(1469.0)">
              the idea of superposition.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:33,190'); seek(1473.0)">
              And superposition is basically a hypothesis that attempts
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:37,286'); seek(1477.0)">
              to answer the puzzle the riddle of how can a model do more represent
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:41,462'); seek(1481.0)">
              more features than it has neurons?
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:44,534'); seek(1484.0)">
              Now, it effectively says that neural networks are
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:47,998'); seek(1487.0)">
              able to do this because they exploit
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:51,470'); seek(1491.0)">
              feature sparsity and the relative feature importance.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:56,694'); seek(1496.0)">
              It basically just says that, like, the model does not, in fact,
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:00,478'); seek(1500.0)">
              do perfectly lossless compression, but it
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:03,702'); seek(1503.0)">
              trades that off in exchange for representing more features,
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:08,534'); seek(1508.0)">
              because of a property called like
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:11,990'); seek(1511.0)">
              feature sparsity, which basically means that, again, even though the english language,
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:15,222'); seek(1515.0)">
              or like any arbitrary text in english language, or like, in the set of all
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:18,470'); seek(1518.0)">
              possible texts of coherent english language sentences,
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:22,062'); seek(1522.0)">
              or perhaps not even coherent,
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:24,974'); seek(1524.0)">
              even though those contain a very large number of features,
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:29,134'); seek(1529.0)">
              it turns out not all those features are active at the same time.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:32,854'); seek(1532.0)">
              And there's a great. And this provides an opportunity for a
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:36,238'); seek(1536.0)">
              trade off where we can say, okay, what if I choose a
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:40,118'); seek(1540.0)">
              not perfectly orthogonal set of
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:43,390'); seek(1543.0)">
              vectors to represent my features, which, again, is the requirement for
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:47,342'); seek(1547.0)">
              that to be a lossless compression. What if,
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:50,102'); seek(1550.0)">
              instead, I chose n plus
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:54,102'); seek(1554.0)">
              m, actually a bit more than this ideal
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:57,334'); seek(1557.0)">
              set of perfectly orthogonal vectors, and in exchange,
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:01,214'); seek(1561.0)">
              basically, each additional direct feature direction that I
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:05,278'); seek(1565.0)">
              add basically adds some noise.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:08,678'); seek(1568.0)">
              Again, using the compression analogy, add some noise.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:11,502'); seek(1571.0)">
              Basically, I trade off a little bit of noise for
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:16,120'); seek(1576.0)">
              having a much wider set of features that can
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:19,400'); seek(1579.0)">
              represent. And again, this only works if all features are not present
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:22,616'); seek(1582.0)">
              together, because, again, if all features are present all the time,
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:26,168'); seek(1586.0)">
              that, again, if you have no sparsity, you will
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:29,472'); seek(1589.0)">
              have noise in all your outputs.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:33,664'); seek(1593.0)">
              And, yeah, this is actually what this is saying, right?
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:37,024'); seek(1597.0)">
              So in the top and the top three boxes you have
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:40,720'); seek(1600.0)">
              there is basically saying, okay, you have,
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:44,194'); seek(1604.0)">
              again, all the different dots are meant to be different features
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:48,090'); seek(1608.0)">
              that your model cares about. Again, maybe one of them is redness, one of them
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:50,586'); seek(1610.0)">
              is blue nest, one of them is square nest, etc.
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:54,194'); seek(1614.0)">
              And you can see you have like a two dimensional surface. You have
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:57,658'); seek(1617.0)">
              a two dimensional surface. In the case where there's
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:01,218'); seek(1621.0)">
              no sparsity, where every feature is as likely to be important
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:05,354'); seek(1625.0)">
              as the other, you effectively have,
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:08,458'); seek(1628.0)">
              um, what we, what we expect that is
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:12,070'); seek(1632.0)">
              like the neural network indeed only has two directions to represent the
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:15,798'); seek(1635.0)">
              two things. Um, most important thing it cares about. Okay? And again,
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:19,254'); seek(1639.0)">
              let's just imagine right now that they're all equally important. So you just like,
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:22,302'); seek(1642.0)">
              randomly chooses two features. Again, maybe it only cares about,
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:25,470'); seek(1645.0)">
              um, having a distinction between redness and.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:29,734'); seek(1649.0)">
              And it's unable to have a distinction between squareness
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:33,910'); seek(1653.0)">
              and triangle nest, for example. Right? It basically just chooses like, one pair.
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:37,890'); seek(1657.0)">
              That is, you know, is the best it can do
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:41,802'); seek(1661.0)">
              to like, get a good classification loss on
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:46,346'); seek(1666.0)">
              the problem set. Okay? But it turns out that as
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:49,610'); seek(1669.0)">
              you increase sparsity, right, as you maybe make redness
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:55,882'); seek(1675.0)">
              and circleness not as common. For example,
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:59,362'); seek(1679.0)">
              let's say you had a case whereby sometimes
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:03,266'); seek(1683.0)">
              the image has no shape in the middle. That is, sometimes it's
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:06,950'); seek(1686.0)">
              just color that matters, and sometimes you have a completely colorless input,
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:10,710'); seek(1690.0)">
              but it's just the shape in the middle. Right? And that's what sparsity means,
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:13,606'); seek(1693.0)">
              right? Where you have like, two different. In this
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:17,390'); seek(1697.0)">
              case, you have like more than two different properties
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:21,494'); seek(1701.0)">
              that don't always coincide together, right? It turns out that
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:26,494'); seek(1706.0)">
              in the 80% sparsity example, as you see here, it actually
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:30,644'); seek(1710.0)">
              chooses to represent more features than it should be
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:33,868'); seek(1713.0)">
              able to, right? Again, this is consistent with what we see in the experience.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:37,404'); seek(1717.0)">
              And on the right here, you see 90% sparsity case. It basically
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:41,228'); seek(1721.0)">
              has that direction showing that, okay, that's what spark, that's what indifference means.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:45,404'); seek(1725.0)">
              Because the whole point of having an orthogonal basis is that if
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:49,540'); seek(1729.0)">
              you try to extract the component feature, that, again, you have some vector,
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:53,340'); seek(1733.0)">
              and then you have only, again, two potential orthogonal,
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:56,924'); seek(1736.0)">
              um, features. If you do a dot product against each
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:00,276'); seek(1740.0)">
              of these, each value you get is, um,
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:04,444'); seek(1744.0)">
              basically saying how much this giving vector
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:08,748'); seek(1748.0)">
              is composed of
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:12,348'); seek(1752.0)">
              each of those directions. So basically, if you have, again, some direction
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:16,476'); seek(1756.0)">
              for some representation of a red
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:20,908'); seek(1760.0)">
              square, basically if you take a dot product of that against the
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:24,980'); seek(1764.0)">
              redness direction, it gives you, oh, this is either really red or
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:28,316'); seek(1768.0)">
              not that much red. And take a dot product of that against the
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:33,812'); seek(1773.0)">
              squared direction. It says, oh, how much of it does
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:36,980'); seek(1776.0)">
              this look like? A square? Right. So basically, so that's why these needs to be
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:39,716'); seek(1779.0)">
              orthogonal. Like they shouldn't interfere with each other. Like the quality of redness
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:43,412'); seek(1783.0)">
              should only interfere with the quality of squareness, if that makes sense.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:47,604'); seek(1787.0)">
              So that's why orthogonality is important. However,
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:51,156'); seek(1791.0)">
              again, if sometimes you basically just
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:54,276'); seek(1794.0)">
              get a colorless square or, or you get a
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:58,804'); seek(1798.0)">
              shapeless color, basically you just have any potential color. There's a
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:02,028'); seek(1802.0)">
              shape at either sparsity where you don't always have cases where these two show
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:06,740'); seek(1806.0)">
              up together. And again, for your problem set,
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:10,628'); seek(1810.0)">
              you only need to care about these in isolation. That is, you only need to
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:13,788'); seek(1813.0)">
              be really good at detecting color sometimes or detecting shape sometimes.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:18,092'); seek(1818.0)">
              It turns out that you actually be fine if
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:21,844'); seek(1821.0)">
              you chose directions for squareness and redness
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:25,012'); seek(1825.0)">
              that interfered with that is what the bottom example
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:28,580'); seek(1828.0)">
              is trying to show. Okay? So on the bottom left square,
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:32,052'); seek(1832.0)">
              you, our, let's say our orange vector is the thing that we actually
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:36,212'); seek(1836.0)">
              want to observe. Again, it's our red square, right?
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:39,612'); seek(1839.0)">
              It's a thing, it's the input is the true
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:43,156'); seek(1843.0)">
              input vector, right? And you
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:47,124'); seek(1847.0)">
              see that, again, we have five different directions, five different features.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:52,304'); seek(1852.0)">
              There's this, if you take a dot product of this value against all the different,
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:56,192'); seek(1856.0)">
              five different vectors to see, like, how much it,
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:59,952'); seek(1859.0)">
              it has a value with all of them. So you see it is along one
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:03,632'); seek(1863.0)">
              direction, for example, right? So that direction would have is given value, right? Let's say
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:07,128'); seek(1867.0)">
              that direction means how red it is. However,
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:09,912'); seek(1869.0)">
              because there's interference. It has tiny little vectors that
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:13,488'); seek(1873.0)">
              are going in along the other features that it actually
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:17,040'); seek(1877.0)">
              doesn't have. Again, work. Let's imagine that in this case, we have
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:20,478'); seek(1880.0)">
              a simple case of where, oh, this input is simply just, again,
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:24,150'); seek(1884.0)">
              a very red input, right? It's just like a red blob or like a red
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:27,958'); seek(1887.0)">
              square, right? Sorry, not a red square, like, I mean, just like a red image.
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:31,534'); seek(1891.0)">
              There's nothing else in it. So indeed it is aligns perfectly with one of
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:35,366'); seek(1895.0)">
              the features. But again, but because in this representation, again,
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:38,558'); seek(1898.0)">
              you have only two dimensions, two pure dimensions, but then
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:41,918'); seek(1901.0)">
              you're trying to squish five different things inside. Um,
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:45,226'); seek(1905.0)">
              you would actually have a little bit of, it would pick up a
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:48,650'); seek(1908.0)">
              little bit of a component along other features that
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:52,386'); seek(1912.0)">
              it actually doesn't have. So that's what interference is.
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:56,034'); seek(1916.0)">
              Um, and however, why this works is that neural
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:59,754'); seek(1919.0)">
              networks have non linearities. Um, basically, like the activation
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:03,794'); seek(1923.0)">
              functions, um, are non linearies that are able to basically
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:08,538'); seek(1928.0)">
              turn off these, um, tiny,
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:12,524'); seek(1932.0)">
              tiny bits of noise, right. If they didn't
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:15,812'); seek(1935.0)">
              have that, then the bits of noise become quite annoying and
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:19,300'); seek(1939.0)">
              would actually, like, count more towards your errors. But because again, in a
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:22,628'); seek(1942.0)">
              case whereby there's actually is very little annoyance
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:27,756'); seek(1947.0)">
              coming from the other values in the dot product, these are able
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:31,172'); seek(1951.0)">
              to be tuned off effectively. Right, so now let's imagine
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:35,108'); seek(1955.0)">
              now on the bottom right. In this case, let's imagine
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:38,350'); seek(1958.0)">
              that the true input, again, like this thing we care about,
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:32:43,534'); seek(1963.0)">
              the two blue vectors. Again, that is, you have something
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:32:47,118'); seek(1967.0)">
              that is a really big square and
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:32:50,446'); seek(1970.0)">
              also a really yellow background.
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:32:54,126'); seek(1974.0)">
              Okay? So again, you have squareness and you have yellowness.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:32:58,534'); seek(1978.0)">
              If you can observe this vector
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:02,086'); seek(1982.0)">
              addition of these two, again, remember, were operating in like a linear combination
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:05,804'); seek(1985.0)">
              regime. This is exactly the
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:09,788'); seek(1989.0)">
              same thing as we get on the left. This is why interference
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:13,268'); seek(1993.0)">
              is important, because interference requires that, like, for it to work. There should be only
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:16,876'); seek(1996.0)">
              very few number of things in this case, like, just say like, for interference to
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:20,100'); seek(2000.0)">
              have no impact here, it should only be one feature
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:23,540'); seek(2003.0)">
              that is truly trying to be detected at a time. But in a case whereby
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:27,108'); seek(2007.0)">
              the two blue directions are trying to be,
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:29,756'); seek(2009.0)">
              um, it would look to our system,
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:33:33,408'); seek(2013.0)">
              our neural network, as if it was actually this case
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:33:36,704'); seek(2016.0)">
              on the left. And in. And as we've seen, it is going to end
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:33:40,312'); seek(2020.0)">
              up chipping away those two different values to nothing because
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:33:43,672'); seek(2023.0)">
              of the non linearities. I'm going to think that, oh, actually, instead of
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:33:47,280'); seek(2027.0)">
              seeing a square, a yellow square, it's just going to see
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:33:51,024'); seek(2031.0)">
              a circle. Maybe that's what that third direction represents, which is
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:33:54,272'); seek(2034.0)">
              complete noise, isn't it? Which is completely wrong, so to
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:33:57,718'); seek(2037.0)">
              speak. Right. This is basically going to end up ignoring the components of this vector
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:01,550'); seek(2041.0)">
              along those two as just being noise, which is really
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:04,694'); seek(2044.0)">
              bad, which is really why, in the case where there's no sparsity, where, like,
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:08,030'); seek(2048.0)">
              again, all the features are likely to be active, the neural network doesn't even
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:12,022'); seek(2052.0)">
              bother trying to do anything funny. It doesn't try any funny
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:15,150'); seek(2055.0)">
              business asset in the top left square. It simply just
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:19,734'); seek(2059.0)">
              represents, you know, again, an arbitrary two features.
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:22,806'); seek(2062.0)">
              Or in a case whereby it's able to have a sense of relative importance
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:34:27,504'); seek(2067.0)">
              of features, maybe, like, one feature is way more important in
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:34:31,824'); seek(2071.0)">
              determining. To give you an example, let's say
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:34:35,360'); seek(2075.0)">
              one feature of language is, well, what language is it
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:34:38,600'); seek(2078.0)">
              in? That is like, is it English or Spanish? Is it English or Chinese?
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:34:41,856'); seek(2081.0)">
              Another feature is the sentence referring
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:34:46,032'); seek(2086.0)">
              to in the past tense or present tense. Right.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:34:49,133'); seek(2089.0)">
              This past or present tense feature, you know, helps you avoid
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:34:52,605'); seek(2092.0)">
              grammatical mistakes, but it's fair enough to assume that the
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:34:56,229'); seek(2096.0)">
              feature of at least knowing what language the question or the
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:34:59,781'); seek(2099.0)">
              query is in is probably way more
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:03,109'); seek(2103.0)">
              important in terms of, like, having you avoid errors
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:07,197'); seek(2107.0)">
              than detecting if it's past tense or present tense.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:10,933'); seek(2110.0)">
              Right? So again, that's just like one abstract idea of
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:15,694'); seek(2115.0)">
              the model. So again, if the model only had like two different features, like one,
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:19,134'); seek(2119.0)">
              let's like just one, like, or like on the margin.
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:22,326'); seek(2122.0)">
              If the model has to represent one more thing and it has to choose between
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:35:25,606'); seek(2125.0)">
              the language detection and the past or
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:35:29,670'); seek(2129.0)">
              present tense, it will most likely prioritize choosing to represent, using that one extra
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:35:33,662'); seek(2133.0)">
              feature to represent language and language type, that is this,
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:35:36,750'); seek(2136.0)">
              English or French or Chinese, as that probably has way more predictive power.
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:35:40,894'); seek(2140.0)">
              Like, we'll have it have way less error than if it was instead
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:35:44,670'); seek(2144.0)">
              of trying to predict the correct tense,
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:35:47,518'); seek(2147.0)">
              but in the wrong language. Again, this bit
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:35:51,278'); seek(2151.0)">
              of a toy example. Okay, so how do we solve this?
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:35:54,854'); seek(2154.0)">
              Right. Again, giving this, we suspect this is what models are doing. Or again,
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:35:58,710'); seek(2158.0)">
              we suspect this is why they're able to do it. This is why they're
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:01,966'); seek(2161.0)">
              able to get away with it. Again, they're trying to exploit sparsity by compressing
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:05,510'); seek(2165.0)">
              stuff. So the paper I shared basically tries to
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:08,878'); seek(2168.0)">
              do this, um, by tackling a smaller
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:12,752'); seek(2172.0)">
              model, right? So the tackle a one layer transformer, and they pick out one
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:16,696'); seek(2176.0)">
              component of the architecture. Again, as I explained in
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:20,648'); seek(2180.0)">
              this, in our typical large transformer, yeah. Every single component
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:36:25,120'); seek(2185.0)">
              is doing some version of this, right? Since this information is
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:36:28,848'); seek(2188.0)">
              flowing through our entire network, each discrete component is going to need to
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:36:32,792'); seek(2192.0)">
              have to do some version of this, right? So they focus on the MLP
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:36:36,656'); seek(2196.0)">
              layer, which is what comes the attention heads. And in
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:36:40,896'); seek(2200.0)">
              the model, they use the dimensions of that,
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:36:44,376'); seek(2204.0)">
              basically, like how many vectors or how many neurons it has.
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:36:47,776'); seek(2207.0)">
              So how many dimensions of each vector has or how many neuron,
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:36:52,144'); seek(2212.0)">
              how many neurons that layer has is 512. And what they do
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:36:55,640'); seek(2215.0)">
              is, as seen here on the right, they use something called a
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:36:58,920'); seek(2218.0)">
              sparse overcomplete order encoder. Obviously,
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:02,040'); seek(2222.0)">
              I'll describe what that means, starting from the right. Okay, so what does that mean?
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:05,280'); seek(2225.0)">
              And autoencoder and a BSN. Autoencoder is basically a neural
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:09,160'); seek(2229.0)">
              network whose primary purpose is reconstruction. So basically
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:12,680'); seek(2232.0)">
              you have some input, you have something in
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:16,136'); seek(2236.0)">
              the middle, which is like, again, your network. And the job of
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:37:19,608'); seek(2239.0)">
              that network is to try to replicate, to reproduce the output.
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:37:24,024'); seek(2244.0)">
              That seems kind of silly. Like why just bother with this density transform?
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:37:27,584'); seek(2247.0)">
              Because, well, in some cases, you might want to do something like,
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:37:31,328'); seek(2251.0)">
              okay, compressed dimensions, right? So let's say you have this very like,
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:37:34,756'); seek(2254.0)">
              large input you want to find interesting.
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:37:39,228'); seek(2259.0)">
              You want to find the most important critical features by compressing it
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:37:42,628'); seek(2262.0)">
              in the middle and seeing how. Well, okay, like,
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:37:45,988'); seek(2265.0)">
              again, let's say something needs five dimensions to this
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:37:49,684'); seek(2269.0)">
              input is five dimensions. What are the two most important
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:37:53,340'); seek(2273.0)">
              dimensions of this or two most important, like representations of these five
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:37:56,652'); seek(2276.0)">
              dimensions I can take that would have me still
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:38:00,588'); seek(2280.0)">
              do well on reconstructing with
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:38:05,412'); seek(2285.0)">
              this. That basically has this property
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:38:08,844'); seek(2288.0)">
              of feature discovery by compression.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:38:12,380'); seek(2292.0)">
              That's what auto encoders do.
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:38:14,564'); seek(2294.0)">
              Overcomplete. Again, starting from the right to left, describe overcomplete,
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:38:18,460'); seek(2298.0)">
              basically does the slightly opposite version of that,
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:38:21,572'); seek(2301.0)">
              which is, instead of compressing, you're basically trying to expand.
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:38:24,660'); seek(2304.0)">
              You basically try to give the
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:38:28,002'); seek(2308.0)">
              order encoder in the middle again between the input and your
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:38:31,666'); seek(2311.0)">
              construction of the input is much larger than as you're saying. If this
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:38:35,274'); seek(2315.0)">
              neural network representation had way more room
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:38:39,154'); seek(2319.0)">
              to represent stuff, what would it look
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:38:42,362'); seek(2322.0)">
              like? Right? And remember, the whole
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:38:46,066'); seek(2326.0)">
              point of our store
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:38:49,218'); seek(2329.0)">
              position is that we're assuming that the model we see is actually trying
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:38:52,862'); seek(2332.0)">
              to simulate a much larger model. Again, remember, that's the
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:38:55,958'); seek(2335.0)">
              whole point of superposition, right? So by using this
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:38:59,982'); seek(2339.0)">
              overcompleted encoder, we're trying to say that, cool, whatever representation
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:39:03,830'); seek(2343.0)">
              this MLP node has for some input,
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:39:08,214'); seek(2348.0)">
              what if we gave it way more neurons to work with?
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:39:12,494'); seek(2352.0)">
              What would you do with it? That's the overcomplete section.
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:39:16,302'); seek(2356.0)">
              Then the sparse component of that description is
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:39:19,908'); seek(2359.0)">
              saying, like, sure, what if we just go from like, you know,
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:39:23,548'); seek(2363.0)">
              a five dimensional,
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:39:26,844'); seek(2366.0)">
              inscrutable, compressed complex thing to
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:39:30,108'); seek(2370.0)">
              a hundred dimension inscrutable complex thing, right?
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:39:33,324'); seek(2373.0)">
              We're not much better than we started, right? And again, neural networks, just like,
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:39:36,428'); seek(2376.0)">
              don't really have any incentives to just make things explainable to us. So the sparse
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:39:40,060'); seek(2380.0)">
              component says, okay, in addition to giving you the
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:39:43,540'); seek(2383.0)">
              network, more room to work with, to like, expand, to like, see what you learned,
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:39:46,932'); seek(2386.0)">
              we want to force you to narrow your
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:39:50,758'); seek(2390.0)">
              learnings, your features, to being
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:39:55,366'); seek(2395.0)">
              active in one node at a time. Right. I think I
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:39:59,118'); seek(2399.0)">
              explained before how just because I
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:40:02,646'); seek(2402.0)">
              think it was, in this example, just going to jump quickly. So just because
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:40:06,654'); seek(2406.0)">
              I say that, oh, like, linearity says you must have as
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:40:10,222'); seek(2410.0)">
              many dimensions as you want features, it doesn't necessarily mean that it
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:40:13,326'); seek(2413.0)">
              will always be one. Hot, right? You might have a case whereby there's several,
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:40:16,724'); seek(2416.0)">
              you know, there are infinite, many orthogonal,
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:40:21,004'); seek(2421.0)">
              four orthogonal vectors, like four vectors that form an orthogonal basis
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:40:24,796'); seek(2424.0)">
              that aren't one. Hot. Right. It's kind of like smeared between all the different values.
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:40:28,196'); seek(2428.0)">
              But again, from our, for our convenience to like say that,
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:40:31,324'); seek(2431.0)">
              that neuron is like firing a lot when it sees redness,
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:40:35,684'); seek(2435.0)">
              we want to impose an extra basic
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:40:39,428'); seek(2439.0)">
              constraint on the auto encoder to say that,
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:40:42,722'); seek(2442.0)">
              cool. Don't just try to find representations
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:40:46,578'); seek(2446.0)">
              with more nodes to work with when you do this,
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:40:50,306'); seek(2450.0)">
              narrow down your learnings or try to isolate your learnings
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:40:53,930'); seek(2453.0)">
              for one feature to like, one node at a time, right?
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:40:56,906'); seek(2456.0)">
              That's basically just for our interpretability benefit.
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:41:00,754'); seek(2460.0)">
              And yet that is what a sparse overcomplete order code is.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:41:03,930'); seek(2463.0)">
              Or usually they usually just ignore the overcomplete
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:41:07,482'); seek(2467.0)">
              part part and just call it a sparse or encoder and basically
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:41:10,710'); seek(2470.0)">
              just says, cool. We want to give neural
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:41:15,542'); seek(2475.0)">
              networks opportunity to want to extract what they've learned by
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:41:19,766'); seek(2479.0)">
              trying to reconstruct representations using more dimensions.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:41:24,334'); seek(2484.0)">
              And we want this new like extraction
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:41:27,726'); seek(2487.0)">
              to be sparse in such a way that only one node
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:41:31,518'); seek(2491.0)">
              is activated at a time for a given feature that is applied and
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:41:37,264'); seek(2497.0)">
              effectively that looks like this. So they ran
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:41:40,712'); seek(2500.0)">
              this, this training, this training
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:41:44,496'); seek(2504.0)">
              process for the sparse auto encoder on their one layer network for the
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:41:47,928'); seek(2507.0)">
              MLP layer. And again, if you see here, they describe on
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:41:51,928'); seek(2511.0)">
              the left there you see this like the act 512,
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:41:55,912'); seek(2515.0)">
              which is like the activation of MLP layer, typically should have 500,
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:41:59,312'); seek(2519.0)">
              1212 dimensions. Again, that would just mean instead of 1
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:42:03,332'); seek(2523.0)">
              second, instead of like four different blocks here,
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:42:06,836'); seek(2526.0)">
              that'll be 512, right? That's like how big the vector is.
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:42:10,404'); seek(2530.0)">
              So they went from 512 and expanded all the RAN
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:42:13,908'); seek(2533.0)">
              different versions, but the largest ones went up to 131k.
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:42:20,524'); seek(2540.0)">
              So basically that would mean if again, with the
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:42:23,948'); seek(2543.0)">
              network of the quarter on the right, if the,
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:42:27,828'); seek(2547.0)">
              on the input and output was 512 different like
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:42:31,764'); seek(2551.0)">
              neurons. And in the middle you had this giant
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:42:36,004'); seek(2556.0)">
              130K node network,
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:42:39,460'); seek(2559.0)">
              or a node like layer, basically that was trying
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:42:42,852'); seek(2562.0)">
              to reconstruct the input into the output.
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:42:47,124'); seek(2567.0)">
              And they learned a bunch of stuff. They have a very
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:42:50,548'); seek(2570.0)">
              nice interactive, um, application that
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:42:54,144'); seek(2574.0)">
              I encourage you all to check out that basically shows the
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:42:58,552'); seek(2578.0)">
              model learning really interesting things. So one of the,
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:43:00,904'); seek(2580.0)">
              um, the neurons I discovered, again, neuron simply means like,
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:43:04,472'); seek(2584.0)">
              because of this like, um, constraint of sparsity, the,
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:43:07,744'); seek(2587.0)">
              the model learns like isolate some abstract
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:43:11,824'); seek(2591.0)">
              feature. So literally one of these 130K nodes,
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:43:15,624'); seek(2595.0)">
              basically, like once this feature is present an input, it just like fires
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:43:19,160'); seek(2599.0)">
              and screams a lot. You see like this input is really here. And these features
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:43:22,888'); seek(2602.0)">
              are like so like wide and varied. When,
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:43:26,608'); seek(2606.0)">
              for example, detects, the,
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:43:30,064'); seek(2610.0)">
              detects arabic characters in input,
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:43:33,472'); seek(2613.0)">
              another of them, as you see here, detects if a sequence
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:43:37,672'); seek(2617.0)">
              of text is probably like a DNA
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:43:41,280'); seek(2621.0)">
              sequence which I think was pretty wild because, like, this could also be gibberish,
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:43:44,712'); seek(2624.0)">
              but there are certain patterns and
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:43:48,280'); seek(2628.0)">
              I guess the actual letters, for example, that is used for DNA encoding.
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:43:52,016'); seek(2632.0)">
              That seems like such an arbitrary thing that a model will learn. But it did
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:43:54,560'); seek(2634.0)">
              learn this. And you can check out other esoteric ones that you learned
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:43:59,984'); seek(2639.0)">
              in this reconstruction. And again, feature was present in
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:44:03,936'); seek(2643.0)">
              the 512 mlp.
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:44:07,960'); seek(2647.0)">
              But because it was coked up and
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:44:11,308'); seek(2651.0)">
              all cooped up together with the superposition,
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:44:16,164'); seek(2656.0)">
              in the superposition phase, it was hard to basically discern. The whole point of
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:44:19,796'); seek(2659.0)">
              the recorder is basically to extract these features out there.
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:44:22,548'); seek(2662.0)">
              So now they become one isolated thing, which kind
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:44:27,068'); seek(2667.0)">
              of brings us full circle to the definition of what a feature is. So again,
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:44:30,684'); seek(2670.0)">
              I've been throwing around the idea of feature as just a distinct
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:44:34,580'); seek(2674.0)">
              thing. Model find to be interesting, right. As basically
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:44:39,592'); seek(2679.0)">
              one perhaps more narrow
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:44:43,752'); seek(2683.0)">
              definition of it. I guess I don't want to say formal, but just like,
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:44:46,952'); seek(2686.0)">
              one more particular definition of it, based on this paradigm that
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:44:50,296'); seek(2690.0)">
              we've described, is like a feature is basically a property that
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:44:54,064'); seek(2694.0)">
              a model would encode.
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:44:57,744'); seek(2697.0)">
              Would dedicate an entire neuron to. Would encode using an.
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:45:00,776'); seek(2700.0)">
              Using one neuron if it had enough neurons, right?
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:45:03,730'); seek(2703.0)">
              So basically, if there's such a thing that if a model was sufficiently
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:45:08,074'); seek(2708.0)">
              large, would it get one neuron to it? That thing is a feature,
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:45:11,586'); seek(2711.0)">
              right? But if there's a thing that no matter how many neurons
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:45:15,114'); seek(2715.0)">
              it had, this thing wouldn't have a neuron,
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:45:18,682'); seek(2718.0)">
              it perhaps would be like a part of some other neuron, then that thing's not
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:45:21,786'); seek(2721.0)">
              a feature, right. It seems kind of circular, but it
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:45:25,906'); seek(2725.0)">
              turns about. Yeah. The precise definition of, like, futures can be kind of gnarly.
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:45:28,938'); seek(2728.0)">
              Um, but, like, for all practical purposes, you know, think of, again, features in the
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:45:32,498'); seek(2732.0)">
              colloquial sense of just like, you know, a thing that the model finds
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:45:35,738'); seek(2735.0)">
              to be interesting, like squareness or bonus or whatever. Um,
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:45:39,474'); seek(2739.0)">
              and but the interesting thing, I guess, is that, again, like,
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:45:42,546'); seek(2742.0)">
              part of the things. Part of the ways, like, a more powerful model is more
            </span>
            
            <span id="chunk-731" class="transcript-chunks" onclick="console.log('00:45:45,890'); seek(2745.0)">
              powerful is because it can indeed encode for more
            </span>
            
            <span id="chunk-732" class="transcript-chunks" onclick="console.log('00:45:49,282'); seek(2749.0)">
              stuff than a small one can. And again, as a proposition suggest
            </span>
            
            <span id="chunk-733" class="transcript-chunks" onclick="console.log('00:45:53,474'); seek(2753.0)">
              the smaller ones actually encode a lot more than they might than
            </span>
            
            <span id="chunk-734" class="transcript-chunks" onclick="console.log('00:45:57,090'); seek(2757.0)">
              their size alone might suggest, right? Because, again, the whole point of this is if
            </span>
            
            <span id="chunk-735" class="transcript-chunks" onclick="console.log('00:46:02,058'); seek(2762.0)">
              indeed there was no superposition, or like, if indeed there was nothing
            </span>
            
            <span id="chunk-736" class="transcript-chunks" onclick="console.log('00:46:05,474'); seek(2765.0)">
              weird happening, then this MLP layer would actually only have 512,
            </span>
            
            <span id="chunk-737" class="transcript-chunks" onclick="console.log('00:46:09,322'); seek(2769.0)">
              but they were able to extract way over 100,000
            </span>
            
            <span id="chunk-738" class="transcript-chunks" onclick="console.log('00:46:13,794'); seek(2773.0)">
              reasonable features. So something for sure where
            </span>
            
            <span id="chunk-739" class="transcript-chunks" onclick="console.log('00:46:17,370'); seek(2777.0)">
              it is happening. And, like. And these features, like, were consistent with
            </span>
            
            <span id="chunk-740" class="transcript-chunks" onclick="console.log('00:46:21,130'); seek(2781.0)">
              experimental validation for.
            </span>
            
            <span id="chunk-741" class="transcript-chunks" onclick="console.log('00:46:24,254'); seek(2784.0)">
              Again like they had different evaluation methods that you can check out in the paper
            </span>
            
            <span id="chunk-742" class="transcript-chunks" onclick="console.log('00:46:27,822'); seek(2787.0)">
              to show like how much confidence they have for it. But basically the features like
            </span>
            
            <span id="chunk-743" class="transcript-chunks" onclick="console.log('00:46:30,542'); seek(2790.0)">
              very confidence or incoherence or at least in like explainability
            </span>
            
            <span id="chunk-744" class="transcript-chunks" onclick="console.log('00:46:34,334'); seek(2794.0)">
              to like it's a real human being human. But I feel like the
            </span>
            
            <span id="chunk-745" class="transcript-chunks" onclick="console.log('00:46:37,638'); seek(2797.0)">
              number of explainable features, high quality feature definitely exceeds 512.
            </span>
            
            <span id="chunk-746" class="transcript-chunks" onclick="console.log('00:46:41,158'); seek(2801.0)">
              So indeed this compression is happening for sure and
            </span>
            
            <span id="chunk-747" class="transcript-chunks" onclick="console.log('00:46:44,534'); seek(2804.0)">
              this is like the proof for it. And yeah the future of this
            </span>
            
            <span id="chunk-748" class="transcript-chunks" onclick="console.log('00:46:47,958'); seek(2807.0)">
              work could basically look like scaling up this auto encoders to work
            </span>
            
            <span id="chunk-749" class="transcript-chunks" onclick="console.log('00:46:51,030'); seek(2811.0)">
              on much larger models and uncover more useful features going forward.
            </span>
            
            <span id="chunk-750" class="transcript-chunks" onclick="console.log('00:46:55,334'); seek(2815.0)">
              Awesome and that is the talk. Thanks for
            </span>
            
            <span id="chunk-751" class="transcript-chunks" onclick="console.log('00:46:58,918'); seek(2818.0)">
              joining here and I encourage you to read more of the
            </span>
            
            <span id="chunk-752" class="transcript-chunks" onclick="console.log('00:47:02,598'); seek(2822.0)">
              papers out there. I think the anthropic blog
            </span>
            
            <span id="chunk-753" class="transcript-chunks" onclick="console.log('00:47:07,374'); seek(2827.0)">
              posts and paper, informal papers and formal papers are a great place to
            </span>
            
            <span id="chunk-754" class="transcript-chunks" onclick="console.log('00:47:10,758'); seek(2830.0)">
              start as that basically represents
            </span>
            
            <span id="chunk-755" class="transcript-chunks" onclick="console.log('00:47:14,158'); seek(2834.0)">
              where the frontiers right now. Awesome,
            </span>
            
            <span id="chunk-756" class="transcript-chunks" onclick="console.log('00:47:17,294'); seek(2837.0)">
              thank you for the time and see you later.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Boluwatife%20Ben-Adeola%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Boluwatife%20Ben-Adeola%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Boluwatife%20Ben-Adeola_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Boluwatife Ben-Adeola
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Independent AI Researcher 
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/ben-adeola/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Boluwatife Ben-Adeola's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Boluwatife Ben-Adeola"
                  data-url="https://www.conf42.com/llms2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Large Language Models"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday San Francisco 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday London 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@widgetbot/crate@3" async defer>
      new Crate({
        server: '814240231606714368',
        channel: '814240231788249115'
      })
    </script>
  </body>
</html>