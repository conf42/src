<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Horizontal Autoscaling with Kubernetes</title>
    <meta name="description" content="Explore the magic world of Kubernetes!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/kube_rob_richardson.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Horizontal Autoscaling with Kubernetes | Conf42"/>
    <meta property="og:description" content="Now that the app is running in Kubernetes, how do we scale it to meet demand? What metric should we use? CPU? Requests? something else? Let's dig into why we auto-scale, and how we auto-scale with lots of examples. Finally we'll look at potential pitfalls and gotchas like how to scale to 0 and how to avoid scaling too big for your budget. Come learn how to scale with Kubernetes."/>
    <meta property="og:url" content="https://conf42.com/Kube_Native_2022_Rob_Richardson_horizontal_autoscaling"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/CLOUD2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Cloud Native 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-03-06
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/cloud2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CA6B46;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Kube Native 2022 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Explore the magic world of Kubernetes!
 -->
              <script>
                const event_date = new Date("2022-10-20T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2022-10-20T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "r-tVKhb1W98"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "geVnpogxgD8"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrCXmMskCiu1Pfv2NDKvM6qd" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, welcome to Comp Kube native Con. This is", "timestamp": "00:00:23,690", "timestamp_s": 23.0}, {"text": "really fun. I get to share with you horizontal auto scaling with", "timestamp": "00:00:27,724", "timestamp_s": 27.0}, {"text": "Kubernetes. Let\u0027s dive in. Here\u0027s the part where I tell you I am", "timestamp": "00:00:31,068", "timestamp_s": 31.0}, {"text": "definitely going to post the slides on my site tonight.", "timestamp": "00:00:34,892", "timestamp_s": 34.0}, {"text": "I\u0027ve changed similar speakers and it\u0027s never worked out very well for me either.", "timestamp": "00:00:37,930", "timestamp_s": 37.0}, {"text": "So let\u0027s go to robridge.org where we can find the slides online right", "timestamp": "00:00:41,852", "timestamp_s": 41.0}, {"text": "now. We\u0027ll go to robridge.org and", "timestamp": "00:00:45,836", "timestamp_s": 45.0}, {"text": "click click here on presentations and we can see horizontal autoscaling", "timestamp": "00:00:49,772", "timestamp_s": 49.0}, {"text": "with Kubernetes. The slides are online right now.", "timestamp": "00:00:53,434", "timestamp_s": 53.0}, {"text": "While we\u0027re here on robrich.org, let\u0027s click on about me and see some", "timestamp": "00:00:57,170", "timestamp_s": 57.0}, {"text": "of the things that I\u0027ve done recently. I\u0027m a developer advocate for", "timestamp": "00:01:00,388", "timestamp_s": 60.0}, {"text": "Jetpackio. If you\u0027re struggling with Kubernetes, I would love to learn with you. I\u0027m also", "timestamp": "00:01:04,292", "timestamp_s": 64.0}, {"text": "a Microsoft MVP and MCT, a Docker captain and", "timestamp": "00:01:08,168", "timestamp_s": 68.0}, {"text": "a friend of Redgate. AZ Givecamp is really fun. AZ Givecamp brings", "timestamp": "00:01:12,072", "timestamp_s": 72.0}, {"text": "volunteer developers together with charities to build free software.", "timestamp": "00:01:16,318", "timestamp_s": 76.0}, {"text": "We start building software Friday after work. Sunday afternoon, we deliver", "timestamp": "00:01:20,098", "timestamp_s": 80.0}, {"text": "completed software to charities. Sleep is optional, caffeine provided. If you\u0027re in", "timestamp": "00:01:23,922", "timestamp_s": 83.0}, {"text": "Phoenix, come join us for the next AZ give camp. Or if you\u0027d like a", "timestamp": "00:01:27,708", "timestamp_s": 87.0}, {"text": "give camp close to where you live, hit me up here at the conference or", "timestamp": "00:01:31,164", "timestamp_s": 91.0}, {"text": "on email or Twitter. And let\u0027s get a gift camp in your neighborhood too.", "timestamp": "00:01:34,768", "timestamp_s": 94.0}, {"text": "Some of the other things that I\u0027ve done I do a lot with Kubernetes and", "timestamp": "00:01:38,480", "timestamp_s": 98.0}, {"text": "Docker and one of the things I\u0027m the most proud of I", "timestamp": "00:01:41,488", "timestamp_s": 101.0}, {"text": "replied to a Net Rocks podcast episode they read my comments on here.", "timestamp": "00:01:44,948", "timestamp_s": 104.0}, {"text": "They sent me a mug.", "timestamp": "00:01:48,436", "timestamp_s": 108.0}, {"text": "So let\u0027s dig into horizontal auto scaling with Kubernetes.", "timestamp": "00:01:51,730", "timestamp_s": 111.0}, {"text": "We talked about this guy first. Let\u0027s talk about autoscaling now.", "timestamp": "00:01:55,590", "timestamp_s": 115.0}, {"text": "As we talk about scaling, part of what we\u0027re trying to accomplish", "timestamp": "00:01:59,592", "timestamp_s": 119.0}, {"text": "is to meet the capacity when we need it and to save money", "timestamp": "00:02:03,422", "timestamp_s": 123.0}, {"text": "when we don\u0027t. That\u0027s the nature of scaling.", "timestamp": "00:02:06,956", "timestamp_s": 126.0}, {"text": "When we talk about scaling, we can talk about both horizontal autoscaling and", "timestamp": "00:02:10,170", "timestamp_s": 130.0}, {"text": "vertical scaling. With horizontal scaling, we\u0027re adding", "timestamp": "00:02:14,092", "timestamp_s": 134.0}, {"text": "more items to be able to reach that capacity.", "timestamp": "00:02:17,762", "timestamp_s": 137.0}, {"text": "With vertical scaling, we\u0027re increasing the size of each item", "timestamp": "00:02:20,758", "timestamp_s": 140.0}, {"text": "to be able to reach that capacity.", "timestamp": "00:02:24,870", "timestamp_s": 144.0}, {"text": "So dialing in some more. With vertical scaling,", "timestamp": "00:02:27,710", "timestamp_s": 147.0}, {"text": "we\u0027re increasing the size of each item.", "timestamp": "00:02:31,050", "timestamp_s": 151.0}, {"text": "Now this might be great for things that need state where we", "timestamp": "00:02:34,154", "timestamp_s": 154.0}, {"text": "don\u0027t want to manage synchronization, maybe a database by", "timestamp": "00:02:38,052", "timestamp_s": 158.0}, {"text": "comparison with horizontal scaling, we are increasing the number of items.", "timestamp": "00:02:41,892", "timestamp_s": 161.0}, {"text": "Now we need to coordinate between them. We may need to populate", "timestamp": "00:02:46,234", "timestamp_s": 166.0}, {"text": "data into a new node. We may need to ensure that", "timestamp": "00:02:49,678", "timestamp_s": 169.0}, {"text": "there\u0027s one main node and that they coordinate together.", "timestamp": "00:02:52,888", "timestamp_s": 172.0}, {"text": "This synchronization isn\u0027t necessary if we\u0027re using a", "timestamp": "00:02:56,570", "timestamp_s": 176.0}, {"text": "stateless service, perhaps a web server.", "timestamp": "00:02:59,772", "timestamp_s": 179.0}, {"text": "So horizontal and vertical scaling.", "timestamp": "00:03:03,370", "timestamp_s": 183.0}, {"text": "Now how did we get here? What are we building on top of? Whose shoulders", "timestamp": "00:03:07,410", "timestamp_s": 187.0}, {"text": "are we standing on top of? Well, back in the old day,", "timestamp": "00:03:11,366", "timestamp_s": 191.0}, {"text": "scaling was hard, it was slow, so we would", "timestamp": "00:03:14,448", "timestamp_s": 194.0}, {"text": "generally over provision. We\u0027re provisioning for the traffic", "timestamp": "00:03:17,872", "timestamp_s": 197.0}, {"text": "on our peak day. Maybe that\u0027s Black Friday, maybe that\u0027s Super", "timestamp": "00:03:21,642", "timestamp_s": 201.0}, {"text": "Bowl Sunday. Maybe that\u0027s when we go viral. But because", "timestamp": "00:03:25,572", "timestamp_s": 205.0}, {"text": "we\u0027re over provisioning for those worst case scenarios,", "timestamp": "00:03:29,380", "timestamp_s": 209.0}, {"text": "on a normal day our machines may sit completely idle.", "timestamp": "00:03:33,802", "timestamp_s": 213.0}, {"text": "Now why did we do this? Well, we did this because provisioning", "timestamp": "00:03:37,278", "timestamp_s": 217.0}, {"text": "was hard. It might take days or weeks or months", "timestamp": "00:03:41,118", "timestamp_s": 221.0}, {"text": "to get approval, buy the hardware, install the content", "timestamp": "00:03:44,888", "timestamp_s": 224.0}, {"text": "and install the operating system, then install", "timestamp": "00:03:49,068", "timestamp_s": 229.0}, {"text": "our application, plug this into the load balancer.", "timestamp": "00:03:52,236", "timestamp_s": 232.0}, {"text": "That\u0027s definitely not something that we can do. If we have additional load yesterday", "timestamp": "00:03:55,234", "timestamp_s": 235.0}, {"text": "that we need to handle tomorrow, this process may take weeks or", "timestamp": "00:03:59,154", "timestamp_s": 239.0}, {"text": "months. So we need to have it all the way done by the time we", "timestamp": "00:04:02,528", "timestamp_s": 242.0}, {"text": "reach that peak load. So we\u0027re over provisioning to", "timestamp": "00:04:05,872", "timestamp_s": 245.0}, {"text": "be able to support the load on those extreme circumstances.", "timestamp": "00:04:09,552", "timestamp_s": 249.0}, {"text": "Today we don\u0027t need to do that. Today we", "timestamp": "00:04:13,490", "timestamp_s": 253.0}, {"text": "buy just what we need. Utility billing with clouds allows", "timestamp": "00:04:16,932", "timestamp_s": 256.0}, {"text": "us to scale easily and quickly to meet", "timestamp": "00:04:20,698", "timestamp_s": 260.0}, {"text": "the demand. And then when the demand eases, then we", "timestamp": "00:04:24,072", "timestamp_s": 264.0}, {"text": "can give those resources back and stop paying them.", "timestamp": "00:04:27,608", "timestamp_s": 267.0}, {"text": "Previously we would run our machines mostly idle so that", "timestamp": "00:04:31,830", "timestamp_s": 271.0}, {"text": "we had additional capacity available. Today we run our machines", "timestamp": "00:04:35,224", "timestamp_s": 275.0}, {"text": "mostly at capacity. 80 or 90% is not uncommon", "timestamp": "00:04:39,026", "timestamp_s": 279.0}, {"text": "because we really want to use our hardware most effectively.", "timestamp": "00:04:43,202", "timestamp_s": 283.0}, {"text": "So utility billing makes this possible.", "timestamp": "00:04:46,970", "timestamp_s": 286.0}, {"text": "Now, all of that scaling applies to any scaling scenario.", "timestamp": "00:04:51,150", "timestamp_s": 291.0}, {"text": "Let\u0027s apply this specifically to kubernetes. Now in", "timestamp": "00:04:54,838", "timestamp_s": 294.0}, {"text": "kubernetes we could talk about scaling a cluster. We\u0027re not going to", "timestamp": "00:04:58,048", "timestamp_s": 298.0}, {"text": "do that today. But as you grab the slides from robrich.org,", "timestamp": "00:05:01,328", "timestamp_s": 301.0}, {"text": "dig into scaling the cluster and that can be a really fun topic.", "timestamp": "00:05:04,634", "timestamp_s": 304.0}, {"text": "Today we\u0027re going to talk about scaling the workload, talking about", "timestamp": "00:05:08,234", "timestamp_s": 308.0}, {"text": "pods. Now that presumes that your cluster is big enough to handle", "timestamp": "00:05:12,164", "timestamp_s": 312.0}, {"text": "this. Next up we could talk about vertical scaling", "timestamp": "00:05:15,438", "timestamp_s": 315.0}, {"text": "or horizontal scaling. Vertical scaling is definitely interesting.", "timestamp": "00:05:19,038", "timestamp_s": 319.0}, {"text": "It\u0027s about changing resource limits on our pods to match", "timestamp": "00:05:22,616", "timestamp_s": 322.0}, {"text": "increased demand. But today we\u0027re going to talk about horizontal", "timestamp": "00:05:26,060", "timestamp_s": 326.0}, {"text": "scaling. We\u0027re going to talk about increasing the count of pods", "timestamp": "00:05:30,290", "timestamp_s": 330.0}, {"text": "to match the demand that we have. So let\u0027s dig", "timestamp": "00:05:34,290", "timestamp_s": 334.0}, {"text": "into pod scaling. Well,", "timestamp": "00:05:38,332", "timestamp_s": 338.0}, {"text": "why isn\u0027t this automatic? Why isn\u0027t there just a push the button", "timestamp": "00:05:42,190", "timestamp_s": 342.0}, {"text": "and now we have scaling in our cluster. Well, it depends a lot on", "timestamp": "00:05:45,824", "timestamp_s": 345.0}, {"text": "the workload, in particular, how your workload works and what", "timestamp": "00:05:49,408", "timestamp_s": 349.0}, {"text": "metric you\u0027re using to measure it. What metric?", "timestamp": "00:05:53,076", "timestamp_s": 353.0}, {"text": "Now, we might have a cpu bound workload, in which case we want to scale", "timestamp": "00:05:57,114", "timestamp_s": 357.0}, {"text": "based on our cpu. Or we might have an IL bound workload,", "timestamp": "00:06:00,602", "timestamp_s": 360.0}, {"text": "in which case we want to scale based on the request current", "timestamp": "00:06:04,202", "timestamp_s": 364.0}, {"text": "concurrent request. Or maybe the request queue length.", "timestamp": "00:06:07,880", "timestamp_s": 367.0}, {"text": "We may scale based on external factors. Maybe we\u0027re looking at", "timestamp": "00:06:11,678", "timestamp_s": 371.0}, {"text": "our message bus queue length. Or maybe we\u0027re looking at our", "timestamp": "00:06:14,904", "timestamp_s": 374.0}, {"text": "load balancer for details of how we should scale.", "timestamp": "00:06:18,488", "timestamp_s": 378.0}, {"text": "Or maybe we\u0027re looking at latency in a critical function.", "timestamp": "00:06:21,698", "timestamp_s": 381.0}, {"text": "Is it taking a long time to log in? Maybe we need to up the", "timestamp": "00:06:24,892", "timestamp_s": 384.0}, {"text": "servers associated with our authentication process. Now this", "timestamp": "00:06:28,332", "timestamp_s": 388.0}, {"text": "is definitely not an exhaustive list of metrics, but why isn\u0027t", "timestamp": "00:06:32,272", "timestamp_s": 392.0}, {"text": "this built in? Because it really depends on how our workload works.", "timestamp": "00:06:35,478", "timestamp_s": 395.0}, {"text": "If it works based on a cpu scaling metric, and we\u0027re scaling based", "timestamp": "00:06:39,568", "timestamp_s": 399.0}, {"text": "on I o metrics, then of course we\u0027re not going to scale correctly.", "timestamp": "00:06:43,472", "timestamp_s": 403.0}, {"text": "Let\u0027s take a look at a few use cases. In this case, we chose", "timestamp": "00:06:47,194", "timestamp_s": 407.0}, {"text": "to scale based on cpu, but it\u0027s an I O bound workload.", "timestamp": "00:06:50,698", "timestamp_s": 410.0}, {"text": "Now, because it\u0027s an I O bound workload, our system sits", "timestamp": "00:06:54,490", "timestamp_s": 414.0}, {"text": "mostly idle as we\u0027re waiting for our external data store.", "timestamp": "00:06:58,398", "timestamp_s": 418.0}, {"text": "Now in this case, because we\u0027re waiting for our external data store,", "timestamp": "00:07:01,544", "timestamp_s": 421.0}, {"text": "and well, our machine is idle, the cpu is low,", "timestamp": "00:07:04,808", "timestamp_s": 424.0}, {"text": "and our system never discovers that our system is under load. So we\u0027re", "timestamp": "00:07:08,828", "timestamp_s": 428.0}, {"text": "never going to scale up beyond the minimum number of pods.", "timestamp": "00:07:12,578", "timestamp_s": 432.0}, {"text": "Similarly, maybe we\u0027re autoscaling based on an I O bound workload,", "timestamp": "00:07:16,010", "timestamp_s": 436.0}, {"text": "so we\u0027re scaling based on concurrent requests.", "timestamp": "00:07:19,926", "timestamp_s": 439.0}, {"text": "And perhaps our application framework limits the number of", "timestamp": "00:07:23,070", "timestamp_s": 443.0}, {"text": "concurrent requests, putting back pressure on our load balancer to queue", "timestamp": "00:07:26,448", "timestamp_s": 446.0}, {"text": "the incoming requests. And so we only have a certain number", "timestamp": "00:07:30,038", "timestamp_s": 450.0}, {"text": "of concurrent requests. So we\u0027ll never scale beyond our", "timestamp": "00:07:33,812", "timestamp_s": 453.0}, {"text": "normal thing. We\u0027ll never scale beyond", "timestamp": "00:07:37,332", "timestamp_s": 457.0}, {"text": "our minimum because Kubernetes doesn\u0027t", "timestamp": "00:07:40,938", "timestamp_s": 460.0}, {"text": "know that our system is under load, we\u0027ve chosen the wrong metric.", "timestamp": "00:07:44,014", "timestamp_s": 464.0}, {"text": "Let\u0027s look at a third use case here. We\u0027ve chosen", "timestamp": "00:07:48,550", "timestamp_s": 468.0}, {"text": "to scale based on our service bus", "timestamp": "00:07:52,718", "timestamp_s": 472.0}, {"text": "queue length. So if there are messages in our", "timestamp": "00:07:56,632", "timestamp_s": 476.0}, {"text": "queue, we\u0027re going to scale up additional pods to be able to handle those messages.", "timestamp": "00:07:59,948", "timestamp_s": 479.0}, {"text": "Perhaps each message sends an email and then when the", "timestamp": "00:08:03,970", "timestamp_s": 483.0}, {"text": "queue length is short, then we\u0027ll scale back down", "timestamp": "00:08:07,452", "timestamp_s": 487.0}, {"text": "so that we\u0027re not using extra resources. In this case we matched", "timestamp": "00:08:10,896", "timestamp_s": 490.0}, {"text": "our metric with our business concerns and so", "timestamp": "00:08:14,822", "timestamp_s": 494.0}, {"text": "we\u0027re able to scale appropriately.", "timestamp": "00:08:17,888", "timestamp_s": 497.0}, {"text": "Now in each of these scenarios we looked at mechanisms where we", "timestamp": "00:08:21,070", "timestamp_s": 501.0}, {"text": "could choose a metric to scale and in many of the instances we chose", "timestamp": "00:08:24,628", "timestamp_s": 504.0}, {"text": "the wrong metric. Not to say that those metrics aren\u0027t good for scaling,", "timestamp": "00:08:28,378", "timestamp_s": 508.0}, {"text": "but that in those scenarios that\u0027s not how that application works.", "timestamp": "00:08:32,090", "timestamp_s": 512.0}, {"text": "Now this is definitely not an exhaustive list, but as you look at scaling", "timestamp": "00:08:35,924", "timestamp_s": 515.0}, {"text": "you might look to these and other metrics to understand the health of", "timestamp": "00:08:39,806", "timestamp_s": 519.0}, {"text": "your system and what your system looks like under load.", "timestamp": "00:08:43,208", "timestamp_s": 523.0}, {"text": "So let\u0027s take a look at the Kubernetes autoscaler and in particular", "timestamp": "00:08:47,770", "timestamp_s": 527.0}, {"text": "let\u0027s look at built in metrics.", "timestamp": "00:08:51,356", "timestamp_s": 531.0}, {"text": "Our first step in enabling the Kubernetes", "timestamp": "00:08:54,650", "timestamp_s": 534.0}, {"text": "autoscale is to enable the metric server. The metric server captures", "timestamp": "00:08:57,922", "timestamp_s": 537.0}, {"text": "cpu and memory on all of our pods and", "timestamp": "00:09:02,006", "timestamp_s": 542.0}, {"text": "presents that to horizontal autoscale. So let\u0027s turn on the", "timestamp": "00:09:05,312", "timestamp_s": 545.0}, {"text": "metric server first. Is it on? Let\u0027s do a", "timestamp": "00:09:08,688", "timestamp_s": 548.0}, {"text": "kubectl top for our pods and in this case across", "timestamp": "00:09:11,984", "timestamp_s": 551.0}, {"text": "all namespaces and see if it errors. If it errors, we need to turn it", "timestamp": "00:09:15,396", "timestamp_s": 555.0}, {"text": "on. So let\u0027s head off to the metric server part of the Kubernetes", "timestamp": "00:09:19,108", "timestamp_s": 559.0}, {"text": "project. Go grab the latest release and apply components.", "timestamp": "00:09:22,346", "timestamp_s": 562.0}, {"text": "Yaml in our case we\u0027re using minicube, so I just enabled the add", "timestamp": "00:09:25,706", "timestamp_s": 565.0}, {"text": "on to enable the metric server. Now that we\u0027ve got the metric server", "timestamp": "00:09:29,432", "timestamp_s": 569.0}, {"text": "enabled, let\u0027s deploy our workload. Now we do need to customize", "timestamp": "00:09:33,582", "timestamp_s": 573.0}, {"text": "our workload ever so slightly to ensure that the autoscale will behave", "timestamp": "00:09:37,282", "timestamp_s": 577.0}, {"text": "as expected. We need to have a resource that knows", "timestamp": "00:09:41,122", "timestamp_s": 581.0}, {"text": "how to build pods. So a deployment,", "timestamp": "00:09:44,802", "timestamp_s": 584.0}, {"text": "a stateful set or a daemon set. In this", "timestamp": "00:09:47,698", "timestamp_s": 587.0}, {"text": "case we now have a recipe, a template of how to build pods and", "timestamp": "00:09:51,084", "timestamp_s": 591.0}, {"text": "we can scale out as we need to in", "timestamp": "00:09:54,608", "timestamp_s": 594.0}, {"text": "our pod definition. We also need to set resource limits.", "timestamp": "00:09:57,968", "timestamp_s": 597.0}, {"text": "Kubernetes is going to look to these resource limits to know how much", "timestamp": "00:10:01,382", "timestamp_s": 601.0}, {"text": "capacity we have left in that pod before it needs to create another", "timestamp": "00:10:05,076", "timestamp_s": 605.0}, {"text": "similar. We need to remove the replica count in", "timestamp": "00:10:08,932", "timestamp_s": 608.0}, {"text": "our deployment. The replica count is going to be controlled by the", "timestamp": "00:10:12,068", "timestamp_s": 612.0}, {"text": "autoscaler, not by the deployment anymore.", "timestamp": "00:10:15,688", "timestamp_s": 615.0}, {"text": "So here\u0027s our deployment. Or maybe it\u0027s a stateful set or daemon set.", "timestamp": "00:10:18,870", "timestamp_s": 618.0}, {"text": "You notice that we\u0027ve commented out the replicas. This shouldn\u0027t be here because", "timestamp": "00:10:22,568", "timestamp_s": 622.0}, {"text": "the autoscaler will do it. We\u0027ve also set limits so that we know how", "timestamp": "00:10:26,232", "timestamp_s": 626.0}, {"text": "much it is. So if we\u0027re using 100%", "timestamp": "00:10:29,868", "timestamp_s": 629.0}, {"text": "of the capacity of this pod, that means we\u0027re using half a cpu.", "timestamp": "00:10:33,484", "timestamp_s": 633.0}, {"text": "For using more than half a cpu, we\u0027re using more than 100% of this", "timestamp": "00:10:37,426", "timestamp_s": 637.0}, {"text": "pod. And if we\u0027re using a quarter of the cpu, we\u0027re using half the capacity", "timestamp": "00:10:41,472", "timestamp_s": 641.0}, {"text": "for this pod. Next up, let\u0027s build the autoscaler.", "timestamp": "00:10:45,462", "timestamp_s": 645.0}, {"text": "Now the autoscaler is going to go grab that metric and", "timestamp": "00:10:49,510", "timestamp_s": 649.0}, {"text": "understand across all of the pods if we need to,", "timestamp": "00:10:53,376", "timestamp_s": 653.0}, {"text": "then increase the pods to get that average down, or decrease", "timestamp": "00:10:57,060", "timestamp_s": 657.0}, {"text": "the count of pods to get that average up.", "timestamp": "00:11:00,602", "timestamp_s": 660.0}, {"text": "A horizontal autoscaler now it\u0027s going to go check these metrics", "timestamp": "00:11:04,290", "timestamp_s": 664.0}, {"text": "every 15 seconds. And once it notices that it needs to make a", "timestamp": "00:11:07,902", "timestamp_s": 667.0}, {"text": "change, then it\u0027ll make that change, but then it won\u0027t make additional changes", "timestamp": "00:11:11,688", "timestamp_s": 671.0}, {"text": "for five minutes. Now we can definitely customize these defaults,", "timestamp": "00:11:15,544", "timestamp_s": 675.0}, {"text": "but these defaults help us to not overly burden our", "timestamp": "00:11:19,410", "timestamp_s": 679.0}, {"text": "system and to reach consensus once we\u0027ve made a scaling", "timestamp": "00:11:23,052", "timestamp_s": 683.0}, {"text": "change. Maybe we need to populate the cache or adjust", "timestamp": "00:11:26,898", "timestamp_s": 686.0}, {"text": "our content across all of our available nodes", "timestamp": "00:11:31,030", "timestamp_s": 691.0}, {"text": "now. And that may take some time. So once we\u0027ve reached stasis", "timestamp": "00:11:34,598", "timestamp_s": 694.0}, {"text": "now, we can make additional scaling decisions.", "timestamp": "00:11:38,790", "timestamp_s": 698.0}, {"text": "So let\u0027s create a horizontal autoscaler. Now here with this Kubectl", "timestamp": "00:11:42,370", "timestamp_s": 702.0}, {"text": "command, we can just quickly identify the deployment that it\u0027s cpu", "timestamp": "00:11:46,362", "timestamp_s": 706.0}, {"text": "bound, the target percentage, in this case 50%. And the minimum and", "timestamp": "00:11:50,362", "timestamp_s": 710.0}, {"text": "maximum number of pods we should create. Now 50% probably", "timestamp": "00:11:54,132", "timestamp_s": 714.0}, {"text": "isn\u0027t a good metric. We probably should run more like 80 or 90%,", "timestamp": "00:11:57,992", "timestamp_s": 717.0}, {"text": "but this is a good demo. We could also deploy", "timestamp": "00:12:01,528", "timestamp_s": 721.0}, {"text": "this as a Kubernetes YamL file.", "timestamp": "00:12:05,278", "timestamp_s": 725.0}, {"text": "Now we\u0027ve identified the deployment that we want to target", "timestamp": "00:12:09,050", "timestamp_s": 729.0}, {"text": "and it is a deployment. We\u0027ve specified the min and max replicas,", "timestamp": "00:12:12,626", "timestamp_s": 732.0}, {"text": "so we\u0027ll have between one and four pods. And we\u0027ve identified the", "timestamp": "00:12:16,370", "timestamp_s": 736.0}, {"text": "type of thing that we want to do. In this case, it\u0027s a resource.", "timestamp": "00:12:20,012", "timestamp_s": 740.0}, {"text": "It\u0027s cpu or memory. We\u0027ve chosen cpu and we", "timestamp": "00:12:22,902", "timestamp_s": 742.0}, {"text": "say that we have a utilization an average of 50%. Now 50%", "timestamp": "00:12:26,112", "timestamp_s": 746.0}, {"text": "is probably low, maybe we want to go 80%. But this is the percent", "timestamp": "00:12:30,336", "timestamp_s": 750.0}, {"text": "of the details in our deployment. So here in", "timestamp": "00:12:34,884", "timestamp_s": 754.0}, {"text": "our deployment we have 0.5 cpu. So 50%", "timestamp": "00:12:38,308", "timestamp_s": 758.0}, {"text": "of our 0.5 cpu would be a quarter of a", "timestamp": "00:12:42,180", "timestamp_s": 762.0}, {"text": "cpu. If we go over a quarter of a cpu, it sounds", "timestamp": "00:12:45,300", "timestamp_s": 765.0}, {"text": "like we need more pods. We go under a quarter of a cpu,", "timestamp": "00:12:48,792", "timestamp_s": 768.0}, {"text": "we\u0027ll need less pods.", "timestamp": "00:12:51,854", "timestamp_s": 771.0}, {"text": "So let\u0027s do this demo. We have", "timestamp": "00:12:55,130", "timestamp_s": 775.0}, {"text": "here a deployment that we will", "timestamp": "00:12:58,316", "timestamp_s": 778.0}, {"text": "build out. Now this references a pod that is", "timestamp": "00:13:01,756", "timestamp_s": 781.0}, {"text": "just a basic exprs server. It has a single", "timestamp": "00:13:05,420", "timestamp_s": 785.0}, {"text": "route that will allow us to just grab text. Notice that we\u0027ve set", "timestamp": "00:13:08,716", "timestamp_s": 788.0}, {"text": "our resource limits so that we can auto scale based on those limits.", "timestamp": "00:13:12,272", "timestamp_s": 792.0}, {"text": "And we\u0027ve chosen just the cpu. Now we", "timestamp": "00:13:15,798", "timestamp_s": 795.0}, {"text": "could specify other limits if we want, but we want to make sure that we", "timestamp": "00:13:19,072", "timestamp_s": 799.0}, {"text": "horizontally autoscale based only on a single metric.", "timestamp": "00:13:22,304", "timestamp_s": 802.0}, {"text": "We\u0027ve also commented out the replicas. We don\u0027t want our deployment", "timestamp": "00:13:25,690", "timestamp_s": 805.0}, {"text": "to specify the count, we want our autoscale to specify it.", "timestamp": "00:13:29,322", "timestamp_s": 809.0}, {"text": "So here\u0027s our autoscale and we can see that it", "timestamp": "00:13:33,060", "timestamp_s": 813.0}, {"text": "scales based on a deployment. This is the deployment name", "timestamp": "00:13:37,190", "timestamp_s": 817.0}, {"text": "and we scaled based on our cpu.", "timestamp": "00:13:41,016", "timestamp_s": 821.0}, {"text": "And in this case, because it\u0027s a very small application,", "timestamp": "00:13:44,910", "timestamp_s": 824.0}, {"text": "we\u0027re going to only scale on 5% of that half a cpu.", "timestamp": "00:13:47,884", "timestamp_s": 827.0}, {"text": "So first stop is to make sure that our metric server is enabled.", "timestamp": "00:13:52,250", "timestamp_s": 832.0}, {"text": "Let\u0027s do cubectl top pod", "timestamp": "00:13:56,178", "timestamp_s": 836.0}, {"text": "and let\u0027s look in all namespaces. And it looks like yes, in this case", "timestamp": "00:14:00,386", "timestamp_s": 840.0}, {"text": "our metric server is enabled. We get the cpu and memory for", "timestamp": "00:14:03,936", "timestamp_s": 843.0}, {"text": "all of our pods whether we\u0027re using a horizontal autoscale or", "timestamp": "00:14:07,776", "timestamp_s": 847.0}, {"text": "not. Great. Cubectl apply F", "timestamp": "00:14:10,864", "timestamp_s": 850.0}, {"text": "cpu deploy. We\u0027ve got our deployment in place", "timestamp": "00:14:15,890", "timestamp_s": 855.0}, {"text": "and let\u0027s also grab our horizontal autoscaler.", "timestamp": "00:14:20,324", "timestamp_s": 860.0}, {"text": "Now when we first spin", "timestamp": "00:14:25,510", "timestamp_s": 865.0}, {"text": "up our horizontal autoscaler our value will be unknown.", "timestamp": "00:14:29,598", "timestamp_s": 869.0}, {"text": "It takes 15 seconds for us to do a lap to go ask the", "timestamp": "00:14:33,374", "timestamp_s": 873.0}, {"text": "pods what their resources are. And so for those 15 seconds we", "timestamp": "00:14:37,032", "timestamp_s": 877.0}, {"text": "don\u0027t know if we need to do anything. So let\u0027s take a look.", "timestamp": "00:14:41,148", "timestamp_s": 881.0}, {"text": "Oh it looks like we have 31%. So it\u0027s going to go create a", "timestamp": "00:14:44,956", "timestamp_s": 884.0}, {"text": "whole bunch of pods to match that capacity.", "timestamp": "00:14:48,464", "timestamp_s": 888.0}, {"text": "Now I\u0027m surprised that it got to 31% straight away. Let\u0027s change", "timestamp": "00:14:51,526", "timestamp_s": 891.0}, {"text": "this metric then to be 25%", "timestamp": "00:14:55,984", "timestamp_s": 895.0}, {"text": "and apply this again.", "timestamp": "00:15:01,060", "timestamp_s": 901.0}, {"text": "Now we probably have to deploy our", "timestamp": "00:15:07,490", "timestamp_s": 907.0}, {"text": "horizontal auto scaler again.", "timestamp": "00:15:11,508", "timestamp_s": 911.0}, {"text": "Yes. So now we should only need two pods. Now we", "timestamp": "00:15:15,670", "timestamp_s": 915.0}, {"text": "were in that spot where we were automatically checking.", "timestamp": "00:15:19,272", "timestamp_s": 919.0}, {"text": "We\u0027re in that spot where we\u0027ve made an adjustment. And so now", "timestamp": "00:15:22,750", "timestamp_s": 922.0}, {"text": "it\u0027ll take a while for this to calm down, but let\u0027s", "timestamp": "00:15:26,072", "timestamp_s": 926.0}, {"text": "generate some load on our system and see if that changes things. So in", "timestamp": "00:15:30,162", "timestamp_s": 930.0}, {"text": "this case I have a busy box thing where I\u0027m just curling into", "timestamp": "00:15:33,868", "timestamp_s": 933.0}, {"text": "that app and so it\u0027s", "timestamp": "00:15:38,156", "timestamp_s": 938.0}, {"text": "returning. Hello world. And we\u0027ll do that a whole bunch of times.", "timestamp": "00:15:41,250", "timestamp_s": 941.0}, {"text": "So now that we\u0027ve got some load on the system, let\u0027s take a look at", "timestamp": "00:15:45,710", "timestamp_s": 945.0}, {"text": "our autoscale. And it looks like we\u0027re down to zero. So now", "timestamp": "00:15:48,848", "timestamp_s": 948.0}, {"text": "we\u0027ve scaled down a whole lot. Now let\u0027s take a", "timestamp": "00:15:52,228", "timestamp_s": 952.0}, {"text": "look at our Autoscale and", "timestamp": "00:15:56,068", "timestamp_s": 956.0}, {"text": "we\u0027ll watch it and we\u0027ll see if we capture some change in", "timestamp": "00:15:59,652", "timestamp_s": 959.0}, {"text": "metrics now that we\u0027ve added some load to it.", "timestamp": "00:16:03,316", "timestamp_s": 963.0}, {"text": "Now, it does run every 15 seconds, so we will have to wait", "timestamp": "00:16:07,670", "timestamp_s": 967.0}, {"text": "a little bit to see if this metric changes.", "timestamp": "00:16:11,576", "timestamp_s": 971.0}, {"text": "But once it changes, then we can recalculate the number of pods", "timestamp": "00:16:14,630", "timestamp_s": 974.0}, {"text": "that we need. Now we can adjust the 15 seconds.", "timestamp": "00:16:18,978", "timestamp_s": 978.0}, {"text": "We can make it more aggressive, so maybe 10", "timestamp": "00:16:23,138", "timestamp_s": 983.0}, {"text": "seconds or sooner to be able to look at our pods more aggressively.", "timestamp": "00:16:26,972", "timestamp_s": 986.0}, {"text": "Or we can specify it much more,", "timestamp": "00:16:31,350", "timestamp_s": 991.0}, {"text": "much larger so that we put less load on our pods", "timestamp": "00:16:35,070", "timestamp_s": 995.0}, {"text": "because, well, it needs to go look. Okay, so now we\u0027ve gotten up", "timestamp": "00:16:38,438", "timestamp_s": 998.0}, {"text": "to 24%. So now based on our 24%,", "timestamp": "00:16:41,888", "timestamp_s": 1001.0}, {"text": "let\u0027s see if we need additional pods. No, it looks like we don\u0027t.", "timestamp": "00:16:45,348", "timestamp_s": 1005.0}, {"text": "So I\u0027m going to specify this back at 10%", "timestamp": "00:16:48,874", "timestamp_s": 1008.0}, {"text": "and let\u0027s deploy our autoscale.", "timestamp": "00:16:53,044", "timestamp_s": 1013.0}, {"text": "And now based on 24%,", "timestamp": "00:16:59,190", "timestamp_s": 1019.0}, {"text": "then it will spin up a whole lot of pods. Great. We saw how we", "timestamp": "00:17:03,400", "timestamp_s": 1023.0}, {"text": "could spin up pods and spin down pods based", "timestamp": "00:17:07,228", "timestamp_s": 1027.0}, {"text": "on the needs of our system. Cubectl,", "timestamp": "00:17:10,636", "timestamp_s": 1030.0}, {"text": "delete F cpu.", "timestamp": "00:17:13,650", "timestamp_s": 1033.0}, {"text": "Let\u0027s delete our deployment. Let\u0027s also delete our", "timestamp": "00:17:19,390", "timestamp_s": 1039.0}, {"text": "autoscale.", "timestamp": "00:17:23,280", "timestamp_s": 1043.0}, {"text": "And now we can see that those are done. Oh, we\u0027re still", "timestamp": "00:17:28,030", "timestamp_s": 1048.0}, {"text": "generating a load. Let\u0027s undo that.", "timestamp": "00:17:31,572", "timestamp_s": 1051.0}, {"text": "Now. If we do kubectl top pod,", "timestamp": "00:17:36,530", "timestamp_s": 1056.0}, {"text": "we can see that we\u0027re still collecting metrics even though there\u0027s no horizontal", "timestamp": "00:17:42,050", "timestamp_s": 1062.0}, {"text": "autoscale using those metrics. That\u0027s fine, it\u0027s nice data", "timestamp": "00:17:45,998", "timestamp_s": 1065.0}, {"text": "to have, but the metric server is still running great.", "timestamp": "00:17:50,056", "timestamp_s": 1070.0}, {"text": "So we got to see the horizontal autoscale,", "timestamp": "00:17:55,400", "timestamp_s": 1075.0}, {"text": "we got to scale based on a cpu metric. And that was great.", "timestamp": "00:17:58,766", "timestamp_s": 1078.0}, {"text": "Let\u0027s take a look at other metrics that we might want to choose. Now,", "timestamp": "00:18:02,316", "timestamp_s": 1082.0}, {"text": "as we looked at this, here\u0027s kind of our mental model. Our horizontal", "timestamp": "00:18:05,868", "timestamp_s": 1085.0}, {"text": "pod autoscaler goes and checks the application", "timestamp": "00:18:09,398", "timestamp_s": 1089.0}, {"text": "every 15 seconds to see if data needs adjusting.", "timestamp": "00:18:13,056", "timestamp_s": 1093.0}, {"text": "Now, that\u0027s a little bit of a naive interpretation", "timestamp": "00:18:17,126", "timestamp_s": 1097.0}, {"text": "because, well, we have our metric server here. I love these", "timestamp": "00:18:20,534", "timestamp_s": 1100.0}, {"text": "graphics. Grab these slides from robridge.org and click through", "timestamp": "00:18:24,132", "timestamp_s": 1104.0}, {"text": "to the learnks IO page.", "timestamp": "00:18:27,716", "timestamp_s": 1107.0}, {"text": "It\u0027s a great tutorial. Now, this too is", "timestamp": "00:18:30,868", "timestamp_s": 1110.0}, {"text": "a little bit naive because inside the metrics server we actually have", "timestamp": "00:18:34,296", "timestamp_s": 1114.0}, {"text": "three different APIs we have resource metrics,", "timestamp": "00:18:38,568", "timestamp_s": 1118.0}, {"text": "APIs, we have custom metrics and we have external", "timestamp": "00:18:42,318", "timestamp_s": 1122.0}, {"text": "metrics. Now, zooming in on each of those, the resource metrics", "timestamp": "00:18:45,502", "timestamp_s": 1125.0}, {"text": "is about cpu and memory. Those are the two built in custom", "timestamp": "00:18:49,778", "timestamp_s": 1129.0}, {"text": "metrics. We might look to our pods to be able to find other", "timestamp": "00:18:53,980", "timestamp_s": 1133.0}, {"text": "details, any details that we can get out of those pods would", "timestamp": "00:18:57,196", "timestamp_s": 1137.0}, {"text": "work nicely here. In the custom metrics API, maybe we\u0027ll harvest", "timestamp": "00:19:01,040", "timestamp_s": 1141.0}, {"text": "Prometheus metrics for example, and then external metrics.", "timestamp": "00:19:04,518", "timestamp_s": 1144.0}, {"text": "Maybe we\u0027re looking at a requests queue length or a", "timestamp": "00:19:08,390", "timestamp_s": 1148.0}, {"text": "message queue length and taking actions based on", "timestamp": "00:19:12,100", "timestamp_s": 1152.0}, {"text": "resources that are external to our pods, maybe other Kubernetes", "timestamp": "00:19:15,636", "timestamp_s": 1155.0}, {"text": "resources, maybe other cloud resources, other hardware within our environment.", "timestamp": "00:19:19,466", "timestamp_s": 1159.0}, {"text": "We can look to that to make external decisions about how many pods", "timestamp": "00:19:23,674", "timestamp_s": 1163.0}, {"text": "we need. So we have these three APIs", "timestamp": "00:19:27,438", "timestamp_s": 1167.0}, {"text": "and each of them will reach out to an adapter that will reach out", "timestamp": "00:19:31,630", "timestamp_s": 1171.0}, {"text": "to a service to get data. So for example,", "timestamp": "00:19:35,432", "timestamp_s": 1175.0}, {"text": "in the metrics API we reach out to the metrics server.", "timestamp": "00:19:38,492", "timestamp_s": 1178.0}, {"text": "The metrics server in turn looks to see Advisor and C", "timestamp": "00:19:41,874", "timestamp_s": 1181.0}, {"text": "advisor will harvest those metrics from our pods.", "timestamp": "00:19:45,372", "timestamp_s": 1185.0}, {"text": "In our custom metrics API. Perhaps we\u0027re using the Prometheus adapter.", "timestamp": "00:19:48,786", "timestamp_s": 1188.0}, {"text": "The Prometheus adapter looks to Prometheus and Prometheus", "timestamp": "00:19:52,614", "timestamp_s": 1192.0}, {"text": "looks to all of our pods. When we\u0027re looking at external things,", "timestamp": "00:19:56,086", "timestamp_s": 1196.0}, {"text": "maybe we\u0027re using Prometheus to monitor those as well. Or maybe", "timestamp": "00:19:59,760", "timestamp_s": 1199.0}, {"text": "we\u0027re using another adapter. So we", "timestamp": "00:20:02,996", "timestamp_s": 1202.0}, {"text": "have the autoscaling in really interesting ways.", "timestamp": "00:20:07,092", "timestamp_s": 1207.0}, {"text": "Let\u0027s take a look at how we might use that with Prometheus.", "timestamp": "00:20:10,436", "timestamp_s": 1210.0}, {"text": "So our first stop is to install the metrics server. We did", "timestamp": "00:20:14,050", "timestamp_s": 1214.0}, {"text": "this previously and even though we\u0027re not using the metrics coming out of the metrics", "timestamp": "00:20:17,432", "timestamp_s": 1217.0}, {"text": "server, this gets us the metrics APIs as well.", "timestamp": "00:20:21,294", "timestamp_s": 1221.0}, {"text": "Then we need to install Prometheus. Now I\u0027m grabbing Prometheus", "timestamp": "00:20:24,970", "timestamp_s": 1224.0}, {"text": "from the Prometheus helm chart.", "timestamp": "00:20:28,962", "timestamp_s": 1228.0}, {"text": "The Prometheus community Prometheus helm chart installs", "timestamp": "00:20:33,210", "timestamp_s": 1233.0}, {"text": "just Prometheus. But if I chose the Prometheus stack, I would also", "timestamp": "00:20:36,978", "timestamp_s": 1236.0}, {"text": "get Grafana. Now I could choose to put this in a", "timestamp": "00:20:40,508", "timestamp_s": 1240.0}, {"text": "different namespace. That would probably be a good best practice, but for the", "timestamp": "00:20:44,128", "timestamp_s": 1244.0}, {"text": "sake of today\u0027s demo, I\u0027ll just put it in the default namespace.", "timestamp": "00:20:47,408", "timestamp_s": 1247.0}, {"text": "Next up, I\u0027m going to install the Metrics adapter. Now I\u0027m going to pull this", "timestamp": "00:20:51,654", "timestamp_s": 1251.0}, {"text": "from Prometheus community helm charts as well. And so", "timestamp": "00:20:55,444", "timestamp_s": 1255.0}, {"text": "then I\u0027ll install this Prometheus adapter. I am going to", "timestamp": "00:20:59,156", "timestamp_s": 1259.0}, {"text": "set some properties here. I could do this with a yaml file or", "timestamp": "00:21:02,596", "timestamp_s": 1262.0}, {"text": "here, I\u0027ll just set them straight away. I\u0027m going to point it at the prometheus", "timestamp": "00:21:06,680", "timestamp_s": 1266.0}, {"text": "URL. The Prometheus helm chart creates a prometheus service", "timestamp": "00:21:10,302", "timestamp_s": 1270.0}, {"text": "called Prometheus service and it\u0027s on port 80 instead", "timestamp": "00:21:14,376", "timestamp_s": 1274.0}, {"text": "of 90 90 as it typically is.", "timestamp": "00:21:17,836", "timestamp_s": 1277.0}, {"text": "So I\u0027ll configure it to point to my Prometheus service.", "timestamp": "00:21:21,148", "timestamp_s": 1281.0}, {"text": "And now I\u0027ve got the Prometheus adapter running.", "timestamp": "00:21:24,348", "timestamp_s": 1284.0}, {"text": "Now I\u0027m going to configure my workload. Now I could configure", "timestamp": "00:21:27,930", "timestamp_s": 1287.0}, {"text": "Prometheus to point it at where my workload is and configure", "timestamp": "00:21:31,302", "timestamp_s": 1291.0}, {"text": "it that way, but because it\u0027s all running in my cluster, I can create", "timestamp": "00:21:35,238", "timestamp_s": 1295.0}, {"text": "an annotation on that deployment that will allow Prometheus", "timestamp": "00:21:38,736", "timestamp_s": 1298.0}, {"text": "to automatically discover it. So here in my deployment,", "timestamp": "00:21:42,602", "timestamp_s": 1302.0}, {"text": "I\u0027m going to create an annotation on my pod", "timestamp": "00:21:46,458", "timestamp_s": 1306.0}, {"text": "that identifies that. I want Prometheus to scrape", "timestamp": "00:21:50,490", "timestamp_s": 1310.0}, {"text": "the metrics and what\u0027s the URL and port that it should scrape?", "timestamp": "00:21:53,994", "timestamp_s": 1313.0}, {"text": "Now this is perfect. I\u0027ve identified that Prometheus should", "timestamp": "00:21:57,910", "timestamp_s": 1317.0}, {"text": "scrape the metrics out of all of these pods.", "timestamp": "00:22:01,960", "timestamp_s": 1321.0}, {"text": "I turn it on, I give it the URL, and I give it the port.", "timestamp": "00:22:05,294", "timestamp_s": 1325.0}, {"text": "Now it is important that these are quoted because if they aren\u0027t, this would", "timestamp": "00:22:08,936", "timestamp_s": 1328.0}, {"text": "be a boolean and an integer respectively, and they need to be", "timestamp": "00:22:12,588", "timestamp_s": 1332.0}, {"text": "strings to be annotations. So I put quotes around it and", "timestamp": "00:22:16,252", "timestamp_s": 1336.0}, {"text": "it works just fine. Now I\u0027ll deploy my workload kubectl,", "timestamp": "00:22:19,548", "timestamp_s": 1339.0}, {"text": "apply that deployment, and now I\u0027ve got my content. I know that Prometheus", "timestamp": "00:22:23,458", "timestamp_s": 1343.0}, {"text": "is going to monitor that content, make those metrics available to the Prometheus", "timestamp": "00:22:27,558", "timestamp_s": 1347.0}, {"text": "adapter, and now our horizontal autoscale can", "timestamp": "00:22:31,562", "timestamp_s": 1351.0}, {"text": "harvest those metrics to make scaling decisions. So next up,", "timestamp": "00:22:35,716", "timestamp_s": 1355.0}, {"text": "let\u0027s put in the horizontal autoscale. Now I\u0027ve got this horizontal", "timestamp": "00:22:39,556", "timestamp_s": 1359.0}, {"text": "autoscale and in this case it\u0027s going to target a deployment. Here\u0027s the", "timestamp": "00:22:43,162", "timestamp_s": 1363.0}, {"text": "name of my deployment. And rather than resources as", "timestamp": "00:22:46,728", "timestamp_s": 1366.0}, {"text": "we saw previously, this one\u0027s going to scale based on pods. I wish", "timestamp": "00:22:50,328", "timestamp_s": 1370.0}, {"text": "this said prometheus, but it doesn\u0027t.", "timestamp": "00:22:53,918", "timestamp_s": 1373.0}, {"text": "We\u0027ll give it some interesting metric from prometheus that the Prometheus", "timestamp": "00:22:58,114", "timestamp_s": 1378.0}, {"text": "adapter knows how to get and we can give it a value that we", "timestamp": "00:23:01,778", "timestamp_s": 1381.0}, {"text": "want to specify. So if it\u0027s lower than this, then we\u0027ll", "timestamp": "00:23:05,292", "timestamp_s": 1385.0}, {"text": "reduce the number of pods and if it\u0027s above this, then we\u0027ll increase the number", "timestamp": "00:23:09,362", "timestamp_s": 1389.0}, {"text": "of pods. Now, how might we look", "timestamp": "00:23:12,512", "timestamp_s": 1392.0}, {"text": "to other metrics? There are lots of different adapters that we can", "timestamp": "00:23:16,048", "timestamp_s": 1396.0}, {"text": "look at and let\u0027s tour. Come. Here\u0027s a really great project", "timestamp": "00:23:19,408", "timestamp_s": 1399.0}, {"text": "that allows us to create adapters from all kinds of sources.", "timestamp": "00:23:23,348", "timestamp_s": 1403.0}, {"text": "So we could call HTTP into our pods", "timestamp": "00:23:26,922", "timestamp_s": 1406.0}, {"text": "and harvest JSON querying into that JSON", "timestamp": "00:23:30,506", "timestamp_s": 1410.0}, {"text": "to be able to grab a particular metric. There\u0027s also Prometheus collector,", "timestamp": "00:23:33,658", "timestamp_s": 1413.0}, {"text": "although the Prometheus adapter is usually a better choice.", "timestamp": "00:23:37,582", "timestamp_s": 1417.0}, {"text": "We could look at the influxDB collector, which is a great example", "timestamp": "00:23:41,006", "timestamp_s": 1421.0}, {"text": "of how we might query other data stores the AWS collector.", "timestamp": "00:23:44,296", "timestamp_s": 1424.0}, {"text": "So we could look at, for example, sqs queue length. We could use", "timestamp": "00:23:47,822", "timestamp_s": 1427.0}, {"text": "this as a template to grab things from blob storage", "timestamp": "00:23:51,132", "timestamp_s": 1431.0}, {"text": "or GCP. And we can also scale", "timestamp": "00:23:54,930", "timestamp_s": 1434.0}, {"text": "based on a schedule. If we know that our work starts in the morning and", "timestamp": "00:23:58,642", "timestamp_s": 1438.0}, {"text": "ends in the evening, and that we won\u0027t use the cluster overnight, we can create", "timestamp": "00:24:01,932", "timestamp_s": 1441.0}, {"text": "a schedule to automatically scale that up or down. Now, unlike the", "timestamp": "00:24:05,392", "timestamp_s": 1445.0}, {"text": "other metrics that look to behaviors in our cluster, this will just", "timestamp": "00:24:08,784", "timestamp_s": 1448.0}, {"text": "do it on a timer and maybe that\u0027s sufficient.", "timestamp": "00:24:12,228", "timestamp_s": 1452.0}, {"text": "We could also look to istio and grab metrics from", "timestamp": "00:24:16,210", "timestamp_s": 1456.0}, {"text": "istio. There are many other adapters that will allow", "timestamp": "00:24:19,748", "timestamp_s": 1459.0}, {"text": "us to query other systems to be able to get metrics", "timestamp": "00:24:23,076", "timestamp_s": 1463.0}, {"text": "both for pods and for external resources where we can make", "timestamp": "00:24:26,702", "timestamp_s": 1466.0}, {"text": "choices about how to scale. We took a look", "timestamp": "00:24:30,456", "timestamp_s": 1470.0}, {"text": "at built in sources for cpu and memory. Now those are", "timestamp": "00:24:34,376", "timestamp_s": 1474.0}, {"text": "definitely the easiest, but if our workload isn\u0027t based on cpu", "timestamp": "00:24:38,008", "timestamp_s": 1478.0}, {"text": "and memory, if it\u0027s based on another metric, perhaps we can look to", "timestamp": "00:24:41,298", "timestamp_s": 1481.0}, {"text": "Prometheus to be able to find metrics specific for our application.", "timestamp": "00:24:44,412", "timestamp_s": 1484.0}, {"text": "Anything that we can expose as a Prometheus metric we can", "timestamp": "00:24:48,810", "timestamp_s": 1488.0}, {"text": "then use to auto scale our service.", "timestamp": "00:24:52,128", "timestamp_s": 1492.0}, {"text": "Similarly, we could look to external metrics.", "timestamp": "00:24:54,830", "timestamp_s": 1494.0}, {"text": "Perhaps we\u0027re looking at our load balancer or our queue length", "timestamp": "00:24:57,974", "timestamp_s": 1497.0}, {"text": "and making decisions on how many pods we need. Based on that,", "timestamp": "00:25:02,006", "timestamp_s": 1502.0}, {"text": "let\u0027s take a look at some best practices. Now, these best practices will", "timestamp": "00:25:07,010", "timestamp_s": 1507.0}, {"text": "help us to make good scaling decisions.", "timestamp": "00:25:10,708", "timestamp_s": 1510.0}, {"text": "What if we scale up too high? Maybe we\u0027re getting", "timestamp": "00:25:14,290", "timestamp_s": 1514.0}, {"text": "attacked. Maybe we have a bug in our software,", "timestamp": "00:25:18,470", "timestamp_s": 1518.0}, {"text": "or maybe we\u0027ve just gone viral and we need to be able to scale up", "timestamp": "00:25:21,774", "timestamp_s": 1521.0}, {"text": "to impossible scale. We probably don\u0027t want to scale infinitely", "timestamp": "00:25:25,272", "timestamp_s": 1525.0}, {"text": "because, well, especially in the case of an attack, we don\u0027t want that big", "timestamp": "00:25:29,698", "timestamp_s": 1529.0}, {"text": "cloud bill. It would be really easy for us to stay", "timestamp": "00:25:33,596", "timestamp_s": 1533.0}, {"text": "scaled for the duration of the attack and end up paying a lot.", "timestamp": "00:25:37,292", "timestamp_s": 1537.0}, {"text": "So let\u0027s create a max value that matches the", "timestamp": "00:25:41,376", "timestamp_s": 1541.0}, {"text": "budget of our organization and lets us determine that.", "timestamp": "00:25:44,688", "timestamp_s": 1544.0}, {"text": "Well, we\u0027re going to understand that our system may not", "timestamp": "00:25:48,128", "timestamp_s": 1548.0}, {"text": "be able to reach that capacity, but it\u0027ll reach our budgetary goals.", "timestamp": "00:25:51,568", "timestamp_s": 1551.0}, {"text": "If it\u0027s an attack, we\u0027re not paying extra to handle that attack.", "timestamp": "00:25:55,466", "timestamp_s": 1555.0}, {"text": "Or if we\u0027ve gone viral, maybe we need to reconsider that upper bound.", "timestamp": "00:25:58,964", "timestamp_s": 1558.0}, {"text": "The other reason we might scale up too high is maybe we\u0027re", "timestamp": "00:26:03,650", "timestamp_s": 1563.0}, {"text": "monitoring more than one metric. Now, Kubernetes is going", "timestamp": "00:26:07,038", "timestamp_s": 1567.0}, {"text": "to do the right thing here. If we\u0027re monitoring two metrics and one", "timestamp": "00:26:10,264", "timestamp_s": 1570.0}, {"text": "is high and one is low, Kubernetes will use the high metric", "timestamp": "00:26:13,608", "timestamp_s": 1573.0}, {"text": "to be able to reach the capacity to make sure that all the", "timestamp": "00:26:17,186", "timestamp_s": 1577.0}, {"text": "metrics are within bounds. But for example, if we\u0027re monitoring", "timestamp": "00:26:20,588", "timestamp_s": 1580.0}, {"text": "both cpu and memory, and the cpu is low,", "timestamp": "00:26:24,578", "timestamp_s": 1584.0}, {"text": "we might say, well, you shouldn\u0027t have scaled up here,", "timestamp": "00:26:28,750", "timestamp_s": 1588.0}, {"text": "but maybe the memory is high and so we did scale up by", "timestamp": "00:26:32,080", "timestamp_s": 1592.0}, {"text": "comparison. So here we need", "timestamp": "00:26:35,952", "timestamp_s": 1595.0}, {"text": "to define the max replicas in addition to", "timestamp": "00:26:39,712", "timestamp_s": 1599.0}, {"text": "the min replicas. Don\u0027t just assume that infinitely high", "timestamp": "00:26:43,028", "timestamp_s": 1603.0}, {"text": "is sufficient. Pick a budget that matches the needs of our organization and", "timestamp": "00:26:46,452", "timestamp_s": 1606.0}, {"text": "understand that our system may be less available if our load", "timestamp": "00:26:50,868", "timestamp_s": 1610.0}, {"text": "exceeds that. But we\u0027re reaching our budget goals, which is the", "timestamp": "00:26:54,282", "timestamp_s": 1614.0}, {"text": "needs of the business. Next up, we may scale too slow.", "timestamp": "00:26:58,008", "timestamp_s": 1618.0}, {"text": "Now, we noted how the horizontal autoscale only checked every 15", "timestamp": "00:27:01,326", "timestamp_s": 1621.0}, {"text": "seconds. That\u0027s definitely a configurable value. And in", "timestamp": "00:27:05,160", "timestamp_s": 1625.0}, {"text": "the case of missing metrics, then Kubernetes will assume the best", "timestamp": "00:27:08,668", "timestamp_s": 1628.0}, {"text": "case scenario. So if we\u0027re scaling out, Kubernetes will", "timestamp": "00:27:12,636", "timestamp_s": 1632.0}, {"text": "assume that that pod is using 0%, therefore it won\u0027t", "timestamp": "00:27:16,108", "timestamp_s": 1636.0}, {"text": "scale out unnecessarily. If we\u0027re scaling in, Kubernetes will", "timestamp": "00:27:20,226", "timestamp_s": 1640.0}, {"text": "assume that that metric was at 100%. Therefore it probably won\u0027t scale", "timestamp": "00:27:24,048", "timestamp_s": 1644.0}, {"text": "in until that metric is available. So if it takes", "timestamp": "00:27:27,702", "timestamp_s": 1647.0}, {"text": "a long time for our pods to be able to surface these metrics,", "timestamp": "00:27:30,832", "timestamp_s": 1650.0}, {"text": "then we may notice that the Kubernetes autoscaler won\u0027t take action.", "timestamp": "00:27:34,410", "timestamp_s": 1654.0}, {"text": "What if when we deploy a new version, it always resets to one pod", "timestamp": "00:27:38,106", "timestamp_s": 1658.0}, {"text": "and then scales back up? Yeah, if we put our", "timestamp": "00:27:42,042", "timestamp_s": 1662.0}, {"text": "HUD coded pod limit, then we might hit a scenario. Well, what happened", "timestamp": "00:27:45,796", "timestamp_s": 1665.0}, {"text": "here? In our deployment or our other service,", "timestamp": "00:27:49,736", "timestamp_s": 1669.0}, {"text": "we had a hard coded replicas count as we deployed", "timestamp": "00:27:53,496", "timestamp_s": 1673.0}, {"text": "the new version of our deployment. Or stateful set or replica", "timestamp": "00:27:57,838", "timestamp_s": 1677.0}, {"text": "set, Kubernetes followed our instructions and killed off all the other", "timestamp": "00:28:01,378", "timestamp_s": 1681.0}, {"text": "pods. So we only ended up with one or maybe a few. Yeah,", "timestamp": "00:28:05,132", "timestamp_s": 1685.0}, {"text": "we really want our autoscale to handle this. So we", "timestamp": "00:28:08,524", "timestamp_s": 1688.0}, {"text": "need to comment out the replicas line in our deployment.", "timestamp": "00:28:12,688", "timestamp_s": 1692.0}, {"text": "We want our horizontal autoscaler to hit this. Now. This does create an edge", "timestamp": "00:28:17,174", "timestamp_s": 1697.0}, {"text": "case where when we deploy it the very, very first time, we\u0027re only going to", "timestamp": "00:28:20,758", "timestamp_s": 1700.0}, {"text": "get one until the autoscaler notices. Well, I\u0027d rather", "timestamp": "00:28:24,084", "timestamp_s": 1704.0}, {"text": "have 15 seconds of only one pod than", "timestamp": "00:28:27,396", "timestamp_s": 1707.0}, {"text": "have it reset to one on every deployment. If you grab these slides", "timestamp": "00:28:31,730", "timestamp_s": 1711.0}, {"text": "from roberts.org and click through to this post, you can find more about", "timestamp": "00:28:35,434", "timestamp_s": 1715.0}, {"text": "that edge case and how to handle it gracefully.", "timestamp": "00:28:38,952", "timestamp_s": 1718.0}, {"text": "Flapping or sloshing? The documentation talks about flapping", "timestamp": "00:28:41,806", "timestamp_s": 1721.0}, {"text": "as if the door keeps opening and closing. I like to talk about sloshing like", "timestamp": "00:28:45,518", "timestamp_s": 1725.0}, {"text": "we\u0027re just pushing the water up against the beach and so the water", "timestamp": "00:28:49,948", "timestamp_s": 1729.0}, {"text": "just keeps going. Let\u0027s assume that we have a Java app that", "timestamp": "00:28:53,660", "timestamp_s": 1733.0}, {"text": "takes a while to spin up. We notice that we don\u0027t have enough capacity,", "timestamp": "00:28:56,972", "timestamp_s": 1736.0}, {"text": "so we spin up some pods. 15 seconds later we notice that those", "timestamp": "00:29:00,290", "timestamp_s": 1740.0}, {"text": "pods aren\u0027t live yet and we choose to decide to scale up again.", "timestamp": "00:29:04,192", "timestamp_s": 1744.0}, {"text": "And so now in a minute, once our Java app is booted and everything is", "timestamp": "00:29:07,888", "timestamp_s": 1747.0}, {"text": "working, we now have too much capacity. So we\u0027ll scale", "timestamp": "00:29:11,792", "timestamp_s": 1751.0}, {"text": "back down. Then we\u0027ll notice we don\u0027t have up scale back up and down and", "timestamp": "00:29:15,098", "timestamp_s": 1755.0}, {"text": "up and on we go, sloshing back and Forth. Well, what happened", "timestamp": "00:29:18,468", "timestamp_s": 1758.0}, {"text": "here? Well, Kubernetes will automatically block additional scaling", "timestamp": "00:29:22,420", "timestamp_s": 1762.0}, {"text": "operations until our system has reached stability.", "timestamp": "00:29:27,998", "timestamp_s": 1767.0}, {"text": "So by default, it\u0027s five minutes. In this case, I added some content", "timestamp": "00:29:31,646", "timestamp_s": 1771.0}, {"text": "to my horizontal autoscaler to set that stabilization", "timestamp": "00:29:35,720", "timestamp_s": 1775.0}, {"text": "window to 60 seconds,", "timestamp": "00:29:39,122", "timestamp_s": 1779.0}, {"text": "600 seconds or ten minutes. So I want to give", "timestamp": "00:29:42,010", "timestamp_s": 1782.0}, {"text": "my time, a little bit of my application, a little bit extra time to get", "timestamp": "00:29:45,532", "timestamp_s": 1785.0}, {"text": "stable. Alternatively, in our demos, we chose to scale", "timestamp": "00:29:48,992", "timestamp_s": 1788.0}, {"text": "it, to set that stabilization window to 1", "timestamp": "00:29:52,822", "timestamp_s": 1792.0}, {"text": "second so that it would automatically make additional scaling things. And that", "timestamp": "00:29:56,272", "timestamp_s": 1796.0}, {"text": "worked out really well for our demo. Scale to zero. Now in", "timestamp": "00:30:00,032", "timestamp_s": 1800.0}, {"text": "our horizontal autoscale, it won\u0027t scale to zero, it\u0027ll only scale to", "timestamp": "00:30:04,292", "timestamp_s": 1804.0}, {"text": "one. And now we\u0027re paying for our application to", "timestamp": "00:30:07,588", "timestamp_s": 1807.0}, {"text": "run even if there\u0027s no load at all. How do we overcome this?", "timestamp": "00:30:10,708", "timestamp_s": 1810.0}, {"text": "Well, the problem is that, well, how do we start the application back", "timestamp": "00:30:14,388", "timestamp_s": 1814.0}, {"text": "up? If a request comes in and there are no deployment,", "timestamp": "00:30:17,992", "timestamp_s": 1817.0}, {"text": "no pods running to handle it, then that request", "timestamp": "00:30:21,694", "timestamp_s": 1821.0}, {"text": "will just fail. So to make this happen, we need a reverse proxy in", "timestamp": "00:30:24,862", "timestamp_s": 1824.0}, {"text": "front of that to be able to handle the load. Notice there\u0027s", "timestamp": "00:30:28,328", "timestamp_s": 1828.0}, {"text": "no pods and kick it back up. Now, it may take a minute for", "timestamp": "00:30:31,538", "timestamp_s": 1831.0}, {"text": "a pod to start on a completely cold start, so maybe that initial request", "timestamp": "00:30:34,956", "timestamp_s": 1834.0}, {"text": "also still fails. But that\u0027s our scale to zero problem. We need", "timestamp": "00:30:38,946", "timestamp_s": 1838.0}, {"text": "a reverse proxy in front of it to be able to notice that our", "timestamp": "00:30:42,528", "timestamp_s": 1842.0}, {"text": "cluster needs turning back on. Now that\u0027s not built in. That\u0027s a", "timestamp": "00:30:46,016", "timestamp_s": 1846.0}, {"text": "problem larger than just horizontal autoscaling between one and", "timestamp": "00:30:49,408", "timestamp_s": 1849.0}, {"text": "a set number. So we might need to reach for external tools.", "timestamp": "00:30:52,768", "timestamp_s": 1852.0}, {"text": "Knative and keta both offer this solution, and so", "timestamp": "00:30:56,778", "timestamp_s": 1856.0}, {"text": "we can reach for one of these products to be able to get to scale", "timestamp": "00:31:00,132", "timestamp_s": 1860.0}, {"text": "to zero. Now, it does mean that we\u0027re going to have some pods running associated", "timestamp": "00:31:03,578", "timestamp_s": 1863.0}, {"text": "with knative and Keda. So if we only have one microservice,", "timestamp": "00:31:07,278", "timestamp_s": 1867.0}, {"text": "maybe just leaving that one microservice running, that might", "timestamp": "00:31:10,878", "timestamp_s": 1870.0}, {"text": "be a simpler solution than a scale to zero solution.", "timestamp": "00:31:14,808", "timestamp_s": 1874.0}, {"text": "We took a look at horizontal autoscaling in Kubernetes and it was really", "timestamp": "00:31:18,482", "timestamp_s": 1878.0}, {"text": "cool. Horizontal autoscaling is about scaling", "timestamp": "00:31:22,396", "timestamp_s": 1882.0}, {"text": "up when we have additional demand and scaling down, paying less", "timestamp": "00:31:25,698", "timestamp_s": 1885.0}, {"text": "when we don\u0027t have demand. This is made possible by utility billing.", "timestamp": "00:31:29,772", "timestamp_s": 1889.0}, {"text": "We can go to a cloud, we can get some resources. When we\u0027re done,", "timestamp": "00:31:33,410", "timestamp_s": 1893.0}, {"text": "we can hand them back and pay. Nothing and the scaling operation can", "timestamp": "00:31:36,812", "timestamp_s": 1896.0}, {"text": "handle can happen in real time. So we don\u0027t need to pre", "timestamp": "00:31:40,148", "timestamp_s": 1900.0}, {"text": "provision our hardware. We don\u0027t need to over buy our systems", "timestamp": "00:31:43,956", "timestamp_s": 1903.0}, {"text": "to reach maximum capacity. We can scale up and down as", "timestamp": "00:31:47,738", "timestamp_s": 1907.0}, {"text": "our needs are.", "timestamp": "00:31:51,028", "timestamp_s": 1911.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'r-tVKhb1W98',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Horizontal Autoscaling with Kubernetes
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Now that the app is running in Kubernetes, how do we scale it to meet demand? What metric should we use? CPU? Requests? something else? Let&rsquo;s dig into why we auto-scale, and how we auto-scale with lots of examples. Finally we&rsquo;ll look at potential pitfalls and gotchas like how to scale to 0 and how to avoid scaling too big for your budget. Come learn how to scale with Kubernetes.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                I get to share with you horizontal auto scaling with Kubernetes. The slides are online right now. AZ Givecamp brings volunteer developers together with charities to build free software. If you're in Phoenix, come join us for the next AZ give camp.

              </li>
              
              <li>
                When we talk about scaling, we can talk about both horizontal autoscaling and vertical scaling. Utility billing with clouds allows us to scale easily and quickly to meet the demand. When the demand eases, then we can give those resources back and stop paying them.

              </li>
              
              <li>
                Today we're going to talk about scaling the workload in kubernetes. It depends a lot on the workload and what metric you're using to measure it. Vertical scaling is about changing resource limits on our pods to match increased demand. horizontal scaling involves increasing the count of pods to meet demand.

              </li>
              
              <li>
                We have a deployment that we will build out. Notice that we've set our resource limits so that we can auto scale based on those limits. Let's generate some load on our system and see if that changes things.

              </li>
              
              <li>
                We have three different APIs we have resource metrics, APIs, we have custom metrics and we have external metrics. We can use that to make external decisions about how many pods we need. Let's take a look at how we might use that with Prometheus.

              </li>
              
              <li>
                 Kubernetes scales based on pods. How might we look to other metrics? There are lots of different adapters that we can look at. These best practices will help us to make good scaling decisions.

              </li>
              
              <li>
                Next up, we may scale too slow. What if when we deploy a new version, it always resets to one pod and then scales back up? Kubernetes will automatically block additional scaling operations until our system has reached stability. How do we overcome this?
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/r-tVKhb1W98.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:23,690'); seek(23.0)">
              Hi, welcome to Comp Kube native Con. This is
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:27,724'); seek(27.0)">
              really fun. I get to share with you horizontal auto scaling with
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:31,068'); seek(31.0)">
              Kubernetes. Let's dive in. Here's the part where I tell you I am
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:34,892'); seek(34.0)">
              definitely going to post the slides on my site tonight.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:37,930'); seek(37.0)">
              I've changed similar speakers and it's never worked out very well for me either.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:41,852'); seek(41.0)">
              So let's go to robridge.org where we can find the slides online right
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:45,836'); seek(45.0)">
              now. We'll go to robridge.org and
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:49,772'); seek(49.0)">
              click click here on presentations and we can see horizontal autoscaling
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:53,434'); seek(53.0)">
              with Kubernetes. The slides are online right now.
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:57,170'); seek(57.0)">
              While we're here on robrich.org, let's click on about me and see some
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:00,388'); seek(60.0)">
              of the things that I've done recently. I'm a developer advocate for
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:04,292'); seek(64.0)">
              Jetpackio. If you're struggling with Kubernetes, I would love to learn with you. I'm also
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:08,168'); seek(68.0)">
              a Microsoft MVP and MCT, a Docker captain and
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:12,072'); seek(72.0)">
              a friend of Redgate. AZ Givecamp is really fun. AZ Givecamp brings
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:16,318'); seek(76.0)">
              volunteer developers together with charities to build free software.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:20,098'); seek(80.0)">
              We start building software Friday after work. Sunday afternoon, we deliver
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:23,922'); seek(83.0)">
              completed software to charities. Sleep is optional, caffeine provided. If you're in
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:27,708'); seek(87.0)">
              Phoenix, come join us for the next AZ give camp. Or if you'd like a
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:31,164'); seek(91.0)">
              give camp close to where you live, hit me up here at the conference or
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:34,768'); seek(94.0)">
              on email or Twitter. And let's get a gift camp in your neighborhood too.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:38,480'); seek(98.0)">
              Some of the other things that I've done I do a lot with Kubernetes and
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,488'); seek(101.0)">
              Docker and one of the things I'm the most proud of I
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:44,948'); seek(104.0)">
              replied to a Net Rocks podcast episode they read my comments on here.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:48,436'); seek(108.0)">
              They sent me a mug.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:51,730'); seek(111.0)">
              So let's dig into horizontal auto scaling with Kubernetes.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:55,590'); seek(115.0)">
              We talked about this guy first. Let's talk about autoscaling now.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:59,592'); seek(119.0)">
              As we talk about scaling, part of what we're trying to accomplish
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:03,422'); seek(123.0)">
              is to meet the capacity when we need it and to save money
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:06,956'); seek(126.0)">
              when we don't. That's the nature of scaling.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:10,170'); seek(130.0)">
              When we talk about scaling, we can talk about both horizontal autoscaling and
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:14,092'); seek(134.0)">
              vertical scaling. With horizontal scaling, we're adding
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:17,762'); seek(137.0)">
              more items to be able to reach that capacity.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:20,758'); seek(140.0)">
              With vertical scaling, we're increasing the size of each item
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:24,870'); seek(144.0)">
              to be able to reach that capacity.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:27,710'); seek(147.0)">
              So dialing in some more. With vertical scaling,
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:31,050'); seek(151.0)">
              we're increasing the size of each item.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:34,154'); seek(154.0)">
              Now this might be great for things that need state where we
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:38,052'); seek(158.0)">
              don't want to manage synchronization, maybe a database by
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:41,892'); seek(161.0)">
              comparison with horizontal scaling, we are increasing the number of items.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:46,234'); seek(166.0)">
              Now we need to coordinate between them. We may need to populate
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:49,678'); seek(169.0)">
              data into a new node. We may need to ensure that
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:52,888'); seek(172.0)">
              there's one main node and that they coordinate together.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:56,570'); seek(176.0)">
              This synchronization isn't necessary if we're using a
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:59,772'); seek(179.0)">
              stateless service, perhaps a web server.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:03,370'); seek(183.0)">
              So horizontal and vertical scaling.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:07,410'); seek(187.0)">
              Now how did we get here? What are we building on top of? Whose shoulders
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:11,366'); seek(191.0)">
              are we standing on top of? Well, back in the old day,
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:14,448'); seek(194.0)">
              scaling was hard, it was slow, so we would
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:17,872'); seek(197.0)">
              generally over provision. We're provisioning for the traffic
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:21,642'); seek(201.0)">
              on our peak day. Maybe that's Black Friday, maybe that's Super
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:25,572'); seek(205.0)">
              Bowl Sunday. Maybe that's when we go viral. But because
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:29,380'); seek(209.0)">
              we're over provisioning for those worst case scenarios,
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:33,802'); seek(213.0)">
              on a normal day our machines may sit completely idle.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:37,278'); seek(217.0)">
              Now why did we do this? Well, we did this because provisioning
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:41,118'); seek(221.0)">
              was hard. It might take days or weeks or months
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:44,888'); seek(224.0)">
              to get approval, buy the hardware, install the content
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:49,068'); seek(229.0)">
              and install the operating system, then install
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:52,236'); seek(232.0)">
              our application, plug this into the load balancer.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:55,234'); seek(235.0)">
              That's definitely not something that we can do. If we have additional load yesterday
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:59,154'); seek(239.0)">
              that we need to handle tomorrow, this process may take weeks or
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:02,528'); seek(242.0)">
              months. So we need to have it all the way done by the time we
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:05,872'); seek(245.0)">
              reach that peak load. So we're over provisioning to
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:09,552'); seek(249.0)">
              be able to support the load on those extreme circumstances.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:13,490'); seek(253.0)">
              Today we don't need to do that. Today we
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:16,932'); seek(256.0)">
              buy just what we need. Utility billing with clouds allows
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:20,698'); seek(260.0)">
              us to scale easily and quickly to meet
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:24,072'); seek(264.0)">
              the demand. And then when the demand eases, then we
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:27,608'); seek(267.0)">
              can give those resources back and stop paying them.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:31,830'); seek(271.0)">
              Previously we would run our machines mostly idle so that
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:35,224'); seek(275.0)">
              we had additional capacity available. Today we run our machines
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:39,026'); seek(279.0)">
              mostly at capacity. 80 or 90% is not uncommon
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:43,202'); seek(283.0)">
              because we really want to use our hardware most effectively.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:46,970'); seek(286.0)">
              So utility billing makes this possible.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:51,150'); seek(291.0)">
              Now, all of that scaling applies to any scaling scenario.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:54,838'); seek(294.0)">
              Let's apply this specifically to kubernetes. Now in
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:58,048'); seek(298.0)">
              kubernetes we could talk about scaling a cluster. We're not going to
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:01,328'); seek(301.0)">
              do that today. But as you grab the slides from robrich.org,
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:04,634'); seek(304.0)">
              dig into scaling the cluster and that can be a really fun topic.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:08,234'); seek(308.0)">
              Today we're going to talk about scaling the workload, talking about
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:12,164'); seek(312.0)">
              pods. Now that presumes that your cluster is big enough to handle
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:15,438'); seek(315.0)">
              this. Next up we could talk about vertical scaling
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:19,038'); seek(319.0)">
              or horizontal scaling. Vertical scaling is definitely interesting.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:22,616'); seek(322.0)">
              It's about changing resource limits on our pods to match
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:26,060'); seek(326.0)">
              increased demand. But today we're going to talk about horizontal
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:30,290'); seek(330.0)">
              scaling. We're going to talk about increasing the count of pods
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:34,290'); seek(334.0)">
              to match the demand that we have. So let's dig
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:38,332'); seek(338.0)">
              into pod scaling. Well,
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:42,190'); seek(342.0)">
              why isn't this automatic? Why isn't there just a push the button
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:45,824'); seek(345.0)">
              and now we have scaling in our cluster. Well, it depends a lot on
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:49,408'); seek(349.0)">
              the workload, in particular, how your workload works and what
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:53,076'); seek(353.0)">
              metric you're using to measure it. What metric?
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:57,114'); seek(357.0)">
              Now, we might have a cpu bound workload, in which case we want to scale
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:00,602'); seek(360.0)">
              based on our cpu. Or we might have an IL bound workload,
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:04,202'); seek(364.0)">
              in which case we want to scale based on the request current
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:07,880'); seek(367.0)">
              concurrent request. Or maybe the request queue length.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:11,678'); seek(371.0)">
              We may scale based on external factors. Maybe we're looking at
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:14,904'); seek(374.0)">
              our message bus queue length. Or maybe we're looking at our
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:18,488'); seek(378.0)">
              load balancer for details of how we should scale.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:21,698'); seek(381.0)">
              Or maybe we're looking at latency in a critical function.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:24,892'); seek(384.0)">
              Is it taking a long time to log in? Maybe we need to up the
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:28,332'); seek(388.0)">
              servers associated with our authentication process. Now this
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:32,272'); seek(392.0)">
              is definitely not an exhaustive list of metrics, but why isn't
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:35,478'); seek(395.0)">
              this built in? Because it really depends on how our workload works.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:39,568'); seek(399.0)">
              If it works based on a cpu scaling metric, and we're scaling based
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:43,472'); seek(403.0)">
              on I o metrics, then of course we're not going to scale correctly.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:47,194'); seek(407.0)">
              Let's take a look at a few use cases. In this case, we chose
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:50,698'); seek(410.0)">
              to scale based on cpu, but it's an I O bound workload.
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:54,490'); seek(414.0)">
              Now, because it's an I O bound workload, our system sits
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:58,398'); seek(418.0)">
              mostly idle as we're waiting for our external data store.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:01,544'); seek(421.0)">
              Now in this case, because we're waiting for our external data store,
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:04,808'); seek(424.0)">
              and well, our machine is idle, the cpu is low,
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:08,828'); seek(428.0)">
              and our system never discovers that our system is under load. So we're
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:12,578'); seek(432.0)">
              never going to scale up beyond the minimum number of pods.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:16,010'); seek(436.0)">
              Similarly, maybe we're autoscaling based on an I O bound workload,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:19,926'); seek(439.0)">
              so we're scaling based on concurrent requests.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:23,070'); seek(443.0)">
              And perhaps our application framework limits the number of
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:26,448'); seek(446.0)">
              concurrent requests, putting back pressure on our load balancer to queue
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:30,038'); seek(450.0)">
              the incoming requests. And so we only have a certain number
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:33,812'); seek(453.0)">
              of concurrent requests. So we'll never scale beyond our
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:37,332'); seek(457.0)">
              normal thing. We'll never scale beyond
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:40,938'); seek(460.0)">
              our minimum because Kubernetes doesn't
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:44,014'); seek(464.0)">
              know that our system is under load, we've chosen the wrong metric.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:48,550'); seek(468.0)">
              Let's look at a third use case here. We've chosen
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:52,718'); seek(472.0)">
              to scale based on our service bus
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:56,632'); seek(476.0)">
              queue length. So if there are messages in our
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:59,948'); seek(479.0)">
              queue, we're going to scale up additional pods to be able to handle those messages.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:03,970'); seek(483.0)">
              Perhaps each message sends an email and then when the
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:07,452'); seek(487.0)">
              queue length is short, then we'll scale back down
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:10,896'); seek(490.0)">
              so that we're not using extra resources. In this case we matched
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:14,822'); seek(494.0)">
              our metric with our business concerns and so
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:17,888'); seek(497.0)">
              we're able to scale appropriately.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:21,070'); seek(501.0)">
              Now in each of these scenarios we looked at mechanisms where we
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:24,628'); seek(504.0)">
              could choose a metric to scale and in many of the instances we chose
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:28,378'); seek(508.0)">
              the wrong metric. Not to say that those metrics aren't good for scaling,
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:32,090'); seek(512.0)">
              but that in those scenarios that's not how that application works.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:35,924'); seek(515.0)">
              Now this is definitely not an exhaustive list, but as you look at scaling
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:39,806'); seek(519.0)">
              you might look to these and other metrics to understand the health of
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:43,208'); seek(523.0)">
              your system and what your system looks like under load.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:47,770'); seek(527.0)">
              So let's take a look at the Kubernetes autoscaler and in particular
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:51,356'); seek(531.0)">
              let's look at built in metrics.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:54,650'); seek(534.0)">
              Our first step in enabling the Kubernetes
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:57,922'); seek(537.0)">
              autoscale is to enable the metric server. The metric server captures
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:02,006'); seek(542.0)">
              cpu and memory on all of our pods and
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:05,312'); seek(545.0)">
              presents that to horizontal autoscale. So let's turn on the
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:08,688'); seek(548.0)">
              metric server first. Is it on? Let's do a
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:11,984'); seek(551.0)">
              kubectl top for our pods and in this case across
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:15,396'); seek(555.0)">
              all namespaces and see if it errors. If it errors, we need to turn it
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:19,108'); seek(559.0)">
              on. So let's head off to the metric server part of the Kubernetes
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:22,346'); seek(562.0)">
              project. Go grab the latest release and apply components.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:25,706'); seek(565.0)">
              Yaml in our case we're using minicube, so I just enabled the add
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:29,432'); seek(569.0)">
              on to enable the metric server. Now that we've got the metric server
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:33,582'); seek(573.0)">
              enabled, let's deploy our workload. Now we do need to customize
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:37,282'); seek(577.0)">
              our workload ever so slightly to ensure that the autoscale will behave
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:41,122'); seek(581.0)">
              as expected. We need to have a resource that knows
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:44,802'); seek(584.0)">
              how to build pods. So a deployment,
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:47,698'); seek(587.0)">
              a stateful set or a daemon set. In this
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:51,084'); seek(591.0)">
              case we now have a recipe, a template of how to build pods and
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:54,608'); seek(594.0)">
              we can scale out as we need to in
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:57,968'); seek(597.0)">
              our pod definition. We also need to set resource limits.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:01,382'); seek(601.0)">
              Kubernetes is going to look to these resource limits to know how much
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:05,076'); seek(605.0)">
              capacity we have left in that pod before it needs to create another
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:08,932'); seek(608.0)">
              similar. We need to remove the replica count in
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:12,068'); seek(612.0)">
              our deployment. The replica count is going to be controlled by the
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:15,688'); seek(615.0)">
              autoscaler, not by the deployment anymore.
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:18,870'); seek(618.0)">
              So here's our deployment. Or maybe it's a stateful set or daemon set.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:22,568'); seek(622.0)">
              You notice that we've commented out the replicas. This shouldn't be here because
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:26,232'); seek(626.0)">
              the autoscaler will do it. We've also set limits so that we know how
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:29,868'); seek(629.0)">
              much it is. So if we're using 100%
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:33,484'); seek(633.0)">
              of the capacity of this pod, that means we're using half a cpu.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:37,426'); seek(637.0)">
              For using more than half a cpu, we're using more than 100% of this
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:41,472'); seek(641.0)">
              pod. And if we're using a quarter of the cpu, we're using half the capacity
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:45,462'); seek(645.0)">
              for this pod. Next up, let's build the autoscaler.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:49,510'); seek(649.0)">
              Now the autoscaler is going to go grab that metric and
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:53,376'); seek(653.0)">
              understand across all of the pods if we need to,
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:57,060'); seek(657.0)">
              then increase the pods to get that average down, or decrease
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:00,602'); seek(660.0)">
              the count of pods to get that average up.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:04,290'); seek(664.0)">
              A horizontal autoscaler now it's going to go check these metrics
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:07,902'); seek(667.0)">
              every 15 seconds. And once it notices that it needs to make a
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:11,688'); seek(671.0)">
              change, then it'll make that change, but then it won't make additional changes
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:15,544'); seek(675.0)">
              for five minutes. Now we can definitely customize these defaults,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:19,410'); seek(679.0)">
              but these defaults help us to not overly burden our
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:23,052'); seek(683.0)">
              system and to reach consensus once we've made a scaling
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:26,898'); seek(686.0)">
              change. Maybe we need to populate the cache or adjust
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:31,030'); seek(691.0)">
              our content across all of our available nodes
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:34,598'); seek(694.0)">
              now. And that may take some time. So once we've reached stasis
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:38,790'); seek(698.0)">
              now, we can make additional scaling decisions.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:42,370'); seek(702.0)">
              So let's create a horizontal autoscaler. Now here with this Kubectl
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:46,362'); seek(706.0)">
              command, we can just quickly identify the deployment that it's cpu
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:50,362'); seek(710.0)">
              bound, the target percentage, in this case 50%. And the minimum and
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:54,132'); seek(714.0)">
              maximum number of pods we should create. Now 50% probably
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:57,992'); seek(717.0)">
              isn't a good metric. We probably should run more like 80 or 90%,
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:01,528'); seek(721.0)">
              but this is a good demo. We could also deploy
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:05,278'); seek(725.0)">
              this as a Kubernetes YamL file.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:09,050'); seek(729.0)">
              Now we've identified the deployment that we want to target
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:12,626'); seek(732.0)">
              and it is a deployment. We've specified the min and max replicas,
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:16,370'); seek(736.0)">
              so we'll have between one and four pods. And we've identified the
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:20,012'); seek(740.0)">
              type of thing that we want to do. In this case, it's a resource.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:22,902'); seek(742.0)">
              It's cpu or memory. We've chosen cpu and we
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:26,112'); seek(746.0)">
              say that we have a utilization an average of 50%. Now 50%
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:30,336'); seek(750.0)">
              is probably low, maybe we want to go 80%. But this is the percent
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:34,884'); seek(754.0)">
              of the details in our deployment. So here in
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:38,308'); seek(758.0)">
              our deployment we have 0.5 cpu. So 50%
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:42,180'); seek(762.0)">
              of our 0.5 cpu would be a quarter of a
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:45,300'); seek(765.0)">
              cpu. If we go over a quarter of a cpu, it sounds
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:48,792'); seek(768.0)">
              like we need more pods. We go under a quarter of a cpu,
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:51,854'); seek(771.0)">
              we'll need less pods.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:55,130'); seek(775.0)">
              So let's do this demo. We have
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:58,316'); seek(778.0)">
              here a deployment that we will
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:01,756'); seek(781.0)">
              build out. Now this references a pod that is
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:05,420'); seek(785.0)">
              just a basic exprs server. It has a single
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:08,716'); seek(788.0)">
              route that will allow us to just grab text. Notice that we've set
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:12,272'); seek(792.0)">
              our resource limits so that we can auto scale based on those limits.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:15,798'); seek(795.0)">
              And we've chosen just the cpu. Now we
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:19,072'); seek(799.0)">
              could specify other limits if we want, but we want to make sure that we
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:22,304'); seek(802.0)">
              horizontally autoscale based only on a single metric.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:25,690'); seek(805.0)">
              We've also commented out the replicas. We don't want our deployment
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:29,322'); seek(809.0)">
              to specify the count, we want our autoscale to specify it.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:33,060'); seek(813.0)">
              So here's our autoscale and we can see that it
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:37,190'); seek(817.0)">
              scales based on a deployment. This is the deployment name
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:41,016'); seek(821.0)">
              and we scaled based on our cpu.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:44,910'); seek(824.0)">
              And in this case, because it's a very small application,
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:47,884'); seek(827.0)">
              we're going to only scale on 5% of that half a cpu.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:52,250'); seek(832.0)">
              So first stop is to make sure that our metric server is enabled.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:13:56,178'); seek(836.0)">
              Let's do cubectl top pod
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:00,386'); seek(840.0)">
              and let's look in all namespaces. And it looks like yes, in this case
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:03,936'); seek(843.0)">
              our metric server is enabled. We get the cpu and memory for
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:07,776'); seek(847.0)">
              all of our pods whether we're using a horizontal autoscale or
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:10,864'); seek(850.0)">
              not. Great. Cubectl apply F
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:15,890'); seek(855.0)">
              cpu deploy. We've got our deployment in place
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:20,324'); seek(860.0)">
              and let's also grab our horizontal autoscaler.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:25,510'); seek(865.0)">
              Now when we first spin
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:29,598'); seek(869.0)">
              up our horizontal autoscaler our value will be unknown.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:33,374'); seek(873.0)">
              It takes 15 seconds for us to do a lap to go ask the
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:37,032'); seek(877.0)">
              pods what their resources are. And so for those 15 seconds we
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:41,148'); seek(881.0)">
              don't know if we need to do anything. So let's take a look.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:44,956'); seek(884.0)">
              Oh it looks like we have 31%. So it's going to go create a
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:48,464'); seek(888.0)">
              whole bunch of pods to match that capacity.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:51,526'); seek(891.0)">
              Now I'm surprised that it got to 31% straight away. Let's change
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:55,984'); seek(895.0)">
              this metric then to be 25%
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:01,060'); seek(901.0)">
              and apply this again.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:07,490'); seek(907.0)">
              Now we probably have to deploy our
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:11,508'); seek(911.0)">
              horizontal auto scaler again.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:15,670'); seek(915.0)">
              Yes. So now we should only need two pods. Now we
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:19,272'); seek(919.0)">
              were in that spot where we were automatically checking.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:22,750'); seek(922.0)">
              We're in that spot where we've made an adjustment. And so now
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:26,072'); seek(926.0)">
              it'll take a while for this to calm down, but let's
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:30,162'); seek(930.0)">
              generate some load on our system and see if that changes things. So in
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:33,868'); seek(933.0)">
              this case I have a busy box thing where I'm just curling into
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:38,156'); seek(938.0)">
              that app and so it's
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:41,250'); seek(941.0)">
              returning. Hello world. And we'll do that a whole bunch of times.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:45,710'); seek(945.0)">
              So now that we've got some load on the system, let's take a look at
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:48,848'); seek(948.0)">
              our autoscale. And it looks like we're down to zero. So now
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:52,228'); seek(952.0)">
              we've scaled down a whole lot. Now let's take a
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:56,068'); seek(956.0)">
              look at our Autoscale and
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:59,652'); seek(959.0)">
              we'll watch it and we'll see if we capture some change in
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:03,316'); seek(963.0)">
              metrics now that we've added some load to it.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:07,670'); seek(967.0)">
              Now, it does run every 15 seconds, so we will have to wait
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:11,576'); seek(971.0)">
              a little bit to see if this metric changes.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:14,630'); seek(974.0)">
              But once it changes, then we can recalculate the number of pods
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:18,978'); seek(978.0)">
              that we need. Now we can adjust the 15 seconds.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:23,138'); seek(983.0)">
              We can make it more aggressive, so maybe 10
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:26,972'); seek(986.0)">
              seconds or sooner to be able to look at our pods more aggressively.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:31,350'); seek(991.0)">
              Or we can specify it much more,
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:35,070'); seek(995.0)">
              much larger so that we put less load on our pods
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:38,438'); seek(998.0)">
              because, well, it needs to go look. Okay, so now we've gotten up
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:41,888'); seek(1001.0)">
              to 24%. So now based on our 24%,
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:45,348'); seek(1005.0)">
              let's see if we need additional pods. No, it looks like we don't.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:48,874'); seek(1008.0)">
              So I'm going to specify this back at 10%
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:53,044'); seek(1013.0)">
              and let's deploy our autoscale.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:59,190'); seek(1019.0)">
              And now based on 24%,
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:03,400'); seek(1023.0)">
              then it will spin up a whole lot of pods. Great. We saw how we
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:07,228'); seek(1027.0)">
              could spin up pods and spin down pods based
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:10,636'); seek(1030.0)">
              on the needs of our system. Cubectl,
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:13,650'); seek(1033.0)">
              delete F cpu.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:19,390'); seek(1039.0)">
              Let's delete our deployment. Let's also delete our
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:23,280'); seek(1043.0)">
              autoscale.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:28,030'); seek(1048.0)">
              And now we can see that those are done. Oh, we're still
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:31,572'); seek(1051.0)">
              generating a load. Let's undo that.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:36,530'); seek(1056.0)">
              Now. If we do kubectl top pod,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:42,050'); seek(1062.0)">
              we can see that we're still collecting metrics even though there's no horizontal
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:45,998'); seek(1065.0)">
              autoscale using those metrics. That's fine, it's nice data
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:50,056'); seek(1070.0)">
              to have, but the metric server is still running great.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:55,400'); seek(1075.0)">
              So we got to see the horizontal autoscale,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:58,766'); seek(1078.0)">
              we got to scale based on a cpu metric. And that was great.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:02,316'); seek(1082.0)">
              Let's take a look at other metrics that we might want to choose. Now,
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:05,868'); seek(1085.0)">
              as we looked at this, here's kind of our mental model. Our horizontal
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:09,398'); seek(1089.0)">
              pod autoscaler goes and checks the application
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:13,056'); seek(1093.0)">
              every 15 seconds to see if data needs adjusting.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:17,126'); seek(1097.0)">
              Now, that's a little bit of a naive interpretation
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:20,534'); seek(1100.0)">
              because, well, we have our metric server here. I love these
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:24,132'); seek(1104.0)">
              graphics. Grab these slides from robridge.org and click through
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:27,716'); seek(1107.0)">
              to the learnks IO page.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:30,868'); seek(1110.0)">
              It's a great tutorial. Now, this too is
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:34,296'); seek(1114.0)">
              a little bit naive because inside the metrics server we actually have
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:38,568'); seek(1118.0)">
              three different APIs we have resource metrics,
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:42,318'); seek(1122.0)">
              APIs, we have custom metrics and we have external
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:45,502'); seek(1125.0)">
              metrics. Now, zooming in on each of those, the resource metrics
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:49,778'); seek(1129.0)">
              is about cpu and memory. Those are the two built in custom
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:53,980'); seek(1133.0)">
              metrics. We might look to our pods to be able to find other
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:57,196'); seek(1137.0)">
              details, any details that we can get out of those pods would
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:01,040'); seek(1141.0)">
              work nicely here. In the custom metrics API, maybe we'll harvest
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:04,518'); seek(1144.0)">
              Prometheus metrics for example, and then external metrics.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:08,390'); seek(1148.0)">
              Maybe we're looking at a requests queue length or a
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:12,100'); seek(1152.0)">
              message queue length and taking actions based on
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:15,636'); seek(1155.0)">
              resources that are external to our pods, maybe other Kubernetes
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:19,466'); seek(1159.0)">
              resources, maybe other cloud resources, other hardware within our environment.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:23,674'); seek(1163.0)">
              We can look to that to make external decisions about how many pods
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:27,438'); seek(1167.0)">
              we need. So we have these three APIs
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:31,630'); seek(1171.0)">
              and each of them will reach out to an adapter that will reach out
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:35,432'); seek(1175.0)">
              to a service to get data. So for example,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:38,492'); seek(1178.0)">
              in the metrics API we reach out to the metrics server.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:41,874'); seek(1181.0)">
              The metrics server in turn looks to see Advisor and C
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:45,372'); seek(1185.0)">
              advisor will harvest those metrics from our pods.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:48,786'); seek(1188.0)">
              In our custom metrics API. Perhaps we're using the Prometheus adapter.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:52,614'); seek(1192.0)">
              The Prometheus adapter looks to Prometheus and Prometheus
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:56,086'); seek(1196.0)">
              looks to all of our pods. When we're looking at external things,
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:59,760'); seek(1199.0)">
              maybe we're using Prometheus to monitor those as well. Or maybe
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:02,996'); seek(1202.0)">
              we're using another adapter. So we
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:07,092'); seek(1207.0)">
              have the autoscaling in really interesting ways.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:10,436'); seek(1210.0)">
              Let's take a look at how we might use that with Prometheus.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:14,050'); seek(1214.0)">
              So our first stop is to install the metrics server. We did
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:17,432'); seek(1217.0)">
              this previously and even though we're not using the metrics coming out of the metrics
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:21,294'); seek(1221.0)">
              server, this gets us the metrics APIs as well.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:24,970'); seek(1224.0)">
              Then we need to install Prometheus. Now I'm grabbing Prometheus
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:28,962'); seek(1228.0)">
              from the Prometheus helm chart.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:33,210'); seek(1233.0)">
              The Prometheus community Prometheus helm chart installs
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:36,978'); seek(1236.0)">
              just Prometheus. But if I chose the Prometheus stack, I would also
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:40,508'); seek(1240.0)">
              get Grafana. Now I could choose to put this in a
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:44,128'); seek(1244.0)">
              different namespace. That would probably be a good best practice, but for the
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:47,408'); seek(1247.0)">
              sake of today's demo, I'll just put it in the default namespace.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:51,654'); seek(1251.0)">
              Next up, I'm going to install the Metrics adapter. Now I'm going to pull this
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:55,444'); seek(1255.0)">
              from Prometheus community helm charts as well. And so
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:59,156'); seek(1259.0)">
              then I'll install this Prometheus adapter. I am going to
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:02,596'); seek(1262.0)">
              set some properties here. I could do this with a yaml file or
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:06,680'); seek(1266.0)">
              here, I'll just set them straight away. I'm going to point it at the prometheus
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:10,302'); seek(1270.0)">
              URL. The Prometheus helm chart creates a prometheus service
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:14,376'); seek(1274.0)">
              called Prometheus service and it's on port 80 instead
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:17,836'); seek(1277.0)">
              of 90 90 as it typically is.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:21,148'); seek(1281.0)">
              So I'll configure it to point to my Prometheus service.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:24,348'); seek(1284.0)">
              And now I've got the Prometheus adapter running.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:27,930'); seek(1287.0)">
              Now I'm going to configure my workload. Now I could configure
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:31,302'); seek(1291.0)">
              Prometheus to point it at where my workload is and configure
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:35,238'); seek(1295.0)">
              it that way, but because it's all running in my cluster, I can create
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:38,736'); seek(1298.0)">
              an annotation on that deployment that will allow Prometheus
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:42,602'); seek(1302.0)">
              to automatically discover it. So here in my deployment,
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:46,458'); seek(1306.0)">
              I'm going to create an annotation on my pod
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:50,490'); seek(1310.0)">
              that identifies that. I want Prometheus to scrape
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:53,994'); seek(1313.0)">
              the metrics and what's the URL and port that it should scrape?
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:57,910'); seek(1317.0)">
              Now this is perfect. I've identified that Prometheus should
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:01,960'); seek(1321.0)">
              scrape the metrics out of all of these pods.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:05,294'); seek(1325.0)">
              I turn it on, I give it the URL, and I give it the port.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:08,936'); seek(1328.0)">
              Now it is important that these are quoted because if they aren't, this would
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:12,588'); seek(1332.0)">
              be a boolean and an integer respectively, and they need to be
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:16,252'); seek(1336.0)">
              strings to be annotations. So I put quotes around it and
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:19,548'); seek(1339.0)">
              it works just fine. Now I'll deploy my workload kubectl,
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:23,458'); seek(1343.0)">
              apply that deployment, and now I've got my content. I know that Prometheus
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:27,558'); seek(1347.0)">
              is going to monitor that content, make those metrics available to the Prometheus
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:31,562'); seek(1351.0)">
              adapter, and now our horizontal autoscale can
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:35,716'); seek(1355.0)">
              harvest those metrics to make scaling decisions. So next up,
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:39,556'); seek(1359.0)">
              let's put in the horizontal autoscale. Now I've got this horizontal
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:43,162'); seek(1363.0)">
              autoscale and in this case it's going to target a deployment. Here's the
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:46,728'); seek(1366.0)">
              name of my deployment. And rather than resources as
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:50,328'); seek(1370.0)">
              we saw previously, this one's going to scale based on pods. I wish
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:53,918'); seek(1373.0)">
              this said prometheus, but it doesn't.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:58,114'); seek(1378.0)">
              We'll give it some interesting metric from prometheus that the Prometheus
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:01,778'); seek(1381.0)">
              adapter knows how to get and we can give it a value that we
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:05,292'); seek(1385.0)">
              want to specify. So if it's lower than this, then we'll
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:09,362'); seek(1389.0)">
              reduce the number of pods and if it's above this, then we'll increase the number
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:12,512'); seek(1392.0)">
              of pods. Now, how might we look
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:16,048'); seek(1396.0)">
              to other metrics? There are lots of different adapters that we can
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:19,408'); seek(1399.0)">
              look at and let's tour. Come. Here's a really great project
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:23,348'); seek(1403.0)">
              that allows us to create adapters from all kinds of sources.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:26,922'); seek(1406.0)">
              So we could call HTTP into our pods
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:30,506'); seek(1410.0)">
              and harvest JSON querying into that JSON
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:33,658'); seek(1413.0)">
              to be able to grab a particular metric. There's also Prometheus collector,
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:37,582'); seek(1417.0)">
              although the Prometheus adapter is usually a better choice.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:41,006'); seek(1421.0)">
              We could look at the influxDB collector, which is a great example
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:44,296'); seek(1424.0)">
              of how we might query other data stores the AWS collector.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:47,822'); seek(1427.0)">
              So we could look at, for example, sqs queue length. We could use
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:51,132'); seek(1431.0)">
              this as a template to grab things from blob storage
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:54,930'); seek(1434.0)">
              or GCP. And we can also scale
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:58,642'); seek(1438.0)">
              based on a schedule. If we know that our work starts in the morning and
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:01,932'); seek(1441.0)">
              ends in the evening, and that we won't use the cluster overnight, we can create
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:05,392'); seek(1445.0)">
              a schedule to automatically scale that up or down. Now, unlike the
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:08,784'); seek(1448.0)">
              other metrics that look to behaviors in our cluster, this will just
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:12,228'); seek(1452.0)">
              do it on a timer and maybe that's sufficient.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:16,210'); seek(1456.0)">
              We could also look to istio and grab metrics from
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:19,748'); seek(1459.0)">
              istio. There are many other adapters that will allow
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:23,076'); seek(1463.0)">
              us to query other systems to be able to get metrics
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:26,702'); seek(1466.0)">
              both for pods and for external resources where we can make
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:30,456'); seek(1470.0)">
              choices about how to scale. We took a look
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:34,376'); seek(1474.0)">
              at built in sources for cpu and memory. Now those are
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:38,008'); seek(1478.0)">
              definitely the easiest, but if our workload isn't based on cpu
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:41,298'); seek(1481.0)">
              and memory, if it's based on another metric, perhaps we can look to
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:44,412'); seek(1484.0)">
              Prometheus to be able to find metrics specific for our application.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:48,810'); seek(1488.0)">
              Anything that we can expose as a Prometheus metric we can
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:52,128'); seek(1492.0)">
              then use to auto scale our service.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:54,830'); seek(1494.0)">
              Similarly, we could look to external metrics.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:57,974'); seek(1497.0)">
              Perhaps we're looking at our load balancer or our queue length
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:02,006'); seek(1502.0)">
              and making decisions on how many pods we need. Based on that,
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:07,010'); seek(1507.0)">
              let's take a look at some best practices. Now, these best practices will
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:10,708'); seek(1510.0)">
              help us to make good scaling decisions.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:14,290'); seek(1514.0)">
              What if we scale up too high? Maybe we're getting
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:18,470'); seek(1518.0)">
              attacked. Maybe we have a bug in our software,
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:21,774'); seek(1521.0)">
              or maybe we've just gone viral and we need to be able to scale up
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:25,272'); seek(1525.0)">
              to impossible scale. We probably don't want to scale infinitely
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:29,698'); seek(1529.0)">
              because, well, especially in the case of an attack, we don't want that big
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:33,596'); seek(1533.0)">
              cloud bill. It would be really easy for us to stay
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:37,292'); seek(1537.0)">
              scaled for the duration of the attack and end up paying a lot.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:41,376'); seek(1541.0)">
              So let's create a max value that matches the
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:44,688'); seek(1544.0)">
              budget of our organization and lets us determine that.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:48,128'); seek(1548.0)">
              Well, we're going to understand that our system may not
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:51,568'); seek(1551.0)">
              be able to reach that capacity, but it'll reach our budgetary goals.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:55,466'); seek(1555.0)">
              If it's an attack, we're not paying extra to handle that attack.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:58,964'); seek(1558.0)">
              Or if we've gone viral, maybe we need to reconsider that upper bound.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:03,650'); seek(1563.0)">
              The other reason we might scale up too high is maybe we're
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:07,038'); seek(1567.0)">
              monitoring more than one metric. Now, Kubernetes is going
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:10,264'); seek(1570.0)">
              to do the right thing here. If we're monitoring two metrics and one
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:13,608'); seek(1573.0)">
              is high and one is low, Kubernetes will use the high metric
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:17,186'); seek(1577.0)">
              to be able to reach the capacity to make sure that all the
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:20,588'); seek(1580.0)">
              metrics are within bounds. But for example, if we're monitoring
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:24,578'); seek(1584.0)">
              both cpu and memory, and the cpu is low,
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:28,750'); seek(1588.0)">
              we might say, well, you shouldn't have scaled up here,
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:32,080'); seek(1592.0)">
              but maybe the memory is high and so we did scale up by
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:35,952'); seek(1595.0)">
              comparison. So here we need
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:39,712'); seek(1599.0)">
              to define the max replicas in addition to
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:43,028'); seek(1603.0)">
              the min replicas. Don't just assume that infinitely high
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:46,452'); seek(1606.0)">
              is sufficient. Pick a budget that matches the needs of our organization and
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:50,868'); seek(1610.0)">
              understand that our system may be less available if our load
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:26:54,282'); seek(1614.0)">
              exceeds that. But we're reaching our budget goals, which is the
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:26:58,008'); seek(1618.0)">
              needs of the business. Next up, we may scale too slow.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:01,326'); seek(1621.0)">
              Now, we noted how the horizontal autoscale only checked every 15
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:05,160'); seek(1625.0)">
              seconds. That's definitely a configurable value. And in
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:08,668'); seek(1628.0)">
              the case of missing metrics, then Kubernetes will assume the best
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:12,636'); seek(1632.0)">
              case scenario. So if we're scaling out, Kubernetes will
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:16,108'); seek(1636.0)">
              assume that that pod is using 0%, therefore it won't
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:20,226'); seek(1640.0)">
              scale out unnecessarily. If we're scaling in, Kubernetes will
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:24,048'); seek(1644.0)">
              assume that that metric was at 100%. Therefore it probably won't scale
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:27,702'); seek(1647.0)">
              in until that metric is available. So if it takes
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:30,832'); seek(1650.0)">
              a long time for our pods to be able to surface these metrics,
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:34,410'); seek(1654.0)">
              then we may notice that the Kubernetes autoscaler won't take action.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:38,106'); seek(1658.0)">
              What if when we deploy a new version, it always resets to one pod
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:42,042'); seek(1662.0)">
              and then scales back up? Yeah, if we put our
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:45,796'); seek(1665.0)">
              HUD coded pod limit, then we might hit a scenario. Well, what happened
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:49,736'); seek(1669.0)">
              here? In our deployment or our other service,
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:53,496'); seek(1673.0)">
              we had a hard coded replicas count as we deployed
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:27:57,838'); seek(1677.0)">
              the new version of our deployment. Or stateful set or replica
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:01,378'); seek(1681.0)">
              set, Kubernetes followed our instructions and killed off all the other
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:05,132'); seek(1685.0)">
              pods. So we only ended up with one or maybe a few. Yeah,
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:08,524'); seek(1688.0)">
              we really want our autoscale to handle this. So we
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:12,688'); seek(1692.0)">
              need to comment out the replicas line in our deployment.
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:17,174'); seek(1697.0)">
              We want our horizontal autoscaler to hit this. Now. This does create an edge
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:20,758'); seek(1700.0)">
              case where when we deploy it the very, very first time, we're only going to
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:24,084'); seek(1704.0)">
              get one until the autoscaler notices. Well, I'd rather
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:27,396'); seek(1707.0)">
              have 15 seconds of only one pod than
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:31,730'); seek(1711.0)">
              have it reset to one on every deployment. If you grab these slides
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:35,434'); seek(1715.0)">
              from roberts.org and click through to this post, you can find more about
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:38,952'); seek(1718.0)">
              that edge case and how to handle it gracefully.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:41,806'); seek(1721.0)">
              Flapping or sloshing? The documentation talks about flapping
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:45,518'); seek(1725.0)">
              as if the door keeps opening and closing. I like to talk about sloshing like
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:49,948'); seek(1729.0)">
              we're just pushing the water up against the beach and so the water
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:53,660'); seek(1733.0)">
              just keeps going. Let's assume that we have a Java app that
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:28:56,972'); seek(1736.0)">
              takes a while to spin up. We notice that we don't have enough capacity,
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:00,290'); seek(1740.0)">
              so we spin up some pods. 15 seconds later we notice that those
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:04,192'); seek(1744.0)">
              pods aren't live yet and we choose to decide to scale up again.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:07,888'); seek(1747.0)">
              And so now in a minute, once our Java app is booted and everything is
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:11,792'); seek(1751.0)">
              working, we now have too much capacity. So we'll scale
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:15,098'); seek(1755.0)">
              back down. Then we'll notice we don't have up scale back up and down and
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:18,468'); seek(1758.0)">
              up and on we go, sloshing back and Forth. Well, what happened
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:22,420'); seek(1762.0)">
              here? Well, Kubernetes will automatically block additional scaling
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:27,998'); seek(1767.0)">
              operations until our system has reached stability.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:31,646'); seek(1771.0)">
              So by default, it's five minutes. In this case, I added some content
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:35,720'); seek(1775.0)">
              to my horizontal autoscaler to set that stabilization
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:39,122'); seek(1779.0)">
              window to 60 seconds,
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:42,010'); seek(1782.0)">
              600 seconds or ten minutes. So I want to give
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:45,532'); seek(1785.0)">
              my time, a little bit of my application, a little bit extra time to get
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:48,992'); seek(1788.0)">
              stable. Alternatively, in our demos, we chose to scale
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:52,822'); seek(1792.0)">
              it, to set that stabilization window to 1
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:29:56,272'); seek(1796.0)">
              second so that it would automatically make additional scaling things. And that
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:00,032'); seek(1800.0)">
              worked out really well for our demo. Scale to zero. Now in
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:04,292'); seek(1804.0)">
              our horizontal autoscale, it won't scale to zero, it'll only scale to
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:07,588'); seek(1807.0)">
              one. And now we're paying for our application to
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:10,708'); seek(1810.0)">
              run even if there's no load at all. How do we overcome this?
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:14,388'); seek(1814.0)">
              Well, the problem is that, well, how do we start the application back
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:17,992'); seek(1817.0)">
              up? If a request comes in and there are no deployment,
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:21,694'); seek(1821.0)">
              no pods running to handle it, then that request
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:24,862'); seek(1824.0)">
              will just fail. So to make this happen, we need a reverse proxy in
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:28,328'); seek(1828.0)">
              front of that to be able to handle the load. Notice there's
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:31,538'); seek(1831.0)">
              no pods and kick it back up. Now, it may take a minute for
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:34,956'); seek(1834.0)">
              a pod to start on a completely cold start, so maybe that initial request
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:38,946'); seek(1838.0)">
              also still fails. But that's our scale to zero problem. We need
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:42,528'); seek(1842.0)">
              a reverse proxy in front of it to be able to notice that our
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:46,016'); seek(1846.0)">
              cluster needs turning back on. Now that's not built in. That's a
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:49,408'); seek(1849.0)">
              problem larger than just horizontal autoscaling between one and
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:30:52,768'); seek(1852.0)">
              a set number. So we might need to reach for external tools.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:30:56,778'); seek(1856.0)">
              Knative and keta both offer this solution, and so
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:00,132'); seek(1860.0)">
              we can reach for one of these products to be able to get to scale
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:03,578'); seek(1863.0)">
              to zero. Now, it does mean that we're going to have some pods running associated
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:07,278'); seek(1867.0)">
              with knative and Keda. So if we only have one microservice,
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:10,878'); seek(1870.0)">
              maybe just leaving that one microservice running, that might
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:14,808'); seek(1874.0)">
              be a simpler solution than a scale to zero solution.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:18,482'); seek(1878.0)">
              We took a look at horizontal autoscaling in Kubernetes and it was really
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:22,396'); seek(1882.0)">
              cool. Horizontal autoscaling is about scaling
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:25,698'); seek(1885.0)">
              up when we have additional demand and scaling down, paying less
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:29,772'); seek(1889.0)">
              when we don't have demand. This is made possible by utility billing.
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:33,410'); seek(1893.0)">
              We can go to a cloud, we can get some resources. When we're done,
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:36,812'); seek(1896.0)">
              we can hand them back and pay. Nothing and the scaling operation can
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:40,148'); seek(1900.0)">
              handle can happen in real time. So we don't need to pre
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:31:43,956'); seek(1903.0)">
              provision our hardware. We don't need to over buy our systems
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:31:47,738'); seek(1907.0)">
              to reach maximum capacity. We can scale up and down as
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:31:51,028'); seek(1911.0)">
              our needs are.
            </span>
            
            </div>
          </div>
          
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/kubenative2022" class="btn btn-sm btn-danger shadow lift" style="background-color: #CA6B46;">
                <i class="fe fe-grid me-2"></i>
                See all 13 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/kube_rob_richardson.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Rob Richardson
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Developer Advocate @ Jetpack.io
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/erobrich/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Rob Richardson's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@rob_rich" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Rob Richardson's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @rob_rich"
                  data-url="https://www.conf42.com/kubenative2022"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/kubenative2022"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Kube Native"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>