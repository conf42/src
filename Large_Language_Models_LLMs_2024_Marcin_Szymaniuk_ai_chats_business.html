<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: AI Chats: What Nobody Told You - The Conundrums of Business Integration</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Marcin%20Szymaniuk_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="AI Chats: What Nobody Told You - The Conundrums of Business Integration | Conf42"/>
    <meta property="og:description" content="Explore the intricacies of integrating ChatGPT into business systems with data privacy challenges, cost implications, and the strategic analysis required for successful integration. Learn about direct API integration, cost optimization, and customizing privately hosted models to fit your resources and needs."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2024_Marcin_Szymaniuk_ai_chats_business"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2024 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2024-04-11">April 11 2024</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2024-04-11T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-11T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "kmVB_-NmEkw"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "TQwxk0c4sh0"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrBjR6ZR0g0LRq9Fp8c_4HrI" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Today I am going to share with you some of the lessons learned from multiple", "timestamp": "00:00:21,200", "timestamp_s": 21.0}, {"text": "AI chatbot projects where we utilized large language models", "timestamp": "00:00:24,358", "timestamp_s": 24.0}, {"text": "and doing that is actually quite tricky. So by the end of the presentation", "timestamp": "00:00:28,518", "timestamp_s": 28.0}, {"text": "you will have a list of what to pay attention to,", "timestamp": "00:00:32,382", "timestamp_s": 32.0}, {"text": "sometimes critical issues, sometimes tiny little details", "timestamp": "00:00:35,126", "timestamp_s": 35.0}, {"text": "which are still important in the project success.", "timestamp": "00:00:39,158", "timestamp_s": 39.0}, {"text": "And we will start with the introduction to rag, what it is", "timestamp": "00:00:42,694", "timestamp_s": 42.0}, {"text": "and what kind of challenges you can expect when building complex applications.", "timestamp": "00:00:46,910", "timestamp_s": 46.0}, {"text": "Then we will talk about hallucinations, but also how", "timestamp": "00:00:51,534", "timestamp_s": 51.0}, {"text": "we control the scope of the conversation. So if we", "timestamp": "00:00:55,680", "timestamp_s": 55.0}, {"text": "are dealing with customer issue, we dont start talking about", "timestamp": "00:00:59,328", "timestamp_s": 59.0}, {"text": "us presidency, election or any other issue which is not", "timestamp": "00:01:03,016", "timestamp_s": 63.0}, {"text": "relevant. We will also cover the cost,", "timestamp": "00:01:06,840", "timestamp_s": 66.0}, {"text": "how to calculate it and whats important in", "timestamp": "00:01:10,712", "timestamp_s": 70.0}, {"text": "various scenarios. And at the end ill briefly", "timestamp": "00:01:13,880", "timestamp_s": 73.0}, {"text": "describe privacy issues related to llms and the consequences", "timestamp": "00:01:17,624", "timestamp_s": 77.0}, {"text": "of various decisions. My name is Martin,", "timestamp": "00:01:21,902", "timestamp_s": 81.0}, {"text": "my background is in data engineering and mlobs and I\u0027m", "timestamp": "00:01:26,230", "timestamp_s": 86.0}, {"text": "running a team specialized in everything data. At Tantus data and", "timestamp": "00:01:29,742", "timestamp_s": 89.0}, {"text": "at Tantus data we help our customers with setting up data", "timestamp": "00:01:34,262", "timestamp_s": 94.0}, {"text": "infrastructure, building data pipelines, and machine learning", "timestamp": "00:01:37,678", "timestamp_s": 97.0}, {"text": "and genai driven applications. So during that", "timestamp": "00:01:41,286", "timestamp_s": 101.0}, {"text": "presentation I will share lessons learned from some", "timestamp": "00:01:44,694", "timestamp_s": 104.0}, {"text": "of our projects. And a little disclaimer before", "timestamp": "00:01:47,974", "timestamp_s": 107.0}, {"text": "we get started. We need to be aware that the entire area of", "timestamp": "00:01:51,734", "timestamp_s": 111.0}, {"text": "Genai is moving incredibly fast. The models", "timestamp": "00:01:55,734", "timestamp_s": 115.0}, {"text": "improve over time, the libraries, the tools improve,", "timestamp": "00:01:59,158", "timestamp_s": 119.0}, {"text": "some of them die. So it\u0027s really hard", "timestamp": "00:02:03,054", "timestamp_s": 123.0}, {"text": "to keep track of all that. And because of that,", "timestamp": "00:02:06,494", "timestamp_s": 126.0}, {"text": "be aware that some of the tools I\u0027m referring to might", "timestamp": "00:02:09,582", "timestamp_s": 129.0}, {"text": "be outdated by the time you listen", "timestamp": "00:02:13,278", "timestamp_s": 133.0}, {"text": "to it. And I\u0027ll try not to", "timestamp": "00:02:16,594", "timestamp_s": 136.0}, {"text": "focus on specific tools, but more on problems, solutions,", "timestamp": "00:02:20,522", "timestamp_s": 140.0}, {"text": "techniques and general ideas.", "timestamp": "00:02:24,042", "timestamp_s": 144.0}, {"text": "But since there are so much going on", "timestamp": "00:02:27,354", "timestamp_s": 147.0}, {"text": "in the area of Genai after the presentation,", "timestamp": "00:02:30,970", "timestamp_s": 150.0}, {"text": "I would be really happy to hear from you about your", "timestamp": "00:02:34,242", "timestamp_s": 154.0}, {"text": "findings, your experience. So don\u0027t be", "timestamp": "00:02:37,658", "timestamp_s": 157.0}, {"text": "shy and let\u0027s connect on LinkedIn.", "timestamp": "00:02:41,190", "timestamp_s": 161.0}, {"text": "Okay, so let\u0027s get started. Let\u0027s think about concrete business", "timestamp": "00:02:44,734", "timestamp_s": 164.0}, {"text": "problem you would like to solve. And let\u0027s think about", "timestamp": "00:02:48,622", "timestamp_s": 168.0}, {"text": "a chat which is travel assistant on vacation rental website.", "timestamp": "00:02:51,902", "timestamp_s": 171.0}, {"text": "And let\u0027s say the customer comes and asks,", "timestamp": "00:02:55,774", "timestamp_s": 175.0}, {"text": "I need an apartment in London", "timestamp": "00:03:00,030", "timestamp_s": 180.0}, {"text": "with elevator. How do we know what the", "timestamp": "00:03:03,846", "timestamp_s": 183.0}, {"text": "customer is asking for?", "timestamp": "00:03:07,740", "timestamp_s": 187.0}, {"text": "How do we come up with specific information and use that in the", "timestamp": "00:03:12,084", "timestamp_s": 192.0}, {"text": "chat? So one of the", "timestamp": "00:03:15,380", "timestamp_s": 195.0}, {"text": "very common answer to these kind of questions is vector embeddings", "timestamp": "00:03:19,052", "timestamp_s": 199.0}, {"text": "and vector databases. So let\u0027s quickly define what they", "timestamp": "00:03:23,156", "timestamp_s": 203.0}, {"text": "are and why are they good in natural language", "timestamp": "00:03:27,212", "timestamp_s": 207.0}, {"text": "problems. But then I will show you", "timestamp": "00:03:31,484", "timestamp_s": 211.0}, {"text": "some examples of when they do not work that well and what", "timestamp": "00:03:34,882", "timestamp_s": 214.0}, {"text": "we can do. So the promise about", "timestamp": "00:03:38,890", "timestamp_s": 218.0}, {"text": "vector embeddings is very simple. First of all,", "timestamp": "00:03:42,978", "timestamp_s": 222.0}, {"text": "you transform the text into a vector and the vector represents", "timestamp": "00:03:46,970", "timestamp_s": 226.0}, {"text": "the semantic meaning of the text. So two", "timestamp": "00:03:51,114", "timestamp_s": 231.0}, {"text": "texts which have similar meaning will be transformed into two vectors", "timestamp": "00:03:54,986", "timestamp_s": 234.0}, {"text": "which are also close to each other.", "timestamp": "00:03:59,450", "timestamp_s": 239.0}, {"text": "And let\u0027s have a look at examples.", "timestamp": "00:04:03,474", "timestamp_s": 243.0}, {"text": "This is one of the very classical examples.", "timestamp": "00:04:06,354", "timestamp_s": 246.0}, {"text": "King and queen are somewhat the same", "timestamp": "00:04:10,154", "timestamp_s": 250.0}, {"text": "role, you can say, and the only difference is gender.", "timestamp": "00:04:13,762", "timestamp_s": 253.0}, {"text": "So in the perfect vector space, the distance between king and queen", "timestamp": "00:04:18,034", "timestamp_s": 258.0}, {"text": "should be the same as between men.", "timestamp": "00:04:22,570", "timestamp_s": 262.0}, {"text": "And you should be even able to do this", "timestamp": "00:04:26,654", "timestamp_s": 266.0}, {"text": "kind of math like queen equals king,", "timestamp": "00:04:30,102", "timestamp_s": 270.0}, {"text": "man plus woman.", "timestamp": "00:04:33,542", "timestamp_s": 273.0}, {"text": "And this is another example. The words red,", "timestamp": "00:04:36,694", "timestamp_s": 276.0}, {"text": "orange and yellow represents colors, so they are close to each", "timestamp": "00:04:40,230", "timestamp_s": 280.0}, {"text": "other. Then king and queen are also close to", "timestamp": "00:04:43,542", "timestamp_s": 283.0}, {"text": "each other and car is somewhere completely else.", "timestamp": "00:04:47,270", "timestamp_s": 287.0}, {"text": "And this is very flat and simplified", "timestamp": "00:04:51,564", "timestamp_s": 291.0}, {"text": "dummy example of vector embeddings, because in reality", "timestamp": "00:04:55,236", "timestamp_s": 295.0}, {"text": "they have hundreds or thousands of dimensions.", "timestamp": "00:04:58,852", "timestamp_s": 298.0}, {"text": "But the idea, the promise from embeddings", "timestamp": "00:05:02,524", "timestamp_s": 302.0}, {"text": "is that the vectors are close to each other if", "timestamp": "00:05:06,116", "timestamp_s": 306.0}, {"text": "the text has similar meaning.", "timestamp": "00:05:09,660", "timestamp_s": 309.0}, {"text": "So it\u0027s not a surprise that for searching information needed", "timestamp": "00:05:12,444", "timestamp_s": 312.0}, {"text": "by LLM in a chatbot, we likely want to try vector", "timestamp": "00:05:16,132", "timestamp_s": 316.0}, {"text": "database. So the super basic idea is that you transform your", "timestamp": "00:05:20,214", "timestamp_s": 320.0}, {"text": "documents into vector, you store them into vector database", "timestamp": "00:05:23,742", "timestamp_s": 323.0}, {"text": "and you serve the relevant documents to the LLM.", "timestamp": "00:05:27,662", "timestamp_s": 327.0}, {"text": "And more general version of this diagram is", "timestamp": "00:05:32,694", "timestamp_s": 332.0}, {"text": "that one when we provide an LLM with access", "timestamp": "00:05:36,342", "timestamp_s": 336.0}, {"text": "to our documents, databases, API,", "timestamp": "00:05:40,206", "timestamp_s": 340.0}, {"text": "basically everything needed in order to understand our domain information.", "timestamp": "00:05:43,678", "timestamp_s": 343.0}, {"text": "And this technique is called RaG, stands for retrieval", "timestamp": "00:05:47,984", "timestamp_s": 347.0}, {"text": "augmented generation. But once again,", "timestamp": "00:05:51,800", "timestamp_s": 351.0}, {"text": "why are we doing this? We need to remember that", "timestamp": "00:05:55,608", "timestamp_s": 355.0}, {"text": "the main ability of LLM is not really the knowledge it", "timestamp": "00:05:59,432", "timestamp_s": 359.0}, {"text": "comes with, but the ability to work with texts, with texts", "timestamp": "00:06:02,680", "timestamp_s": 362.0}, {"text": "written in natural language, and ability to follow", "timestamp": "00:06:06,712", "timestamp_s": 366.0}, {"text": "instructions related to these texts. So LLM has", "timestamp": "00:06:10,470", "timestamp_s": 370.0}, {"text": "a chance to know only about the information it was", "timestamp": "00:06:13,870", "timestamp_s": 373.0}, {"text": "trained on and we need to provide it with our specific domain", "timestamp": "00:06:17,518", "timestamp_s": 377.0}, {"text": "knowledge. Let\u0027s get back to our example, our business", "timestamp": "00:06:21,822", "timestamp_s": 381.0}, {"text": "problem. How do we use that technique? How do we use vector", "timestamp": "00:06:25,830", "timestamp_s": 385.0}, {"text": "databases for our I need", "timestamp": "00:06:29,454", "timestamp_s": 389.0}, {"text": "an apartment with elevator in London query.", "timestamp": "00:06:32,646", "timestamp_s": 392.0}, {"text": "If we have our apartment descriptions in the vector", "timestamp": "00:06:36,344", "timestamp_s": 396.0}, {"text": "database, what we could do, we could just check if the vector", "timestamp": "00:06:39,664", "timestamp_s": 399.0}, {"text": "representing our query is close to any of our property description.", "timestamp": "00:06:43,320", "timestamp_s": 403.0}, {"text": "And what we hope for is that I", "timestamp": "00:06:48,016", "timestamp_s": 408.0}, {"text": "need an apartment with elevator in London. Vector will be", "timestamp": "00:06:51,648", "timestamp_s": 411.0}, {"text": "close to an apartment with description apartment", "timestamp": "00:06:55,488", "timestamp_s": 415.0}, {"text": "with elevator in London and not that", "timestamp": "00:06:59,752", "timestamp_s": 419.0}, {"text": "close to apartment with description apartment in", "timestamp": "00:07:03,464", "timestamp_s": 423.0}, {"text": "London. So no elevator mentioned.", "timestamp": "00:07:07,240", "timestamp_s": 427.0}, {"text": "But once again, this example is way too simplistic.", "timestamp": "00:07:10,624", "timestamp_s": 430.0}, {"text": "This is perfectly valid technique, and it describes what vector", "timestamp": "00:07:14,480", "timestamp_s": 434.0}, {"text": "embeddings and vector databases could be used for. But I would", "timestamp": "00:07:18,304", "timestamp_s": 438.0}, {"text": "like to focus on the challenges which you might face. So first", "timestamp": "00:07:21,720", "timestamp_s": 441.0}, {"text": "of all, the apartment description will never be just a single sentence.", "timestamp": "00:07:25,672", "timestamp_s": 445.0}, {"text": "They will look more like this. This is", "timestamp": "00:07:29,184", "timestamp_s": 449.0}, {"text": "an example cottage in Cornwall,", "timestamp": "00:07:32,720", "timestamp_s": 452.0}, {"text": "western England, and it\u0027s not that expensive.", "timestamp": "00:07:35,776", "timestamp_s": 455.0}, {"text": "We have one more very similar one. So you can see the descriptions are", "timestamp": "00:07:39,264", "timestamp_s": 459.0}, {"text": "quite long and you have some extra information about them.", "timestamp": "00:07:42,792", "timestamp_s": 462.0}, {"text": "But we have also some completely different properties.", "timestamp": "00:07:46,736", "timestamp_s": 466.0}, {"text": "We have another one in London. It\u0027s not a cottage anymore,", "timestamp": "00:07:51,120", "timestamp_s": 471.0}, {"text": "it\u0027s an apartment that is much more expensive. So completely", "timestamp": "00:07:54,592", "timestamp_s": 474.0}, {"text": "different type of property and one more", "timestamp": "00:07:58,396", "timestamp_s": 478.0}, {"text": "similar. And then if we take all four properties I", "timestamp": "00:08:01,972", "timestamp_s": 481.0}, {"text": "have just shown, get the description and take the", "timestamp": "00:08:05,612", "timestamp_s": 485.0}, {"text": "vector embeddings, then we end up with something like this.", "timestamp": "00:08:10,012", "timestamp_s": 490.0}, {"text": "I do understand that this is not very readable, but this", "timestamp": "00:08:13,580", "timestamp_s": 493.0}, {"text": "actually represents very well the problem an engineer", "timestamp": "00:08:18,020", "timestamp_s": 498.0}, {"text": "is struggling with. So we have four different properties both,", "timestamp": "00:08:22,004", "timestamp_s": 502.0}, {"text": "but in the world of vectors, they are very close to each other,", "timestamp": "00:08:25,940", "timestamp_s": 505.0}, {"text": "simply because the wording used in the description", "timestamp": "00:08:30,208", "timestamp_s": 510.0}, {"text": "is very similar. It\u0027s very far away from the", "timestamp": "00:08:34,272", "timestamp_s": 514.0}, {"text": "word banana, it\u0027s very far away from some sentence of", "timestamp": "00:08:37,840", "timestamp_s": 517.0}, {"text": "some sentence about constitution, but it", "timestamp": "00:08:42,104", "timestamp_s": 522.0}, {"text": "doesn\u0027t really help us because the property description itself", "timestamp": "00:08:45,888", "timestamp_s": 525.0}, {"text": "is very close to each other. So it\u0027s very hard to distinguish", "timestamp": "00:08:50,160", "timestamp_s": 530.0}, {"text": "what is what in very hard to make a good", "timestamp": "00:08:54,416", "timestamp_s": 534.0}, {"text": "proposal for the customer. And the reason for that", "timestamp": "00:08:58,136", "timestamp_s": 538.0}, {"text": "is that if we are using general vector", "timestamp": "00:09:01,816", "timestamp_s": 541.0}, {"text": "embeddings, they are good in general language, but they are not specialized", "timestamp": "00:09:05,384", "timestamp_s": 545.0}, {"text": "in a specific domain, and the specialization in a specific domain", "timestamp": "00:09:09,360", "timestamp_s": 549.0}, {"text": "is usually what we want. So maybe that", "timestamp": "00:09:13,056", "timestamp_s": 553.0}, {"text": "will come up as a surprise. But magic does not exist. There is", "timestamp": "00:09:16,672", "timestamp_s": 556.0}, {"text": "no such thing as a silver bullet. So vector databases", "timestamp": "00:09:20,512", "timestamp_s": 560.0}, {"text": "are useful, but you need to test what will work for you.", "timestamp": "00:09:24,316", "timestamp_s": 564.0}, {"text": "Maybe you will need to fine tune the embedding so they are specialized", "timestamp": "00:09:28,204", "timestamp_s": 568.0}, {"text": "to the domain. For sure, you will need to do splitting of long documents", "timestamp": "00:09:31,684", "timestamp_s": 571.0}, {"text": "because of the context length limitation of vector embedding models,", "timestamp": "00:09:35,892", "timestamp_s": 575.0}, {"text": "they can accept text up to specific limit,", "timestamp": "00:09:39,940", "timestamp_s": 579.0}, {"text": "few hundreds, up to few thousand at most.", "timestamp": "00:09:43,636", "timestamp_s": 583.0}, {"text": "But even if you can fit long text in the embedding model,", "timestamp": "00:09:46,412", "timestamp_s": 586.0}, {"text": "it does not mean the longer text will work better for", "timestamp": "00:09:50,740", "timestamp_s": 590.0}, {"text": "you. This is something to be tested.", "timestamp": "00:09:54,232", "timestamp_s": 594.0}, {"text": "One of the secret ingredients making", "timestamp": "00:09:58,384", "timestamp_s": 598.0}, {"text": "your chat better is splitting the documents you are working with", "timestamp": "00:10:01,736", "timestamp_s": 601.0}, {"text": "into digestible chunks, that\u0027s for sure. But if", "timestamp": "00:10:05,352", "timestamp_s": 605.0}, {"text": "I tell you, if I tell you,", "timestamp": "00:10:09,440", "timestamp_s": 609.0}, {"text": "get the document description, get the apartment description,", "timestamp": "00:10:13,784", "timestamp_s": 613.0}, {"text": "get a PDF document, and split it into chunks,", "timestamp": "00:10:17,048", "timestamp_s": 617.0}, {"text": "it will be a bit too simplistic. It will", "timestamp": "00:10:20,434", "timestamp_s": 620.0}, {"text": "be somewhat like saying,", "timestamp": "00:10:23,762", "timestamp_s": 623.0}, {"text": "just draw two circles, complete the owl,", "timestamp": "00:10:27,098", "timestamp_s": 627.0}, {"text": "something is missing. So what we do,", "timestamp": "00:10:31,442", "timestamp_s": 631.0}, {"text": "what we pay attention to when splitting documents, let\u0027s have a", "timestamp": "00:10:34,762", "timestamp_s": 634.0}, {"text": "look, let\u0027s have a look at some of the solutions.", "timestamp": "00:10:38,090", "timestamp_s": 638.0}, {"text": "When you split the document, what will matter for sure is the size.", "timestamp": "00:10:42,314", "timestamp_s": 642.0}, {"text": "And all I can say for sure is that very big chunk will not work", "timestamp": "00:10:46,162", "timestamp_s": 646.0}, {"text": "very well and it\u0027s kind of intuitive. The vector size is", "timestamp": "00:10:49,674", "timestamp_s": 649.0}, {"text": "static and if you try to squeeze too much information into", "timestamp": "00:10:53,202", "timestamp_s": 653.0}, {"text": "it, you will lose some of it.", "timestamp": "00:10:56,954", "timestamp_s": 656.0}, {"text": "But other than that, when you split the document, you need", "timestamp": "00:11:00,274", "timestamp_s": 660.0}, {"text": "to know something about the context. And a good", "timestamp": "00:11:04,178", "timestamp_s": 664.0}, {"text": "example would be a large PDF, and having just a chunk", "timestamp": "00:11:07,954", "timestamp_s": 667.0}, {"text": "of it without knowing which chapter or which section it", "timestamp": "00:11:11,290", "timestamp_s": 671.0}, {"text": "comes from, it will not be very helpful.", "timestamp": "00:11:14,522", "timestamp_s": 674.0}, {"text": "That\u0027s why it\u0027s important to keep the relevant information as part", "timestamp": "00:11:18,388", "timestamp_s": 678.0}, {"text": "of the chunk or as part of the metadata.", "timestamp": "00:11:22,468", "timestamp_s": 682.0}, {"text": "And if you Google search for what, if the data is too", "timestamp": "00:11:27,804", "timestamp_s": 687.0}, {"text": "large for LLM context, or if you just scan the QR code,", "timestamp": "00:11:31,540", "timestamp_s": 691.0}, {"text": "you will get to one of our articles describing these kind of problems.", "timestamp": "00:11:35,244", "timestamp_s": 695.0}, {"text": "But we also described there a mechanism called self", "timestamp": "00:11:39,236", "timestamp_s": 699.0}, {"text": "core retriever and it\u0027s super useful in situations", "timestamp": "00:11:42,594", "timestamp_s": 702.0}, {"text": "when you have a granular split with all the details necessary.", "timestamp": "00:11:45,922", "timestamp_s": 705.0}, {"text": "But still the vector similarity of multiple chunks is too", "timestamp": "00:11:50,178", "timestamp_s": 710.0}, {"text": "close to each other and it\u0027s hard to distinct", "timestamp": "00:11:53,882", "timestamp_s": 713.0}, {"text": "which one is the best in a given situation. And in", "timestamp": "00:11:57,922", "timestamp_s": 717.0}, {"text": "such cases it\u0027s good to try the mechanism and", "timestamp": "00:12:01,842", "timestamp_s": 721.0}, {"text": "what it does. It\u0027s basically a tool in LangChain", "timestamp": "00:12:06,298", "timestamp_s": 726.0}, {"text": "which allows us to come up with structured query", "timestamp": "00:12:10,704", "timestamp_s": 730.0}, {"text": "for specific attributes you predefined. So let\u0027s say from", "timestamp": "00:12:14,792", "timestamp_s": 734.0}, {"text": "a PDF chunk you will extract price or", "timestamp": "00:12:19,152", "timestamp_s": 739.0}, {"text": "offer name. And if you predefined them,", "timestamp": "00:12:23,496", "timestamp_s": 743.0}, {"text": "you can have another LLM call for better understanding", "timestamp": "00:12:27,792", "timestamp_s": 747.0}, {"text": "of values of these kind of attributes. So you,", "timestamp": "00:12:31,760", "timestamp_s": 751.0}, {"text": "you can make better decision. You can make a better decision", "timestamp": "00:12:35,816", "timestamp_s": 755.0}, {"text": "about what answer to present to the user and it\u0027s very useful.", "timestamp": "00:12:39,612", "timestamp_s": 759.0}, {"text": "I recommend you to read up on that.", "timestamp": "00:12:44,372", "timestamp_s": 764.0}, {"text": "But let\u0027s move on. One more", "timestamp": "00:12:47,324", "timestamp_s": 767.0}, {"text": "disclaimer, one more disclaimer about PDF files I mentioned.", "timestamp": "00:12:51,260", "timestamp_s": 771.0}, {"text": "The disclaimer is that a lot will depend on the format", "timestamp": "00:12:54,844", "timestamp_s": 774.0}, {"text": "and how exactly you parse the PDF. Sometimes you", "timestamp": "00:12:58,292", "timestamp_s": 778.0}, {"text": "need to just find a specific parser for a specific document,", "timestamp": "00:13:02,248", "timestamp_s": 782.0}, {"text": "but sometimes maybe it\u0027s worth looking around.", "timestamp": "00:13:05,832", "timestamp_s": 785.0}, {"text": "Maybe you have a chance to get the data you need from a source", "timestamp": "00:13:09,560", "timestamp_s": 789.0}, {"text": "which has structure just better than the PDF file.", "timestamp": "00:13:12,992", "timestamp_s": 792.0}, {"text": "Maybe the same data exists in better format.", "timestamp": "00:13:17,080", "timestamp_s": 797.0}, {"text": "So far we\u0027ve been focusing on how we can improve", "timestamp": "00:13:21,264", "timestamp_s": 801.0}, {"text": "the vector search by splitting the documents.", "timestamp": "00:13:24,752", "timestamp_s": 804.0}, {"text": "But what else we can do in order to improve", "timestamp": "00:13:28,544", "timestamp_s": 808.0}, {"text": "the vector search, you can use something else instead of", "timestamp": "00:13:31,928", "timestamp_s": 811.0}, {"text": "vector search. And I just wanted to say that vector databases", "timestamp": "00:13:35,440", "timestamp_s": 815.0}, {"text": "are very popular. They are growing, they are very", "timestamp": "00:13:39,904", "timestamp_s": 819.0}, {"text": "natural to be used in context of natural language processing.", "timestamp": "00:13:43,232", "timestamp_s": 823.0}, {"text": "But just the fact that they are popular, just the fact that", "timestamp": "00:13:46,960", "timestamp_s": 826.0}, {"text": "they are very much connected with our lens,", "timestamp": "00:13:50,960", "timestamp_s": 830.0}, {"text": "does not mean this is the only tool you can use.", "timestamp": "00:13:54,376", "timestamp_s": 834.0}, {"text": "So for instance, if you have an elasticsearch,", "timestamp": "00:13:58,254", "timestamp_s": 838.0}, {"text": "or if you have some search API in your company, there is", "timestamp": "00:14:01,454", "timestamp_s": 841.0}, {"text": "really no reason not to use it, not to try,", "timestamp": "00:14:04,750", "timestamp_s": 844.0}, {"text": "if it can provide you with relevant info. And at the", "timestamp": "00:14:07,902", "timestamp_s": 847.0}, {"text": "same time, most of the vector databases, they come", "timestamp": "00:14:11,678", "timestamp_s": 851.0}, {"text": "up with not only the vector search ability,", "timestamp": "00:14:15,086", "timestamp_s": 855.0}, {"text": "but they have hybrid search ability.", "timestamp": "00:14:18,974", "timestamp_s": 858.0}, {"text": "So on top of vector search, you can", "timestamp": "00:14:21,814", "timestamp_s": 861.0}, {"text": "enable more traditional keyword search, for example", "timestamp": "00:14:25,668", "timestamp_s": 865.0}, {"text": "BM 25, and you can verify which results", "timestamp": "00:14:29,092", "timestamp_s": 869.0}, {"text": "are better. Maybe you can mix them together. Maybe you can", "timestamp": "00:14:32,652", "timestamp_s": 872.0}, {"text": "use both results. And once", "timestamp": "00:14:36,132", "timestamp_s": 876.0}, {"text": "you mix them together, once you utilize data from multiple", "timestamp": "00:14:39,956", "timestamp_s": 879.0}, {"text": "search methods, what you can do is you can re", "timestamp": "00:14:43,996", "timestamp_s": 883.0}, {"text": "rank the responses you received. So in many", "timestamp": "00:14:47,612", "timestamp_s": 887.0}, {"text": "of our cases we have implemented, we realized", "timestamp": "00:14:51,388", "timestamp_s": 891.0}, {"text": "that it makes a lot of sense to blend", "timestamp": "00:14:55,452", "timestamp_s": 895.0}, {"text": "multiple sources, multiple results,", "timestamp": "00:14:58,908", "timestamp_s": 898.0}, {"text": "blend them together. And what you can consider, except of", "timestamp": "00:15:02,956", "timestamp_s": 902.0}, {"text": "vector databases, is data coming directly from backend database,", "timestamp": "00:15:07,764", "timestamp_s": 907.0}, {"text": "from data lake, from data warehouse, internal APIs,", "timestamp": "00:15:11,756", "timestamp_s": 911.0}, {"text": "but also external APIs like panel", "timestamp": "00:15:15,924", "timestamp_s": 915.0}, {"text": "data, or from Google search.", "timestamp": "00:15:19,696", "timestamp_s": 919.0}, {"text": "So far we\u0027ve been focusing on how we can improve the", "timestamp": "00:15:23,704", "timestamp_s": 923.0}, {"text": "vector search by splitting the documents.", "timestamp": "00:15:27,616", "timestamp_s": 927.0}, {"text": "But what else we can do in order to improve", "timestamp": "00:15:30,984", "timestamp_s": 930.0}, {"text": "the vector search, you can use something else instead of vector", "timestamp": "00:15:34,376", "timestamp_s": 934.0}, {"text": "search. And I just wanted to say that vector", "timestamp": "00:15:38,304", "timestamp_s": 938.0}, {"text": "databases are very popular, they are growing, they are very", "timestamp": "00:15:41,736", "timestamp_s": 941.0}, {"text": "natural to be used in context of natural language processing.", "timestamp": "00:15:45,682", "timestamp_s": 945.0}, {"text": "But just the fact that they are popular,", "timestamp": "00:15:49,450", "timestamp_s": 949.0}, {"text": "just the fact that they are very much connected with llms", "timestamp": "00:15:52,298", "timestamp_s": 952.0}, {"text": "does not mean this is the only tool you can use.", "timestamp": "00:15:56,818", "timestamp_s": 956.0}, {"text": "So for instance, if you have an elasticsearch, or if", "timestamp": "00:16:00,714", "timestamp_s": 960.0}, {"text": "you have some search API in your company, there is really no reason", "timestamp": "00:16:04,370", "timestamp_s": 964.0}, {"text": "not to use it, not to try, if it can provide you with", "timestamp": "00:16:08,378", "timestamp_s": 968.0}, {"text": "relevant info. And at the same time, most of", "timestamp": "00:16:11,824", "timestamp_s": 971.0}, {"text": "the vector databases, they come up with not only the", "timestamp": "00:16:15,624", "timestamp_s": 975.0}, {"text": "vector search ability, but they have hybrid", "timestamp": "00:16:19,584", "timestamp_s": 979.0}, {"text": "search ability. So on top of vector search,", "timestamp": "00:16:23,464", "timestamp_s": 983.0}, {"text": "you can enable more traditional keyword search,", "timestamp": "00:16:27,208", "timestamp_s": 987.0}, {"text": "for example BM 25, and you can verify", "timestamp": "00:16:30,928", "timestamp_s": 990.0}, {"text": "which results are better. Maybe you can mix them together.", "timestamp": "00:16:34,336", "timestamp_s": 994.0}, {"text": "Maybe you can use both results. And once", "timestamp": "00:16:37,898", "timestamp_s": 997.0}, {"text": "you mix them together, once you utilize data from", "timestamp": "00:16:42,186", "timestamp_s": 1002.0}, {"text": "multiple search methods. What you can do is you can", "timestamp": "00:16:45,738", "timestamp_s": 1005.0}, {"text": "rerank the responses you received. So in many", "timestamp": "00:16:49,666", "timestamp_s": 1009.0}, {"text": "of our cases we have implemented,", "timestamp": "00:16:53,618", "timestamp_s": 1013.0}, {"text": "we realized that it makes a lot of", "timestamp": "00:16:56,298", "timestamp_s": 1016.0}, {"text": "sense to blend multiple sources, multiple result,", "timestamp": "00:17:00,186", "timestamp_s": 1020.0}, {"text": "blend them together. And what you can consider,", "timestamp": "00:17:05,216", "timestamp_s": 1025.0}, {"text": "except of vector databases, is data coming directly", "timestamp": "00:17:08,472", "timestamp_s": 1028.0}, {"text": "from backend database, from data lake, from data", "timestamp": "00:17:12,704", "timestamp_s": 1032.0}, {"text": "warehouse, internal APIs, but also external", "timestamp": "00:17:16,088", "timestamp_s": 1036.0}, {"text": "APIs like panel data or from", "timestamp": "00:17:20,568", "timestamp_s": 1040.0}, {"text": "Google search. And then on top of", "timestamp": "00:17:24,088", "timestamp_s": 1044.0}, {"text": "quite aggressive query query, which is providing us with many", "timestamp": "00:17:27,768", "timestamp_s": 1047.0}, {"text": "results, what we do, we do re rank and we select", "timestamp": "00:17:31,404", "timestamp_s": 1051.0}, {"text": "the best candidates, the candidates which are the most promising.", "timestamp": "00:17:34,836", "timestamp_s": 1054.0}, {"text": "So the chatbot can utilize the information from the most promising ones", "timestamp": "00:17:38,964", "timestamp_s": 1058.0}, {"text": "in coming up with the most relevant answer.", "timestamp": "00:17:43,108", "timestamp_s": 1063.0}, {"text": "The last technique I wanted to mention, and it\u0027s actually quite", "timestamp": "00:17:47,044", "timestamp_s": 1067.0}, {"text": "simple but still quite powerful, is preprocessing", "timestamp": "00:17:50,476", "timestamp_s": 1070.0}, {"text": "using large language models. So let\u0027s say you", "timestamp": "00:17:54,460", "timestamp_s": 1074.0}, {"text": "have some metadata, but in your metadata, you don\u0027t", "timestamp": "00:17:58,224", "timestamp_s": 1078.0}, {"text": "have any information if an apartment has an elevator", "timestamp": "00:18:02,072", "timestamp_s": 1082.0}, {"text": "or not. But the customers are looking for this kind", "timestamp": "00:18:06,232", "timestamp_s": 1086.0}, {"text": "of information. And you do have that information in", "timestamp": "00:18:09,600", "timestamp_s": 1089.0}, {"text": "the description in a free text. So what you can", "timestamp": "00:18:13,808", "timestamp_s": 1093.0}, {"text": "do a batch preprocessing", "timestamp": "00:18:17,376", "timestamp_s": 1097.0}, {"text": "using LLM in search for specific metadata,", "timestamp": "00:18:20,584", "timestamp_s": 1100.0}, {"text": "you know, users are often looking for. And then", "timestamp": "00:18:24,360", "timestamp_s": 1104.0}, {"text": "once you extract the metadata, you can just save it. You can enrich", "timestamp": "00:18:28,532", "timestamp_s": 1108.0}, {"text": "your database and use it in your queries.", "timestamp": "00:18:32,628", "timestamp_s": 1112.0}, {"text": "So basically, you are utilizing the fact that LLMs are", "timestamp": "00:18:36,172", "timestamp_s": 1116.0}, {"text": "very, very good in tasks like sentiment analysis,", "timestamp": "00:18:40,452", "timestamp_s": 1120.0}, {"text": "text categorization and so on. You just", "timestamp": "00:18:43,788", "timestamp_s": 1123.0}, {"text": "tell them which category you are looking for,", "timestamp": "00:18:47,716", "timestamp_s": 1127.0}, {"text": "what information you are looking for, and they do it for you. They do", "timestamp": "00:18:51,054", "timestamp_s": 1131.0}, {"text": "it basically out of the box. They are", "timestamp": "00:18:54,670", "timestamp_s": 1134.0}, {"text": "good at this kind of tasks, out of the box. So there is really", "timestamp": "00:18:57,942", "timestamp_s": 1137.0}, {"text": "no reason not to, not to use that fact.", "timestamp": "00:19:01,502", "timestamp_s": 1141.0}, {"text": "Okay, so we\u0027ve been talking about techniques which leads us to providing the", "timestamp": "00:19:04,934", "timestamp_s": 1144.0}, {"text": "most relevant information to the chatbot. But even if", "timestamp": "00:19:08,950", "timestamp_s": 1148.0}, {"text": "you provide it with very, very relevant information, it\u0027s still", "timestamp": "00:19:12,470", "timestamp_s": 1152.0}, {"text": "can make a mistake. It still can hallucinate. So yes,", "timestamp": "00:19:16,630", "timestamp_s": 1156.0}, {"text": "one way of preventing or limiting the hallucination is to provide", "timestamp": "00:19:20,892", "timestamp_s": 1160.0}, {"text": "it with relevant info, but there is really", "timestamp": "00:19:24,548", "timestamp_s": 1164.0}, {"text": "no guarantee that the answer chat comes up with based on the prompt,", "timestamp": "00:19:27,828", "timestamp_s": 1167.0}, {"text": "the data you provided provided with,", "timestamp": "00:19:31,820", "timestamp_s": 1171.0}, {"text": "there is no guarantee that the information produced by the", "timestamp": "00:19:34,964", "timestamp_s": 1174.0}, {"text": "chatbot is correct. So I will show you a very quick demo of what", "timestamp": "00:19:38,468", "timestamp_s": 1178.0}, {"text": "the hallucination looks like and one specific technique", "timestamp": "00:19:42,676", "timestamp_s": 1182.0}, {"text": "which you could use in your project in", "timestamp": "00:19:46,158", "timestamp_s": 1186.0}, {"text": "order to prevent the hallucination. So let\u0027s have a look at the demo I", "timestamp": "00:19:49,470", "timestamp_s": 1189.0}, {"text": "recorded. Let\u0027s have a look.", "timestamp": "00:19:53,414", "timestamp_s": 1193.0}, {"text": "What we have is Python code where we import a", "timestamp": "00:19:57,854", "timestamp_s": 1197.0}, {"text": "tool called nemo guardrails. It\u0027s a tool created by Nvidia.", "timestamp": "00:20:01,846", "timestamp_s": 1201.0}, {"text": "And we have a text file with some questions.", "timestamp": "00:20:06,254", "timestamp_s": 1206.0}, {"text": "We\u0027ll have a look at it in a second. And then we define that we", "timestamp": "00:20:10,022", "timestamp_s": 1210.0}, {"text": "want to use an old OpenAI model text, davinci zero three.", "timestamp": "00:20:13,348", "timestamp_s": 1213.0}, {"text": "And then in the file we define some", "timestamp": "00:20:18,044", "timestamp_s": 1218.0}, {"text": "questions. The first question", "timestamp": "00:20:21,388", "timestamp_s": 1221.0}, {"text": "we define is when did", "timestamp": "00:20:25,180", "timestamp_s": 1225.0}, {"text": "the roman empire collapse? So we want to ask that question", "timestamp": "00:20:28,612", "timestamp_s": 1228.0}, {"text": "to the model. And I am asking the question about the", "timestamp": "00:20:32,508", "timestamp_s": 1232.0}, {"text": "roman empire because it\u0027s a common knowledge. And the second", "timestamp": "00:20:36,332", "timestamp_s": 1236.0}, {"text": "question I\u0027m asking is how", "timestamp": "00:20:40,360", "timestamp_s": 1240.0}, {"text": "many goals has been scored in polish extraclass in a specific season?", "timestamp": "00:20:43,744", "timestamp_s": 1243.0}, {"text": "So since the first question is a common knowledge and the second one", "timestamp": "00:20:47,704", "timestamp_s": 1247.0}, {"text": "is not, I expect one of the questions not to be", "timestamp": "00:20:51,224", "timestamp_s": 1251.0}, {"text": "the hallucination, one of the answer to the question not to be the", "timestamp": "00:20:54,960", "timestamp_s": 1254.0}, {"text": "hallucination, and one of them. For one of them,", "timestamp": "00:20:58,288", "timestamp_s": 1258.0}, {"text": "I do expect the model to hallucinate. And let\u0027s see if the", "timestamp": "00:21:01,752", "timestamp_s": 1261.0}, {"text": "tool can spot what is hallucination, what is not.", "timestamp": "00:21:04,952", "timestamp_s": 1264.0}, {"text": "So let\u0027s see, we run the code and", "timestamp": "00:21:09,464", "timestamp_s": 1269.0}, {"text": "we will have a lot of logs. And once", "timestamp": "00:21:14,608", "timestamp_s": 1274.0}, {"text": "we scroll all the way up, after it completes,", "timestamp": "00:21:18,776", "timestamp_s": 1278.0}, {"text": "after it completes, we can see the", "timestamp": "00:21:22,784", "timestamp_s": 1282.0}, {"text": "first question, when did the roman empire collapse?", "timestamp": "00:21:26,672", "timestamp_s": 1286.0}, {"text": "And we get a bottle some bot responses", "timestamp": "00:21:29,624", "timestamp_s": 1289.0}, {"text": "and it\u0027s getting flagged as not hallucination.", "timestamp": "00:21:32,916", "timestamp_s": 1292.0}, {"text": "But how exactly did the tool spot", "timestamp": "00:21:36,164", "timestamp_s": 1296.0}, {"text": "that? Let\u0027s have a look into the details. Using the second question", "timestamp": "00:21:39,404", "timestamp_s": 1299.0}, {"text": "as an example, how many goals has been scored in polish extraclassa?", "timestamp": "00:21:43,148", "timestamp_s": 1303.0}, {"text": "The bot response we are receiving is 1800.", "timestamp": "00:21:47,484", "timestamp_s": 1307.0}, {"text": "I have no idea if it\u0027s correct or not, but the whole point is that", "timestamp": "00:21:51,804", "timestamp_s": 1311.0}, {"text": "what the tool is doing, it\u0027s asking exactly the same question for the second time,", "timestamp": "00:21:55,484", "timestamp_s": 1315.0}, {"text": "and then we get completely different response,", "timestamp": "00:21:59,944", "timestamp_s": 1319.0}, {"text": "and then the tool is asking the same question for the third", "timestamp": "00:22:03,464", "timestamp_s": 1323.0}, {"text": "time and you\u0027re getting, once again different", "timestamp": "00:22:07,216", "timestamp_s": 1327.0}, {"text": "response. And then what the tool", "timestamp": "00:22:10,696", "timestamp_s": 1330.0}, {"text": "is doing is actually checking if the answers", "timestamp": "00:22:14,376", "timestamp_s": 1334.0}, {"text": "we are getting are in sync, if the", "timestamp": "00:22:19,072", "timestamp_s": 1339.0}, {"text": "meaning of them is exactly the same. So it\u0027s actually doing another prompt", "timestamp": "00:22:23,432", "timestamp_s": 1343.0}, {"text": "to the model. And the prompt is", "timestamp": "00:22:27,280", "timestamp_s": 1347.0}, {"text": "you are given a task to identify if the hypothesis", "timestamp": "00:22:30,538", "timestamp_s": 1350.0}, {"text": "is in agreement with the context below and", "timestamp": "00:22:34,514", "timestamp_s": 1354.0}, {"text": "the hypothesis is the original answer", "timestamp": "00:22:37,858", "timestamp_s": 1357.0}, {"text": "we received. So the answer to the first", "timestamp": "00:22:42,426", "timestamp_s": 1362.0}, {"text": "time we ask that question and then context", "timestamp": "00:22:46,250", "timestamp_s": 1366.0}, {"text": "are two extra responses we have received because the", "timestamp": "00:22:51,194", "timestamp_s": 1371.0}, {"text": "tool was asking the same question three times and the", "timestamp": "00:22:55,058", "timestamp_s": 1375.0}, {"text": "answer from the model is no", "timestamp": "00:22:59,294", "timestamp_s": 1379.0}, {"text": "informations are not, which means", "timestamp": "00:23:03,374", "timestamp_s": 1383.0}, {"text": "we flag it as hallucination. So yeah,", "timestamp": "00:23:07,014", "timestamp_s": 1387.0}, {"text": "there are ways of preventing the hallucinations. It\u0027s good to", "timestamp": "00:23:11,326", "timestamp_s": 1391.0}, {"text": "be aware of them, but at the same time it\u0027s good to be aware of", "timestamp": "00:23:14,918", "timestamp_s": 1394.0}, {"text": "consequences of these kind of techniques, because there is no such thing", "timestamp": "00:23:18,206", "timestamp_s": 1398.0}, {"text": "as free lunch. First of all, you need to be aware of the costs", "timestamp": "00:23:21,606", "timestamp_s": 1401.0}, {"text": "associated with that. The cost of us dollars you", "timestamp": "00:23:25,714", "timestamp_s": 1405.0}, {"text": "pay for the extra API, call the cost of", "timestamp": "00:23:29,202", "timestamp_s": 1409.0}, {"text": "slower system because you make extra API, so you introduce an", "timestamp": "00:23:32,858", "timestamp_s": 1412.0}, {"text": "extra delay, but also the cost of false positive,", "timestamp": "00:23:36,610", "timestamp_s": 1416.0}, {"text": "because there is really no guarantee that this kind of technique always", "timestamp": "00:23:40,226", "timestamp_s": 1420.0}, {"text": "works. But all that,", "timestamp": "00:23:44,762", "timestamp_s": 1424.0}, {"text": "the existence of hallucinations, the fact that we", "timestamp": "00:23:48,690", "timestamp_s": 1428.0}, {"text": "have to deal with them, but also how we have to experiment", "timestamp": "00:23:52,358", "timestamp_s": 1432.0}, {"text": "with cutting the documents, how we have to tune the search", "timestamp": "00:23:56,214", "timestamp_s": 1436.0}, {"text": "engine, all of that can lead to the conclusion that we are back to", "timestamp": "00:23:59,326", "timestamp_s": 1439.0}, {"text": "square one to some extent, and that there is really no shortcut.", "timestamp": "00:24:02,990", "timestamp_s": 1442.0}, {"text": "And even though LLMs are really impressive,", "timestamp": "00:24:07,462", "timestamp_s": 1447.0}, {"text": "you cannot avoid working on the data quality", "timestamp": "00:24:11,518", "timestamp_s": 1451.0}, {"text": "or just careful engineering. Tools like llms", "timestamp": "00:24:14,678", "timestamp_s": 1454.0}, {"text": "are impressive, but you still have to do your homework.", "timestamp": "00:24:18,934", "timestamp_s": 1458.0}, {"text": "The good news is that there are many tools which could", "timestamp": "00:24:23,854", "timestamp_s": 1463.0}, {"text": "help you to some extent. So I mentioned Nemo guardiols,", "timestamp": "00:24:27,910", "timestamp_s": 1467.0}, {"text": "but it\u0027s worth looking into memgpt weaviate but", "timestamp": "00:24:31,470", "timestamp_s": 1471.0}, {"text": "at the same time, do not expect that some tool will solve", "timestamp": "00:24:35,478", "timestamp_s": 1475.0}, {"text": "all your problems. Do not expect", "timestamp": "00:24:39,358", "timestamp_s": 1479.0}, {"text": "that you buy some tool which will magically solve everything.", "timestamp": "00:24:43,684", "timestamp_s": 1483.0}, {"text": "This approach, shut up and take my money will", "timestamp": "00:24:47,900", "timestamp_s": 1487.0}, {"text": "probably not work. It\u0027s not gonna happen. The tool might", "timestamp": "00:24:51,356", "timestamp_s": 1491.0}, {"text": "be helpful, but the tools themselves are coming", "timestamp": "00:24:55,092", "timestamp_s": 1495.0}, {"text": "with their own problems. The tools themselves are quite", "timestamp": "00:24:58,444", "timestamp_s": 1498.0}, {"text": "immature because basically the entire area of large language models,", "timestamp": "00:25:02,460", "timestamp_s": 1502.0}, {"text": "chatbots and so on, is quite", "timestamp": "00:25:07,108", "timestamp_s": 1507.0}, {"text": "new, quite fresh. And just", "timestamp": "00:25:10,786", "timestamp_s": 1510.0}, {"text": "to show you an example of how the", "timestamp": "00:25:14,530", "timestamp_s": 1514.0}, {"text": "tools are changing, this is the history of code in Lancranc", "timestamp": "00:25:17,714", "timestamp_s": 1517.0}, {"text": "project. And there are tons of changes, which on", "timestamp": "00:25:21,490", "timestamp_s": 1521.0}, {"text": "one hand is a good thing because the project is evolving and it\u0027s actually", "timestamp": "00:25:25,090", "timestamp_s": 1525.0}, {"text": "impressive how fast it\u0027s growing. But on", "timestamp": "00:25:28,658", "timestamp_s": 1528.0}, {"text": "the other hand, that means you have to be aware", "timestamp": "00:25:31,858", "timestamp_s": 1531.0}, {"text": "of the updates, upcoming changes, there will be some bugs introduced,", "timestamp": "00:25:35,160", "timestamp_s": 1535.0}, {"text": "there will be some breaking changes over time, and you just", "timestamp": "00:25:39,248", "timestamp_s": 1539.0}, {"text": "need to be ready for that. You just need to be aware", "timestamp": "00:25:43,016", "timestamp_s": 1543.0}, {"text": "of that. So we have all the tools which are helpful,", "timestamp": "00:25:46,232", "timestamp_s": 1546.0}, {"text": "but not very stable yet, and we are working with a completely", "timestamp": "00:25:50,040", "timestamp_s": 1550.0}, {"text": "new area and there is a lot of unknown here. And that is why it", "timestamp": "00:25:53,616", "timestamp_s": 1553.0}, {"text": "is really important that you do the testing. And testing of", "timestamp": "00:25:56,816", "timestamp_s": 1556.0}, {"text": "LLM project is really, really tricky. So what you", "timestamp": "00:26:00,270", "timestamp_s": 1560.0}, {"text": "can do for sure, and what you should do is testing of", "timestamp": "00:26:03,726", "timestamp_s": 1563.0}, {"text": "the retrieval because this is fully under your control and", "timestamp": "00:26:07,510", "timestamp_s": 1567.0}, {"text": "this is quite predictable. So it\u0027s easy to define the test condition,", "timestamp": "00:26:11,270", "timestamp_s": 1571.0}, {"text": "but you should also test", "timestamp": "00:26:15,094", "timestamp_s": 1575.0}, {"text": "the LLM actions wherever you can.", "timestamp": "00:26:18,462", "timestamp_s": 1578.0}, {"text": "And I say wherever you can because it\u0027s actually quite tricky", "timestamp": "00:26:22,214", "timestamp_s": 1582.0}, {"text": "and it\u0027s very hard to define reliable tests,", "timestamp": "00:26:26,262", "timestamp_s": 1586.0}, {"text": "reliable tests which cover most of the possibilities.", "timestamp": "00:26:29,752", "timestamp_s": 1589.0}, {"text": "And one of the problem with testing llms is that even if", "timestamp": "00:26:33,664", "timestamp_s": 1593.0}, {"text": "you have exactly the same input in", "timestamp": "00:26:37,400", "timestamp_s": 1597.0}, {"text": "your test, the output could vary.", "timestamp": "00:26:40,600", "timestamp_s": 1600.0}, {"text": "So there is this post on OpenAI forum, and I really recommend", "timestamp": "00:26:45,184", "timestamp_s": 1605.0}, {"text": "you to read the question of determinism.", "timestamp": "00:26:48,632", "timestamp_s": 1608.0}, {"text": "The bottom line is that large language model action is not really", "timestamp": "00:26:52,464", "timestamp_s": 1612.0}, {"text": "deterministic. So yeah, you can have the parameters", "timestamp": "00:26:56,488", "timestamp_s": 1616.0}, {"text": "like temperature, you can set it, and this should control", "timestamp": "00:27:00,212", "timestamp_s": 1620.0}, {"text": "how creative the model is. But there is this misconception", "timestamp": "00:27:04,052", "timestamp_s": 1624.0}, {"text": "that if you set it to zero, LLM will be behaving", "timestamp": "00:27:07,612", "timestamp_s": 1627.0}, {"text": "in exactly the same way. In reality it will be", "timestamp": "00:27:11,124", "timestamp_s": 1631.0}, {"text": "just kind of less creative.", "timestamp": "00:27:14,852", "timestamp_s": 1634.0}, {"text": "But it still might provide you with various results,", "timestamp": "00:27:18,108", "timestamp_s": 1638.0}, {"text": "mostly because of the hardware it\u0027s being physically run on. But also", "timestamp": "00:27:21,700", "timestamp_s": 1641.0}, {"text": "you can always end up with two tokens which have exactly the same probability.", "timestamp": "00:27:25,366", "timestamp_s": 1645.0}, {"text": "So one or the other will be randomly selected in your result.", "timestamp": "00:27:30,014", "timestamp_s": 1650.0}, {"text": "So keep that in mind when you write the test,", "timestamp": "00:27:34,334", "timestamp_s": 1654.0}, {"text": "and it\u0027s always worth checking the lang chain utils", "timestamp": "00:27:37,734", "timestamp_s": 1657.0}, {"text": "lang chain utils for testing because they take this kind of", "timestamp": "00:27:41,894", "timestamp_s": 1661.0}, {"text": "lack of determinism into consideration and they aim to mitigate", "timestamp": "00:27:45,814", "timestamp_s": 1665.0}, {"text": "it during testing. But what is critical", "timestamp": "00:27:50,254", "timestamp_s": 1670.0}, {"text": "when you move to production is that you collect the data from your", "timestamp": "00:27:54,528", "timestamp_s": 1674.0}, {"text": "run, from your run with real users,", "timestamp": "00:27:58,416", "timestamp_s": 1678.0}, {"text": "because that is really something which gives you the real feedback", "timestamp": "00:28:01,696", "timestamp_s": 1681.0}, {"text": "about how it is going, how the users are using the application,", "timestamp": "00:28:05,176", "timestamp_s": 1685.0}, {"text": "whether they are happy with that or not. Make sure you", "timestamp": "00:28:09,744", "timestamp_s": 1689.0}, {"text": "collect the data. Make sure you analyze that, especially in the", "timestamp": "00:28:13,280", "timestamp_s": 1693.0}, {"text": "early phases of of the project.", "timestamp": "00:28:16,632", "timestamp_s": 1696.0}, {"text": "Let\u0027s have a look at legal and privacy aspects of llms.", "timestamp": "00:28:19,564", "timestamp_s": 1699.0}, {"text": "What we need to understand is that whenever we", "timestamp": "00:28:23,964", "timestamp_s": 1703.0}, {"text": "pull the data from any database and then process", "timestamp": "00:28:27,140", "timestamp_s": 1707.0}, {"text": "the data and then eventually pass", "timestamp": "00:28:30,524", "timestamp_s": 1710.0}, {"text": "the data to LLM, our data is being sent to the", "timestamp": "00:28:34,700", "timestamp_s": 1714.0}, {"text": "LLM provider, to OpenAI, to Microsoft,", "timestamp": "00:28:38,092", "timestamp_s": 1718.0}, {"text": "Google, and in some cases it\u0027s perfectly fine. But there", "timestamp": "00:28:41,244", "timestamp_s": 1721.0}, {"text": "are cases that you don\u0027t want to send the data", "timestamp": "00:28:45,212", "timestamp_s": 1725.0}, {"text": "anywhere because it\u0027s too sensitive. And that means that", "timestamp": "00:28:48,780", "timestamp_s": 1728.0}, {"text": "you might want to use an open source LLM installed in", "timestamp": "00:28:52,596", "timestamp_s": 1732.0}, {"text": "a data center you own.", "timestamp": "00:28:56,708", "timestamp_s": 1736.0}, {"text": "Keep in mind that in situations when LLM over API", "timestamp": "00:29:00,084", "timestamp_s": 1740.0}, {"text": "is not possible, you not only have to have a private", "timestamp": "00:29:03,564", "timestamp_s": 1743.0}, {"text": "LLM installation, you also need to have", "timestamp": "00:29:07,532", "timestamp_s": 1747.0}, {"text": "your private embedding, private vector, DB and", "timestamp": "00:29:10,692", "timestamp_s": 1750.0}, {"text": "so on. And installing all that is not a rocket science,", "timestamp": "00:29:14,262", "timestamp_s": 1754.0}, {"text": "but at the same time. It increases the complexity of your ecosystem", "timestamp": "00:29:18,078", "timestamp_s": 1758.0}, {"text": "and there is a lot more that you have to maintain.", "timestamp": "00:29:22,134", "timestamp_s": 1762.0}, {"text": "And let\u0027s keep in mind that privacy and where the data is being sent", "timestamp": "00:29:26,774", "timestamp_s": 1766.0}, {"text": "is just one aspect of legal concerns when it comes to llms.", "timestamp": "00:29:30,582", "timestamp_s": 1770.0}, {"text": "I would really recommend to read the license terms of", "timestamp": "00:29:34,822", "timestamp_s": 1774.0}, {"text": "the ones you plan to use. For instance, you should not", "timestamp": "00:29:38,878", "timestamp_s": 1778.0}, {"text": "get misled by the term open source. Open source", "timestamp": "00:29:42,414", "timestamp_s": 1782.0}, {"text": "does not automatically mean that you can do everything with it.", "timestamp": "00:29:46,462", "timestamp_s": 1786.0}, {"text": "Some of open source licenses are limiting how you can use the", "timestamp": "00:29:50,086", "timestamp_s": 1790.0}, {"text": "data produced by the LLM. So for instance, you won\u0027t", "timestamp": "00:29:53,750", "timestamp_s": 1793.0}, {"text": "be able to use the data you collected for training another", "timestamp": "00:29:57,830", "timestamp_s": 1797.0}, {"text": "LLM in case you decide to change the model.", "timestamp": "00:30:01,798", "timestamp_s": 1801.0}, {"text": "So you collect the data from the chatbot. You cannot use that in the future", "timestamp": "00:30:05,904", "timestamp_s": 1805.0}, {"text": "for the training purposes. Similarly,", "timestamp": "00:30:10,424", "timestamp_s": 1810.0}, {"text": "generating synthetic data for machine learning model is very", "timestamp": "00:30:13,600", "timestamp_s": 1813.0}, {"text": "blurry area when it gets to llms. So once", "timestamp": "00:30:17,240", "timestamp_s": 1817.0}, {"text": "again, don\u0027t assume too much and make", "timestamp": "00:30:21,072", "timestamp_s": 1821.0}, {"text": "sure you don\u0027t get into the unpleasant surprises.", "timestamp": "00:30:24,504", "timestamp_s": 1824.0}, {"text": "Another very important consideration when starting a project", "timestamp": "00:30:29,344", "timestamp_s": 1829.0}, {"text": "and deciding which LLM to use is cost. And you might think", "timestamp": "00:30:33,224", "timestamp_s": 1833.0}, {"text": "open source is cheaper because you basically don\u0027t pay for the API call.", "timestamp": "00:30:36,930", "timestamp_s": 1836.0}, {"text": "But in context of Llm it\u0027s not that obvious.", "timestamp": "00:30:40,898", "timestamp_s": 1840.0}, {"text": "And why is that? First of all,", "timestamp": "00:30:44,514", "timestamp_s": 1844.0}, {"text": "because simple math is not that simple anymore.", "timestamp": "00:30:47,514", "timestamp_s": 1847.0}, {"text": "And what do I mean by the simple math?", "timestamp": "00:30:50,994", "timestamp_s": 1850.0}, {"text": "Let\u0027s start with the API calls. For instance,", "timestamp": "00:30:54,194", "timestamp_s": 1854.0}, {"text": "when you are using GPT 3.5, you pay", "timestamp": "00:30:57,330", "timestamp_s": 1857.0}, {"text": "half a dollar per million tokens in the input and then", "timestamp": "00:31:00,614", "timestamp_s": 1860.0}, {"text": "$1.5 for million tokens in the output.", "timestamp": "00:31:03,814", "timestamp_s": 1863.0}, {"text": "But then for GPT four you pay 30", "timestamp": "00:31:07,558", "timestamp_s": 1867.0}, {"text": "and 60 respectively. So already order of magnitude", "timestamp": "00:31:11,062", "timestamp_s": 1871.0}, {"text": "more. And in general you have a price list.", "timestamp": "00:31:14,942", "timestamp_s": 1874.0}, {"text": "And based on that you can estimate how much single interaction", "timestamp": "00:31:18,334", "timestamp_s": 1878.0}, {"text": "with user can cost and then you can multiply it by number", "timestamp": "00:31:21,982", "timestamp_s": 1881.0}, {"text": "of expected interactions. But there", "timestamp": "00:31:25,366", "timestamp_s": 1885.0}, {"text": "will be a few small asterisks to remember about. So first of all,", "timestamp": "00:31:29,520", "timestamp_s": 1889.0}, {"text": "the math will depend not only on the number of tokens", "timestamp": "00:31:33,736", "timestamp_s": 1893.0}, {"text": "in general, but also on our understanding of", "timestamp": "00:31:37,440", "timestamp_s": 1897.0}, {"text": "what is the balance between input.", "timestamp": "00:31:41,160", "timestamp_s": 1901.0}, {"text": "Cloud is cheaper for input but more expensive for output.", "timestamp": "00:31:43,824", "timestamp_s": 1903.0}, {"text": "And in most cases it\u0027s good enough assumption that token", "timestamp": "00:31:48,104", "timestamp_s": 1908.0}, {"text": "is a word. But if you are in situation that", "timestamp": "00:31:51,608", "timestamp_s": 1911.0}, {"text": "small difference matters. Then it\u0027s worth looking closer", "timestamp": "00:31:55,146", "timestamp_s": 1915.0}, {"text": "at the tokenizers. It\u0027s worth looking", "timestamp": "00:31:58,562", "timestamp_s": 1918.0}, {"text": "closer at them because the models use different tokenizers,", "timestamp": "00:32:02,474", "timestamp_s": 1922.0}, {"text": "and number of tokens consumed for the same text", "timestamp": "00:32:05,482", "timestamp_s": 1925.0}, {"text": "by cloud is different, actually a bit larger", "timestamp": "00:32:10,154", "timestamp_s": 1930.0}, {"text": "than the one from chat GPT. So to make it even more", "timestamp": "00:32:14,162", "timestamp_s": 1934.0}, {"text": "confusing, Google Gemini charges not per token", "timestamp": "00:32:18,234", "timestamp_s": 1938.0}, {"text": "but per character. So the math", "timestamp": "00:32:22,180", "timestamp_s": 1942.0}, {"text": "is a little bit tricky already. But doing", "timestamp": "00:32:26,260", "timestamp_s": 1946.0}, {"text": "back of the envelope calculation should give us close enough", "timestamp": "00:32:29,900", "timestamp_s": 1949.0}, {"text": "number, and it becomes much more", "timestamp": "00:32:33,556", "timestamp_s": 1953.0}, {"text": "complex when we try to do the math for open source.", "timestamp": "00:32:37,484", "timestamp_s": 1957.0}, {"text": "For open source LLM, we host ourselves.", "timestamp": "00:32:41,196", "timestamp_s": 1961.0}, {"text": "Then you don\u0027t calculate the cost per token or characters", "timestamp": "00:32:44,584", "timestamp_s": 1964.0}, {"text": "produced, but you start with the price of the machine,", "timestamp": "00:32:48,448", "timestamp_s": 1968.0}, {"text": "price of the GPU, the price for maintenance,", "timestamp": "00:32:52,472", "timestamp_s": 1972.0}, {"text": "and then you need to estimate the expected traffic.", "timestamp": "00:32:55,896", "timestamp_s": 1975.0}, {"text": "If your traffic is low, the cost per", "timestamp": "00:33:00,384", "timestamp_s": 1980.0}, {"text": "request will be extremely high. So it\u0027s not obvious math.", "timestamp": "00:33:03,792", "timestamp_s": 1983.0}, {"text": "It\u0027s prone to errors. In many cases, it will be more expensive", "timestamp": "00:33:07,624", "timestamp_s": 1987.0}, {"text": "than using APIs, or, or at least the return of", "timestamp": "00:33:11,240", "timestamp_s": 1991.0}, {"text": "investment won\u0027t be. I briefly mentioned open", "timestamp": "00:33:14,956", "timestamp_s": 1994.0}, {"text": "source models, and I\u0027m actually coming from the background where I\u0027ve always been using", "timestamp": "00:33:18,436", "timestamp_s": 1998.0}, {"text": "open source, open source databases, open source", "timestamp": "00:33:22,588", "timestamp_s": 2002.0}, {"text": "data tools, and I really like them. But it", "timestamp": "00:33:25,908", "timestamp_s": 2005.0}, {"text": "was kind of comfortable working with the open source products", "timestamp": "00:33:29,620", "timestamp_s": 2009.0}, {"text": "because the open source was actually ahead. They were leading", "timestamp": "00:33:33,132", "timestamp_s": 2013.0}, {"text": "the innovation and then at some point the cloud providers", "timestamp": "00:33:36,924", "timestamp_s": 2016.0}, {"text": "came. They were to some extent kind of wrapping", "timestamp": "00:33:40,724", "timestamp_s": 2020.0}, {"text": "the open source innovation into more convenient way of using", "timestamp": "00:33:44,844", "timestamp_s": 2024.0}, {"text": "it. But now, I\u0027m a bit sad to say that,", "timestamp": "00:33:48,980", "timestamp_s": 2028.0}, {"text": "but the open source llms are still behind", "timestamp": "00:33:53,196", "timestamp_s": 2033.0}, {"text": "and they don\u0027t perform as good as the commercial", "timestamp": "00:33:56,684", "timestamp_s": 2036.0}, {"text": "ones. They are good, they are improving,", "timestamp": "00:34:00,476", "timestamp_s": 2040.0}, {"text": "but be prepared for extra effort if you want to tune", "timestamp": "00:34:03,788", "timestamp_s": 2043.0}, {"text": "specific use case with open source LLM. And of course", "timestamp": "00:34:07,516", "timestamp_s": 2047.0}, {"text": "you can fine tune the model. But before you even do that,", "timestamp": "00:34:11,260", "timestamp_s": 2051.0}, {"text": "make sure that your data is in good shape.", "timestamp": "00:34:15,148", "timestamp_s": 2055.0}, {"text": "Data will be the starting point for you anyway, and the", "timestamp": "00:34:18,004", "timestamp_s": 2058.0}, {"text": "easiest way to start is with rag application instead of fine", "timestamp": "00:34:21,732", "timestamp_s": 2061.0}, {"text": "tuning. So starting with simplerag can provide you with", "timestamp": "00:34:25,140", "timestamp_s": 2065.0}, {"text": "much faster result and much faster feedback", "timestamp": "00:34:28,980", "timestamp_s": 2068.0}, {"text": "from the customer. But if at some", "timestamp": "00:34:32,996", "timestamp_s": 2072.0}, {"text": "point you decide to tune the model itself, beware that", "timestamp": "00:34:36,924", "timestamp_s": 2076.0}, {"text": "there are various types of tuning and they differ.", "timestamp": "00:34:41,396", "timestamp_s": 2081.0}, {"text": "They differ in the sense of how much data you need,", "timestamp": "00:34:45,092", "timestamp_s": 2085.0}, {"text": "what kind of results you can expect, and whether they introduce extra latency.", "timestamp": "00:34:48,484", "timestamp_s": 2088.0}, {"text": "All things considered, building chatbots is an area", "timestamp": "00:34:53,884", "timestamp_s": 2093.0}, {"text": "where you need to experiment a lot. But when you experiment, make sure", "timestamp": "00:34:57,572", "timestamp_s": 2097.0}, {"text": "you don\u0027t get overwhelmed by that. Make sure you have", "timestamp": "00:35:01,628", "timestamp_s": 2101.0}, {"text": "business goal in mind all the time, because it\u0027s very easy to get lost", "timestamp": "00:35:05,244", "timestamp_s": 2105.0}, {"text": "and end up in never ending experiments.", "timestamp": "00:35:09,636", "timestamp_s": 2109.0}, {"text": "In most cases, you are not creating a research company.", "timestamp": "00:35:12,644", "timestamp_s": 2112.0}, {"text": "In most cases you want to solve some specific business problems.", "timestamp": "00:35:15,900", "timestamp_s": 2115.0}, {"text": "So keep that in mind. So working with", "timestamp": "00:35:19,684", "timestamp_s": 2119.0}, {"text": "llms is a very, very nice,", "timestamp": "00:35:23,332", "timestamp_s": 2123.0}, {"text": "interesting job. But at the same time you need to stay focused", "timestamp": "00:35:26,708", "timestamp_s": 2126.0}, {"text": "on the business goal and make sure you are pragmatic.", "timestamp": "00:35:30,844", "timestamp_s": 2130.0}, {"text": "Thanks a lot. If you have any questions,", "timestamp": "00:35:36,484", "timestamp_s": 2136.0}, {"text": "drop me an email or drop me a line on LinkedIn. I\u0027m always", "timestamp": "00:35:39,776", "timestamp_s": 2139.0}, {"text": "happy to chat. Thank you.", "timestamp": "00:35:43,288", "timestamp_s": 2143.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'kmVB_-NmEkw',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              AI Chats: What Nobody Told You - The Conundrums of Business Integration
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Explore the intricacies of integrating ChatGPT into business systems with data privacy challenges, cost implications, and the strategic analysis required for successful integration. Learn about direct API integration, cost optimization, and customizing privately hosted models to fit your resources and needs.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Today I am going to share with you some of the lessons learned from multiple AI chatbot projects. By the end of the presentation you will have a list of what to pay attention to. And at the end ill briefly describe privacy issues related to llms.

              </li>
              
              <li>
                Martin will share lessons learned from some of our projects. Be aware that the entire area of Genai is moving incredibly fast. Some of the tools I'm referring to might be outdated by the time you listen to it. After the presentation, I would be really happy to hear from you about your findings.

              </li>
              
              <li>
                 vector embeddings and vector databases are good in natural language problems. The idea is that the vectors are close to each other if the text has similar meaning. Here are some examples of when they do not work that well and what we can do.

              </li>
              
              <li>
                So far we've been focusing on how we can improve the vector search by splitting the documents. But what else we can do in order to improve the. vector search, you can use something else instead of vector search. Last technique I wanted to mention, and it's actually quite simple but still quite powerful, is preprocessing using large language models.

              </li>
              
              <li>
                Even if you provide it with very, very relevant information, it's still can make a mistake. There is no guarantee that the information produced by the chatbot is correct. Here is one technique which you could use in your project to prevent the hallucination.

              </li>
              
              <li>
                Another important consideration when starting a project and deciding which LLM to use is cost. Cloud is cheaper for input but more expensive for output. Be prepared for extra effort if you want to tune specific use case with open source LLM.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/kmVB_-NmEkw.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:21,200'); seek(21.0)">
              Today I am going to share with you some of the lessons learned from multiple
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:24,358'); seek(24.0)">
              AI chatbot projects where we utilized large language models
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:28,518'); seek(28.0)">
              and doing that is actually quite tricky. So by the end of the presentation
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,382'); seek(32.0)">
              you will have a list of what to pay attention to,
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:35,126'); seek(35.0)">
              sometimes critical issues, sometimes tiny little details
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,158'); seek(39.0)">
              which are still important in the project success.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:42,694'); seek(42.0)">
              And we will start with the introduction to rag, what it is
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:46,910'); seek(46.0)">
              and what kind of challenges you can expect when building complex applications.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:51,534'); seek(51.0)">
              Then we will talk about hallucinations, but also how
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:55,680'); seek(55.0)">
              we control the scope of the conversation. So if we
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:59,328'); seek(59.0)">
              are dealing with customer issue, we dont start talking about
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:03,016'); seek(63.0)">
              us presidency, election or any other issue which is not
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:06,840'); seek(66.0)">
              relevant. We will also cover the cost,
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:10,712'); seek(70.0)">
              how to calculate it and whats important in
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:13,880'); seek(73.0)">
              various scenarios. And at the end ill briefly
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:17,624'); seek(77.0)">
              describe privacy issues related to llms and the consequences
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:21,902'); seek(81.0)">
              of various decisions. My name is Martin,
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:26,230'); seek(86.0)">
              my background is in data engineering and mlobs and I'm
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:29,742'); seek(89.0)">
              running a team specialized in everything data. At Tantus data and
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:34,262'); seek(94.0)">
              at Tantus data we help our customers with setting up data
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:37,678'); seek(97.0)">
              infrastructure, building data pipelines, and machine learning
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:41,286'); seek(101.0)">
              and genai driven applications. So during that
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:44,694'); seek(104.0)">
              presentation I will share lessons learned from some
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:47,974'); seek(107.0)">
              of our projects. And a little disclaimer before
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:51,734'); seek(111.0)">
              we get started. We need to be aware that the entire area of
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:55,734'); seek(115.0)">
              Genai is moving incredibly fast. The models
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:59,158'); seek(119.0)">
              improve over time, the libraries, the tools improve,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:03,054'); seek(123.0)">
              some of them die. So it's really hard
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:06,494'); seek(126.0)">
              to keep track of all that. And because of that,
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:09,582'); seek(129.0)">
              be aware that some of the tools I'm referring to might
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:13,278'); seek(133.0)">
              be outdated by the time you listen
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:16,594'); seek(136.0)">
              to it. And I'll try not to
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:20,522'); seek(140.0)">
              focus on specific tools, but more on problems, solutions,
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:24,042'); seek(144.0)">
              techniques and general ideas.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:27,354'); seek(147.0)">
              But since there are so much going on
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:30,970'); seek(150.0)">
              in the area of Genai after the presentation,
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:34,242'); seek(154.0)">
              I would be really happy to hear from you about your
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:37,658'); seek(157.0)">
              findings, your experience. So don't be
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:41,190'); seek(161.0)">
              shy and let's connect on LinkedIn.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:44,734'); seek(164.0)">
              Okay, so let's get started. Let's think about concrete business
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:48,622'); seek(168.0)">
              problem you would like to solve. And let's think about
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:51,902'); seek(171.0)">
              a chat which is travel assistant on vacation rental website.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:55,774'); seek(175.0)">
              And let's say the customer comes and asks,
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:00,030'); seek(180.0)">
              I need an apartment in London
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:03,846'); seek(183.0)">
              with elevator. How do we know what the
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:07,740'); seek(187.0)">
              customer is asking for?
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:12,084'); seek(192.0)">
              How do we come up with specific information and use that in the
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:15,380'); seek(195.0)">
              chat? So one of the
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:19,052'); seek(199.0)">
              very common answer to these kind of questions is vector embeddings
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:23,156'); seek(203.0)">
              and vector databases. So let's quickly define what they
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:27,212'); seek(207.0)">
              are and why are they good in natural language
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:31,484'); seek(211.0)">
              problems. But then I will show you
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:34,882'); seek(214.0)">
              some examples of when they do not work that well and what
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:38,890'); seek(218.0)">
              we can do. So the promise about
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:42,978'); seek(222.0)">
              vector embeddings is very simple. First of all,
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:46,970'); seek(226.0)">
              you transform the text into a vector and the vector represents
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:51,114'); seek(231.0)">
              the semantic meaning of the text. So two
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:54,986'); seek(234.0)">
              texts which have similar meaning will be transformed into two vectors
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:59,450'); seek(239.0)">
              which are also close to each other.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:03,474'); seek(243.0)">
              And let's have a look at examples.
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:06,354'); seek(246.0)">
              This is one of the very classical examples.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:10,154'); seek(250.0)">
              King and queen are somewhat the same
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:13,762'); seek(253.0)">
              role, you can say, and the only difference is gender.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:18,034'); seek(258.0)">
              So in the perfect vector space, the distance between king and queen
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:22,570'); seek(262.0)">
              should be the same as between men.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:26,654'); seek(266.0)">
              And you should be even able to do this
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:30,102'); seek(270.0)">
              kind of math like queen equals king,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:33,542'); seek(273.0)">
              man plus woman.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:36,694'); seek(276.0)">
              And this is another example. The words red,
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:40,230'); seek(280.0)">
              orange and yellow represents colors, so they are close to each
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:43,542'); seek(283.0)">
              other. Then king and queen are also close to
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:47,270'); seek(287.0)">
              each other and car is somewhere completely else.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:51,564'); seek(291.0)">
              And this is very flat and simplified
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:55,236'); seek(295.0)">
              dummy example of vector embeddings, because in reality
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:58,852'); seek(298.0)">
              they have hundreds or thousands of dimensions.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:02,524'); seek(302.0)">
              But the idea, the promise from embeddings
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:06,116'); seek(306.0)">
              is that the vectors are close to each other if
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:09,660'); seek(309.0)">
              the text has similar meaning.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:12,444'); seek(312.0)">
              So it's not a surprise that for searching information needed
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:16,132'); seek(316.0)">
              by LLM in a chatbot, we likely want to try vector
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:20,214'); seek(320.0)">
              database. So the super basic idea is that you transform your
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:23,742'); seek(323.0)">
              documents into vector, you store them into vector database
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:27,662'); seek(327.0)">
              and you serve the relevant documents to the LLM.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:32,694'); seek(332.0)">
              And more general version of this diagram is
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:36,342'); seek(336.0)">
              that one when we provide an LLM with access
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:40,206'); seek(340.0)">
              to our documents, databases, API,
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:43,678'); seek(343.0)">
              basically everything needed in order to understand our domain information.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:47,984'); seek(347.0)">
              And this technique is called RaG, stands for retrieval
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:51,800'); seek(351.0)">
              augmented generation. But once again,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:55,608'); seek(355.0)">
              why are we doing this? We need to remember that
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:59,432'); seek(359.0)">
              the main ability of LLM is not really the knowledge it
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:02,680'); seek(362.0)">
              comes with, but the ability to work with texts, with texts
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:06,712'); seek(366.0)">
              written in natural language, and ability to follow
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:10,470'); seek(370.0)">
              instructions related to these texts. So LLM has
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:13,870'); seek(373.0)">
              a chance to know only about the information it was
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:17,518'); seek(377.0)">
              trained on and we need to provide it with our specific domain
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:21,822'); seek(381.0)">
              knowledge. Let's get back to our example, our business
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:25,830'); seek(385.0)">
              problem. How do we use that technique? How do we use vector
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:29,454'); seek(389.0)">
              databases for our I need
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:32,646'); seek(392.0)">
              an apartment with elevator in London query.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:36,344'); seek(396.0)">
              If we have our apartment descriptions in the vector
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:39,664'); seek(399.0)">
              database, what we could do, we could just check if the vector
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:43,320'); seek(403.0)">
              representing our query is close to any of our property description.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:48,016'); seek(408.0)">
              And what we hope for is that I
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:51,648'); seek(411.0)">
              need an apartment with elevator in London. Vector will be
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:55,488'); seek(415.0)">
              close to an apartment with description apartment
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:59,752'); seek(419.0)">
              with elevator in London and not that
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:03,464'); seek(423.0)">
              close to apartment with description apartment in
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:07,240'); seek(427.0)">
              London. So no elevator mentioned.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:10,624'); seek(430.0)">
              But once again, this example is way too simplistic.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:14,480'); seek(434.0)">
              This is perfectly valid technique, and it describes what vector
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:18,304'); seek(438.0)">
              embeddings and vector databases could be used for. But I would
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:21,720'); seek(441.0)">
              like to focus on the challenges which you might face. So first
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:25,672'); seek(445.0)">
              of all, the apartment description will never be just a single sentence.
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:29,184'); seek(449.0)">
              They will look more like this. This is
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:32,720'); seek(452.0)">
              an example cottage in Cornwall,
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:35,776'); seek(455.0)">
              western England, and it's not that expensive.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:39,264'); seek(459.0)">
              We have one more very similar one. So you can see the descriptions are
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:42,792'); seek(462.0)">
              quite long and you have some extra information about them.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:46,736'); seek(466.0)">
              But we have also some completely different properties.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:51,120'); seek(471.0)">
              We have another one in London. It's not a cottage anymore,
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:54,592'); seek(474.0)">
              it's an apartment that is much more expensive. So completely
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:58,396'); seek(478.0)">
              different type of property and one more
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:01,972'); seek(481.0)">
              similar. And then if we take all four properties I
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:05,612'); seek(485.0)">
              have just shown, get the description and take the
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:10,012'); seek(490.0)">
              vector embeddings, then we end up with something like this.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:13,580'); seek(493.0)">
              I do understand that this is not very readable, but this
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:18,020'); seek(498.0)">
              actually represents very well the problem an engineer
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:22,004'); seek(502.0)">
              is struggling with. So we have four different properties both,
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:25,940'); seek(505.0)">
              but in the world of vectors, they are very close to each other,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:30,208'); seek(510.0)">
              simply because the wording used in the description
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:34,272'); seek(514.0)">
              is very similar. It's very far away from the
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:37,840'); seek(517.0)">
              word banana, it's very far away from some sentence of
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:42,104'); seek(522.0)">
              some sentence about constitution, but it
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:45,888'); seek(525.0)">
              doesn't really help us because the property description itself
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:50,160'); seek(530.0)">
              is very close to each other. So it's very hard to distinguish
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:54,416'); seek(534.0)">
              what is what in very hard to make a good
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:58,136'); seek(538.0)">
              proposal for the customer. And the reason for that
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:01,816'); seek(541.0)">
              is that if we are using general vector
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:05,384'); seek(545.0)">
              embeddings, they are good in general language, but they are not specialized
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:09,360'); seek(549.0)">
              in a specific domain, and the specialization in a specific domain
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:13,056'); seek(553.0)">
              is usually what we want. So maybe that
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:16,672'); seek(556.0)">
              will come up as a surprise. But magic does not exist. There is
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:20,512'); seek(560.0)">
              no such thing as a silver bullet. So vector databases
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:24,316'); seek(564.0)">
              are useful, but you need to test what will work for you.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:28,204'); seek(568.0)">
              Maybe you will need to fine tune the embedding so they are specialized
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:31,684'); seek(571.0)">
              to the domain. For sure, you will need to do splitting of long documents
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:35,892'); seek(575.0)">
              because of the context length limitation of vector embedding models,
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:39,940'); seek(579.0)">
              they can accept text up to specific limit,
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:43,636'); seek(583.0)">
              few hundreds, up to few thousand at most.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:46,412'); seek(586.0)">
              But even if you can fit long text in the embedding model,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:50,740'); seek(590.0)">
              it does not mean the longer text will work better for
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:54,232'); seek(594.0)">
              you. This is something to be tested.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:58,384'); seek(598.0)">
              One of the secret ingredients making
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:01,736'); seek(601.0)">
              your chat better is splitting the documents you are working with
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:05,352'); seek(605.0)">
              into digestible chunks, that's for sure. But if
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:09,440'); seek(609.0)">
              I tell you, if I tell you,
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:13,784'); seek(613.0)">
              get the document description, get the apartment description,
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:17,048'); seek(617.0)">
              get a PDF document, and split it into chunks,
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:20,434'); seek(620.0)">
              it will be a bit too simplistic. It will
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:23,762'); seek(623.0)">
              be somewhat like saying,
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:27,098'); seek(627.0)">
              just draw two circles, complete the owl,
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:31,442'); seek(631.0)">
              something is missing. So what we do,
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:34,762'); seek(634.0)">
              what we pay attention to when splitting documents, let's have a
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:38,090'); seek(638.0)">
              look, let's have a look at some of the solutions.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:42,314'); seek(642.0)">
              When you split the document, what will matter for sure is the size.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:46,162'); seek(646.0)">
              And all I can say for sure is that very big chunk will not work
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:49,674'); seek(649.0)">
              very well and it's kind of intuitive. The vector size is
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:53,202'); seek(653.0)">
              static and if you try to squeeze too much information into
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:56,954'); seek(656.0)">
              it, you will lose some of it.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:00,274'); seek(660.0)">
              But other than that, when you split the document, you need
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:04,178'); seek(664.0)">
              to know something about the context. And a good
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:07,954'); seek(667.0)">
              example would be a large PDF, and having just a chunk
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:11,290'); seek(671.0)">
              of it without knowing which chapter or which section it
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:14,522'); seek(674.0)">
              comes from, it will not be very helpful.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:18,388'); seek(678.0)">
              That's why it's important to keep the relevant information as part
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:22,468'); seek(682.0)">
              of the chunk or as part of the metadata.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:27,804'); seek(687.0)">
              And if you Google search for what, if the data is too
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:31,540'); seek(691.0)">
              large for LLM context, or if you just scan the QR code,
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:35,244'); seek(695.0)">
              you will get to one of our articles describing these kind of problems.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:39,236'); seek(699.0)">
              But we also described there a mechanism called self
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:42,594'); seek(702.0)">
              core retriever and it's super useful in situations
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:45,922'); seek(705.0)">
              when you have a granular split with all the details necessary.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:50,178'); seek(710.0)">
              But still the vector similarity of multiple chunks is too
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:53,882'); seek(713.0)">
              close to each other and it's hard to distinct
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:57,922'); seek(717.0)">
              which one is the best in a given situation. And in
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:01,842'); seek(721.0)">
              such cases it's good to try the mechanism and
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:06,298'); seek(726.0)">
              what it does. It's basically a tool in LangChain
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:10,704'); seek(730.0)">
              which allows us to come up with structured query
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:14,792'); seek(734.0)">
              for specific attributes you predefined. So let's say from
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:19,152'); seek(739.0)">
              a PDF chunk you will extract price or
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:23,496'); seek(743.0)">
              offer name. And if you predefined them,
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:27,792'); seek(747.0)">
              you can have another LLM call for better understanding
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:31,760'); seek(751.0)">
              of values of these kind of attributes. So you,
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:35,816'); seek(755.0)">
              you can make better decision. You can make a better decision
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:39,612'); seek(759.0)">
              about what answer to present to the user and it's very useful.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:44,372'); seek(764.0)">
              I recommend you to read up on that.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:47,324'); seek(767.0)">
              But let's move on. One more
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:51,260'); seek(771.0)">
              disclaimer, one more disclaimer about PDF files I mentioned.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:54,844'); seek(774.0)">
              The disclaimer is that a lot will depend on the format
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:58,292'); seek(778.0)">
              and how exactly you parse the PDF. Sometimes you
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:02,248'); seek(782.0)">
              need to just find a specific parser for a specific document,
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:05,832'); seek(785.0)">
              but sometimes maybe it's worth looking around.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:09,560'); seek(789.0)">
              Maybe you have a chance to get the data you need from a source
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:12,992'); seek(792.0)">
              which has structure just better than the PDF file.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:17,080'); seek(797.0)">
              Maybe the same data exists in better format.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:21,264'); seek(801.0)">
              So far we've been focusing on how we can improve
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:24,752'); seek(804.0)">
              the vector search by splitting the documents.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:28,544'); seek(808.0)">
              But what else we can do in order to improve
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:31,928'); seek(811.0)">
              the vector search, you can use something else instead of
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:35,440'); seek(815.0)">
              vector search. And I just wanted to say that vector databases
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:39,904'); seek(819.0)">
              are very popular. They are growing, they are very
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:43,232'); seek(823.0)">
              natural to be used in context of natural language processing.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:46,960'); seek(826.0)">
              But just the fact that they are popular, just the fact that
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:50,960'); seek(830.0)">
              they are very much connected with our lens,
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:54,376'); seek(834.0)">
              does not mean this is the only tool you can use.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:58,254'); seek(838.0)">
              So for instance, if you have an elasticsearch,
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:01,454'); seek(841.0)">
              or if you have some search API in your company, there is
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:04,750'); seek(844.0)">
              really no reason not to use it, not to try,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:07,902'); seek(847.0)">
              if it can provide you with relevant info. And at the
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:11,678'); seek(851.0)">
              same time, most of the vector databases, they come
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:15,086'); seek(855.0)">
              up with not only the vector search ability,
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:18,974'); seek(858.0)">
              but they have hybrid search ability.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:21,814'); seek(861.0)">
              So on top of vector search, you can
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:25,668'); seek(865.0)">
              enable more traditional keyword search, for example
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:29,092'); seek(869.0)">
              BM 25, and you can verify which results
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:32,652'); seek(872.0)">
              are better. Maybe you can mix them together. Maybe you can
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:36,132'); seek(876.0)">
              use both results. And once
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:39,956'); seek(879.0)">
              you mix them together, once you utilize data from multiple
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:43,996'); seek(883.0)">
              search methods, what you can do is you can re
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:47,612'); seek(887.0)">
              rank the responses you received. So in many
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:51,388'); seek(891.0)">
              of our cases we have implemented, we realized
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:55,452'); seek(895.0)">
              that it makes a lot of sense to blend
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:58,908'); seek(898.0)">
              multiple sources, multiple results,
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:02,956'); seek(902.0)">
              blend them together. And what you can consider, except of
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:07,764'); seek(907.0)">
              vector databases, is data coming directly from backend database,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:11,756'); seek(911.0)">
              from data lake, from data warehouse, internal APIs,
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:15,924'); seek(915.0)">
              but also external APIs like panel
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:19,696'); seek(919.0)">
              data, or from Google search.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:23,704'); seek(923.0)">
              So far we've been focusing on how we can improve the
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:27,616'); seek(927.0)">
              vector search by splitting the documents.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:30,984'); seek(930.0)">
              But what else we can do in order to improve
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:34,376'); seek(934.0)">
              the vector search, you can use something else instead of vector
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:38,304'); seek(938.0)">
              search. And I just wanted to say that vector
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:41,736'); seek(941.0)">
              databases are very popular, they are growing, they are very
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:45,682'); seek(945.0)">
              natural to be used in context of natural language processing.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:49,450'); seek(949.0)">
              But just the fact that they are popular,
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:52,298'); seek(952.0)">
              just the fact that they are very much connected with llms
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:56,818'); seek(956.0)">
              does not mean this is the only tool you can use.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:00,714'); seek(960.0)">
              So for instance, if you have an elasticsearch, or if
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:04,370'); seek(964.0)">
              you have some search API in your company, there is really no reason
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:08,378'); seek(968.0)">
              not to use it, not to try, if it can provide you with
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:11,824'); seek(971.0)">
              relevant info. And at the same time, most of
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:15,624'); seek(975.0)">
              the vector databases, they come up with not only the
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:19,584'); seek(979.0)">
              vector search ability, but they have hybrid
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:23,464'); seek(983.0)">
              search ability. So on top of vector search,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:27,208'); seek(987.0)">
              you can enable more traditional keyword search,
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:30,928'); seek(990.0)">
              for example BM 25, and you can verify
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:34,336'); seek(994.0)">
              which results are better. Maybe you can mix them together.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:37,898'); seek(997.0)">
              Maybe you can use both results. And once
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:42,186'); seek(1002.0)">
              you mix them together, once you utilize data from
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:45,738'); seek(1005.0)">
              multiple search methods. What you can do is you can
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:49,666'); seek(1009.0)">
              rerank the responses you received. So in many
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:53,618'); seek(1013.0)">
              of our cases we have implemented,
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:56,298'); seek(1016.0)">
              we realized that it makes a lot of
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:00,186'); seek(1020.0)">
              sense to blend multiple sources, multiple result,
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:05,216'); seek(1025.0)">
              blend them together. And what you can consider,
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:08,472'); seek(1028.0)">
              except of vector databases, is data coming directly
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:12,704'); seek(1032.0)">
              from backend database, from data lake, from data
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:16,088'); seek(1036.0)">
              warehouse, internal APIs, but also external
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:20,568'); seek(1040.0)">
              APIs like panel data or from
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:24,088'); seek(1044.0)">
              Google search. And then on top of
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:27,768'); seek(1047.0)">
              quite aggressive query query, which is providing us with many
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:31,404'); seek(1051.0)">
              results, what we do, we do re rank and we select
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:34,836'); seek(1054.0)">
              the best candidates, the candidates which are the most promising.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:38,964'); seek(1058.0)">
              So the chatbot can utilize the information from the most promising ones
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:43,108'); seek(1063.0)">
              in coming up with the most relevant answer.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:47,044'); seek(1067.0)">
              The last technique I wanted to mention, and it's actually quite
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:50,476'); seek(1070.0)">
              simple but still quite powerful, is preprocessing
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:54,460'); seek(1074.0)">
              using large language models. So let's say you
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:58,224'); seek(1078.0)">
              have some metadata, but in your metadata, you don't
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:02,072'); seek(1082.0)">
              have any information if an apartment has an elevator
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:06,232'); seek(1086.0)">
              or not. But the customers are looking for this kind
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:09,600'); seek(1089.0)">
              of information. And you do have that information in
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:13,808'); seek(1093.0)">
              the description in a free text. So what you can
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:17,376'); seek(1097.0)">
              do a batch preprocessing
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:20,584'); seek(1100.0)">
              using LLM in search for specific metadata,
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:24,360'); seek(1104.0)">
              you know, users are often looking for. And then
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:28,532'); seek(1108.0)">
              once you extract the metadata, you can just save it. You can enrich
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:32,628'); seek(1112.0)">
              your database and use it in your queries.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:36,172'); seek(1116.0)">
              So basically, you are utilizing the fact that LLMs are
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:40,452'); seek(1120.0)">
              very, very good in tasks like sentiment analysis,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:43,788'); seek(1123.0)">
              text categorization and so on. You just
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:47,716'); seek(1127.0)">
              tell them which category you are looking for,
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:51,054'); seek(1131.0)">
              what information you are looking for, and they do it for you. They do
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:54,670'); seek(1134.0)">
              it basically out of the box. They are
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:57,942'); seek(1137.0)">
              good at this kind of tasks, out of the box. So there is really
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:01,502'); seek(1141.0)">
              no reason not to, not to use that fact.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:04,934'); seek(1144.0)">
              Okay, so we've been talking about techniques which leads us to providing the
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:08,950'); seek(1148.0)">
              most relevant information to the chatbot. But even if
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:12,470'); seek(1152.0)">
              you provide it with very, very relevant information, it's still
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:16,630'); seek(1156.0)">
              can make a mistake. It still can hallucinate. So yes,
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:20,892'); seek(1160.0)">
              one way of preventing or limiting the hallucination is to provide
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:24,548'); seek(1164.0)">
              it with relevant info, but there is really
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:27,828'); seek(1167.0)">
              no guarantee that the answer chat comes up with based on the prompt,
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:31,820'); seek(1171.0)">
              the data you provided provided with,
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:34,964'); seek(1174.0)">
              there is no guarantee that the information produced by the
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:38,468'); seek(1178.0)">
              chatbot is correct. So I will show you a very quick demo of what
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:42,676'); seek(1182.0)">
              the hallucination looks like and one specific technique
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:46,158'); seek(1186.0)">
              which you could use in your project in
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:49,470'); seek(1189.0)">
              order to prevent the hallucination. So let's have a look at the demo I
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:53,414'); seek(1193.0)">
              recorded. Let's have a look.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:57,854'); seek(1197.0)">
              What we have is Python code where we import a
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:01,846'); seek(1201.0)">
              tool called nemo guardrails. It's a tool created by Nvidia.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:20:06,254'); seek(1206.0)">
              And we have a text file with some questions.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:10,022'); seek(1210.0)">
              We'll have a look at it in a second. And then we define that we
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:13,348'); seek(1213.0)">
              want to use an old OpenAI model text, davinci zero three.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:18,044'); seek(1218.0)">
              And then in the file we define some
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:21,388'); seek(1221.0)">
              questions. The first question
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:25,180'); seek(1225.0)">
              we define is when did
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:28,612'); seek(1228.0)">
              the roman empire collapse? So we want to ask that question
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:32,508'); seek(1232.0)">
              to the model. And I am asking the question about the
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:36,332'); seek(1236.0)">
              roman empire because it's a common knowledge. And the second
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:40,360'); seek(1240.0)">
              question I'm asking is how
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:43,744'); seek(1243.0)">
              many goals has been scored in polish extraclass in a specific season?
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:47,704'); seek(1247.0)">
              So since the first question is a common knowledge and the second one
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:51,224'); seek(1251.0)">
              is not, I expect one of the questions not to be
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:54,960'); seek(1254.0)">
              the hallucination, one of the answer to the question not to be the
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:58,288'); seek(1258.0)">
              hallucination, and one of them. For one of them,
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:01,752'); seek(1261.0)">
              I do expect the model to hallucinate. And let's see if the
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:04,952'); seek(1264.0)">
              tool can spot what is hallucination, what is not.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:09,464'); seek(1269.0)">
              So let's see, we run the code and
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:14,608'); seek(1274.0)">
              we will have a lot of logs. And once
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:18,776'); seek(1278.0)">
              we scroll all the way up, after it completes,
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:22,784'); seek(1282.0)">
              after it completes, we can see the
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:26,672'); seek(1286.0)">
              first question, when did the roman empire collapse?
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:29,624'); seek(1289.0)">
              And we get a bottle some bot responses
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:32,916'); seek(1292.0)">
              and it's getting flagged as not hallucination.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:36,164'); seek(1296.0)">
              But how exactly did the tool spot
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:39,404'); seek(1299.0)">
              that? Let's have a look into the details. Using the second question
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:43,148'); seek(1303.0)">
              as an example, how many goals has been scored in polish extraclassa?
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:47,484'); seek(1307.0)">
              The bot response we are receiving is 1800.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:51,804'); seek(1311.0)">
              I have no idea if it's correct or not, but the whole point is that
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:55,484'); seek(1315.0)">
              what the tool is doing, it's asking exactly the same question for the second time,
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:59,944'); seek(1319.0)">
              and then we get completely different response,
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:03,464'); seek(1323.0)">
              and then the tool is asking the same question for the third
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:07,216'); seek(1327.0)">
              time and you're getting, once again different
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:10,696'); seek(1330.0)">
              response. And then what the tool
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:14,376'); seek(1334.0)">
              is doing is actually checking if the answers
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:19,072'); seek(1339.0)">
              we are getting are in sync, if the
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:23,432'); seek(1343.0)">
              meaning of them is exactly the same. So it's actually doing another prompt
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:27,280'); seek(1347.0)">
              to the model. And the prompt is
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:30,538'); seek(1350.0)">
              you are given a task to identify if the hypothesis
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:34,514'); seek(1354.0)">
              is in agreement with the context below and
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:37,858'); seek(1357.0)">
              the hypothesis is the original answer
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:42,426'); seek(1362.0)">
              we received. So the answer to the first
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:46,250'); seek(1366.0)">
              time we ask that question and then context
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:51,194'); seek(1371.0)">
              are two extra responses we have received because the
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:55,058'); seek(1375.0)">
              tool was asking the same question three times and the
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:59,294'); seek(1379.0)">
              answer from the model is no
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:03,374'); seek(1383.0)">
              informations are not, which means
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:07,014'); seek(1387.0)">
              we flag it as hallucination. So yeah,
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:11,326'); seek(1391.0)">
              there are ways of preventing the hallucinations. It's good to
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:14,918'); seek(1394.0)">
              be aware of them, but at the same time it's good to be aware of
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:18,206'); seek(1398.0)">
              consequences of these kind of techniques, because there is no such thing
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:21,606'); seek(1401.0)">
              as free lunch. First of all, you need to be aware of the costs
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:25,714'); seek(1405.0)">
              associated with that. The cost of us dollars you
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:29,202'); seek(1409.0)">
              pay for the extra API, call the cost of
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:32,858'); seek(1412.0)">
              slower system because you make extra API, so you introduce an
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:36,610'); seek(1416.0)">
              extra delay, but also the cost of false positive,
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:40,226'); seek(1420.0)">
              because there is really no guarantee that this kind of technique always
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:44,762'); seek(1424.0)">
              works. But all that,
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:48,690'); seek(1428.0)">
              the existence of hallucinations, the fact that we
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:52,358'); seek(1432.0)">
              have to deal with them, but also how we have to experiment
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:56,214'); seek(1436.0)">
              with cutting the documents, how we have to tune the search
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:59,326'); seek(1439.0)">
              engine, all of that can lead to the conclusion that we are back to
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:02,990'); seek(1442.0)">
              square one to some extent, and that there is really no shortcut.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:07,462'); seek(1447.0)">
              And even though LLMs are really impressive,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:11,518'); seek(1451.0)">
              you cannot avoid working on the data quality
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:14,678'); seek(1454.0)">
              or just careful engineering. Tools like llms
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:18,934'); seek(1458.0)">
              are impressive, but you still have to do your homework.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:23,854'); seek(1463.0)">
              The good news is that there are many tools which could
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:27,910'); seek(1467.0)">
              help you to some extent. So I mentioned Nemo guardiols,
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:31,470'); seek(1471.0)">
              but it's worth looking into memgpt weaviate but
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:35,478'); seek(1475.0)">
              at the same time, do not expect that some tool will solve
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:39,358'); seek(1479.0)">
              all your problems. Do not expect
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:43,684'); seek(1483.0)">
              that you buy some tool which will magically solve everything.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:47,900'); seek(1487.0)">
              This approach, shut up and take my money will
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:51,356'); seek(1491.0)">
              probably not work. It's not gonna happen. The tool might
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:55,092'); seek(1495.0)">
              be helpful, but the tools themselves are coming
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:58,444'); seek(1498.0)">
              with their own problems. The tools themselves are quite
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:02,460'); seek(1502.0)">
              immature because basically the entire area of large language models,
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:07,108'); seek(1507.0)">
              chatbots and so on, is quite
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:10,786'); seek(1510.0)">
              new, quite fresh. And just
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:14,530'); seek(1514.0)">
              to show you an example of how the
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:17,714'); seek(1517.0)">
              tools are changing, this is the history of code in Lancranc
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:21,490'); seek(1521.0)">
              project. And there are tons of changes, which on
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:25,090'); seek(1525.0)">
              one hand is a good thing because the project is evolving and it's actually
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:28,658'); seek(1528.0)">
              impressive how fast it's growing. But on
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:31,858'); seek(1531.0)">
              the other hand, that means you have to be aware
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:35,160'); seek(1535.0)">
              of the updates, upcoming changes, there will be some bugs introduced,
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:39,248'); seek(1539.0)">
              there will be some breaking changes over time, and you just
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:43,016'); seek(1543.0)">
              need to be ready for that. You just need to be aware
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:46,232'); seek(1546.0)">
              of that. So we have all the tools which are helpful,
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:50,040'); seek(1550.0)">
              but not very stable yet, and we are working with a completely
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:53,616'); seek(1553.0)">
              new area and there is a lot of unknown here. And that is why it
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:56,816'); seek(1556.0)">
              is really important that you do the testing. And testing of
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:00,270'); seek(1560.0)">
              LLM project is really, really tricky. So what you
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:03,726'); seek(1563.0)">
              can do for sure, and what you should do is testing of
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:07,510'); seek(1567.0)">
              the retrieval because this is fully under your control and
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:11,270'); seek(1571.0)">
              this is quite predictable. So it's easy to define the test condition,
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:15,094'); seek(1575.0)">
              but you should also test
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:18,462'); seek(1578.0)">
              the LLM actions wherever you can.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:22,214'); seek(1582.0)">
              And I say wherever you can because it's actually quite tricky
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:26,262'); seek(1586.0)">
              and it's very hard to define reliable tests,
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:29,752'); seek(1589.0)">
              reliable tests which cover most of the possibilities.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:33,664'); seek(1593.0)">
              And one of the problem with testing llms is that even if
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:37,400'); seek(1597.0)">
              you have exactly the same input in
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:40,600'); seek(1600.0)">
              your test, the output could vary.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:45,184'); seek(1605.0)">
              So there is this post on OpenAI forum, and I really recommend
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:48,632'); seek(1608.0)">
              you to read the question of determinism.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:52,464'); seek(1612.0)">
              The bottom line is that large language model action is not really
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:56,488'); seek(1616.0)">
              deterministic. So yeah, you can have the parameters
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:00,212'); seek(1620.0)">
              like temperature, you can set it, and this should control
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:04,052'); seek(1624.0)">
              how creative the model is. But there is this misconception
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:07,612'); seek(1627.0)">
              that if you set it to zero, LLM will be behaving
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:11,124'); seek(1631.0)">
              in exactly the same way. In reality it will be
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:14,852'); seek(1634.0)">
              just kind of less creative.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:18,108'); seek(1638.0)">
              But it still might provide you with various results,
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:21,700'); seek(1641.0)">
              mostly because of the hardware it's being physically run on. But also
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:25,366'); seek(1645.0)">
              you can always end up with two tokens which have exactly the same probability.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:30,014'); seek(1650.0)">
              So one or the other will be randomly selected in your result.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:34,334'); seek(1654.0)">
              So keep that in mind when you write the test,
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:37,734'); seek(1657.0)">
              and it's always worth checking the lang chain utils
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:41,894'); seek(1661.0)">
              lang chain utils for testing because they take this kind of
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:45,814'); seek(1665.0)">
              lack of determinism into consideration and they aim to mitigate
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:50,254'); seek(1670.0)">
              it during testing. But what is critical
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:54,528'); seek(1674.0)">
              when you move to production is that you collect the data from your
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:58,416'); seek(1678.0)">
              run, from your run with real users,
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:01,696'); seek(1681.0)">
              because that is really something which gives you the real feedback
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:05,176'); seek(1685.0)">
              about how it is going, how the users are using the application,
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:09,744'); seek(1689.0)">
              whether they are happy with that or not. Make sure you
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:13,280'); seek(1693.0)">
              collect the data. Make sure you analyze that, especially in the
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:16,632'); seek(1696.0)">
              early phases of of the project.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:19,564'); seek(1699.0)">
              Let's have a look at legal and privacy aspects of llms.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:23,964'); seek(1703.0)">
              What we need to understand is that whenever we
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:27,140'); seek(1707.0)">
              pull the data from any database and then process
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:30,524'); seek(1710.0)">
              the data and then eventually pass
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:34,700'); seek(1714.0)">
              the data to LLM, our data is being sent to the
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:38,092'); seek(1718.0)">
              LLM provider, to OpenAI, to Microsoft,
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:41,244'); seek(1721.0)">
              Google, and in some cases it's perfectly fine. But there
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:45,212'); seek(1725.0)">
              are cases that you don't want to send the data
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:48,780'); seek(1728.0)">
              anywhere because it's too sensitive. And that means that
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:52,596'); seek(1732.0)">
              you might want to use an open source LLM installed in
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:56,708'); seek(1736.0)">
              a data center you own.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:00,084'); seek(1740.0)">
              Keep in mind that in situations when LLM over API
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:03,564'); seek(1743.0)">
              is not possible, you not only have to have a private
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:07,532'); seek(1747.0)">
              LLM installation, you also need to have
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:10,692'); seek(1750.0)">
              your private embedding, private vector, DB and
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:14,262'); seek(1754.0)">
              so on. And installing all that is not a rocket science,
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:18,078'); seek(1758.0)">
              but at the same time. It increases the complexity of your ecosystem
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:22,134'); seek(1762.0)">
              and there is a lot more that you have to maintain.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:26,774'); seek(1766.0)">
              And let's keep in mind that privacy and where the data is being sent
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:30,582'); seek(1770.0)">
              is just one aspect of legal concerns when it comes to llms.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:34,822'); seek(1774.0)">
              I would really recommend to read the license terms of
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:38,878'); seek(1778.0)">
              the ones you plan to use. For instance, you should not
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:42,414'); seek(1782.0)">
              get misled by the term open source. Open source
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:46,462'); seek(1786.0)">
              does not automatically mean that you can do everything with it.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:50,086'); seek(1790.0)">
              Some of open source licenses are limiting how you can use the
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:53,750'); seek(1793.0)">
              data produced by the LLM. So for instance, you won't
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:57,830'); seek(1797.0)">
              be able to use the data you collected for training another
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:01,798'); seek(1801.0)">
              LLM in case you decide to change the model.
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:05,904'); seek(1805.0)">
              So you collect the data from the chatbot. You cannot use that in the future
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:10,424'); seek(1810.0)">
              for the training purposes. Similarly,
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:13,600'); seek(1813.0)">
              generating synthetic data for machine learning model is very
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:17,240'); seek(1817.0)">
              blurry area when it gets to llms. So once
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:21,072'); seek(1821.0)">
              again, don't assume too much and make
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:24,504'); seek(1824.0)">
              sure you don't get into the unpleasant surprises.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:29,344'); seek(1829.0)">
              Another very important consideration when starting a project
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:33,224'); seek(1833.0)">
              and deciding which LLM to use is cost. And you might think
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:36,930'); seek(1836.0)">
              open source is cheaper because you basically don't pay for the API call.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:40,898'); seek(1840.0)">
              But in context of Llm it's not that obvious.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:44,514'); seek(1844.0)">
              And why is that? First of all,
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:47,514'); seek(1847.0)">
              because simple math is not that simple anymore.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:50,994'); seek(1850.0)">
              And what do I mean by the simple math?
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:54,194'); seek(1854.0)">
              Let's start with the API calls. For instance,
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:57,330'); seek(1857.0)">
              when you are using GPT 3.5, you pay
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:00,614'); seek(1860.0)">
              half a dollar per million tokens in the input and then
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:03,814'); seek(1863.0)">
              $1.5 for million tokens in the output.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:07,558'); seek(1867.0)">
              But then for GPT four you pay 30
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:11,062'); seek(1871.0)">
              and 60 respectively. So already order of magnitude
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:14,942'); seek(1874.0)">
              more. And in general you have a price list.
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:18,334'); seek(1878.0)">
              And based on that you can estimate how much single interaction
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:21,982'); seek(1881.0)">
              with user can cost and then you can multiply it by number
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:25,366'); seek(1885.0)">
              of expected interactions. But there
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:29,520'); seek(1889.0)">
              will be a few small asterisks to remember about. So first of all,
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:33,736'); seek(1893.0)">
              the math will depend not only on the number of tokens
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:37,440'); seek(1897.0)">
              in general, but also on our understanding of
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:41,160'); seek(1901.0)">
              what is the balance between input.
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:43,824'); seek(1903.0)">
              Cloud is cheaper for input but more expensive for output.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:48,104'); seek(1908.0)">
              And in most cases it's good enough assumption that token
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:51,608'); seek(1911.0)">
              is a word. But if you are in situation that
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:55,146'); seek(1915.0)">
              small difference matters. Then it's worth looking closer
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:58,562'); seek(1918.0)">
              at the tokenizers. It's worth looking
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:02,474'); seek(1922.0)">
              closer at them because the models use different tokenizers,
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:05,482'); seek(1925.0)">
              and number of tokens consumed for the same text
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:10,154'); seek(1930.0)">
              by cloud is different, actually a bit larger
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:14,162'); seek(1934.0)">
              than the one from chat GPT. So to make it even more
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:18,234'); seek(1938.0)">
              confusing, Google Gemini charges not per token
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:22,180'); seek(1942.0)">
              but per character. So the math
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:26,260'); seek(1946.0)">
              is a little bit tricky already. But doing
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:29,900'); seek(1949.0)">
              back of the envelope calculation should give us close enough
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:33,556'); seek(1953.0)">
              number, and it becomes much more
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:37,484'); seek(1957.0)">
              complex when we try to do the math for open source.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:41,196'); seek(1961.0)">
              For open source LLM, we host ourselves.
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:44,584'); seek(1964.0)">
              Then you don't calculate the cost per token or characters
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:48,448'); seek(1968.0)">
              produced, but you start with the price of the machine,
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:52,472'); seek(1972.0)">
              price of the GPU, the price for maintenance,
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:32:55,896'); seek(1975.0)">
              and then you need to estimate the expected traffic.
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:00,384'); seek(1980.0)">
              If your traffic is low, the cost per
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:03,792'); seek(1983.0)">
              request will be extremely high. So it's not obvious math.
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:07,624'); seek(1987.0)">
              It's prone to errors. In many cases, it will be more expensive
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:11,240'); seek(1991.0)">
              than using APIs, or, or at least the return of
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:14,956'); seek(1994.0)">
              investment won't be. I briefly mentioned open
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:18,436'); seek(1998.0)">
              source models, and I'm actually coming from the background where I've always been using
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:22,588'); seek(2002.0)">
              open source, open source databases, open source
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:25,908'); seek(2005.0)">
              data tools, and I really like them. But it
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:29,620'); seek(2009.0)">
              was kind of comfortable working with the open source products
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:33,132'); seek(2013.0)">
              because the open source was actually ahead. They were leading
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:36,924'); seek(2016.0)">
              the innovation and then at some point the cloud providers
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:40,724'); seek(2020.0)">
              came. They were to some extent kind of wrapping
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:44,844'); seek(2024.0)">
              the open source innovation into more convenient way of using
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:33:48,980'); seek(2028.0)">
              it. But now, I'm a bit sad to say that,
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:33:53,196'); seek(2033.0)">
              but the open source llms are still behind
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:33:56,684'); seek(2036.0)">
              and they don't perform as good as the commercial
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:00,476'); seek(2040.0)">
              ones. They are good, they are improving,
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:03,788'); seek(2043.0)">
              but be prepared for extra effort if you want to tune
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:07,516'); seek(2047.0)">
              specific use case with open source LLM. And of course
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:11,260'); seek(2051.0)">
              you can fine tune the model. But before you even do that,
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:15,148'); seek(2055.0)">
              make sure that your data is in good shape.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:18,004'); seek(2058.0)">
              Data will be the starting point for you anyway, and the
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:21,732'); seek(2061.0)">
              easiest way to start is with rag application instead of fine
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:25,140'); seek(2065.0)">
              tuning. So starting with simplerag can provide you with
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:28,980'); seek(2068.0)">
              much faster result and much faster feedback
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:32,996'); seek(2072.0)">
              from the customer. But if at some
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:36,924'); seek(2076.0)">
              point you decide to tune the model itself, beware that
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:41,396'); seek(2081.0)">
              there are various types of tuning and they differ.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:34:45,092'); seek(2085.0)">
              They differ in the sense of how much data you need,
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:34:48,484'); seek(2088.0)">
              what kind of results you can expect, and whether they introduce extra latency.
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:34:53,884'); seek(2093.0)">
              All things considered, building chatbots is an area
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:34:57,572'); seek(2097.0)">
              where you need to experiment a lot. But when you experiment, make sure
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:01,628'); seek(2101.0)">
              you don't get overwhelmed by that. Make sure you have
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:05,244'); seek(2105.0)">
              business goal in mind all the time, because it's very easy to get lost
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:09,636'); seek(2109.0)">
              and end up in never ending experiments.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:12,644'); seek(2112.0)">
              In most cases, you are not creating a research company.
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:15,900'); seek(2115.0)">
              In most cases you want to solve some specific business problems.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:19,684'); seek(2119.0)">
              So keep that in mind. So working with
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:23,332'); seek(2123.0)">
              llms is a very, very nice,
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:26,708'); seek(2126.0)">
              interesting job. But at the same time you need to stay focused
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:30,844'); seek(2130.0)">
              on the business goal and make sure you are pragmatic.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:36,484'); seek(2136.0)">
              Thanks a lot. If you have any questions,
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:39,776'); seek(2139.0)">
              drop me an email or drop me a line on LinkedIn. I'm always
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:43,288'); seek(2143.0)">
              happy to chat. Thank you.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Marcin%20Szymaniuk%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Marcin%20Szymaniuk%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 28 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Marcin%20Szymaniuk_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Marcin Szymaniuk
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    CEO @ TantusData
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/marcin-szymaniuk/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Marcin Szymaniuk's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Marcin Szymaniuk"
                  data-url="https://www.conf42.com/llms2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Large Language Models"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>