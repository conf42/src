<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Benchmarking the Warm-Up Performance of HotSpot VM, GraalVM and OpenJ9 -- A Learner's Journey</title>
    <meta name="description" content="Make your code Enterprise-ready.">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/java_frank.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Benchmarking the Warm-Up Performance of HotSpot VM, GraalVM and OpenJ9 -- A Learner's Journey | Conf42"/>
    <meta property="og:description" content="Are you new to the JVM? Did you just run your Java programs but never cared what the JVM does with your code under the hood? Want to learn about JVM internals, how to (not) write a Java benchmark test or are you simply curious about JVM performance? Then this talk is for you!"/>
    <meta property="og:url" content="https://conf42.com/Enterprise_Software_2021_Frank_Kriegl_hotspot_vm_graalvm_openj9"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/SREday2023_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        SREday San Francisco Q4 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-08
                      </p>
                      <!-- Button -->
                      <a href="https://sreday.com/2024-san-francisco-q4/" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-san-francisco-q4/">
                            SREday San Francisco Q4
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #555553;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Enterprise Software 2021 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2021-03-25">March 25 2021</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Make your code Enterprise-ready.
 -->
              <script>
                const event_date = new Date("2021-03-25T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2021-03-25T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "KcEDAMHvpis"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "lSguqR93rjs"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrC2XSOWkyyUkOWXMCnXmWiF" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "You. Hello everyone,", "timestamp": "00:00:25,410", "timestamp_s": 25.0}, {"text": "and thanks for tuning in to my talk at this year\u0027s", "timestamp": "00:00:28,652", "timestamp_s": 28.0}, {"text": "Conf 42 Java conference. Today I will talk about", "timestamp": "00:00:32,274", "timestamp_s": 32.0}, {"text": "benchmarking the warmer performance of hotspot VM,", "timestamp": "00:00:35,980", "timestamp_s": 35.0}, {"text": "crawl VM and OpenJ nine. Let\u0027s get started.", "timestamp": "00:00:39,186", "timestamp_s": 39.0}, {"text": "So, my name is Frank Kriegl. I live in Heidelberg,", "timestamp": "00:00:43,132", "timestamp_s": 43.0}, {"text": "Germany, and I\u0027ve been working as a Java developer since", "timestamp": "00:00:47,042", "timestamp_s": 47.0}, {"text": "almost four years, and currently I\u0027m also finishing", "timestamp": "00:00:51,810", "timestamp_s": 51.0}, {"text": "my master of science in parallel to my regular employment,", "timestamp": "00:00:56,218", "timestamp_s": 56.0}, {"text": "which is also where this talk originates from.", "timestamp": "00:01:00,058", "timestamp_s": 60.0}, {"text": "Recently I had to write research paper", "timestamp": "00:01:03,416", "timestamp_s": 63.0}, {"text": "and I was simply curious to learn more about", "timestamp": "00:01:07,510", "timestamp_s": 67.0}, {"text": "jvms in general and saw this as a chance to deepen", "timestamp": "00:01:11,096", "timestamp_s": 71.0}, {"text": "my knowledge. And that\u0027s why this talk\u0027s subtitle", "timestamp": "00:01:14,734", "timestamp_s": 74.0}, {"text": "is also a learner\u0027s journey. So here\u0027s today\u0027s agenda.", "timestamp": "00:01:18,258", "timestamp_s": 78.0}, {"text": "First, I will start with a brief introduction.", "timestamp": "00:01:23,210", "timestamp_s": 83.0}, {"text": "Then I will set the baseline with some information bits", "timestamp": "00:01:27,138", "timestamp_s": 87.0}, {"text": "about JVM internals. Next I will talk", "timestamp": "00:01:30,738", "timestamp_s": 90.0}, {"text": "about my learnings when I try to compare the warmup performance", "timestamp": "00:01:33,872", "timestamp_s": 93.0}, {"text": "of the three different JVM. So I will spend", "timestamp": "00:01:37,926", "timestamp_s": 97.0}, {"text": "some words on the pitfalls of creating good or", "timestamp": "00:01:41,796", "timestamp_s": 101.0}, {"text": "bad benchmark tests.", "timestamp": "00:01:46,020", "timestamp_s": 106.0}, {"text": "Next I will describe my test adapt", "timestamp": "00:01:48,850", "timestamp_s": 108.0}, {"text": "for benchmarking the warmup performance, and also", "timestamp": "00:01:52,538", "timestamp_s": 112.0}, {"text": "mention some configurations I made for the", "timestamp": "00:01:56,790", "timestamp_s": 116.0}, {"text": "jvms on the test. Finally, I\u0027d like to present you", "timestamp": "00:02:00,488", "timestamp_s": 120.0}, {"text": "my test results and for sure also give some interpretation", "timestamp": "00:02:03,992", "timestamp_s": 123.0}, {"text": "on them. In the end, I will draw a short conclusion.", "timestamp": "00:02:07,602", "timestamp_s": 127.0}, {"text": "The goal of my talk is actually to motivate you to", "timestamp": "00:02:10,834", "timestamp_s": 130.0}, {"text": "start with java micro benchmarking on your own. So I hope", "timestamp": "00:02:15,180", "timestamp_s": 135.0}, {"text": "that in the end of this presentation you will have a basic", "timestamp": "00:02:18,540", "timestamp_s": 138.0}, {"text": "understanding of JVMs and are ready to get started with", "timestamp": "00:02:21,798", "timestamp_s": 141.0}, {"text": "your own java or JVM benchmark measurements. So let\u0027s", "timestamp": "00:02:25,536", "timestamp_s": 145.0}, {"text": "talk about the what and why. What is warmup actually?", "timestamp": "00:02:29,318", "timestamp_s": 149.0}, {"text": "Usually, warmup is defined as the number of iterations the", "timestamp": "00:02:34,290", "timestamp_s": 154.0}, {"text": "JVM needs to increase the speed of method execution between", "timestamp": "00:02:38,388", "timestamp_s": 158.0}, {"text": "the first and the nth invocation by", "timestamp": "00:02:41,876", "timestamp_s": 161.0}, {"text": "applying JIT compiler optimizations on the bytecode. Okay, that\u0027s the", "timestamp": "00:02:45,032", "timestamp_s": 165.0}, {"text": "definition, and now let me show you what it actually means. So in this", "timestamp": "00:02:49,512", "timestamp_s": 169.0}, {"text": "chart you see on the vertical axis the time", "timestamp": "00:02:53,432", "timestamp_s": 173.0}, {"text": "per operation, and on the horizontal axis the number of", "timestamp": "00:02:56,876", "timestamp_s": 176.0}, {"text": "iterations and warmup is the part", "timestamp": "00:03:00,348", "timestamp_s": 180.0}, {"text": "here. From the first iteration, it takes quite long to", "timestamp": "00:03:03,756", "timestamp_s": 183.0}, {"text": "complete one operation for the JVM one method execution, and over", "timestamp": "00:03:07,628", "timestamp_s": 187.0}, {"text": "time it\u0027s getting faster. So after 200 iterations", "timestamp": "00:03:11,536", "timestamp_s": 191.0}, {"text": "it\u0027s much faster than the first iteration.", "timestamp": "00:03:15,542", "timestamp_s": 195.0}, {"text": "And this decline in execution time is called", "timestamp": "00:03:18,534", "timestamp_s": 198.0}, {"text": "warm up. Next, I\u0027d like to answer the question why?", "timestamp": "00:03:21,616", "timestamp_s": 201.0}, {"text": "I would like to compare this. So mainly out of curiosity,", "timestamp": "00:03:25,092", "timestamp_s": 205.0}, {"text": "to be honest. But there are for sure also some actual", "timestamp": "00:03:29,370", "timestamp_s": 209.0}, {"text": "reasons. Like I was searching on the Internet and I", "timestamp": "00:03:33,300", "timestamp_s": 213.0}, {"text": "only found little research in this area. So the most", "timestamp": "00:03:37,112", "timestamp_s": 217.0}, {"text": "interesting article I found was don\u0027t get caught in the", "timestamp": "00:03:40,696", "timestamp_s": 220.0}, {"text": "cold warmup your jvm and it\u0027s but hot", "timestamp": "00:03:44,248", "timestamp_s": 224.0}, {"text": "tub which is a new JVM implementation to", "timestamp": "00:03:48,172", "timestamp_s": 228.0}, {"text": "use pre cared JVM to avoid the warmup", "timestamp": "00:03:51,532", "timestamp_s": 231.0}, {"text": "overhead. And so I thought, okay, why not doing my own research? I just", "timestamp": "00:03:55,058", "timestamp_s": 235.0}, {"text": "wanted to see how much the jvms I wanted to", "timestamp": "00:03:59,232", "timestamp_s": 239.0}, {"text": "test how they differ in the method, warmup speed, and eventually", "timestamp": "00:04:03,088", "timestamp_s": 243.0}, {"text": "if there is a difference. Well, there is a difference and", "timestamp": "00:04:07,782", "timestamp_s": 247.0}, {"text": "what it looks like between JIt compilers and Aot compilers,", "timestamp": "00:04:11,892", "timestamp_s": 251.0}, {"text": "and the code they produce. Okay, next it\u0027s about", "timestamp": "00:04:15,738", "timestamp_s": 255.0}, {"text": "setting the baseline. So on this slide you", "timestamp": "00:04:19,492", "timestamp_s": 259.0}, {"text": "see a picture of the Java heap structure.", "timestamp": "00:04:22,952", "timestamp_s": 262.0}, {"text": "The example is for the hotspot VM, and the Java", "timestamp": "00:04:26,606", "timestamp_s": 266.0}, {"text": "heap is actually separated into several parts.", "timestamp": "00:04:30,254", "timestamp_s": 270.0}, {"text": "So you see here there is the young generation and", "timestamp": "00:04:33,646", "timestamp_s": 273.0}, {"text": "the old generation. And the young generation itself consists", "timestamp": "00:04:37,500", "timestamp_s": 277.0}, {"text": "of Eden space and two survivor spaces.", "timestamp": "00:04:41,410", "timestamp_s": 281.0}, {"text": "So how does memory allocation happen in the JVM?", "timestamp": "00:04:45,026", "timestamp_s": 285.0}, {"text": "New memory is always allocated in the Eden space,", "timestamp": "00:04:48,834", "timestamp_s": 288.0}, {"text": "and as soon as just before the Eden space", "timestamp": "00:04:53,056", "timestamp_s": 293.0}, {"text": "fills up, some minor garbage collection occurs", "timestamp": "00:04:56,560", "timestamp_s": 296.0}, {"text": "and the objects are transferred into survivor spaces.", "timestamp": "00:05:00,038", "timestamp_s": 300.0}, {"text": "One survivor space is always free and the other one", "timestamp": "00:05:03,754", "timestamp_s": 303.0}, {"text": "is occupied. And if one survivor", "timestamp": "00:05:06,996", "timestamp_s": 306.0}, {"text": "space is running full, minor garbage collection will", "timestamp": "00:05:10,234", "timestamp_s": 310.0}, {"text": "just swap these spaces, clear up unused objects", "timestamp": "00:05:13,752", "timestamp_s": 313.0}, {"text": "or unreferenced objects, and the survivors will stay there.", "timestamp": "00:05:17,918", "timestamp_s": 317.0}, {"text": "If there are long living objects that survive several minor", "timestamp": "00:05:21,624", "timestamp_s": 321.0}, {"text": "garbage collection cycles, it could actually happen that some", "timestamp": "00:05:25,038", "timestamp_s": 325.0}, {"text": "major garbage collection occurs and these objects", "timestamp": "00:05:29,180", "timestamp_s": 329.0}, {"text": "are then transferred into the old generation space,", "timestamp": "00:05:32,578", "timestamp_s": 332.0}, {"text": "also called tenured space. Next, and I already mentioned it,", "timestamp": "00:05:36,444", "timestamp_s": 336.0}, {"text": "I briefly touched the topic of garbage collection.", "timestamp": "00:05:40,480", "timestamp_s": 340.0}, {"text": "So meanwhile there exists, I think, seven garbage", "timestamp": "00:05:43,446", "timestamp_s": 343.0}, {"text": "collection algorithms, at least in the version of Java", "timestamp": "00:05:47,542", "timestamp_s": 347.0}, {"text": "eleven. Thing is that garbage collection can have", "timestamp": "00:05:51,018", "timestamp_s": 351.0}, {"text": "unwanted side effects in performance testing,", "timestamp": "00:05:54,436", "timestamp_s": 354.0}, {"text": "so you better try to eliminate that.", "timestamp": "00:05:58,058", "timestamp_s": 358.0}, {"text": "Luckily, there\u0027s the Java enhancement proposal 318,", "timestamp": "00:06:01,588", "timestamp_s": 361.0}, {"text": "which is about epsilon, a no op garbage collector.", "timestamp": "00:06:07,006", "timestamp_s": 367.0}, {"text": "I linked it here, can read the details if you", "timestamp": "00:06:10,974", "timestamp_s": 370.0}, {"text": "like. And that\u0027s actually a garbage collection algorithm which will", "timestamp": "00:06:14,168", "timestamp_s": 374.0}, {"text": "always allocate memory but never freed up again.", "timestamp": "00:06:18,316", "timestamp_s": 378.0}, {"text": "Next, it\u0027s about JIT versus Aot compilation.", "timestamp": "00:06:21,836", "timestamp_s": 381.0}, {"text": "So as you might know, Java code is pre compiled to", "timestamp": "00:06:25,890", "timestamp_s": 385.0}, {"text": "Java bytecode, which will then be run on any", "timestamp": "00:06:30,080", "timestamp_s": 390.0}, {"text": "JVM. The JIT compiler, just in time compiler is", "timestamp": "00:06:33,600", "timestamp_s": 393.0}, {"text": "first doing some profiling on the bytecode and", "timestamp": "00:06:37,344", "timestamp_s": 397.0}, {"text": "then it will apply optimizations like", "timestamp": "00:06:41,668", "timestamp_s": 401.0}, {"text": "method inlining, branch prediction, loop unrolling, dead code", "timestamp": "00:06:45,060", "timestamp_s": 405.0}, {"text": "elimination, and many more.", "timestamp": "00:06:48,916", "timestamp_s": 408.0}, {"text": "And it will also only compile parts of", "timestamp": "00:06:51,668", "timestamp_s": 411.0}, {"text": "the bytecode to machine code because it has to decide which parts", "timestamp": "00:06:55,252", "timestamp_s": 415.0}, {"text": "of the code need to be optimized. Then on the other hand, there\u0027s the head", "timestamp": "00:06:59,038", "timestamp_s": 419.0}, {"text": "of time compiler, which will just directly compile", "timestamp": "00:07:02,968", "timestamp_s": 422.0}, {"text": "all the bytecode to machine code when JVM starts", "timestamp": "00:07:06,866", "timestamp_s": 426.0}, {"text": "up. So for the jig compiler", "timestamp": "00:07:10,658", "timestamp_s": 430.0}, {"text": "since JDK eight, there are actually five", "timestamp": "00:07:13,954", "timestamp_s": 433.0}, {"text": "levels of tit compilation. At least that\u0027s what applies for", "timestamp": "00:07:17,792", "timestamp_s": 437.0}, {"text": "the hotspot VM. The first level is just about interpreting", "timestamp": "00:07:21,488", "timestamp_s": 441.0}, {"text": "bytecode, so it\u0027s level zero, and the JVM", "timestamp": "00:07:25,542", "timestamp_s": 445.0}, {"text": "will not compile anything at all, but just run as", "timestamp": "00:07:29,622", "timestamp_s": 449.0}, {"text": "an interpreter. And after a few iterations the chit", "timestamp": "00:07:33,268", "timestamp_s": 453.0}, {"text": "compiler will make use of its first compiler. It\u0027s the C one", "timestamp": "00:07:37,258", "timestamp_s": 457.0}, {"text": "compiler, also called client compiler,", "timestamp": "00:07:41,236", "timestamp_s": 461.0}, {"text": "and produce some simple c one compile", "timestamp": "00:07:44,014", "timestamp_s": 464.0}, {"text": "code. So we talk about level one, two three", "timestamp": "00:07:47,406", "timestamp_s": 467.0}, {"text": "compilations, which are all done by this C one compiler.", "timestamp": "00:07:50,872", "timestamp_s": 470.0}, {"text": "After about 10,000 invocations, code will", "timestamp": "00:07:54,414", "timestamp_s": 474.0}, {"text": "eventually become marked as hot,", "timestamp": "00:07:58,220", "timestamp_s": 478.0}, {"text": "and then it will become subject to level", "timestamp": "00:08:01,372", "timestamp_s": 481.0}, {"text": "four compilations, which is then done by the c two compiler.", "timestamp": "00:08:04,812", "timestamp_s": 484.0}, {"text": "This is cared a server compiler and it will do some", "timestamp": "00:08:08,166", "timestamp_s": 488.0}, {"text": "much better optimization with your Java bytecode. Okay,", "timestamp": "00:08:11,936", "timestamp_s": 491.0}, {"text": "next we continue with Java micro benchmarking. My lessons", "timestamp": "00:08:15,616", "timestamp_s": 495.0}, {"text": "learned so I was not sure in the beginning", "timestamp": "00:08:19,766", "timestamp_s": 499.0}, {"text": "how to start my learners journey.", "timestamp": "00:08:23,402", "timestamp_s": 503.0}, {"text": "I searched on the Internet and found that there are existing benchmark", "timestamp": "00:08:26,714", "timestamp_s": 506.0}, {"text": "suites like spec JVM 2008,", "timestamp": "00:08:30,858", "timestamp_s": 510.0}, {"text": "which is from 2008, and the Decapo", "timestamp": "00:08:34,520", "timestamp_s": 514.0}, {"text": "benchmark suite, which was first released in 2009.", "timestamp": "00:08:38,094", "timestamp_s": 518.0}, {"text": "While the last maintenance release of the cared benchmark", "timestamp": "00:08:41,864", "timestamp_s": 521.0}, {"text": "suite is almost two years ago, which was eight months", "timestamp": "00:08:45,966", "timestamp_s": 525.0}, {"text": "before the release of JDK eleven, for me they felt quite", "timestamp": "00:08:49,836", "timestamp_s": 529.0}, {"text": "outdated, so I didn\u0027t want to use them for that reason.", "timestamp": "00:08:53,516", "timestamp_s": 533.0}, {"text": "Also, not all benchmark tests were working with the", "timestamp": "00:08:57,020", "timestamp_s": 537.0}, {"text": "targeted Java version eleven, so I was actually trying to use them,", "timestamp": "00:09:00,624", "timestamp_s": 540.0}, {"text": "but failed. And finally the", "timestamp": "00:09:04,288", "timestamp_s": 544.0}, {"text": "output format. The measurement units did not suit", "timestamp": "00:09:07,632", "timestamp_s": 547.0}, {"text": "or run it in a suitable format, which I could use for further analyzing", "timestamp": "00:09:11,958", "timestamp_s": 551.0}, {"text": "the collected data. So simply using some", "timestamp": "00:09:15,978", "timestamp_s": 555.0}, {"text": "out of the box benchmark suites did not work for me.", "timestamp": "00:09:19,796", "timestamp_s": 559.0}, {"text": "So I came up with the idea of writing my own benchmark.", "timestamp": "00:09:23,348", "timestamp_s": 563.0}, {"text": "You have to know, writing a good benchmark is not easy.", "timestamp": "00:09:27,246", "timestamp_s": 567.0}, {"text": "There are two fault categories. On the one hand, there are conceptual", "timestamp": "00:09:30,616", "timestamp_s": 570.0}, {"text": "flaws when designing a micro benchmark, which I will show you an example", "timestamp": "00:09:34,686", "timestamp_s": 574.0}, {"text": "in a minute, and on the other hand, there are contextual effects when", "timestamp": "00:09:38,200", "timestamp_s": 578.0}, {"text": "running it. Here is an example for a conceptual flaw.", "timestamp": "00:09:42,092", "timestamp_s": 582.0}, {"text": "On the left hand side we have the method create arrayupto", "timestamp": "00:09:45,090", "timestamp_s": 585.0}, {"text": "and the method that code elimination, which will", "timestamp": "00:09:48,674", "timestamp_s": 588.0}, {"text": "invoke the first method to create an array with the length of 21,000", "timestamp": "00:09:52,368", "timestamp_s": 592.0}, {"text": "containing values from one to 21,000. The array is", "timestamp": "00:09:56,384", "timestamp_s": 596.0}, {"text": "then processed and all the values are accumulated", "timestamp": "00:10:00,192", "timestamp_s": 600.0}, {"text": "into the result variable, but this variable is actually", "timestamp": "00:10:03,770", "timestamp_s": 603.0}, {"text": "never returned, so the calculation result is not used at", "timestamp": "00:10:07,908", "timestamp_s": 607.0}, {"text": "all. If we then execute this for like", "timestamp": "00:10:11,428", "timestamp_s": 611.0}, {"text": "18,000 times, invoke system current time", "timestamp": "00:10:15,060", "timestamp_s": 615.0}, {"text": "millies before and after the method invocation, we could calculate", "timestamp": "00:10:18,372", "timestamp_s": 618.0}, {"text": "the duration it takes to execute that code elimination", "timestamp": "00:10:21,982", "timestamp_s": 621.0}, {"text": "method by subtract the start value from the end value.", "timestamp": "00:10:25,618", "timestamp_s": 625.0}, {"text": "But here\u0027s the issue. When running the code, the JVM will", "timestamp": "00:10:29,804", "timestamp_s": 629.0}, {"text": "first just interpret your method and eventually collect", "timestamp": "00:10:33,772", "timestamp_s": 633.0}, {"text": "some profiling data on it and figure out that the", "timestamp": "00:10:37,986", "timestamp_s": 637.0}, {"text": "result of the method is actually never used because", "timestamp": "00:10:41,632", "timestamp_s": 641.0}, {"text": "it\u0027s never returned. So at some point in time the JVM", "timestamp": "00:10:44,976", "timestamp_s": 644.0}, {"text": "will just eliminate this invocation and you\u0027ll see that", "timestamp": "00:10:48,662", "timestamp_s": 648.0}, {"text": "in your output that at some point in time the", "timestamp": "00:10:52,548", "timestamp_s": 652.0}, {"text": "execution time will just drop to almost zero milliseconds", "timestamp": "00:10:55,972", "timestamp_s": 655.0}, {"text": "because what you measure is just the time between invoking", "timestamp": "00:11:00,282", "timestamp_s": 660.0}, {"text": "system current time release the first time and the second time.", "timestamp": "00:11:04,542", "timestamp_s": 664.0}, {"text": "But there is JMH to the rescue, so conceptual flaws", "timestamp": "00:11:08,104", "timestamp_s": 668.0}, {"text": "can mostly be avoided by using frameworks like JMH.", "timestamp": "00:11:12,158", "timestamp_s": 672.0}, {"text": "JMH is the Java benchmarking house,", "timestamp": "00:11:15,806", "timestamp_s": 675.0}, {"text": "and it is a tool that was created with the intention to help", "timestamp": "00:11:19,660", "timestamp_s": 679.0}, {"text": "developers in avoiding common pitfalls when writing and", "timestamp": "00:11:23,276", "timestamp_s": 683.0}, {"text": "executing Java benchmarks. So it\u0027s actually", "timestamp": "00:11:26,636", "timestamp_s": 686.0}, {"text": "quite handy to use it. But also you have to be careful what you\u0027re", "timestamp": "00:11:30,076", "timestamp_s": 690.0}, {"text": "doing. And here you can see one of my first tries", "timestamp": "00:11:34,038", "timestamp_s": 694.0}, {"text": "where I was using JMH to write my own benchmark. I actually", "timestamp": "00:11:38,294", "timestamp_s": 698.0}, {"text": "asked for some feedback on Twitter and got none,", "timestamp": "00:11:42,192", "timestamp_s": 702.0}, {"text": "but didn\u0027t stop me from continuing my learning journey.", "timestamp": "00:11:45,530", "timestamp_s": 705.0}, {"text": "You can see there are two things I\u0027d like to point out here. One thing", "timestamp": "00:11:48,794", "timestamp_s": 708.0}, {"text": "is that JMH provides you with black holes,", "timestamp": "00:11:52,292", "timestamp_s": 712.0}, {"text": "which you can use to consume some objects in", "timestamp": "00:11:55,694", "timestamp_s": 715.0}, {"text": "your benchmark. So this will make sure that the code is not eliminated", "timestamp": "00:11:59,144", "timestamp_s": 719.0}, {"text": "by the JVM. You could also just return that or print it to", "timestamp": "00:12:03,278", "timestamp_s": 723.0}, {"text": "system out that will have the same effect, but there are black holes then.", "timestamp": "00:12:07,016", "timestamp_s": 727.0}, {"text": "Second is that you should also consider warm up and", "timestamp": "00:12:10,780", "timestamp_s": 730.0}, {"text": "there\u0027s an annotation at fork and you can specify the", "timestamp": "00:12:14,860", "timestamp_s": 734.0}, {"text": "number of forks which you want to execute. So how often", "timestamp": "00:12:18,048", "timestamp_s": 738.0}, {"text": "the benchmark test should be executed in standalone", "timestamp": "00:12:21,984", "timestamp_s": 741.0}, {"text": "jvms and also warmup iterations to actually avoid", "timestamp": "00:12:25,446", "timestamp_s": 745.0}, {"text": "warmup when benchmarking your code. But in my case I wanted to", "timestamp": "00:12:29,702", "timestamp_s": 749.0}, {"text": "measure warmup, so I set this to zero to get some observation.", "timestamp": "00:12:33,268", "timestamp_s": 753.0}, {"text": "I tried several different approaches to write some", "timestamp": "00:12:36,858", "timestamp_s": 756.0}, {"text": "good benchmark tests. I tried to reuse existing benchmark tests", "timestamp": "00:12:40,740", "timestamp_s": 760.0}, {"text": "from the Dakarpo or spec JVM suite, but that all", "timestamp": "00:12:45,182", "timestamp_s": 765.0}, {"text": "didn\u0027t work out for me. But in the end I ended", "timestamp": "00:12:48,920", "timestamp_s": 768.0}, {"text": "up with a sudoku backdracking algorithm, which turned", "timestamp": "00:12:52,878", "timestamp_s": 772.0}, {"text": "out to be working quite well for my case. So you can find", "timestamp": "00:12:56,798", "timestamp_s": 776.0}, {"text": "that code on GitHub. I will not go into details there,", "timestamp": "00:13:00,108", "timestamp_s": 780.0}, {"text": "but this is the code I used to benchmark the JVM warmup", "timestamp": "00:13:03,708", "timestamp_s": 783.0}, {"text": "performance. So here\u0027s my test environment.", "timestamp": "00:13:07,474", "timestamp_s": 787.0}, {"text": "I did all the benchmarking on a virtual machine,", "timestamp": "00:13:11,126", "timestamp_s": 791.0}, {"text": "which is not optimal, but I tried to", "timestamp": "00:13:14,694", "timestamp_s": 794.0}, {"text": "compensate that with multiple test runs. See that in a minute.", "timestamp": "00:13:17,808", "timestamp_s": 797.0}, {"text": "So the operating system is a Ubuntu version 2064", "timestamp": "00:13:21,082", "timestamp_s": 801.0}, {"text": "bits, and I had eight virtual cpu cores based", "timestamp": "00:13:25,812", "timestamp_s": 805.0}, {"text": "on AMD Opturam processor. There were eight", "timestamp": "00:13:30,116", "timestamp_s": 810.0}, {"text": "gigs of ram available, no swap configured, and a storage", "timestamp": "00:13:33,492", "timestamp_s": 813.0}, {"text": "of eight gig hard drive disk. My test setup", "timestamp": "00:13:37,482", "timestamp_s": 817.0}, {"text": "I decided to execute my benchmark tests with", "timestamp": "00:13:40,590", "timestamp_s": 820.0}, {"text": "21,000 iterations to also see some", "timestamp": "00:13:44,968", "timestamp_s": 824.0}, {"text": "effect when a method gets marked as hot.", "timestamp": "00:13:48,636", "timestamp_s": 828.0}, {"text": "Every one consisted of 20 forks, which means that JMH", "timestamp": "00:13:52,028", "timestamp_s": 832.0}, {"text": "will spawn up 20 independent jvms", "timestamp": "00:13:56,626", "timestamp_s": 836.0}, {"text": "to not accidentally make use of already pre cared", "timestamp": "00:14:00,054", "timestamp_s": 840.0}, {"text": "code. Then I executed twelve runs", "timestamp": "00:14:03,686", "timestamp_s": 843.0}, {"text": "at different days and daytimes to eliminate these", "timestamp": "00:14:07,510", "timestamp_s": 847.0}, {"text": "contextual effects I would face in a virtual environment.", "timestamp": "00:14:11,140", "timestamp_s": 851.0}, {"text": "When you multiply all these numbers, 21,000 iterations", "timestamp": "00:14:15,098", "timestamp_s": 855.0}, {"text": "in 20 forks and twelve runs, you get", "timestamp": "00:14:18,698", "timestamp_s": 858.0}, {"text": "5.4 million sudoku solved per JVM.", "timestamp": "00:14:22,692", "timestamp_s": 862.0}, {"text": "Always the same sudoku though the JVM parameters.", "timestamp": "00:14:26,638", "timestamp_s": 866.0}, {"text": "I did not touch much because I wanted", "timestamp": "00:14:30,286", "timestamp_s": 870.0}, {"text": "to take the approach of simulating a", "timestamp": "00:14:33,384", "timestamp_s": 873.0}, {"text": "daily user who would just throw code the JVM at the JVM and", "timestamp": "00:14:36,584", "timestamp_s": 876.0}, {"text": "run it. Besides two exceptions, the one is that I was using", "timestamp": "00:14:40,188", "timestamp_s": 880.0}, {"text": "the no operation garbage collector epsilon or", "timestamp": "00:14:43,916", "timestamp_s": 883.0}, {"text": "respective other ones for the other jvms,", "timestamp": "00:14:47,852", "timestamp_s": 887.0}, {"text": "and also the pretouch memory option, which I will explain in", "timestamp": "00:14:51,494", "timestamp_s": 891.0}, {"text": "a minute. So here are my jvms under test I", "timestamp": "00:14:55,024", "timestamp_s": 895.0}, {"text": "decided for the tried and trusted hotspot VM", "timestamp": "00:14:58,720", "timestamp_s": 898.0}, {"text": "where I used an OpenJDK 64 bit", "timestamp": "00:15:02,378", "timestamp_s": 902.0}, {"text": "build from adopt OpenjDK. And as you", "timestamp": "00:15:05,620", "timestamp_s": 905.0}, {"text": "can see I also configured some alias for every jvm which", "timestamp": "00:15:09,044", "timestamp_s": 909.0}, {"text": "I could use later and just shorten the amount", "timestamp": "00:15:13,172", "timestamp_s": 913.0}, {"text": "of text on my slides. So secondly,", "timestamp": "00:15:16,712", "timestamp_s": 916.0}, {"text": "I went for GraalVM, which is a polyglode VM.", "timestamp": "00:15:20,174", "timestamp_s": 920.0}, {"text": "I used the community edition for my benchmark testing in version", "timestamp": "00:15:23,934", "timestamp_s": 923.0}, {"text": "22. And last but not least,", "timestamp": "00:15:28,178", "timestamp_s": 928.0}, {"text": "Opengenine as an enterprise JVM, which actually", "timestamp": "00:15:31,804", "timestamp_s": 931.0}, {"text": "promises to have better performance on its website than hotspot", "timestamp": "00:15:35,420", "timestamp_s": 935.0}, {"text": "VM. We\u0027ll talk about that later. Yeah, with this test", "timestamp": "00:15:39,458", "timestamp_s": 939.0}, {"text": "setup, I started my measurements. So let\u0027s take a look at", "timestamp": "00:15:43,536", "timestamp_s": 943.0}, {"text": "the runtime flex which I used to execute my benchmark.", "timestamp": "00:15:47,552", "timestamp_s": 947.0}, {"text": "This one is for hotspot VM, and let\u0027s go through the", "timestamp": "00:15:51,210", "timestamp_s": 951.0}, {"text": "lines step by step. So here I specify", "timestamp": "00:15:54,868", "timestamp_s": 954.0}, {"text": "the benchmark target, which is my backtracking algorithm,", "timestamp": "00:15:58,426", "timestamp_s": 958.0}, {"text": "and this is just some syntax given by JMH.", "timestamp": "00:16:02,474", "timestamp_s": 962.0}, {"text": "The next line I will have to provide some JVM", "timestamp": "00:16:06,382", "timestamp_s": 966.0}, {"text": "arguments for JMH that it will use for every", "timestamp": "00:16:10,302", "timestamp_s": 970.0}, {"text": "fork it spawns up to execute the benchmark.", "timestamp": "00:16:13,896", "timestamp_s": 973.0}, {"text": "I used a configuration of 5gb of heap", "timestamp": "00:16:17,154", "timestamp_s": 977.0}, {"text": "and also provided the flag heap dump on", "timestamp": "00:16:21,170", "timestamp_s": 981.0}, {"text": "out of memory error to just show me if my", "timestamp": "00:16:24,396", "timestamp_s": 984.0}, {"text": "JVM crashes. Next you see some double", "timestamp": "00:16:27,612", "timestamp_s": 987.0}, {"text": "x flags like unlock experimental VM options, which I need", "timestamp": "00:16:30,902", "timestamp_s": 990.0}, {"text": "to make use of the Epsilon garbage collector, which I", "timestamp": "00:16:34,560", "timestamp_s": 994.0}, {"text": "mentioned earlier to avoid garbage collection interrupting", "timestamp": "00:16:37,888", "timestamp_s": 997.0}, {"text": "my measurements. And then there\u0027s also the always pre touch", "timestamp": "00:16:41,514", "timestamp_s": 1001.0}, {"text": "option which will claim physical memory", "timestamp": "00:16:45,204", "timestamp_s": 1005.0}, {"text": "from the operating system right at the beginning rather", "timestamp": "00:16:48,618", "timestamp_s": 1008.0}, {"text": "than on the fly. So this would also eliminate", "timestamp": "00:16:52,276", "timestamp_s": 1012.0}, {"text": "some interference by the JVM when it would find", "timestamp": "00:16:56,458", "timestamp_s": 1016.0}, {"text": "out that it needs more memory. This flag will just tell JMH", "timestamp": "00:16:59,912", "timestamp_s": 1019.0}, {"text": "where to store the measurement output and in which format,", "timestamp": "00:17:04,110", "timestamp_s": 1024.0}, {"text": "so it can output things in adjacent format and also", "timestamp": "00:17:07,986", "timestamp_s": 1027.0}, {"text": "others. And last line, I specify the number", "timestamp": "00:17:11,756", "timestamp_s": 1031.0}, {"text": "of iterations, which is 21,000 per fork. I run", "timestamp": "00:17:15,228", "timestamp_s": 1035.0}, {"text": "20 forks and the timeout is just", "timestamp": "00:17:19,104", "timestamp_s": 1039.0}, {"text": "set to 360 minutes, which is very high,", "timestamp": "00:17:22,464", "timestamp_s": 1042.0}, {"text": "but just didn\u0027t want to let JMH time but", "timestamp": "00:17:26,912", "timestamp_s": 1046.0}, {"text": "and abort my measurements. Okay, and the last line I just wanted", "timestamp": "00:17:30,528", "timestamp_s": 1050.0}, {"text": "to collect the output of my program into a", "timestamp": "00:17:34,340", "timestamp_s": 1054.0}, {"text": "log file. The runtime flags for GraalVM look quite", "timestamp": "00:17:37,828", "timestamp_s": 1057.0}, {"text": "similar. For one small exception,", "timestamp": "00:17:41,172", "timestamp_s": 1061.0}, {"text": "I did not find any no operation garbage collection algorithm", "timestamp": "00:17:43,978", "timestamp_s": 1063.0}, {"text": "for GraalVM in this version. So I made use of a", "timestamp": "00:17:47,882", "timestamp_s": 1067.0}, {"text": "workaround. I set the max new size parameter", "timestamp": "00:17:51,224", "timestamp_s": 1071.0}, {"text": "for libcall compiler to a number which", "timestamp": "00:17:55,102", "timestamp_s": 1075.0}, {"text": "is higher than the actually available memory for the heap,", "timestamp": "00:17:58,748", "timestamp_s": 1078.0}, {"text": "which makes the JVM create a huge young", "timestamp": "00:18:02,450", "timestamp_s": 1082.0}, {"text": "generation, but no old generation space in the heap.", "timestamp": "00:18:06,156", "timestamp_s": 1086.0}, {"text": "So what would occur here is that actually no garbage collection", "timestamp": "00:18:09,766", "timestamp_s": 1089.0}, {"text": "can occur, or before it would occur, the JVM", "timestamp": "00:18:13,894", "timestamp_s": 1093.0}, {"text": "would run out of memory. So it\u0027s important to have", "timestamp": "00:18:17,206", "timestamp_s": 1097.0}, {"text": "enough memory for your benchmark tests available. Opengen nine", "timestamp": "00:18:20,676", "timestamp_s": 1100.0}, {"text": "has also a slight difference here. I unfortunately", "timestamp": "00:18:24,772", "timestamp_s": 1104.0}, {"text": "found that the Linux version of Openj nine", "timestamp": "00:18:28,906", "timestamp_s": 1108.0}, {"text": "does not offer a pretouch option. So this", "timestamp": "00:18:32,260", "timestamp_s": 1112.0}, {"text": "one will claim memory on the fly if it needs more from", "timestamp": "00:18:35,876", "timestamp_s": 1115.0}, {"text": "the operating system. Okay, that was the setup. And now", "timestamp": "00:18:39,048", "timestamp_s": 1119.0}, {"text": "I would already like to share some test results. Here you", "timestamp": "00:18:42,376", "timestamp_s": 1122.0}, {"text": "see the overall chart which I generated out", "timestamp": "00:18:45,868", "timestamp_s": 1125.0}, {"text": "of the collected data from the benchmarking", "timestamp": "00:18:49,068", "timestamp_s": 1129.0}, {"text": "of hotspot vm. It\u0027s on the vertical axis,", "timestamp": "00:18:52,306", "timestamp_s": 1132.0}, {"text": "again the time per operation in nanoseconds.", "timestamp": "00:18:55,906", "timestamp_s": 1135.0}, {"text": "And on the horizontal axis, the number of iterations up to", "timestamp": "00:18:59,490", "timestamp_s": 1139.0}, {"text": "21,000. If we now zoom in a little,", "timestamp": "00:19:03,216", "timestamp_s": 1143.0}, {"text": "you can see that there is a light red colored background", "timestamp": "00:19:06,608", "timestamp_s": 1146.0}, {"text": "of the warmup graph. And I call this light colored graph", "timestamp": "00:19:10,522", "timestamp_s": 1150.0}, {"text": "the scatter shade because this actually represents the scattering", "timestamp": "00:19:14,682", "timestamp_s": 1154.0}, {"text": "of the different fox individual data", "timestamp": "00:19:19,002", "timestamp_s": 1159.0}, {"text": "points of any given time slice. So they are", "timestamp": "00:19:22,116", "timestamp_s": 1162.0}, {"text": "the interquartile ranges, q one to q three,", "timestamp": "00:19:25,556", "timestamp_s": 1165.0}, {"text": "and the red line is the median value of", "timestamp": "00:19:28,792", "timestamp_s": 1168.0}, {"text": "the execution time. So on this slide, I again", "timestamp": "00:19:32,344", "timestamp_s": 1172.0}, {"text": "zoomed in to the first thousand executions.", "timestamp": "00:19:36,024", "timestamp_s": 1176.0}, {"text": "And here you can actually see that there\u0027s already in the beginning", "timestamp": "00:19:39,858", "timestamp_s": 1179.0}, {"text": "a significant drop in the execution time. There are several things we", "timestamp": "00:19:43,826", "timestamp_s": 1183.0}, {"text": "can observe here. First of all, we see that the", "timestamp": "00:19:47,548", "timestamp_s": 1187.0}, {"text": "scatter shade is tightly following the median curve and", "timestamp": "00:19:50,672", "timestamp_s": 1190.0}, {"text": "also narrowing over time. So that shows that the", "timestamp": "00:19:54,624", "timestamp_s": 1194.0}, {"text": "execution time is generally declining. Next,", "timestamp": "00:19:58,352", "timestamp_s": 1198.0}, {"text": "the median curve is also tending", "timestamp": "00:20:01,444", "timestamp_s": 1201.0}, {"text": "to be at lower bound of the interquartile ranges of the scatter shade.", "timestamp": "00:20:04,842", "timestamp_s": 1204.0}, {"text": "Which allows the conclusion that data points between", "timestamp": "00:20:08,522", "timestamp_s": 1208.0}, {"text": "the median and q three quartile under spread", "timestamp": "00:20:11,812", "timestamp_s": 1211.0}, {"text": "compared to the range from q one to the median. Which makes absolutely", "timestamp": "00:20:15,502", "timestamp_s": 1215.0}, {"text": "sense because there\u0027s a physical lower bound when executing", "timestamp": "00:20:19,864", "timestamp_s": 1219.0}, {"text": "and this behavior and the scatter shades can also be observed", "timestamp": "00:20:23,454", "timestamp_s": 1223.0}, {"text": "for the other JVM charts for GraalVM and Openj", "timestamp": "00:20:27,550", "timestamp_s": 1227.0}, {"text": "nine. Here we have the chart for GraalVM for the", "timestamp": "00:20:31,442", "timestamp_s": 1231.0}, {"text": "first thousand benchmark iterations. Both GraalVM", "timestamp": "00:20:35,260", "timestamp_s": 1235.0}, {"text": "and hotspot actually have this sudden", "timestamp": "00:20:39,362", "timestamp_s": 1239.0}, {"text": "decline at around 100 executions where the", "timestamp": "00:20:43,062", "timestamp_s": 1243.0}, {"text": "execution time significantly drops. There\u0027s not", "timestamp": "00:20:47,072", "timestamp_s": 1247.0}, {"text": "only in the median curve, but also in the scatter shade this", "timestamp": "00:20:50,692", "timestamp_s": 1250.0}, {"text": "significant decline. And we also see", "timestamp": "00:20:54,532", "timestamp_s": 1254.0}, {"text": "that at this point, the q three boundary.", "timestamp": "00:20:58,132", "timestamp_s": 1258.0}, {"text": "So the upper part of the scatter shade will eventually fall", "timestamp": "00:21:01,898", "timestamp_s": 1261.0}, {"text": "below the q one boundary of previous data points.", "timestamp": "00:21:05,156", "timestamp_s": 1265.0}, {"text": "So I tried to visualize that with this red bar. You see that", "timestamp": "00:21:08,456", "timestamp_s": 1268.0}, {"text": "here the under bound of the scatter shade is below the lower", "timestamp": "00:21:12,344", "timestamp_s": 1272.0}, {"text": "bound. That\u0027s another view on the GraalVM warmup", "timestamp": "00:21:15,836", "timestamp_s": 1275.0}, {"text": "chart between iteration 6000,", "timestamp": "00:21:19,426", "timestamp_s": 1279.0}, {"text": "406,800 GraalVM", "timestamp": "00:21:22,124", "timestamp_s": 1282.0}, {"text": "actually shows this bump. And I did not dig", "timestamp": "00:21:25,746", "timestamp_s": 1285.0}, {"text": "into details here because I didn\u0027t have a good profile", "timestamp": "00:21:29,372", "timestamp_s": 1289.0}, {"text": "at hand. However, I think it would be definitely interesting to investigate this", "timestamp": "00:21:32,838", "timestamp_s": 1292.0}, {"text": "anomaly. If you have any guess what this bump is about,", "timestamp": "00:21:36,912", "timestamp_s": 1296.0}, {"text": "please let me know. So the blue chart is for openj nine.", "timestamp": "00:21:40,672", "timestamp_s": 1300.0}, {"text": "Again, we look at the first thousand iterations for", "timestamp": "00:21:44,964", "timestamp_s": 1304.0}, {"text": "this benchmark. You can already see that the warmup chart of openj", "timestamp": "00:21:49,172", "timestamp_s": 1309.0}, {"text": "nine looks somewhat different than the others.", "timestamp": "00:21:52,778", "timestamp_s": 1312.0}, {"text": "So first of all, there is no sudden decline at", "timestamp": "00:21:55,848", "timestamp_s": 1315.0}, {"text": "the mark of 100 iterations, but instead there are some", "timestamp": "00:21:59,608", "timestamp_s": 1319.0}, {"text": "spikes in the execution time for single iterations.", "timestamp": "00:22:02,968", "timestamp_s": 1322.0}, {"text": "You see that here are some spikes, and also later on", "timestamp": "00:22:06,398", "timestamp_s": 1326.0}, {"text": "they\u0027re getting less over time, but they are always present.", "timestamp": "00:22:10,236", "timestamp_s": 1330.0}, {"text": "I was thinking, okay, maybe these spikes could be cared", "timestamp": "00:22:13,964", "timestamp_s": 1333.0}, {"text": "by the missing pretouch option, which is not available", "timestamp": "00:22:17,538", "timestamp_s": 1337.0}, {"text": "in open gen nine for Linux. To find out if this behavior", "timestamp": "00:22:21,008", "timestamp_s": 1341.0}, {"text": "could be, or the spikes could be attributed to the missing pretouch", "timestamp": "00:22:24,886", "timestamp_s": 1344.0}, {"text": "option. I would have expected to observe", "timestamp": "00:22:28,326", "timestamp_s": 1348.0}, {"text": "similar behavior for the other two jvms when I disabled the", "timestamp": "00:22:32,106", "timestamp_s": 1352.0}, {"text": "always pretouch option for them. So therefore I made", "timestamp": "00:22:35,732", "timestamp_s": 1355.0}, {"text": "another measurement series with GraalVM and hotspot", "timestamp": "00:22:39,636", "timestamp_s": 1359.0}, {"text": "having the always pretouch option disabled.", "timestamp": "00:22:44,010", "timestamp_s": 1364.0}, {"text": "But the warmup charts looked the same. There were no spikes for", "timestamp": "00:22:47,002", "timestamp_s": 1367.0}, {"text": "GraalVM or hotspot. There were no hints for my", "timestamp": "00:22:50,968", "timestamp_s": 1370.0}, {"text": "suspicion, which leads to the conclusion that in my test setup,", "timestamp": "00:22:54,072", "timestamp_s": 1374.0}, {"text": "fetching actual memory from the operating system had only", "timestamp": "00:22:58,018", "timestamp_s": 1378.0}, {"text": "minor or even no effect on the measurement series.", "timestamp": "00:23:01,724", "timestamp_s": 1381.0}, {"text": "And these spikes in the warmup graph of", "timestamp": "00:23:05,682", "timestamp_s": 1385.0}, {"text": "opengenine cannot directly be attributed to the fetching", "timestamp": "00:23:09,612", "timestamp_s": 1389.0}, {"text": "memory from the operating system. Okay, so up to now we just had a look", "timestamp": "00:23:13,078", "timestamp_s": 1393.0}, {"text": "at each JVM individually. Now I\u0027d like to", "timestamp": "00:23:17,056", "timestamp_s": 1397.0}, {"text": "continue to compare them. To get started, I just talk about", "timestamp": "00:23:20,368", "timestamp_s": 1400.0}, {"text": "the average execution times. So on the left hand side you see a histogram", "timestamp": "00:23:24,020", "timestamp_s": 1404.0}, {"text": "which includes the execution times", "timestamp": "00:23:28,458", "timestamp_s": 1408.0}, {"text": "for opengen nine, hotspot and GraalVM,", "timestamp": "00:23:31,700", "timestamp_s": 1411.0}, {"text": "all in JIT compiler mode. You can see that the histogram", "timestamp": "00:23:35,018", "timestamp_s": 1415.0}, {"text": "for hotspot and GraalVM looks quite similar, and opengenine", "timestamp": "00:23:39,006", "timestamp_s": 1419.0}, {"text": "describes a rather different curve. However, they all have this tail to the right.", "timestamp": "00:23:43,646", "timestamp_s": 1423.0}, {"text": "The average execution time for hotspot and GraalVM is", "timestamp": "00:23:47,580", "timestamp_s": 1427.0}, {"text": "around 0.4 milliseconds. Graalvm seems to be", "timestamp": "00:23:51,260", "timestamp_s": 1431.0}, {"text": "a little bit faster, and Openj nine is following", "timestamp": "00:23:54,748", "timestamp_s": 1434.0}, {"text": "tightly at almost 0.5 milliseconds.", "timestamp": "00:23:58,518", "timestamp_s": 1438.0}, {"text": "Then I also made some measurements where I enabled the", "timestamp": "00:24:02,390", "timestamp_s": 1442.0}, {"text": "Aot compiler for opengenine, and this one turned", "timestamp": "00:24:05,632", "timestamp_s": 1445.0}, {"text": "out to be faster than opengenine in Jit code,", "timestamp": "00:24:09,574", "timestamp_s": 1449.0}, {"text": "but still slower on average than GraalVM", "timestamp": "00:24:13,242", "timestamp_s": 1453.0}, {"text": "or hotspot. So that\u0027s also what you see here on the right", "timestamp": "00:24:17,210", "timestamp_s": 1457.0}, {"text": "hand side in the chart. Purple curve is opengenine", "timestamp": "00:24:20,868", "timestamp_s": 1460.0}, {"text": "in Aot mode. It\u0027s faster than OpenJ nine in Jit mode", "timestamp": "00:24:24,682", "timestamp_s": 1464.0}, {"text": "overall. Okay, let\u0027s dig deeper. One interesting", "timestamp": "00:24:28,814", "timestamp_s": 1468.0}, {"text": "thing to observe in the warmup charts is the amount", "timestamp": "00:24:32,328", "timestamp_s": 1472.0}, {"text": "of time, the number of iterations it takes to speed up", "timestamp": "00:24:35,816", "timestamp_s": 1475.0}, {"text": "the method execution from five milliseconds to 0.5", "timestamp": "00:24:39,116", "timestamp_s": 1479.0}, {"text": "milliseconds. I\u0027m talking in the unit of milliseconds,", "timestamp": "00:24:43,196", "timestamp_s": 1483.0}, {"text": "because that\u0027s easier to pronounce. But just don\u0027t get confused", "timestamp": "00:24:46,162", "timestamp_s": 1486.0}, {"text": "by the scales here. It\u0027s still nanoseconds on", "timestamp": "00:24:49,958", "timestamp_s": 1489.0}, {"text": "the chart. The first red bar is at five", "timestamp": "00:24:53,248", "timestamp_s": 1493.0}, {"text": "milliseconds, the second one is at 2.5 milliseconds,", "timestamp": "00:24:56,960", "timestamp_s": 1496.0}, {"text": "and the third one is at 0.5 milliseconds.", "timestamp": "00:25:01,786", "timestamp_s": 1501.0}, {"text": "So for this blue chart, which represents openj", "timestamp": "00:25:05,738", "timestamp_s": 1505.0}, {"text": "nine, it takes 150 iterations", "timestamp": "00:25:09,482", "timestamp_s": 1509.0}, {"text": "to gain a 90% performance improvement within", "timestamp": "00:25:13,226", "timestamp_s": 1513.0}, {"text": "the first iterations of the benchmark test. So in", "timestamp": "00:25:17,320", "timestamp_s": 1517.0}, {"text": "numbers, this means that for every next", "timestamp": "00:25:21,240", "timestamp_s": 1521.0}, {"text": "execution, the JVM can execute the method 0.3", "timestamp": "00:25:25,432", "timestamp_s": 1525.0}, {"text": "nanoseconds faster than the previous operation.", "timestamp": "00:25:31,164", "timestamp_s": 1531.0}, {"text": "If we take a look for this KPI at hotspot,", "timestamp": "00:25:34,338", "timestamp_s": 1534.0}, {"text": "we see that the negative slope is", "timestamp": "00:25:38,002", "timestamp_s": 1538.0}, {"text": "not as steep as in open G nine, and we can also", "timestamp": "00:25:41,756", "timestamp_s": 1541.0}, {"text": "prove that by calculating it. So,", "timestamp": "00:25:45,392", "timestamp_s": 1545.0}, {"text": "reaching the lower bound of 0.5 milliseconds", "timestamp": "00:25:48,208", "timestamp_s": 1548.0}, {"text": "from the beginning, where we start at five milliseconds,", "timestamp": "00:25:52,874", "timestamp_s": 1552.0}, {"text": "takes around 700 executions of the benchmark method.", "timestamp": "00:25:56,330", "timestamp_s": 1556.0}, {"text": "So we can say that with every", "timestamp": "00:26:00,474", "timestamp_s": 1560.0}, {"text": "next execution, the JVM or hotspot can", "timestamp": "00:26:04,260", "timestamp_s": 1564.0}, {"text": "speed up the method execution by zero point", "timestamp": "00:26:08,488", "timestamp_s": 1568.0}, {"text": "63 nanoseconds per operation compared", "timestamp": "00:26:13,110", "timestamp_s": 1573.0}, {"text": "to the previous operation. Which means that during the first few", "timestamp": "00:26:16,690", "timestamp_s": 1576.0}, {"text": "iterations where warmup takes place, hotspot Vm is 4.6", "timestamp": "00:26:20,092", "timestamp_s": 1580.0}, {"text": "times slower than open gen nine. If we compare all", "timestamp": "00:26:24,652", "timestamp_s": 1584.0}, {"text": "the three jvms together, you will see that Opengen", "timestamp": "00:26:28,336", "timestamp_s": 1588.0}, {"text": "nine will only win the race within the first few hundred", "timestamp": "00:26:32,198", "timestamp_s": 1592.0}, {"text": "iterations. But if we compare that after", "timestamp": "00:26:36,160", "timestamp_s": 1596.0}, {"text": "around 600 iterations, we\u0027ll see that", "timestamp": "00:26:39,952", "timestamp_s": 1599.0}, {"text": "the blue chart is above the green and red chart", "timestamp": "00:26:43,556", "timestamp_s": 1603.0}, {"text": "of hotspot and gravm, which means that in the end,", "timestamp": "00:26:47,162", "timestamp_s": 1607.0}, {"text": "Openj nine will be slower than its opponents. But just right", "timestamp": "00:26:50,676", "timestamp_s": 1610.0}, {"text": "at the beginning, it\u0027s warming up faster. I also promised to shortly", "timestamp": "00:26:54,552", "timestamp_s": 1614.0}, {"text": "talk about JIT compilers versus Aot compilers,", "timestamp": "00:26:59,006", "timestamp_s": 1619.0}, {"text": "and for that I made some measurements with OpenJ nine jit mode,", "timestamp": "00:27:02,222", "timestamp_s": 1622.0}, {"text": "which is the blue graph again. And in AOT mode, which is", "timestamp": "00:27:05,918", "timestamp_s": 1625.0}, {"text": "the purple graph here you can see the flags you need to provide", "timestamp": "00:27:09,356", "timestamp_s": 1629.0}, {"text": "to enable the Aot mode on open genine, and you", "timestamp": "00:27:13,468", "timestamp_s": 1633.0}, {"text": "can easily spot that right from the beginning. The Open", "timestamp": "00:27:17,728", "timestamp_s": 1637.0}, {"text": "Geni Aot compiler starts at its maximum", "timestamp": "00:27:20,864", "timestamp_s": 1640.0}, {"text": "performance and executes the code always in the same", "timestamp": "00:27:24,502", "timestamp_s": 1644.0}, {"text": "speed, while the jig compiler will take up on that", "timestamp": "00:27:28,208", "timestamp_s": 1648.0}, {"text": "after a few hundred executions again. So having all", "timestamp": "00:27:32,500", "timestamp_s": 1652.0}, {"text": "these nice looking charts is quite cool actually.", "timestamp": "00:27:36,436", "timestamp_s": 1656.0}, {"text": "But I also wanted to know what\u0027s actually happening there.", "timestamp": "00:27:39,764", "timestamp_s": 1659.0}, {"text": "Why is the warm up as it is, and what\u0027s", "timestamp": "00:27:42,532", "timestamp_s": 1662.0}, {"text": "causing it? So for that I found ditchwatch which is", "timestamp": "00:27:45,754", "timestamp_s": 1665.0}, {"text": "a block analyzer and visualizer for the hotspot jig compiler,", "timestamp": "00:27:49,592", "timestamp_s": 1669.0}, {"text": "and it\u0027s a really cool tool actually. You can enable it with", "timestamp": "00:27:53,326", "timestamp_s": 1673.0}, {"text": "these flags if you provide these runtime flags on your jvm.", "timestamp": "00:27:57,080", "timestamp_s": 1677.0}, {"text": "However, you have to know that this will have a", "timestamp": "00:28:00,434", "timestamp_s": 1680.0}, {"text": "negative impact on performance, so do not do that during", "timestamp": "00:28:03,708", "timestamp_s": 1683.0}, {"text": "your benchmarking, but just afterwards to investigate.", "timestamp": "00:28:06,812", "timestamp_s": 1686.0}, {"text": "And the output file, which is a XML log file", "timestamp": "00:28:09,814", "timestamp_s": 1689.0}, {"text": "you can just load into jitwatch afterwards. Then jitwatch", "timestamp": "00:28:13,750", "timestamp_s": 1693.0}, {"text": "will show you the compilations for every single method. So here\u0027s", "timestamp": "00:28:17,798", "timestamp_s": 1697.0}, {"text": "an example for compilation list of the method", "timestamp": "00:28:21,898", "timestamp_s": 1701.0}, {"text": "solve integer array, which is one of the methods", "timestamp": "00:28:25,290", "timestamp_s": 1705.0}, {"text": "in my Sudoku benchmark tests. You see actually that there", "timestamp": "00:28:28,842", "timestamp_s": 1708.0}, {"text": "are some c one compilations happen and happening, and also some", "timestamp": "00:28:32,728", "timestamp_s": 1712.0}, {"text": "c two compilations also on stack replacements,", "timestamp": "00:28:36,392", "timestamp_s": 1716.0}, {"text": "but all only after 20 seconds,", "timestamp": "00:28:40,070", "timestamp_s": 1720.0}, {"text": "which is actually like half of the time the", "timestamp": "00:28:43,614", "timestamp_s": 1723.0}, {"text": "benchmark test runs. So this is way beyond the", "timestamp": "00:28:47,708", "timestamp_s": 1727.0}, {"text": "initial warm up we saw, and actually they do", "timestamp": "00:28:51,356", "timestamp_s": 1731.0}, {"text": "not have a lot of effect on the execution time anymore. So I", "timestamp": "00:28:55,148", "timestamp_s": 1735.0}, {"text": "was wondering what else would then cause the warmup", "timestamp": "00:28:58,668", "timestamp_s": 1738.0}, {"text": "in the initial 1000 iterations if", "timestamp": "00:29:02,226", "timestamp_s": 1742.0}, {"text": "all these compilations shown by Jitbotch kick in much later.", "timestamp": "00:29:05,920", "timestamp_s": 1745.0}, {"text": "So while Jitbotch is a useful tool to visualize the", "timestamp": "00:29:09,952", "timestamp_s": 1749.0}, {"text": "actions of the JIT compiler, I encountered discrepancy", "timestamp": "00:29:13,668", "timestamp_s": 1753.0}, {"text": "between the compilations shown by Jitbotch and the JIT", "timestamp": "00:29:17,738", "timestamp_s": 1757.0}, {"text": "compiler actions locked on the terminal by providing the runtime", "timestamp": "00:29:20,858", "timestamp_s": 1760.0}, {"text": "flex print compilation and print inlining.", "timestamp": "00:29:25,086", "timestamp_s": 1765.0}, {"text": "So the terminal lock output showed several inlining", "timestamp": "00:29:28,318", "timestamp_s": 1768.0}, {"text": "operations taking place already during the first iterations of the benchmark", "timestamp": "00:29:32,302", "timestamp_s": 1772.0}, {"text": "execution. These inlining operations also fit to the warmup", "timestamp": "00:29:36,322", "timestamp_s": 1776.0}, {"text": "charts where we see a steep decline over", "timestamp": "00:29:40,498", "timestamp_s": 1780.0}, {"text": "the first few hundred or thousand iterations. So these inland", "timestamp": "00:29:44,092", "timestamp_s": 1784.0}, {"text": "operations cared probably the main driver for the fast decline", "timestamp": "00:29:47,922", "timestamp_s": 1787.0}, {"text": "in the warm up graphs we\u0027ve just seen. The difference between", "timestamp": "00:29:51,510", "timestamp_s": 1791.0}, {"text": "the XML compilation log file used by Jitwatch", "timestamp": "00:29:55,184", "timestamp_s": 1795.0}, {"text": "and the compilation log output on the terminal", "timestamp": "00:29:58,966", "timestamp_s": 1798.0}, {"text": "can actually be explained by the fact that there\u0027s a limitation", "timestamp": "00:30:02,810", "timestamp_s": 1802.0}, {"text": "in the log compilation option, which leads to", "timestamp": "00:30:06,426", "timestamp_s": 1806.0}, {"text": "the fact that these inline decisions made by the c one", "timestamp": "00:30:10,068", "timestamp_s": 1810.0}, {"text": "compiler early on are not included in the XML log", "timestamp": "00:30:13,748", "timestamp_s": 1813.0}, {"text": "file which is used by Jitwatch. You can read the details", "timestamp": "00:30:17,496", "timestamp_s": 1817.0}, {"text": "here where I provided a link to the OpenJDK wiki.", "timestamp": "00:30:21,886", "timestamp_s": 1821.0}, {"text": "Okay, now I\u0027d like to draw short conclusion", "timestamp": "00:30:25,874", "timestamp_s": 1825.0}, {"text": "and also have some additional remarks to my benchmark", "timestamp": "00:30:29,682", "timestamp_s": 1829.0}, {"text": "measurements. First of all, all the benchmark measurements I made", "timestamp": "00:30:33,426", "timestamp_s": 1833.0}, {"text": "were done for JDK version eleven for all the mentioned", "timestamp": "00:30:37,596", "timestamp_s": 1837.0}, {"text": "jvms. I did not perform measurements in any other", "timestamp": "00:30:41,808", "timestamp_s": 1841.0}, {"text": "JDK version. Secondly, the benchmark", "timestamp": "00:30:45,216", "timestamp_s": 1845.0}, {"text": "measurements I conducted in October and November 2020.", "timestamp": "00:30:48,438", "timestamp_s": 1848.0}, {"text": "So meanwhile there are new versions of the jvms,", "timestamp": "00:30:52,228", "timestamp_s": 1852.0}, {"text": "so it would be interesting to also take a look at them. Yeah,", "timestamp": "00:30:55,674", "timestamp_s": 1855.0}, {"text": "and here are also my final thoughts. As just said,", "timestamp": "00:30:59,604", "timestamp_s": 1859.0}, {"text": "graalvm version 21 was recently released.", "timestamp": "00:31:03,444", "timestamp_s": 1863.0}, {"text": "It now comes with the espresso JVM, which is a", "timestamp": "00:31:07,118", "timestamp_s": 1867.0}, {"text": "JVM fully written in Java. It\u0027s Java on truffle,", "timestamp": "00:31:10,328", "timestamp_s": 1870.0}, {"text": "if you know what that means. Yeah, maybe I find the time", "timestamp": "00:31:13,838", "timestamp_s": 1873.0}, {"text": "to also do some warm up performance benchmarking on the", "timestamp": "00:31:17,372", "timestamp_s": 1877.0}, {"text": "espresso JVM. The second thought that comes to my", "timestamp": "00:31:21,068", "timestamp_s": 1881.0}, {"text": "mind is that Opengenine\u0027s benefit is definitely", "timestamp": "00:31:24,508", "timestamp_s": 1884.0}, {"text": "its Aot mode. So it\u0027s performing better in Aot mode,", "timestamp": "00:31:28,140", "timestamp_s": 1888.0}, {"text": "at least in my measurements. But I\u0027m asking myself,", "timestamp": "00:31:31,990", "timestamp_s": 1891.0}, {"text": "why don\u0027t they make this the default configuration if they", "timestamp": "00:31:36,144", "timestamp_s": 1896.0}, {"text": "also advertise with it that they are faster than the hotspot", "timestamp": "00:31:39,792", "timestamp_s": 1899.0}, {"text": "VM? Last but not least, I think there are many other JVM that", "timestamp": "00:31:43,194", "timestamp_s": 1903.0}, {"text": "also deserve to be benchmark on warmup performance because they", "timestamp": "00:31:46,916", "timestamp_s": 1906.0}, {"text": "become more and more important in the world of different JDK", "timestamp": "00:31:50,820", "timestamp_s": 1910.0}, {"text": "releases. For example, the Amazon Krata JVM or Alibaba Dragonwell.", "timestamp": "00:31:54,938", "timestamp_s": 1914.0}, {"text": "All right, that was my presentation. I hope you", "timestamp": "00:31:59,402", "timestamp_s": 1919.0}, {"text": "like it. It was the first talk I ever", "timestamp": "00:32:02,648", "timestamp_s": 1922.0}, {"text": "held in public, and if you want to check out", "timestamp": "00:32:05,896", "timestamp_s": 1925.0}, {"text": "my references or take a look at the source code,", "timestamp": "00:32:09,308", "timestamp_s": 1929.0}, {"text": "you can find many more details on my blog post about", "timestamp": "00:32:12,444", "timestamp_s": 1932.0}, {"text": "that topic, which is linked here. If you have any questions", "timestamp": "00:32:15,932", "timestamp_s": 1935.0}, {"text": "about my measurements, my talk, my learnings,", "timestamp": "00:32:19,564", "timestamp_s": 1939.0}, {"text": "or want to discuss something, yeah, just send me an", "timestamp": "00:32:22,802", "timestamp_s": 1942.0}, {"text": "email. Here\u0027s my contact information and thank you for tuning in.", "timestamp": "00:32:26,108", "timestamp_s": 1946.0}, {"text": "See you.", "timestamp": "00:32:30,300", "timestamp_s": 1950.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'KcEDAMHvpis',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Benchmarking the Warm-Up Performance of HotSpot VM, GraalVM and OpenJ9 -- A Learner's Journey
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Are you new to the JVM? Did you just run your Java programs but never cared what the JVM does with your code under the hood? Want to learn about JVM internals, how to (not) write a Java benchmark test or are you simply curious about JVM performance? Then this talk is for you!</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Frank Kriegl will talk about benchmarking the warmer performance of hotspot VM, crawl VM and OpenJ nine. The goal of the talk is to motivate you to start with java micro benchmarking on your own.

              </li>
              
              <li>
                Warmup is defined as the number of iterations the JVM needs to increase the speed of method execution between the first and the nth invocation. There is a difference and what it looks like between JIt compilers and Aot compilers, and the code they produce.

              </li>
              
              <li>
                The Java heap is separated into several parts. Young generation consists of Eden space and two survivor spaces. There are seven garbage collection algorithms. garbage collection can have unwanted side effects in performance testing. Luckily, there's the Java enhancement proposal 318, a no op garbage collector.

              </li>
              
              <li>
                Next, it's about JIT versus Aot compilation. Java code is pre compiled to Java bytecode, which will then be run on any JVM. Head of time compiler will just directly compile all the bytecode to machine code when JVM starts up. For the jig compiler since JDK eight, there are five levels of compilation.

              </li>
              
              <li>
                Writing a good benchmark is not easy. There are conceptual flaws when designing a micro benchmark. But there is JMH to the rescue, so these flaws can mostly be avoided. I tried several different approaches to write some good benchmark tests.

              </li>
              
              <li>
                JMH uses a configuration of 5gb of heap and also provided the flag heap dump on out of memory error. Last line, I specify the number of iterations, which is 21,000 per fork. I run 20 forks and the timeout is just set to 360 minutes.

              </li>
              
              <li>
                Both GraalVM and hotspot have this sudden decline at around 100 executions where the execution time significantly drops. The scatter shade is tightly following the median curve and also narrowing over time. If you have any guess what this bump is about, please let me know.

              </li>
              
              <li>
                There are spikes in the execution time for single iterations of openj nine. I thought maybe these spikes could be cared by the missing pretouch option, which is not available in open gen nine for Linux. But in my test setup, fetching actual memory from the operating system had only minor or even no effect on the measurement series.

              </li>
              
              <li>
                Opengen nine, hotspot and GraalVM, all in JIT compiler mode. One interesting thing to observe is the amount of time it takes to speed up the method execution from five milliseconds to 0.5 milliseconds. Why is the warm up as it is, and what's causing it?

              </li>
              
              <li>
                The benchmark measurements were done for JDK version eleven for all the mentioned jvms. Opengenine's benefit is definitely its Aot mode. Many other JVM also deserve to be benchmarked on warmup performance.

              </li>
              
              <li>
                It was the first talk I ever held in public. You can find many more details on my blog post about that topic. If you have any questions about my measurements, my talk, my learnings, or want to discuss something, just send me an email.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/KcEDAMHvpis.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:25,410'); seek(25.0)">
              You. Hello everyone,
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:28,652'); seek(28.0)">
              and thanks for tuning in to my talk at this year's
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:32,274'); seek(32.0)">
              Conf 42 Java conference. Today I will talk about
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:35,980'); seek(35.0)">
              benchmarking the warmer performance of hotspot VM,
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:39,186'); seek(39.0)">
              crawl VM and OpenJ nine. Let's get started.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:43,132'); seek(43.0)">
              So, my name is Frank Kriegl. I live in Heidelberg,
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:47,042'); seek(47.0)">
              Germany, and I've been working as a Java developer since
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:51,810'); seek(51.0)">
              almost four years, and currently I'm also finishing
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:56,218'); seek(56.0)">
              my master of science in parallel to my regular employment,
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:01:00,058'); seek(60.0)">
              which is also where this talk originates from.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:03,416'); seek(63.0)">
              Recently I had to write research paper
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:07,510'); seek(67.0)">
              and I was simply curious to learn more about
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:11,096'); seek(71.0)">
              jvms in general and saw this as a chance to deepen
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:14,734'); seek(74.0)">
              my knowledge. And that's why this talk's subtitle
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:18,258'); seek(78.0)">
              is also a learner's journey. So here's today's agenda.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:23,210'); seek(83.0)">
              First, I will start with a brief introduction.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:27,138'); seek(87.0)">
              Then I will set the baseline with some information bits
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:30,738'); seek(90.0)">
              about JVM internals. Next I will talk
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:33,872'); seek(93.0)">
              about my learnings when I try to compare the warmup performance
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:37,926'); seek(97.0)">
              of the three different JVM. So I will spend
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:41,796'); seek(101.0)">
              some words on the pitfalls of creating good or
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:46,020'); seek(106.0)">
              bad benchmark tests.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:48,850'); seek(108.0)">
              Next I will describe my test adapt
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:52,538'); seek(112.0)">
              for benchmarking the warmup performance, and also
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:56,790'); seek(116.0)">
              mention some configurations I made for the
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:02:00,488'); seek(120.0)">
              jvms on the test. Finally, I'd like to present you
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:03,992'); seek(123.0)">
              my test results and for sure also give some interpretation
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:07,602'); seek(127.0)">
              on them. In the end, I will draw a short conclusion.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:10,834'); seek(130.0)">
              The goal of my talk is actually to motivate you to
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:15,180'); seek(135.0)">
              start with java micro benchmarking on your own. So I hope
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:18,540'); seek(138.0)">
              that in the end of this presentation you will have a basic
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:21,798'); seek(141.0)">
              understanding of JVMs and are ready to get started with
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:25,536'); seek(145.0)">
              your own java or JVM benchmark measurements. So let's
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:29,318'); seek(149.0)">
              talk about the what and why. What is warmup actually?
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:34,290'); seek(154.0)">
              Usually, warmup is defined as the number of iterations the
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:38,388'); seek(158.0)">
              JVM needs to increase the speed of method execution between
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:41,876'); seek(161.0)">
              the first and the nth invocation by
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:45,032'); seek(165.0)">
              applying JIT compiler optimizations on the bytecode. Okay, that's the
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:49,512'); seek(169.0)">
              definition, and now let me show you what it actually means. So in this
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:53,432'); seek(173.0)">
              chart you see on the vertical axis the time
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:56,876'); seek(176.0)">
              per operation, and on the horizontal axis the number of
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:00,348'); seek(180.0)">
              iterations and warmup is the part
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:03,756'); seek(183.0)">
              here. From the first iteration, it takes quite long to
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:07,628'); seek(187.0)">
              complete one operation for the JVM one method execution, and over
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:11,536'); seek(191.0)">
              time it's getting faster. So after 200 iterations
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:15,542'); seek(195.0)">
              it's much faster than the first iteration.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:18,534'); seek(198.0)">
              And this decline in execution time is called
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:21,616'); seek(201.0)">
              warm up. Next, I'd like to answer the question why?
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:25,092'); seek(205.0)">
              I would like to compare this. So mainly out of curiosity,
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:29,370'); seek(209.0)">
              to be honest. But there are for sure also some actual
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:33,300'); seek(213.0)">
              reasons. Like I was searching on the Internet and I
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:37,112'); seek(217.0)">
              only found little research in this area. So the most
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:40,696'); seek(220.0)">
              interesting article I found was don't get caught in the
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:44,248'); seek(224.0)">
              cold warmup your jvm and it's but hot
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:48,172'); seek(228.0)">
              tub which is a new JVM implementation to
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:51,532'); seek(231.0)">
              use pre cared JVM to avoid the warmup
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:55,058'); seek(235.0)">
              overhead. And so I thought, okay, why not doing my own research? I just
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:59,232'); seek(239.0)">
              wanted to see how much the jvms I wanted to
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:03,088'); seek(243.0)">
              test how they differ in the method, warmup speed, and eventually
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:07,782'); seek(247.0)">
              if there is a difference. Well, there is a difference and
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:11,892'); seek(251.0)">
              what it looks like between JIt compilers and Aot compilers,
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:15,738'); seek(255.0)">
              and the code they produce. Okay, next it's about
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:19,492'); seek(259.0)">
              setting the baseline. So on this slide you
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:22,952'); seek(262.0)">
              see a picture of the Java heap structure.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:26,606'); seek(266.0)">
              The example is for the hotspot VM, and the Java
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:30,254'); seek(270.0)">
              heap is actually separated into several parts.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:33,646'); seek(273.0)">
              So you see here there is the young generation and
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:37,500'); seek(277.0)">
              the old generation. And the young generation itself consists
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:41,410'); seek(281.0)">
              of Eden space and two survivor spaces.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:45,026'); seek(285.0)">
              So how does memory allocation happen in the JVM?
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:48,834'); seek(288.0)">
              New memory is always allocated in the Eden space,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:53,056'); seek(293.0)">
              and as soon as just before the Eden space
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:56,560'); seek(296.0)">
              fills up, some minor garbage collection occurs
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:00,038'); seek(300.0)">
              and the objects are transferred into survivor spaces.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:03,754'); seek(303.0)">
              One survivor space is always free and the other one
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:06,996'); seek(306.0)">
              is occupied. And if one survivor
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:10,234'); seek(310.0)">
              space is running full, minor garbage collection will
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:13,752'); seek(313.0)">
              just swap these spaces, clear up unused objects
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:17,918'); seek(317.0)">
              or unreferenced objects, and the survivors will stay there.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:21,624'); seek(321.0)">
              If there are long living objects that survive several minor
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:25,038'); seek(325.0)">
              garbage collection cycles, it could actually happen that some
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:29,180'); seek(329.0)">
              major garbage collection occurs and these objects
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:32,578'); seek(332.0)">
              are then transferred into the old generation space,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:36,444'); seek(336.0)">
              also called tenured space. Next, and I already mentioned it,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:40,480'); seek(340.0)">
              I briefly touched the topic of garbage collection.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:43,446'); seek(343.0)">
              So meanwhile there exists, I think, seven garbage
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:47,542'); seek(347.0)">
              collection algorithms, at least in the version of Java
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:51,018'); seek(351.0)">
              eleven. Thing is that garbage collection can have
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:54,436'); seek(354.0)">
              unwanted side effects in performance testing,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:58,058'); seek(358.0)">
              so you better try to eliminate that.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:01,588'); seek(361.0)">
              Luckily, there's the Java enhancement proposal 318,
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:07,006'); seek(367.0)">
              which is about epsilon, a no op garbage collector.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:10,974'); seek(370.0)">
              I linked it here, can read the details if you
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:14,168'); seek(374.0)">
              like. And that's actually a garbage collection algorithm which will
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:18,316'); seek(378.0)">
              always allocate memory but never freed up again.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:21,836'); seek(381.0)">
              Next, it's about JIT versus Aot compilation.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:25,890'); seek(385.0)">
              So as you might know, Java code is pre compiled to
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:30,080'); seek(390.0)">
              Java bytecode, which will then be run on any
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:33,600'); seek(393.0)">
              JVM. The JIT compiler, just in time compiler is
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:37,344'); seek(397.0)">
              first doing some profiling on the bytecode and
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:41,668'); seek(401.0)">
              then it will apply optimizations like
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:45,060'); seek(405.0)">
              method inlining, branch prediction, loop unrolling, dead code
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:48,916'); seek(408.0)">
              elimination, and many more.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:51,668'); seek(411.0)">
              And it will also only compile parts of
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:55,252'); seek(415.0)">
              the bytecode to machine code because it has to decide which parts
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:59,038'); seek(419.0)">
              of the code need to be optimized. Then on the other hand, there's the head
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:02,968'); seek(422.0)">
              of time compiler, which will just directly compile
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:06,866'); seek(426.0)">
              all the bytecode to machine code when JVM starts
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:10,658'); seek(430.0)">
              up. So for the jig compiler
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:13,954'); seek(433.0)">
              since JDK eight, there are actually five
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:17,792'); seek(437.0)">
              levels of tit compilation. At least that's what applies for
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:21,488'); seek(441.0)">
              the hotspot VM. The first level is just about interpreting
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:25,542'); seek(445.0)">
              bytecode, so it's level zero, and the JVM
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:29,622'); seek(449.0)">
              will not compile anything at all, but just run as
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:33,268'); seek(453.0)">
              an interpreter. And after a few iterations the chit
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:37,258'); seek(457.0)">
              compiler will make use of its first compiler. It's the C one
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:41,236'); seek(461.0)">
              compiler, also called client compiler,
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:44,014'); seek(464.0)">
              and produce some simple c one compile
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:47,406'); seek(467.0)">
              code. So we talk about level one, two three
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:50,872'); seek(470.0)">
              compilations, which are all done by this C one compiler.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:54,414'); seek(474.0)">
              After about 10,000 invocations, code will
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:58,220'); seek(478.0)">
              eventually become marked as hot,
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:01,372'); seek(481.0)">
              and then it will become subject to level
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:04,812'); seek(484.0)">
              four compilations, which is then done by the c two compiler.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:08,166'); seek(488.0)">
              This is cared a server compiler and it will do some
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:11,936'); seek(491.0)">
              much better optimization with your Java bytecode. Okay,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:15,616'); seek(495.0)">
              next we continue with Java micro benchmarking. My lessons
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:19,766'); seek(499.0)">
              learned so I was not sure in the beginning
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:23,402'); seek(503.0)">
              how to start my learners journey.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:26,714'); seek(506.0)">
              I searched on the Internet and found that there are existing benchmark
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:30,858'); seek(510.0)">
              suites like spec JVM 2008,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:34,520'); seek(514.0)">
              which is from 2008, and the Decapo
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:38,094'); seek(518.0)">
              benchmark suite, which was first released in 2009.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:41,864'); seek(521.0)">
              While the last maintenance release of the cared benchmark
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:45,966'); seek(525.0)">
              suite is almost two years ago, which was eight months
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:49,836'); seek(529.0)">
              before the release of JDK eleven, for me they felt quite
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:53,516'); seek(533.0)">
              outdated, so I didn't want to use them for that reason.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:57,020'); seek(537.0)">
              Also, not all benchmark tests were working with the
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:00,624'); seek(540.0)">
              targeted Java version eleven, so I was actually trying to use them,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:04,288'); seek(544.0)">
              but failed. And finally the
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:07,632'); seek(547.0)">
              output format. The measurement units did not suit
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:11,958'); seek(551.0)">
              or run it in a suitable format, which I could use for further analyzing
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:15,978'); seek(555.0)">
              the collected data. So simply using some
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:19,796'); seek(559.0)">
              out of the box benchmark suites did not work for me.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:23,348'); seek(563.0)">
              So I came up with the idea of writing my own benchmark.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:27,246'); seek(567.0)">
              You have to know, writing a good benchmark is not easy.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:30,616'); seek(570.0)">
              There are two fault categories. On the one hand, there are conceptual
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:34,686'); seek(574.0)">
              flaws when designing a micro benchmark, which I will show you an example
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:38,200'); seek(578.0)">
              in a minute, and on the other hand, there are contextual effects when
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:42,092'); seek(582.0)">
              running it. Here is an example for a conceptual flaw.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:45,090'); seek(585.0)">
              On the left hand side we have the method create arrayupto
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:48,674'); seek(588.0)">
              and the method that code elimination, which will
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:52,368'); seek(592.0)">
              invoke the first method to create an array with the length of 21,000
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:56,384'); seek(596.0)">
              containing values from one to 21,000. The array is
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:00,192'); seek(600.0)">
              then processed and all the values are accumulated
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:03,770'); seek(603.0)">
              into the result variable, but this variable is actually
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:07,908'); seek(607.0)">
              never returned, so the calculation result is not used at
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:11,428'); seek(611.0)">
              all. If we then execute this for like
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:15,060'); seek(615.0)">
              18,000 times, invoke system current time
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:18,372'); seek(618.0)">
              millies before and after the method invocation, we could calculate
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:21,982'); seek(621.0)">
              the duration it takes to execute that code elimination
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:25,618'); seek(625.0)">
              method by subtract the start value from the end value.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:29,804'); seek(629.0)">
              But here's the issue. When running the code, the JVM will
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:33,772'); seek(633.0)">
              first just interpret your method and eventually collect
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:37,986'); seek(637.0)">
              some profiling data on it and figure out that the
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:41,632'); seek(641.0)">
              result of the method is actually never used because
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:44,976'); seek(644.0)">
              it's never returned. So at some point in time the JVM
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:48,662'); seek(648.0)">
              will just eliminate this invocation and you'll see that
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:52,548'); seek(652.0)">
              in your output that at some point in time the
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:55,972'); seek(655.0)">
              execution time will just drop to almost zero milliseconds
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:00,282'); seek(660.0)">
              because what you measure is just the time between invoking
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:04,542'); seek(664.0)">
              system current time release the first time and the second time.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:08,104'); seek(668.0)">
              But there is JMH to the rescue, so conceptual flaws
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:12,158'); seek(672.0)">
              can mostly be avoided by using frameworks like JMH.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:15,806'); seek(675.0)">
              JMH is the Java benchmarking house,
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:19,660'); seek(679.0)">
              and it is a tool that was created with the intention to help
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:23,276'); seek(683.0)">
              developers in avoiding common pitfalls when writing and
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:26,636'); seek(686.0)">
              executing Java benchmarks. So it's actually
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:30,076'); seek(690.0)">
              quite handy to use it. But also you have to be careful what you're
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:34,038'); seek(694.0)">
              doing. And here you can see one of my first tries
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:38,294'); seek(698.0)">
              where I was using JMH to write my own benchmark. I actually
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:42,192'); seek(702.0)">
              asked for some feedback on Twitter and got none,
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:45,530'); seek(705.0)">
              but didn't stop me from continuing my learning journey.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:48,794'); seek(708.0)">
              You can see there are two things I'd like to point out here. One thing
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:52,292'); seek(712.0)">
              is that JMH provides you with black holes,
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:55,694'); seek(715.0)">
              which you can use to consume some objects in
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:59,144'); seek(719.0)">
              your benchmark. So this will make sure that the code is not eliminated
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:03,278'); seek(723.0)">
              by the JVM. You could also just return that or print it to
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:07,016'); seek(727.0)">
              system out that will have the same effect, but there are black holes then.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:10,780'); seek(730.0)">
              Second is that you should also consider warm up and
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:14,860'); seek(734.0)">
              there's an annotation at fork and you can specify the
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:18,048'); seek(738.0)">
              number of forks which you want to execute. So how often
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:21,984'); seek(741.0)">
              the benchmark test should be executed in standalone
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:25,446'); seek(745.0)">
              jvms and also warmup iterations to actually avoid
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:29,702'); seek(749.0)">
              warmup when benchmarking your code. But in my case I wanted to
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:33,268'); seek(753.0)">
              measure warmup, so I set this to zero to get some observation.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:36,858'); seek(756.0)">
              I tried several different approaches to write some
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:40,740'); seek(760.0)">
              good benchmark tests. I tried to reuse existing benchmark tests
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:45,182'); seek(765.0)">
              from the Dakarpo or spec JVM suite, but that all
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:48,920'); seek(768.0)">
              didn't work out for me. But in the end I ended
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:52,878'); seek(772.0)">
              up with a sudoku backdracking algorithm, which turned
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:56,798'); seek(776.0)">
              out to be working quite well for my case. So you can find
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:00,108'); seek(780.0)">
              that code on GitHub. I will not go into details there,
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:03,708'); seek(783.0)">
              but this is the code I used to benchmark the JVM warmup
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:07,474'); seek(787.0)">
              performance. So here's my test environment.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:11,126'); seek(791.0)">
              I did all the benchmarking on a virtual machine,
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:14,694'); seek(794.0)">
              which is not optimal, but I tried to
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:17,808'); seek(797.0)">
              compensate that with multiple test runs. See that in a minute.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:21,082'); seek(801.0)">
              So the operating system is a Ubuntu version 2064
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:25,812'); seek(805.0)">
              bits, and I had eight virtual cpu cores based
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:30,116'); seek(810.0)">
              on AMD Opturam processor. There were eight
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:33,492'); seek(813.0)">
              gigs of ram available, no swap configured, and a storage
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:37,482'); seek(817.0)">
              of eight gig hard drive disk. My test setup
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:40,590'); seek(820.0)">
              I decided to execute my benchmark tests with
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:44,968'); seek(824.0)">
              21,000 iterations to also see some
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:48,636'); seek(828.0)">
              effect when a method gets marked as hot.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:52,028'); seek(832.0)">
              Every one consisted of 20 forks, which means that JMH
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:56,626'); seek(836.0)">
              will spawn up 20 independent jvms
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:00,054'); seek(840.0)">
              to not accidentally make use of already pre cared
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:03,686'); seek(843.0)">
              code. Then I executed twelve runs
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:07,510'); seek(847.0)">
              at different days and daytimes to eliminate these
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:11,140'); seek(851.0)">
              contextual effects I would face in a virtual environment.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:15,098'); seek(855.0)">
              When you multiply all these numbers, 21,000 iterations
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:18,698'); seek(858.0)">
              in 20 forks and twelve runs, you get
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:22,692'); seek(862.0)">
              5.4 million sudoku solved per JVM.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:26,638'); seek(866.0)">
              Always the same sudoku though the JVM parameters.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:30,286'); seek(870.0)">
              I did not touch much because I wanted
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:33,384'); seek(873.0)">
              to take the approach of simulating a
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:36,584'); seek(876.0)">
              daily user who would just throw code the JVM at the JVM and
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:40,188'); seek(880.0)">
              run it. Besides two exceptions, the one is that I was using
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:43,916'); seek(883.0)">
              the no operation garbage collector epsilon or
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:47,852'); seek(887.0)">
              respective other ones for the other jvms,
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:51,494'); seek(891.0)">
              and also the pretouch memory option, which I will explain in
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:55,024'); seek(895.0)">
              a minute. So here are my jvms under test I
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:58,720'); seek(898.0)">
              decided for the tried and trusted hotspot VM
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:02,378'); seek(902.0)">
              where I used an OpenJDK 64 bit
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:05,620'); seek(905.0)">
              build from adopt OpenjDK. And as you
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:09,044'); seek(909.0)">
              can see I also configured some alias for every jvm which
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:13,172'); seek(913.0)">
              I could use later and just shorten the amount
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:16,712'); seek(916.0)">
              of text on my slides. So secondly,
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:20,174'); seek(920.0)">
              I went for GraalVM, which is a polyglode VM.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:23,934'); seek(923.0)">
              I used the community edition for my benchmark testing in version
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:28,178'); seek(928.0)">
              22. And last but not least,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:31,804'); seek(931.0)">
              Opengenine as an enterprise JVM, which actually
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:35,420'); seek(935.0)">
              promises to have better performance on its website than hotspot
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:39,458'); seek(939.0)">
              VM. We'll talk about that later. Yeah, with this test
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:43,536'); seek(943.0)">
              setup, I started my measurements. So let's take a look at
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:47,552'); seek(947.0)">
              the runtime flex which I used to execute my benchmark.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:51,210'); seek(951.0)">
              This one is for hotspot VM, and let's go through the
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:54,868'); seek(954.0)">
              lines step by step. So here I specify
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:58,426'); seek(958.0)">
              the benchmark target, which is my backtracking algorithm,
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:02,474'); seek(962.0)">
              and this is just some syntax given by JMH.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:06,382'); seek(966.0)">
              The next line I will have to provide some JVM
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:10,302'); seek(970.0)">
              arguments for JMH that it will use for every
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:13,896'); seek(973.0)">
              fork it spawns up to execute the benchmark.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:17,154'); seek(977.0)">
              I used a configuration of 5gb of heap
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:21,170'); seek(981.0)">
              and also provided the flag heap dump on
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:24,396'); seek(984.0)">
              out of memory error to just show me if my
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:27,612'); seek(987.0)">
              JVM crashes. Next you see some double
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:30,902'); seek(990.0)">
              x flags like unlock experimental VM options, which I need
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:34,560'); seek(994.0)">
              to make use of the Epsilon garbage collector, which I
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:37,888'); seek(997.0)">
              mentioned earlier to avoid garbage collection interrupting
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:41,514'); seek(1001.0)">
              my measurements. And then there's also the always pre touch
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:45,204'); seek(1005.0)">
              option which will claim physical memory
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:48,618'); seek(1008.0)">
              from the operating system right at the beginning rather
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:52,276'); seek(1012.0)">
              than on the fly. So this would also eliminate
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:56,458'); seek(1016.0)">
              some interference by the JVM when it would find
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:59,912'); seek(1019.0)">
              out that it needs more memory. This flag will just tell JMH
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:04,110'); seek(1024.0)">
              where to store the measurement output and in which format,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:07,986'); seek(1027.0)">
              so it can output things in adjacent format and also
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:11,756'); seek(1031.0)">
              others. And last line, I specify the number
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:15,228'); seek(1035.0)">
              of iterations, which is 21,000 per fork. I run
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:19,104'); seek(1039.0)">
              20 forks and the timeout is just
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:22,464'); seek(1042.0)">
              set to 360 minutes, which is very high,
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:26,912'); seek(1046.0)">
              but just didn't want to let JMH time but
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:30,528'); seek(1050.0)">
              and abort my measurements. Okay, and the last line I just wanted
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:34,340'); seek(1054.0)">
              to collect the output of my program into a
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:37,828'); seek(1057.0)">
              log file. The runtime flags for GraalVM look quite
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:41,172'); seek(1061.0)">
              similar. For one small exception,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:43,978'); seek(1063.0)">
              I did not find any no operation garbage collection algorithm
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:47,882'); seek(1067.0)">
              for GraalVM in this version. So I made use of a
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:51,224'); seek(1071.0)">
              workaround. I set the max new size parameter
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:55,102'); seek(1075.0)">
              for libcall compiler to a number which
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:58,748'); seek(1078.0)">
              is higher than the actually available memory for the heap,
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:02,450'); seek(1082.0)">
              which makes the JVM create a huge young
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:06,156'); seek(1086.0)">
              generation, but no old generation space in the heap.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:09,766'); seek(1089.0)">
              So what would occur here is that actually no garbage collection
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:13,894'); seek(1093.0)">
              can occur, or before it would occur, the JVM
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:17,206'); seek(1097.0)">
              would run out of memory. So it's important to have
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:20,676'); seek(1100.0)">
              enough memory for your benchmark tests available. Opengen nine
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:24,772'); seek(1104.0)">
              has also a slight difference here. I unfortunately
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:28,906'); seek(1108.0)">
              found that the Linux version of Openj nine
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:32,260'); seek(1112.0)">
              does not offer a pretouch option. So this
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:35,876'); seek(1115.0)">
              one will claim memory on the fly if it needs more from
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:39,048'); seek(1119.0)">
              the operating system. Okay, that was the setup. And now
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:42,376'); seek(1122.0)">
              I would already like to share some test results. Here you
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:45,868'); seek(1125.0)">
              see the overall chart which I generated out
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:49,068'); seek(1129.0)">
              of the collected data from the benchmarking
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:52,306'); seek(1132.0)">
              of hotspot vm. It's on the vertical axis,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:55,906'); seek(1135.0)">
              again the time per operation in nanoseconds.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:59,490'); seek(1139.0)">
              And on the horizontal axis, the number of iterations up to
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:03,216'); seek(1143.0)">
              21,000. If we now zoom in a little,
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:06,608'); seek(1146.0)">
              you can see that there is a light red colored background
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:10,522'); seek(1150.0)">
              of the warmup graph. And I call this light colored graph
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:14,682'); seek(1154.0)">
              the scatter shade because this actually represents the scattering
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:19,002'); seek(1159.0)">
              of the different fox individual data
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:22,116'); seek(1162.0)">
              points of any given time slice. So they are
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:25,556'); seek(1165.0)">
              the interquartile ranges, q one to q three,
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:28,792'); seek(1168.0)">
              and the red line is the median value of
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:32,344'); seek(1172.0)">
              the execution time. So on this slide, I again
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:36,024'); seek(1176.0)">
              zoomed in to the first thousand executions.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:39,858'); seek(1179.0)">
              And here you can actually see that there's already in the beginning
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:43,826'); seek(1183.0)">
              a significant drop in the execution time. There are several things we
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:47,548'); seek(1187.0)">
              can observe here. First of all, we see that the
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:50,672'); seek(1190.0)">
              scatter shade is tightly following the median curve and
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:54,624'); seek(1194.0)">
              also narrowing over time. So that shows that the
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:58,352'); seek(1198.0)">
              execution time is generally declining. Next,
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:01,444'); seek(1201.0)">
              the median curve is also tending
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:04,842'); seek(1204.0)">
              to be at lower bound of the interquartile ranges of the scatter shade.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:08,522'); seek(1208.0)">
              Which allows the conclusion that data points between
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:11,812'); seek(1211.0)">
              the median and q three quartile under spread
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:15,502'); seek(1215.0)">
              compared to the range from q one to the median. Which makes absolutely
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:19,864'); seek(1219.0)">
              sense because there's a physical lower bound when executing
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:23,454'); seek(1223.0)">
              and this behavior and the scatter shades can also be observed
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:27,550'); seek(1227.0)">
              for the other JVM charts for GraalVM and Openj
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:31,442'); seek(1231.0)">
              nine. Here we have the chart for GraalVM for the
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:35,260'); seek(1235.0)">
              first thousand benchmark iterations. Both GraalVM
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:39,362'); seek(1239.0)">
              and hotspot actually have this sudden
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:43,062'); seek(1243.0)">
              decline at around 100 executions where the
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:47,072'); seek(1247.0)">
              execution time significantly drops. There's not
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:50,692'); seek(1250.0)">
              only in the median curve, but also in the scatter shade this
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:54,532'); seek(1254.0)">
              significant decline. And we also see
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:58,132'); seek(1258.0)">
              that at this point, the q three boundary.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:01,898'); seek(1261.0)">
              So the upper part of the scatter shade will eventually fall
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:05,156'); seek(1265.0)">
              below the q one boundary of previous data points.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:08,456'); seek(1268.0)">
              So I tried to visualize that with this red bar. You see that
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:12,344'); seek(1272.0)">
              here the under bound of the scatter shade is below the lower
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:15,836'); seek(1275.0)">
              bound. That's another view on the GraalVM warmup
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:19,426'); seek(1279.0)">
              chart between iteration 6000,
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:22,124'); seek(1282.0)">
              406,800 GraalVM
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:25,746'); seek(1285.0)">
              actually shows this bump. And I did not dig
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:29,372'); seek(1289.0)">
              into details here because I didn't have a good profile
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:32,838'); seek(1292.0)">
              at hand. However, I think it would be definitely interesting to investigate this
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:36,912'); seek(1296.0)">
              anomaly. If you have any guess what this bump is about,
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:40,672'); seek(1300.0)">
              please let me know. So the blue chart is for openj nine.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:44,964'); seek(1304.0)">
              Again, we look at the first thousand iterations for
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:49,172'); seek(1309.0)">
              this benchmark. You can already see that the warmup chart of openj
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:52,778'); seek(1312.0)">
              nine looks somewhat different than the others.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:55,848'); seek(1315.0)">
              So first of all, there is no sudden decline at
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:59,608'); seek(1319.0)">
              the mark of 100 iterations, but instead there are some
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:02,968'); seek(1322.0)">
              spikes in the execution time for single iterations.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:06,398'); seek(1326.0)">
              You see that here are some spikes, and also later on
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:10,236'); seek(1330.0)">
              they're getting less over time, but they are always present.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:13,964'); seek(1333.0)">
              I was thinking, okay, maybe these spikes could be cared
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:17,538'); seek(1337.0)">
              by the missing pretouch option, which is not available
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:21,008'); seek(1341.0)">
              in open gen nine for Linux. To find out if this behavior
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:24,886'); seek(1344.0)">
              could be, or the spikes could be attributed to the missing pretouch
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:28,326'); seek(1348.0)">
              option. I would have expected to observe
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:32,106'); seek(1352.0)">
              similar behavior for the other two jvms when I disabled the
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:35,732'); seek(1355.0)">
              always pretouch option for them. So therefore I made
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:39,636'); seek(1359.0)">
              another measurement series with GraalVM and hotspot
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:44,010'); seek(1364.0)">
              having the always pretouch option disabled.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:47,002'); seek(1367.0)">
              But the warmup charts looked the same. There were no spikes for
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:50,968'); seek(1370.0)">
              GraalVM or hotspot. There were no hints for my
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:54,072'); seek(1374.0)">
              suspicion, which leads to the conclusion that in my test setup,
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:58,018'); seek(1378.0)">
              fetching actual memory from the operating system had only
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:01,724'); seek(1381.0)">
              minor or even no effect on the measurement series.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:05,682'); seek(1385.0)">
              And these spikes in the warmup graph of
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:09,612'); seek(1389.0)">
              opengenine cannot directly be attributed to the fetching
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:13,078'); seek(1393.0)">
              memory from the operating system. Okay, so up to now we just had a look
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:17,056'); seek(1397.0)">
              at each JVM individually. Now I'd like to
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:20,368'); seek(1400.0)">
              continue to compare them. To get started, I just talk about
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:24,020'); seek(1404.0)">
              the average execution times. So on the left hand side you see a histogram
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:28,458'); seek(1408.0)">
              which includes the execution times
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:31,700'); seek(1411.0)">
              for opengen nine, hotspot and GraalVM,
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:35,018'); seek(1415.0)">
              all in JIT compiler mode. You can see that the histogram
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:39,006'); seek(1419.0)">
              for hotspot and GraalVM looks quite similar, and opengenine
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:43,646'); seek(1423.0)">
              describes a rather different curve. However, they all have this tail to the right.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:47,580'); seek(1427.0)">
              The average execution time for hotspot and GraalVM is
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:51,260'); seek(1431.0)">
              around 0.4 milliseconds. Graalvm seems to be
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:54,748'); seek(1434.0)">
              a little bit faster, and Openj nine is following
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:58,518'); seek(1438.0)">
              tightly at almost 0.5 milliseconds.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:02,390'); seek(1442.0)">
              Then I also made some measurements where I enabled the
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:05,632'); seek(1445.0)">
              Aot compiler for opengenine, and this one turned
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:09,574'); seek(1449.0)">
              out to be faster than opengenine in Jit code,
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:13,242'); seek(1453.0)">
              but still slower on average than GraalVM
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:17,210'); seek(1457.0)">
              or hotspot. So that's also what you see here on the right
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:20,868'); seek(1460.0)">
              hand side in the chart. Purple curve is opengenine
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:24,682'); seek(1464.0)">
              in Aot mode. It's faster than OpenJ nine in Jit mode
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:28,814'); seek(1468.0)">
              overall. Okay, let's dig deeper. One interesting
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:32,328'); seek(1472.0)">
              thing to observe in the warmup charts is the amount
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:35,816'); seek(1475.0)">
              of time, the number of iterations it takes to speed up
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:39,116'); seek(1479.0)">
              the method execution from five milliseconds to 0.5
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:43,196'); seek(1483.0)">
              milliseconds. I'm talking in the unit of milliseconds,
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:46,162'); seek(1486.0)">
              because that's easier to pronounce. But just don't get confused
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:49,958'); seek(1489.0)">
              by the scales here. It's still nanoseconds on
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:53,248'); seek(1493.0)">
              the chart. The first red bar is at five
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:56,960'); seek(1496.0)">
              milliseconds, the second one is at 2.5 milliseconds,
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:01,786'); seek(1501.0)">
              and the third one is at 0.5 milliseconds.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:05,738'); seek(1505.0)">
              So for this blue chart, which represents openj
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:09,482'); seek(1509.0)">
              nine, it takes 150 iterations
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:13,226'); seek(1513.0)">
              to gain a 90% performance improvement within
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:17,320'); seek(1517.0)">
              the first iterations of the benchmark test. So in
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:21,240'); seek(1521.0)">
              numbers, this means that for every next
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:25,432'); seek(1525.0)">
              execution, the JVM can execute the method 0.3
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:31,164'); seek(1531.0)">
              nanoseconds faster than the previous operation.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:34,338'); seek(1534.0)">
              If we take a look for this KPI at hotspot,
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:38,002'); seek(1538.0)">
              we see that the negative slope is
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:41,756'); seek(1541.0)">
              not as steep as in open G nine, and we can also
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:45,392'); seek(1545.0)">
              prove that by calculating it. So,
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:48,208'); seek(1548.0)">
              reaching the lower bound of 0.5 milliseconds
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:52,874'); seek(1552.0)">
              from the beginning, where we start at five milliseconds,
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:56,330'); seek(1556.0)">
              takes around 700 executions of the benchmark method.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:00,474'); seek(1560.0)">
              So we can say that with every
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:04,260'); seek(1564.0)">
              next execution, the JVM or hotspot can
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:08,488'); seek(1568.0)">
              speed up the method execution by zero point
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:13,110'); seek(1573.0)">
              63 nanoseconds per operation compared
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:16,690'); seek(1576.0)">
              to the previous operation. Which means that during the first few
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:20,092'); seek(1580.0)">
              iterations where warmup takes place, hotspot Vm is 4.6
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:24,652'); seek(1584.0)">
              times slower than open gen nine. If we compare all
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:28,336'); seek(1588.0)">
              the three jvms together, you will see that Opengen
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:32,198'); seek(1592.0)">
              nine will only win the race within the first few hundred
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:36,160'); seek(1596.0)">
              iterations. But if we compare that after
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:39,952'); seek(1599.0)">
              around 600 iterations, we'll see that
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:43,556'); seek(1603.0)">
              the blue chart is above the green and red chart
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:47,162'); seek(1607.0)">
              of hotspot and gravm, which means that in the end,
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:50,676'); seek(1610.0)">
              Openj nine will be slower than its opponents. But just right
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:54,552'); seek(1614.0)">
              at the beginning, it's warming up faster. I also promised to shortly
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:59,006'); seek(1619.0)">
              talk about JIT compilers versus Aot compilers,
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:02,222'); seek(1622.0)">
              and for that I made some measurements with OpenJ nine jit mode,
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:05,918'); seek(1625.0)">
              which is the blue graph again. And in AOT mode, which is
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:09,356'); seek(1629.0)">
              the purple graph here you can see the flags you need to provide
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:13,468'); seek(1633.0)">
              to enable the Aot mode on open genine, and you
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:17,728'); seek(1637.0)">
              can easily spot that right from the beginning. The Open
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:20,864'); seek(1640.0)">
              Geni Aot compiler starts at its maximum
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:24,502'); seek(1644.0)">
              performance and executes the code always in the same
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:28,208'); seek(1648.0)">
              speed, while the jig compiler will take up on that
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:32,500'); seek(1652.0)">
              after a few hundred executions again. So having all
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:36,436'); seek(1656.0)">
              these nice looking charts is quite cool actually.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:39,764'); seek(1659.0)">
              But I also wanted to know what's actually happening there.
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:42,532'); seek(1662.0)">
              Why is the warm up as it is, and what's
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:45,754'); seek(1665.0)">
              causing it? So for that I found ditchwatch which is
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:49,592'); seek(1669.0)">
              a block analyzer and visualizer for the hotspot jig compiler,
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:53,326'); seek(1673.0)">
              and it's a really cool tool actually. You can enable it with
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:57,080'); seek(1677.0)">
              these flags if you provide these runtime flags on your jvm.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:00,434'); seek(1680.0)">
              However, you have to know that this will have a
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:03,708'); seek(1683.0)">
              negative impact on performance, so do not do that during
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:06,812'); seek(1686.0)">
              your benchmarking, but just afterwards to investigate.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:09,814'); seek(1689.0)">
              And the output file, which is a XML log file
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:13,750'); seek(1693.0)">
              you can just load into jitwatch afterwards. Then jitwatch
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:17,798'); seek(1697.0)">
              will show you the compilations for every single method. So here's
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:21,898'); seek(1701.0)">
              an example for compilation list of the method
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:25,290'); seek(1705.0)">
              solve integer array, which is one of the methods
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:28,842'); seek(1708.0)">
              in my Sudoku benchmark tests. You see actually that there
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:32,728'); seek(1712.0)">
              are some c one compilations happen and happening, and also some
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:36,392'); seek(1716.0)">
              c two compilations also on stack replacements,
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:40,070'); seek(1720.0)">
              but all only after 20 seconds,
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:43,614'); seek(1723.0)">
              which is actually like half of the time the
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:47,708'); seek(1727.0)">
              benchmark test runs. So this is way beyond the
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:51,356'); seek(1731.0)">
              initial warm up we saw, and actually they do
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:55,148'); seek(1735.0)">
              not have a lot of effect on the execution time anymore. So I
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:58,668'); seek(1738.0)">
              was wondering what else would then cause the warmup
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:02,226'); seek(1742.0)">
              in the initial 1000 iterations if
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:05,920'); seek(1745.0)">
              all these compilations shown by Jitbotch kick in much later.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:09,952'); seek(1749.0)">
              So while Jitbotch is a useful tool to visualize the
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:13,668'); seek(1753.0)">
              actions of the JIT compiler, I encountered discrepancy
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:17,738'); seek(1757.0)">
              between the compilations shown by Jitbotch and the JIT
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:20,858'); seek(1760.0)">
              compiler actions locked on the terminal by providing the runtime
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:25,086'); seek(1765.0)">
              flex print compilation and print inlining.
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:28,318'); seek(1768.0)">
              So the terminal lock output showed several inlining
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:32,302'); seek(1772.0)">
              operations taking place already during the first iterations of the benchmark
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:36,322'); seek(1776.0)">
              execution. These inlining operations also fit to the warmup
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:40,498'); seek(1780.0)">
              charts where we see a steep decline over
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:44,092'); seek(1784.0)">
              the first few hundred or thousand iterations. So these inland
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:47,922'); seek(1787.0)">
              operations cared probably the main driver for the fast decline
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:51,510'); seek(1791.0)">
              in the warm up graphs we've just seen. The difference between
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:55,184'); seek(1795.0)">
              the XML compilation log file used by Jitwatch
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:58,966'); seek(1798.0)">
              and the compilation log output on the terminal
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:02,810'); seek(1802.0)">
              can actually be explained by the fact that there's a limitation
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:06,426'); seek(1806.0)">
              in the log compilation option, which leads to
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:10,068'); seek(1810.0)">
              the fact that these inline decisions made by the c one
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:13,748'); seek(1813.0)">
              compiler early on are not included in the XML log
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:17,496'); seek(1817.0)">
              file which is used by Jitwatch. You can read the details
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:21,886'); seek(1821.0)">
              here where I provided a link to the OpenJDK wiki.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:25,874'); seek(1825.0)">
              Okay, now I'd like to draw short conclusion
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:29,682'); seek(1829.0)">
              and also have some additional remarks to my benchmark
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:33,426'); seek(1833.0)">
              measurements. First of all, all the benchmark measurements I made
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:37,596'); seek(1837.0)">
              were done for JDK version eleven for all the mentioned
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:41,808'); seek(1841.0)">
              jvms. I did not perform measurements in any other
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:45,216'); seek(1845.0)">
              JDK version. Secondly, the benchmark
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:48,438'); seek(1848.0)">
              measurements I conducted in October and November 2020.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:52,228'); seek(1852.0)">
              So meanwhile there are new versions of the jvms,
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:55,674'); seek(1855.0)">
              so it would be interesting to also take a look at them. Yeah,
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:59,604'); seek(1859.0)">
              and here are also my final thoughts. As just said,
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:03,444'); seek(1863.0)">
              graalvm version 21 was recently released.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:07,118'); seek(1867.0)">
              It now comes with the espresso JVM, which is a
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:10,328'); seek(1870.0)">
              JVM fully written in Java. It's Java on truffle,
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:13,838'); seek(1873.0)">
              if you know what that means. Yeah, maybe I find the time
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:17,372'); seek(1877.0)">
              to also do some warm up performance benchmarking on the
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:21,068'); seek(1881.0)">
              espresso JVM. The second thought that comes to my
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:24,508'); seek(1884.0)">
              mind is that Opengenine's benefit is definitely
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:28,140'); seek(1888.0)">
              its Aot mode. So it's performing better in Aot mode,
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:31,990'); seek(1891.0)">
              at least in my measurements. But I'm asking myself,
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:36,144'); seek(1896.0)">
              why don't they make this the default configuration if they
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:39,792'); seek(1899.0)">
              also advertise with it that they are faster than the hotspot
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:43,194'); seek(1903.0)">
              VM? Last but not least, I think there are many other JVM that
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:46,916'); seek(1906.0)">
              also deserve to be benchmark on warmup performance because they
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:50,820'); seek(1910.0)">
              become more and more important in the world of different JDK
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:31:54,938'); seek(1914.0)">
              releases. For example, the Amazon Krata JVM or Alibaba Dragonwell.
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:31:59,402'); seek(1919.0)">
              All right, that was my presentation. I hope you
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:02,648'); seek(1922.0)">
              like it. It was the first talk I ever
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:05,896'); seek(1925.0)">
              held in public, and if you want to check out
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:09,308'); seek(1929.0)">
              my references or take a look at the source code,
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:12,444'); seek(1932.0)">
              you can find many more details on my blog post about
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:15,932'); seek(1935.0)">
              that topic, which is linked here. If you have any questions
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:19,564'); seek(1939.0)">
              about my measurements, my talk, my learnings,
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:22,802'); seek(1942.0)">
              or want to discuss something, yeah, just send me an
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:26,108'); seek(1946.0)">
              email. Here's my contact information and thank you for tuning in.
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:32:30,300'); seek(1950.0)">
              See you.
            </span>
            
            </div>
          </div>
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/enterprise2021" class="btn btn-sm btn-danger shadow lift" style="background-color: #555553;">
                <i class="fe fe-grid me-2"></i>
                See all 21 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/java_frank.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Frank Kriegl
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Software Developer & Java Enthusiast 
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/frank-kriegl/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Frank Kriegl's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@frankfranok" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Frank Kriegl's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @frankfranok"
                  data-url="https://www.conf42.com/enterprise2021"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/enterprise2021"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="JavaScript"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-san-francisco-q4/">
                  SREday San Francisco Q4 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>