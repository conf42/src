<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Aggressive LLMs Optimization: Making Them Work on Tiny Devices</title>
    <meta name="description" content="Help us build a dystopian, machine-ated future!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Max%20Navrotsky%20%26%20Oleksandr%20Gordieiev_ml.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Aggressive LLMs Optimization: Making Them Work on Tiny Devices | Conf42"/>
    <meta property="og:description" content="Discover how to shrink GPT‑2 for ultra‑weak hardware without sacrificing performance! We reveal how pruning, quantization, and fine‑tuning can unlock big large language model (LLM) power in tiny form."/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2025_Max_Navrotsky_Oleksandr_Gordieiev_llms_optimization_devices"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/ML2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Machine Learning 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-05-08
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ml2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2025 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Help us build a dystopian, machine-ated future!
 -->
              <script>
                const event_date = new Date("2025-05-08T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-05-08T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "85k01nwkN5s"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrDbH1VBaoA60lLAAVqmiLPe" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello everyone.", "timestamp": "00:00:00,360", "timestamp_s": 0.0}, {"text": "My name is Max, and today we\u0027re gonna talk about the aggressive", "timestamp": "00:00:01,290", "timestamp_s": 1.0}, {"text": "optimization of large scale language models in order to make sure that we", "timestamp": "00:00:03,960", "timestamp_s": 3.0}, {"text": "can make them work on tiny devices.", "timestamp": "00:00:08,580", "timestamp_s": 8.0}, {"text": "So let\u0027s start with a few words about us, me, myself, I\u0027m Max Roski.", "timestamp": "00:00:11,670", "timestamp_s": 11.0}, {"text": "I\u0027m senior software engineer VGS.", "timestamp": "00:00:15,750", "timestamp_s": 15.0}, {"text": "While my cos speaker today is Alexander Gev, the professor of software engineer", "timestamp": "00:00:18,610", "timestamp_s": 18.0}, {"text": "at Lud National Technical University.", "timestamp": "00:00:23,035", "timestamp_s": 23.0}, {"text": "Also shout out to my.", "timestamp": "00:00:25,255", "timestamp_s": 25.0}, {"text": "Why that helped me arrange this beautiful presentation here.", "timestamp": "00:00:27,100", "timestamp_s": 27.0}, {"text": "So yeah, my thanks.", "timestamp": "00:00:29,950", "timestamp_s": 29.0}, {"text": "Okay, let\u0027s start from the challenge.", "timestamp": "00:00:31,720", "timestamp_s": 31.0}, {"text": "Why actually do we need optimize those LLMs for big devices By today\u0027s standards", "timestamp": "00:00:33,160", "timestamp_s": 33.0}, {"text": "the all new large scale variations of those models actually require", "timestamp": "00:00:38,780", "timestamp_s": 38.0}, {"text": "significant competition resources, which may result, as you may guessed", "timestamp": "00:00:43,100", "timestamp_s": 43.0}, {"text": "in, overlooking the possibility of their practical deployment of low end resource", "timestamp": "00:00:47,059", "timestamp_s": 47.0}, {"text": "constrained devices, which may include.", "timestamp": "00:00:51,559", "timestamp_s": 51.0}, {"text": "Field operations, offline systems, and better device and such.", "timestamp": "00:00:53,749", "timestamp_s": 53.0}, {"text": "Our resource goal today is to find out whether the aggressive model optimization", "timestamp": "00:00:57,960", "timestamp_s": 57.0}, {"text": "techniques such as architecture streaming, pruning quantization, can", "timestamp": "00:01:02,520", "timestamp_s": 62.0}, {"text": "enable the LMS to operate efficiently under the extreme hardware constraints.", "timestamp": "00:01:06,630", "timestamp_s": 66.0}, {"text": "So as you may guess, our demonstration approach will be.", "timestamp": "00:01:12,550", "timestamp_s": 72.0}, {"text": "To use practical task in order to evaluate our optimization strategy.", "timestamp": "00:01:16,485", "timestamp_s": 76.0}, {"text": "The task will be, we\u0027ll try to fine tune and use our model to", "timestamp": "00:01:21,385", "timestamp_s": 81.0}, {"text": "generate ISO compliant software requirements basically without it.", "timestamp": "00:01:26,515", "timestamp_s": 86.0}, {"text": "Not any product can start properly and finish not only software.", "timestamp": "00:01:31,495", "timestamp_s": 91.0}, {"text": "We thought of it as a great task to evaluate the, and measure the trade", "timestamp": "00:01:36,125", "timestamp_s": 96.0}, {"text": "offs between model compression, resource consumption, and output stability.", "timestamp": "00:01:41,275", "timestamp_s": 101.0}, {"text": "Alright, so before we start optimize pretty much anything else, we need to", "timestamp": "00:01:47,045", "timestamp_s": 107.0}, {"text": "find out which model will suit the best.", "timestamp": "00:01:51,605", "timestamp_s": 111.0}, {"text": "Beside of the different alternatives there, we have been looking on the model", "timestamp": "00:01:54,335", "timestamp_s": 114.0}, {"text": "that A is open source B is not already compressed not already compressed, not", "timestamp": "00:01:59,015", "timestamp_s": 119.0}, {"text": "any techniques has been applied to it.", "timestamp": "00:02:08,265", "timestamp_s": 128.0}, {"text": "So we need something that is kinda blank sheet, but already with a small size.", "timestamp": "00:02:10,245", "timestamp_s": 130.0}, {"text": "So as you may guess from all the alternatives we stopped on GPT two.", "timestamp": "00:02:16,605", "timestamp_s": 136.0}, {"text": "Why as I mentioned before, it\u0027s open source so we can play around as", "timestamp": "00:02:21,485", "timestamp_s": 141.0}, {"text": "much as we want without encountering licensing or API limitations.", "timestamp": "00:02:26,205", "timestamp_s": 146.0}, {"text": "Second is relatively lightweight, both on parameter size with", "timestamp": "00:02:29,745", "timestamp_s": 149.0}, {"text": "117 million parameters.", "timestamp": "00:02:33,885", "timestamp_s": 153.0}, {"text": "Oh, and by the role model size, it\u0027s only 500 megabytes which is", "timestamp": "00:02:36,375", "timestamp_s": 156.0}, {"text": "not that much as you may guess.", "timestamp": "00:02:42,375", "timestamp_s": 162.0}, {"text": "Critically also that we have been looking for the GP D two.", "timestamp": "00:02:44,454", "timestamp_s": 164.0}, {"text": "Is really great at generative possibilities despite the fact", "timestamp": "00:02:47,995", "timestamp_s": 167.0}, {"text": "that it\u0027s buzz gen and it had been released in two 29, 20 19.", "timestamp": "00:02:53,524", "timestamp_s": 173.0}, {"text": "It\u0027s actually really good at producing coherent, dramatically sound.", "timestamp": "00:02:58,385", "timestamp_s": 178.0}, {"text": "The does aligned outputs, so it\u0027s actually very good, real solid for fine tuning", "timestamp": "00:03:02,255", "timestamp_s": 182.0}, {"text": "for speci, specifical demands domains.", "timestamp": "00:03:08,515", "timestamp_s": 188.0}, {"text": "And finally as a bonus point, pretty much it\u0027s actually have a transparent", "timestamp": "00:03:11,620", "timestamp_s": 191.0}, {"text": "and well-documented architecture, which allows us, allowed us to dive", "timestamp": "00:03:16,979", "timestamp_s": 196.0}, {"text": "deep into finding out the limitations of those optimization techniques.", "timestamp": "00:03:22,999", "timestamp_s": 202.0}, {"text": "So it was actually great.", "timestamp": "00:03:28,249", "timestamp_s": 208.0}, {"text": "So to sum up, if we had only one model to carry with us into forest", "timestamp": "00:03:30,389", "timestamp_s": 210.0}, {"text": "on an old laptop, it\u0027ll be GPT two.", "timestamp": "00:03:34,559", "timestamp_s": 214.0}, {"text": "Let\u0027s start with the plan.", "timestamp": "00:03:38,079", "timestamp_s": 218.0}, {"text": "So it\u0027ll be really simple one.", "timestamp": "00:03:39,249", "timestamp_s": 219.0}, {"text": "First of all, we\u0027ll go.", "timestamp": "00:03:41,589", "timestamp_s": 221.0}, {"text": "We are going to cover up the theory, then the practical results and conclusion.", "timestamp": "00:03:42,669", "timestamp_s": 222.0}, {"text": "So let\u0027s start with theory.", "timestamp": "00:03:48,609", "timestamp_s": 228.0}, {"text": "First of all, we are going to look for.", "timestamp": "00:03:51,749", "timestamp_s": 231.0}, {"text": "It\u0027s a student model concept.", "timestamp": "00:03:55,094", "timestamp_s": 235.0}, {"text": "The core idea basically student model is a instance of the basic model", "timestamp": "00:03:56,594", "timestamp_s": 236.0}, {"text": "by, but the difference that you can play around as much as you want.", "timestamp": "00:04:03,084", "timestamp_s": 243.0}, {"text": "So basically you can screw it up.", "timestamp": "00:04:06,984", "timestamp_s": 246.0}, {"text": "Maybe you will need to redo the things, but it won\u0027t affect the original.", "timestamp": "00:04:09,204", "timestamp_s": 249.0}, {"text": "So consider this something like a clone, but you can work with as much as you want.", "timestamp": "00:04:13,329", "timestamp_s": 253.0}, {"text": "So yeah, that\u0027s pretty much it.", "timestamp": "00:04:20,899", "timestamp_s": 260.0}, {"text": "Metrics by which we are going to measure the success.", "timestamp": "00:04:24,469", "timestamp_s": 264.0}, {"text": "It\u0027s four of them.", "timestamp": "00:04:28,099", "timestamp_s": 268.0}, {"text": "First of all, perplexity, the model accuracy, whether can", "timestamp": "00:04:29,419", "timestamp_s": 269.0}, {"text": "it output things correctly.", "timestamp": "00:04:33,109", "timestamp_s": 273.0}, {"text": "CPU memory usage, as you may guess, it will be really critical for measuring", "timestamp": "00:04:35,389", "timestamp_s": 275.0}, {"text": "success for like of performance on low resource, low end devices.", "timestamp": "00:04:40,669", "timestamp_s": 280.0}, {"text": "Inter interference speed, faster response time, pretty straightforward", "timestamp": "00:04:45,984", "timestamp_s": 285.0}, {"text": "and model size basically.", "timestamp": "00:04:50,004", "timestamp_s": 290.0}, {"text": "The smaller, the better general pattern here, as you noticed is", "timestamp": "00:04:51,864", "timestamp_s": 291.0}, {"text": "the smaller better, the smaller faster equals better usually.", "timestamp": "00:04:55,744", "timestamp_s": 295.0}, {"text": "Let\u0027s start with defining what we actually define as aggressive", "timestamp": "00:05:02,390", "timestamp_s": 302.0}, {"text": "methods and non-aggressive methods.", "timestamp": "00:05:05,930", "timestamp_s": 305.0}, {"text": "Let\u0027s start with non aggressive methods, because there are really", "timestamp": "00:05:08,930", "timestamp_s": 308.0}, {"text": "only one that we can specify today is a knowledge distillation.", "timestamp": "00:05:12,109", "timestamp_s": 312.0}, {"text": "Is the technique when student mimics teacher tissue model closely, like without", "timestamp": "00:05:16,204", "timestamp_s": 316.0}, {"text": "any changes at all to architecture.", "timestamp": "00:05:22,594", "timestamp_s": 322.0}, {"text": "While aggressive methods, as you may guess, is those methods there", "timestamp": "00:05:24,844", "timestamp_s": 324.0}, {"text": "will interfere with model like architecture layers, count and stuff.", "timestamp": "00:05:28,544", "timestamp_s": 328.0}, {"text": "So there are three of them.", "timestamp": "00:05:34,784", "timestamp_s": 334.0}, {"text": "Architecture, treatment they will have, like this technique is all", "timestamp": "00:05:36,194", "timestamp_s": 336.0}, {"text": "around reducing layers in neuro count.", "timestamp": "00:05:40,425", "timestamp_s": 340.0}, {"text": "Pruning, remove less important parameters in weights and ization.", "timestamp": "00:05:43,170", "timestamp_s": 343.0}, {"text": "Basically changing the AC accuracy of the weights from like fourth", "timestamp": "00:05:48,420", "timestamp_s": 348.0}, {"text": "float 42 into integer eight.", "timestamp": "00:05:52,410", "timestamp_s": 352.0}, {"text": "Standard.", "timestamp": "00:05:55,570", "timestamp_s": 355.0}, {"text": "Okay, cool.", "timestamp": "00:05:57,085", "timestamp_s": 357.0}, {"text": "So let\u0027s start with covering up the basics of the each optimization technique.", "timestamp": "00:05:57,775", "timestamp_s": 357.0}, {"text": "So with architecture, treatment, the main concept here, if it\u0027s", "timestamp": "00:06:02,905", "timestamp_s": 362.0}, {"text": "too big, just make it smaller.", "timestamp": "00:06:06,085", "timestamp_s": 366.0}, {"text": "So I would say, you should imagine this, our model as a building.", "timestamp": "00:06:08,465", "timestamp_s": 368.0}, {"text": "So like every floor and room can be considered as layer and neurons here.", "timestamp": "00:06:12,365", "timestamp_s": 372.0}, {"text": "And pretty much we just, in those technique, we just remove", "timestamp": "00:06:18,545", "timestamp_s": 378.0}, {"text": "unnecessary layers and neurons.", "timestamp": "00:06:22,175", "timestamp_s": 382.0}, {"text": "That\u0027s it.", "timestamp": "00:06:25,295", "timestamp_s": 385.0}, {"text": "With layers, we, when we remove layers, we just reduce the number", "timestamp": "00:06:26,685", "timestamp_s": 386.0}, {"text": "of protesting stages in the model.", "timestamp": "00:06:29,955", "timestamp_s": 389.0}, {"text": "While with neurons, we decrease the number of computational euros per layer, right?", "timestamp": "00:06:32,565", "timestamp_s": 392.0}, {"text": "So also we have a glossary on the bottom of the slides.", "timestamp": "00:06:38,025", "timestamp_s": 398.0}, {"text": "So feel free to pause the window and check it out, like the better", "timestamp": "00:06:41,305", "timestamp_s": 401.0}, {"text": "definition of layer in euro.", "timestamp": "00:06:44,785", "timestamp_s": 404.0}, {"text": "So that\u0027s pretty much it.", "timestamp": "00:06:46,975", "timestamp_s": 406.0}, {"text": "Pruning.", "timestamp": "00:06:48,655", "timestamp_s": 408.0}, {"text": "If it\u0027s not important, just cut it off.", "timestamp": "00:06:49,555", "timestamp_s": 409.0}, {"text": "I think we can imagine for this purpose, we can imagine a model like", "timestamp": "00:06:51,995", "timestamp_s": 411.0}, {"text": "a tree when every branch is connection between neurons and even each branch has", "timestamp": "00:06:55,655", "timestamp_s": 415.0}, {"text": "leaves, which is parameters and weights.", "timestamp": "00:07:01,735", "timestamp_s": 421.0}, {"text": "So with pruning, we can actually decide which weights we can", "timestamp": "00:07:04,285", "timestamp_s": 424.0}, {"text": "disable and just not use it all.", "timestamp": "00:07:09,265", "timestamp_s": 429.0}, {"text": "Interesting thing here that while we disabling and turning off some", "timestamp": "00:07:12,595", "timestamp_s": 432.0}, {"text": "parameters and weights, it also can.", "timestamp": "00:07:16,995", "timestamp_s": 436.0}, {"text": "Like indirectly affect the neurons because when you delete and turn off some of the", "timestamp": "00:07:19,605", "timestamp_s": 439.0}, {"text": "neurons some of the weights in parameters, it may just turn off some neurons.", "timestamp": "00:07:25,915", "timestamp_s": 445.0}, {"text": "So it\u0027s really interesting here and here.", "timestamp": "00:07:32,055", "timestamp_s": 452.0}, {"text": "Quantization.", "timestamp": "00:07:34,395", "timestamp_s": 454.0}, {"text": "Basically the main concept here is you may see heat precision isn\u0027t critical.", "timestamp": "00:07:35,325", "timestamp_s": 455.0}, {"text": "We do not need use heavy tools.", "timestamp": "00:07:39,315", "timestamp_s": 459.0}, {"text": "Basically speaking we are turning off.", "timestamp": "00:07:42,015", "timestamp_s": 462.0}, {"text": "Like changing the basic float 32 standard and like into integer eight.", "timestamp": "00:07:45,135", "timestamp_s": 465.0}, {"text": "So it will be less, our model will be less precise, but it\u0027ll", "timestamp": "00:07:51,955", "timestamp_s": 471.0}, {"text": "be great in like CPU performance and much more easier to work with.", "timestamp": "00:07:56,365", "timestamp_s": 476.0}, {"text": "Yeah.", "timestamp": "00:08:01,645", "timestamp_s": 481.0}, {"text": "So we just make sure that our weights are, turned, turned", "timestamp": "00:08:01,914", "timestamp_s": 481.0}, {"text": "into smaller, lightweight ones.", "timestamp": "00:08:06,075", "timestamp_s": 486.0}, {"text": "Those effects, as you may see on the graph, it affects only", "timestamp": "00:08:08,325", "timestamp_s": 488.0}, {"text": "weights and parameters here.", "timestamp": "00:08:11,445", "timestamp_s": 491.0}, {"text": "And for the non-aggressive optimization methods here", "timestamp": "00:08:15,255", "timestamp_s": 495.0}, {"text": "distillation can be considered as a mutation of the teacher model here.", "timestamp": "00:08:18,775", "timestamp_s": 498.0}, {"text": "So it\u0027s the student that copies from the experienced teacher.", "timestamp": "00:08:24,475", "timestamp_s": 504.0}, {"text": "Very important note here.", "timestamp": "00:08:27,955", "timestamp_s": 507.0}, {"text": "This thing, this method is non aggressive because it does not", "timestamp": "00:08:29,815", "timestamp_s": 509.0}, {"text": "interfere with model architecture.", "timestamp": "00:08:33,865", "timestamp_s": 513.0}, {"text": "Therefore, we do not need to be worried about performance de degradation here.", "timestamp": "00:08:37,775", "timestamp_s": 517.0}, {"text": "Good.", "timestamp": "00:08:43,535", "timestamp_s": 523.0}, {"text": "Also the most important know that we want to live here is that.", "timestamp": "00:08:46,625", "timestamp_s": 526.0}, {"text": "Distillation is really, will work on it.", "timestamp": "00:08:51,520", "timestamp_s": 531.0}, {"text": "It\u0027ll work good if only the student model has not anything", "timestamp": "00:08:54,400", "timestamp_s": 534.0}, {"text": "changed in the architecture.", "timestamp": "00:08:59,410", "timestamp_s": 539.0}, {"text": "So the, both the student model and teacher one should be pretty much the same.", "timestamp": "00:09:00,760", "timestamp_s": 540.0}, {"text": "And here, as you may see in the graph it\u0027s not affecting anything", "timestamp": "00:09:07,510", "timestamp_s": 547.0}, {"text": "in the architecture, but it just learns the outputs and the", "timestamp": "00:09:11,150", "timestamp_s": 551.0}, {"text": "weights from the tissue once.", "timestamp": "00:09:15,140", "timestamp_s": 555.0}, {"text": "So it\u0027s all in once.", "timestamp": "00:09:16,430", "timestamp_s": 556.0}, {"text": "Okay, cool.", "timestamp": "00:09:19,285", "timestamp_s": 559.0}, {"text": "So as you, we noticed those three aggressive methods, architecture,", "timestamp": "00:09:19,735", "timestamp_s": 559.0}, {"text": "dreaming, proving quantization are playing with models,", "timestamp": "00:09:23,805", "timestamp_s": 563.0}, {"text": "architecture in different way.", "timestamp": "00:09:30,075", "timestamp_s": 570.0}, {"text": "One in, for instance, for archite architecture dreaming.", "timestamp": "00:09:32,295", "timestamp_s": 572.0}, {"text": "We just remove some of the layers while pruning, for instance, just", "timestamp": "00:09:35,625", "timestamp_s": 575.0}, {"text": "remove not layers, but weights.", "timestamp": "00:09:39,945", "timestamp_s": 579.0}, {"text": "And quantization just reducing the accuracy of those weights", "timestamp": "00:09:42,315", "timestamp_s": 582.0}, {"text": "but not removing them.", "timestamp": "00:09:45,795", "timestamp_s": 585.0}, {"text": "So they\u0027re really the same, but in different way.", "timestamp": "00:09:46,905", "timestamp_s": 586.0}, {"text": "Alright, so yeah, that\u0027s the summary for you if you want to", "timestamp": "00:09:50,865", "timestamp_s": 590.0}, {"text": "pass out video and check it out.", "timestamp": "00:09:53,715", "timestamp_s": 593.0}, {"text": "So let\u0027s start with part two, practical research.", "timestamp": "00:09:56,355", "timestamp_s": 596.0}, {"text": "As you may guessed, we already have an order of experiments here.", "timestamp": "00:09:59,815", "timestamp_s": 599.0}, {"text": "So first of all we will our, like this part will switch in several steps.", "timestamp": "00:10:03,145", "timestamp_s": 603.0}, {"text": "First one, we are gonna fine tune our model because without fine tuning,", "timestamp": "00:10:08,635", "timestamp_s": 608.0}, {"text": "it does not make much many sense.", "timestamp": "00:10:11,725", "timestamp_s": 611.0}, {"text": "And therefore we\u0027ll continue with architecture, treatment, distillation,", "timestamp": "00:10:13,965", "timestamp_s": 613.0}, {"text": "pruning, quantization, and then we\u0027re gonna combine those methods.", "timestamp": "00:10:17,865", "timestamp_s": 617.0}, {"text": "We are gonna explain later why we do this methods in this specific order.", "timestamp": "00:10:21,675", "timestamp_s": 621.0}, {"text": "So let\u0027s start.", "timestamp": "00:10:26,545", "timestamp_s": 626.0}, {"text": "But before we start, we need to get the basic benchmark of", "timestamp": "00:10:28,235", "timestamp_s": 628.0}, {"text": "training the base role, DPT two.", "timestamp": "00:10:32,485", "timestamp_s": 632.0}, {"text": "So it\u0027s pre-trained.", "timestamp": "00:10:35,785", "timestamp_s": 635.0}, {"text": "Non-specialized and it\u0027ll struggle with any task specific like structure there.", "timestamp": "00:10:37,390", "timestamp_s": 637.0}, {"text": "Those, some metrics on the left that we specify before, perplexity usage, memory", "timestamp": "00:10:43,190", "timestamp_s": 643.0}, {"text": "usage, inference, speed, and model size.", "timestamp": "00:10:47,210", "timestamp_s": 647.0}, {"text": "And therefore they are prompt results.", "timestamp": "00:10:49,520", "timestamp_s": 649.0}, {"text": "So you can see like visually what is going on, as you may see on the output.", "timestamp": "00:10:52,100", "timestamp_s": 652.0}, {"text": "It\u0027s not hallucinating, I would say, but it\u0027s not that semantically.", "timestamp": "00:10:57,770", "timestamp_s": 657.0}, {"text": "Correct.", "timestamp": "00:11:01,940", "timestamp_s": 661.0}, {"text": "Which may result in, the possibility and the requirement of actually fine", "timestamp": "00:11:03,330", "timestamp_s": 663.0}, {"text": "tuning our model to do specific tasks like iso requirements generation.", "timestamp": "00:11:06,690", "timestamp_s": 666.0}, {"text": "Okay.", "timestamp": "00:11:14,500", "timestamp_s": 674.0}, {"text": "I think the first step after comparing with the role GPT two we need to", "timestamp": "00:11:14,970", "timestamp_s": 674.0}, {"text": "fine tune the model basically.", "timestamp": "00:11:19,900", "timestamp_s": 679.0}, {"text": "I\u0027m sorry.", "timestamp": "00:11:22,630", "timestamp_s": 682.0}, {"text": "Basically this model will, there will no optimization applied first.", "timestamp": "00:11:23,560", "timestamp_s": 683.0}, {"text": "Our model is fine tuned towards ISO compliance software requirements", "timestamp": "00:11:28,150", "timestamp_s": 688.0}, {"text": "that I set and it\u0027ll useful GPTT architecture and it\u0027ll the", "timestamp": "00:11:31,600", "timestamp_s": 691.0}, {"text": "reference point for our comparisons.", "timestamp": "00:11:36,190", "timestamp_s": 696.0}, {"text": "As you may see, after we fine tune it to our, to to our specific task,", "timestamp": "00:11:37,780", "timestamp_s": 697.0}, {"text": "the output is much more better.", "timestamp": "00:11:41,340", "timestamp_s": 701.0}, {"text": "So that\u0027s I would say reference point.", "timestamp": "00:11:43,320", "timestamp_s": 703.0}, {"text": "Yeah.", "timestamp": "00:11:47,150", "timestamp_s": 707.0}, {"text": "So with fine tune, with fine tuning model, everything got better there.", "timestamp": "00:11:47,660", "timestamp_s": 707.0}, {"text": "Only perplexity got a little bit worse.", "timestamp": "00:11:51,625", "timestamp_s": 711.0}, {"text": "I would say perplexity value starting from one up to one and five are really", "timestamp": "00:11:54,565", "timestamp_s": 714.0}, {"text": "solid, and we\u0027ll provide you the quality of the model that we\u0027re, that you will", "timestamp": "00:12:00,175", "timestamp_s": 720.0}, {"text": "see that is good visually at least.", "timestamp": "00:12:06,145", "timestamp_s": 726.0}, {"text": "Okay, so let\u0027s start with the first step.", "timestamp": "00:12:09,415", "timestamp_s": 729.0}, {"text": "I think the most mandatory one, architecture dreaming.", "timestamp": "00:12:11,155", "timestamp_s": 731.0}, {"text": "In our practical research, we remote, we removed half of the GPT two layers.", "timestamp": "00:12:14,055", "timestamp_s": 734.0}, {"text": "And reduce hidden size.", "timestamp": "00:12:18,855", "timestamp_s": 738.0}, {"text": "Basically, we shifted from 12 layers to six from like 768 dimensions", "timestamp": "00:12:20,535", "timestamp_s": 740.0}, {"text": "to 384, which means same inputs, but just lighter architecture", "timestamp": "00:12:28,425", "timestamp_s": 748.0}, {"text": "and fighter and faster execution.", "timestamp": "00:12:34,935", "timestamp_s": 754.0}, {"text": "You may also ask about how did we pick which layers to trim?", "timestamp": "00:12:37,185", "timestamp_s": 757.0}, {"text": "The strategy there was actually really simple one.", "timestamp": "00:12:40,895", "timestamp_s": 760.0}, {"text": "We just removed layers symmetrically from center.", "timestamp": "00:12:44,075", "timestamp_s": 764.0}, {"text": "Which allows us to preserve bottom layers that are responsible for basic", "timestamp": "00:12:46,725", "timestamp_s": 766.0}, {"text": "syntax and token level understanding.", "timestamp": "00:12:50,565", "timestamp_s": 770.0}, {"text": "And also we preserve top layers, which are for higher level structure, for", "timestamp": "00:12:52,485", "timestamp_s": 772.0}, {"text": "context, you know what I\u0027m saying?", "timestamp": "00:12:58,275", "timestamp_s": 778.0}, {"text": "Basically speaking, this allow allowed us to maintain both low level", "timestamp": "00:13:01,375", "timestamp_s": 781.0}, {"text": "and high level processing there.", "timestamp": "00:13:04,825", "timestamp_s": 784.0}, {"text": "Awesome.", "timestamp": "00:13:06,625", "timestamp_s": 786.0}, {"text": "So let\u0027s compare the performance here.", "timestamp": "00:13:08,455", "timestamp_s": 788.0}, {"text": "As you may see, perplexity gone a little bit worse.", "timestamp": "00:13:12,055", "timestamp_s": 792.0}, {"text": "Because like it\u0027s gone.", "timestamp": "00:13:15,050", "timestamp_s": 795.0}, {"text": "Not that accurate, but as you may see, the output to the prompt is really solid.", "timestamp": "00:13:16,250", "timestamp_s": 796.0}, {"text": "It\u0027s pretty much the same.", "timestamp": "00:13:23,180", "timestamp_s": 803.0}, {"text": "It hasn\u0027t changed.", "timestamp": "00:13:24,260", "timestamp_s": 804.0}, {"text": "But here we also notice here that the memory usage actually increased.", "timestamp": "00:13:25,460", "timestamp_s": 805.0}, {"text": "Why?", "timestamp": "00:13:30,500", "timestamp_s": 810.0}, {"text": "When we.", "timestamp": "00:13:30,940", "timestamp_s": 810.0}, {"text": "We reduce our CP usage.", "timestamp": "00:13:31,795", "timestamp_s": 811.0}, {"text": "Somebody has to pay and this somebody is wrong.", "timestamp": "00:13:34,255", "timestamp_s": 814.0}, {"text": "Basically speaking.", "timestamp": "00:13:38,455", "timestamp_s": 818.0}, {"text": "We with optimizations like quantization layer treatment, we reduce processing", "timestamp": "00:13:39,515", "timestamp_s": 819.0}, {"text": "time, but they will compensate in tensor sizes, caching, parallel processing,", "timestamp": "00:13:44,315", "timestamp_s": 824.0}, {"text": "which will increase their wrong memory.", "timestamp": "00:13:51,095", "timestamp_s": 831.0}, {"text": "Why this matters.", "timestamp": "00:13:55,035", "timestamp_s": 835.0}, {"text": "CPU time equals the energy cost on battery powered by the devices.", "timestamp": "00:13:56,770", "timestamp_s": 836.0}, {"text": "And most of the time CPU U is the biggest power draw.", "timestamp": "00:14:02,080", "timestamp_s": 842.0}, {"text": "While RO is something that we can neglect and it\u0027s generally", "timestamp": "00:14:05,440", "timestamp_s": 845.0}, {"text": "more available, but not limited.", "timestamp": "00:14:10,920", "timestamp_s": 850.0}, {"text": "So it\u0027s actually, we consider it as a cheap to access.", "timestamp": "00:14:13,790", "timestamp_s": 853.0}, {"text": "But a little bit limited on the old laptops and microcontrollers,", "timestamp": "00:14:17,565", "timestamp_s": 857.0}, {"text": "which is, in our use case.", "timestamp": "00:14:20,895", "timestamp_s": 860.0}, {"text": "It\u0027s not that problematic as we more lean towards providing the proper experience", "timestamp": "00:14:22,425", "timestamp_s": 862.0}, {"text": "with CPU in order to make sure that they can work on embedded devices.", "timestamp": "00:14:29,865", "timestamp_s": 869.0}, {"text": "Yeah, so in this graph, it\u0027s pretty much the summary of all the things", "timestamp": "00:14:35,655", "timestamp_s": 875.0}, {"text": "that we talked before with the graphs.", "timestamp": "00:14:38,985", "timestamp_s": 878.0}, {"text": "As you as you may see on the x. Axis we have starting from the Rob GT two and at", "timestamp": "00:14:40,965", "timestamp_s": 880.0}, {"text": "the end you will, we will compare also combine sensors there, the RAM users", "timestamp": "00:14:46,210", "timestamp_s": 886.0}, {"text": "there changed by almost 200 megabytes.", "timestamp": "00:14:50,170", "timestamp_s": 890.0}, {"text": "Not that big, but something that we have to consider on.", "timestamp": "00:14:52,990", "timestamp_s": 892.0}, {"text": "Okay, let\u0027s continue.", "timestamp": "00:14:55,570", "timestamp_s": 895.0}, {"text": "You may also ask, but why don\u0027t we apply distillation", "timestamp": "00:14:57,550", "timestamp_s": 897.0}, {"text": "and therefore it\u0027s break point.", "timestamp": "00:15:02,020", "timestamp_s": 902.0}, {"text": "The thing is that we student modeled it\u0027s trained.", "timestamp": "00:15:05,200", "timestamp_s": 905.0}, {"text": "In this process, the student model trained to mimic, make a bigger teacher model.", "timestamp": "00:15:08,630", "timestamp_s": 908.0}, {"text": "But after we chopped hard, the student model it just too small", "timestamp": "00:15:12,860", "timestamp_s": 912.0}, {"text": "to understand the teacher.", "timestamp": "00:15:17,690", "timestamp_s": 917.0}, {"text": "It means that student just can does not have enough layers to understand teacher", "timestamp": "00:15:19,700", "timestamp_s": 919.0}, {"text": "outputs, which means that our student model will try to compensate it and it\u0027ll", "timestamp": "00:15:25,540", "timestamp_s": 925.0}, {"text": "result in hallucinations and repetitions.", "timestamp": "00:15:30,920", "timestamp_s": 930.0}, {"text": "Yeah, this graph pretty much basically represents the effect that", "timestamp": "00:15:36,555", "timestamp_s": 936.0}, {"text": "we are trying to represent here.", "timestamp": "00:15:40,695", "timestamp_s": 940.0}, {"text": "While at some point, student model will just stop, basically understand", "timestamp": "00:15:42,495", "timestamp_s": 942.0}, {"text": "what model tries to learn and to teach.", "timestamp": "00:15:48,075", "timestamp_s": 948.0}, {"text": "So it\u0027ll do the only thing it\u0027s possible to do with architecture when LLMs.", "timestamp": "00:15:52,515", "timestamp_s": 952.0}, {"text": "Hallucination and repetition.", "timestamp": "00:15:57,750", "timestamp_s": 957.0}, {"text": "As we mentioned before.", "timestamp": "00:15:59,130", "timestamp_s": 959.0}, {"text": "As a result, we finishing critical failure point and here there\u0027s", "timestamp": "00:16:00,690", "timestamp_s": 960.0}, {"text": "nothing we can do with distillation and we need to drop it off.", "timestamp": "00:16:04,490", "timestamp_s": 964.0}, {"text": "Yeah.", "timestamp": "00:16:09,710", "timestamp_s": 969.0}, {"text": "As you may see with a performance snapshot for distillation, the", "timestamp": "00:16:10,280", "timestamp_s": 970.0}, {"text": "output is straight up non-usable with propensity well is for it\u0027s.", "timestamp": "00:16:14,260", "timestamp_s": 974.0}, {"text": "As you may see by output, it\u0027s not usable.", "timestamp": "00:16:22,140", "timestamp_s": 982.0}, {"text": "So yeah, we just skip it all together.", "timestamp": "00:16:25,140", "timestamp_s": 985.0}, {"text": "That\u0027s why it\u0027s called non aggressive, as you may see.", "timestamp": "00:16:27,690", "timestamp_s": 987.0}, {"text": "As a quick conclusion here, non aggressive methods are not working", "timestamp": "00:16:30,830", "timestamp_s": 990.0}, {"text": "right with aggressive ones.", "timestamp": "00:16:33,980", "timestamp_s": 993.0}, {"text": "Okay?", "timestamp": "00:16:35,510", "timestamp_s": 995.0}, {"text": "Yeah.", "timestamp": "00:16:37,220", "timestamp_s": 997.0}, {"text": "So let\u0027s continue with pruning.", "timestamp": "00:16:37,610", "timestamp_s": 997.0}, {"text": "With pruning.", "timestamp": "00:16:39,860", "timestamp_s": 999.0}, {"text": "As we mentioned before, the theoretical part, really more parameters", "timestamp": "00:16:40,430", "timestamp_s": 1000.0}, {"text": "that have low or no contribution.", "timestamp": "00:16:43,790", "timestamp_s": 1003.0}, {"text": "How do we choose those weights?", "timestamp": "00:16:46,310", "timestamp_s": 1006.0}, {"text": "We just rank all weights by getting their absolute value,", "timestamp": "00:16:48,260", "timestamp_s": 1008.0}, {"text": "then just remove the one one.", "timestamp": "00:16:52,230", "timestamp_s": 1012.0}, {"text": "Yeah, it\u0027s pretty much simple.", "timestamp": "00:16:53,760", "timestamp_s": 1013.0}, {"text": "It\u0027s not that hard.", "timestamp": "00:16:55,290", "timestamp_s": 1015.0}, {"text": "We just muting the quietest voices in the nose, noisy room, and why it\u0027s", "timestamp": "00:16:57,050", "timestamp_s": 1017.0}, {"text": "working, because many weights are in large, more are close to zero,", "timestamp": "00:17:01,490", "timestamp_s": 1021.0}, {"text": "which allows them to balance out.", "timestamp": "00:17:05,660", "timestamp_s": 1025.0}, {"text": "Some like context and for the larger models, it\u0027ll be really great in", "timestamp": "00:17:07,800", "timestamp_s": 1027.0}, {"text": "order to have general context.", "timestamp": "00:17:12,660", "timestamp_s": 1032.0}, {"text": "But in our use case, the le less memory, faster competition, but only slightly.", "timestamp": "00:17:14,580", "timestamp_s": 1034.0}, {"text": "Yeah, from the benchmark here, perplexity here is pretty much the", "timestamp": "00:17:21,070", "timestamp_s": 1041.0}, {"text": "same as for architecture training.", "timestamp": "00:17:24,460", "timestamp_s": 1044.0}, {"text": "But the memory, use it really hard.", "timestamp": "00:17:26,330", "timestamp_s": 1046.0}, {"text": "Like going really like big, I would say as you may see it sometimes it", "timestamp": "00:17:28,020", "timestamp_s": 1048.0}, {"text": "hallucinates and just does not do anything, but no worries will get better", "timestamp": "00:17:33,870", "timestamp_s": 1053.0}, {"text": "results after we combine those methods.", "timestamp": "00:17:39,140", "timestamp_s": 1059.0}, {"text": "Quantization quantization, as we said before in theoretical part, when we", "timestamp": "00:17:42,110", "timestamp_s": 1062.0}, {"text": "convert them, model weights, accuracy from flow through the two into enter eight.", "timestamp": "00:17:46,780", "timestamp_s": 1066.0}, {"text": "We make sure, like we don\u0027t delete anything but just make the", "timestamp": "00:17:52,280", "timestamp_s": 1072.0}, {"text": "model a little bit less precise.", "timestamp": "00:17:56,120", "timestamp_s": 1076.0}, {"text": "So here we\u0027ll get a huge benefit of less CPU load and basically", "timestamp": "00:17:58,100", "timestamp_s": 1078.0}, {"text": "no work actual changes needed.", "timestamp": "00:18:04,490", "timestamp_s": 1084.0}, {"text": "So pretty much no performance degradation there.", "timestamp": "00:18:05,840", "timestamp_s": 1085.0}, {"text": "Okay, so when we go to performance, you will see that the memory", "timestamp": "00:18:10,490", "timestamp_s": 1090.0}, {"text": "usage there is pretty much almost non didn\u0027t change at all.", "timestamp": "00:18:14,390", "timestamp_s": 1094.0}, {"text": "While the model size is produced drastically with the CPU usage at 12%,", "timestamp": "00:18:19,720", "timestamp_s": 1099.0}, {"text": "12 and a half percent, while basic RGBT model will occupy like 45% of your", "timestamp": "00:18:25,870", "timestamp_s": 1105.0}, {"text": "like low end device, which is huge.", "timestamp": "00:18:31,660", "timestamp_s": 1111.0}, {"text": "And you\u0027ll see, and you\u0027ll see you later see by, see it by yourself, by at the end", "timestamp": "00:18:34,330", "timestamp_s": 1114.0}, {"text": "of the talk while we get the conclusion.", "timestamp": "00:18:39,760", "timestamp_s": 1119.0}, {"text": "So we are coming up to the combined optimization here and, in those", "timestamp": "00:18:42,730", "timestamp_s": 1122.0}, {"text": "optimization methods, we are combining treatment, pruning and quantization.", "timestamp": "00:18:47,430", "timestamp_s": 1127.0}, {"text": "So at the end, we\u0027ll have fine tuned model, fine tuned, GPT model for one,", "timestamp": "00:18:51,060", "timestamp_s": 1131.0}, {"text": "task, three model to six layers, prune 40% of smaller weights, and we\u0027ll quantize.", "timestamp": "00:18:56,760", "timestamp_s": 1136.0}, {"text": "Two in eight from flow through the two for CPU Efficiency.", "timestamp": "00:19:04,920", "timestamp_s": 1144.0}, {"text": "As as you may see, we don\u0027t use distillation at all because it just", "timestamp": "00:19:09,150", "timestamp_s": 1149.0}, {"text": "does not stack neither work with aggressive methods combined about in", "timestamp": "00:19:12,530", "timestamp_s": 1152.0}, {"text": "this case, there are no methods that will allow distillation work with", "timestamp": "00:19:17,440", "timestamp_s": 1157.0}, {"text": "aggressive methods as architecture.", "timestamp": "00:19:20,590", "timestamp_s": 1160.0}, {"text": "Defense is too drastic.", "timestamp": "00:19:22,780", "timestamp_s": 1162.0}, {"text": "Okay, so with the performance snapshot of our best combined methods here,", "timestamp": "00:19:25,045", "timestamp_s": 1165.0}, {"text": "perplexity changed by really little bit.", "timestamp": "00:19:29,335", "timestamp_s": 1169.0}, {"text": "While CPU usage there got almost twice as small while memory usage,", "timestamp": "00:19:31,475", "timestamp_s": 1171.0}, {"text": "as you may see, is almost like 200 megabytes higher with inference", "timestamp": "00:19:36,405", "timestamp_s": 1176.0}, {"text": "speed really perfect, almost newer.", "timestamp": "00:19:41,335", "timestamp_s": 1181.0}, {"text": "Perfect, I would say.", "timestamp": "00:19:43,585", "timestamp_s": 1183.0}, {"text": "And the model size shrunk into like almost five times of the original.", "timestamp": "00:19:44,605", "timestamp_s": 1184.0}, {"text": "Yeah, it\u0027s really perfect.", "timestamp": "00:19:50,365", "timestamp_s": 1190.0}, {"text": "One.", "timestamp": "00:19:51,835", "timestamp_s": 1191.0}, {"text": "So let\u0027s see how it\u0027s gonna represent in different metrics.", "timestamp": "00:19:52,520", "timestamp_s": 1192.0}, {"text": "So we\u0027ll we can see here by using the company combined optimization", "timestamp": "00:19:57,410", "timestamp_s": 1197.0}, {"text": "methods those, our students, our student model will reduce CPU load by", "timestamp": "00:20:02,020", "timestamp_s": 1202.0}, {"text": "almost a half compared to row G PT two", "timestamp": "00:20:06,650", "timestamp_s": 1206.0}, {"text": "which makes it significantly more suitable for battery powered CPU only", "timestamp": "00:20:12,480", "timestamp_s": 1212.0}, {"text": "devices where energy is critical.", "timestamp": "00:20:15,870", "timestamp_s": 1215.0}, {"text": "Basically it means less CPU, faster response times, lower energy costs,", "timestamp": "00:20:19,680", "timestamp_s": 1219.0}, {"text": "everyone\u0027s happy memory usage.", "timestamp": "00:20:24,180", "timestamp_s": 1224.0}, {"text": "As you may see, the change there is not that big, but it\u0027s a kind of trade", "timestamp": "00:20:27,080", "timestamp_s": 1227.0}, {"text": "off that we pay for lower CPU costs.", "timestamp": "00:20:32,040", "timestamp_s": 1232.0}, {"text": "It\u0027s acceptable, especially in Muslim low end laptops and body boards.", "timestamp": "00:20:35,730", "timestamp_s": 1235.0}, {"text": "But this, there is the thing that we should consider of a memory usage.", "timestamp": "00:20:40,200", "timestamp_s": 1240.0}, {"text": "This is the thing that pays off for the all optimizations.", "timestamp": "00:20:44,640", "timestamp_s": 1244.0}, {"text": "Perplexity actually remained the same.", "timestamp": "00:20:48,705", "timestamp_s": 1248.0}, {"text": "So we were really happy with the results.", "timestamp": "00:20:50,925", "timestamp_s": 1250.0}, {"text": "So it means at the end we can conclude that the optimization, the combining", "timestamp": "00:20:53,595", "timestamp_s": 1253.0}, {"text": "optimization techniques are not equal degradation if fine tuning done right,", "timestamp": "00:20:59,415", "timestamp_s": 1259.0}, {"text": "model size as you may see it shrink almost in five times of the original,", "timestamp": "00:21:06,285", "timestamp_s": 1266.0}, {"text": "basically smaller model, same brain.", "timestamp": "00:21:11,015", "timestamp_s": 1271.0}, {"text": "We are going to part three conclusions.", "timestamp": "00:21:14,525", "timestamp_s": 1274.0}, {"text": "So you might also thought if their methods are so good, why should", "timestamp": "00:21:16,985", "timestamp_s": 1276.0}, {"text": "we like not always use them?", "timestamp": "00:21:20,695", "timestamp_s": 1280.0}, {"text": "It me, like basically we omitted the fact that it\u0027s work perfectly", "timestamp": "00:21:23,305", "timestamp_s": 1283.0}, {"text": "only on fine tuned models.", "timestamp": "00:21:28,705", "timestamp_s": 1288.0}, {"text": "So actually why fine tuning map like fine tuning technique matters.", "timestamp": "00:21:31,645", "timestamp_s": 1291.0}, {"text": "Fine tuning aligns the model to a single atomic task.", "timestamp": "00:21:36,200", "timestamp_s": 1296.0}, {"text": "Therefore, that specific focus make the model resistant to aggressive compression", "timestamp": "00:21:39,410", "timestamp_s": 1299.0}, {"text": "While out of the box models are kinda generalist and they\u0027re like not good in", "timestamp": "00:21:46,230", "timestamp_s": 1306.0}, {"text": "anything else, like jack of all trades.", "timestamp": "00:21:50,700", "timestamp_s": 1310.0}, {"text": "And they basically, they\u0027re trying to do everything and they will be really", "timestamp": "00:21:52,710", "timestamp_s": 1312.0}, {"text": "fragile towards like applying any of them.", "timestamp": "00:21:56,730", "timestamp_s": 1316.0}, {"text": "Yeah.", "timestamp": "00:22:00,540", "timestamp_s": 1320.0}, {"text": "So with the League of Mind, Alexandra, we defined definition", "timestamp": "00:22:02,220", "timestamp_s": 1322.0}, {"text": "of Reist model resistance.", "timestamp": "00:22:07,490", "timestamp_s": 1327.0}, {"text": "It means that it defines how well model maintains output quality", "timestamp": "00:22:09,410", "timestamp_s": 1329.0}, {"text": "after aggressive compression.", "timestamp": "00:22:14,390", "timestamp_s": 1334.0}, {"text": "So by high resistance, we define fine tuned models for one clear", "timestamp": "00:22:16,420", "timestamp_s": 1336.0}, {"text": "task, which means strong internal signal, the translation to low", "timestamp": "00:22:20,920", "timestamp_s": 1340.0}, {"text": "dependency on full architecture.", "timestamp": "00:22:25,260", "timestamp_s": 1345.0}, {"text": "When quality drops really slowly, even heavy pruning on quantization and for", "timestamp": "00:22:27,675", "timestamp_s": 1347.0}, {"text": "the lower resistance, we define this and the, as the general purpose model", "timestamp": "00:22:32,865", "timestamp_s": 1352.0}, {"text": "that has like many overlapping skills and even the smallest optimization there", "timestamp": "00:22:37,365", "timestamp_s": 1357.0}, {"text": "would result into breaking the visual results and the performance metrics.", "timestamp": "00:22:43,135", "timestamp_s": 1363.0}, {"text": "Also, we have a graph to we also applied the same methods to the raw", "timestamp": "00:22:49,855", "timestamp_s": 1369.0}, {"text": "G PT two, and the results were not.", "timestamp": "00:22:53,625", "timestamp_s": 1373.0}, {"text": "Usable at all.", "timestamp": "00:22:56,625", "timestamp_s": 1376.0}, {"text": "So as you may see for the fine tuned models it\u0027s almost changed", "timestamp": "00:22:58,125", "timestamp_s": 1378.0}, {"text": "like it hasn\u0027t changed at all.", "timestamp": "00:23:02,435", "timestamp_s": 1382.0}, {"text": "While for BT two it changed really drastically.", "timestamp": "00:23:04,235", "timestamp_s": 1384.0}, {"text": "So as you may see, the re resistance team here is really important.", "timestamp": "00:23:07,175", "timestamp_s": 1387.0}, {"text": "So fine tuning models here is really important by as", "timestamp": "00:23:11,405", "timestamp_s": 1391.0}, {"text": "treatment stable perplexity.", "timestamp": "00:23:15,835", "timestamp_s": 1395.0}, {"text": "Almost grow slowly or not growing at all while general purpose models break", "timestamp": "00:23:18,190", "timestamp_s": 1398.0}, {"text": "fast and perpetuate their skyrockets.", "timestamp": "00:23:22,780", "timestamp_s": 1402.0}, {"text": "So it\u0027s, it is great.", "timestamp": "00:23:26,480", "timestamp_s": 1406.0}, {"text": "While fine tuning mon, like fine tuning models allows us to focus on", "timestamp": "00:23:27,530", "timestamp_s": 1407.0}, {"text": "the single task which is kinda reducing general noise and general models", "timestamp": "00:23:31,460", "timestamp_s": 1411.0}, {"text": "in the controversy are too broad.", "timestamp": "00:23:37,200", "timestamp_s": 1417.0}, {"text": "Even small cuts will disrupt everything.", "timestamp": "00:23:39,090", "timestamp_s": 1419.0}, {"text": "So basically speaking optimizations.", "timestamp": "00:23:42,090", "timestamp_s": 1422.0}, {"text": "Combining the optimization methods work best, but the model", "timestamp": "00:23:44,520", "timestamp_s": 1424.0}, {"text": "knows what it\u0027s supposed to do.", "timestamp": "00:23:47,670", "timestamp_s": 1427.0}, {"text": "Yeah.", "timestamp": "00:23:51,420", "timestamp_s": 1431.0}, {"text": "Without fine tuning, pruning will break meaning of general model.", "timestamp": "00:23:53,310", "timestamp_s": 1433.0}, {"text": "Quantization will introduce noise, which also affect the", "timestamp": "00:23:57,510", "timestamp_s": 1437.0}, {"text": "visual represe of the output.", "timestamp": "00:24:01,950", "timestamp_s": 1441.0}, {"text": "And trimming also deletes the clear within the path.", "timestamp": "00:24:03,750", "timestamp_s": 1443.0}, {"text": "So at the end with fine tuning, everything stays coherent even.", "timestamp": "00:24:07,240", "timestamp_s": 1447.0}, {"text": "And 75% of compression as you may see, basically fine tuning", "timestamp": "00:24:11,500", "timestamp_s": 1451.0}, {"text": "isn\u0027t a just an extra step.", "timestamp": "00:24:16,150", "timestamp_s": 1456.0}, {"text": "It\u0027s what makes optimization possible.", "timestamp": "00:24:17,830", "timestamp_s": 1457.0}, {"text": "So yeah, that\u0027s pretty much finishing slide with the final takeaways.", "timestamp": "00:24:21,390", "timestamp_s": 1461.0}, {"text": "First of all, fine tuning is the true enabler.", "timestamp": "00:24:24,510", "timestamp_s": 1464.0}, {"text": "It makes compression possible without the collapse of the model", "timestamp": "00:24:26,940", "timestamp_s": 1466.0}, {"text": "while we apply those techniques.", "timestamp": "00:24:30,960", "timestamp_s": 1470.0}, {"text": "Architecture driven reduces, depths and size brilliant", "timestamp": "00:24:33,150", "timestamp_s": 1473.0}, {"text": "remotes, low impact weights.", "timestamp": "00:24:35,760", "timestamp_s": 1475.0}, {"text": "Quantization boosts CPU Efficiency while distillation fails when applied", "timestamp": "00:24:37,840", "timestamp_s": 1477.0}, {"text": "to aggressively minimize students.", "timestamp": "00:24:42,310", "timestamp_s": 1482.0}, {"text": "Resistance here is a key.", "timestamp": "00:24:44,530", "timestamp_s": 1484.0}, {"text": "Fine tune models resist degradation, far better than general models.", "timestamp": "00:24:46,630", "timestamp_s": 1486.0}, {"text": "So basically speaking, we didn\u0027t just shrink a model, we built", "timestamp": "00:24:50,605", "timestamp_s": 1490.0}, {"text": "a focused, efficient specialist and fine tuning may possible.", "timestamp": "00:24:53,575", "timestamp_s": 1493.0}, {"text": "Thank you very much.", "timestamp": "00:24:59,455", "timestamp_s": 1499.0}, {"text": "It was my pleasure.", "timestamp": "00:25:00,705", "timestamp_s": 1500.0}, {"text": "Great pleasure to provide a talk here.", "timestamp": "00:25:01,665", "timestamp_s": 1501.0}, {"text": "Thank you.", "timestamp": "00:25:04,215", "timestamp_s": 1504.0}, {"text": "Have a nice day.", "timestamp": "00:25:05,325", "timestamp_s": 1505.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '85k01nwkN5s',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Aggressive LLMs Optimization: Making Them Work on Tiny Devices
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Discover how to shrink GPT‑2 for ultra‑weak hardware without sacrificing performance! We reveal how pruning, quantization, and fine‑tuning can unlock big large language model (LLM) power in tiny form.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/ml2025_Max_Navrotsky.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,360'); seek(0.0)">
              Hello everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:01,290'); seek(1.0)">
              My name is Max, and today we're gonna talk about the aggressive
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:03,960'); seek(3.0)">
              optimization of large scale language models in order to make sure that we
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:08,580'); seek(8.0)">
              can make them work on tiny devices.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:11,670'); seek(11.0)">
              So let's start with a few words about us, me, myself, I'm Max Roski.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:15,750'); seek(15.0)">
              I'm senior software engineer VGS.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:18,610'); seek(18.0)">
              While my cos speaker today is Alexander Gev, the professor of software engineer
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:23,035'); seek(23.0)">
              at Lud National Technical University.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:25,255'); seek(25.0)">
              Also shout out to my.
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:27,100'); seek(27.0)">
              Why that helped me arrange this beautiful presentation here.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:29,950'); seek(29.0)">
              So yeah, my thanks.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:31,720'); seek(31.0)">
              Okay, let's start from the challenge.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:33,160'); seek(33.0)">
              Why actually do we need optimize those LLMs for big devices By today's standards
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:38,780'); seek(38.0)">
              the all new large scale variations of those models actually require
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:43,100'); seek(43.0)">
              significant competition resources, which may result, as you may guessed
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:47,059'); seek(47.0)">
              in, overlooking the possibility of their practical deployment of low end resource
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:51,559'); seek(51.0)">
              constrained devices, which may include.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:53,749'); seek(53.0)">
              Field operations, offline systems, and better device and such.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:00:57,960'); seek(57.0)">
              Our resource goal today is to find out whether the aggressive model optimization
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:02,520'); seek(62.0)">
              techniques such as architecture streaming, pruning quantization, can
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:06,630'); seek(66.0)">
              enable the LMS to operate efficiently under the extreme hardware constraints.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:12,550'); seek(72.0)">
              So as you may guess, our demonstration approach will be.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:16,485'); seek(76.0)">
              To use practical task in order to evaluate our optimization strategy.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:21,385'); seek(81.0)">
              The task will be, we'll try to fine tune and use our model to
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:26,515'); seek(86.0)">
              generate ISO compliant software requirements basically without it.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:31,495'); seek(91.0)">
              Not any product can start properly and finish not only software.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:36,125'); seek(96.0)">
              We thought of it as a great task to evaluate the, and measure the trade
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:41,275'); seek(101.0)">
              offs between model compression, resource consumption, and output stability.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:47,045'); seek(107.0)">
              Alright, so before we start optimize pretty much anything else, we need to
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:51,605'); seek(111.0)">
              find out which model will suit the best.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:54,335'); seek(114.0)">
              Beside of the different alternatives there, we have been looking on the model
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:59,015'); seek(119.0)">
              that A is open source B is not already compressed not already compressed, not
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:08,265'); seek(128.0)">
              any techniques has been applied to it.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:10,245'); seek(130.0)">
              So we need something that is kinda blank sheet, but already with a small size.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:16,605'); seek(136.0)">
              So as you may guess from all the alternatives we stopped on GPT two.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:21,485'); seek(141.0)">
              Why as I mentioned before, it's open source so we can play around as
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:26,205'); seek(146.0)">
              much as we want without encountering licensing or API limitations.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:29,745'); seek(149.0)">
              Second is relatively lightweight, both on parameter size with
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:33,885'); seek(153.0)">
              117 million parameters.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:36,375'); seek(156.0)">
              Oh, and by the role model size, it's only 500 megabytes which is
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:42,375'); seek(162.0)">
              not that much as you may guess.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:44,454'); seek(164.0)">
              Critically also that we have been looking for the GP D two.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:47,995'); seek(167.0)">
              Is really great at generative possibilities despite the fact
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:53,524'); seek(173.0)">
              that it's buzz gen and it had been released in two 29, 20 19.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:58,385'); seek(178.0)">
              It's actually really good at producing coherent, dramatically sound.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:02,255'); seek(182.0)">
              The does aligned outputs, so it's actually very good, real solid for fine tuning
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:08,515'); seek(188.0)">
              for speci, specifical demands domains.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:11,620'); seek(191.0)">
              And finally as a bonus point, pretty much it's actually have a transparent
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:16,979'); seek(196.0)">
              and well-documented architecture, which allows us, allowed us to dive
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:22,999'); seek(202.0)">
              deep into finding out the limitations of those optimization techniques.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:28,249'); seek(208.0)">
              So it was actually great.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:30,389'); seek(210.0)">
              So to sum up, if we had only one model to carry with us into forest
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:34,559'); seek(214.0)">
              on an old laptop, it'll be GPT two.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:38,079'); seek(218.0)">
              Let's start with the plan.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:39,249'); seek(219.0)">
              So it'll be really simple one.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:41,589'); seek(221.0)">
              First of all, we'll go.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:42,669'); seek(222.0)">
              We are going to cover up the theory, then the practical results and conclusion.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:48,609'); seek(228.0)">
              So let's start with theory.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:51,749'); seek(231.0)">
              First of all, we are going to look for.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:55,094'); seek(235.0)">
              It's a student model concept.
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:56,594'); seek(236.0)">
              The core idea basically student model is a instance of the basic model
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:03,084'); seek(243.0)">
              by, but the difference that you can play around as much as you want.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:06,984'); seek(246.0)">
              So basically you can screw it up.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:09,204'); seek(249.0)">
              Maybe you will need to redo the things, but it won't affect the original.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:13,329'); seek(253.0)">
              So consider this something like a clone, but you can work with as much as you want.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:20,899'); seek(260.0)">
              So yeah, that's pretty much it.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:24,469'); seek(264.0)">
              Metrics by which we are going to measure the success.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:28,099'); seek(268.0)">
              It's four of them.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:29,419'); seek(269.0)">
              First of all, perplexity, the model accuracy, whether can
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:33,109'); seek(273.0)">
              it output things correctly.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:35,389'); seek(275.0)">
              CPU memory usage, as you may guess, it will be really critical for measuring
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:40,669'); seek(280.0)">
              success for like of performance on low resource, low end devices.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:45,984'); seek(285.0)">
              Inter interference speed, faster response time, pretty straightforward
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:50,004'); seek(290.0)">
              and model size basically.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:51,864'); seek(291.0)">
              The smaller, the better general pattern here, as you noticed is
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:55,744'); seek(295.0)">
              the smaller better, the smaller faster equals better usually.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:02,390'); seek(302.0)">
              Let's start with defining what we actually define as aggressive
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:05,930'); seek(305.0)">
              methods and non-aggressive methods.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:08,930'); seek(308.0)">
              Let's start with non aggressive methods, because there are really
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:12,109'); seek(312.0)">
              only one that we can specify today is a knowledge distillation.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:16,204'); seek(316.0)">
              Is the technique when student mimics teacher tissue model closely, like without
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:22,594'); seek(322.0)">
              any changes at all to architecture.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:24,844'); seek(324.0)">
              While aggressive methods, as you may guess, is those methods there
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:28,544'); seek(328.0)">
              will interfere with model like architecture layers, count and stuff.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:34,784'); seek(334.0)">
              So there are three of them.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:36,194'); seek(336.0)">
              Architecture, treatment they will have, like this technique is all
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:40,425'); seek(340.0)">
              around reducing layers in neuro count.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:43,170'); seek(343.0)">
              Pruning, remove less important parameters in weights and ization.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:48,420'); seek(348.0)">
              Basically changing the AC accuracy of the weights from like fourth
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:52,410'); seek(352.0)">
              float 42 into integer eight.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:55,570'); seek(355.0)">
              Standard.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:57,085'); seek(357.0)">
              Okay, cool.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:57,775'); seek(357.0)">
              So let's start with covering up the basics of the each optimization technique.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:02,905'); seek(362.0)">
              So with architecture, treatment, the main concept here, if it's
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:06,085'); seek(366.0)">
              too big, just make it smaller.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:08,465'); seek(368.0)">
              So I would say, you should imagine this, our model as a building.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:12,365'); seek(372.0)">
              So like every floor and room can be considered as layer and neurons here.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:18,545'); seek(378.0)">
              And pretty much we just, in those technique, we just remove
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:22,175'); seek(382.0)">
              unnecessary layers and neurons.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:25,295'); seek(385.0)">
              That's it.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:26,685'); seek(386.0)">
              With layers, we, when we remove layers, we just reduce the number
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:29,955'); seek(389.0)">
              of protesting stages in the model.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:32,565'); seek(392.0)">
              While with neurons, we decrease the number of computational euros per layer, right?
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:38,025'); seek(398.0)">
              So also we have a glossary on the bottom of the slides.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:41,305'); seek(401.0)">
              So feel free to pause the window and check it out, like the better
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:44,785'); seek(404.0)">
              definition of layer in euro.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:46,975'); seek(406.0)">
              So that's pretty much it.
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:48,655'); seek(408.0)">
              Pruning.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:49,555'); seek(409.0)">
              If it's not important, just cut it off.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:51,995'); seek(411.0)">
              I think we can imagine for this purpose, we can imagine a model like
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:06:55,655'); seek(415.0)">
              a tree when every branch is connection between neurons and even each branch has
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:01,735'); seek(421.0)">
              leaves, which is parameters and weights.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:04,285'); seek(424.0)">
              So with pruning, we can actually decide which weights we can
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:09,265'); seek(429.0)">
              disable and just not use it all.
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:12,595'); seek(432.0)">
              Interesting thing here that while we disabling and turning off some
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:16,995'); seek(436.0)">
              parameters and weights, it also can.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:19,605'); seek(439.0)">
              Like indirectly affect the neurons because when you delete and turn off some of the
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:25,915'); seek(445.0)">
              neurons some of the weights in parameters, it may just turn off some neurons.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:32,055'); seek(452.0)">
              So it's really interesting here and here.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:34,395'); seek(454.0)">
              Quantization.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:35,325'); seek(455.0)">
              Basically the main concept here is you may see heat precision isn't critical.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:39,315'); seek(459.0)">
              We do not need use heavy tools.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:42,015'); seek(462.0)">
              Basically speaking we are turning off.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:45,135'); seek(465.0)">
              Like changing the basic float 32 standard and like into integer eight.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:51,955'); seek(471.0)">
              So it will be less, our model will be less precise, but it'll
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:56,365'); seek(476.0)">
              be great in like CPU performance and much more easier to work with.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:01,645'); seek(481.0)">
              Yeah.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:01,914'); seek(481.0)">
              So we just make sure that our weights are, turned, turned
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:06,075'); seek(486.0)">
              into smaller, lightweight ones.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:08,325'); seek(488.0)">
              Those effects, as you may see on the graph, it affects only
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:11,445'); seek(491.0)">
              weights and parameters here.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:15,255'); seek(495.0)">
              And for the non-aggressive optimization methods here
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:18,775'); seek(498.0)">
              distillation can be considered as a mutation of the teacher model here.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:24,475'); seek(504.0)">
              So it's the student that copies from the experienced teacher.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:27,955'); seek(507.0)">
              Very important note here.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:29,815'); seek(509.0)">
              This thing, this method is non aggressive because it does not
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:33,865'); seek(513.0)">
              interfere with model architecture.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:37,775'); seek(517.0)">
              Therefore, we do not need to be worried about performance de degradation here.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:43,535'); seek(523.0)">
              Good.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:46,625'); seek(526.0)">
              Also the most important know that we want to live here is that.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:51,520'); seek(531.0)">
              Distillation is really, will work on it.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:54,400'); seek(534.0)">
              It'll work good if only the student model has not anything
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:08:59,410'); seek(539.0)">
              changed in the architecture.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:00,760'); seek(540.0)">
              So the, both the student model and teacher one should be pretty much the same.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:07,510'); seek(547.0)">
              And here, as you may see in the graph it's not affecting anything
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:11,150'); seek(551.0)">
              in the architecture, but it just learns the outputs and the
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:15,140'); seek(555.0)">
              weights from the tissue once.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:16,430'); seek(556.0)">
              So it's all in once.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:19,285'); seek(559.0)">
              Okay, cool.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:19,735'); seek(559.0)">
              So as you, we noticed those three aggressive methods, architecture,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:23,805'); seek(563.0)">
              dreaming, proving quantization are playing with models,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:30,075'); seek(570.0)">
              architecture in different way.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:32,295'); seek(572.0)">
              One in, for instance, for archite architecture dreaming.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:35,625'); seek(575.0)">
              We just remove some of the layers while pruning, for instance, just
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:39,945'); seek(579.0)">
              remove not layers, but weights.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:42,315'); seek(582.0)">
              And quantization just reducing the accuracy of those weights
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:45,795'); seek(585.0)">
              but not removing them.
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:46,905'); seek(586.0)">
              So they're really the same, but in different way.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:50,865'); seek(590.0)">
              Alright, so yeah, that's the summary for you if you want to
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:53,715'); seek(593.0)">
              pass out video and check it out.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:09:56,355'); seek(596.0)">
              So let's start with part two, practical research.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:09:59,815'); seek(599.0)">
              As you may guessed, we already have an order of experiments here.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:03,145'); seek(603.0)">
              So first of all we will our, like this part will switch in several steps.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:08,635'); seek(608.0)">
              First one, we are gonna fine tune our model because without fine tuning,
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:11,725'); seek(611.0)">
              it does not make much many sense.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:13,965'); seek(613.0)">
              And therefore we'll continue with architecture, treatment, distillation,
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:17,865'); seek(617.0)">
              pruning, quantization, and then we're gonna combine those methods.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:21,675'); seek(621.0)">
              We are gonna explain later why we do this methods in this specific order.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:26,545'); seek(626.0)">
              So let's start.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:28,235'); seek(628.0)">
              But before we start, we need to get the basic benchmark of
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:32,485'); seek(632.0)">
              training the base role, DPT two.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:35,785'); seek(635.0)">
              So it's pre-trained.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:37,390'); seek(637.0)">
              Non-specialized and it'll struggle with any task specific like structure there.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:43,190'); seek(643.0)">
              Those, some metrics on the left that we specify before, perplexity usage, memory
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:47,210'); seek(647.0)">
              usage, inference, speed, and model size.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:10:49,520'); seek(649.0)">
              And therefore they are prompt results.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:10:52,100'); seek(652.0)">
              So you can see like visually what is going on, as you may see on the output.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:10:57,770'); seek(657.0)">
              It's not hallucinating, I would say, but it's not that semantically.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:01,940'); seek(661.0)">
              Correct.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:03,330'); seek(663.0)">
              Which may result in, the possibility and the requirement of actually fine
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:06,690'); seek(666.0)">
              tuning our model to do specific tasks like iso requirements generation.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:14,500'); seek(674.0)">
              Okay.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:14,970'); seek(674.0)">
              I think the first step after comparing with the role GPT two we need to
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:19,900'); seek(679.0)">
              fine tune the model basically.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:22,630'); seek(682.0)">
              I'm sorry.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:23,560'); seek(683.0)">
              Basically this model will, there will no optimization applied first.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:28,150'); seek(688.0)">
              Our model is fine tuned towards ISO compliance software requirements
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:31,600'); seek(691.0)">
              that I set and it'll useful GPTT architecture and it'll the
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:36,190'); seek(696.0)">
              reference point for our comparisons.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:37,780'); seek(697.0)">
              As you may see, after we fine tune it to our, to to our specific task,
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:41,340'); seek(701.0)">
              the output is much more better.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:11:43,320'); seek(703.0)">
              So that's I would say reference point.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:11:47,150'); seek(707.0)">
              Yeah.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:11:47,660'); seek(707.0)">
              So with fine tune, with fine tuning model, everything got better there.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:11:51,625'); seek(711.0)">
              Only perplexity got a little bit worse.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:11:54,565'); seek(714.0)">
              I would say perplexity value starting from one up to one and five are really
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:00,175'); seek(720.0)">
              solid, and we'll provide you the quality of the model that we're, that you will
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:06,145'); seek(726.0)">
              see that is good visually at least.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:09,415'); seek(729.0)">
              Okay, so let's start with the first step.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:11,155'); seek(731.0)">
              I think the most mandatory one, architecture dreaming.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:14,055'); seek(734.0)">
              In our practical research, we remote, we removed half of the GPT two layers.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:18,855'); seek(738.0)">
              And reduce hidden size.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:20,535'); seek(740.0)">
              Basically, we shifted from 12 layers to six from like 768 dimensions
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:28,425'); seek(748.0)">
              to 384, which means same inputs, but just lighter architecture
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:34,935'); seek(754.0)">
              and fighter and faster execution.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:37,185'); seek(757.0)">
              You may also ask about how did we pick which layers to trim?
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:40,895'); seek(760.0)">
              The strategy there was actually really simple one.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:44,075'); seek(764.0)">
              We just removed layers symmetrically from center.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:12:46,725'); seek(766.0)">
              Which allows us to preserve bottom layers that are responsible for basic
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:12:50,565'); seek(770.0)">
              syntax and token level understanding.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:12:52,485'); seek(772.0)">
              And also we preserve top layers, which are for higher level structure, for
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:12:58,275'); seek(778.0)">
              context, you know what I'm saying?
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:01,375'); seek(781.0)">
              Basically speaking, this allow allowed us to maintain both low level
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:04,825'); seek(784.0)">
              and high level processing there.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:06,625'); seek(786.0)">
              Awesome.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:08,455'); seek(788.0)">
              So let's compare the performance here.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:12,055'); seek(792.0)">
              As you may see, perplexity gone a little bit worse.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:15,050'); seek(795.0)">
              Because like it's gone.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:16,250'); seek(796.0)">
              Not that accurate, but as you may see, the output to the prompt is really solid.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:23,180'); seek(803.0)">
              It's pretty much the same.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:24,260'); seek(804.0)">
              It hasn't changed.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:25,460'); seek(805.0)">
              But here we also notice here that the memory usage actually increased.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:30,500'); seek(810.0)">
              Why?
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:13:30,940'); seek(810.0)">
              When we.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:13:31,795'); seek(811.0)">
              We reduce our CP usage.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:13:34,255'); seek(814.0)">
              Somebody has to pay and this somebody is wrong.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:13:38,455'); seek(818.0)">
              Basically speaking.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:13:39,515'); seek(819.0)">
              We with optimizations like quantization layer treatment, we reduce processing
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:13:44,315'); seek(824.0)">
              time, but they will compensate in tensor sizes, caching, parallel processing,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:13:51,095'); seek(831.0)">
              which will increase their wrong memory.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:13:55,035'); seek(835.0)">
              Why this matters.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:13:56,770'); seek(836.0)">
              CPU time equals the energy cost on battery powered by the devices.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:02,080'); seek(842.0)">
              And most of the time CPU U is the biggest power draw.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:05,440'); seek(845.0)">
              While RO is something that we can neglect and it's generally
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:10,920'); seek(850.0)">
              more available, but not limited.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:13,790'); seek(853.0)">
              So it's actually, we consider it as a cheap to access.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:17,565'); seek(857.0)">
              But a little bit limited on the old laptops and microcontrollers,
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:20,895'); seek(860.0)">
              which is, in our use case.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:22,425'); seek(862.0)">
              It's not that problematic as we more lean towards providing the proper experience
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:14:29,865'); seek(869.0)">
              with CPU in order to make sure that they can work on embedded devices.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:14:35,655'); seek(875.0)">
              Yeah, so in this graph, it's pretty much the summary of all the things
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:14:38,985'); seek(878.0)">
              that we talked before with the graphs.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:14:40,965'); seek(880.0)">
              As you as you may see on the x. Axis we have starting from the Rob GT two and at
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:14:46,210'); seek(886.0)">
              the end you will, we will compare also combine sensors there, the RAM users
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:14:50,170'); seek(890.0)">
              there changed by almost 200 megabytes.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:14:52,990'); seek(892.0)">
              Not that big, but something that we have to consider on.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:14:55,570'); seek(895.0)">
              Okay, let's continue.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:14:57,550'); seek(897.0)">
              You may also ask, but why don't we apply distillation
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:02,020'); seek(902.0)">
              and therefore it's break point.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:05,200'); seek(905.0)">
              The thing is that we student modeled it's trained.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:08,630'); seek(908.0)">
              In this process, the student model trained to mimic, make a bigger teacher model.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:12,860'); seek(912.0)">
              But after we chopped hard, the student model it just too small
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:17,690'); seek(917.0)">
              to understand the teacher.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:19,700'); seek(919.0)">
              It means that student just can does not have enough layers to understand teacher
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:25,540'); seek(925.0)">
              outputs, which means that our student model will try to compensate it and it'll
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:15:30,920'); seek(930.0)">
              result in hallucinations and repetitions.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:15:36,555'); seek(936.0)">
              Yeah, this graph pretty much basically represents the effect that
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:15:40,695'); seek(940.0)">
              we are trying to represent here.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:15:42,495'); seek(942.0)">
              While at some point, student model will just stop, basically understand
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:15:48,075'); seek(948.0)">
              what model tries to learn and to teach.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:15:52,515'); seek(952.0)">
              So it'll do the only thing it's possible to do with architecture when LLMs.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:15:57,750'); seek(957.0)">
              Hallucination and repetition.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:15:59,130'); seek(959.0)">
              As we mentioned before.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:00,690'); seek(960.0)">
              As a result, we finishing critical failure point and here there's
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:04,490'); seek(964.0)">
              nothing we can do with distillation and we need to drop it off.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:09,710'); seek(969.0)">
              Yeah.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:10,280'); seek(970.0)">
              As you may see with a performance snapshot for distillation, the
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:14,260'); seek(974.0)">
              output is straight up non-usable with propensity well is for it's.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:22,140'); seek(982.0)">
              As you may see by output, it's not usable.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:25,140'); seek(985.0)">
              So yeah, we just skip it all together.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:16:27,690'); seek(987.0)">
              That's why it's called non aggressive, as you may see.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:16:30,830'); seek(990.0)">
              As a quick conclusion here, non aggressive methods are not working
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:16:33,980'); seek(993.0)">
              right with aggressive ones.
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:16:35,510'); seek(995.0)">
              Okay?
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:16:37,220'); seek(997.0)">
              Yeah.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:16:37,610'); seek(997.0)">
              So let's continue with pruning.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:16:39,860'); seek(999.0)">
              With pruning.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:16:40,430'); seek(1000.0)">
              As we mentioned before, the theoretical part, really more parameters
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:16:43,790'); seek(1003.0)">
              that have low or no contribution.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:16:46,310'); seek(1006.0)">
              How do we choose those weights?
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:16:48,260'); seek(1008.0)">
              We just rank all weights by getting their absolute value,
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:16:52,230'); seek(1012.0)">
              then just remove the one one.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:16:53,760'); seek(1013.0)">
              Yeah, it's pretty much simple.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:16:55,290'); seek(1015.0)">
              It's not that hard.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:16:57,050'); seek(1017.0)">
              We just muting the quietest voices in the nose, noisy room, and why it's
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:01,490'); seek(1021.0)">
              working, because many weights are in large, more are close to zero,
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:17:05,660'); seek(1025.0)">
              which allows them to balance out.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:17:07,800'); seek(1027.0)">
              Some like context and for the larger models, it'll be really great in
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:17:12,660'); seek(1032.0)">
              order to have general context.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:17:14,580'); seek(1034.0)">
              But in our use case, the le less memory, faster competition, but only slightly.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:17:21,070'); seek(1041.0)">
              Yeah, from the benchmark here, perplexity here is pretty much the
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:17:24,460'); seek(1044.0)">
              same as for architecture training.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:17:26,330'); seek(1046.0)">
              But the memory, use it really hard.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:17:28,020'); seek(1048.0)">
              Like going really like big, I would say as you may see it sometimes it
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:17:33,870'); seek(1053.0)">
              hallucinates and just does not do anything, but no worries will get better
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:17:39,140'); seek(1059.0)">
              results after we combine those methods.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:17:42,110'); seek(1062.0)">
              Quantization quantization, as we said before in theoretical part, when we
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:17:46,780'); seek(1066.0)">
              convert them, model weights, accuracy from flow through the two into enter eight.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:17:52,280'); seek(1072.0)">
              We make sure, like we don't delete anything but just make the
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:17:56,120'); seek(1076.0)">
              model a little bit less precise.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:17:58,100'); seek(1078.0)">
              So here we'll get a huge benefit of less CPU load and basically
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:04,490'); seek(1084.0)">
              no work actual changes needed.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:18:05,840'); seek(1085.0)">
              So pretty much no performance degradation there.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:18:10,490'); seek(1090.0)">
              Okay, so when we go to performance, you will see that the memory
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:18:14,390'); seek(1094.0)">
              usage there is pretty much almost non didn't change at all.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:18:19,720'); seek(1099.0)">
              While the model size is produced drastically with the CPU usage at 12%,
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:18:25,870'); seek(1105.0)">
              12 and a half percent, while basic RGBT model will occupy like 45% of your
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:18:31,660'); seek(1111.0)">
              like low end device, which is huge.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:18:34,330'); seek(1114.0)">
              And you'll see, and you'll see you later see by, see it by yourself, by at the end
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:18:39,760'); seek(1119.0)">
              of the talk while we get the conclusion.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:18:42,730'); seek(1122.0)">
              So we are coming up to the combined optimization here and, in those
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:18:47,430'); seek(1127.0)">
              optimization methods, we are combining treatment, pruning and quantization.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:18:51,060'); seek(1131.0)">
              So at the end, we'll have fine tuned model, fine tuned, GPT model for one,
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:18:56,760'); seek(1136.0)">
              task, three model to six layers, prune 40% of smaller weights, and we'll quantize.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:04,920'); seek(1144.0)">
              Two in eight from flow through the two for CPU Efficiency.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:09,150'); seek(1149.0)">
              As as you may see, we don't use distillation at all because it just
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:12,530'); seek(1152.0)">
              does not stack neither work with aggressive methods combined about in
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:17,440'); seek(1157.0)">
              this case, there are no methods that will allow distillation work with
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:19:20,590'); seek(1160.0)">
              aggressive methods as architecture.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:19:22,780'); seek(1162.0)">
              Defense is too drastic.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:19:25,045'); seek(1165.0)">
              Okay, so with the performance snapshot of our best combined methods here,
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:19:29,335'); seek(1169.0)">
              perplexity changed by really little bit.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:19:31,475'); seek(1171.0)">
              While CPU usage there got almost twice as small while memory usage,
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:19:36,405'); seek(1176.0)">
              as you may see, is almost like 200 megabytes higher with inference
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:19:41,335'); seek(1181.0)">
              speed really perfect, almost newer.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:19:43,585'); seek(1183.0)">
              Perfect, I would say.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:19:44,605'); seek(1184.0)">
              And the model size shrunk into like almost five times of the original.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:19:50,365'); seek(1190.0)">
              Yeah, it's really perfect.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:19:51,835'); seek(1191.0)">
              One.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:19:52,520'); seek(1192.0)">
              So let's see how it's gonna represent in different metrics.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:19:57,410'); seek(1197.0)">
              So we'll we can see here by using the company combined optimization
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:02,020'); seek(1202.0)">
              methods those, our students, our student model will reduce CPU load by
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:06,650'); seek(1206.0)">
              almost a half compared to row G PT two
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:12,480'); seek(1212.0)">
              which makes it significantly more suitable for battery powered CPU only
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:20:15,870'); seek(1215.0)">
              devices where energy is critical.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:20:19,680'); seek(1219.0)">
              Basically it means less CPU, faster response times, lower energy costs,
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:20:24,180'); seek(1224.0)">
              everyone's happy memory usage.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:20:27,080'); seek(1227.0)">
              As you may see, the change there is not that big, but it's a kind of trade
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:20:32,040'); seek(1232.0)">
              off that we pay for lower CPU costs.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:20:35,730'); seek(1235.0)">
              It's acceptable, especially in Muslim low end laptops and body boards.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:20:40,200'); seek(1240.0)">
              But this, there is the thing that we should consider of a memory usage.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:20:44,640'); seek(1244.0)">
              This is the thing that pays off for the all optimizations.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:20:48,705'); seek(1248.0)">
              Perplexity actually remained the same.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:20:50,925'); seek(1250.0)">
              So we were really happy with the results.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:20:53,595'); seek(1253.0)">
              So it means at the end we can conclude that the optimization, the combining
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:20:59,415'); seek(1259.0)">
              optimization techniques are not equal degradation if fine tuning done right,
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:06,285'); seek(1266.0)">
              model size as you may see it shrink almost in five times of the original,
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:11,015'); seek(1271.0)">
              basically smaller model, same brain.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:14,525'); seek(1274.0)">
              We are going to part three conclusions.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:16,985'); seek(1276.0)">
              So you might also thought if their methods are so good, why should
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:20,695'); seek(1280.0)">
              we like not always use them?
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:21:23,305'); seek(1283.0)">
              It me, like basically we omitted the fact that it's work perfectly
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:21:28,705'); seek(1288.0)">
              only on fine tuned models.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:21:31,645'); seek(1291.0)">
              So actually why fine tuning map like fine tuning technique matters.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:21:36,200'); seek(1296.0)">
              Fine tuning aligns the model to a single atomic task.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:21:39,410'); seek(1299.0)">
              Therefore, that specific focus make the model resistant to aggressive compression
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:21:46,230'); seek(1306.0)">
              While out of the box models are kinda generalist and they're like not good in
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:21:50,700'); seek(1310.0)">
              anything else, like jack of all trades.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:21:52,710'); seek(1312.0)">
              And they basically, they're trying to do everything and they will be really
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:21:56,730'); seek(1316.0)">
              fragile towards like applying any of them.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:00,540'); seek(1320.0)">
              Yeah.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:02,220'); seek(1322.0)">
              So with the League of Mind, Alexandra, we defined definition
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:07,490'); seek(1327.0)">
              of Reist model resistance.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:09,410'); seek(1329.0)">
              It means that it defines how well model maintains output quality
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:14,390'); seek(1334.0)">
              after aggressive compression.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:16,420'); seek(1336.0)">
              So by high resistance, we define fine tuned models for one clear
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:20,920'); seek(1340.0)">
              task, which means strong internal signal, the translation to low
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:22:25,260'); seek(1345.0)">
              dependency on full architecture.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:22:27,675'); seek(1347.0)">
              When quality drops really slowly, even heavy pruning on quantization and for
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:22:32,865'); seek(1352.0)">
              the lower resistance, we define this and the, as the general purpose model
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:22:37,365'); seek(1357.0)">
              that has like many overlapping skills and even the smallest optimization there
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:22:43,135'); seek(1363.0)">
              would result into breaking the visual results and the performance metrics.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:22:49,855'); seek(1369.0)">
              Also, we have a graph to we also applied the same methods to the raw
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:22:53,625'); seek(1373.0)">
              G PT two, and the results were not.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:22:56,625'); seek(1376.0)">
              Usable at all.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:22:58,125'); seek(1378.0)">
              So as you may see for the fine tuned models it's almost changed
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:02,435'); seek(1382.0)">
              like it hasn't changed at all.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:04,235'); seek(1384.0)">
              While for BT two it changed really drastically.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:07,175'); seek(1387.0)">
              So as you may see, the re resistance team here is really important.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:11,405'); seek(1391.0)">
              So fine tuning models here is really important by as
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:15,835'); seek(1395.0)">
              treatment stable perplexity.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:18,190'); seek(1398.0)">
              Almost grow slowly or not growing at all while general purpose models break
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:23:22,780'); seek(1402.0)">
              fast and perpetuate their skyrockets.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:23:26,480'); seek(1406.0)">
              So it's, it is great.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:23:27,530'); seek(1407.0)">
              While fine tuning mon, like fine tuning models allows us to focus on
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:23:31,460'); seek(1411.0)">
              the single task which is kinda reducing general noise and general models
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:23:37,200'); seek(1417.0)">
              in the controversy are too broad.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:23:39,090'); seek(1419.0)">
              Even small cuts will disrupt everything.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:23:42,090'); seek(1422.0)">
              So basically speaking optimizations.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:23:44,520'); seek(1424.0)">
              Combining the optimization methods work best, but the model
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:23:47,670'); seek(1427.0)">
              knows what it's supposed to do.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:23:51,420'); seek(1431.0)">
              Yeah.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:23:53,310'); seek(1433.0)">
              Without fine tuning, pruning will break meaning of general model.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:23:57,510'); seek(1437.0)">
              Quantization will introduce noise, which also affect the
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:01,950'); seek(1441.0)">
              visual represe of the output.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:03,750'); seek(1443.0)">
              And trimming also deletes the clear within the path.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:07,240'); seek(1447.0)">
              So at the end with fine tuning, everything stays coherent even.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:11,500'); seek(1451.0)">
              And 75% of compression as you may see, basically fine tuning
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:16,150'); seek(1456.0)">
              isn't a just an extra step.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:24:17,830'); seek(1457.0)">
              It's what makes optimization possible.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:24:21,390'); seek(1461.0)">
              So yeah, that's pretty much finishing slide with the final takeaways.
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:24:24,510'); seek(1464.0)">
              First of all, fine tuning is the true enabler.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:24:26,940'); seek(1466.0)">
              It makes compression possible without the collapse of the model
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:24:30,960'); seek(1470.0)">
              while we apply those techniques.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:24:33,150'); seek(1473.0)">
              Architecture driven reduces, depths and size brilliant
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:24:35,760'); seek(1475.0)">
              remotes, low impact weights.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:24:37,840'); seek(1477.0)">
              Quantization boosts CPU Efficiency while distillation fails when applied
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:24:42,310'); seek(1482.0)">
              to aggressively minimize students.
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:24:44,530'); seek(1484.0)">
              Resistance here is a key.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:24:46,630'); seek(1486.0)">
              Fine tune models resist degradation, far better than general models.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:24:50,605'); seek(1490.0)">
              So basically speaking, we didn't just shrink a model, we built
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:24:53,575'); seek(1493.0)">
              a focused, efficient specialist and fine tuning may possible.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:24:59,455'); seek(1499.0)">
              Thank you very much.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:00,705'); seek(1500.0)">
              It was my pleasure.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:01,665'); seek(1501.0)">
              Great pleasure to provide a talk here.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:25:04,215'); seek(1504.0)">
              Thank you.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:25:05,325'); seek(1505.0)">
              Have a nice day.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Max%20Navrotsky%20%26%20Oleksandr%20Gordieiev%20-%20Conf42%20Machine%20Learning%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Max%20Navrotsky%20%26%20Oleksandr%20Gordieiev%20-%20Conf42%20Machine%20Learning%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 132 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Max%20Navrotsky%20%26%20Oleksandr%20Gordieiev_ml.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Max Navrotsky
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Software Engineer @ VGS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/max-navrotsky/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Max Navrotsky's LinkedIn account" />
                  </a>
                  
                  
                </p>
                
                <!-- Author 2 -->
                <h2 class="me-2">
                  Oleksandr Gordieiev
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Professor at Software Engineering Department @ Lutsk National Technical University
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-8">
                  
                  <a href="https://www.linkedin.com/in/oleksandr-gordieiev-4b893716/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Oleksandr Gordieiev's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Max Navrotsky"
                  data-url="https://www.conf42.com/ml2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>