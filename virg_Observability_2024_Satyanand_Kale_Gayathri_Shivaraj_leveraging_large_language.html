<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Leveraging Large Language Models for Advanced AI Applications: A Comprehensive Guide</title>
    <meta name="description" content="Observe the unseen, go beyond the code!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Satyanand%20Kale%20%26%20Gayathri%20Shivaraj_obs.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Leveraging Large Language Models for Advanced AI Applications: A Comprehensive Guide | Conf42"/>
    <meta property="og:description" content="Unveil how Large Language Models (LLMs) like GPT and Turing NLG have transformed trademark identification, reducing audits by 80% and doubling productivity in content creation. Explore their impact across industries, with a 50% boost in material recovery and a 40% improvement in customer service."/>
    <meta property="og:url" content="https://conf42.com/Observability_2024_Satyanand_Kale_Gayathri_Shivaraj_leveraging_large_language"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/CE2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Chaos Engineering 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-02-20
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/ce2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #A8AC51;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Observability 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Observe the unseen, go beyond the code!
 -->
              <script>
                const event_date = new Date("2024-06-13T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-06-13T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "JiU525Fy1Fg"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "dXWedudioKM"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrC-PX2FgCC65tF4cYubwqxj" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone. I\u0027m Gayathri Shivraj and I\u0027m honored to be a speaker at the", "timestamp": "00:00:27,440", "timestamp_s": 27.0}, {"text": "Con 42. I\u0027m a senior program manager at Amazon.", "timestamp": "00:00:31,380", "timestamp_s": 31.0}, {"text": "In the fulfillment services, I primarily focus on", "timestamp": "00:00:34,956", "timestamp_s": 34.0}, {"text": "program and product excellence to provide best in class seller", "timestamp": "00:00:38,844", "timestamp_s": 38.0}, {"text": "experience by optimizing the storage and fulfillment capabilities.", "timestamp": "00:00:42,236", "timestamp_s": 42.0}, {"text": "Large language models are a big part of the products we build as we", "timestamp": "00:00:46,804", "timestamp_s": 46.0}, {"text": "deal with large datasets of seller communication across", "timestamp": "00:00:50,292", "timestamp_s": 50.0}, {"text": "different modalities worldwide.", "timestamp": "00:00:53,844", "timestamp_s": 53.0}, {"text": "Before we dive into the details, let\u0027s take a quick look at the agenda", "timestamp": "00:00:59,894", "timestamp_s": 59.0}, {"text": "for today\u0027s presentation. We have a lot of ground to cover,", "timestamp": "00:01:03,470", "timestamp_s": 63.0}, {"text": "and I want to ensure we have a structured approach to understanding how", "timestamp": "00:01:07,150", "timestamp_s": 67.0}, {"text": "large language models can be leveraged for advanced AI applications.", "timestamp": "00:01:11,118", "timestamp_s": 71.0}, {"text": "We will start with an introduction to large language models,", "timestamp": "00:01:16,134", "timestamp_s": 76.0}, {"text": "or LLMs. This section will provide a foundational", "timestamp": "00:01:19,510", "timestamp_s": 79.0}, {"text": "understanding of what LLMs are, their significance in the field of AI,", "timestamp": "00:01:22,862", "timestamp_s": 82.0}, {"text": "and why they have become so prominent in the recent years.", "timestamp": "00:01:27,392", "timestamp_s": 87.0}, {"text": "Next, we will dwell into the architecture of LLMs.", "timestamp": "00:01:31,424", "timestamp_s": 91.0}, {"text": "We will explore how these models are built, the underlying technologies", "timestamp": "00:01:35,328", "timestamp_s": 95.0}, {"text": "that power them, and the key components that make them effective at processing", "timestamp": "00:01:40,048", "timestamp_s": 100.0}, {"text": "and generating human like text.", "timestamp": "00:01:44,432", "timestamp_s": 104.0}, {"text": "Next, we will talk about methods for leveraging LLMs.", "timestamp": "00:01:47,544", "timestamp_s": 107.0}, {"text": "In this section, I will discuss how to use LLMs", "timestamp": "00:01:51,128", "timestamp_s": 111.0}, {"text": "effectively by leveraging APIs and interactive playgrounds.", "timestamp": "00:01:54,828", "timestamp_s": 114.0}, {"text": "I\u0027ll explain how to deploy these models for production use cases,", "timestamp": "00:01:59,364", "timestamp_s": 119.0}, {"text": "ensuring scalability and reliability.", "timestamp": "00:02:03,852", "timestamp_s": 123.0}, {"text": "Additionally, we will cover how to customize LLMs to", "timestamp": "00:02:06,924", "timestamp_s": 126.0}, {"text": "meet specific needs and how to deploy these customized versions,", "timestamp": "00:02:10,332", "timestamp_s": 130.0}, {"text": "and how to create and use effective prompts to get", "timestamp": "00:02:14,308", "timestamp_s": 134.0}, {"text": "the best results from LLMs.", "timestamp": "00:02:17,460", "timestamp_s": 137.0}, {"text": "Next limitations of using LLMs while LLMs", "timestamp": "00:02:20,704", "timestamp_s": 140.0}, {"text": "are powerful, they come with their own set of constraints and challenges.", "timestamp": "00:02:23,936", "timestamp_s": 143.0}, {"text": "We will cover the limitations, potential pitfalls, and ethical considerations", "timestamp": "00:02:28,264", "timestamp_s": 148.0}, {"text": "when deploying these models in real world scenarios.", "timestamp": "00:02:32,872", "timestamp_s": 152.0}, {"text": "And finally, with the real world success stories,", "timestamp": "00:02:36,344", "timestamp_s": 156.0}, {"text": "we will look at some of the real world success stories. I will", "timestamp": "00:02:39,568", "timestamp_s": 159.0}, {"text": "share case studies and examples of how organizations,", "timestamp": "00:02:43,232", "timestamp_s": 163.0}, {"text": "including Amazon, have successfully implemented LLMs", "timestamp": "00:02:46,960", "timestamp_s": 166.0}, {"text": "to solve complex problems, improve efficiency,", "timestamp": "00:02:50,700", "timestamp_s": 170.0}, {"text": "and enhance customer experiences.", "timestamp": "00:02:55,268", "timestamp_s": 175.0}, {"text": "Let\u0027s take a closer look at what LLMs are, their key", "timestamp": "00:03:00,764", "timestamp_s": 180.0}, {"text": "components, capabilities, and applications across various industries.", "timestamp": "00:03:04,108", "timestamp_s": 184.0}, {"text": "What are LLMs? Large language models are advanced", "timestamp": "00:03:08,964", "timestamp_s": 188.0}, {"text": "AI models trained on extensive datasets to understand", "timestamp": "00:03:12,636", "timestamp_s": 192.0}, {"text": "and generate human like language. These models are", "timestamp": "00:03:16,044", "timestamp_s": 196.0}, {"text": "designed to perform a wide range of language related tasks,", "timestamp": "00:03:19,754", "timestamp_s": 199.0}, {"text": "making them incredibly versatile and powerful tools in the", "timestamp": "00:03:23,186", "timestamp_s": 203.0}, {"text": "field of AI. The key components of", "timestamp": "00:03:26,578", "timestamp_s": 206.0}, {"text": "LLMs transformer architecture at", "timestamp": "00:03:29,962", "timestamp_s": 209.0}, {"text": "the heart of LLMs is the transformer architecture.", "timestamp": "00:03:33,458", "timestamp_s": 213.0}, {"text": "This architecture allows the model to handle long reach dependencies", "timestamp": "00:03:36,994", "timestamp_s": 216.0}, {"text": "in text, making it possible to generate coherent", "timestamp": "00:03:41,290", "timestamp_s": 221.0}, {"text": "and contextual relevant responses.", "timestamp": "00:03:44,458", "timestamp_s": 224.0}, {"text": "Pre trained parameters LLMs come with", "timestamp": "00:03:48,014", "timestamp_s": 228.0}, {"text": "millions, billions, and sometimes trillions of pre trained parameters.", "timestamp": "00:03:51,174", "timestamp_s": 231.0}, {"text": "These parameters are learned from vast amounts of text data,", "timestamp": "00:03:55,462", "timestamp_s": 235.0}, {"text": "enabling the model to understand language nuances", "timestamp": "00:03:58,966", "timestamp_s": 238.0}, {"text": "and context. Finally, fine tuning", "timestamp": "00:04:02,254", "timestamp_s": 242.0}, {"text": "after pre training, LLMs can be fine tuned on specific", "timestamp": "00:04:06,078", "timestamp_s": 246.0}, {"text": "data sets to adapt to particular tasks or domains.", "timestamp": "00:04:09,790", "timestamp_s": 249.0}, {"text": "This fine tuning process tailors the model\u0027s capabilities to", "timestamp": "00:04:13,350", "timestamp_s": 253.0}, {"text": "meet specific needs more effectively.", "timestamp": "00:04:16,900", "timestamp_s": 256.0}, {"text": "Capabilities of LLMs content generation and comprehensions", "timestamp": "00:04:21,404", "timestamp_s": 261.0}, {"text": "LLMs excel at text generation, allowing them to create human", "timestamp": "00:04:26,604", "timestamp_s": 266.0}, {"text": "like text based on given prompts. They can also perform question", "timestamp": "00:04:30,420", "timestamp_s": 270.0}, {"text": "answering, providing relevant and accurate responses to user queries.", "timestamp": "00:04:34,524", "timestamp_s": 274.0}, {"text": "Language processing these models are capable", "timestamp": "00:04:39,504", "timestamp_s": 279.0}, {"text": "of language translation and summarization,", "timestamp": "00:04:42,576", "timestamp_s": 282.0}, {"text": "breaking down language barriers, and condensing information", "timestamp": "00:04:45,264", "timestamp_s": 285.0}, {"text": "into more digestible formats. Analysis and", "timestamp": "00:04:48,416", "timestamp_s": 288.0}, {"text": "recognition LLMs can analyze sentiments,", "timestamp": "00:04:52,424", "timestamp_s": 292.0}, {"text": "classify text, and recognize named entities,", "timestamp": "00:04:56,208", "timestamp_s": 296.0}, {"text": "making them useful for tasks such as sentiment analysis, text classification,", "timestamp": "00:04:59,632", "timestamp_s": 299.0}, {"text": "and named entity recognition applications", "timestamp": "00:05:04,896", "timestamp_s": 304.0}, {"text": "across industries. Software development in software", "timestamp": "00:05:08,972", "timestamp_s": 308.0}, {"text": "development, LLMs facilitate code summarization,", "timestamp": "00:05:12,716", "timestamp_s": 312.0}, {"text": "natural code search, and automated documentation generation.", "timestamp": "00:05:15,892", "timestamp_s": 315.0}, {"text": "These capabilities enhance developer productivity and", "timestamp": "00:05:20,324", "timestamp_s": 320.0}, {"text": "improve code understanding. Learning LLMs", "timestamp": "00:05:24,316", "timestamp_s": 324.0}, {"text": "can serve as education tools for learning programming languages.", "timestamp": "00:05:28,588", "timestamp_s": 328.0}, {"text": "They provide personalized feedback and tutoring to", "timestamp": "00:05:32,428", "timestamp_s": 332.0}, {"text": "aspiring developers and support the creation of attractive", "timestamp": "00:05:35,876", "timestamp_s": 335.0}, {"text": "coding exercises and adaptive learning platforms.", "timestamp": "00:05:39,466", "timestamp_s": 339.0}, {"text": "Thank you, Gayathri hello, I\u0027m Satya", "timestamp": "00:05:51,874", "timestamp_s": 351.0}, {"text": "and thank you for the opportunity to speak at Conf 42.", "timestamp": "00:05:55,482", "timestamp_s": 355.0}, {"text": "I am a senior engineer at Amazon in the brand protection organization.", "timestamp": "00:05:59,682", "timestamp_s": 359.0}, {"text": "In my role, my team and I build systems to protect the integrity of", "timestamp": "00:06:03,834", "timestamp_s": 363.0}, {"text": "our website by monitoring and preventing infringements and counterfeits.", "timestamp": "00:06:08,210", "timestamp_s": 368.0}, {"text": "We focus on preventing the misuse of IP of brands,", "timestamp": "00:06:14,234", "timestamp_s": 374.0}, {"text": "ensuring that our customers can shop with confidence in", "timestamp": "00:06:17,770", "timestamp_s": 377.0}, {"text": "building these systems. We leverage multiple LLMs and multimodal", "timestamp": "00:06:21,810", "timestamp_s": 381.0}, {"text": "LLMs to accomplish this goal.", "timestamp": "00:06:25,946", "timestamp_s": 385.0}, {"text": "Let\u0027s quickly delve into the architecture of transformers.", "timestamp": "00:06:30,194", "timestamp_s": 390.0}, {"text": "The transformers architecture represents a significant breakthrough", "timestamp": "00:06:43,534", "timestamp_s": 403.0}, {"text": "in the field of natural language processing and serves as a backbone", "timestamp": "00:06:47,438", "timestamp_s": 407.0}, {"text": "for many state of the art LLMs.", "timestamp": "00:06:50,894", "timestamp_s": 410.0}, {"text": "The transformer architecture is a game changer in the field of LLMs", "timestamp": "00:06:53,814", "timestamp_s": 413.0}, {"text": "because it overcomes the limitations of previous architectures like", "timestamp": "00:06:58,826", "timestamp_s": 418.0}, {"text": "RNN\u0027s and LSTM networks. The problem", "timestamp": "00:07:02,386", "timestamp_s": 422.0}, {"text": "with RNN\u0027s is they tend to forget important information from", "timestamp": "00:07:06,546", "timestamp_s": 426.0}, {"text": "earlier in a sequence because they process words", "timestamp": "00:07:10,682", "timestamp_s": 430.0}, {"text": "one by one, making them very slow and less accurate for very", "timestamp": "00:07:14,106", "timestamp_s": 434.0}, {"text": "long ticks. Lstms improve memory retention,", "timestamp": "00:07:18,506", "timestamp_s": 438.0}, {"text": "but they are still slow since they also handle words", "timestamp": "00:07:22,154", "timestamp_s": 442.0}, {"text": "sequentially. Some of the key components", "timestamp": "00:07:26,386", "timestamp_s": 446.0}, {"text": "of transformers architecture are self attention mechanism,", "timestamp": "00:07:30,282", "timestamp_s": 450.0}, {"text": "positional encodings, feed forward neural networks,", "timestamp": "00:07:34,298", "timestamp_s": 454.0}, {"text": "encoder decoder, multi head attention layer normalization,", "timestamp": "00:07:37,522", "timestamp_s": 457.0}, {"text": "and residual connections. The fundamental parts are", "timestamp": "00:07:41,170", "timestamp_s": 461.0}, {"text": "basically the encoder and the decoder. And it", "timestamp": "00:07:44,442", "timestamp_s": 464.0}, {"text": "all started when a paper was released in 2017", "timestamp": "00:07:47,770", "timestamp_s": 467.0}, {"text": "which had the title attention is all you need, and that\u0027s from", "timestamp": "00:07:51,874", "timestamp_s": 471.0}, {"text": "Washirani and others. And going", "timestamp": "00:07:55,386", "timestamp_s": 475.0}, {"text": "into the architecture of LLMs,", "timestamp": "00:08:00,242", "timestamp_s": 480.0}, {"text": "the self attention mechanism think of the self", "timestamp": "00:08:03,114", "timestamp_s": 483.0}, {"text": "attention mechanism as a way for the model to look at all the", "timestamp": "00:08:06,754", "timestamp_s": 486.0}, {"text": "words in a sentence and decide which ones are most important.", "timestamp": "00:08:10,378", "timestamp_s": 490.0}, {"text": "And for example, in the sentence", "timestamp": "00:08:14,594", "timestamp_s": 494.0}, {"text": "the cat sat on the mat. The word cat may pay more", "timestamp": "00:08:17,946", "timestamp_s": 497.0}, {"text": "attention to words sat and mat because", "timestamp": "00:08:22,282", "timestamp_s": 502.0}, {"text": "they are closely related.", "timestamp": "00:08:25,858", "timestamp_s": 505.0}, {"text": "Now, the second component of transformers", "timestamp": "00:08:28,314", "timestamp_s": 508.0}, {"text": "architecture, the positional encoding, is just because", "timestamp": "00:08:32,666", "timestamp_s": 512.0}, {"text": "the transformers don\u0027t naturally understand the words in which", "timestamp": "00:08:36,674", "timestamp_s": 516.0}, {"text": "they are ordered. Positional encoding helps the model know", "timestamp": "00:08:39,930", "timestamp_s": 519.0}, {"text": "the position of each word in the sentence. Then comes the", "timestamp": "00:08:43,658", "timestamp_s": 523.0}, {"text": "feed forward neural networks the", "timestamp": "00:08:47,248", "timestamp_s": 527.0}, {"text": "feed forward neural networks after applying the self", "timestamp": "00:08:51,360", "timestamp_s": 531.0}, {"text": "attention and positional encoding, the process tokens are", "timestamp": "00:08:54,672", "timestamp_s": 534.0}, {"text": "passed through the free forward neural networks within each layer", "timestamp": "00:08:58,480", "timestamp_s": 538.0}, {"text": "of the transformer. These feed forward neural networks", "timestamp": "00:09:01,800", "timestamp_s": 541.0}, {"text": "consist of multiple fully connected layers with nonlinear", "timestamp": "00:09:05,688", "timestamp_s": 545.0}, {"text": "activation functions, for example,", "timestamp": "00:09:09,072", "timestamp_s": 549.0}, {"text": "relu, and they enable the model to", "timestamp": "00:09:11,568", "timestamp_s": 551.0}, {"text": "learn complex patterns and representations from the input", "timestamp": "00:09:14,878", "timestamp_s": 554.0}, {"text": "data. Then the", "timestamp": "00:09:18,222", "timestamp_s": 558.0}, {"text": "next part is the encoder decoder. The encoder component", "timestamp": "00:09:22,534", "timestamp_s": 562.0}, {"text": "is basically responsible for translating the input sequence.", "timestamp": "00:09:26,462", "timestamp_s": 566.0}, {"text": "It processes the input sequence while the decoder generates the output", "timestamp": "00:09:30,670", "timestamp_s": 570.0}, {"text": "sequence.", "timestamp": "00:09:34,342", "timestamp_s": 574.0}, {"text": "The next one is the multi head.", "timestamp": "00:09:38,514", "timestamp_s": 578.0}, {"text": "Attention. To enhance the learning capabilities", "timestamp": "00:09:41,498", "timestamp_s": 581.0}, {"text": "of the LLM and capture different types of information,", "timestamp": "00:09:45,802", "timestamp_s": 585.0}, {"text": "transformers typically employ multi head attention mechanisms.", "timestamp": "00:09:48,994", "timestamp_s": 588.0}, {"text": "This feature allows the model to focus on certain parts of the input", "timestamp": "00:09:52,954", "timestamp_s": 592.0}, {"text": "sentence, simultaneously enhancing its understanding", "timestamp": "00:09:58,514", "timestamp_s": 598.0}, {"text": "of the text. For example, in a translation task,", "timestamp": "00:10:02,130", "timestamp_s": 602.0}, {"text": "one part of the model might focus on nouns, while the", "timestamp": "00:10:05,322", "timestamp_s": 605.0}, {"text": "other part focuses on verbs. These points of focus", "timestamp": "00:10:08,706", "timestamp_s": 608.0}, {"text": "can be referred as heads.", "timestamp": "00:10:13,794", "timestamp_s": 613.0}, {"text": "Then the last part of it is the layer normalization and residual connections", "timestamp": "00:10:18,234", "timestamp_s": 618.0}, {"text": "to stabilize the training process and ensure that", "timestamp": "00:10:22,594", "timestamp_s": 622.0}, {"text": "the model learns efficiently by", "timestamp": "00:10:26,218", "timestamp_s": 626.0}, {"text": "allowing information to flow smoothly between the layers.", "timestamp": "00:10:29,782", "timestamp_s": 629.0}, {"text": "This layer normalization technique is used to normalize the", "timestamp": "00:10:32,718", "timestamp_s": 632.0}, {"text": "weights.", "timestamp": "00:10:36,094", "timestamp_s": 636.0}, {"text": "Pre trained parameters are the numerical values associated", "timestamp": "00:10:45,094", "timestamp_s": 645.0}, {"text": "with the connections between neurons in the neural network architecture", "timestamp": "00:10:48,670", "timestamp_s": 648.0}, {"text": "of an LLM. These parameters represent the learned knowledge and", "timestamp": "00:10:52,302", "timestamp_s": 652.0}, {"text": "patterns extracted from the training data during the pre training", "timestamp": "00:10:56,542", "timestamp_s": 656.0}, {"text": "phase. As the model processes the input text,", "timestamp": "00:11:00,258", "timestamp_s": 660.0}, {"text": "it adjusts its parameters, that is, weights and biases,", "timestamp": "00:11:03,970", "timestamp_s": 663.0}, {"text": "to minimize a predefined loss function, such as cross entropy", "timestamp": "00:11:07,818", "timestamp_s": 667.0}, {"text": "loss, applied to the pre training objective,", "timestamp": "00:11:11,954", "timestamp_s": 671.0}, {"text": "the components of pre trained parameters are", "timestamp": "00:11:15,474", "timestamp_s": 675.0}, {"text": "word embeddings, parameters that represent the", "timestamp": "00:11:19,122", "timestamp_s": 679.0}, {"text": "initial numerical representations of word words or subwords", "timestamp": "00:11:22,362", "timestamp_s": 682.0}, {"text": "in the vocabulary. Word embeddings capture semantic", "timestamp": "00:11:25,892", "timestamp_s": 685.0}, {"text": "similarities between words based on their contextual usage in the", "timestamp": "00:11:29,604", "timestamp_s": 689.0}, {"text": "training data transformer layers parameters", "timestamp": "00:11:33,220", "timestamp_s": 693.0}, {"text": "associated with the multiple layers of the transformer architecture used in LLMs.", "timestamp": "00:11:37,044", "timestamp_s": 697.0}, {"text": "These layers include self attention mechanisms and feed forward", "timestamp": "00:11:41,764", "timestamp_s": 701.0}, {"text": "neural networks. Output layer parameters", "timestamp": "00:11:45,588", "timestamp_s": 705.0}, {"text": "parameters of the output layer, which map the final hidden", "timestamp": "00:11:49,684", "timestamp_s": 709.0}, {"text": "states of the model to predictions for specific tasks", "timestamp": "00:11:53,636", "timestamp_s": 713.0}, {"text": "such as classification and task generation.", "timestamp": "00:11:57,948", "timestamp_s": 717.0}, {"text": "Fine tuning is the process of adjusting the parameters", "timestamp": "00:12:03,684", "timestamp_s": 723.0}, {"text": "of a pre trained large language model to a specific task or", "timestamp": "00:12:07,308", "timestamp_s": 727.0}, {"text": "domain. Although pre trained language models possess vast", "timestamp": "00:12:10,836", "timestamp_s": 730.0}, {"text": "language knowledge, they lack specialization in specific areas.", "timestamp": "00:12:14,700", "timestamp_s": 734.0}, {"text": "Fine tuning addresses this limitation by allowing the", "timestamp": "00:12:19,204", "timestamp_s": 739.0}, {"text": "model to learn from domain specific data to be more accurate", "timestamp": "00:12:22,452", "timestamp_s": 742.0}, {"text": "and for targeted applications. Some of", "timestamp": "00:12:26,292", "timestamp_s": 746.0}, {"text": "the commonly used fine tuning techniques are hyperparameterization.", "timestamp": "00:12:30,018", "timestamp_s": 750.0}, {"text": "It is a simple approach that involves manually adjusting the model", "timestamp": "00:12:35,434", "timestamp_s": 755.0}, {"text": "hyperparameters such as the learning rate, batch size,", "timestamp": "00:12:39,234", "timestamp_s": 759.0}, {"text": "and the number of epochs until you achieve the desired performance.", "timestamp": "00:12:43,066", "timestamp_s": 763.0}, {"text": "One or few shot learning enables a model to", "timestamp": "00:12:48,154", "timestamp_s": 768.0}, {"text": "adapt to a new task with little task specific data.", "timestamp": "00:12:51,514", "timestamp_s": 771.0}, {"text": "In this technique, the model is given one or few examples", "timestamp": "00:12:55,360", "timestamp_s": 775.0}, {"text": "during inference time to learn a new task.", "timestamp": "00:12:59,552", "timestamp_s": 779.0}, {"text": "The idea behind this approach is to guide the model\u0027s predictions by", "timestamp": "00:13:03,104", "timestamp_s": 783.0}, {"text": "providing context and examples directly in the prompt.", "timestamp": "00:13:07,024", "timestamp_s": 787.0}, {"text": "This approach is beneficial when the task specific label", "timestamp": "00:13:10,744", "timestamp_s": 790.0}, {"text": "data is scarce or expensive.", "timestamp": "00:13:14,360", "timestamp_s": 794.0}, {"text": "Domain adaptation Domain adaptation is particularly", "timestamp": "00:13:17,944", "timestamp_s": 797.0}, {"text": "valuable when you want to optimize the model\u0027s performance for a single", "timestamp": "00:13:21,732", "timestamp_s": 801.0}, {"text": "well defined task, ensuring that the model excels", "timestamp": "00:13:25,564", "timestamp_s": 805.0}, {"text": "in generating task specific content with precision and accuracy.", "timestamp": "00:13:28,868", "timestamp_s": 808.0}, {"text": "Now look at how we can leverage large language models in", "timestamp": "00:13:35,404", "timestamp_s": 815.0}, {"text": "our day to day life.", "timestamp": "00:13:38,788", "timestamp_s": 818.0}, {"text": "So for developers you have multiple", "timestamp": "00:13:41,964", "timestamp_s": 821.0}, {"text": "ways to leverage LLMs starting from directly using their", "timestamp": "00:13:46,834", "timestamp_s": 826.0}, {"text": "APIs. Are playgrounds with standalone", "timestamp": "00:13:50,242", "timestamp_s": 830.0}, {"text": "models to developing your own customized", "timestamp": "00:13:53,946", "timestamp_s": 833.0}, {"text": "models for basically", "timestamp": "00:13:57,266", "timestamp_s": 837.0}, {"text": "for your own domain or use case and deploying it in your own custom", "timestamp": "00:14:02,234", "timestamp_s": 842.0}, {"text": "environments or hosts.", "timestamp": "00:14:06,114", "timestamp_s": 846.0}, {"text": "The first easiest way to interact with LLMs", "timestamp": "00:14:15,214", "timestamp_s": 855.0}, {"text": "is by using playgrounds or direct", "timestamp": "00:14:19,198", "timestamp_s": 859.0}, {"text": "API integration. Here is one such example where you can use", "timestamp": "00:14:23,334", "timestamp_s": 863.0}, {"text": "AWS bedrock to load the anthropoclad", "timestamp": "00:14:27,142", "timestamp_s": 867.0}, {"text": "v two model and then invoke the model with a specific prompt.", "timestamp": "00:14:31,222", "timestamp_s": 871.0}, {"text": "There are other uis are playgrounds", "timestamp": "00:14:35,734", "timestamp_s": 875.0}, {"text": "that don\u0027t need any coding and you would be able to interact", "timestamp": "00:14:39,482", "timestamp_s": 879.0}, {"text": "with those everyone knows about chat, GPT and", "timestamp": "00:14:43,002", "timestamp_s": 883.0}, {"text": "AWS. Bedrock also has playground where you can basically", "timestamp": "00:14:46,570", "timestamp_s": 886.0}, {"text": "give your prompts and get responses. Some of the bedrock some", "timestamp": "00:14:50,154", "timestamp_s": 890.0}, {"text": "of the models that are supported by bedrock are listed here.", "timestamp": "00:14:53,450", "timestamp_s": 893.0}, {"text": "You have Jurassic Titan command,", "timestamp": "00:14:56,978", "timestamp_s": 896.0}, {"text": "Lama Mistral for text generation. Then for", "timestamp": "00:15:01,114", "timestamp_s": 901.0}, {"text": "the image generation there is titan image generator and stability", "timestamp": "00:15:04,638", "timestamp_s": 904.0}, {"text": "diffusion from stability AI. There are multimodal", "timestamp": "00:15:08,062", "timestamp_s": 908.0}, {"text": "models as well on bedrock like", "timestamp": "00:15:12,326", "timestamp_s": 912.0}, {"text": "cloud three, Haiku and cloud three sonnet.", "timestamp": "00:15:17,334", "timestamp_s": 917.0}, {"text": "These two are the popular ones and there", "timestamp": "00:15:21,654", "timestamp_s": 921.0}, {"text": "is another one from anthropic which is cloud three", "timestamp": "00:15:24,958", "timestamp_s": 924.0}, {"text": "opus. And apart from this for the", "timestamp": "00:15:29,434", "timestamp_s": 929.0}, {"text": "similarity similar similarity search based use cases you have a", "timestamp": "00:15:32,706", "timestamp_s": 932.0}, {"text": "couple of embeddings model embedding based models on bedrock", "timestamp": "00:15:36,666", "timestamp_s": 936.0}, {"text": "as well.", "timestamp": "00:15:40,658", "timestamp_s": 940.0}, {"text": "This is an example of a screen that is taken", "timestamp": "00:15:46,754", "timestamp_s": 946.0}, {"text": "from AWS bedrock. Here is a playground", "timestamp": "00:15:50,194", "timestamp_s": 950.0}, {"text": "on cloud based on cloud this", "timestamp": "00:15:54,674", "timestamp_s": 954.0}, {"text": "is one of the prompts that you can use and tune some of the parameters", "timestamp": "00:15:58,300", "timestamp_s": 958.0}, {"text": "here to get your inference response.", "timestamp": "00:16:02,084", "timestamp_s": 962.0}, {"text": "Here is a question and here is the answer. You can format the question such", "timestamp": "00:16:05,740", "timestamp_s": 965.0}, {"text": "a way that your answer is well", "timestamp": "00:16:09,100", "timestamp_s": 969.0}, {"text": "structured. We\u0027ll get into this in the prompt engineering section that", "timestamp": "00:16:12,492", "timestamp_s": 972.0}, {"text": "will later be explained by Gayathri in the", "timestamp": "00:16:16,452", "timestamp_s": 976.0}, {"text": "upcoming slides. One of the", "timestamp": "00:16:20,444", "timestamp_s": 980.0}, {"text": "easier ways that I have discussed is using playgrounds", "timestamp": "00:16:24,248", "timestamp_s": 984.0}, {"text": "or APIs. You can use hugging face for it.", "timestamp": "00:16:27,464", "timestamp_s": 987.0}, {"text": "Let me show a quick demo of how you can use", "timestamp": "00:16:31,544", "timestamp_s": 991.0}, {"text": "hugging face. Here is the model", "timestamp": "00:16:35,152", "timestamp_s": 995.0}, {"text": "hub for hugging face. You can see that there are bunch of models", "timestamp": "00:16:38,664", "timestamp_s": 998.0}, {"text": "listed on hugging face. Let\u0027s search for", "timestamp": "00:16:42,736", "timestamp_s": 1002.0}, {"text": "Mistral.", "timestamp": "00:16:46,328", "timestamp_s": 1006.0}, {"text": "Let\u0027s go with the Mistral seven b instruct model.", "timestamp": "00:16:50,204", "timestamp_s": 1010.0}, {"text": "Here is an example of the playground that they have. This is a serverless one.", "timestamp": "00:16:53,604", "timestamp_s": 1013.0}, {"text": "It\u0027s free. It can be used for experimentation.", "timestamp": "00:16:58,404", "timestamp_s": 1018.0}, {"text": "It is hugging face.", "timestamp": "00:17:03,244", "timestamp_s": 1023.0}, {"text": "It gives you an opportunity to test out a few models before", "timestamp": "00:17:06,924", "timestamp_s": 1026.0}, {"text": "using it for production use cases.", "timestamp": "00:17:11,780", "timestamp_s": 1031.0}, {"text": "Even though this is free, they throttle you based on", "timestamp": "00:17:15,433", "timestamp_s": 1035.0}, {"text": "the API key that you provide.", "timestamp": "00:17:18,969", "timestamp_s": 1038.0}, {"text": "It cannot be used for production use cases because you will not be able to", "timestamp": "00:17:23,833", "timestamp_s": 1043.0}, {"text": "get the guarantee on availability.", "timestamp": "00:17:28,393", "timestamp_s": 1048.0}, {"text": "They give you options around deploying the model as", "timestamp": "00:17:33,673", "timestamp_s": 1053.0}, {"text": "a dedicated endpoint. Here\u0027s one such option where you can deploy", "timestamp": "00:17:36,937", "timestamp_s": 1056.0}, {"text": "the model. If it is a standalone model and", "timestamp": "00:17:40,474", "timestamp_s": 1060.0}, {"text": "you wanted a standalone version of the model, then you can deploy it on", "timestamp": "00:17:43,866", "timestamp_s": 1063.0}, {"text": "your one of the cloud service providers.", "timestamp": "00:17:47,418", "timestamp_s": 1067.0}, {"text": "Here are the costs and you can choose one of the instance types and", "timestamp": "00:17:53,154", "timestamp_s": 1073.0}, {"text": "this is a very seamless integration with the endpoint.", "timestamp": "00:17:57,514", "timestamp_s": 1077.0}, {"text": "You\u0027ll be charged based on the usage per hours.", "timestamp": "00:18:02,314", "timestamp_s": 1082.0}, {"text": "There is another way where you could. You could take", "timestamp": "00:18:06,234", "timestamp_s": 1086.0}, {"text": "control of the you could take control of the", "timestamp": "00:18:09,912", "timestamp_s": 1089.0}, {"text": "host as well. If you want to deploy it on your AWS sagemaker", "timestamp": "00:18:13,568", "timestamp_s": 1093.0}, {"text": "accounts for your service or for your application, you can do that as well.", "timestamp": "00:18:17,640", "timestamp_s": 1097.0}, {"text": "They they provide you the code on how to deploy", "timestamp": "00:18:23,064", "timestamp_s": 1103.0}, {"text": "it. This is one such example.", "timestamp": "00:18:26,624", "timestamp_s": 1106.0}, {"text": "They also give options to deploy it in", "timestamp": "00:18:31,504", "timestamp_s": 1111.0}, {"text": "Azure and Google Cloud. They have.", "timestamp": "00:18:35,120", "timestamp_s": 1115.0}, {"text": "They also give options to train the model", "timestamp": "00:18:38,376", "timestamp_s": 1118.0}, {"text": "or fine tune the model.", "timestamp": "00:18:42,224", "timestamp_s": 1122.0}, {"text": "Here is a serverless inference for prototyping. This is", "timestamp": "00:18:49,664", "timestamp_s": 1129.0}, {"text": "an image segmentation kind of use case and this", "timestamp": "00:18:53,288", "timestamp_s": 1133.0}, {"text": "is a very simple code that you can use to call", "timestamp": "00:18:56,800", "timestamp_s": 1136.0}, {"text": "any model host run", "timestamp": "00:19:01,632", "timestamp_s": 1141.0}, {"text": "hanging face.", "timestamp": "00:19:05,704", "timestamp_s": 1145.0}, {"text": "This is the code for deploying the hugging face model directly on to", "timestamp": "00:19:10,144", "timestamp_s": 1150.0}, {"text": "your AWS account on the sagemaker or", "timestamp": "00:19:13,960", "timestamp_s": 1153.0}, {"text": "you can choose to deploy it. This is the same code that", "timestamp": "00:19:18,704", "timestamp_s": 1158.0}, {"text": "you get once you click this button.", "timestamp": "00:19:22,496", "timestamp_s": 1162.0}, {"text": "This is a this is what we have seen in the demo", "timestamp": "00:19:26,764", "timestamp_s": 1166.0}, {"text": "and you have other option of deploying using AWS SageMaker", "timestamp": "00:19:31,524", "timestamp_s": 1171.0}, {"text": "Studio to find the foundational models from", "timestamp": "00:19:35,604", "timestamp_s": 1175.0}, {"text": "hugging face or from the other repositories and then", "timestamp": "00:19:39,540", "timestamp_s": 1179.0}, {"text": "deploy it on the sagemaker instance or train it or evaluate", "timestamp": "00:19:42,772", "timestamp_s": 1182.0}, {"text": "compare it with other models. They have good tools", "timestamp": "00:19:46,492", "timestamp_s": 1186.0}, {"text": "to do that.", "timestamp": "00:19:49,700", "timestamp_s": 1189.0}, {"text": "You can also deploy the customized version according to your", "timestamp": "00:19:53,164", "timestamp_s": 1193.0}, {"text": "domain or fine tune version according to your domain.", "timestamp": "00:19:56,692", "timestamp_s": 1196.0}, {"text": "AWS bedrock offers you easier", "timestamp": "00:19:59,764", "timestamp_s": 1199.0}, {"text": "ways to fine tune it based", "timestamp": "00:20:03,588", "timestamp_s": 1203.0}, {"text": "on the foundation models that you choose.", "timestamp": "00:20:07,460", "timestamp_s": 1207.0}, {"text": "They also allow you to custom import a model,", "timestamp": "00:20:11,324", "timestamp_s": 1211.0}, {"text": "but that is supported just for Mistral, Flanti, five and Lama.", "timestamp": "00:20:15,164", "timestamp_s": 1215.0}, {"text": "As of now,", "timestamp": "00:20:18,916", "timestamp_s": 1218.0}, {"text": "you can also write your own custom inference code,", "timestamp": "00:20:22,484", "timestamp_s": 1222.0}, {"text": "write your own get your own model artifacts", "timestamp": "00:20:25,452", "timestamp_s": 1225.0}, {"text": "and deploy it using on a gpu", "timestamp": "00:20:28,876", "timestamp_s": 1228.0}, {"text": "or on a CPU or AWS inferential chips", "timestamp": "00:20:32,092", "timestamp_s": 1232.0}, {"text": "along with the custom images that AWS provides,", "timestamp": "00:20:36,924", "timestamp_s": 1236.0}, {"text": "and then host it yourself.", "timestamp": "00:20:42,324", "timestamp_s": 1242.0}, {"text": "And this is a sample inference code that you can use to", "timestamp": "00:20:46,624", "timestamp_s": 1246.0}, {"text": "deploy your own custom model.", "timestamp": "00:20:50,448", "timestamp_s": 1250.0}, {"text": "Now let\u0027s talk about some of the limitations of standalone LLMs.", "timestamp": "00:20:54,384", "timestamp_s": 1254.0}, {"text": "First, LLMs can sometimes produce content that is inaccurate", "timestamp": "00:20:58,624", "timestamp_s": 1258.0}, {"text": "or completely fabricated, known as hallucinations.", "timestamp": "00:21:02,568", "timestamp_s": 1262.0}, {"text": "This can be problematic, especially in applications requiring precise", "timestamp": "00:21:06,040", "timestamp_s": 1266.0}, {"text": "and reliable information. Secondly, LLMs struggle", "timestamp": "00:21:10,272", "timestamp_s": 1270.0}, {"text": "with providing up to date information because they are trained on data", "timestamp": "00:21:14,394", "timestamp_s": 1274.0}, {"text": "available up to a certain cutoff point.", "timestamp": "00:21:18,090", "timestamp_s": 1278.0}, {"text": "Any developments or changes that occur after this point", "timestamp": "00:21:21,274", "timestamp_s": 1281.0}, {"text": "won\u0027t be reflected in their responses.", "timestamp": "00:21:24,650", "timestamp_s": 1284.0}, {"text": "Another challenge is that general purpose LLMs often", "timestamp": "00:21:28,274", "timestamp_s": 1288.0}, {"text": "have difficulty handling domain specific queries effectively.", "timestamp": "00:21:31,490", "timestamp_s": 1291.0}, {"text": "They might not have the specialized knowledge needed for", "timestamp": "00:21:36,154", "timestamp_s": 1296.0}, {"text": "specific industries or fields without further customization.", "timestamp": "00:21:39,264", "timestamp_s": 1299.0}, {"text": "Limited contextual understanding is also a concern.", "timestamp": "00:21:44,224", "timestamp_s": 1304.0}, {"text": "LLMs may not always grasp the full context of complex", "timestamp": "00:21:48,104", "timestamp_s": 1308.0}, {"text": "queries or conversations, leading to responses that are", "timestamp": "00:21:51,800", "timestamp_s": 1311.0}, {"text": "off target or incomplete. Ethical and", "timestamp": "00:21:55,528", "timestamp_s": 1315.0}, {"text": "bias issues are significant as well. These models", "timestamp": "00:21:59,224", "timestamp_s": 1319.0}, {"text": "can sometimes produce biased or ethically questionable", "timestamp": "00:22:02,656", "timestamp_s": 1322.0}, {"text": "outputs reflecting biases present in the training data.", "timestamp": "00:22:06,652", "timestamp_s": 1326.0}, {"text": "Fine tuning large LLMs to improve their performance", "timestamp": "00:22:11,404", "timestamp_s": 1331.0}, {"text": "for specific tasks requires substantial computational resources,", "timestamp": "00:22:15,444", "timestamp_s": 1335.0}, {"text": "which can be costly and time consuming.", "timestamp": "00:22:19,772", "timestamp_s": 1339.0}, {"text": "Lastly, handling of potentially sensitive data underscores", "timestamp": "00:22:23,204", "timestamp_s": 1343.0}, {"text": "the importance of stringent data governance.", "timestamp": "00:22:27,252", "timestamp_s": 1347.0}, {"text": "For the limitations that were discussed in the previous slide, we can have", "timestamp": "00:22:34,864", "timestamp_s": 1354.0}, {"text": "a system called rag to reduce the problems", "timestamp": "00:22:38,312", "timestamp_s": 1358.0}, {"text": "caused by the hallucinations. What is Rac rag", "timestamp": "00:22:42,152", "timestamp_s": 1362.0}, {"text": "is basically a advanced AI approach that combines the strength", "timestamp": "00:22:45,992", "timestamp_s": 1365.0}, {"text": "of retrieval systems with generative models.", "timestamp": "00:22:49,264", "timestamp_s": 1369.0}, {"text": "It aims to enhance the capabilities of LLMs by grounding", "timestamp": "00:22:52,544", "timestamp_s": 1372.0}, {"text": "generated responses in factual information retrieved from", "timestamp": "00:22:56,544", "timestamp_s": 1376.0}, {"text": "knowledge basis. How does a rack work?", "timestamp": "00:23:00,574", "timestamp_s": 1380.0}, {"text": "It has two components, retrieval component and generative component.", "timestamp": "00:23:04,614", "timestamp_s": 1384.0}, {"text": "The retrieval system features relevant documents or", "timestamp": "00:23:07,910", "timestamp_s": 1387.0}, {"text": "pieces of information from a predefined knowledge base based on", "timestamp": "00:23:11,334", "timestamp_s": 1391.0}, {"text": "the user\u0027s query. Techniques such as", "timestamp": "00:23:15,238", "timestamp_s": 1395.0}, {"text": "keyword matching, semantic search, or vector based retrieval ensures", "timestamp": "00:23:19,022", "timestamp_s": 1399.0}, {"text": "accurate and contextually relevant information is being retrieved.", "timestamp": "00:23:23,172", "timestamp_s": 1403.0}, {"text": "The second component is a generative component.", "timestamp": "00:23:27,060", "timestamp_s": 1407.0}, {"text": "The generative model typically in LLM uses these retrieved", "timestamp": "00:23:32,004", "timestamp_s": 1412.0}, {"text": "information from the retrieval component to generate", "timestamp": "00:23:35,716", "timestamp_s": 1415.0}, {"text": "coherent and contextually enriched responses.", "timestamp": "00:23:39,284", "timestamp_s": 1419.0}, {"text": "This integration allows the LLM to provide answers that are", "timestamp": "00:23:42,804", "timestamp_s": 1422.0}, {"text": "not fluently, that are not only fluent, but all but also", "timestamp": "00:23:46,268", "timestamp_s": 1426.0}, {"text": "contextually relevant.", "timestamp": "00:23:50,076", "timestamp_s": 1430.0}, {"text": "What are the coming to the benefits of Frag?", "timestamp": "00:23:54,004", "timestamp_s": 1434.0}, {"text": "The first one is the improved accuracy.", "timestamp": "00:23:57,564", "timestamp_s": 1437.0}, {"text": "By incorporating retriever retrieved factual information,", "timestamp": "00:24:01,684", "timestamp_s": 1441.0}, {"text": "Rag significantly reduces the likelihood of generating incorrect", "timestamp": "00:24:05,404", "timestamp_s": 1445.0}, {"text": "responses. And by providing", "timestamp": "00:24:08,844", "timestamp_s": 1448.0}, {"text": "more context from the information that is retrieved by the retrieval component,", "timestamp": "00:24:12,572", "timestamp_s": 1452.0}, {"text": "you can have more contextual relevance on", "timestamp": "00:24:16,372", "timestamp_s": 1456.0}, {"text": "the responses that you get.", "timestamp": "00:24:20,088", "timestamp_s": 1460.0}, {"text": "Like the limitation that was discussed earlier, the knowledge cut", "timestamp": "00:24:24,424", "timestamp_s": 1464.0}, {"text": "off. You can use the rag. You can populate", "timestamp": "00:24:27,552", "timestamp_s": 1467.0}, {"text": "the rag with up to date information to get the up to", "timestamp": "00:24:31,280", "timestamp_s": 1471.0}, {"text": "date knowledge and ask queries based on that up to", "timestamp": "00:24:34,808", "timestamp_s": 1474.0}, {"text": "date knowledge.", "timestamp": "00:24:38,400", "timestamp_s": 1478.0}, {"text": "And how do you implement a Rag?", "timestamp": "00:24:48,364", "timestamp_s": 1488.0}, {"text": "Typically it contains four steps. First one is selecting a", "timestamp": "00:24:51,380", "timestamp_s": 1491.0}, {"text": "knowledge database. This is a company\u0027s internal", "timestamp": "00:24:54,756", "timestamp_s": 1494.0}, {"text": "database. You can have it as a vector database. You can have it as a", "timestamp": "00:24:57,964", "timestamp_s": 1497.0}, {"text": "keyword store or anything where you can comprehensively", "timestamp": "00:25:01,876", "timestamp_s": 1501.0}, {"text": "put all the documents that are relevant to your company or", "timestamp": "00:25:06,484", "timestamp_s": 1506.0}, {"text": "for the domain. Then next step is the data preparation.", "timestamp": "00:25:10,772", "timestamp_s": 1510.0}, {"text": "You clean up the data, have the data structured,", "timestamp": "00:25:14,068", "timestamp_s": 1514.0}, {"text": "choose a good storage solution where you can", "timestamp": "00:25:18,020", "timestamp_s": 1518.0}, {"text": "efficiently retrieve the data on demand.", "timestamp": "00:25:21,420", "timestamp_s": 1521.0}, {"text": "So techniques such as vector based search are", "timestamp": "00:25:24,844", "timestamp_s": 1524.0}, {"text": "techniques to store the knowledge as embeddings", "timestamp": "00:25:29,332", "timestamp_s": 1529.0}, {"text": "would help a lot in this particular step.", "timestamp": "00:25:32,828", "timestamp_s": 1532.0}, {"text": "There are custom solutions available in the market like", "timestamp": "00:25:36,544", "timestamp_s": 1536.0}, {"text": "AWS open search and AWS document", "timestamp": "00:25:39,920", "timestamp_s": 1539.0}, {"text": "DB to store these documents. There is another", "timestamp": "00:25:44,512", "timestamp_s": 1544.0}, {"text": "system called Pinecone which is a popular", "timestamp": "00:25:47,960", "timestamp_s": 1547.0}, {"text": "vector database.", "timestamp": "00:25:51,736", "timestamp_s": 1551.0}, {"text": "You can index all the documents that are relevant to your company\u0027s", "timestamp": "00:25:54,824", "timestamp_s": 1554.0}, {"text": "knowledge into that vector database as embeddings using one", "timestamp": "00:25:58,312", "timestamp_s": 1558.0}, {"text": "of the FIAS storage techniques", "timestamp": "00:26:01,808", "timestamp_s": 1561.0}, {"text": "using the fyess engine and then use KNN to basically retrieve those", "timestamp": "00:26:06,192", "timestamp_s": 1566.0}, {"text": "documents. Then third part is the retrieval develop", "timestamp": "00:26:09,352", "timestamp_s": 1569.0}, {"text": "the retrieval system. This system, usually we aim", "timestamp": "00:26:13,264", "timestamp_s": 1573.0}, {"text": "to be very fast, so we try to", "timestamp": "00:26:16,768", "timestamp_s": 1576.0}, {"text": "do a KNN search on the database.", "timestamp": "00:26:20,320", "timestamp_s": 1580.0}, {"text": "Typically a KNN search or you can probably do a semantic search", "timestamp": "00:26:24,200", "timestamp_s": 1584.0}, {"text": "or a keyword based search. The retrieval system has to be", "timestamp": "00:26:28,344", "timestamp_s": 1588.0}, {"text": "fast to give the documents more relevant documents", "timestamp": "00:26:31,888", "timestamp_s": 1591.0}, {"text": "so that you can plug it into the LLM as part of its context.", "timestamp": "00:26:36,014", "timestamp_s": 1596.0}, {"text": "The fourth is the combining the retrieval responses and", "timestamp": "00:26:40,214", "timestamp_s": 1600.0}, {"text": "adding it as a input query to the LLM before forming", "timestamp": "00:26:44,350", "timestamp_s": 1604.0}, {"text": "your question. So apart", "timestamp": "00:26:48,630", "timestamp_s": 1608.0}, {"text": "from the knowledge limitations that are also typically cost concerns and around", "timestamp": "00:26:56,422", "timestamp_s": 1616.0}, {"text": "the LLMs, typically these LLMs are resource", "timestamp": "00:27:02,302", "timestamp_s": 1622.0}, {"text": "intensive. They require high computational requirements.", "timestamp": "00:27:06,094", "timestamp_s": 1626.0}, {"text": "For example, the Lama three 8 billion parameter model", "timestamp": "00:27:09,246", "timestamp_s": 1629.0}, {"text": "and 70 billion parameter model. You would need", "timestamp": "00:27:13,318", "timestamp_s": 1633.0}, {"text": "a minimum of g 512 x large for the 8 billion parameter model and p", "timestamp": "00:27:16,518", "timestamp_s": 1636.0}, {"text": "large for the 70 billion parameter model. And you\u0027re looking at", "timestamp": "00:27:22,870", "timestamp_s": 1642.0}, {"text": "a cost of $7 per hour for the twelve x largest", "timestamp": "00:27:26,086", "timestamp_s": 1646.0}, {"text": "and $37 for the 24 x largest.", "timestamp": "00:27:29,664", "timestamp_s": 1649.0}, {"text": "And they have four to eight Nvidia", "timestamp": "00:27:33,240", "timestamp_s": 1653.0}, {"text": "GPU\u0027s of different configurations.", "timestamp": "00:27:37,040", "timestamp_s": 1657.0}, {"text": "And second, you are looking at a high cost and", "timestamp": "00:27:40,504", "timestamp_s": 1660.0}, {"text": "the maintaining maintenance of this knowledge basis.", "timestamp": "00:27:43,784", "timestamp_s": 1663.0}, {"text": "Typically if your knowledge base is huge like we", "timestamp": "00:27:48,504", "timestamp_s": 1668.0}, {"text": "have it on my team, we have a", "timestamp": "00:27:51,872", "timestamp_s": 1671.0}, {"text": "huge knowledge base of infringements of around 20 billion documents.", "timestamp": "00:27:55,852", "timestamp_s": 1675.0}, {"text": "Sorry, my bad, 2 billion documents that costs", "timestamp": "00:27:59,804", "timestamp_s": 1679.0}, {"text": "us around million dollars a year. So unless", "timestamp": "00:28:03,428", "timestamp_s": 1683.0}, {"text": "you choose some optimized ways of storing these documents, like IVF", "timestamp": "00:28:07,516", "timestamp_s": 1687.0}, {"text": "flat format or IVF product", "timestamp": "00:28:11,812", "timestamp_s": 1691.0}, {"text": "quantization techniques applied", "timestamp": "00:28:16,724", "timestamp_s": 1696.0}, {"text": "to the document are choosing it as indexing strategies.", "timestamp": "00:28:20,100", "timestamp_s": 1700.0}, {"text": "While indexing will help a lot in reducing the cost,", "timestamp": "00:28:23,988", "timestamp_s": 1703.0}, {"text": "the third is the operational maintenance costs. The maintenance", "timestamp": "00:28:28,324", "timestamp_s": 1708.0}, {"text": "of LLMs is a significant factor because you have to scale up the", "timestamp": "00:28:31,644", "timestamp_s": 1711.0}, {"text": "LLM according to your needs. You have to basically", "timestamp": "00:28:34,916", "timestamp_s": 1714.0}, {"text": "fine tune it. It also, the fine tuning process", "timestamp": "00:28:38,156", "timestamp_s": 1718.0}, {"text": "is also kind of slightly expensive because you would need", "timestamp": "00:28:41,916", "timestamp_s": 1721.0}, {"text": "to procure more hosts for fine tuning and then typically", "timestamp": "00:28:45,228", "timestamp_s": 1725.0}, {"text": "you run into availability issues.", "timestamp": "00:28:49,164", "timestamp_s": 1729.0}, {"text": "Some of the cost reduction strategies that we can look at is basically", "timestamp": "00:28:55,364", "timestamp_s": 1735.0}, {"text": "using if your system, if your", "timestamp": "00:28:59,524", "timestamp_s": 1739.0}, {"text": "use cases do not warrant for a deployment of", "timestamp": "00:29:02,964", "timestamp_s": 1742.0}, {"text": "a fine tuned model, then you can use pre trained models and", "timestamp": "00:29:07,844", "timestamp_s": 1747.0}, {"text": "you can interact with them with APIs and other", "timestamp": "00:29:11,588", "timestamp_s": 1751.0}, {"text": "offerings by the cloud service providers. Typically they charge you", "timestamp": "00:29:15,074", "timestamp_s": 1755.0}, {"text": "by the request so you don\u0027t have to bear the upfront cost of hosting", "timestamp": "00:29:18,418", "timestamp_s": 1758.0}, {"text": "it and keeping it alive.", "timestamp": "00:29:22,962", "timestamp_s": 1762.0}, {"text": "Then you can also leverage foundation models of", "timestamp": "00:29:27,034", "timestamp_s": 1767.0}, {"text": "model offerings by cloud service provider like AWS, bedrock and", "timestamp": "00:29:30,610", "timestamp_s": 1770.0}, {"text": "Sagemaker. They have a good set of popular models where", "timestamp": "00:29:34,058", "timestamp_s": 1774.0}, {"text": "you can directly use it without having to host it yourself. Then you", "timestamp": "00:29:37,722", "timestamp_s": 1777.0}, {"text": "can optimize a large model into a smaller model", "timestamp": "00:29:43,506", "timestamp_s": 1783.0}, {"text": "by model distillation, transfer the knowledge of the larger model to a smaller", "timestamp": "00:29:47,994", "timestamp_s": 1787.0}, {"text": "model, distill that knowledge and then have a smaller model.", "timestamp": "00:29:51,682", "timestamp_s": 1791.0}, {"text": "Run your request, process your requests", "timestamp": "00:29:55,354", "timestamp_s": 1795.0}, {"text": "and you can also do quantization by changing the precision", "timestamp": "00:29:58,642", "timestamp_s": 1798.0}, {"text": "for the model from FP 32", "timestamp": "00:30:03,466", "timestamp_s": 1803.0}, {"text": "to FP 16, which will bring down the memory.", "timestamp": "00:30:06,842", "timestamp_s": 1806.0}, {"text": "And you can also prune the model to remove the unnecessary weights", "timestamp": "00:30:10,250", "timestamp_s": 1810.0}, {"text": "or layers and probably reduce the size of", "timestamp": "00:30:13,658", "timestamp_s": 1813.0}, {"text": "the model significantly. Then for efficient", "timestamp": "00:30:16,826", "timestamp_s": 1816.0}, {"text": "resource utilization, you can choose to configure", "timestamp": "00:30:20,226", "timestamp_s": 1820.0}, {"text": "auto scaling, automated scale out", "timestamp": "00:30:24,042", "timestamp_s": 1824.0}, {"text": "and scale in based on your traffic patterns. And then you can", "timestamp": "00:30:27,402", "timestamp_s": 1827.0}, {"text": "batch more and then go with an asynchronous invocation", "timestamp": "00:30:31,242", "timestamp_s": 1831.0}, {"text": "where you don\u0027t need the response immediately. You can reserve some of the instances", "timestamp": "00:30:34,762", "timestamp_s": 1834.0}, {"text": "on Sagemaker and other cloud service providers so that you can procure", "timestamp": "00:30:38,420", "timestamp_s": 1838.0}, {"text": "the host at a cheaper cost. You can cache your responses. These are some of", "timestamp": "00:30:42,220", "timestamp_s": 1842.0}, {"text": "the strategies that you can employ then for the data management for", "timestamp": "00:30:45,636", "timestamp_s": 1845.0}, {"text": "hosting knowledge databases are indexing solutions. You have", "timestamp": "00:30:49,772", "timestamp_s": 1849.0}, {"text": "IVF flat, IVF PQ. You can prefer these", "timestamp": "00:30:53,804", "timestamp_s": 1853.0}, {"text": "techniques indexing techniques instead of", "timestamp": "00:30:56,964", "timestamp_s": 1856.0}, {"text": "storing the documents in HNSW format to", "timestamp": "00:31:00,420", "timestamp_s": 1860.0}, {"text": "reduce the memory and thereby reducing your costs,", "timestamp": "00:31:04,578", "timestamp_s": 1864.0}, {"text": "you can also use model cascading. You can deploy the smaller", "timestamp": "00:31:08,274", "timestamp_s": 1868.0}, {"text": "versions of the model or low precision models at cheaper cost as", "timestamp": "00:31:14,450", "timestamp_s": 1874.0}, {"text": "a filter. And then for those requests that come", "timestamp": "00:31:19,450", "timestamp_s": 1879.0}, {"text": "out of these smaller models, you can probably use a complex", "timestamp": "00:31:23,330", "timestamp_s": 1883.0}, {"text": "model to look at some of the complex patterns.", "timestamp": "00:31:26,466", "timestamp_s": 1886.0}, {"text": "So just like a filtering technique, you can do the model", "timestamp": "00:31:29,794", "timestamp_s": 1889.0}, {"text": "cascading as well.", "timestamp": "00:31:33,202", "timestamp_s": 1893.0}, {"text": "Prompt engineering is about crafting inputs that guide the", "timestamp": "00:31:37,794", "timestamp_s": 1897.0}, {"text": "model towards the desired output. A good example", "timestamp": "00:31:41,122", "timestamp_s": 1901.0}, {"text": "of an effective prompt should contain contextual information", "timestamp": "00:31:44,754", "timestamp_s": 1904.0}, {"text": "about the task. Reference text for the task clear", "timestamp": "00:31:48,794", "timestamp_s": 1908.0}, {"text": "and complete instruction clear instruction at", "timestamp": "00:31:52,754", "timestamp_s": 1912.0}, {"text": "the end of the prompt and as an option, you can specify", "timestamp": "00:31:56,290", "timestamp_s": 1916.0}, {"text": "the format of the output for", "timestamp": "00:32:00,168", "timestamp_s": 1920.0}, {"text": "a task like text classification. Here is a good example by", "timestamp": "00:32:05,560", "timestamp_s": 1925.0}, {"text": "anthropic cloud, where you have the description of the task,", "timestamp": "00:32:09,424", "timestamp_s": 1929.0}, {"text": "reference text for the task, and the classification labels.", "timestamp": "00:32:13,992", "timestamp_s": 1933.0}, {"text": "Another example of question answer based prompt", "timestamp": "00:32:21,944", "timestamp_s": 1941.0}, {"text": "you need to provide the instruction reference based text", "timestamp": "00:32:26,074", "timestamp_s": 1946.0}, {"text": "and at the end you have a clear and concise question for", "timestamp": "00:32:30,282", "timestamp_s": 1950.0}, {"text": "the text summarization task, you have the text for the", "timestamp": "00:32:39,178", "timestamp_s": 1959.0}, {"text": "reference text and a clear instruction to summarize", "timestamp": "00:32:42,402", "timestamp_s": 1962.0}, {"text": "it in the format you choose.", "timestamp": "00:32:46,426", "timestamp_s": 1966.0}, {"text": "For code generation, a clear instruction on what you want,", "timestamp": "00:32:53,294", "timestamp_s": 1973.0}, {"text": "and the specific programming language that you need the code to be in.", "timestamp": "00:32:57,342", "timestamp_s": 1977.0}, {"text": "Large language models offers a myriad of applications for", "timestamp": "00:33:05,934", "timestamp_s": 1985.0}, {"text": "both software engineers and tech professionals. Let\u0027s explore", "timestamp": "00:33:09,350", "timestamp_s": 1989.0}, {"text": "some of these practical uses. As a software engineer,", "timestamp": "00:33:13,518", "timestamp_s": 1993.0}, {"text": "automated code generation can significantly speed up development by", "timestamp": "00:33:17,942", "timestamp_s": 1997.0}, {"text": "handling repetitive tasks and providing code suggestions.", "timestamp": "00:33:21,934", "timestamp_s": 2001.0}, {"text": "For instance, GitHub copilot can generate code snippets", "timestamp": "00:33:25,574", "timestamp_s": 2005.0}, {"text": "based on comments. LLMs assist", "timestamp": "00:33:29,510", "timestamp_s": 2009.0}, {"text": "in code review and debugging by identifying potential bugs", "timestamp": "00:33:32,662", "timestamp_s": 2012.0}, {"text": "and suggesting fix. Similar to tools like deep code and codeguru,", "timestamp": "00:33:36,254", "timestamp_s": 2016.0}, {"text": "generating documentation becomes easier with LLMs,", "timestamp": "00:33:41,654", "timestamp_s": 2021.0}, {"text": "which can create detailed doc strings, readme files,", "timestamp": "00:33:45,110", "timestamp_s": 2025.0}, {"text": "and API documentation from the code base.", "timestamp": "00:33:48,478", "timestamp_s": 2028.0}, {"text": "Natural language interfaces allow for more intuitive software", "timestamp": "00:33:52,624", "timestamp_s": 2032.0}, {"text": "interactions, enabling users to perform tasks using chatbots", "timestamp": "00:33:56,528", "timestamp_s": 2036.0}, {"text": "or voice assistants. As a tech professional,", "timestamp": "00:34:00,296", "timestamp_s": 2040.0}, {"text": "technical support is enhanced with AI driven chatbots that", "timestamp": "00:34:04,000", "timestamp_s": 2044.0}, {"text": "provide first level support, reducing the burden on human teams", "timestamp": "00:34:08,264", "timestamp_s": 2048.0}, {"text": "and improving response times.", "timestamp": "00:34:11,784", "timestamp_s": 2051.0}, {"text": "LLMs can analyze data, generate reports, and extract insights", "timestamp": "00:34:14,424", "timestamp_s": 2054.0}, {"text": "from textual data, aiding in decision making and strategy", "timestamp": "00:34:18,611", "timestamp_s": 2058.0}, {"text": "formulation. Content creation for marketing documentation", "timestamp": "00:34:22,763", "timestamp_s": 2062.0}, {"text": "and internal communications can be automated,", "timestamp": "00:34:26,891", "timestamp_s": 2066.0}, {"text": "streamlining workflows and ensuring consistency.", "timestamp": "00:34:30,123", "timestamp_s": 2070.0}, {"text": "Training programs powered by LLMs offer personalized learning experiences,", "timestamp": "00:34:34,243", "timestamp_s": 2074.0}, {"text": "making knowledge sharing more efficient and interactive.", "timestamp": "00:34:38,723", "timestamp_s": 2078.0}, {"text": "In conclusion, by leveraging LLMs, both software engineers", "timestamp": "00:34:44,174", "timestamp_s": 2084.0}, {"text": "and tech professionals can enhance productivity,", "timestamp": "00:34:47,862", "timestamp_s": 2087.0}, {"text": "improve efficiency and innovate in their respective fields.", "timestamp": "00:34:50,646", "timestamp_s": 2090.0}, {"text": "Coming to how we do it in our brand protection organization", "timestamp": "00:34:58,494", "timestamp_s": 2098.0}, {"text": "how we leverage LLM we leverage LLM", "timestamp": "00:35:03,302", "timestamp_s": 2103.0}, {"text": "for trademark and copyright wireless detections.", "timestamp": "00:35:06,694", "timestamp_s": 2106.0}, {"text": "We analyze the brand names, logos and other intellectual properties", "timestamp": "00:35:11,694", "timestamp_s": 2111.0}, {"text": "on the product listings and we", "timestamp": "00:35:15,678", "timestamp_s": 2115.0}, {"text": "try to identify the brands to whom the trademarks belongs", "timestamp": "00:35:19,558", "timestamp_s": 2119.0}, {"text": "to. We have a corpus of trademarks", "timestamp": "00:35:22,918", "timestamp_s": 2122.0}, {"text": "and copyrights belonging to the brands for it for,", "timestamp": "00:35:26,702", "timestamp_s": 2126.0}, {"text": "I believe, trademarks for around 1 million,", "timestamp": "00:35:30,542", "timestamp_s": 2130.0}, {"text": "sorry, around 100k brands and copyrights", "timestamp": "00:35:33,430", "timestamp_s": 2133.0}, {"text": "and logos for another 50,000 brands.", "timestamp": "00:35:36,884", "timestamp_s": 2136.0}, {"text": "For the counterfeit detection we do use LLMs to notice", "timestamp": "00:35:41,524", "timestamp_s": 2141.0}, {"text": "to recognize subtle differences between genuine and fake product listings", "timestamp": "00:35:46,372", "timestamp_s": 2146.0}, {"text": "and the lms are also very helpful in", "timestamp": "00:35:50,652", "timestamp_s": 2150.0}, {"text": "detecting obfuscations like people who use n", "timestamp": "00:35:54,532", "timestamp_s": 2154.0}, {"text": "one ke instead of Nike and for analyzing", "timestamp": "00:35:57,980", "timestamp_s": 2157.0}, {"text": "behavioral and analytics of the seller behavior and", "timestamp": "00:36:01,612", "timestamp_s": 2161.0}, {"text": "some of the real world examples that we have on our site,", "timestamp": "00:36:09,674", "timestamp_s": 2169.0}, {"text": "the last one being ours. The first three are public now.", "timestamp": "00:36:14,074", "timestamp_s": 2174.0}, {"text": "I guess everybody", "timestamp": "00:36:17,674", "timestamp_s": 2177.0}, {"text": "now can see review highlights on the product listings page", "timestamp": "00:36:20,850", "timestamp_s": 2180.0}, {"text": "of Amazon you see a summary of what", "timestamp": "00:36:24,250", "timestamp_s": 2184.0}, {"text": "customers say. Then there is a this", "timestamp": "00:36:28,194", "timestamp_s": 2188.0}, {"text": "is early access for the offered offer to the sellers when", "timestamp": "00:36:33,102", "timestamp_s": 2193.0}, {"text": "they create listings on Amazon.", "timestamp": "00:36:37,214", "timestamp_s": 2197.0}, {"text": "The LLMs can generate content based on very", "timestamp": "00:36:40,694", "timestamp_s": 2200.0}, {"text": "small description of the product that you are selling.", "timestamp": "00:36:44,534", "timestamp_s": 2204.0}, {"text": "It can fill the gaps or it can fill more details about the product.", "timestamp": "00:36:47,910", "timestamp_s": 2207.0}, {"text": "Then Amazon pharmacy started", "timestamp": "00:36:51,734", "timestamp_s": 2211.0}, {"text": "using this LLMs recently to answer questions more", "timestamp": "00:36:55,818", "timestamp_s": 2215.0}, {"text": "quickly because the LLMs can now look at", "timestamp": "00:37:00,002", "timestamp_s": 2220.0}, {"text": "the whole corpus of internal wikis and provide more info,", "timestamp": "00:37:03,634", "timestamp_s": 2223.0}, {"text": "more information on the drugs, and much more.", "timestamp": "00:37:06,714", "timestamp_s": 2226.0}, {"text": "Quickly then in our space, we reduce the human", "timestamp": "00:37:11,674", "timestamp_s": 2231.0}, {"text": "audits for detecting infringements by 80% for famous brands like Apple,", "timestamp": "00:37:15,714", "timestamp_s": 2235.0}, {"text": "et cetera.", "timestamp": "00:37:19,426", "timestamp_s": 2239.0}, {"text": "For hard to find copyright violations,", "timestamp": "00:37:22,554", "timestamp_s": 2242.0}, {"text": "we run the LLM for around 1", "timestamp": "00:37:26,354", "timestamp_s": 2246.0}, {"text": "million products a day.", "timestamp": "00:37:31,290", "timestamp_s": 2251.0}, {"text": "And the final output coming out of the LLMs", "timestamp": "00:37:35,514", "timestamp_s": 2255.0}, {"text": "that is flagged for deeper look", "timestamp": "00:37:39,178", "timestamp_s": 2259.0}, {"text": "is around 20% of those 1", "timestamp": "00:37:43,954", "timestamp_s": 2263.0}, {"text": "million. So around two hundred k.", "timestamp": "00:37:48,090", "timestamp_s": 2268.0}, {"text": "And finally, thank you for this opportunity.", "timestamp": "00:37:53,154", "timestamp_s": 2273.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'JiU525Fy1Fg',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Leveraging Large Language Models for Advanced AI Applications: A Comprehensive Guide
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Unveil how Large Language Models (LLMs) like GPT and Turing NLG have transformed trademark identification, reducing audits by 80% and doubling productivity in content creation. Explore their impact across industries, with a 50% boost in material recovery and a 40% improvement in customer service.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Gayathri Shivraj is a senior program manager at Amazon. He focuses on program and product excellence to provide best in class seller experience. Large language models are a big part of the products we build. He will be a speaker at the Con 42.

              </li>
              
              <li>
                Large language models can be leveraged for advanced AI applications. While LLMs are powerful, they come with their own set of constraints and challenges. We will cover the limitations, potential pitfalls, and ethical considerations when deploying these models in real world scenarios. Finally, we will look at some of the real world success stories.

              </li>
              
              <li>
                Large language models are advanced AI models trained on extensive datasets to understand and generate human like language. These models are designed to perform a wide range of language related tasks, making them incredibly versatile and powerful tools. Let's take a closer look at what LLMs are, their key components, capabilities, and applications across various industries.

              </li>
              
              <li>
                Satya is a senior engineer at Amazon in the brand protection organization. The transformers architecture represents a significant breakthrough in the field of natural language processing. It overcomes the limitations of previous architectures like RNN's and LSTM networks. Fine tuning is the process of adjusting the parameters of a pre trained large language model.

              </li>
              
              <li>
                For developers you have multiple ways to leverage LLMs starting from directly using their APIs. The first easiest way to interact with LLMs is by using playgrounds or direct API integration. Are playgrounds with standalone models to developing your own customized models for basically for your own domain or use case.

              </li>
              
              <li>
                You can use hugging face for experimentation. It gives you an opportunity to test out a few models before using it for production use cases. They give you options around deploying the model as a dedicated endpoint. They also give options to train the model or fine tune the model.

              </li>
              
              <li>
                Rag is an advanced AI approach that combines the strength of retrieval systems with generative models. It aims to enhance the capabilities of LLMs by grounding generated responses in factual information retrieved from knowledge basis. The benefits of Frag include improved accuracy and contextual relevance.

              </li>
              
              <li>
                We leverage LLM for trademark and copyright wireless detections. We analyze the brand names, logos and other intellectual properties on the product listings. For hard to find copyright violations, we run the LLm for around 1 million products a day. And finally, thank you for this opportunity.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/JiU525Fy1Fg.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:27,440'); seek(27.0)">
              Hi everyone. I'm Gayathri Shivraj and I'm honored to be a speaker at the
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:31,380'); seek(31.0)">
              Con 42. I'm a senior program manager at Amazon.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:34,956'); seek(34.0)">
              In the fulfillment services, I primarily focus on
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:38,844'); seek(38.0)">
              program and product excellence to provide best in class seller
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:42,236'); seek(42.0)">
              experience by optimizing the storage and fulfillment capabilities.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:46,804'); seek(46.0)">
              Large language models are a big part of the products we build as we
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:50,292'); seek(50.0)">
              deal with large datasets of seller communication across
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:53,844'); seek(53.0)">
              different modalities worldwide.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:59,894'); seek(59.0)">
              Before we dive into the details, let's take a quick look at the agenda
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:01:03,470'); seek(63.0)">
              for today's presentation. We have a lot of ground to cover,
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:07,150'); seek(67.0)">
              and I want to ensure we have a structured approach to understanding how
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:11,118'); seek(71.0)">
              large language models can be leveraged for advanced AI applications.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:16,134'); seek(76.0)">
              We will start with an introduction to large language models,
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:19,510'); seek(79.0)">
              or LLMs. This section will provide a foundational
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:22,862'); seek(82.0)">
              understanding of what LLMs are, their significance in the field of AI,
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:27,392'); seek(87.0)">
              and why they have become so prominent in the recent years.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:31,424'); seek(91.0)">
              Next, we will dwell into the architecture of LLMs.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:35,328'); seek(95.0)">
              We will explore how these models are built, the underlying technologies
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:40,048'); seek(100.0)">
              that power them, and the key components that make them effective at processing
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:44,432'); seek(104.0)">
              and generating human like text.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:47,544'); seek(107.0)">
              Next, we will talk about methods for leveraging LLMs.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:51,128'); seek(111.0)">
              In this section, I will discuss how to use LLMs
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:54,828'); seek(114.0)">
              effectively by leveraging APIs and interactive playgrounds.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:59,364'); seek(119.0)">
              I'll explain how to deploy these models for production use cases,
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:02:03,852'); seek(123.0)">
              ensuring scalability and reliability.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:02:06,924'); seek(126.0)">
              Additionally, we will cover how to customize LLMs to
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:10,332'); seek(130.0)">
              meet specific needs and how to deploy these customized versions,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:14,308'); seek(134.0)">
              and how to create and use effective prompts to get
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:17,460'); seek(137.0)">
              the best results from LLMs.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:20,704'); seek(140.0)">
              Next limitations of using LLMs while LLMs
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:23,936'); seek(143.0)">
              are powerful, they come with their own set of constraints and challenges.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:28,264'); seek(148.0)">
              We will cover the limitations, potential pitfalls, and ethical considerations
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:32,872'); seek(152.0)">
              when deploying these models in real world scenarios.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:36,344'); seek(156.0)">
              And finally, with the real world success stories,
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:39,568'); seek(159.0)">
              we will look at some of the real world success stories. I will
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:43,232'); seek(163.0)">
              share case studies and examples of how organizations,
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:46,960'); seek(166.0)">
              including Amazon, have successfully implemented LLMs
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:50,700'); seek(170.0)">
              to solve complex problems, improve efficiency,
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:55,268'); seek(175.0)">
              and enhance customer experiences.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:03:00,764'); seek(180.0)">
              Let's take a closer look at what LLMs are, their key
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:04,108'); seek(184.0)">
              components, capabilities, and applications across various industries.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:08,964'); seek(188.0)">
              What are LLMs? Large language models are advanced
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:12,636'); seek(192.0)">
              AI models trained on extensive datasets to understand
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:16,044'); seek(196.0)">
              and generate human like language. These models are
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:19,754'); seek(199.0)">
              designed to perform a wide range of language related tasks,
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:23,186'); seek(203.0)">
              making them incredibly versatile and powerful tools in the
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:26,578'); seek(206.0)">
              field of AI. The key components of
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:29,962'); seek(209.0)">
              LLMs transformer architecture at
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:33,458'); seek(213.0)">
              the heart of LLMs is the transformer architecture.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:36,994'); seek(216.0)">
              This architecture allows the model to handle long reach dependencies
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:41,290'); seek(221.0)">
              in text, making it possible to generate coherent
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:44,458'); seek(224.0)">
              and contextual relevant responses.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:48,014'); seek(228.0)">
              Pre trained parameters LLMs come with
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:51,174'); seek(231.0)">
              millions, billions, and sometimes trillions of pre trained parameters.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:55,462'); seek(235.0)">
              These parameters are learned from vast amounts of text data,
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:58,966'); seek(238.0)">
              enabling the model to understand language nuances
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:02,254'); seek(242.0)">
              and context. Finally, fine tuning
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:06,078'); seek(246.0)">
              after pre training, LLMs can be fine tuned on specific
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:09,790'); seek(249.0)">
              data sets to adapt to particular tasks or domains.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:13,350'); seek(253.0)">
              This fine tuning process tailors the model's capabilities to
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:16,900'); seek(256.0)">
              meet specific needs more effectively.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:21,404'); seek(261.0)">
              Capabilities of LLMs content generation and comprehensions
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:26,604'); seek(266.0)">
              LLMs excel at text generation, allowing them to create human
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:30,420'); seek(270.0)">
              like text based on given prompts. They can also perform question
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:34,524'); seek(274.0)">
              answering, providing relevant and accurate responses to user queries.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:39,504'); seek(279.0)">
              Language processing these models are capable
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:42,576'); seek(282.0)">
              of language translation and summarization,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:45,264'); seek(285.0)">
              breaking down language barriers, and condensing information
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:48,416'); seek(288.0)">
              into more digestible formats. Analysis and
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:52,424'); seek(292.0)">
              recognition LLMs can analyze sentiments,
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:56,208'); seek(296.0)">
              classify text, and recognize named entities,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:59,632'); seek(299.0)">
              making them useful for tasks such as sentiment analysis, text classification,
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:04,896'); seek(304.0)">
              and named entity recognition applications
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:08,972'); seek(308.0)">
              across industries. Software development in software
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:12,716'); seek(312.0)">
              development, LLMs facilitate code summarization,
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:15,892'); seek(315.0)">
              natural code search, and automated documentation generation.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:20,324'); seek(320.0)">
              These capabilities enhance developer productivity and
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:24,316'); seek(324.0)">
              improve code understanding. Learning LLMs
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:28,588'); seek(328.0)">
              can serve as education tools for learning programming languages.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:32,428'); seek(332.0)">
              They provide personalized feedback and tutoring to
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:35,876'); seek(335.0)">
              aspiring developers and support the creation of attractive
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:39,466'); seek(339.0)">
              coding exercises and adaptive learning platforms.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:51,874'); seek(351.0)">
              Thank you, Gayathri hello, I'm Satya
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:55,482'); seek(355.0)">
              and thank you for the opportunity to speak at Conf 42.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:59,682'); seek(359.0)">
              I am a senior engineer at Amazon in the brand protection organization.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:06:03,834'); seek(363.0)">
              In my role, my team and I build systems to protect the integrity of
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:06:08,210'); seek(368.0)">
              our website by monitoring and preventing infringements and counterfeits.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:14,234'); seek(374.0)">
              We focus on preventing the misuse of IP of brands,
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:17,770'); seek(377.0)">
              ensuring that our customers can shop with confidence in
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:21,810'); seek(381.0)">
              building these systems. We leverage multiple LLMs and multimodal
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:25,946'); seek(385.0)">
              LLMs to accomplish this goal.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:30,194'); seek(390.0)">
              Let's quickly delve into the architecture of transformers.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:43,534'); seek(403.0)">
              The transformers architecture represents a significant breakthrough
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:47,438'); seek(407.0)">
              in the field of natural language processing and serves as a backbone
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:50,894'); seek(410.0)">
              for many state of the art LLMs.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:53,814'); seek(413.0)">
              The transformer architecture is a game changer in the field of LLMs
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:58,826'); seek(418.0)">
              because it overcomes the limitations of previous architectures like
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:07:02,386'); seek(422.0)">
              RNN's and LSTM networks. The problem
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:07:06,546'); seek(426.0)">
              with RNN's is they tend to forget important information from
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:07:10,682'); seek(430.0)">
              earlier in a sequence because they process words
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:07:14,106'); seek(434.0)">
              one by one, making them very slow and less accurate for very
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:07:18,506'); seek(438.0)">
              long ticks. Lstms improve memory retention,
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:07:22,154'); seek(442.0)">
              but they are still slow since they also handle words
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:26,386'); seek(446.0)">
              sequentially. Some of the key components
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:30,282'); seek(450.0)">
              of transformers architecture are self attention mechanism,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:34,298'); seek(454.0)">
              positional encodings, feed forward neural networks,
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:37,522'); seek(457.0)">
              encoder decoder, multi head attention layer normalization,
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:41,170'); seek(461.0)">
              and residual connections. The fundamental parts are
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:44,442'); seek(464.0)">
              basically the encoder and the decoder. And it
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:47,770'); seek(467.0)">
              all started when a paper was released in 2017
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:51,874'); seek(471.0)">
              which had the title attention is all you need, and that's from
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:55,386'); seek(475.0)">
              Washirani and others. And going
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:08:00,242'); seek(480.0)">
              into the architecture of LLMs,
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:08:03,114'); seek(483.0)">
              the self attention mechanism think of the self
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:08:06,754'); seek(486.0)">
              attention mechanism as a way for the model to look at all the
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:08:10,378'); seek(490.0)">
              words in a sentence and decide which ones are most important.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:08:14,594'); seek(494.0)">
              And for example, in the sentence
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:17,946'); seek(497.0)">
              the cat sat on the mat. The word cat may pay more
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:22,282'); seek(502.0)">
              attention to words sat and mat because
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:25,858'); seek(505.0)">
              they are closely related.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:28,314'); seek(508.0)">
              Now, the second component of transformers
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:32,666'); seek(512.0)">
              architecture, the positional encoding, is just because
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:36,674'); seek(516.0)">
              the transformers don't naturally understand the words in which
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:39,930'); seek(519.0)">
              they are ordered. Positional encoding helps the model know
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:43,658'); seek(523.0)">
              the position of each word in the sentence. Then comes the
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:47,248'); seek(527.0)">
              feed forward neural networks the
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:51,360'); seek(531.0)">
              feed forward neural networks after applying the self
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:54,672'); seek(534.0)">
              attention and positional encoding, the process tokens are
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:58,480'); seek(538.0)">
              passed through the free forward neural networks within each layer
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:09:01,800'); seek(541.0)">
              of the transformer. These feed forward neural networks
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:09:05,688'); seek(545.0)">
              consist of multiple fully connected layers with nonlinear
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:09:09,072'); seek(549.0)">
              activation functions, for example,
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:09:11,568'); seek(551.0)">
              relu, and they enable the model to
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:14,878'); seek(554.0)">
              learn complex patterns and representations from the input
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:18,222'); seek(558.0)">
              data. Then the
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:22,534'); seek(562.0)">
              next part is the encoder decoder. The encoder component
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:26,462'); seek(566.0)">
              is basically responsible for translating the input sequence.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:30,670'); seek(570.0)">
              It processes the input sequence while the decoder generates the output
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:34,342'); seek(574.0)">
              sequence.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:38,514'); seek(578.0)">
              The next one is the multi head.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:41,498'); seek(581.0)">
              Attention. To enhance the learning capabilities
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:45,802'); seek(585.0)">
              of the LLM and capture different types of information,
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:48,994'); seek(588.0)">
              transformers typically employ multi head attention mechanisms.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:52,954'); seek(592.0)">
              This feature allows the model to focus on certain parts of the input
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:58,514'); seek(598.0)">
              sentence, simultaneously enhancing its understanding
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:10:02,130'); seek(602.0)">
              of the text. For example, in a translation task,
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:10:05,322'); seek(605.0)">
              one part of the model might focus on nouns, while the
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:10:08,706'); seek(608.0)">
              other part focuses on verbs. These points of focus
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:10:13,794'); seek(613.0)">
              can be referred as heads.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:18,234'); seek(618.0)">
              Then the last part of it is the layer normalization and residual connections
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:22,594'); seek(622.0)">
              to stabilize the training process and ensure that
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:26,218'); seek(626.0)">
              the model learns efficiently by
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:29,782'); seek(629.0)">
              allowing information to flow smoothly between the layers.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:32,718'); seek(632.0)">
              This layer normalization technique is used to normalize the
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:36,094'); seek(636.0)">
              weights.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:45,094'); seek(645.0)">
              Pre trained parameters are the numerical values associated
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:48,670'); seek(648.0)">
              with the connections between neurons in the neural network architecture
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:52,302'); seek(652.0)">
              of an LLM. These parameters represent the learned knowledge and
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:56,542'); seek(656.0)">
              patterns extracted from the training data during the pre training
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:11:00,258'); seek(660.0)">
              phase. As the model processes the input text,
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:11:03,970'); seek(663.0)">
              it adjusts its parameters, that is, weights and biases,
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:11:07,818'); seek(667.0)">
              to minimize a predefined loss function, such as cross entropy
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:11:11,954'); seek(671.0)">
              loss, applied to the pre training objective,
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:15,474'); seek(675.0)">
              the components of pre trained parameters are
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:19,122'); seek(679.0)">
              word embeddings, parameters that represent the
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:22,362'); seek(682.0)">
              initial numerical representations of word words or subwords
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:25,892'); seek(685.0)">
              in the vocabulary. Word embeddings capture semantic
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:29,604'); seek(689.0)">
              similarities between words based on their contextual usage in the
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:33,220'); seek(693.0)">
              training data transformer layers parameters
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:37,044'); seek(697.0)">
              associated with the multiple layers of the transformer architecture used in LLMs.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:41,764'); seek(701.0)">
              These layers include self attention mechanisms and feed forward
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:45,588'); seek(705.0)">
              neural networks. Output layer parameters
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:49,684'); seek(709.0)">
              parameters of the output layer, which map the final hidden
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:53,636'); seek(713.0)">
              states of the model to predictions for specific tasks
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:57,948'); seek(717.0)">
              such as classification and task generation.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:12:03,684'); seek(723.0)">
              Fine tuning is the process of adjusting the parameters
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:12:07,308'); seek(727.0)">
              of a pre trained large language model to a specific task or
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:12:10,836'); seek(730.0)">
              domain. Although pre trained language models possess vast
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:14,700'); seek(734.0)">
              language knowledge, they lack specialization in specific areas.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:19,204'); seek(739.0)">
              Fine tuning addresses this limitation by allowing the
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:22,452'); seek(742.0)">
              model to learn from domain specific data to be more accurate
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:26,292'); seek(746.0)">
              and for targeted applications. Some of
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:30,018'); seek(750.0)">
              the commonly used fine tuning techniques are hyperparameterization.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:35,434'); seek(755.0)">
              It is a simple approach that involves manually adjusting the model
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:39,234'); seek(759.0)">
              hyperparameters such as the learning rate, batch size,
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:43,066'); seek(763.0)">
              and the number of epochs until you achieve the desired performance.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:48,154'); seek(768.0)">
              One or few shot learning enables a model to
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:51,514'); seek(771.0)">
              adapt to a new task with little task specific data.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:55,360'); seek(775.0)">
              In this technique, the model is given one or few examples
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:59,552'); seek(779.0)">
              during inference time to learn a new task.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:13:03,104'); seek(783.0)">
              The idea behind this approach is to guide the model's predictions by
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:13:07,024'); seek(787.0)">
              providing context and examples directly in the prompt.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:13:10,744'); seek(790.0)">
              This approach is beneficial when the task specific label
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:14,360'); seek(794.0)">
              data is scarce or expensive.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:17,944'); seek(797.0)">
              Domain adaptation Domain adaptation is particularly
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:21,732'); seek(801.0)">
              valuable when you want to optimize the model's performance for a single
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:25,564'); seek(805.0)">
              well defined task, ensuring that the model excels
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:28,868'); seek(808.0)">
              in generating task specific content with precision and accuracy.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:35,404'); seek(815.0)">
              Now look at how we can leverage large language models in
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:38,788'); seek(818.0)">
              our day to day life.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:41,964'); seek(821.0)">
              So for developers you have multiple
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:46,834'); seek(826.0)">
              ways to leverage LLMs starting from directly using their
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:50,242'); seek(830.0)">
              APIs. Are playgrounds with standalone
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:53,946'); seek(833.0)">
              models to developing your own customized
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:57,266'); seek(837.0)">
              models for basically
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:14:02,234'); seek(842.0)">
              for your own domain or use case and deploying it in your own custom
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:14:06,114'); seek(846.0)">
              environments or hosts.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:14:15,214'); seek(855.0)">
              The first easiest way to interact with LLMs
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:19,198'); seek(859.0)">
              is by using playgrounds or direct
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:23,334'); seek(863.0)">
              API integration. Here is one such example where you can use
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:27,142'); seek(867.0)">
              AWS bedrock to load the anthropoclad
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:31,222'); seek(871.0)">
              v two model and then invoke the model with a specific prompt.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:35,734'); seek(875.0)">
              There are other uis are playgrounds
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:39,482'); seek(879.0)">
              that don't need any coding and you would be able to interact
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:43,002'); seek(883.0)">
              with those everyone knows about chat, GPT and
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:46,570'); seek(886.0)">
              AWS. Bedrock also has playground where you can basically
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:50,154'); seek(890.0)">
              give your prompts and get responses. Some of the bedrock some
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:53,450'); seek(893.0)">
              of the models that are supported by bedrock are listed here.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:56,978'); seek(896.0)">
              You have Jurassic Titan command,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:15:01,114'); seek(901.0)">
              Lama Mistral for text generation. Then for
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:15:04,638'); seek(904.0)">
              the image generation there is titan image generator and stability
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:15:08,062'); seek(908.0)">
              diffusion from stability AI. There are multimodal
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:15:12,326'); seek(912.0)">
              models as well on bedrock like
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:17,334'); seek(917.0)">
              cloud three, Haiku and cloud three sonnet.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:21,654'); seek(921.0)">
              These two are the popular ones and there
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:24,958'); seek(924.0)">
              is another one from anthropic which is cloud three
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:29,434'); seek(929.0)">
              opus. And apart from this for the
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:32,706'); seek(932.0)">
              similarity similar similarity search based use cases you have a
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:36,666'); seek(936.0)">
              couple of embeddings model embedding based models on bedrock
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:40,658'); seek(940.0)">
              as well.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:46,754'); seek(946.0)">
              This is an example of a screen that is taken
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:50,194'); seek(950.0)">
              from AWS bedrock. Here is a playground
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:54,674'); seek(954.0)">
              on cloud based on cloud this
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:58,300'); seek(958.0)">
              is one of the prompts that you can use and tune some of the parameters
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:16:02,084'); seek(962.0)">
              here to get your inference response.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:16:05,740'); seek(965.0)">
              Here is a question and here is the answer. You can format the question such
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:16:09,100'); seek(969.0)">
              a way that your answer is well
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:16:12,492'); seek(972.0)">
              structured. We'll get into this in the prompt engineering section that
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:16,452'); seek(976.0)">
              will later be explained by Gayathri in the
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:20,444'); seek(980.0)">
              upcoming slides. One of the
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:24,248'); seek(984.0)">
              easier ways that I have discussed is using playgrounds
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:27,464'); seek(987.0)">
              or APIs. You can use hugging face for it.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:31,544'); seek(991.0)">
              Let me show a quick demo of how you can use
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:35,152'); seek(995.0)">
              hugging face. Here is the model
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:38,664'); seek(998.0)">
              hub for hugging face. You can see that there are bunch of models
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:42,736'); seek(1002.0)">
              listed on hugging face. Let's search for
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:46,328'); seek(1006.0)">
              Mistral.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:50,204'); seek(1010.0)">
              Let's go with the Mistral seven b instruct model.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:53,604'); seek(1013.0)">
              Here is an example of the playground that they have. This is a serverless one.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:58,404'); seek(1018.0)">
              It's free. It can be used for experimentation.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:17:03,244'); seek(1023.0)">
              It is hugging face.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:17:06,924'); seek(1026.0)">
              It gives you an opportunity to test out a few models before
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:17:11,780'); seek(1031.0)">
              using it for production use cases.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:17:15,433'); seek(1035.0)">
              Even though this is free, they throttle you based on
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:18,969'); seek(1038.0)">
              the API key that you provide.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:23,833'); seek(1043.0)">
              It cannot be used for production use cases because you will not be able to
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:28,393'); seek(1048.0)">
              get the guarantee on availability.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:33,673'); seek(1053.0)">
              They give you options around deploying the model as
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:36,937'); seek(1056.0)">
              a dedicated endpoint. Here's one such option where you can deploy
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:40,474'); seek(1060.0)">
              the model. If it is a standalone model and
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:43,866'); seek(1063.0)">
              you wanted a standalone version of the model, then you can deploy it on
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:47,418'); seek(1067.0)">
              your one of the cloud service providers.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:53,154'); seek(1073.0)">
              Here are the costs and you can choose one of the instance types and
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:57,514'); seek(1077.0)">
              this is a very seamless integration with the endpoint.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:18:02,314'); seek(1082.0)">
              You'll be charged based on the usage per hours.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:18:06,234'); seek(1086.0)">
              There is another way where you could. You could take
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:18:09,912'); seek(1089.0)">
              control of the you could take control of the
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:18:13,568'); seek(1093.0)">
              host as well. If you want to deploy it on your AWS sagemaker
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:18:17,640'); seek(1097.0)">
              accounts for your service or for your application, you can do that as well.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:18:23,064'); seek(1103.0)">
              They they provide you the code on how to deploy
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:26,624'); seek(1106.0)">
              it. This is one such example.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:31,504'); seek(1111.0)">
              They also give options to deploy it in
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:35,120'); seek(1115.0)">
              Azure and Google Cloud. They have.
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:38,376'); seek(1118.0)">
              They also give options to train the model
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:42,224'); seek(1122.0)">
              or fine tune the model.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:49,664'); seek(1129.0)">
              Here is a serverless inference for prototyping. This is
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:53,288'); seek(1133.0)">
              an image segmentation kind of use case and this
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:56,800'); seek(1136.0)">
              is a very simple code that you can use to call
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:19:01,632'); seek(1141.0)">
              any model host run
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:19:05,704'); seek(1145.0)">
              hanging face.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:19:10,144'); seek(1150.0)">
              This is the code for deploying the hugging face model directly on to
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:19:13,960'); seek(1153.0)">
              your AWS account on the sagemaker or
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:19:18,704'); seek(1158.0)">
              you can choose to deploy it. This is the same code that
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:19:22,496'); seek(1162.0)">
              you get once you click this button.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:26,764'); seek(1166.0)">
              This is a this is what we have seen in the demo
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:31,524'); seek(1171.0)">
              and you have other option of deploying using AWS SageMaker
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:35,604'); seek(1175.0)">
              Studio to find the foundational models from
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:39,540'); seek(1179.0)">
              hugging face or from the other repositories and then
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:42,772'); seek(1182.0)">
              deploy it on the sagemaker instance or train it or evaluate
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:46,492'); seek(1186.0)">
              compare it with other models. They have good tools
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:49,700'); seek(1189.0)">
              to do that.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:53,164'); seek(1193.0)">
              You can also deploy the customized version according to your
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:56,692'); seek(1196.0)">
              domain or fine tune version according to your domain.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:59,764'); seek(1199.0)">
              AWS bedrock offers you easier
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:20:03,588'); seek(1203.0)">
              ways to fine tune it based
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:20:07,460'); seek(1207.0)">
              on the foundation models that you choose.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:20:11,324'); seek(1211.0)">
              They also allow you to custom import a model,
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:20:15,164'); seek(1215.0)">
              but that is supported just for Mistral, Flanti, five and Lama.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:18,916'); seek(1218.0)">
              As of now,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:22,484'); seek(1222.0)">
              you can also write your own custom inference code,
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:25,452'); seek(1225.0)">
              write your own get your own model artifacts
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:28,876'); seek(1228.0)">
              and deploy it using on a gpu
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:32,092'); seek(1232.0)">
              or on a CPU or AWS inferential chips
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:36,924'); seek(1236.0)">
              along with the custom images that AWS provides,
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:42,324'); seek(1242.0)">
              and then host it yourself.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:46,624'); seek(1246.0)">
              And this is a sample inference code that you can use to
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:50,448'); seek(1250.0)">
              deploy your own custom model.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:54,384'); seek(1254.0)">
              Now let's talk about some of the limitations of standalone LLMs.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:58,624'); seek(1258.0)">
              First, LLMs can sometimes produce content that is inaccurate
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:21:02,568'); seek(1262.0)">
              or completely fabricated, known as hallucinations.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:21:06,040'); seek(1266.0)">
              This can be problematic, especially in applications requiring precise
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:21:10,272'); seek(1270.0)">
              and reliable information. Secondly, LLMs struggle
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:21:14,394'); seek(1274.0)">
              with providing up to date information because they are trained on data
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:21:18,090'); seek(1278.0)">
              available up to a certain cutoff point.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:21,274'); seek(1281.0)">
              Any developments or changes that occur after this point
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:24,650'); seek(1284.0)">
              won't be reflected in their responses.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:28,274'); seek(1288.0)">
              Another challenge is that general purpose LLMs often
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:31,490'); seek(1291.0)">
              have difficulty handling domain specific queries effectively.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:36,154'); seek(1296.0)">
              They might not have the specialized knowledge needed for
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:39,264'); seek(1299.0)">
              specific industries or fields without further customization.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:44,224'); seek(1304.0)">
              Limited contextual understanding is also a concern.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:48,104'); seek(1308.0)">
              LLMs may not always grasp the full context of complex
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:51,800'); seek(1311.0)">
              queries or conversations, leading to responses that are
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:55,528'); seek(1315.0)">
              off target or incomplete. Ethical and
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:59,224'); seek(1319.0)">
              bias issues are significant as well. These models
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:22:02,656'); seek(1322.0)">
              can sometimes produce biased or ethically questionable
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:22:06,652'); seek(1326.0)">
              outputs reflecting biases present in the training data.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:22:11,404'); seek(1331.0)">
              Fine tuning large LLMs to improve their performance
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:22:15,444'); seek(1335.0)">
              for specific tasks requires substantial computational resources,
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:22:19,772'); seek(1339.0)">
              which can be costly and time consuming.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:22:23,204'); seek(1343.0)">
              Lastly, handling of potentially sensitive data underscores
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:22:27,252'); seek(1347.0)">
              the importance of stringent data governance.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:34,864'); seek(1354.0)">
              For the limitations that were discussed in the previous slide, we can have
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:38,312'); seek(1358.0)">
              a system called rag to reduce the problems
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:42,152'); seek(1362.0)">
              caused by the hallucinations. What is Rac rag
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:45,992'); seek(1365.0)">
              is basically a advanced AI approach that combines the strength
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:49,264'); seek(1369.0)">
              of retrieval systems with generative models.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:52,544'); seek(1372.0)">
              It aims to enhance the capabilities of LLMs by grounding
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:56,544'); seek(1376.0)">
              generated responses in factual information retrieved from
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:23:00,574'); seek(1380.0)">
              knowledge basis. How does a rack work?
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:23:04,614'); seek(1384.0)">
              It has two components, retrieval component and generative component.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:23:07,910'); seek(1387.0)">
              The retrieval system features relevant documents or
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:23:11,334'); seek(1391.0)">
              pieces of information from a predefined knowledge base based on
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:23:15,238'); seek(1395.0)">
              the user's query. Techniques such as
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:23:19,022'); seek(1399.0)">
              keyword matching, semantic search, or vector based retrieval ensures
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:23:23,172'); seek(1403.0)">
              accurate and contextually relevant information is being retrieved.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:27,060'); seek(1407.0)">
              The second component is a generative component.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:23:32,004'); seek(1412.0)">
              The generative model typically in LLM uses these retrieved
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:35,716'); seek(1415.0)">
              information from the retrieval component to generate
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:39,284'); seek(1419.0)">
              coherent and contextually enriched responses.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:42,804'); seek(1422.0)">
              This integration allows the LLM to provide answers that are
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:46,268'); seek(1426.0)">
              not fluently, that are not only fluent, but all but also
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:50,076'); seek(1430.0)">
              contextually relevant.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:54,004'); seek(1434.0)">
              What are the coming to the benefits of Frag?
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:57,564'); seek(1437.0)">
              The first one is the improved accuracy.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:24:01,684'); seek(1441.0)">
              By incorporating retriever retrieved factual information,
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:24:05,404'); seek(1445.0)">
              Rag significantly reduces the likelihood of generating incorrect
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:24:08,844'); seek(1448.0)">
              responses. And by providing
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:24:12,572'); seek(1452.0)">
              more context from the information that is retrieved by the retrieval component,
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:24:16,372'); seek(1456.0)">
              you can have more contextual relevance on
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:24:20,088'); seek(1460.0)">
              the responses that you get.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:24:24,424'); seek(1464.0)">
              Like the limitation that was discussed earlier, the knowledge cut
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:27,552'); seek(1467.0)">
              off. You can use the rag. You can populate
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:24:31,280'); seek(1471.0)">
              the rag with up to date information to get the up to
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:34,808'); seek(1474.0)">
              date knowledge and ask queries based on that up to
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:38,400'); seek(1478.0)">
              date knowledge.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:48,364'); seek(1488.0)">
              And how do you implement a Rag?
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:51,380'); seek(1491.0)">
              Typically it contains four steps. First one is selecting a
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:54,756'); seek(1494.0)">
              knowledge database. This is a company's internal
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:57,964'); seek(1497.0)">
              database. You can have it as a vector database. You can have it as a
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:25:01,876'); seek(1501.0)">
              keyword store or anything where you can comprehensively
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:25:06,484'); seek(1506.0)">
              put all the documents that are relevant to your company or
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:25:10,772'); seek(1510.0)">
              for the domain. Then next step is the data preparation.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:25:14,068'); seek(1514.0)">
              You clean up the data, have the data structured,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:25:18,020'); seek(1518.0)">
              choose a good storage solution where you can
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:25:21,420'); seek(1521.0)">
              efficiently retrieve the data on demand.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:25:24,844'); seek(1524.0)">
              So techniques such as vector based search are
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:25:29,332'); seek(1529.0)">
              techniques to store the knowledge as embeddings
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:25:32,828'); seek(1532.0)">
              would help a lot in this particular step.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:25:36,544'); seek(1536.0)">
              There are custom solutions available in the market like
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:39,920'); seek(1539.0)">
              AWS open search and AWS document
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:44,512'); seek(1544.0)">
              DB to store these documents. There is another
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:47,960'); seek(1547.0)">
              system called Pinecone which is a popular
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:51,736'); seek(1551.0)">
              vector database.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:54,824'); seek(1554.0)">
              You can index all the documents that are relevant to your company's
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:58,312'); seek(1558.0)">
              knowledge into that vector database as embeddings using one
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:26:01,808'); seek(1561.0)">
              of the FIAS storage techniques
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:26:06,192'); seek(1566.0)">
              using the fyess engine and then use KNN to basically retrieve those
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:26:09,352'); seek(1569.0)">
              documents. Then third part is the retrieval develop
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:26:13,264'); seek(1573.0)">
              the retrieval system. This system, usually we aim
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:26:16,768'); seek(1576.0)">
              to be very fast, so we try to
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:26:20,320'); seek(1580.0)">
              do a KNN search on the database.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:26:24,200'); seek(1584.0)">
              Typically a KNN search or you can probably do a semantic search
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:26:28,344'); seek(1588.0)">
              or a keyword based search. The retrieval system has to be
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:26:31,888'); seek(1591.0)">
              fast to give the documents more relevant documents
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:26:36,014'); seek(1596.0)">
              so that you can plug it into the LLM as part of its context.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:26:40,214'); seek(1600.0)">
              The fourth is the combining the retrieval responses and
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:44,350'); seek(1604.0)">
              adding it as a input query to the LLM before forming
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:48,630'); seek(1608.0)">
              your question. So apart
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:56,422'); seek(1616.0)">
              from the knowledge limitations that are also typically cost concerns and around
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:27:02,302'); seek(1622.0)">
              the LLMs, typically these LLMs are resource
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:27:06,094'); seek(1626.0)">
              intensive. They require high computational requirements.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:27:09,246'); seek(1629.0)">
              For example, the Lama three 8 billion parameter model
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:27:13,318'); seek(1633.0)">
              and 70 billion parameter model. You would need
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:27:16,518'); seek(1636.0)">
              a minimum of g 512 x large for the 8 billion parameter model and p
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:27:22,870'); seek(1642.0)">
              large for the 70 billion parameter model. And you're looking at
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:27:26,086'); seek(1646.0)">
              a cost of $7 per hour for the twelve x largest
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:27:29,664'); seek(1649.0)">
              and $37 for the 24 x largest.
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:27:33,240'); seek(1653.0)">
              And they have four to eight Nvidia
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:27:37,040'); seek(1657.0)">
              GPU's of different configurations.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:27:40,504'); seek(1660.0)">
              And second, you are looking at a high cost and
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:43,784'); seek(1663.0)">
              the maintaining maintenance of this knowledge basis.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:48,504'); seek(1668.0)">
              Typically if your knowledge base is huge like we
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:51,872'); seek(1671.0)">
              have it on my team, we have a
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:55,852'); seek(1675.0)">
              huge knowledge base of infringements of around 20 billion documents.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:59,804'); seek(1679.0)">
              Sorry, my bad, 2 billion documents that costs
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:28:03,428'); seek(1683.0)">
              us around million dollars a year. So unless
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:28:07,516'); seek(1687.0)">
              you choose some optimized ways of storing these documents, like IVF
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:28:11,812'); seek(1691.0)">
              flat format or IVF product
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:28:16,724'); seek(1696.0)">
              quantization techniques applied
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:28:20,100'); seek(1700.0)">
              to the document are choosing it as indexing strategies.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:28:23,988'); seek(1703.0)">
              While indexing will help a lot in reducing the cost,
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:28:28,324'); seek(1708.0)">
              the third is the operational maintenance costs. The maintenance
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:28:31,644'); seek(1711.0)">
              of LLMs is a significant factor because you have to scale up the
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:28:34,916'); seek(1714.0)">
              LLM according to your needs. You have to basically
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:28:38,156'); seek(1718.0)">
              fine tune it. It also, the fine tuning process
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:28:41,916'); seek(1721.0)">
              is also kind of slightly expensive because you would need
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:28:45,228'); seek(1725.0)">
              to procure more hosts for fine tuning and then typically
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:49,164'); seek(1729.0)">
              you run into availability issues.
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:55,364'); seek(1735.0)">
              Some of the cost reduction strategies that we can look at is basically
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:59,524'); seek(1739.0)">
              using if your system, if your
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:29:02,964'); seek(1742.0)">
              use cases do not warrant for a deployment of
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:29:07,844'); seek(1747.0)">
              a fine tuned model, then you can use pre trained models and
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:29:11,588'); seek(1751.0)">
              you can interact with them with APIs and other
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:29:15,074'); seek(1755.0)">
              offerings by the cloud service providers. Typically they charge you
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:29:18,418'); seek(1758.0)">
              by the request so you don't have to bear the upfront cost of hosting
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:29:22,962'); seek(1762.0)">
              it and keeping it alive.
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:29:27,034'); seek(1767.0)">
              Then you can also leverage foundation models of
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:29:30,610'); seek(1770.0)">
              model offerings by cloud service provider like AWS, bedrock and
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:29:34,058'); seek(1774.0)">
              Sagemaker. They have a good set of popular models where
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:29:37,722'); seek(1777.0)">
              you can directly use it without having to host it yourself. Then you
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:29:43,506'); seek(1783.0)">
              can optimize a large model into a smaller model
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:29:47,994'); seek(1787.0)">
              by model distillation, transfer the knowledge of the larger model to a smaller
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:29:51,682'); seek(1791.0)">
              model, distill that knowledge and then have a smaller model.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:55,354'); seek(1795.0)">
              Run your request, process your requests
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:58,642'); seek(1798.0)">
              and you can also do quantization by changing the precision
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:30:03,466'); seek(1803.0)">
              for the model from FP 32
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:30:06,842'); seek(1806.0)">
              to FP 16, which will bring down the memory.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:30:10,250'); seek(1810.0)">
              And you can also prune the model to remove the unnecessary weights
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:30:13,658'); seek(1813.0)">
              or layers and probably reduce the size of
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:30:16,826'); seek(1816.0)">
              the model significantly. Then for efficient
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:30:20,226'); seek(1820.0)">
              resource utilization, you can choose to configure
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:30:24,042'); seek(1824.0)">
              auto scaling, automated scale out
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:30:27,402'); seek(1827.0)">
              and scale in based on your traffic patterns. And then you can
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:30:31,242'); seek(1831.0)">
              batch more and then go with an asynchronous invocation
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:30:34,762'); seek(1834.0)">
              where you don't need the response immediately. You can reserve some of the instances
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:30:38,420'); seek(1838.0)">
              on Sagemaker and other cloud service providers so that you can procure
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:30:42,220'); seek(1842.0)">
              the host at a cheaper cost. You can cache your responses. These are some of
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:30:45,636'); seek(1845.0)">
              the strategies that you can employ then for the data management for
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:49,772'); seek(1849.0)">
              hosting knowledge databases are indexing solutions. You have
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:53,804'); seek(1853.0)">
              IVF flat, IVF PQ. You can prefer these
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:56,964'); seek(1856.0)">
              techniques indexing techniques instead of
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:31:00,420'); seek(1860.0)">
              storing the documents in HNSW format to
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:31:04,578'); seek(1864.0)">
              reduce the memory and thereby reducing your costs,
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:31:08,274'); seek(1868.0)">
              you can also use model cascading. You can deploy the smaller
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:31:14,450'); seek(1874.0)">
              versions of the model or low precision models at cheaper cost as
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:31:19,450'); seek(1879.0)">
              a filter. And then for those requests that come
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:31:23,330'); seek(1883.0)">
              out of these smaller models, you can probably use a complex
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:31:26,466'); seek(1886.0)">
              model to look at some of the complex patterns.
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:31:29,794'); seek(1889.0)">
              So just like a filtering technique, you can do the model
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:31:33,202'); seek(1893.0)">
              cascading as well.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:31:37,794'); seek(1897.0)">
              Prompt engineering is about crafting inputs that guide the
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:31:41,122'); seek(1901.0)">
              model towards the desired output. A good example
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:31:44,754'); seek(1904.0)">
              of an effective prompt should contain contextual information
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:31:48,794'); seek(1908.0)">
              about the task. Reference text for the task clear
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:52,754'); seek(1912.0)">
              and complete instruction clear instruction at
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:56,290'); seek(1916.0)">
              the end of the prompt and as an option, you can specify
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:32:00,168'); seek(1920.0)">
              the format of the output for
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:32:05,560'); seek(1925.0)">
              a task like text classification. Here is a good example by
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:32:09,424'); seek(1929.0)">
              anthropic cloud, where you have the description of the task,
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:32:13,992'); seek(1933.0)">
              reference text for the task, and the classification labels.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:32:21,944'); seek(1941.0)">
              Another example of question answer based prompt
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:32:26,074'); seek(1946.0)">
              you need to provide the instruction reference based text
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:32:30,282'); seek(1950.0)">
              and at the end you have a clear and concise question for
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:32:39,178'); seek(1959.0)">
              the text summarization task, you have the text for the
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:32:42,402'); seek(1962.0)">
              reference text and a clear instruction to summarize
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:32:46,426'); seek(1966.0)">
              it in the format you choose.
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:32:53,294'); seek(1973.0)">
              For code generation, a clear instruction on what you want,
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:32:57,342'); seek(1977.0)">
              and the specific programming language that you need the code to be in.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:33:05,934'); seek(1985.0)">
              Large language models offers a myriad of applications for
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:33:09,350'); seek(1989.0)">
              both software engineers and tech professionals. Let's explore
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:33:13,518'); seek(1993.0)">
              some of these practical uses. As a software engineer,
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:33:17,942'); seek(1997.0)">
              automated code generation can significantly speed up development by
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:33:21,934'); seek(2001.0)">
              handling repetitive tasks and providing code suggestions.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:33:25,574'); seek(2005.0)">
              For instance, GitHub copilot can generate code snippets
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:33:29,510'); seek(2009.0)">
              based on comments. LLMs assist
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:33:32,662'); seek(2012.0)">
              in code review and debugging by identifying potential bugs
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:33:36,254'); seek(2016.0)">
              and suggesting fix. Similar to tools like deep code and codeguru,
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:33:41,654'); seek(2021.0)">
              generating documentation becomes easier with LLMs,
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:33:45,110'); seek(2025.0)">
              which can create detailed doc strings, readme files,
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:33:48,478'); seek(2028.0)">
              and API documentation from the code base.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:33:52,624'); seek(2032.0)">
              Natural language interfaces allow for more intuitive software
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:33:56,528'); seek(2036.0)">
              interactions, enabling users to perform tasks using chatbots
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:34:00,296'); seek(2040.0)">
              or voice assistants. As a tech professional,
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:34:04,000'); seek(2044.0)">
              technical support is enhanced with AI driven chatbots that
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:34:08,264'); seek(2048.0)">
              provide first level support, reducing the burden on human teams
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:34:11,784'); seek(2051.0)">
              and improving response times.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:34:14,424'); seek(2054.0)">
              LLMs can analyze data, generate reports, and extract insights
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:34:18,611'); seek(2058.0)">
              from textual data, aiding in decision making and strategy
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:34:22,763'); seek(2062.0)">
              formulation. Content creation for marketing documentation
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:34:26,891'); seek(2066.0)">
              and internal communications can be automated,
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:34:30,123'); seek(2070.0)">
              streamlining workflows and ensuring consistency.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:34:34,243'); seek(2074.0)">
              Training programs powered by LLMs offer personalized learning experiences,
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:34:38,723'); seek(2078.0)">
              making knowledge sharing more efficient and interactive.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:34:44,174'); seek(2084.0)">
              In conclusion, by leveraging LLMs, both software engineers
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:34:47,862'); seek(2087.0)">
              and tech professionals can enhance productivity,
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:34:50,646'); seek(2090.0)">
              improve efficiency and innovate in their respective fields.
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:34:58,494'); seek(2098.0)">
              Coming to how we do it in our brand protection organization
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:35:03,302'); seek(2103.0)">
              how we leverage LLM we leverage LLM
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:35:06,694'); seek(2106.0)">
              for trademark and copyright wireless detections.
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:35:11,694'); seek(2111.0)">
              We analyze the brand names, logos and other intellectual properties
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:35:15,678'); seek(2115.0)">
              on the product listings and we
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:35:19,558'); seek(2119.0)">
              try to identify the brands to whom the trademarks belongs
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:35:22,918'); seek(2122.0)">
              to. We have a corpus of trademarks
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:35:26,702'); seek(2126.0)">
              and copyrights belonging to the brands for it for,
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:35:30,542'); seek(2130.0)">
              I believe, trademarks for around 1 million,
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:35:33,430'); seek(2133.0)">
              sorry, around 100k brands and copyrights
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:35:36,884'); seek(2136.0)">
              and logos for another 50,000 brands.
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:35:41,524'); seek(2141.0)">
              For the counterfeit detection we do use LLMs to notice
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:35:46,372'); seek(2146.0)">
              to recognize subtle differences between genuine and fake product listings
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:35:50,652'); seek(2150.0)">
              and the lms are also very helpful in
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:35:54,532'); seek(2154.0)">
              detecting obfuscations like people who use n
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:35:57,980'); seek(2157.0)">
              one ke instead of Nike and for analyzing
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:36:01,612'); seek(2161.0)">
              behavioral and analytics of the seller behavior and
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:36:09,674'); seek(2169.0)">
              some of the real world examples that we have on our site,
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:36:14,074'); seek(2174.0)">
              the last one being ours. The first three are public now.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:36:17,674'); seek(2177.0)">
              I guess everybody
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:36:20,850'); seek(2180.0)">
              now can see review highlights on the product listings page
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:36:24,250'); seek(2184.0)">
              of Amazon you see a summary of what
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:36:28,194'); seek(2188.0)">
              customers say. Then there is a this
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:36:33,102'); seek(2193.0)">
              is early access for the offered offer to the sellers when
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:36:37,214'); seek(2197.0)">
              they create listings on Amazon.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:36:40,694'); seek(2200.0)">
              The LLMs can generate content based on very
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:36:44,534'); seek(2204.0)">
              small description of the product that you are selling.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:36:47,910'); seek(2207.0)">
              It can fill the gaps or it can fill more details about the product.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:36:51,734'); seek(2211.0)">
              Then Amazon pharmacy started
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:36:55,818'); seek(2215.0)">
              using this LLMs recently to answer questions more
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:37:00,002'); seek(2220.0)">
              quickly because the LLMs can now look at
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:37:03,634'); seek(2223.0)">
              the whole corpus of internal wikis and provide more info,
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:37:06,714'); seek(2226.0)">
              more information on the drugs, and much more.
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:37:11,674'); seek(2231.0)">
              Quickly then in our space, we reduce the human
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:37:15,714'); seek(2235.0)">
              audits for detecting infringements by 80% for famous brands like Apple,
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:37:19,426'); seek(2239.0)">
              et cetera.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:37:22,554'); seek(2242.0)">
              For hard to find copyright violations,
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:37:26,354'); seek(2246.0)">
              we run the LLM for around 1
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:37:31,290'); seek(2251.0)">
              million products a day.
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:37:35,514'); seek(2255.0)">
              And the final output coming out of the LLMs
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:37:39,178'); seek(2259.0)">
              that is flagged for deeper look
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:37:43,954'); seek(2263.0)">
              is around 20% of those 1
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:37:48,090'); seek(2268.0)">
              million. So around two hundred k.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:37:53,154'); seek(2273.0)">
              And finally, thank you for this opportunity.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Satyanand%20Kale%20%26%20Gayathri%20Shivaraj%20-%20Conf42%20Observability%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Satyanand%20Kale%20%26%20Gayathri%20Shivaraj%20-%20Conf42%20Observability%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #A8AC51;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/obs2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #A8AC51;">
                <i class="fe fe-grid me-2"></i>
                See all 22 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Satyanand%20Kale%20%26%20Gayathri%20Shivaraj_obs.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Satyanand Kale
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Software Development Engineer @ Amazon
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/satyanand-kale-a8002183/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Satyanand Kale's LinkedIn account" />
                  </a>
                  
                  
                </p>
                
                <!-- Author 2 -->
                <h2 class="me-2">
                  Gayathri Shivaraj
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Program Manager @ Amazon
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-8">
                  
                  <a href="https://www.linkedin.com/in/gayathri-shivaraj-9b700b7/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Gayathri Shivaraj's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Satyanand Kale"
                  data-url="https://www.conf42.com/obs2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/obs2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Observability"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>