<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Natural language modelling with Amazon SageMaker BlazingText algorithm</title>
    <meta name="description" content="Like the Machines need our help to take over the world">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/ml_dinesh.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Natural language modelling with Amazon SageMaker BlazingText algorithm | Conf42"/>
    <meta property="og:description" content="In this session, we showcase the power of machine learning in taking a large corpus of a foreign language text (we use the entire Wikipedia) and automatically learning word embeddings for that language.   This is typically the first key step in building natural language processing (NLP) solutions, such as text classification or topic modelling. You see how easy it is to apply the BlazingText algorithm built into Amazon SageMaker in order to process the entire contents of Wikipedia in this language and visualize the results. You then can apply these learnings to any language of your choice."/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2021_Dinesh_Subramani_Natural_language_modelling_Amazon_SageMaker_BlazingText_algor"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/DEVSECOPS2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        DevSecOps 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-12-05
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/devsecops2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2021 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Like the Machines need our help to take over the world
 -->
              <script>
                const event_date = new Date("2021-07-29T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2021-07-29T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "Ta5Lq2kbiQQ"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "h6kzwaBwrCY"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrD02X7IKNNxFMy_K8oEejAu" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello everyone, welcome to this session on natural language mod link with", "timestamp": "00:00:22,010", "timestamp_s": 22.0}, {"text": "Amazon, sagemaker and blazing text algorithm. My name", "timestamp": "00:00:25,628", "timestamp_s": 25.0}, {"text": "is Dinesh Kumar. I\u0027m an aspiring ML specialist and", "timestamp": "00:00:29,068", "timestamp_s": 29.0}, {"text": "I\u0027m hoping to convince by end of this session that you don\u0027t need machine learning", "timestamp": "00:00:32,412", "timestamp_s": 32.0}, {"text": "degree to take advantage of tooling AWS has put", "timestamp": "00:00:36,460", "timestamp_s": 36.0}, {"text": "at your disposal. Now, as part of this session,", "timestamp": "00:00:39,712", "timestamp_s": 39.0}, {"text": "we will pick a language purposefully, a foreign language likely", "timestamp": "00:00:43,542", "timestamp_s": 43.0}, {"text": "unfamiliar to you, and apply machine learnings to create some magic.", "timestamp": "00:00:47,462", "timestamp_s": 47.0}, {"text": "We will use the language of Tamar. The Tamar language is one of the world\u0027s", "timestamp": "00:00:51,638", "timestamp_s": 51.0}, {"text": "longest surviving classical language with a history dating back", "timestamp": "00:00:55,802", "timestamp_s": 55.0}, {"text": "to 300 bc. Tamar as a language is rich in literature and", "timestamp": "00:00:59,332", "timestamp_s": 59.0}, {"text": "one of the language that has evolved over thousands of years.", "timestamp": "00:01:03,012", "timestamp_s": 63.0}, {"text": "The reason I picked it is I\u0027m familiar with this language and", "timestamp": "00:01:06,068", "timestamp_s": 66.0}, {"text": "I was keen to see whether machine learnings was able to figure out the relationship", "timestamp": "00:01:09,672", "timestamp_s": 69.0}, {"text": "between the words of this language and I want to", "timestamp": "00:01:13,368", "timestamp_s": 73.0}, {"text": "apply known machine learning algorithm such as lacing text,", "timestamp": "00:01:16,588", "timestamp_s": 76.0}, {"text": "in this case within Sagemaker to discover these relationships.", "timestamp": "00:01:20,076", "timestamp_s": 80.0}, {"text": "What\u0027s cool about today\u0027s talk also", "timestamp": "00:01:23,602", "timestamp_s": 83.0}, {"text": "is you will be able to apply these", "timestamp": "00:01:26,924", "timestamp_s": 86.0}, {"text": "techniques post this session to", "timestamp": "00:01:30,656", "timestamp_s": 90.0}, {"text": "the language of your own choice and discover", "timestamp": "00:01:33,856", "timestamp_s": 93.0}, {"text": "the relationships yourselves. Now, what are the prerequisites for this", "timestamp": "00:01:38,262", "timestamp_s": 98.0}, {"text": "session? It will be good to have fundamentals of the", "timestamp": "00:01:41,732", "timestamp_s": 101.0}, {"text": "machine learning or deep learning and understanding", "timestamp": "00:01:45,124", "timestamp_s": 105.0}, {"text": "of typical natural language processing problems,", "timestamp": "00:01:49,402", "timestamp_s": 109.0}, {"text": "ie search and some familiarity with AWS services.", "timestamp": "00:01:53,112", "timestamp_s": 113.0}, {"text": "Not necessarily sagemaker. I will surely cover that as", "timestamp": "00:01:57,272", "timestamp_s": 117.0}, {"text": "part of my session and then knowledge of python or numpy.", "timestamp": "00:02:00,488", "timestamp_s": 120.0}, {"text": "As long as you know any other coding language, this is straightforward,", "timestamp": "00:02:04,814", "timestamp_s": 124.0}, {"text": "you would not be lost and these knowledge", "timestamp": "00:02:08,578", "timestamp_s": 128.0}, {"text": "of Jupyter environment notebook environment as such would", "timestamp": "00:02:12,258", "timestamp_s": 132.0}, {"text": "be very handy. Now in order to", "timestamp": "00:02:16,108", "timestamp_s": 136.0}, {"text": "get this magic happen, we need to introduce word embedding with", "timestamp": "00:02:19,180", "timestamp_s": 139.0}, {"text": "word to vec algorithm. Then we need to understand bit about Amazon Sagemaker", "timestamp": "00:02:23,424", "timestamp_s": 143.0}, {"text": "and its unique capabilities, especially around NLP area. Then we can", "timestamp": "00:02:27,638", "timestamp_s": 147.0}, {"text": "spend bulk of our time with building text algorithm and a quick", "timestamp": "00:02:31,472", "timestamp_s": 151.0}, {"text": "demo. So that takes us to these interesting topic", "timestamp": "00:02:35,252", "timestamp_s": 155.0}, {"text": "of word embedding. Let\u0027s dive into word embedding, natural language,", "timestamp": "00:02:39,002", "timestamp_s": 159.0}, {"text": "text, contents of words and so we need to represent", "timestamp": "00:02:42,762", "timestamp_s": 162.0}, {"text": "individual words, sentences and collection of", "timestamp": "00:02:46,046", "timestamp_s": 166.0}, {"text": "words in some way. Now couldn\u0027t we just use strings", "timestamp": "00:02:49,592", "timestamp_s": 169.0}, {"text": "containing the words? First of all, words have different lengths", "timestamp": "00:02:53,086", "timestamp_s": 173.0}, {"text": "and even written representations differ dramatically from language to", "timestamp": "00:02:57,234", "timestamp_s": 177.0}, {"text": "language. So if you look at the", "timestamp": "00:03:00,892", "timestamp_s": 180.0}, {"text": "language of Tamil, some words might be mentioned", "timestamp": "00:03:05,148", "timestamp_s": 185.0}, {"text": "in a different way in different region of Tamil", "timestamp": "00:03:09,136", "timestamp_s": 189.0}, {"text": "Nadu, while the same words will", "timestamp": "00:03:12,438", "timestamp_s": 192.0}, {"text": "have different representation or different way of being pronounced", "timestamp": "00:03:16,656", "timestamp_s": 196.0}, {"text": "or spelled in different region.", "timestamp": "00:03:20,986", "timestamp_s": 200.0}, {"text": "Now, with these complications and", "timestamp": "00:03:24,266", "timestamp_s": 204.0}, {"text": "added to that, more importantly, many machine learning techniques", "timestamp": "00:03:27,956", "timestamp_s": 207.0}, {"text": "require numeric rather than text input as you would obviously.", "timestamp": "00:03:31,642", "timestamp_s": 211.0}, {"text": "You know, computers are good with numbers and", "timestamp": "00:03:35,784", "timestamp_s": 215.0}, {"text": "may not be with natural language vocabulary like us.", "timestamp": "00:03:39,576", "timestamp_s": 219.0}, {"text": "So that brings us to the topic of representing", "timestamp": "00:03:43,336", "timestamp_s": 223.0}, {"text": "these words in a numerical form. So if I want to represent", "timestamp": "00:03:46,542", "timestamp_s": 226.0}, {"text": "this particular phrase, you see there to be or not to be in a numerical", "timestamp": "00:03:50,322", "timestamp_s": 230.0}, {"text": "form, how can I go about it? Let\u0027s say I", "timestamp": "00:03:54,322", "timestamp_s": 234.0}, {"text": "represent each of it with an individual label. Let\u0027s say", "timestamp": "00:03:57,756", "timestamp_s": 237.0}, {"text": "I represent two with zero, b with one, or with two,", "timestamp": "00:04:01,200", "timestamp_s": 241.0}, {"text": "not with three. Now that gives me zero, one, two, these zero,", "timestamp": "00:04:04,576", "timestamp_s": 244.0}, {"text": "one, a random set of numbers. Now, this particular way", "timestamp": "00:04:07,856", "timestamp_s": 247.0}, {"text": "of representing it with just unique labels is actually going to create", "timestamp": "00:04:11,748", "timestamp_s": 251.0}, {"text": "or introduce random relationships. For example,", "timestamp": "00:04:15,890", "timestamp_s": 255.0}, {"text": "b as a word is now closer to two", "timestamp": "00:04:22,290", "timestamp_s": 262.0}, {"text": "and r but away from not.", "timestamp": "00:04:25,656", "timestamp_s": 265.0}, {"text": "Is that true? No. So how did we even arrive at", "timestamp": "00:04:28,664", "timestamp_s": 268.0}, {"text": "these labels when there is no such relationship?", "timestamp": "00:04:32,168", "timestamp_s": 272.0}, {"text": "So just randomly naming them with numerical label may", "timestamp": "00:04:35,450", "timestamp_s": 275.0}, {"text": "not be great way of solving the problem. Now let\u0027s", "timestamp": "00:04:39,228", "timestamp_s": 279.0}, {"text": "say we use vector", "timestamp": "00:04:42,498", "timestamp_s": 282.0}, {"text": "instead of single number. Typical approach is to use one, not encoding.", "timestamp": "00:04:45,586", "timestamp_s": 285.0}, {"text": "Here each word access an index into a vector of all zeros", "timestamp": "00:04:49,362", "timestamp_s": 289.0}, {"text": "with only a single element set to one. Now you", "timestamp": "00:04:52,838", "timestamp_s": 292.0}, {"text": "would have already guessed these problem with one out encoding approach.", "timestamp": "00:04:56,352", "timestamp_s": 296.0}, {"text": "The example here is having just four words, and a typical", "timestamp": "00:04:59,750", "timestamp_s": 299.0}, {"text": "language will have hundreds and thousands of words. In case of Tamar,", "timestamp": "00:05:03,766", "timestamp_s": 303.0}, {"text": "I don\u0027t have account, but it\u0027s a very rich language, as I said earlier,", "timestamp": "00:05:07,466", "timestamp_s": 307.0}, {"text": "and there is quite a lot of words to its vocabulary. So representing them", "timestamp": "00:05:11,386", "timestamp_s": 311.0}, {"text": "by ones and zeros may not be the efficient way of actually", "timestamp": "00:05:15,592", "timestamp_s": 315.0}, {"text": "solving the problem in hand.", "timestamp": "00:05:20,390", "timestamp_s": 320.0}, {"text": "Now with that in mind, let\u0027s look", "timestamp": "00:05:22,936", "timestamp_s": 322.0}, {"text": "at the other side of the coin. Given a sentence,", "timestamp": "00:05:26,268", "timestamp_s": 326.0}, {"text": "what is our chances of maximizing the probability", "timestamp": "00:05:31,130", "timestamp_s": 331.0}, {"text": "of predicting the context words? Let\u0027s say I introduce", "timestamp": "00:05:34,514", "timestamp_s": 334.0}, {"text": "this word, Tom Hanks. How can I predict the", "timestamp": "00:05:38,754", "timestamp_s": 338.0}, {"text": "context of this word? In this example? Let\u0027s say we want", "timestamp": "00:05:42,832", "timestamp_s": 342.0}, {"text": "to predict the context of Tom Hanks. What is the probability that somewhere", "timestamp": "00:05:45,888", "timestamp_s": 345.0}, {"text": "around Tom Hanks we will find words? Great. Can actor", "timestamp": "00:05:49,782", "timestamp_s": 349.0}, {"text": "quite a lot because he\u0027s an actor. So there is quite a lot of chances", "timestamp": "00:05:53,418", "timestamp_s": 353.0}, {"text": "that those words would appear somewhere near", "timestamp": "00:05:57,402", "timestamp_s": 357.0}, {"text": "Tom Hanks. But what is the chances of me finding something like", "timestamp": "00:06:00,644", "timestamp_s": 360.0}, {"text": "quantum physics next to Tom Hanks? Maybe very less.", "timestamp": "00:06:04,440", "timestamp_s": 364.0}, {"text": "I would not say zero, but it is relatively less", "timestamp": "00:06:08,470", "timestamp_s": 368.0}, {"text": "when you compare it to word actor. Now that\u0027s the point we are trying", "timestamp": "00:06:12,408", "timestamp_s": 372.0}, {"text": "to actually make. How do I figure out that", "timestamp": "00:06:15,628", "timestamp_s": 375.0}, {"text": "this particular word has more relationship and", "timestamp": "00:06:19,436", "timestamp_s": 379.0}, {"text": "hence contextually more closer to this word.", "timestamp": "00:06:23,452", "timestamp_s": 383.0}, {"text": "In typically deep learning world,", "timestamp": "00:06:27,276", "timestamp_s": 387.0}, {"text": "we will actually have a fully connected network.", "timestamp": "00:06:30,816", "timestamp_s": 390.0}, {"text": "So for every input word it receives, let\u0027s say a", "timestamp": "00:06:34,438", "timestamp_s": 394.0}, {"text": "vocabulary has 10,000 words, and if we receive one word,", "timestamp": "00:06:38,048", "timestamp_s": 398.0}, {"text": "then the output", "timestamp": "00:06:41,988", "timestamp_s": 401.0}, {"text": "of this network should be able to figure out what are those", "timestamp": "00:06:45,498", "timestamp_s": 405.0}, {"text": "words within those 10,000 words this particular input", "timestamp": "00:06:50,210", "timestamp_s": 410.0}, {"text": "word is closer to. So there will be lot of", "timestamp": "00:06:53,918", "timestamp_s": 413.0}, {"text": "hidden layers of network that will try to", "timestamp": "00:06:57,592", "timestamp_s": 417.0}, {"text": "extract the contents words and then it\u0027ll spit out the", "timestamp": "00:07:01,048", "timestamp_s": 421.0}, {"text": "probability of the words that might sit", "timestamp": "00:07:04,872", "timestamp_s": 424.0}, {"text": "contextually closer to that input word. After training such", "timestamp": "00:07:08,476", "timestamp_s": 428.0}, {"text": "a network, we can now quickly compute denser output vector for a", "timestamp": "00:07:11,708", "timestamp_s": 431.0}, {"text": "sparse input vector that we had after our 1 hour ten coding.", "timestamp": "00:07:15,244", "timestamp_s": 435.0}, {"text": "So we have now grasped a bit about the problem itself", "timestamp": "00:07:19,010", "timestamp_s": 439.0}, {"text": "that we are trying to solve. The problem statement is we", "timestamp": "00:07:22,800", "timestamp_s": 442.0}, {"text": "want to understand the probability of a", "timestamp": "00:07:26,416", "timestamp_s": 446.0}, {"text": "word being in closer relationship with,", "timestamp": "00:07:30,308", "timestamp_s": 450.0}, {"text": "or probability of having set of words that", "timestamp": "00:07:33,812", "timestamp_s": 453.0}, {"text": "are in close relationship to the input word that is coming", "timestamp": "00:07:38,052", "timestamp_s": 458.0}, {"text": "in for inference. Now it\u0027s time to understand about the word to veg", "timestamp": "00:07:41,476", "timestamp_s": 461.0}, {"text": "algorithm itself. So, dimensionality of the", "timestamp": "00:07:45,502", "timestamp_s": 465.0}, {"text": "output vector is a parameter we choose. This is why we said embeddings", "timestamp": "00:07:49,048", "timestamp_s": 469.0}, {"text": "high dimensional object, one not encoded word, in this case", "timestamp": "00:07:52,862", "timestamp_s": 472.0}, {"text": "into small dimensional space. Turning a sparse vector into a much denser", "timestamp": "00:07:56,232", "timestamp_s": 476.0}, {"text": "representation is what we are trying to achieve. Once this representation is", "timestamp": "00:08:00,018", "timestamp_s": 480.0}, {"text": "computed, we can simply convert every word into an n", "timestamp": "00:08:03,852", "timestamp_s": 483.0}, {"text": "dimensional space. In the end,", "timestamp": "00:08:07,452", "timestamp_s": 487.0}, {"text": "words that appear in similar context will likely be", "timestamp": "00:08:11,008", "timestamp_s": 491.0}, {"text": "mapped to similar vectors. Words close to each other in vector", "timestamp": "00:08:14,432", "timestamp_s": 494.0}, {"text": "space are likely to be similar in meaning as they tend to be used in", "timestamp": "00:08:17,702", "timestamp_s": 497.0}, {"text": "similar context. This is where we are getting closer to", "timestamp": "00:08:21,248", "timestamp_s": 501.0}, {"text": "these magic a machine learning system automatically discovering", "timestamp": "00:08:24,724", "timestamp_s": 504.0}, {"text": "words that appear to have similar meaning. In theory,", "timestamp": "00:08:27,962", "timestamp_s": 507.0}, {"text": "we also expect certain vector relationships to hold. This doesn\u0027t", "timestamp": "00:08:31,402", "timestamp_s": 511.0}, {"text": "have to be exact and depends totally on the carcass being", "timestamp": "00:08:35,438", "timestamp_s": 515.0}, {"text": "used for training. We can help to discover word relationships with", "timestamp": "00:08:38,776", "timestamp_s": 518.0}, {"text": "transitive properties, as shown on the slide. For example,", "timestamp": "00:08:42,456", "timestamp_s": 522.0}, {"text": "if we take a vector that corresponds to word king,", "timestamp": "00:08:46,088", "timestamp_s": 526.0}, {"text": "that\u0027s a classic example that we usually see.", "timestamp": "00:08:49,234", "timestamp_s": 529.0}, {"text": "Let\u0027s say I have found a vector for the word king and subtract", "timestamp": "00:08:53,290", "timestamp_s": 533.0}, {"text": "vector for the word man.", "timestamp": "00:08:57,682", "timestamp_s": 537.0}, {"text": "I get a meaning that says there is some sort", "timestamp": "00:09:02,830", "timestamp_s": 542.0}, {"text": "of royalty associated, and then if I add vector", "timestamp": "00:09:06,448", "timestamp_s": 546.0}, {"text": "of woman to it, I\u0027ve arrived at vector of queen.", "timestamp": "00:09:10,406", "timestamp_s": 550.0}, {"text": "This is magic here because we have managed to", "timestamp": "00:09:13,818", "timestamp_s": 553.0}, {"text": "understand the meaning of a word and then doing typical", "timestamp": "00:09:17,556", "timestamp_s": 557.0}, {"text": "addition subtraction that we play with numbers, but in this case", "timestamp": "00:09:21,626", "timestamp_s": 561.0}, {"text": "with words and their inherent meaning that", "timestamp": "00:09:25,032", "timestamp_s": 565.0}, {"text": "they bring with it. So that\u0027s exactly", "timestamp": "00:09:28,568", "timestamp_s": 568.0}, {"text": "what word to vec algorithm is actually trying to solve.", "timestamp": "00:09:32,008", "timestamp_s": 572.0}, {"text": "You may have heard about new models such as Bert, Roberta,", "timestamp": "00:09:36,046", "timestamp_s": 576.0}, {"text": "but the end goal is to achieve the word embeddings.", "timestamp": "00:09:39,170", "timestamp_s": 579.0}, {"text": "Yeah, I\u0027ll probably show you this", "timestamp": "00:09:42,418", "timestamp_s": 582.0}, {"text": "completed word embedding for english language.", "timestamp": "00:09:46,890", "timestamp_s": 586.0}, {"text": "And this has been mapped into 100 dimensional vector.", "timestamp": "00:09:50,590", "timestamp_s": 590.0}, {"text": "How can we visualize this result high daily on a two dimensional", "timestamp": "00:09:54,054", "timestamp_s": 594.0}, {"text": "picture? This is where we probably could use another", "timestamp": "00:09:57,590", "timestamp_s": 597.0}, {"text": "trick of trade. T distributed stochastic neighbor", "timestamp": "00:10:01,620", "timestamp_s": 601.0}, {"text": "embedding plot. Now that might be a", "timestamp": "00:10:05,418", "timestamp_s": 605.0}, {"text": "bunch of words, but it\u0027s just simple way of telling", "timestamp": "00:10:09,028", "timestamp_s": 609.0}, {"text": "that we now have way to visualize all", "timestamp": "00:10:12,522", "timestamp_s": 612.0}, {"text": "those relationships in a two dimensional space.", "timestamp": "00:10:16,056", "timestamp_s": 616.0}, {"text": "As you see here, the model has", "timestamp": "00:10:19,816", "timestamp_s": 619.0}, {"text": "now figured out american, british, English,", "timestamp": "00:10:23,192", "timestamp_s": 623.0}, {"text": "London, England, French, France, German. Now all of", "timestamp": "00:10:25,906", "timestamp_s": 625.0}, {"text": "these are closer to each other. It has mapped", "timestamp": "00:10:29,452", "timestamp_s": 629.0}, {"text": "that they all can contextually appear closer", "timestamp": "00:10:33,426", "timestamp_s": 633.0}, {"text": "or they are all related in some form or shape. And these clusters", "timestamp": "00:10:37,266", "timestamp_s": 637.0}, {"text": "are interesting clusters that it has figured out because", "timestamp": "00:10:41,590", "timestamp_s": 641.0}, {"text": "of the corpus that was thrown at it. The very", "timestamp": "00:10:45,536", "timestamp_s": 645.0}, {"text": "important one I would probably show is if you see there,", "timestamp": "00:10:48,736", "timestamp_s": 648.0}, {"text": "it has found out that there is relationship between son,", "timestamp": "00:10:53,090", "timestamp_s": 653.0}, {"text": "family, children, father, death, life.", "timestamp": "00:10:56,884", "timestamp_s": 656.0}, {"text": "It is able to actually figure out that these", "timestamp": "00:11:02,130", "timestamp_s": 662.0}, {"text": "words are related and are closer", "timestamp": "00:11:06,536", "timestamp_s": 666.0}, {"text": "in context. And there is more probability", "timestamp": "00:11:09,678", "timestamp_s": 669.0}, {"text": "of a word from this particular cluster appearing next", "timestamp": "00:11:12,878", "timestamp_s": 672.0}, {"text": "to a word that has just come, that it has just come across.", "timestamp": "00:11:17,132", "timestamp_s": 677.0}, {"text": "Now, enough of the word to vec and", "timestamp": "00:11:21,468", "timestamp_s": 681.0}, {"text": "word embedding the actual problem statement that we were trying", "timestamp": "00:11:25,052", "timestamp_s": 685.0}, {"text": "to solve. Let\u0027s try to understand the toolings that are at our disposal", "timestamp": "00:11:28,588", "timestamp_s": 688.0}, {"text": "and how sage maker itself as a service is able to help", "timestamp": "00:11:32,230", "timestamp_s": 692.0}, {"text": "us with in solving this problem. And our placing text", "timestamp": "00:11:36,032", "timestamp_s": 696.0}, {"text": "algorithm then fits into it. This is a typical AAML", "timestamp": "00:11:39,936", "timestamp_s": 699.0}, {"text": "stack. In the top you see AI services.", "timestamp": "00:11:43,898", "timestamp_s": 703.0}, {"text": "Most of these services are out of box services", "timestamp": "00:11:47,172", "timestamp_s": 707.0}, {"text": "in the sense you do not need to have any sort of machine learning skill.", "timestamp": "00:11:51,188", "timestamp_s": 711.0}, {"text": "Let\u0027s say you are a team of developers", "timestamp": "00:11:55,038", "timestamp_s": 715.0}, {"text": "who are having zero skill with machine learning, but want", "timestamp": "00:11:59,470", "timestamp_s": 719.0}, {"text": "to actually see how you could use it for your", "timestamp": "00:12:02,968", "timestamp_s": 722.0}, {"text": "own application or a problem", "timestamp": "00:12:06,396", "timestamp_s": 726.0}, {"text": "or a workload that you have. Then these are", "timestamp": "00:12:10,076", "timestamp_s": 730.0}, {"text": "some go to AI services. These are across different areas.", "timestamp": "00:12:13,628", "timestamp_s": 733.0}, {"text": "For example, we have AI services for vision, speech language,", "timestamp": "00:12:17,842", "timestamp_s": 737.0}, {"text": "chatbots, forecasting recommendations. All you need to do is an API", "timestamp": "00:12:21,366", "timestamp_s": 741.0}, {"text": "call. These are models that are up and running and are always", "timestamp": "00:12:25,382", "timestamp_s": 745.0}, {"text": "learning because so many of our other customers are using it.", "timestamp": "00:12:28,896", "timestamp_s": 748.0}, {"text": "And you will be able to just, with an API call,", "timestamp": "00:12:32,420", "timestamp_s": 752.0}, {"text": "get the inferences back. And you do not have to go", "timestamp": "00:12:35,860", "timestamp_s": 755.0}, {"text": "down the route of building a model, training it,", "timestamp": "00:12:39,668", "timestamp_s": 759.0}, {"text": "validating it and monitoring it of any sort,", "timestamp": "00:12:43,236", "timestamp_s": 763.0}, {"text": "you\u0027re just going to consume it. But let\u0027s say you are a bunch of", "timestamp": "00:12:47,430", "timestamp_s": 767.0}, {"text": "developers who are already actually into machine learning and want", "timestamp": "00:12:51,400", "timestamp_s": 771.0}, {"text": "to make your life simple, then that\u0027s where ML services", "timestamp": "00:12:54,712", "timestamp_s": 774.0}, {"text": "with Amazon Sagemaker as a platform would come into picture.", "timestamp": "00:12:59,450", "timestamp_s": 779.0}, {"text": "Amazon Sagemaker is a platform that was built ground up", "timestamp": "00:13:03,538", "timestamp_s": 783.0}, {"text": "for developers. The primary ambition was", "timestamp": "00:13:07,532", "timestamp_s": 787.0}, {"text": "to actually make machine learning development easy for developers,", "timestamp": "00:13:11,008", "timestamp_s": 791.0}, {"text": "and hence there are lot of services that", "timestamp": "00:13:14,806", "timestamp_s": 794.0}, {"text": "it packs that makes the development lifecycle", "timestamp": "00:13:18,208", "timestamp_s": 798.0}, {"text": "lot easier than it was before.", "timestamp": "00:13:22,902", "timestamp_s": 802.0}, {"text": "We will dive into that part in detail, but otherwise,", "timestamp": "00:13:26,290", "timestamp_s": 806.0}, {"text": "if you are experts and if you want to actually do", "timestamp": "00:13:29,626", "timestamp_s": 809.0}, {"text": "it at your own pace,", "timestamp": "00:13:33,416", "timestamp_s": 813.0}, {"text": "the frameworks of your choice, and then", "timestamp": "00:13:37,310", "timestamp_s": 817.0}, {"text": "we completely support Tensorflow, Mxnet and all those popular", "timestamp": "00:13:41,240", "timestamp_s": 821.0}, {"text": "frameworks, and quite a lot of instances", "timestamp": "00:13:44,782", "timestamp_s": 824.0}, {"text": "and GPU", "timestamp": "00:13:48,722", "timestamp_s": 828.0}, {"text": "based instances that are available for you to leverage.", "timestamp": "00:13:52,258", "timestamp_s": 832.0}, {"text": "But we would primarily focus on Sagemaker as a platform", "timestamp": "00:13:55,362", "timestamp_s": 835.0}, {"text": "as part of these session, because it\u0027s a very big world", "timestamp": "00:13:58,944", "timestamp_s": 838.0}, {"text": "to explore on its own. So let\u0027s just take ourselves to", "timestamp": "00:14:02,816", "timestamp_s": 842.0}, {"text": "the main hero of today\u0027s subject,", "timestamp": "00:14:07,390", "timestamp_s": 847.0}, {"text": "Sagemaker. So amazing. Sagemaker. As I said,", "timestamp": "00:14:10,118", "timestamp_s": 850.0}, {"text": "you can build, train and deploy ML models", "timestamp": "00:14:14,130", "timestamp_s": 854.0}, {"text": "at scale. Now at scale is the key term", "timestamp": "00:14:17,738", "timestamp_s": 857.0}, {"text": "there. Whatever be the part of your journey,", "timestamp": "00:14:21,322", "timestamp_s": 861.0}, {"text": "either it be building or training or deploying.", "timestamp": "00:14:24,222", "timestamp_s": 864.0}, {"text": "For each of these stages, Sagemaker as", "timestamp": "00:14:28,030", "timestamp_s": 868.0}, {"text": "a platform offers you the right set of APIs with", "timestamp": "00:14:31,272", "timestamp_s": 871.0}, {"text": "bunch of python code. You will be able", "timestamp": "00:14:35,208", "timestamp_s": 875.0}, {"text": "to build your model, train your model, validate your", "timestamp": "00:14:38,716", "timestamp_s": 878.0}, {"text": "model and deploy it. And of course, AWS, part of", "timestamp": "00:14:42,332", "timestamp_s": 882.0}, {"text": "today\u0027s demo, we will show you how it is being done,", "timestamp": "00:14:46,028", "timestamp_s": 886.0}, {"text": "but that\u0027s how easy it is to get going in Sagemaker.", "timestamp": "00:14:49,632", "timestamp_s": 889.0}, {"text": "So to start with, we offer pre", "timestamp": "00:14:53,910", "timestamp_s": 893.0}, {"text": "built notebooks. These pre built notebooks examples", "timestamp": "00:14:58,032", "timestamp_s": 898.0}, {"text": "are very much available within sagemaker environment. In your own AWS", "timestamp": "00:15:01,802", "timestamp_s": 901.0}, {"text": "console, machine learning developers can just use these examples to", "timestamp": "00:15:05,962", "timestamp_s": 905.0}, {"text": "start experimenting for their own specific use cases.", "timestamp": "00:15:09,972", "timestamp_s": 909.0}, {"text": "So if you are actually new to sagemaker, you do not have", "timestamp": "00:15:13,594", "timestamp_s": 913.0}, {"text": "to start from scratch. You could leverage these pre built notebook", "timestamp": "00:15:16,888", "timestamp_s": 916.0}, {"text": "examples and use that as a", "timestamp": "00:15:20,606", "timestamp_s": 920.0}, {"text": "starter to explore the sagemaker environment.", "timestamp": "00:15:24,168", "timestamp_s": 924.0}, {"text": "Now, let\u0027s say you explored it and you", "timestamp": "00:15:27,410", "timestamp_s": 927.0}, {"text": "want to actually move forward. Then once you settle in", "timestamp": "00:15:32,012", "timestamp_s": 932.0}, {"text": "with your training data, of course, that\u0027s these most important bit.", "timestamp": "00:15:35,852", "timestamp_s": 935.0}, {"text": "Your models are as good as your training data. So quite", "timestamp": "00:15:39,804", "timestamp_s": 939.0}, {"text": "a lot of our customers spend a lot of time in ensuring", "timestamp": "00:15:44,112", "timestamp_s": 944.0}, {"text": "they have the right data. Let\u0027s say you have the right data, training data", "timestamp": "00:15:47,302", "timestamp_s": 947.0}, {"text": "that you need. You then need to choose right algorithms", "timestamp": "00:15:51,056", "timestamp_s": 951.0}, {"text": "that will have to actually go with them. Now, when it comes", "timestamp": "00:15:54,646", "timestamp_s": 954.0}, {"text": "down to algorithm. We have lots of choices within", "timestamp": "00:15:58,212", "timestamp_s": 958.0}, {"text": "these sage maker world. As you see either it", "timestamp": "00:16:02,628", "timestamp_s": 962.0}, {"text": "be regression or classification, or image", "timestamp": "00:16:06,008", "timestamp_s": 966.0}, {"text": "vision based aa models. You have quite a lot", "timestamp": "00:16:10,870", "timestamp_s": 970.0}, {"text": "of built algorithms that comes very handy. These algorithms", "timestamp": "00:16:14,824", "timestamp_s": 974.0}, {"text": "are in the form of containers. All you need to do is", "timestamp": "00:16:18,706", "timestamp_s": 978.0}, {"text": "actually refer to the container registry and pull the", "timestamp": "00:16:22,332", "timestamp_s": 982.0}, {"text": "right container for this algorithms, and then you should", "timestamp": "00:16:26,348", "timestamp_s": 986.0}, {"text": "be get going with it. Otherwise,", "timestamp": "00:16:29,968", "timestamp_s": 989.0}, {"text": "if none of these existing built in algorithms does", "timestamp": "00:16:33,590", "timestamp_s": 993.0}, {"text": "not cater to your needs, you could always bring in your own algorithms", "timestamp": "00:16:37,008", "timestamp_s": 997.0}, {"text": "in the form of containers and leverage", "timestamp": "00:16:41,306", "timestamp_s": 1001.0}, {"text": "the sagemaker as a platform. Now, what\u0027s unique about", "timestamp": "00:16:46,290", "timestamp_s": 1006.0}, {"text": "these inbuilt algorithms is that they could actually take advantage", "timestamp": "00:16:52,390", "timestamp_s": 1012.0}, {"text": "of distributed computing infrastructure", "timestamp": "00:16:56,126", "timestamp_s": 1016.0}, {"text": "we have in cloud. And you", "timestamp": "00:17:00,302", "timestamp_s": 1020.0}, {"text": "might sometimes find the equivalent of these algorithms", "timestamp": "00:17:06,908", "timestamp_s": 1026.0}, {"text": "in open source as well. But the ones", "timestamp": "00:17:11,058", "timestamp_s": 1031.0}, {"text": "that are inbuilt with Sagemaker are validated", "timestamp": "00:17:15,788", "timestamp_s": 1035.0}, {"text": "for their efficiency in utilizing the distributed", "timestamp": "00:17:20,134", "timestamp_s": 1040.0}, {"text": "compute environment and infrastructure that the cloud offers. And hence it is", "timestamp": "00:17:23,558", "timestamp_s": 1043.0}, {"text": "always relatively lot performant than the", "timestamp": "00:17:27,552", "timestamp_s": 1047.0}, {"text": "open source version of the equivalent algorithm you will find out", "timestamp": "00:17:31,268", "timestamp_s": 1051.0}, {"text": "in the market, in the open source market. So let\u0027s", "timestamp": "00:17:34,452", "timestamp_s": 1054.0}, {"text": "say you determine the algorithm,", "timestamp": "00:17:38,362", "timestamp_s": 1058.0}, {"text": "then you need to train the", "timestamp": "00:17:41,978", "timestamp_s": 1061.0}, {"text": "model. So you will want to tell", "timestamp": "00:17:45,316", "timestamp_s": 1065.0}, {"text": "the number of missions you want to use for your training purpose.", "timestamp": "00:17:48,920", "timestamp_s": 1068.0}, {"text": "You can then kick start the training with just one line of python", "timestamp": "00:17:51,790", "timestamp_s": 1071.0}, {"text": "code. Yes, you heard it right, it is just one line of", "timestamp": "00:17:55,598", "timestamp_s": 1075.0}, {"text": "python code within your sage maker SDK or", "timestamp": "00:17:58,828", "timestamp_s": 1078.0}, {"text": "click in a console. And that\u0027s all it takes to actually", "timestamp": "00:18:03,052", "timestamp_s": 1083.0}, {"text": "get the training going. And you can actually do", "timestamp": "00:18:07,290", "timestamp_s": 1087.0}, {"text": "your training and create your model out of it.", "timestamp": "00:18:10,912", "timestamp_s": 1090.0}, {"text": "These are so many deep learning framework containers that", "timestamp": "00:18:14,190", "timestamp_s": 1094.0}, {"text": "are supported in Sagemaker. So it", "timestamp": "00:18:17,488", "timestamp_s": 1097.0}, {"text": "uses docker containers, as I said earlier, that\u0027s designed for", "timestamp": "00:18:20,688", "timestamp_s": 1100.0}, {"text": "that specific algorithm, and that\u0027s designed to support that particular framework.", "timestamp": "00:18:23,748", "timestamp_s": 1103.0}, {"text": "So let\u0027s say you have a particular algorithm in Tensorflow that", "timestamp": "00:18:27,242", "timestamp_s": 1107.0}, {"text": "you want to use for your use case. Then you", "timestamp": "00:18:30,932", "timestamp_s": 1110.0}, {"text": "will find a container for that particular framework,", "timestamp": "00:18:34,212", "timestamp_s": 1114.0}, {"text": "for that particular algorithm. And as long as you", "timestamp": "00:18:37,662", "timestamp_s": 1117.0}, {"text": "actually refer to that in your code, you will be able to pick and run", "timestamp": "00:18:40,792", "timestamp_s": 1120.0}, {"text": "with it. What you do is when executing the training,", "timestamp": "00:18:43,432", "timestamp_s": 1123.0}, {"text": "as I said, you just select the right container and provide the data in", "timestamp": "00:18:47,830", "timestamp_s": 1127.0}, {"text": "form of a file in simple storage service. Now what Sagemaker", "timestamp": "00:18:51,852", "timestamp_s": 1131.0}, {"text": "would do is launch cluster of training machines.", "timestamp": "00:18:55,458", "timestamp_s": 1135.0}, {"text": "And again, it will not just launch a lot of machines,", "timestamp": "00:18:58,418", "timestamp_s": 1138.0}, {"text": "you do not have to worry about the cost, it just launches the", "timestamp": "00:19:01,622", "timestamp_s": 1141.0}, {"text": "number of machines you are told within your code", "timestamp": "00:19:04,752", "timestamp_s": 1144.0}, {"text": "and the type of instances that you have advised for it", "timestamp": "00:19:08,688", "timestamp_s": 1148.0}, {"text": "to pick up for the trading purpose, and then use", "timestamp": "00:19:11,984", "timestamp_s": 1151.0}, {"text": "those machines to train with the data that it", "timestamp": "00:19:15,236", "timestamp_s": 1155.0}, {"text": "has from s three. Now, it can also perform distributed training.", "timestamp": "00:19:18,868", "timestamp_s": 1158.0}, {"text": "As I said earlier, if it", "timestamp": "00:19:22,516", "timestamp_s": 1162.0}, {"text": "is distributed, you can train it in multiple instances, or you", "timestamp": "00:19:26,328", "timestamp_s": 1166.0}, {"text": "could always choose to train it in single machine", "timestamp": "00:19:30,008", "timestamp_s": 1170.0}, {"text": "and end of the day, the output, the resulting model", "timestamp": "00:19:33,534", "timestamp_s": 1173.0}, {"text": "will be back in s three. So you could always actually", "timestamp": "00:19:37,564", "timestamp_s": 1177.0}, {"text": "look at the model and see how accurate", "timestamp": "00:19:42,410", "timestamp_s": 1182.0}, {"text": "is the model giving inferences,", "timestamp": "00:19:47,010", "timestamp_s": 1187.0}, {"text": "and then decide to go ahead or not, or retrain the model", "timestamp": "00:19:51,478", "timestamp_s": 1191.0}, {"text": "again with new set of data. Now,", "timestamp": "00:19:55,040", "timestamp_s": 1195.0}, {"text": "what if the model is not optimal enough? As I said,", "timestamp": "00:19:59,390", "timestamp_s": 1199.0}, {"text": "there are so many optimization techniques that are available for", "timestamp": "00:20:02,724", "timestamp_s": 1202.0}, {"text": "you now.", "timestamp": "00:20:05,972", "timestamp_s": 1205.0}, {"text": "Usually, let\u0027s say you create a model and", "timestamp": "00:20:10,050", "timestamp_s": 1210.0}, {"text": "it is not really performing well. What the", "timestamp": "00:20:13,992", "timestamp_s": 1213.0}, {"text": "usual ML developers do is actually they tune", "timestamp": "00:20:18,616", "timestamp_s": 1218.0}, {"text": "the hyperparameters associated with that algorithm.", "timestamp": "00:20:22,078", "timestamp_s": 1222.0}, {"text": "So for people who may not know what are these? There is usually", "timestamp": "00:20:25,910", "timestamp_s": 1225.0}, {"text": "a bunch of parameters that contents behavior of a given algorithm.", "timestamp": "00:20:29,228", "timestamp_s": 1229.0}, {"text": "Often machine learning developers are left in dark as to", "timestamp": "00:20:32,834", "timestamp_s": 1232.0}, {"text": "what value should they use for these different parameters to get their model", "timestamp": "00:20:35,932", "timestamp_s": 1235.0}, {"text": "optimized. That\u0027s where automated model tuning comes to the", "timestamp": "00:20:39,600", "timestamp_s": 1239.0}, {"text": "rescue. The reality is even machine learning practitioners", "timestamp": "00:20:42,848", "timestamp_s": 1242.0}, {"text": "themselves, even experienced ones,", "timestamp": "00:20:46,886", "timestamp_s": 1246.0}, {"text": "often don\u0027t know what to do. In these cases, they just rely on", "timestamp": "00:20:50,080", "timestamp_s": 1250.0}, {"text": "random grid based hyperparameter", "timestamp": "00:20:56,370", "timestamp_s": 1256.0}, {"text": "choosing strategy.", "timestamp": "00:21:00,210", "timestamp_s": 1260.0}, {"text": "Now, Sagemaker allows you to do that by kicking", "timestamp": "00:21:03,030", "timestamp_s": 1263.0}, {"text": "off the so called hyperparameter optimization job,", "timestamp": "00:21:07,038", "timestamp_s": 1267.0}, {"text": "and you specify how many machines it needs to run", "timestamp": "00:21:10,872", "timestamp_s": 1270.0}, {"text": "on to control the cost. And ultimately it helps you identify the", "timestamp": "00:21:14,632", "timestamp_s": 1274.0}, {"text": "right parameters to optimize your model. It does it with the bayesian", "timestamp": "00:21:18,284", "timestamp_s": 1278.0}, {"text": "search algorithm. Basically, let\u0027s say it", "timestamp": "00:21:21,922", "timestamp_s": 1281.0}, {"text": "ran the training with bunch of parameters and", "timestamp": "00:21:26,140", "timestamp_s": 1286.0}, {"text": "it gets a model accuracy and it is not", "timestamp": "00:21:30,156", "timestamp_s": 1290.0}, {"text": "fitting the built it will now remember what are the parameters that it", "timestamp": "00:21:33,632", "timestamp_s": 1293.0}, {"text": "ran with in the previous iteration, and hence choose to", "timestamp": "00:21:36,928", "timestamp_s": 1296.0}, {"text": "deviate away or go towards it based", "timestamp": "00:21:40,692", "timestamp_s": 1300.0}, {"text": "on the iteration and the learning", "timestamp": "00:21:44,276", "timestamp_s": 1304.0}, {"text": "that it\u0027s picking up. It is not efficient way of actually tuning", "timestamp": "00:21:48,530", "timestamp_s": 1308.0}, {"text": "the model, and many of our customers leverage this", "timestamp": "00:21:52,878", "timestamp_s": 1312.0}, {"text": "for their machine learning training", "timestamp": "00:21:56,232", "timestamp_s": 1316.0}, {"text": "purpose. Amazon Sagemaker Neo is something that I would briefly touch", "timestamp": "00:22:00,280", "timestamp_s": 1320.0}, {"text": "on with Neo. You can compile your models to be ported", "timestamp": "00:22:04,216", "timestamp_s": 1324.0}, {"text": "to any of the target processes you may choose to run your model on.", "timestamp": "00:22:07,630", "timestamp_s": 1327.0}, {"text": "This way your model would not only be smaller", "timestamp": "00:22:11,100", "timestamp_s": 1331.0}, {"text": "and deployment ready built, also more performant. So it doesn\u0027t", "timestamp": "00:22:14,642", "timestamp_s": 1334.0}, {"text": "matter which end architecture you want to port", "timestamp": "00:22:18,738", "timestamp_s": 1338.0}, {"text": "your model to. Neo may help you do that and you will also", "timestamp": "00:22:22,496", "timestamp_s": 1342.0}, {"text": "be actually carry your model with you and deploy", "timestamp": "00:22:25,872", "timestamp_s": 1345.0}, {"text": "it in lot lighter form in any architecture", "timestamp": "00:22:29,558", "timestamp_s": 1349.0}, {"text": "of your choice. And the list of architectures to which you could port it", "timestamp": "00:22:33,498", "timestamp_s": 1353.0}, {"text": "to is always being added on. So you", "timestamp": "00:22:36,868", "timestamp_s": 1356.0}, {"text": "could always check our AWS pages to figure out what", "timestamp": "00:22:39,988", "timestamp_s": 1359.0}, {"text": "are the ones that we support. So let\u0027s say we", "timestamp": "00:22:44,392", "timestamp_s": 1364.0}, {"text": "have got the data, we trained the model, we have validated", "timestamp": "00:22:48,888", "timestamp_s": 1368.0}, {"text": "the model after the fine tuning thanks to hyperparameter", "timestamp": "00:22:53,022", "timestamp_s": 1373.0}, {"text": "optimization, and we have now got the right accuracy", "timestamp": "00:22:57,602", "timestamp_s": 1377.0}, {"text": "and performance we needed to deploy this in production.", "timestamp": "00:23:01,698", "timestamp_s": 1381.0}, {"text": "Now, what we will see as", "timestamp": "00:23:06,482", "timestamp_s": 1386.0}, {"text": "part of the demo as well is that", "timestamp": "00:23:10,592", "timestamp_s": 1390.0}, {"text": "with one line of python code, you can take this model to production.", "timestamp": "00:23:14,224", "timestamp_s": 1394.0}, {"text": "You can then manage the same and easily scale with Amazon", "timestamp": "00:23:17,766", "timestamp_s": 1397.0}, {"text": "Web services. Now that\u0027s the beauty of Sagemaker.", "timestamp": "00:23:21,482", "timestamp_s": 1401.0}, {"text": "Everything is simplified for the", "timestamp": "00:23:25,970", "timestamp_s": 1405.0}, {"text": "developers to leverage this distributed", "timestamp": "00:23:29,556", "timestamp_s": 1409.0}, {"text": "computing platform and focus", "timestamp": "00:23:33,342", "timestamp_s": 1413.0}, {"text": "on the business outcomes that they want,", "timestamp": "00:23:38,280", "timestamp_s": 1418.0}, {"text": "rather than all the undifferentiated heavy lifting", "timestamp": "00:23:41,336", "timestamp_s": 1421.0}, {"text": "they will have to do in building,", "timestamp": "00:23:44,782", "timestamp_s": 1424.0}, {"text": "training and validating these models.", "timestamp": "00:23:49,004", "timestamp_s": 1429.0}, {"text": "So that\u0027s the bet with", "timestamp": "00:23:51,850", "timestamp_s": 1431.0}, {"text": "Sage maker that I wanted to cover before we dive into", "timestamp": "00:23:56,044", "timestamp_s": 1436.0}, {"text": "the world of blazingtext algorithm.", "timestamp": "00:24:00,400", "timestamp_s": 1440.0}, {"text": "So as I said, blazing text algorithm", "timestamp": "00:24:03,766", "timestamp_s": 1443.0}, {"text": "was published back in 2017 by", "timestamp": "00:24:07,542", "timestamp_s": 1447.0}, {"text": "a couple of Amazonians. This is the paper that was", "timestamp": "00:24:12,196", "timestamp_s": 1452.0}, {"text": "released back in 2017 to", "timestamp": "00:24:15,652", "timestamp_s": 1455.0}, {"text": "discuss how the blazing text algorithm will go about this", "timestamp": "00:24:20,212", "timestamp_s": 1460.0}, {"text": "particular problem. Now, key thing to", "timestamp": "00:24:25,112", "timestamp_s": 1465.0}, {"text": "note these is this algorithm provides highly optimized implementation", "timestamp": "00:24:28,328", "timestamp_s": 1468.0}, {"text": "of word to Vic and text classification algorithm.", "timestamp": "00:24:32,222", "timestamp_s": 1472.0}, {"text": "Using blazing text. You can train a model with more than billion of", "timestamp": "00:24:35,646", "timestamp_s": 1475.0}, {"text": "words in probably a couple of minutes using", "timestamp": "00:24:39,212", "timestamp_s": 1479.0}, {"text": "multicore cpu or GPU, and you can achieve performance on par with state", "timestamp": "00:24:43,356", "timestamp_s": 1483.0}, {"text": "of art deep learning text classification algorithms", "timestamp": "00:24:47,516", "timestamp_s": 1487.0}, {"text": "out there. So the other important thing that", "timestamp": "00:24:50,742", "timestamp_s": 1490.0}, {"text": "it offers is an implementation of supervised", "timestamp": "00:24:54,992", "timestamp_s": 1494.0}, {"text": "multiclass, multilabel text classification algorithm,", "timestamp": "00:24:58,614", "timestamp_s": 1498.0}, {"text": "extending the fast text algorithm implementation by using", "timestamp": "00:25:01,978", "timestamp_s": 1501.0}, {"text": "GPU acceleration with custom CuDA kernels, but also relying on", "timestamp": "00:25:05,684", "timestamp_s": 1505.0}, {"text": "multiple cpus for certain modes of operating this algorithm.", "timestamp": "00:25:09,428", "timestamp_s": 1509.0}, {"text": "In this particular demo, we will be using distributed", "timestamp": "00:25:14,950", "timestamp_s": 1514.0}, {"text": "training, just so you know.", "timestamp": "00:25:20,142", "timestamp_s": 1520.0}, {"text": "But there is no hard role.", "timestamp": "00:25:22,744", "timestamp_s": 1522.0}, {"text": "You could always do it in single machine if that suffice", "timestamp": "00:25:26,290", "timestamp_s": 1526.0}, {"text": "your needs. These are some of the highlights of", "timestamp": "00:25:29,698", "timestamp_s": 1529.0}, {"text": "blazingtext that I would love to highlight.", "timestamp": "00:25:33,724", "timestamp_s": 1533.0}, {"text": "As I said, you can run with single cpu instances, you can run with multiple", "timestamp": "00:25:37,058", "timestamp_s": 1537.0}, {"text": "GPU acceleration if needed.", "timestamp": "00:25:41,430", "timestamp_s": 1541.0}, {"text": "And these interesting", "timestamp": "00:25:45,630", "timestamp_s": 1545.0}, {"text": "thing that you would see from these slide is it can be 21 times faster", "timestamp": "00:25:49,230", "timestamp_s": 1549.0}, {"text": "and 20% cheaper than fast text on a", "timestamp": "00:25:53,370", "timestamp_s": 1553.0}, {"text": "single c four. And if", "timestamp": "00:25:56,708", "timestamp_s": 1556.0}, {"text": "you go down the distributed training route, it can achieve", "timestamp": "00:26:01,348", "timestamp_s": 1561.0}, {"text": "a training speed of up to 50 million words per second.", "timestamp": "00:26:05,418", "timestamp_s": 1565.0}, {"text": "Now this is speed of eleven times over one", "timestamp": "00:26:08,728", "timestamp_s": 1568.0}, {"text": "c four lodge that we saw in the previous one, which is amazing,", "timestamp": "00:26:12,296", "timestamp_s": 1572.0}, {"text": "actually, the kind of efficiency that", "timestamp": "00:26:15,708", "timestamp_s": 1575.0}, {"text": "these have actually managed to harness", "timestamp": "00:26:21,388", "timestamp_s": 1581.0}, {"text": "from blazing text algorithm is amazing. Now how do they do that", "timestamp": "00:26:25,794", "timestamp_s": 1585.0}, {"text": "in our demo? As I said, we will use blazing", "timestamp": "00:26:30,750", "timestamp_s": 1590.0}, {"text": "text on multiple cpus. But even within single cpu, blazing text", "timestamp": "00:26:34,438", "timestamp_s": 1594.0}, {"text": "takes certain steps to optimize its performance. And that\u0027s", "timestamp": "00:26:38,496", "timestamp_s": 1598.0}, {"text": "what we are seeing here.", "timestamp": "00:26:42,538", "timestamp_s": 1602.0}, {"text": "It uses blast two by intel", "timestamp": "00:26:46,770", "timestamp_s": 1606.0}, {"text": "and hence it is a", "timestamp": "00:26:50,698", "timestamp_s": 1610.0}, {"text": "lot more optimized in terms of cpu utilization.", "timestamp": "00:26:53,704", "timestamp_s": 1613.0}, {"text": "And as you see here, this picture", "timestamp": "00:26:57,742", "timestamp_s": 1617.0}, {"text": "is showing how we", "timestamp": "00:27:02,158", "timestamp_s": 1622.0}, {"text": "are optimizing bird to vec by sharing the k negative", "timestamp": "00:27:05,468", "timestamp_s": 1625.0}, {"text": "samples across using the blast to", "timestamp": "00:27:09,042", "timestamp_s": 1629.0}, {"text": "advantage that we have from intel. Now this is a", "timestamp": "00:27:12,970", "timestamp_s": 1632.0}, {"text": "slide that compares the throughput of 1 billion bird", "timestamp": "00:27:17,068", "timestamp_s": 1637.0}, {"text": "benchmark data set. Over here you are seeing", "timestamp": "00:27:21,046", "timestamp_s": 1641.0}, {"text": "throughput characteristics of the blazingtext right hand", "timestamp": "00:27:24,624", "timestamp_s": 1644.0}, {"text": "side you see implementation of fast text, sort of what", "timestamp": "00:27:27,968", "timestamp_s": 1647.0}, {"text": "is published out there. Because fast text is not able", "timestamp": "00:27:31,248", "timestamp_s": 1651.0}, {"text": "to be distributed on multiple cpus or gpus, we are", "timestamp": "00:27:34,756", "timestamp_s": 1654.0}, {"text": "running it for benchmarking on single machine. Now you can", "timestamp": "00:27:38,564", "timestamp_s": 1658.0}, {"text": "compare and contrast the performance when you look at left hand side where the algorithm", "timestamp": "00:27:41,812", "timestamp_s": 1661.0}, {"text": "has been run on multiple multicore gpu machines. And in the middle", "timestamp": "00:27:45,678", "timestamp_s": 1665.0}, {"text": "section where you see the yellow bars, we have performed batch", "timestamp": "00:27:49,336", "timestamp_s": 1669.0}, {"text": "skip gram benchmarking. And again here you are seeing the results of", "timestamp": "00:27:52,622", "timestamp_s": 1672.0}, {"text": "running algorithm in distributed fashion on multiple cpus.", "timestamp": "00:27:56,072", "timestamp_s": 1676.0}, {"text": "But of course throughput is always not the only factor that you", "timestamp": "00:27:59,530", "timestamp_s": 1679.0}, {"text": "would choose to run with a particular algorithm", "timestamp": "00:28:02,908", "timestamp_s": 1682.0}, {"text": "because we also need to consider accuracy and cost.", "timestamp": "00:28:06,722", "timestamp_s": 1686.0}, {"text": "So I would love to actually show you another set", "timestamp": "00:28:10,176", "timestamp_s": 1690.0}, {"text": "of benchmark results.", "timestamp": "00:28:13,952", "timestamp_s": 1693.0}, {"text": "Basically, as you see here,", "timestamp": "00:28:18,510", "timestamp_s": 1698.0}, {"text": "I think the right way to interpret this diagram", "timestamp": "00:28:21,650", "timestamp_s": 1701.0}, {"text": "is that the circle that we see", "timestamp": "00:28:25,562", "timestamp_s": 1705.0}, {"text": "here is the throughput. And when", "timestamp": "00:28:29,124", "timestamp_s": 1709.0}, {"text": "you compare number eight and number two,", "timestamp": "00:28:33,928", "timestamp_s": 1713.0}, {"text": "sorry, I think these number", "timestamp": "00:28:37,688", "timestamp_s": 1717.0}, {"text": "eight is the one that was run by", "timestamp": "00:28:41,576", "timestamp_s": 1721.0}, {"text": "skip Graham blazing text. So yes, what I", "timestamp": "00:28:45,464", "timestamp_s": 1725.0}, {"text": "said is right, if you compare number eight and number two,", "timestamp": "00:28:49,324", "timestamp_s": 1729.0}, {"text": "you get lot of throughput, you get lot of accuracy.", "timestamp": "00:28:53,290", "timestamp_s": 1733.0}, {"text": "In fact, almost same accuracy for very less cost.", "timestamp": "00:28:56,690", "timestamp_s": 1736.0}, {"text": "The horizontal axis here is cost. The vertical", "timestamp": "00:29:01,550", "timestamp_s": 1741.0}, {"text": "axis here is accuracy. The size of the circle denotes the throughput", "timestamp": "00:29:04,806", "timestamp_s": 1744.0}, {"text": "that that particular algorithm is able to achieve with", "timestamp": "00:29:08,950", "timestamp_s": 1748.0}, {"text": "the given configuration.", "timestamp": "00:29:12,772", "timestamp_s": 1752.0}, {"text": "So it just goes on to confirm", "timestamp": "00:29:15,338", "timestamp_s": 1755.0}, {"text": "the previous claim we had that", "timestamp": "00:29:20,290", "timestamp_s": 1760.0}, {"text": "it is a lot more performant and lot more cheaper when compared", "timestamp": "00:29:24,264", "timestamp_s": 1764.0}, {"text": "to our other fast text algorithm.", "timestamp": "00:29:28,462", "timestamp_s": 1768.0}, {"text": "With that we will move on to", "timestamp": "00:29:32,286", "timestamp_s": 1772.0}, {"text": "the demo part of our discussion,", "timestamp": "00:29:35,532", "timestamp_s": 1775.0}, {"text": "which is called as semurai in Tambur. By the", "timestamp": "00:29:39,730", "timestamp_s": 1779.0}, {"text": "way, let me bring the demo", "timestamp": "00:29:43,404", "timestamp_s": 1783.0}, {"text": "page for you. So hope you\u0027re able to", "timestamp": "00:29:47,740", "timestamp_s": 1787.0}, {"text": "see this. This is the", "timestamp": "00:29:51,168", "timestamp_s": 1791.0}, {"text": "notebook that I have created in Amazon", "timestamp": "00:29:55,150", "timestamp_s": 1795.0}, {"text": "Sagemaker. Now you could just go to Amazon", "timestamp": "00:29:58,758", "timestamp_s": 1798.0}, {"text": "Sagemaker service. I can probably", "timestamp": "00:30:03,098", "timestamp_s": 1803.0}, {"text": "show you that quickly.", "timestamp": "00:30:07,970", "timestamp_s": 1807.0}, {"text": "I think we\u0027ll just continue with the notebook because", "timestamp": "00:30:12,610", "timestamp_s": 1812.0}, {"text": "it might be a bit tricky for me to actually share that screen.", "timestamp": "00:30:16,744", "timestamp_s": 1816.0}, {"text": "So it\u0027s very simple.", "timestamp": "00:30:20,310", "timestamp_s": 1820.0}, {"text": "If you go to Amazon Sagemaker service within AWS console,", "timestamp": "00:30:23,496", "timestamp_s": 1823.0}, {"text": "you go to notebook that", "timestamp": "00:30:27,298", "timestamp_s": 1827.0}, {"text": "will be in your left panel and you create a Jupyter notebook.", "timestamp": "00:30:31,228", "timestamp_s": 1831.0}, {"text": "This is as simple as any Jupyter notebook", "timestamp": "00:30:35,218", "timestamp_s": 1835.0}, {"text": "that you would have seen, nothing special about it. And it", "timestamp": "00:30:38,882", "timestamp_s": 1838.0}, {"text": "is just an environment for, if someone is", "timestamp": "00:30:43,504", "timestamp_s": 1843.0}, {"text": "not aware of it. It is just an environment for data scientists to", "timestamp": "00:30:47,232", "timestamp_s": 1847.0}, {"text": "share and do more data science", "timestamp": "00:30:51,236", "timestamp_s": 1851.0}, {"text": "in a collaborative way.", "timestamp": "00:30:55,450", "timestamp_s": 1855.0}, {"text": "That\u0027s all about this environment. Now,", "timestamp": "00:30:58,690", "timestamp_s": 1858.0}, {"text": "if you look at this,", "timestamp": "00:31:02,210", "timestamp_s": 1862.0}, {"text": "as I said, we are going to actually take a large corpus of text", "timestamp": "00:31:05,750", "timestamp_s": 1865.0}, {"text": "in Tamil. We will use this large corpus of", "timestamp": "00:31:09,464", "timestamp_s": 1869.0}, {"text": "text for data ingestion purpose. Now, in this case,", "timestamp": "00:31:12,808", "timestamp_s": 1872.0}, {"text": "I have actually taken the dump from this", "timestamp": "00:31:16,152", "timestamp_s": 1876.0}, {"text": "particular URL. You could very well actually get it from whatever", "timestamp": "00:31:19,532", "timestamp_s": 1879.0}, {"text": "of your choice. But ideally, Aws, I said your", "timestamp": "00:31:23,772", "timestamp_s": 1883.0}, {"text": "model is as good as your data. So always please be", "timestamp": "00:31:26,892", "timestamp_s": 1886.0}, {"text": "careful with the data that you choose.", "timestamp": "00:31:32,110", "timestamp_s": 1892.0}, {"text": "In my case, I\u0027ve chosen it from wiki dump. It\u0027s totally up", "timestamp": "00:31:36,350", "timestamp_s": 1896.0}, {"text": "to you where you get it from, but more the data,", "timestamp": "00:31:40,128", "timestamp_s": 1900.0}, {"text": "more you could learn and actually the inferences", "timestamp": "00:31:43,890", "timestamp_s": 1903.0}, {"text": "could be a lot better. Now, we have downloaded this wiki", "timestamp": "00:31:47,770", "timestamp_s": 1907.0}, {"text": "dump. Now there is this wiki extractor py", "timestamp": "00:31:52,154", "timestamp_s": 1912.0}, {"text": "script created by Atadi.", "timestamp": "00:31:55,790", "timestamp_s": 1915.0}, {"text": "You could find it in GitHub. What we are doing", "timestamp": "00:31:59,030", "timestamp_s": 1919.0}, {"text": "here is we are actually passing the dump that we have got and", "timestamp": "00:32:02,792", "timestamp_s": 1922.0}, {"text": "we are doing extraction of that data.", "timestamp": "00:32:06,812", "timestamp_s": 1926.0}, {"text": "So we have downloaded that extractor", "timestamp": "00:32:11,244", "timestamp_s": 1931.0}, {"text": "script and we are using that extractor script to", "timestamp": "00:32:14,706", "timestamp_s": 1934.0}, {"text": "extract these information from the dump.", "timestamp": "00:32:18,800", "timestamp_s": 1938.0}, {"text": "So what this extractor would do is just cleanse the data and", "timestamp": "00:32:23,062", "timestamp_s": 1943.0}, {"text": "make it easy for us to do the machine learning model training.", "timestamp": "00:32:27,424", "timestamp_s": 1947.0}, {"text": "So as you see, it has picked up that file and it has actually given", "timestamp": "00:32:31,184", "timestamp_s": 1951.0}, {"text": "us the list of words that we could actually pass", "timestamp": "00:32:35,140", "timestamp_s": 1955.0}, {"text": "in for our training stage. So we have all", "timestamp": "00:32:39,636", "timestamp_s": 1959.0}, {"text": "these tamil words, mudarpakam, katirakalai, katirangalin,", "timestamp": "00:32:43,492", "timestamp_s": 1963.0}, {"text": "patiyal, poviyal, varala, arupuri. So these are", "timestamp": "00:32:47,274", "timestamp_s": 1967.0}, {"text": "all tamil words that it has picked up from the dump. Now,", "timestamp": "00:32:51,048", "timestamp_s": 1971.0}, {"text": "this is a very big dump that I had", "timestamp": "00:32:54,712", "timestamp_s": 1974.0}, {"text": "downloaded, so I didn\u0027t want to actually waste", "timestamp": "00:32:58,492", "timestamp_s": 1978.0}, {"text": "the time during the demo. And hence I have done that hard", "timestamp": "00:33:02,578", "timestamp_s": 1982.0}, {"text": "task of actually getting this downloaded and training", "timestamp": "00:33:07,036", "timestamp_s": 1987.0}, {"text": "the model prior to these session. So I\u0027ll", "timestamp": "00:33:10,560", "timestamp_s": 1990.0}, {"text": "just drag to the bottom of extraction", "timestamp": "00:33:14,022", "timestamp_s": 1994.0}, {"text": "part, or rather the cleanse part,", "timestamp": "00:33:18,438", "timestamp_s": 1998.0}, {"text": "and these we go. So the extractor is done.", "timestamp": "00:33:22,430", "timestamp_s": 2002.0}, {"text": "In fact, actually it was just going on for a long time.", "timestamp": "00:33:26,340", "timestamp_s": 2006.0}, {"text": "I thought I\u0027ve got enough data, so I just killed it", "timestamp": "00:33:29,492", "timestamp_s": 2009.0}, {"text": "and to get on with the next stage.", "timestamp": "00:33:33,124", "timestamp_s": 2013.0}, {"text": "But you can actually leave", "timestamp": "00:33:37,510", "timestamp_s": 2017.0}, {"text": "it for a long time if you want a lot more data.", "timestamp": "00:33:41,592", "timestamp_s": 2021.0}, {"text": "As I said, more the data, more it is good.", "timestamp": "00:33:46,010", "timestamp_s": 2026.0}, {"text": "Now this is where the sagemaker", "timestamp": "00:33:49,930", "timestamp_s": 2029.0}, {"text": "comes to party. If you see here, we are creating a sagemaker.", "timestamp": "00:33:53,474", "timestamp_s": 2033.0}, {"text": "We are importing the sagemaker SDK sagemaker.", "timestamp": "00:33:57,970", "timestamp_s": 2037.0}, {"text": "We are creating a sagemaker session and we are creating", "timestamp": "00:34:01,206", "timestamp_s": 2041.0}, {"text": "a default bucket that we will use for this", "timestamp": "00:34:05,222", "timestamp_s": 2045.0}, {"text": "particular training purpose.", "timestamp": "00:34:09,872", "timestamp_s": 2049.0}, {"text": "Now what we are doing is we are uploading the data.", "timestamp": "00:34:12,690", "timestamp_s": 2052.0}, {"text": "So the cleansed data that we", "timestamp": "00:34:16,196", "timestamp_s": 2056.0}, {"text": "now have got after running that wiki extractor Py", "timestamp": "00:34:19,988", "timestamp_s": 2059.0}, {"text": "is what is now being pushed to the bucket and", "timestamp": "00:34:23,342", "timestamp_s": 2063.0}, {"text": "we are also setting the output location for s three.", "timestamp": "00:34:27,288", "timestamp_s": 2067.0}, {"text": "Now those are the basic", "timestamp": "00:34:31,430", "timestamp_s": 2071.0}, {"text": "constructs that we need from the sage", "timestamp": "00:34:37,510", "timestamp_s": 2077.0}, {"text": "maker service before we could actually go about", "timestamp": "00:34:40,622", "timestamp_s": 2080.0}, {"text": "the algorithm side of things.", "timestamp": "00:34:46,330", "timestamp_s": 2086.0}, {"text": "Now, as I said,", "timestamp": "00:34:50,510", "timestamp_s": 2090.0}, {"text": "using the inbuilt algorithm is just one line of python", "timestamp": "00:34:53,950", "timestamp_s": 2093.0}, {"text": "code. And there you see we", "timestamp": "00:34:58,102", "timestamp_s": 2098.0}, {"text": "are from Sagemaker. We are importing", "timestamp": "00:35:02,788", "timestamp_s": 2102.0}, {"text": "image URis and we are saying image", "timestamp": "00:35:05,978", "timestamp_s": 2105.0}, {"text": "Blazingtext. Now this brings", "timestamp": "00:35:10,634", "timestamp_s": 2110.0}, {"text": "you pointer", "timestamp": "00:35:14,046", "timestamp_s": 2114.0}, {"text": "to the blazingtext algorithm.", "timestamp": "00:35:19,374", "timestamp_s": 2119.0}, {"text": "And here you see you are using Sagemaker", "timestamp": "00:35:23,910", "timestamp_s": 2123.0}, {"text": "blazing text container from EU west one.", "timestamp": "00:35:27,234", "timestamp_s": 2127.0}, {"text": "After we create the container object, which now essentially", "timestamp": "00:35:33,690", "timestamp_s": 2133.0}, {"text": "holds the kind of algorithm that it is going to apply for this", "timestamp": "00:35:37,778", "timestamp_s": 2137.0}, {"text": "training purpose. Again, as I said in this case we have chosen basing", "timestamp": "00:35:41,472", "timestamp_s": 2141.0}, {"text": "text. You could either go and choose some", "timestamp": "00:35:45,014", "timestamp_s": 2145.0}, {"text": "other built algorithm of your choice within", "timestamp": "00:35:49,568", "timestamp_s": 2149.0}, {"text": "Amazon Sagemaker world, or you could bring in your own", "timestamp": "00:35:54,450", "timestamp_s": 2154.0}, {"text": "containers that you might have in on premise to use that", "timestamp": "00:35:58,116", "timestamp_s": 2158.0}, {"text": "for your training purpose. And now we are actually creating", "timestamp": "00:36:01,188", "timestamp_s": 2161.0}, {"text": "the estimator object.", "timestamp": "00:36:05,406", "timestamp_s": 2165.0}, {"text": "Now estimator is where we pass", "timestamp": "00:36:09,350", "timestamp_s": 2169.0}, {"text": "the container object. We just created the role", "timestamp": "00:36:13,000", "timestamp_s": 2173.0}, {"text": "that the training job", "timestamp": "00:36:16,482", "timestamp_s": 2176.0}, {"text": "would assume when it is actually doing the training.", "timestamp": "00:36:21,356", "timestamp_s": 2181.0}, {"text": "So this role is what is going to allow it to retrieve the data", "timestamp": "00:36:24,684", "timestamp_s": 2184.0}, {"text": "from s three, push the data back, or push the model", "timestamp": "00:36:28,796", "timestamp_s": 2188.0}, {"text": "trained model back to s three and do all that sort of start or", "timestamp": "00:36:32,750", "timestamp_s": 2192.0}, {"text": "any other service it has to interact with. This is the role", "timestamp": "00:36:36,272", "timestamp_s": 2196.0}, {"text": "that probably will actually control the permissions associated", "timestamp": "00:36:39,558", "timestamp_s": 2199.0}, {"text": "with that particular training job. We are also giving", "timestamp": "00:36:43,178", "timestamp_s": 2203.0}, {"text": "it the number of instances we wanted to use for training. As I", "timestamp": "00:36:46,772", "timestamp_s": 2206.0}, {"text": "said, it is totally dictated", "timestamp": "00:36:50,004", "timestamp_s": 2210.0}, {"text": "by you. What instances are being used,", "timestamp": "00:36:54,366", "timestamp_s": 2214.0}, {"text": "how many instances are being used, what instance type is being used", "timestamp": "00:36:57,990", "timestamp_s": 2217.0}, {"text": "and what is the input mode.", "timestamp": "00:37:01,768", "timestamp_s": 2221.0}, {"text": "You can actually choose it to be file or", "timestamp": "00:37:06,330", "timestamp_s": 2226.0}, {"text": "there is another option of actually another", "timestamp": "00:37:10,588", "timestamp_s": 2230.0}, {"text": "performance option of input mode. You could go for.", "timestamp": "00:37:17,452", "timestamp_s": 2237.0}, {"text": "And once you choose these parameters", "timestamp": "00:37:21,710", "timestamp_s": 2241.0}, {"text": "and create the estimator object, you then pass", "timestamp": "00:37:25,286", "timestamp_s": 2245.0}, {"text": "the hyperparameters. In this case, we have actually passed the", "timestamp": "00:37:28,976", "timestamp_s": 2248.0}, {"text": "hyperparameters ourselves. But as I said,", "timestamp": "00:37:32,644", "timestamp_s": 2252.0}, {"text": "we could actually use hyperparameter tuning or the hyperparameter", "timestamp": "00:37:35,956", "timestamp_s": 2255.0}, {"text": "optimization option that we had mentioned earlier", "timestamp": "00:37:40,202", "timestamp_s": 2260.0}, {"text": "and discussed about which could actually do that", "timestamp": "00:37:43,838", "timestamp_s": 2263.0}, {"text": "iterations to lock in to the", "timestamp": "00:37:48,070", "timestamp_s": 2268.0}, {"text": "best hyperparameters that will give you the best accuracy and", "timestamp": "00:37:51,816", "timestamp_s": 2271.0}, {"text": "give you the best performance model that you can choose from.", "timestamp": "00:37:58,730", "timestamp_s": 2278.0}, {"text": "Once you set the hyperparameters, you then actually", "timestamp": "00:38:03,690", "timestamp_s": 2283.0}, {"text": "kick start the training by you", "timestamp": "00:38:09,370", "timestamp_s": 2289.0}, {"text": "point these training data that needs to be used and then you kick start", "timestamp": "00:38:13,472", "timestamp_s": 2293.0}, {"text": "the training by calling this fit method.", "timestamp": "00:38:16,752", "timestamp_s": 2296.0}, {"text": "Now, once you say model fit aws, you see here,", "timestamp": "00:38:19,790", "timestamp_s": 2299.0}, {"text": "it starts the training job, it completes", "timestamp": "00:38:23,572", "timestamp_s": 2303.0}, {"text": "the training, and you", "timestamp": "00:38:27,082", "timestamp_s": 2307.0}, {"text": "are going to be just charged for whatever time that", "timestamp": "00:38:34,148", "timestamp_s": 2314.0}, {"text": "the training has run. As you see here,", "timestamp": "00:38:37,608", "timestamp_s": 2317.0}, {"text": "the total training time in seconds is 32 86.", "timestamp": "00:38:40,488", "timestamp_s": 2320.0}, {"text": "So these four instances that you had chosen of", "timestamp": "00:38:44,264", "timestamp_s": 2324.0}, {"text": "type c, four, two, x, lodge, they are", "timestamp": "00:38:50,216", "timestamp_s": 2330.0}, {"text": "going to be charged only for those whatever seconds,", "timestamp": "00:38:53,308", "timestamp_s": 2333.0}, {"text": "36 odd seconds or 32 odd seconds that", "timestamp": "00:38:57,618", "timestamp_s": 2337.0}, {"text": "the actual training job took. Now,", "timestamp": "00:39:01,728", "timestamp_s": 2341.0}, {"text": "once the training is completed, the trained model is now uploaded to s three.", "timestamp": "00:39:05,230", "timestamp_s": 2345.0}, {"text": "It\u0027s now going to be residing in s three. And as", "timestamp": "00:39:09,120", "timestamp_s": 2349.0}, {"text": "I said again earlier during our session,", "timestamp": "00:39:12,628", "timestamp_s": 2352.0}, {"text": "right after this training is completed,", "timestamp": "00:39:16,210", "timestamp_s": 2356.0}, {"text": "if you are happy with these accuracy, usually our customers choose", "timestamp": "00:39:21,170", "timestamp_s": 2361.0}, {"text": "to have a validation stage. So one of your", "timestamp": "00:39:25,016", "timestamp_s": 2365.0}, {"text": "data engineers or data scientists,", "timestamp": "00:39:28,536", "timestamp_s": 2368.0}, {"text": "whoever controls what model gets deployed in production,", "timestamp": "00:39:31,822", "timestamp_s": 2371.0}, {"text": "might get an approval task,", "timestamp": "00:39:35,730", "timestamp_s": 2375.0}, {"text": "and they will see whether these accuracy of", "timestamp": "00:39:38,818", "timestamp_s": 2378.0}, {"text": "the model is good enough to be deployed in", "timestamp": "00:39:42,268", "timestamp_s": 2382.0}, {"text": "production, and then they will give it a go.", "timestamp": "00:39:45,548", "timestamp_s": 2385.0}, {"text": "So this whole thing actually could be orchestrated", "timestamp": "00:39:48,990", "timestamp_s": 2388.0}, {"text": "in a CI CD fashion. We have got", "timestamp": "00:39:54,030", "timestamp_s": 2394.0}, {"text": "something separately called sagemaker pipelines.", "timestamp": "00:39:57,408", "timestamp_s": 2397.0}, {"text": "It\u0027s a feature within Sagemaker that you could leverage. There\u0027s no charges", "timestamp": "00:40:00,406", "timestamp_s": 2400.0}, {"text": "for it, it\u0027s just the way you can do CI CD for", "timestamp": "00:40:03,882", "timestamp_s": 2403.0}, {"text": "machine learning. All of these tasks,", "timestamp": "00:40:08,036", "timestamp_s": 2408.0}, {"text": "starting from ingestion training", "timestamp": "00:40:11,114", "timestamp_s": 2411.0}, {"text": "and then validating, deploying, all of this could be orchestrated", "timestamp": "00:40:15,080", "timestamp_s": 2415.0}, {"text": "in a totally automated fashion if you want, but deployment", "timestamp": "00:40:18,942", "timestamp_s": 2418.0}, {"text": "itself is just that one line of code that you see", "timestamp": "00:40:23,646", "timestamp_s": 2423.0}, {"text": "there. So I\u0027m happy with this model and I want", "timestamp": "00:40:27,212", "timestamp_s": 2427.0}, {"text": "to deploy it in this particular instance", "timestamp": "00:40:30,348", "timestamp_s": 2430.0}, {"text": "type. And that\u0027s it. It gets deployed.", "timestamp": "00:40:33,826", "timestamp_s": 2433.0}, {"text": "Now, once it is deployed, you now have an", "timestamp": "00:40:40,270", "timestamp_s": 2440.0}, {"text": "endpoint to do inference against. So if you see here,", "timestamp": "00:40:43,888", "timestamp_s": 2443.0}, {"text": "I am actually creating set of", "timestamp": "00:40:50,130", "timestamp_s": 2450.0}, {"text": "words that I want to use for inference.", "timestamp": "00:40:55,730", "timestamp_s": 2455.0}, {"text": "So these, you see, the first word", "timestamp": "00:40:59,354", "timestamp_s": 2459.0}, {"text": "is tamar, the second word", "timestamp": "00:41:02,872", "timestamp_s": 2462.0}, {"text": "is language, or mori music", "timestamp": "00:41:06,296", "timestamp_s": 2466.0}, {"text": "which is in Tamar isai,", "timestamp": "00:41:12,070", "timestamp_s": 2472.0}, {"text": "song is another word which in tamaris pardal,", "timestamp": "00:41:16,010", "timestamp_s": 2476.0}, {"text": "politics in Tamaris Arasiel,", "timestamp": "00:41:21,610", "timestamp_s": 2481.0}, {"text": "leader in Tamaris, Talibar, year in", "timestamp": "00:41:24,530", "timestamp_s": 2484.0}, {"text": "tamaris and century in Tamaris Notranda.", "timestamp": "00:41:28,412", "timestamp_s": 2488.0}, {"text": "So these are random words. Some of them are related, some of them", "timestamp": "00:41:31,842", "timestamp_s": 2491.0}, {"text": "are not related. We will see how the entrance behaves", "timestamp": "00:41:35,248", "timestamp_s": 2495.0}, {"text": "based on the context that it has explored", "timestamp": "00:41:41,090", "timestamp_s": 2501.0}, {"text": "with the blazingtext algorithm that we used for our training purpose.", "timestamp": "00:41:47,010", "timestamp_s": 2507.0}, {"text": "So we are pointing it to the endpoint that we just created", "timestamp": "00:41:51,226", "timestamp_s": 2511.0}, {"text": "by doing the deployment. And now", "timestamp": "00:41:55,934", "timestamp_s": 2515.0}, {"text": "what is happening here is Aws,", "timestamp": "00:41:59,480", "timestamp_s": 2519.0}, {"text": "I pass these words, it is creating vector", "timestamp": "00:42:02,552", "timestamp_s": 2522.0}, {"text": "representation of these words. Now for example,", "timestamp": "00:42:06,274", "timestamp_s": 2526.0}, {"text": "starting from here, you see,", "timestamp": "00:42:11,210", "timestamp_s": 2531.0}, {"text": "until here is the vector representation of word.", "timestamp": "00:42:14,650", "timestamp_s": 2534.0}, {"text": "Now what it is doing is it is actually trying to map these word", "timestamp": "00:42:18,524", "timestamp_s": 2538.0}, {"text": "thumbnail in an n dimensional space.", "timestamp": "00:42:22,336", "timestamp_s": 2542.0}, {"text": "And that\u0027s why you have so many weird numbers like it\u0027s", "timestamp": "00:42:25,728", "timestamp_s": 2545.0}, {"text": "being represented as a list here.", "timestamp": "00:42:30,198", "timestamp_s": 2550.0}, {"text": "So you will get these kind of list for EAch word", "timestamp": "00:42:33,730", "timestamp_s": 2553.0}, {"text": "you are trying to vectorize. And then what", "timestamp": "00:42:37,492", "timestamp_s": 2557.0}, {"text": "you are trying to do is actually map these words that are in", "timestamp": "00:42:41,748", "timestamp_s": 2561.0}, {"text": "n dimensional space into", "timestamp": "00:42:45,512", "timestamp_s": 2565.0}, {"text": "two dimensional space for", "timestamp": "00:42:49,144", "timestamp_s": 2569.0}, {"text": "Your picturization or visualization case.", "timestamp": "00:42:54,390", "timestamp_s": 2574.0}, {"text": "But otherwise, this is where the word tobac", "timestamp": "00:42:58,124", "timestamp_s": 2578.0}, {"text": "actually is trying to do the magic.", "timestamp": "00:43:01,442", "timestamp_s": 2581.0}, {"text": "Once this vectorization is completed,", "timestamp": "00:43:05,770", "timestamp_s": 2585.0}, {"text": "you can now actually,", "timestamp": "00:43:08,990", "timestamp_s": 2588.0}, {"text": "now you have the numerical representation of those words.", "timestamp": "00:43:12,590", "timestamp_s": 2592.0}, {"text": "It\u0027s just not zeros and ones, it\u0027s this weird list of", "timestamp": "00:43:16,064", "timestamp_s": 2596.0}, {"text": "array that we see there in the top.", "timestamp": "00:43:19,712", "timestamp_s": 2599.0}, {"text": "Now this is the real fun. If you see music,", "timestamp": "00:43:23,970", "timestamp_s": 2603.0}, {"text": "the word isai is closer to the", "timestamp": "00:43:29,650", "timestamp_s": 2609.0}, {"text": "word song because song is paddle.", "timestamp": "00:43:34,452", "timestamp_s": 2614.0}, {"text": "They both are closer. And hence, if you", "timestamp": "00:43:37,890", "timestamp_s": 2617.0}, {"text": "see the relationship or the", "timestamp": "00:43:41,332", "timestamp_s": 2621.0}, {"text": "vector subtraction is giving you 6.17,", "timestamp": "00:43:45,884", "timestamp_s": 2625.0}, {"text": "forget about that number. But that\u0027s how close", "timestamp": "00:43:49,794", "timestamp_s": 2629.0}, {"text": "they are is what actually it has inferred. But now", "timestamp": "00:43:53,756", "timestamp_s": 2633.0}, {"text": "if you see politics and leader,", "timestamp": "00:43:58,010", "timestamp_s": 2638.0}, {"text": "yes, they are close. And hence if you see vector of", "timestamp": "00:44:00,934", "timestamp_s": 2640.0}, {"text": "leader minus vector of politics, it\u0027s giving you 5.8. They are", "timestamp": "00:44:04,592", "timestamp_s": 2644.0}, {"text": "a lot closer because these", "timestamp": "00:44:07,968", "timestamp_s": 2647.0}, {"text": "are words that appear in contents. Now when I try", "timestamp": "00:44:12,916", "timestamp_s": 2652.0}, {"text": "music and politics,", "timestamp": "00:44:17,060", "timestamp_s": 2657.0}, {"text": "it has figured out that they are bit away than politics", "timestamp": "00:44:21,490", "timestamp_s": 2661.0}, {"text": "and leader. So what we have now", "timestamp": "00:44:25,662", "timestamp_s": 2665.0}, {"text": "achieved is actually we have now created", "timestamp": "00:44:29,256", "timestamp_s": 2669.0}, {"text": "the vector representation of each of these words", "timestamp": "00:44:32,798", "timestamp_s": 2672.0}, {"text": "and have now actually identified the distance between them", "timestamp": "00:44:37,128", "timestamp_s": 2677.0}, {"text": "contextually and where", "timestamp": "00:44:42,250", "timestamp_s": 2682.0}, {"text": "would they sit in an n dimensional space in", "timestamp": "00:44:45,676", "timestamp_s": 2685.0}, {"text": "terms of context. So that\u0027s what our inferences achieved.", "timestamp": "00:44:50,688", "timestamp_s": 2690.0}, {"text": "Now, because I restricted", "timestamp": "00:44:54,102", "timestamp_s": 2694.0}, {"text": "myself to less words within our carpus", "timestamp": "00:44:58,198", "timestamp_s": 2698.0}, {"text": "and did not bother much about", "timestamp": "00:45:04,350", "timestamp_s": 2704.0}, {"text": "accuracy, we are", "timestamp": "00:45:07,556", "timestamp_s": 2707.0}, {"text": "seeing what we are seeing, but with", "timestamp": "00:45:11,044", "timestamp_s": 2711.0}, {"text": "bit more effort on hyperparameter optimization.", "timestamp": "00:45:14,472", "timestamp_s": 2714.0}, {"text": "This can be lot accurate and very", "timestamp": "00:45:17,710", "timestamp_s": 2717.0}, {"text": "interesting inference could be made from this one. Now another", "timestamp": "00:45:22,552", "timestamp_s": 2722.0}, {"text": "trick that I probably mentioned earlier was you could actually bring in", "timestamp": "00:45:26,140", "timestamp_s": 2726.0}, {"text": "the model and unpack it and", "timestamp": "00:45:30,268", "timestamp_s": 2730.0}, {"text": "apply matte plotlib techniques", "timestamp": "00:45:34,092", "timestamp_s": 2734.0}, {"text": "to actually create a", "timestamp": "00:45:38,262", "timestamp_s": 2738.0}, {"text": "two dimensional representation of these words later", "timestamp": "00:45:41,584", "timestamp_s": 2741.0}, {"text": "on. But I think with", "timestamp": "00:45:46,016", "timestamp_s": 2746.0}, {"text": "that we come to the end of this session. Just to summarize,", "timestamp": "00:45:52,372", "timestamp_s": 2752.0}, {"text": "we started with an unknown language, the language of Tamar,", "timestamp": "00:45:56,234", "timestamp_s": 2756.0}, {"text": "and then we understood what is word to wake", "timestamp": "00:46:00,634", "timestamp_s": 2760.0}, {"text": "and what is word embedding and why do we", "timestamp": "00:46:04,158", "timestamp_s": 2764.0}, {"text": "need to do that. And then we introduced sagemaker", "timestamp": "00:46:07,368", "timestamp_s": 2767.0}, {"text": "as a platform and lot of features that comes packed", "timestamp": "00:46:11,598", "timestamp_s": 2771.0}, {"text": "into it and how sage Maker as a platform could actually", "timestamp": "00:46:15,762", "timestamp_s": 2775.0}, {"text": "help you in making your machine learning development lifecycle", "timestamp": "00:46:19,100", "timestamp_s": 2779.0}, {"text": "lot simpler by offloading", "timestamp": "00:46:22,850", "timestamp_s": 2782.0}, {"text": "the undifferentiated heavy lifting you will be doing at", "timestamp": "00:46:26,530", "timestamp_s": 2786.0}, {"text": "the moment. And we also explored how", "timestamp": "00:46:30,688", "timestamp_s": 2790.0}, {"text": "easy it is to actually apply the", "timestamp": "00:46:34,112", "timestamp_s": 2794.0}, {"text": "placing text algorithm on the data of your choice", "timestamp": "00:46:38,176", "timestamp_s": 2798.0}, {"text": "by simple demo that we saw at the", "timestamp": "00:46:42,618", "timestamp_s": 2802.0}, {"text": "later part of the session. Now,", "timestamp": "00:46:45,988", "timestamp_s": 2805.0}, {"text": "I believe this would have created some sort of interest within", "timestamp": "00:46:48,948", "timestamp_s": 2808.0}, {"text": "you to actually go and explore the natural language processing", "timestamp": "00:46:54,036", "timestamp_s": 2814.0}, {"text": "using some of the input algorithms we have within Sagemaker or", "timestamp": "00:46:57,818", "timestamp_s": 2817.0}, {"text": "the algorithm of your choice and play", "timestamp": "00:47:01,812", "timestamp_s": 2821.0}, {"text": "with one of your favorite language of your choice", "timestamp": "00:47:05,996", "timestamp_s": 2825.0}, {"text": "and explore the world of machine learning within the AWS", "timestamp": "00:47:09,698", "timestamp_s": 2829.0}, {"text": "ecosystem. Thanks for joining the session. It was my pleasure to", "timestamp": "00:47:12,882", "timestamp_s": 2832.0}, {"text": "actually give this session for you and wishing you a great day ahead.", "timestamp": "00:47:16,172", "timestamp_s": 2836.0}, {"text": "Bye now.", "timestamp": "00:47:19,692", "timestamp_s": 2839.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'Ta5Lq2kbiQQ',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Natural language modelling with Amazon SageMaker BlazingText algorithm
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>In this session, we showcase the power of machine learning in taking a large corpus of a foreign language text (we use the entire Wikipedia) and automatically learning word embeddings for that language. </p>
<p>This is typically the first key step in building natural language processing (NLP) solutions, such as text classification or topic modelling. You see how easy it is to apply the BlazingText algorithm built into Amazon SageMaker in order to process the entire contents of Wikipedia in this language and visualize the results. You then can apply these learnings to any language of your choice.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Session on natural language mod link with Amazon, sagemaker and blazing text algorithm. We will use the language of Tamar, one of the world's longest surviving classical language. In order to get this magic happen, we need to introduce word embedding with word tovec algorithm.

              </li>
              
              <li>
                Many machine learning techniques require numeric rather than text input. Words have different lengths and even written representations differ dramatically from language to language. Just randomly naming them with numerical label may not be great way of solving the problem. Typical approach is to use one, not encoding.

              </li>
              
              <li>
                 word to veg algorithm is trying to solve the problem of finding words that are in close relationship to the input word. The end goal is to achieve the word embeddings. How can we visualize this result high daily on a two dimensional picture?

              </li>
              
              <li>
                Amazon Sagemaker is a platform that was built ground up for developers. The primary ambition was to make machine learning development easy. There are lot of services that it packs that makes the development lifecycle a lot easier.

              </li>
              
              <li>
                Sagemaker allows you to build, train and deploy ML models at scale. Inbuilt algorithms take advantage of distributed computing infrastructure we have in cloud. You can kick start the training with just one line of python code.

              </li>
              
              <li>
                 blazing text algorithm was published back in 2017 by a couple of Amazonians. It provides highly optimized implementation of word to Vic and text classification algorithm. Can be 21 times faster and 20% cheaper than fast text on a single c four. But of course throughput is always not the only factor that you would choose to run with a particular algorithm because we also need to consider accuracy and cost.

              </li>
              
              <li>
                We are going to use a large corpus of text in Tamil for data ingestion purpose. We are using a wiki extractor script to extract these information from the dump. More the data, more you could learn and actually the inferences could be a lot better.

              </li>
              
              <li>
                Using the inbuilt algorithm is just one line of python code. The whole thing could be orchestrated in a CI CD fashion. There's a feature within Sagemaker that you could leverage. All of these tasks could be automated in a totally fashion.

              </li>
              
              <li>
                Sage Maker could make your machine learning development lifecycle a lot simpler. Explore the natural language processing using some of the input algorithms we have within Sagemaker. Play with one of your favorite language of your choice and explore the world of machine learning within the AWS ecosystem.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/Ta5Lq2kbiQQ.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:22,010'); seek(22.0)">
              Hello everyone, welcome to this session on natural language mod link with
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:25,628'); seek(25.0)">
              Amazon, sagemaker and blazing text algorithm. My name
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:29,068'); seek(29.0)">
              is Dinesh Kumar. I'm an aspiring ML specialist and
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:32,412'); seek(32.0)">
              I'm hoping to convince by end of this session that you don't need machine learning
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:36,460'); seek(36.0)">
              degree to take advantage of tooling AWS has put
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:39,712'); seek(39.0)">
              at your disposal. Now, as part of this session,
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:43,542'); seek(43.0)">
              we will pick a language purposefully, a foreign language likely
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:47,462'); seek(47.0)">
              unfamiliar to you, and apply machine learnings to create some magic.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:51,638'); seek(51.0)">
              We will use the language of Tamar. The Tamar language is one of the world's
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:55,802'); seek(55.0)">
              longest surviving classical language with a history dating back
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:59,332'); seek(59.0)">
              to 300 bc. Tamar as a language is rich in literature and
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:03,012'); seek(63.0)">
              one of the language that has evolved over thousands of years.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:06,068'); seek(66.0)">
              The reason I picked it is I'm familiar with this language and
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:09,672'); seek(69.0)">
              I was keen to see whether machine learnings was able to figure out the relationship
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:13,368'); seek(73.0)">
              between the words of this language and I want to
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:16,588'); seek(76.0)">
              apply known machine learning algorithm such as lacing text,
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:20,076'); seek(80.0)">
              in this case within Sagemaker to discover these relationships.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:23,602'); seek(83.0)">
              What's cool about today's talk also
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:26,924'); seek(86.0)">
              is you will be able to apply these
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:30,656'); seek(90.0)">
              techniques post this session to
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:33,856'); seek(93.0)">
              the language of your own choice and discover
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:38,262'); seek(98.0)">
              the relationships yourselves. Now, what are the prerequisites for this
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:41,732'); seek(101.0)">
              session? It will be good to have fundamentals of the
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:45,124'); seek(105.0)">
              machine learning or deep learning and understanding
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:49,402'); seek(109.0)">
              of typical natural language processing problems,
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:53,112'); seek(113.0)">
              ie search and some familiarity with AWS services.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:57,272'); seek(117.0)">
              Not necessarily sagemaker. I will surely cover that as
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:00,488'); seek(120.0)">
              part of my session and then knowledge of python or numpy.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:04,814'); seek(124.0)">
              As long as you know any other coding language, this is straightforward,
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:08,578'); seek(128.0)">
              you would not be lost and these knowledge
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:12,258'); seek(132.0)">
              of Jupyter environment notebook environment as such would
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:16,108'); seek(136.0)">
              be very handy. Now in order to
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:19,180'); seek(139.0)">
              get this magic happen, we need to introduce word embedding with
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:23,424'); seek(143.0)">
              word to vec algorithm. Then we need to understand bit about Amazon Sagemaker
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:27,638'); seek(147.0)">
              and its unique capabilities, especially around NLP area. Then we can
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:31,472'); seek(151.0)">
              spend bulk of our time with building text algorithm and a quick
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:35,252'); seek(155.0)">
              demo. So that takes us to these interesting topic
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:39,002'); seek(159.0)">
              of word embedding. Let's dive into word embedding, natural language,
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:42,762'); seek(162.0)">
              text, contents of words and so we need to represent
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:46,046'); seek(166.0)">
              individual words, sentences and collection of
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:49,592'); seek(169.0)">
              words in some way. Now couldn't we just use strings
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:53,086'); seek(173.0)">
              containing the words? First of all, words have different lengths
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:57,234'); seek(177.0)">
              and even written representations differ dramatically from language to
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:00,892'); seek(180.0)">
              language. So if you look at the
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:05,148'); seek(185.0)">
              language of Tamil, some words might be mentioned
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:09,136'); seek(189.0)">
              in a different way in different region of Tamil
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:12,438'); seek(192.0)">
              Nadu, while the same words will
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:16,656'); seek(196.0)">
              have different representation or different way of being pronounced
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:20,986'); seek(200.0)">
              or spelled in different region.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:24,266'); seek(204.0)">
              Now, with these complications and
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:27,956'); seek(207.0)">
              added to that, more importantly, many machine learning techniques
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:31,642'); seek(211.0)">
              require numeric rather than text input as you would obviously.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:35,784'); seek(215.0)">
              You know, computers are good with numbers and
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:39,576'); seek(219.0)">
              may not be with natural language vocabulary like us.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:43,336'); seek(223.0)">
              So that brings us to the topic of representing
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:46,542'); seek(226.0)">
              these words in a numerical form. So if I want to represent
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:50,322'); seek(230.0)">
              this particular phrase, you see there to be or not to be in a numerical
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:54,322'); seek(234.0)">
              form, how can I go about it? Let's say I
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:57,756'); seek(237.0)">
              represent each of it with an individual label. Let's say
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:01,200'); seek(241.0)">
              I represent two with zero, b with one, or with two,
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:04,576'); seek(244.0)">
              not with three. Now that gives me zero, one, two, these zero,
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:07,856'); seek(247.0)">
              one, a random set of numbers. Now, this particular way
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:11,748'); seek(251.0)">
              of representing it with just unique labels is actually going to create
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:15,890'); seek(255.0)">
              or introduce random relationships. For example,
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:22,290'); seek(262.0)">
              b as a word is now closer to two
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:25,656'); seek(265.0)">
              and r but away from not.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:28,664'); seek(268.0)">
              Is that true? No. So how did we even arrive at
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:32,168'); seek(272.0)">
              these labels when there is no such relationship?
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:35,450'); seek(275.0)">
              So just randomly naming them with numerical label may
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:39,228'); seek(279.0)">
              not be great way of solving the problem. Now let's
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:42,498'); seek(282.0)">
              say we use vector
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:45,586'); seek(285.0)">
              instead of single number. Typical approach is to use one, not encoding.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:49,362'); seek(289.0)">
              Here each word access an index into a vector of all zeros
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:52,838'); seek(292.0)">
              with only a single element set to one. Now you
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:56,352'); seek(296.0)">
              would have already guessed these problem with one out encoding approach.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:59,750'); seek(299.0)">
              The example here is having just four words, and a typical
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:03,766'); seek(303.0)">
              language will have hundreds and thousands of words. In case of Tamar,
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:07,466'); seek(307.0)">
              I don't have account, but it's a very rich language, as I said earlier,
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:11,386'); seek(311.0)">
              and there is quite a lot of words to its vocabulary. So representing them
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:15,592'); seek(315.0)">
              by ones and zeros may not be the efficient way of actually
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:20,390'); seek(320.0)">
              solving the problem in hand.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:22,936'); seek(322.0)">
              Now with that in mind, let's look
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:26,268'); seek(326.0)">
              at the other side of the coin. Given a sentence,
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:31,130'); seek(331.0)">
              what is our chances of maximizing the probability
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:34,514'); seek(334.0)">
              of predicting the context words? Let's say I introduce
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:38,754'); seek(338.0)">
              this word, Tom Hanks. How can I predict the
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:42,832'); seek(342.0)">
              context of this word? In this example? Let's say we want
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:45,888'); seek(345.0)">
              to predict the context of Tom Hanks. What is the probability that somewhere
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:49,782'); seek(349.0)">
              around Tom Hanks we will find words? Great. Can actor
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:53,418'); seek(353.0)">
              quite a lot because he's an actor. So there is quite a lot of chances
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:57,402'); seek(357.0)">
              that those words would appear somewhere near
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:00,644'); seek(360.0)">
              Tom Hanks. But what is the chances of me finding something like
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:04,440'); seek(364.0)">
              quantum physics next to Tom Hanks? Maybe very less.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:08,470'); seek(368.0)">
              I would not say zero, but it is relatively less
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:12,408'); seek(372.0)">
              when you compare it to word actor. Now that's the point we are trying
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:15,628'); seek(375.0)">
              to actually make. How do I figure out that
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:19,436'); seek(379.0)">
              this particular word has more relationship and
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:23,452'); seek(383.0)">
              hence contextually more closer to this word.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:27,276'); seek(387.0)">
              In typically deep learning world,
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:30,816'); seek(390.0)">
              we will actually have a fully connected network.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:34,438'); seek(394.0)">
              So for every input word it receives, let's say a
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:38,048'); seek(398.0)">
              vocabulary has 10,000 words, and if we receive one word,
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:41,988'); seek(401.0)">
              then the output
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:45,498'); seek(405.0)">
              of this network should be able to figure out what are those
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:50,210'); seek(410.0)">
              words within those 10,000 words this particular input
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:53,918'); seek(413.0)">
              word is closer to. So there will be lot of
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:57,592'); seek(417.0)">
              hidden layers of network that will try to
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:01,048'); seek(421.0)">
              extract the contents words and then it'll spit out the
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:04,872'); seek(424.0)">
              probability of the words that might sit
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:08,476'); seek(428.0)">
              contextually closer to that input word. After training such
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:11,708'); seek(431.0)">
              a network, we can now quickly compute denser output vector for a
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:15,244'); seek(435.0)">
              sparse input vector that we had after our 1 hour ten coding.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:19,010'); seek(439.0)">
              So we have now grasped a bit about the problem itself
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:22,800'); seek(442.0)">
              that we are trying to solve. The problem statement is we
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:26,416'); seek(446.0)">
              want to understand the probability of a
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:30,308'); seek(450.0)">
              word being in closer relationship with,
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:33,812'); seek(453.0)">
              or probability of having set of words that
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:38,052'); seek(458.0)">
              are in close relationship to the input word that is coming
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:41,476'); seek(461.0)">
              in for inference. Now it's time to understand about the word to veg
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:45,502'); seek(465.0)">
              algorithm itself. So, dimensionality of the
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:49,048'); seek(469.0)">
              output vector is a parameter we choose. This is why we said embeddings
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:52,862'); seek(472.0)">
              high dimensional object, one not encoded word, in this case
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:56,232'); seek(476.0)">
              into small dimensional space. Turning a sparse vector into a much denser
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:00,018'); seek(480.0)">
              representation is what we are trying to achieve. Once this representation is
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:03,852'); seek(483.0)">
              computed, we can simply convert every word into an n
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:07,452'); seek(487.0)">
              dimensional space. In the end,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:11,008'); seek(491.0)">
              words that appear in similar context will likely be
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:14,432'); seek(494.0)">
              mapped to similar vectors. Words close to each other in vector
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:17,702'); seek(497.0)">
              space are likely to be similar in meaning as they tend to be used in
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:21,248'); seek(501.0)">
              similar context. This is where we are getting closer to
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:24,724'); seek(504.0)">
              these magic a machine learning system automatically discovering
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:27,962'); seek(507.0)">
              words that appear to have similar meaning. In theory,
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:31,402'); seek(511.0)">
              we also expect certain vector relationships to hold. This doesn't
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:35,438'); seek(515.0)">
              have to be exact and depends totally on the carcass being
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:38,776'); seek(518.0)">
              used for training. We can help to discover word relationships with
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:42,456'); seek(522.0)">
              transitive properties, as shown on the slide. For example,
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:46,088'); seek(526.0)">
              if we take a vector that corresponds to word king,
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:49,234'); seek(529.0)">
              that's a classic example that we usually see.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:53,290'); seek(533.0)">
              Let's say I have found a vector for the word king and subtract
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:57,682'); seek(537.0)">
              vector for the word man.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:02,830'); seek(542.0)">
              I get a meaning that says there is some sort
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:06,448'); seek(546.0)">
              of royalty associated, and then if I add vector
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:10,406'); seek(550.0)">
              of woman to it, I've arrived at vector of queen.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:13,818'); seek(553.0)">
              This is magic here because we have managed to
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:17,556'); seek(557.0)">
              understand the meaning of a word and then doing typical
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:21,626'); seek(561.0)">
              addition subtraction that we play with numbers, but in this case
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:25,032'); seek(565.0)">
              with words and their inherent meaning that
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:28,568'); seek(568.0)">
              they bring with it. So that's exactly
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:32,008'); seek(572.0)">
              what word to vec algorithm is actually trying to solve.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:36,046'); seek(576.0)">
              You may have heard about new models such as Bert, Roberta,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:39,170'); seek(579.0)">
              but the end goal is to achieve the word embeddings.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:42,418'); seek(582.0)">
              Yeah, I'll probably show you this
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:46,890'); seek(586.0)">
              completed word embedding for english language.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:50,590'); seek(590.0)">
              And this has been mapped into 100 dimensional vector.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:54,054'); seek(594.0)">
              How can we visualize this result high daily on a two dimensional
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:57,590'); seek(597.0)">
              picture? This is where we probably could use another
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:01,620'); seek(601.0)">
              trick of trade. T distributed stochastic neighbor
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:05,418'); seek(605.0)">
              embedding plot. Now that might be a
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:09,028'); seek(609.0)">
              bunch of words, but it's just simple way of telling
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:12,522'); seek(612.0)">
              that we now have way to visualize all
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:16,056'); seek(616.0)">
              those relationships in a two dimensional space.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:19,816'); seek(619.0)">
              As you see here, the model has
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:23,192'); seek(623.0)">
              now figured out american, british, English,
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:25,906'); seek(625.0)">
              London, England, French, France, German. Now all of
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:29,452'); seek(629.0)">
              these are closer to each other. It has mapped
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:33,426'); seek(633.0)">
              that they all can contextually appear closer
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:37,266'); seek(637.0)">
              or they are all related in some form or shape. And these clusters
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:41,590'); seek(641.0)">
              are interesting clusters that it has figured out because
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:45,536'); seek(645.0)">
              of the corpus that was thrown at it. The very
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:48,736'); seek(648.0)">
              important one I would probably show is if you see there,
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:53,090'); seek(653.0)">
              it has found out that there is relationship between son,
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:56,884'); seek(656.0)">
              family, children, father, death, life.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:02,130'); seek(662.0)">
              It is able to actually figure out that these
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:06,536'); seek(666.0)">
              words are related and are closer
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:09,678'); seek(669.0)">
              in context. And there is more probability
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:12,878'); seek(672.0)">
              of a word from this particular cluster appearing next
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:17,132'); seek(677.0)">
              to a word that has just come, that it has just come across.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:21,468'); seek(681.0)">
              Now, enough of the word to vec and
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:25,052'); seek(685.0)">
              word embedding the actual problem statement that we were trying
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:28,588'); seek(688.0)">
              to solve. Let's try to understand the toolings that are at our disposal
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:32,230'); seek(692.0)">
              and how sage maker itself as a service is able to help
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:36,032'); seek(696.0)">
              us with in solving this problem. And our placing text
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:39,936'); seek(699.0)">
              algorithm then fits into it. This is a typical AAML
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:43,898'); seek(703.0)">
              stack. In the top you see AI services.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:47,172'); seek(707.0)">
              Most of these services are out of box services
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:51,188'); seek(711.0)">
              in the sense you do not need to have any sort of machine learning skill.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:55,038'); seek(715.0)">
              Let's say you are a team of developers
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:59,470'); seek(719.0)">
              who are having zero skill with machine learning, but want
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:02,968'); seek(722.0)">
              to actually see how you could use it for your
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:06,396'); seek(726.0)">
              own application or a problem
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:10,076'); seek(730.0)">
              or a workload that you have. Then these are
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:13,628'); seek(733.0)">
              some go to AI services. These are across different areas.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:17,842'); seek(737.0)">
              For example, we have AI services for vision, speech language,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:21,366'); seek(741.0)">
              chatbots, forecasting recommendations. All you need to do is an API
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:25,382'); seek(745.0)">
              call. These are models that are up and running and are always
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:28,896'); seek(748.0)">
              learning because so many of our other customers are using it.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:32,420'); seek(752.0)">
              And you will be able to just, with an API call,
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:35,860'); seek(755.0)">
              get the inferences back. And you do not have to go
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:39,668'); seek(759.0)">
              down the route of building a model, training it,
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:43,236'); seek(763.0)">
              validating it and monitoring it of any sort,
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:47,430'); seek(767.0)">
              you're just going to consume it. But let's say you are a bunch of
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:51,400'); seek(771.0)">
              developers who are already actually into machine learning and want
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:54,712'); seek(774.0)">
              to make your life simple, then that's where ML services
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:59,450'); seek(779.0)">
              with Amazon Sagemaker as a platform would come into picture.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:03,538'); seek(783.0)">
              Amazon Sagemaker is a platform that was built ground up
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:07,532'); seek(787.0)">
              for developers. The primary ambition was
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:11,008'); seek(791.0)">
              to actually make machine learning development easy for developers,
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:14,806'); seek(794.0)">
              and hence there are lot of services that
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:18,208'); seek(798.0)">
              it packs that makes the development lifecycle
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:22,902'); seek(802.0)">
              lot easier than it was before.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:26,290'); seek(806.0)">
              We will dive into that part in detail, but otherwise,
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:29,626'); seek(809.0)">
              if you are experts and if you want to actually do
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:33,416'); seek(813.0)">
              it at your own pace,
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:37,310'); seek(817.0)">
              the frameworks of your choice, and then
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:41,240'); seek(821.0)">
              we completely support Tensorflow, Mxnet and all those popular
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:44,782'); seek(824.0)">
              frameworks, and quite a lot of instances
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:48,722'); seek(828.0)">
              and GPU
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:52,258'); seek(832.0)">
              based instances that are available for you to leverage.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:55,362'); seek(835.0)">
              But we would primarily focus on Sagemaker as a platform
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:58,944'); seek(838.0)">
              as part of these session, because it's a very big world
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:02,816'); seek(842.0)">
              to explore on its own. So let's just take ourselves to
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:07,390'); seek(847.0)">
              the main hero of today's subject,
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:10,118'); seek(850.0)">
              Sagemaker. So amazing. Sagemaker. As I said,
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:14,130'); seek(854.0)">
              you can build, train and deploy ML models
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:17,738'); seek(857.0)">
              at scale. Now at scale is the key term
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:21,322'); seek(861.0)">
              there. Whatever be the part of your journey,
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:24,222'); seek(864.0)">
              either it be building or training or deploying.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:28,030'); seek(868.0)">
              For each of these stages, Sagemaker as
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:31,272'); seek(871.0)">
              a platform offers you the right set of APIs with
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:35,208'); seek(875.0)">
              bunch of python code. You will be able
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:38,716'); seek(878.0)">
              to build your model, train your model, validate your
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:42,332'); seek(882.0)">
              model and deploy it. And of course, AWS, part of
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:46,028'); seek(886.0)">
              today's demo, we will show you how it is being done,
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:49,632'); seek(889.0)">
              but that's how easy it is to get going in Sagemaker.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:53,910'); seek(893.0)">
              So to start with, we offer pre
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:58,032'); seek(898.0)">
              built notebooks. These pre built notebooks examples
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:01,802'); seek(901.0)">
              are very much available within sagemaker environment. In your own AWS
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:05,962'); seek(905.0)">
              console, machine learning developers can just use these examples to
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:09,972'); seek(909.0)">
              start experimenting for their own specific use cases.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:13,594'); seek(913.0)">
              So if you are actually new to sagemaker, you do not have
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:16,888'); seek(916.0)">
              to start from scratch. You could leverage these pre built notebook
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:20,606'); seek(920.0)">
              examples and use that as a
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:24,168'); seek(924.0)">
              starter to explore the sagemaker environment.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:27,410'); seek(927.0)">
              Now, let's say you explored it and you
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:32,012'); seek(932.0)">
              want to actually move forward. Then once you settle in
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:35,852'); seek(935.0)">
              with your training data, of course, that's these most important bit.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:39,804'); seek(939.0)">
              Your models are as good as your training data. So quite
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:44,112'); seek(944.0)">
              a lot of our customers spend a lot of time in ensuring
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:47,302'); seek(947.0)">
              they have the right data. Let's say you have the right data, training data
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:51,056'); seek(951.0)">
              that you need. You then need to choose right algorithms
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:54,646'); seek(954.0)">
              that will have to actually go with them. Now, when it comes
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:58,212'); seek(958.0)">
              down to algorithm. We have lots of choices within
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:02,628'); seek(962.0)">
              these sage maker world. As you see either it
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:06,008'); seek(966.0)">
              be regression or classification, or image
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:10,870'); seek(970.0)">
              vision based aa models. You have quite a lot
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:14,824'); seek(974.0)">
              of built algorithms that comes very handy. These algorithms
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:18,706'); seek(978.0)">
              are in the form of containers. All you need to do is
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:22,332'); seek(982.0)">
              actually refer to the container registry and pull the
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:26,348'); seek(986.0)">
              right container for this algorithms, and then you should
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:29,968'); seek(989.0)">
              be get going with it. Otherwise,
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:33,590'); seek(993.0)">
              if none of these existing built in algorithms does
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:37,008'); seek(997.0)">
              not cater to your needs, you could always bring in your own algorithms
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:41,306'); seek(1001.0)">
              in the form of containers and leverage
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:46,290'); seek(1006.0)">
              the sagemaker as a platform. Now, what's unique about
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:52,390'); seek(1012.0)">
              these inbuilt algorithms is that they could actually take advantage
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:56,126'); seek(1016.0)">
              of distributed computing infrastructure
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:00,302'); seek(1020.0)">
              we have in cloud. And you
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:06,908'); seek(1026.0)">
              might sometimes find the equivalent of these algorithms
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:11,058'); seek(1031.0)">
              in open source as well. But the ones
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:15,788'); seek(1035.0)">
              that are inbuilt with Sagemaker are validated
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:20,134'); seek(1040.0)">
              for their efficiency in utilizing the distributed
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:23,558'); seek(1043.0)">
              compute environment and infrastructure that the cloud offers. And hence it is
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:27,552'); seek(1047.0)">
              always relatively lot performant than the
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:31,268'); seek(1051.0)">
              open source version of the equivalent algorithm you will find out
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:34,452'); seek(1054.0)">
              in the market, in the open source market. So let's
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:38,362'); seek(1058.0)">
              say you determine the algorithm,
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:41,978'); seek(1061.0)">
              then you need to train the
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:45,316'); seek(1065.0)">
              model. So you will want to tell
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:48,920'); seek(1068.0)">
              the number of missions you want to use for your training purpose.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:51,790'); seek(1071.0)">
              You can then kick start the training with just one line of python
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:55,598'); seek(1075.0)">
              code. Yes, you heard it right, it is just one line of
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:58,828'); seek(1078.0)">
              python code within your sage maker SDK or
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:03,052'); seek(1083.0)">
              click in a console. And that's all it takes to actually
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:18:07,290'); seek(1087.0)">
              get the training going. And you can actually do
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:10,912'); seek(1090.0)">
              your training and create your model out of it.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:14,190'); seek(1094.0)">
              These are so many deep learning framework containers that
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:17,488'); seek(1097.0)">
              are supported in Sagemaker. So it
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:20,688'); seek(1100.0)">
              uses docker containers, as I said earlier, that's designed for
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:23,748'); seek(1103.0)">
              that specific algorithm, and that's designed to support that particular framework.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:27,242'); seek(1107.0)">
              So let's say you have a particular algorithm in Tensorflow that
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:30,932'); seek(1110.0)">
              you want to use for your use case. Then you
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:34,212'); seek(1114.0)">
              will find a container for that particular framework,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:37,662'); seek(1117.0)">
              for that particular algorithm. And as long as you
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:40,792'); seek(1120.0)">
              actually refer to that in your code, you will be able to pick and run
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:43,432'); seek(1123.0)">
              with it. What you do is when executing the training,
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:47,830'); seek(1127.0)">
              as I said, you just select the right container and provide the data in
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:51,852'); seek(1131.0)">
              form of a file in simple storage service. Now what Sagemaker
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:55,458'); seek(1135.0)">
              would do is launch cluster of training machines.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:58,418'); seek(1138.0)">
              And again, it will not just launch a lot of machines,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:01,622'); seek(1141.0)">
              you do not have to worry about the cost, it just launches the
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:04,752'); seek(1144.0)">
              number of machines you are told within your code
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:08,688'); seek(1148.0)">
              and the type of instances that you have advised for it
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:11,984'); seek(1151.0)">
              to pick up for the trading purpose, and then use
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:15,236'); seek(1155.0)">
              those machines to train with the data that it
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:18,868'); seek(1158.0)">
              has from s three. Now, it can also perform distributed training.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:22,516'); seek(1162.0)">
              As I said earlier, if it
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:26,328'); seek(1166.0)">
              is distributed, you can train it in multiple instances, or you
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:30,008'); seek(1170.0)">
              could always choose to train it in single machine
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:33,534'); seek(1173.0)">
              and end of the day, the output, the resulting model
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:37,564'); seek(1177.0)">
              will be back in s three. So you could always actually
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:42,410'); seek(1182.0)">
              look at the model and see how accurate
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:47,010'); seek(1187.0)">
              is the model giving inferences,
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:51,478'); seek(1191.0)">
              and then decide to go ahead or not, or retrain the model
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:55,040'); seek(1195.0)">
              again with new set of data. Now,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:59,390'); seek(1199.0)">
              what if the model is not optimal enough? As I said,
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:20:02,724'); seek(1202.0)">
              there are so many optimization techniques that are available for
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:05,972'); seek(1205.0)">
              you now.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:10,050'); seek(1210.0)">
              Usually, let's say you create a model and
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:13,992'); seek(1213.0)">
              it is not really performing well. What the
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:18,616'); seek(1218.0)">
              usual ML developers do is actually they tune
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:22,078'); seek(1222.0)">
              the hyperparameters associated with that algorithm.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:25,910'); seek(1225.0)">
              So for people who may not know what are these? There is usually
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:29,228'); seek(1229.0)">
              a bunch of parameters that contents behavior of a given algorithm.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:32,834'); seek(1232.0)">
              Often machine learning developers are left in dark as to
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:35,932'); seek(1235.0)">
              what value should they use for these different parameters to get their model
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:39,600'); seek(1239.0)">
              optimized. That's where automated model tuning comes to the
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:42,848'); seek(1242.0)">
              rescue. The reality is even machine learning practitioners
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:46,886'); seek(1246.0)">
              themselves, even experienced ones,
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:50,080'); seek(1250.0)">
              often don't know what to do. In these cases, they just rely on
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:56,370'); seek(1256.0)">
              random grid based hyperparameter
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:00,210'); seek(1260.0)">
              choosing strategy.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:03,030'); seek(1263.0)">
              Now, Sagemaker allows you to do that by kicking
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:07,038'); seek(1267.0)">
              off the so called hyperparameter optimization job,
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:10,872'); seek(1270.0)">
              and you specify how many machines it needs to run
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:14,632'); seek(1274.0)">
              on to control the cost. And ultimately it helps you identify the
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:18,284'); seek(1278.0)">
              right parameters to optimize your model. It does it with the bayesian
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:21,922'); seek(1281.0)">
              search algorithm. Basically, let's say it
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:26,140'); seek(1286.0)">
              ran the training with bunch of parameters and
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:30,156'); seek(1290.0)">
              it gets a model accuracy and it is not
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:33,632'); seek(1293.0)">
              fitting the built it will now remember what are the parameters that it
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:36,928'); seek(1296.0)">
              ran with in the previous iteration, and hence choose to
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:40,692'); seek(1300.0)">
              deviate away or go towards it based
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:44,276'); seek(1304.0)">
              on the iteration and the learning
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:48,530'); seek(1308.0)">
              that it's picking up. It is not efficient way of actually tuning
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:52,878'); seek(1312.0)">
              the model, and many of our customers leverage this
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:56,232'); seek(1316.0)">
              for their machine learning training
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:00,280'); seek(1320.0)">
              purpose. Amazon Sagemaker Neo is something that I would briefly touch
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:04,216'); seek(1324.0)">
              on with Neo. You can compile your models to be ported
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:07,630'); seek(1327.0)">
              to any of the target processes you may choose to run your model on.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:11,100'); seek(1331.0)">
              This way your model would not only be smaller
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:14,642'); seek(1334.0)">
              and deployment ready built, also more performant. So it doesn't
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:18,738'); seek(1338.0)">
              matter which end architecture you want to port
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:22,496'); seek(1342.0)">
              your model to. Neo may help you do that and you will also
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:25,872'); seek(1345.0)">
              be actually carry your model with you and deploy
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:29,558'); seek(1349.0)">
              it in lot lighter form in any architecture
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:33,498'); seek(1353.0)">
              of your choice. And the list of architectures to which you could port it
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:36,868'); seek(1356.0)">
              to is always being added on. So you
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:39,988'); seek(1359.0)">
              could always check our AWS pages to figure out what
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:44,392'); seek(1364.0)">
              are the ones that we support. So let's say we
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:48,888'); seek(1368.0)">
              have got the data, we trained the model, we have validated
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:53,022'); seek(1373.0)">
              the model after the fine tuning thanks to hyperparameter
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:57,602'); seek(1377.0)">
              optimization, and we have now got the right accuracy
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:01,698'); seek(1381.0)">
              and performance we needed to deploy this in production.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:06,482'); seek(1386.0)">
              Now, what we will see as
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:10,592'); seek(1390.0)">
              part of the demo as well is that
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:14,224'); seek(1394.0)">
              with one line of python code, you can take this model to production.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:17,766'); seek(1397.0)">
              You can then manage the same and easily scale with Amazon
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:21,482'); seek(1401.0)">
              Web services. Now that's the beauty of Sagemaker.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:25,970'); seek(1405.0)">
              Everything is simplified for the
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:29,556'); seek(1409.0)">
              developers to leverage this distributed
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:33,342'); seek(1413.0)">
              computing platform and focus
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:38,280'); seek(1418.0)">
              on the business outcomes that they want,
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:41,336'); seek(1421.0)">
              rather than all the undifferentiated heavy lifting
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:44,782'); seek(1424.0)">
              they will have to do in building,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:49,004'); seek(1429.0)">
              training and validating these models.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:51,850'); seek(1431.0)">
              So that's the bet with
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:56,044'); seek(1436.0)">
              Sage maker that I wanted to cover before we dive into
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:00,400'); seek(1440.0)">
              the world of blazingtext algorithm.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:03,766'); seek(1443.0)">
              So as I said, blazing text algorithm
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:07,542'); seek(1447.0)">
              was published back in 2017 by
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:12,196'); seek(1452.0)">
              a couple of Amazonians. This is the paper that was
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:15,652'); seek(1455.0)">
              released back in 2017 to
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:20,212'); seek(1460.0)">
              discuss how the blazing text algorithm will go about this
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:25,112'); seek(1465.0)">
              particular problem. Now, key thing to
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:28,328'); seek(1468.0)">
              note these is this algorithm provides highly optimized implementation
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:24:32,222'); seek(1472.0)">
              of word to Vic and text classification algorithm.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:24:35,646'); seek(1475.0)">
              Using blazing text. You can train a model with more than billion of
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:39,212'); seek(1479.0)">
              words in probably a couple of minutes using
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:43,356'); seek(1483.0)">
              multicore cpu or GPU, and you can achieve performance on par with state
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:47,516'); seek(1487.0)">
              of art deep learning text classification algorithms
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:50,742'); seek(1490.0)">
              out there. So the other important thing that
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:54,992'); seek(1494.0)">
              it offers is an implementation of supervised
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:58,614'); seek(1498.0)">
              multiclass, multilabel text classification algorithm,
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:01,978'); seek(1501.0)">
              extending the fast text algorithm implementation by using
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:05,684'); seek(1505.0)">
              GPU acceleration with custom CuDA kernels, but also relying on
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:09,428'); seek(1509.0)">
              multiple cpus for certain modes of operating this algorithm.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:14,950'); seek(1514.0)">
              In this particular demo, we will be using distributed
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:25:20,142'); seek(1520.0)">
              training, just so you know.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:25:22,744'); seek(1522.0)">
              But there is no hard role.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:25:26,290'); seek(1526.0)">
              You could always do it in single machine if that suffice
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:25:29,698'); seek(1529.0)">
              your needs. These are some of the highlights of
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:25:33,724'); seek(1533.0)">
              blazingtext that I would love to highlight.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:37,058'); seek(1537.0)">
              As I said, you can run with single cpu instances, you can run with multiple
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:41,430'); seek(1541.0)">
              GPU acceleration if needed.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:45,630'); seek(1545.0)">
              And these interesting
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:49,230'); seek(1549.0)">
              thing that you would see from these slide is it can be 21 times faster
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:53,370'); seek(1553.0)">
              and 20% cheaper than fast text on a
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:56,708'); seek(1556.0)">
              single c four. And if
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:01,348'); seek(1561.0)">
              you go down the distributed training route, it can achieve
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:05,418'); seek(1565.0)">
              a training speed of up to 50 million words per second.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:08,728'); seek(1568.0)">
              Now this is speed of eleven times over one
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:26:12,296'); seek(1572.0)">
              c four lodge that we saw in the previous one, which is amazing,
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:26:15,708'); seek(1575.0)">
              actually, the kind of efficiency that
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:26:21,388'); seek(1581.0)">
              these have actually managed to harness
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:26:25,794'); seek(1585.0)">
              from blazing text algorithm is amazing. Now how do they do that
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:26:30,750'); seek(1590.0)">
              in our demo? As I said, we will use blazing
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:26:34,438'); seek(1594.0)">
              text on multiple cpus. But even within single cpu, blazing text
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:26:38,496'); seek(1598.0)">
              takes certain steps to optimize its performance. And that's
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:42,538'); seek(1602.0)">
              what we are seeing here.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:46,770'); seek(1606.0)">
              It uses blast two by intel
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:50,698'); seek(1610.0)">
              and hence it is a
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:53,704'); seek(1613.0)">
              lot more optimized in terms of cpu utilization.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:57,742'); seek(1617.0)">
              And as you see here, this picture
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:02,158'); seek(1622.0)">
              is showing how we
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:05,468'); seek(1625.0)">
              are optimizing bird to vec by sharing the k negative
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:27:09,042'); seek(1629.0)">
              samples across using the blast to
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:27:12,970'); seek(1632.0)">
              advantage that we have from intel. Now this is a
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:27:17,068'); seek(1637.0)">
              slide that compares the throughput of 1 billion bird
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:27:21,046'); seek(1641.0)">
              benchmark data set. Over here you are seeing
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:27:24,624'); seek(1644.0)">
              throughput characteristics of the blazingtext right hand
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:27:27,968'); seek(1647.0)">
              side you see implementation of fast text, sort of what
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:27:31,248'); seek(1651.0)">
              is published out there. Because fast text is not able
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:27:34,756'); seek(1654.0)">
              to be distributed on multiple cpus or gpus, we are
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:27:38,564'); seek(1658.0)">
              running it for benchmarking on single machine. Now you can
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:41,812'); seek(1661.0)">
              compare and contrast the performance when you look at left hand side where the algorithm
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:45,678'); seek(1665.0)">
              has been run on multiple multicore gpu machines. And in the middle
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:49,336'); seek(1669.0)">
              section where you see the yellow bars, we have performed batch
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:52,622'); seek(1672.0)">
              skip gram benchmarking. And again here you are seeing the results of
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:56,072'); seek(1676.0)">
              running algorithm in distributed fashion on multiple cpus.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:59,530'); seek(1679.0)">
              But of course throughput is always not the only factor that you
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:02,908'); seek(1682.0)">
              would choose to run with a particular algorithm
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:28:06,722'); seek(1686.0)">
              because we also need to consider accuracy and cost.
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:28:10,176'); seek(1690.0)">
              So I would love to actually show you another set
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:28:13,952'); seek(1693.0)">
              of benchmark results.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:28:18,510'); seek(1698.0)">
              Basically, as you see here,
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:28:21,650'); seek(1701.0)">
              I think the right way to interpret this diagram
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:28:25,562'); seek(1705.0)">
              is that the circle that we see
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:28:29,124'); seek(1709.0)">
              here is the throughput. And when
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:28:33,928'); seek(1713.0)">
              you compare number eight and number two,
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:28:37,688'); seek(1717.0)">
              sorry, I think these number
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:28:41,576'); seek(1721.0)">
              eight is the one that was run by
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:45,464'); seek(1725.0)">
              skip Graham blazing text. So yes, what I
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:49,324'); seek(1729.0)">
              said is right, if you compare number eight and number two,
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:53,290'); seek(1733.0)">
              you get lot of throughput, you get lot of accuracy.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:56,690'); seek(1736.0)">
              In fact, almost same accuracy for very less cost.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:01,550'); seek(1741.0)">
              The horizontal axis here is cost. The vertical
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:29:04,806'); seek(1744.0)">
              axis here is accuracy. The size of the circle denotes the throughput
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:29:08,950'); seek(1748.0)">
              that that particular algorithm is able to achieve with
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:29:12,772'); seek(1752.0)">
              the given configuration.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:29:15,338'); seek(1755.0)">
              So it just goes on to confirm
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:29:20,290'); seek(1760.0)">
              the previous claim we had that
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:29:24,264'); seek(1764.0)">
              it is a lot more performant and lot more cheaper when compared
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:29:28,462'); seek(1768.0)">
              to our other fast text algorithm.
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:29:32,286'); seek(1772.0)">
              With that we will move on to
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:29:35,532'); seek(1775.0)">
              the demo part of our discussion,
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:29:39,730'); seek(1779.0)">
              which is called as semurai in Tambur. By the
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:29:43,404'); seek(1783.0)">
              way, let me bring the demo
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:47,740'); seek(1787.0)">
              page for you. So hope you're able to
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:51,168'); seek(1791.0)">
              see this. This is the
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:55,150'); seek(1795.0)">
              notebook that I have created in Amazon
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:58,758'); seek(1798.0)">
              Sagemaker. Now you could just go to Amazon
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:03,098'); seek(1803.0)">
              Sagemaker service. I can probably
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:30:07,970'); seek(1807.0)">
              show you that quickly.
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:30:12,610'); seek(1812.0)">
              I think we'll just continue with the notebook because
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:30:16,744'); seek(1816.0)">
              it might be a bit tricky for me to actually share that screen.
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:30:20,310'); seek(1820.0)">
              So it's very simple.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:30:23,496'); seek(1823.0)">
              If you go to Amazon Sagemaker service within AWS console,
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:30:27,298'); seek(1827.0)">
              you go to notebook that
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:30:31,228'); seek(1831.0)">
              will be in your left panel and you create a Jupyter notebook.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:30:35,218'); seek(1835.0)">
              This is as simple as any Jupyter notebook
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:30:38,882'); seek(1838.0)">
              that you would have seen, nothing special about it. And it
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:30:43,504'); seek(1843.0)">
              is just an environment for, if someone is
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:30:47,232'); seek(1847.0)">
              not aware of it. It is just an environment for data scientists to
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:30:51,236'); seek(1851.0)">
              share and do more data science
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:55,450'); seek(1855.0)">
              in a collaborative way.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:58,690'); seek(1858.0)">
              That's all about this environment. Now,
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:02,210'); seek(1862.0)">
              if you look at this,
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:05,750'); seek(1865.0)">
              as I said, we are going to actually take a large corpus of text
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:09,464'); seek(1869.0)">
              in Tamil. We will use this large corpus of
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:12,808'); seek(1872.0)">
              text for data ingestion purpose. Now, in this case,
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:31:16,152'); seek(1876.0)">
              I have actually taken the dump from this
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:31:19,532'); seek(1879.0)">
              particular URL. You could very well actually get it from whatever
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:31:23,772'); seek(1883.0)">
              of your choice. But ideally, Aws, I said your
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:31:26,892'); seek(1886.0)">
              model is as good as your data. So always please be
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:31:32,110'); seek(1892.0)">
              careful with the data that you choose.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:31:36,350'); seek(1896.0)">
              In my case, I've chosen it from wiki dump. It's totally up
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:31:40,128'); seek(1900.0)">
              to you where you get it from, but more the data,
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:31:43,890'); seek(1903.0)">
              more you could learn and actually the inferences
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:31:47,770'); seek(1907.0)">
              could be a lot better. Now, we have downloaded this wiki
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:31:52,154'); seek(1912.0)">
              dump. Now there is this wiki extractor py
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:55,790'); seek(1915.0)">
              script created by Atadi.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:59,030'); seek(1919.0)">
              You could find it in GitHub. What we are doing
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:02,792'); seek(1922.0)">
              here is we are actually passing the dump that we have got and
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:06,812'); seek(1926.0)">
              we are doing extraction of that data.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:11,244'); seek(1931.0)">
              So we have downloaded that extractor
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:14,706'); seek(1934.0)">
              script and we are using that extractor script to
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:18,800'); seek(1938.0)">
              extract these information from the dump.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:23,062'); seek(1943.0)">
              So what this extractor would do is just cleanse the data and
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:27,424'); seek(1947.0)">
              make it easy for us to do the machine learning model training.
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:31,184'); seek(1951.0)">
              So as you see, it has picked up that file and it has actually given
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:32:35,140'); seek(1955.0)">
              us the list of words that we could actually pass
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:32:39,636'); seek(1959.0)">
              in for our training stage. So we have all
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:32:43,492'); seek(1963.0)">
              these tamil words, mudarpakam, katirakalai, katirangalin,
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:32:47,274'); seek(1967.0)">
              patiyal, poviyal, varala, arupuri. So these are
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:32:51,048'); seek(1971.0)">
              all tamil words that it has picked up from the dump. Now,
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:32:54,712'); seek(1974.0)">
              this is a very big dump that I had
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:32:58,492'); seek(1978.0)">
              downloaded, so I didn't want to actually waste
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:02,578'); seek(1982.0)">
              the time during the demo. And hence I have done that hard
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:07,036'); seek(1987.0)">
              task of actually getting this downloaded and training
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:10,560'); seek(1990.0)">
              the model prior to these session. So I'll
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:14,022'); seek(1994.0)">
              just drag to the bottom of extraction
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:18,438'); seek(1998.0)">
              part, or rather the cleanse part,
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:22,430'); seek(2002.0)">
              and these we go. So the extractor is done.
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:26,340'); seek(2006.0)">
              In fact, actually it was just going on for a long time.
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:29,492'); seek(2009.0)">
              I thought I've got enough data, so I just killed it
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:33,124'); seek(2013.0)">
              and to get on with the next stage.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:37,510'); seek(2017.0)">
              But you can actually leave
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:41,592'); seek(2021.0)">
              it for a long time if you want a lot more data.
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:33:46,010'); seek(2026.0)">
              As I said, more the data, more it is good.
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:33:49,930'); seek(2029.0)">
              Now this is where the sagemaker
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:33:53,474'); seek(2033.0)">
              comes to party. If you see here, we are creating a sagemaker.
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:33:57,970'); seek(2037.0)">
              We are importing the sagemaker SDK sagemaker.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:01,206'); seek(2041.0)">
              We are creating a sagemaker session and we are creating
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:05,222'); seek(2045.0)">
              a default bucket that we will use for this
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:09,872'); seek(2049.0)">
              particular training purpose.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:12,690'); seek(2052.0)">
              Now what we are doing is we are uploading the data.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:16,196'); seek(2056.0)">
              So the cleansed data that we
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:19,988'); seek(2059.0)">
              now have got after running that wiki extractor Py
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:23,342'); seek(2063.0)">
              is what is now being pushed to the bucket and
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:27,288'); seek(2067.0)">
              we are also setting the output location for s three.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:31,430'); seek(2071.0)">
              Now those are the basic
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:37,510'); seek(2077.0)">
              constructs that we need from the sage
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:40,622'); seek(2080.0)">
              maker service before we could actually go about
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:46,330'); seek(2086.0)">
              the algorithm side of things.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:50,510'); seek(2090.0)">
              Now, as I said,
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:53,950'); seek(2093.0)">
              using the inbuilt algorithm is just one line of python
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:58,102'); seek(2098.0)">
              code. And there you see we
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:02,788'); seek(2102.0)">
              are from Sagemaker. We are importing
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:05,978'); seek(2105.0)">
              image URis and we are saying image
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:10,634'); seek(2110.0)">
              Blazingtext. Now this brings
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:14,046'); seek(2114.0)">
              you pointer
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:19,374'); seek(2119.0)">
              to the blazingtext algorithm.
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:23,910'); seek(2123.0)">
              And here you see you are using Sagemaker
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:27,234'); seek(2127.0)">
              blazing text container from EU west one.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:33,690'); seek(2133.0)">
              After we create the container object, which now essentially
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:37,778'); seek(2137.0)">
              holds the kind of algorithm that it is going to apply for this
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:41,472'); seek(2141.0)">
              training purpose. Again, as I said in this case we have chosen basing
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:45,014'); seek(2145.0)">
              text. You could either go and choose some
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:49,568'); seek(2149.0)">
              other built algorithm of your choice within
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:54,450'); seek(2154.0)">
              Amazon Sagemaker world, or you could bring in your own
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:58,116'); seek(2158.0)">
              containers that you might have in on premise to use that
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:36:01,188'); seek(2161.0)">
              for your training purpose. And now we are actually creating
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:36:05,406'); seek(2165.0)">
              the estimator object.
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:36:09,350'); seek(2169.0)">
              Now estimator is where we pass
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:36:13,000'); seek(2173.0)">
              the container object. We just created the role
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:36:16,482'); seek(2176.0)">
              that the training job
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:21,356'); seek(2181.0)">
              would assume when it is actually doing the training.
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:24,684'); seek(2184.0)">
              So this role is what is going to allow it to retrieve the data
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:28,796'); seek(2188.0)">
              from s three, push the data back, or push the model
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:32,750'); seek(2192.0)">
              trained model back to s three and do all that sort of start or
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:36,272'); seek(2196.0)">
              any other service it has to interact with. This is the role
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:39,558'); seek(2199.0)">
              that probably will actually control the permissions associated
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:43,178'); seek(2203.0)">
              with that particular training job. We are also giving
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:46,772'); seek(2206.0)">
              it the number of instances we wanted to use for training. As I
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:50,004'); seek(2210.0)">
              said, it is totally dictated
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:54,366'); seek(2214.0)">
              by you. What instances are being used,
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:57,990'); seek(2217.0)">
              how many instances are being used, what instance type is being used
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:37:01,768'); seek(2221.0)">
              and what is the input mode.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:37:06,330'); seek(2226.0)">
              You can actually choose it to be file or
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:37:10,588'); seek(2230.0)">
              there is another option of actually another
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:37:17,452'); seek(2237.0)">
              performance option of input mode. You could go for.
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:37:21,710'); seek(2241.0)">
              And once you choose these parameters
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:37:25,286'); seek(2245.0)">
              and create the estimator object, you then pass
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:37:28,976'); seek(2248.0)">
              the hyperparameters. In this case, we have actually passed the
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:37:32,644'); seek(2252.0)">
              hyperparameters ourselves. But as I said,
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:37:35,956'); seek(2255.0)">
              we could actually use hyperparameter tuning or the hyperparameter
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:37:40,202'); seek(2260.0)">
              optimization option that we had mentioned earlier
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:43,838'); seek(2263.0)">
              and discussed about which could actually do that
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:48,070'); seek(2268.0)">
              iterations to lock in to the
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:51,816'); seek(2271.0)">
              best hyperparameters that will give you the best accuracy and
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:58,730'); seek(2278.0)">
              give you the best performance model that you can choose from.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:38:03,690'); seek(2283.0)">
              Once you set the hyperparameters, you then actually
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:38:09,370'); seek(2289.0)">
              kick start the training by you
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:38:13,472'); seek(2293.0)">
              point these training data that needs to be used and then you kick start
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:38:16,752'); seek(2296.0)">
              the training by calling this fit method.
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:38:19,790'); seek(2299.0)">
              Now, once you say model fit aws, you see here,
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:38:23,572'); seek(2303.0)">
              it starts the training job, it completes
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:38:27,082'); seek(2307.0)">
              the training, and you
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:38:34,148'); seek(2314.0)">
              are going to be just charged for whatever time that
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:38:37,608'); seek(2317.0)">
              the training has run. As you see here,
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:38:40,488'); seek(2320.0)">
              the total training time in seconds is 32 86.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:38:44,264'); seek(2324.0)">
              So these four instances that you had chosen of
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:50,216'); seek(2330.0)">
              type c, four, two, x, lodge, they are
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:53,308'); seek(2333.0)">
              going to be charged only for those whatever seconds,
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:57,618'); seek(2337.0)">
              36 odd seconds or 32 odd seconds that
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:39:01,728'); seek(2341.0)">
              the actual training job took. Now,
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:39:05,230'); seek(2345.0)">
              once the training is completed, the trained model is now uploaded to s three.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:39:09,120'); seek(2349.0)">
              It's now going to be residing in s three. And as
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:39:12,628'); seek(2352.0)">
              I said again earlier during our session,
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:39:16,210'); seek(2356.0)">
              right after this training is completed,
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:39:21,170'); seek(2361.0)">
              if you are happy with these accuracy, usually our customers choose
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:39:25,016'); seek(2365.0)">
              to have a validation stage. So one of your
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:39:28,536'); seek(2368.0)">
              data engineers or data scientists,
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:39:31,822'); seek(2371.0)">
              whoever controls what model gets deployed in production,
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:39:35,730'); seek(2375.0)">
              might get an approval task,
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:39:38,818'); seek(2378.0)">
              and they will see whether these accuracy of
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:39:42,268'); seek(2382.0)">
              the model is good enough to be deployed in
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:39:45,548'); seek(2385.0)">
              production, and then they will give it a go.
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:39:48,990'); seek(2388.0)">
              So this whole thing actually could be orchestrated
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:39:54,030'); seek(2394.0)">
              in a CI CD fashion. We have got
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:39:57,408'); seek(2397.0)">
              something separately called sagemaker pipelines.
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:40:00,406'); seek(2400.0)">
              It's a feature within Sagemaker that you could leverage. There's no charges
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:40:03,882'); seek(2403.0)">
              for it, it's just the way you can do CI CD for
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:40:08,036'); seek(2408.0)">
              machine learning. All of these tasks,
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:40:11,114'); seek(2411.0)">
              starting from ingestion training
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:40:15,080'); seek(2415.0)">
              and then validating, deploying, all of this could be orchestrated
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:40:18,942'); seek(2418.0)">
              in a totally automated fashion if you want, but deployment
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:40:23,646'); seek(2423.0)">
              itself is just that one line of code that you see
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:40:27,212'); seek(2427.0)">
              there. So I'm happy with this model and I want
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:40:30,348'); seek(2430.0)">
              to deploy it in this particular instance
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:40:33,826'); seek(2433.0)">
              type. And that's it. It gets deployed.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:40:40,270'); seek(2440.0)">
              Now, once it is deployed, you now have an
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:40:43,888'); seek(2443.0)">
              endpoint to do inference against. So if you see here,
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:40:50,130'); seek(2450.0)">
              I am actually creating set of
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:40:55,730'); seek(2455.0)">
              words that I want to use for inference.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:40:59,354'); seek(2459.0)">
              So these, you see, the first word
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:41:02,872'); seek(2462.0)">
              is tamar, the second word
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:41:06,296'); seek(2466.0)">
              is language, or mori music
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:41:12,070'); seek(2472.0)">
              which is in Tamar isai,
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:41:16,010'); seek(2476.0)">
              song is another word which in tamaris pardal,
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:41:21,610'); seek(2481.0)">
              politics in Tamaris Arasiel,
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:41:24,530'); seek(2484.0)">
              leader in Tamaris, Talibar, year in
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:41:28,412'); seek(2488.0)">
              tamaris and century in Tamaris Notranda.
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:41:31,842'); seek(2491.0)">
              So these are random words. Some of them are related, some of them
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:41:35,248'); seek(2495.0)">
              are not related. We will see how the entrance behaves
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:41:41,090'); seek(2501.0)">
              based on the context that it has explored
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:41:47,010'); seek(2507.0)">
              with the blazingtext algorithm that we used for our training purpose.
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:41:51,226'); seek(2511.0)">
              So we are pointing it to the endpoint that we just created
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:41:55,934'); seek(2515.0)">
              by doing the deployment. And now
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:41:59,480'); seek(2519.0)">
              what is happening here is Aws,
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:42:02,552'); seek(2522.0)">
              I pass these words, it is creating vector
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:42:06,274'); seek(2526.0)">
              representation of these words. Now for example,
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:42:11,210'); seek(2531.0)">
              starting from here, you see,
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:42:14,650'); seek(2534.0)">
              until here is the vector representation of word.
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:42:18,524'); seek(2538.0)">
              Now what it is doing is it is actually trying to map these word
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:42:22,336'); seek(2542.0)">
              thumbnail in an n dimensional space.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:42:25,728'); seek(2545.0)">
              And that's why you have so many weird numbers like it's
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:42:30,198'); seek(2550.0)">
              being represented as a list here.
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:42:33,730'); seek(2553.0)">
              So you will get these kind of list for EAch word
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:42:37,492'); seek(2557.0)">
              you are trying to vectorize. And then what
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:42:41,748'); seek(2561.0)">
              you are trying to do is actually map these words that are in
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:42:45,512'); seek(2565.0)">
              n dimensional space into
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:42:49,144'); seek(2569.0)">
              two dimensional space for
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:42:54,390'); seek(2574.0)">
              Your picturization or visualization case.
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:42:58,124'); seek(2578.0)">
              But otherwise, this is where the word tobac
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:43:01,442'); seek(2581.0)">
              actually is trying to do the magic.
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:43:05,770'); seek(2585.0)">
              Once this vectorization is completed,
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:43:08,990'); seek(2588.0)">
              you can now actually,
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:43:12,590'); seek(2592.0)">
              now you have the numerical representation of those words.
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:43:16,064'); seek(2596.0)">
              It's just not zeros and ones, it's this weird list of
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:43:19,712'); seek(2599.0)">
              array that we see there in the top.
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:43:23,970'); seek(2603.0)">
              Now this is the real fun. If you see music,
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:43:29,650'); seek(2609.0)">
              the word isai is closer to the
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:43:34,452'); seek(2614.0)">
              word song because song is paddle.
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:43:37,890'); seek(2617.0)">
              They both are closer. And hence, if you
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:43:41,332'); seek(2621.0)">
              see the relationship or the
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:43:45,884'); seek(2625.0)">
              vector subtraction is giving you 6.17,
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:43:49,794'); seek(2629.0)">
              forget about that number. But that's how close
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:43:53,756'); seek(2633.0)">
              they are is what actually it has inferred. But now
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:43:58,010'); seek(2638.0)">
              if you see politics and leader,
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:44:00,934'); seek(2640.0)">
              yes, they are close. And hence if you see vector of
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:44:04,592'); seek(2644.0)">
              leader minus vector of politics, it's giving you 5.8. They are
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:44:07,968'); seek(2647.0)">
              a lot closer because these
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:44:12,916'); seek(2652.0)">
              are words that appear in contents. Now when I try
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:44:17,060'); seek(2657.0)">
              music and politics,
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:44:21,490'); seek(2661.0)">
              it has figured out that they are bit away than politics
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:44:25,662'); seek(2665.0)">
              and leader. So what we have now
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:44:29,256'); seek(2669.0)">
              achieved is actually we have now created
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:44:32,798'); seek(2672.0)">
              the vector representation of each of these words
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:44:37,128'); seek(2677.0)">
              and have now actually identified the distance between them
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:44:42,250'); seek(2682.0)">
              contextually and where
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:44:45,676'); seek(2685.0)">
              would they sit in an n dimensional space in
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:44:50,688'); seek(2690.0)">
              terms of context. So that's what our inferences achieved.
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:44:54,102'); seek(2694.0)">
              Now, because I restricted
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:44:58,198'); seek(2698.0)">
              myself to less words within our carpus
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:45:04,350'); seek(2704.0)">
              and did not bother much about
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:45:07,556'); seek(2707.0)">
              accuracy, we are
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:45:11,044'); seek(2711.0)">
              seeing what we are seeing, but with
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:45:14,472'); seek(2714.0)">
              bit more effort on hyperparameter optimization.
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:45:17,710'); seek(2717.0)">
              This can be lot accurate and very
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:45:22,552'); seek(2722.0)">
              interesting inference could be made from this one. Now another
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:45:26,140'); seek(2726.0)">
              trick that I probably mentioned earlier was you could actually bring in
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:45:30,268'); seek(2730.0)">
              the model and unpack it and
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:45:34,092'); seek(2734.0)">
              apply matte plotlib techniques
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:45:38,262'); seek(2738.0)">
              to actually create a
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:45:41,584'); seek(2741.0)">
              two dimensional representation of these words later
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:45:46,016'); seek(2746.0)">
              on. But I think with
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:45:52,372'); seek(2752.0)">
              that we come to the end of this session. Just to summarize,
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:45:56,234'); seek(2756.0)">
              we started with an unknown language, the language of Tamar,
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:46:00,634'); seek(2760.0)">
              and then we understood what is word to wake
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:46:04,158'); seek(2764.0)">
              and what is word embedding and why do we
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:46:07,368'); seek(2767.0)">
              need to do that. And then we introduced sagemaker
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:46:11,598'); seek(2771.0)">
              as a platform and lot of features that comes packed
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:46:15,762'); seek(2775.0)">
              into it and how sage Maker as a platform could actually
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:46:19,100'); seek(2779.0)">
              help you in making your machine learning development lifecycle
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:46:22,850'); seek(2782.0)">
              lot simpler by offloading
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:46:26,530'); seek(2786.0)">
              the undifferentiated heavy lifting you will be doing at
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:46:30,688'); seek(2790.0)">
              the moment. And we also explored how
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:46:34,112'); seek(2794.0)">
              easy it is to actually apply the
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:46:38,176'); seek(2798.0)">
              placing text algorithm on the data of your choice
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:46:42,618'); seek(2802.0)">
              by simple demo that we saw at the
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:46:45,988'); seek(2805.0)">
              later part of the session. Now,
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:46:48,948'); seek(2808.0)">
              I believe this would have created some sort of interest within
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:46:54,036'); seek(2814.0)">
              you to actually go and explore the natural language processing
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:46:57,818'); seek(2817.0)">
              using some of the input algorithms we have within Sagemaker or
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:47:01,812'); seek(2821.0)">
              the algorithm of your choice and play
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:47:05,996'); seek(2825.0)">
              with one of your favorite language of your choice
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:47:09,698'); seek(2829.0)">
              and explore the world of machine learning within the AWS
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:47:12,882'); seek(2832.0)">
              ecosystem. Thanks for joining the session. It was my pleasure to
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:47:16,172'); seek(2836.0)">
              actually give this session for you and wishing you a great day ahead.
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:47:19,692'); seek(2839.0)">
              Bye now.
            </span>
            
            </div>
          </div>
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2021" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 23 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/ml_dinesh.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Dinesh Subramani
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Solutions Architect @ AWS
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/dsubramani/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Dinesh Subramani's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Dinesh Subramani"
                  data-url="https://www.conf42.com/ml2021"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2021"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Machine Learning"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>