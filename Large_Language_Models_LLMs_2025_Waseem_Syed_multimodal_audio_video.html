<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: LLM-Enhanced Multimodal AI: Revolutionizing Audio & Video Interaction Technologies</title>
    <meta name="description" content="One model, extra large, please!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Waseem%20Syed_llm.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="LLM-Enhanced Multimodal AI: Revolutionizing Audio & Video Interaction Technologies | Conf42"/>
    <meta property="og:description" content="Discover how LLM-enhanced AI revolutionizes audio/video media, boosting engagement with advanced speaker diarization and topic segmentation. Experience precise navigation and personalized content through sophisticated multimodal technologies to enhance user engagement and accessibility."/>
    <meta property="og:url" content="https://conf42.com/Large_Language_Models_LLMs_2025_Waseem_Syed_multimodal_audio_video"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/IOT2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Internet of Things (IoT) 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-12-18
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/iot2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2026
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2026">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2026">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2026">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2026">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2026">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/dbd2026">
                            Database DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2026">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2026">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/agents2026">
                            AI Agents
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2026">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2026">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2026">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2026">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2026">
                            Chaos Engineering
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <!-- <a class="dropdown-item" href="None">
                            <b>Community platform login</b>
                          </a> -->
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #CCB87B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Large Language Models (LLMs) 2025 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2025-03-20">March 20 2025</time>
              
              - premiere 5PM GMT
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- One model, extra large, please!
 -->
              <script>
                const event_date = new Date("2025-03-20T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-03-20T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "03HizoTNHmM"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrCnqe_gWc_lIVyDmyIx8BQG" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone.", "timestamp": "00:00:00,000", "timestamp_s": 0.0}, {"text": "Welcome to my presentation today on the topic LLM Enhanced Multimodal", "timestamp": "00:00:00,840", "timestamp_s": 0.0}, {"text": "AI and how it is revolutionizing the audio interaction technologies.", "timestamp": "00:00:04,920", "timestamp_s": 4.0}, {"text": "A little bit about me.", "timestamp": "00:00:10,020", "timestamp_s": 10.0}, {"text": "I\u0027m a senior staff software engineer at Intuit with over 17 years of", "timestamp": "00:00:11,130", "timestamp_s": 11.0}, {"text": "software development experience and full stack specializing", "timestamp": "00:00:14,790", "timestamp_s": 14.0}, {"text": "in mobile and AI technologies.", "timestamp": "00:00:18,000", "timestamp_s": 18.0}, {"text": "Currently I lead the development of Gen AI mobile applications.", "timestamp": "00:00:19,920", "timestamp_s": 19.0}, {"text": "I\u0027m passionate about technology and I love learning and sharing my", "timestamp": "00:00:23,805", "timestamp_s": 23.0}, {"text": "knowledge through blocks, webinars, publications, and patented innovations.", "timestamp": "00:00:27,525", "timestamp_s": 27.0}, {"text": "Let\u0027s get started.", "timestamp": "00:00:32,384", "timestamp_s": 32.0}, {"text": "as we see, there\u0027s a significant search in the audio content in the", "timestamp": "00:00:33,775", "timestamp_s": 33.0}, {"text": "past few years, particularly podcasts, audio, audio books, and online courses", "timestamp": "00:00:37,825", "timestamp_s": 37.0}, {"text": "becoming, much more mainstream.", "timestamp": "00:00:42,655", "timestamp_s": 42.0}, {"text": "They emerge as an essential challenge, which is a content overload.", "timestamp": "00:00:44,535", "timestamp_s": 44.0}, {"text": "So with so much material available for listeners, they get.", "timestamp": "00:00:48,585", "timestamp_s": 48.0}, {"text": "Pretty overwhelmed with the share volume of audio content.", "timestamp": "00:00:51,975", "timestamp_s": 51.0}, {"text": "and this could lead to navigational difficulties.", "timestamp": "00:00:55,135", "timestamp_s": 55.0}, {"text": "Unlike text-based mediums where you can easily search or skim for a specific", "timestamp": "00:00:57,715", "timestamp_s": 57.0}, {"text": "information with a simple command.", "timestamp": "00:01:02,665", "timestamp_s": 62.0}, {"text": "F for a control f. Audio is inherently linear, and listeners find it", "timestamp": "00:01:04,465", "timestamp_s": 64.0}, {"text": "cumbersome to manually navigate through hours of content without,", "timestamp": "00:01:09,580", "timestamp_s": 69.0}, {"text": "a clear way to locate a specific information that they\u0027re looking for.", "timestamp": "00:01:13,770", "timestamp_s": 73.0}, {"text": "Ultimately, this creates a gap between what listeners want and", "timestamp": "00:01:17,910", "timestamp_s": 77.0}, {"text": "what is currently available.", "timestamp": "00:01:21,450", "timestamp_s": 81.0}, {"text": "users are looking for a solution that allows them to access relevant", "timestamp": "00:01:23,200", "timestamp_s": 83.0}, {"text": "segments quickly, enabling them to enjoy the benefits of audio content", "timestamp": "00:01:26,830", "timestamp_s": 86.0}, {"text": "without feeling lost in the noise.", "timestamp": "00:01:30,670", "timestamp_s": 90.0}, {"text": "Addressing these challenges is what our AI part solution aims to accomplish.", "timestamp": "00:01:32,880", "timestamp_s": 92.0}, {"text": "Before we get into the solution, let\u0027s take a look at what multimodal AI is.", "timestamp": "00:01:38,240", "timestamp_s": 98.0}, {"text": "Multimodal AI refers to a system that integrates and analyzes, multiple types", "timestamp": "00:01:43,220", "timestamp_s": 103.0}, {"text": "of data, such as text, images, audio, and video simultaneously to, to enhance", "timestamp": "00:01:48,430", "timestamp_s": 108.0}, {"text": "understanding or improve decision making.", "timestamp": "00:01:54,660", "timestamp_s": 114.0}, {"text": "So our multimodal AI part solution addresses, these challenges", "timestamp": "00:01:57,479", "timestamp_s": 117.0}, {"text": "with the following key AI driven technologies, which is.", "timestamp": "00:02:02,179", "timestamp_s": 122.0}, {"text": "Speaker Diarization, which automatically identifies who spoke when in an audio file", "timestamp": "00:02:05,974", "timestamp_s": 125.0}, {"text": "and topic segmentation, which divides an audio recording into meaningful segments", "timestamp": "00:02:13,044", "timestamp_s": 133.0}, {"text": "based on the content and multimodal search interface allows users to interact", "timestamp": "00:02:17,304", "timestamp_s": 137.0}, {"text": "with audio via text and voice queries.", "timestamp": "00:02:21,924", "timestamp_s": 141.0}, {"text": "we leverage the advanced AI models for this, like open AI whisper for", "timestamp": "00:02:25,209", "timestamp_s": 145.0}, {"text": "speech to text transcription, or Google Gemini and various, NLP algorithms", "timestamp": "00:02:30,510", "timestamp_s": 150.0}, {"text": "for content indexing and other things.", "timestamp": "00:02:36,289", "timestamp_s": 156.0}, {"text": "speaker Diarization is a process that determines who\u0027s speaking at a given", "timestamp": "00:02:39,129", "timestamp_s": 159.0}, {"text": "point in time, and this is essential in a. In a multi-speaker setting, such", "timestamp": "00:02:43,389", "timestamp_s": 163.0}, {"text": "as podcasts and panel discussions, the traditional systems, they often", "timestamp": "00:02:47,824", "timestamp_s": 167.0}, {"text": "struggle with accuracy because, they\u0027re often based on, identifying based on", "timestamp": "00:02:51,864", "timestamp_s": 171.0}, {"text": "the, based on the sounds, but not the context and the conversation history.", "timestamp": "00:02:56,435", "timestamp_s": 176.0}, {"text": "but the proposed AI part approach, aims to reduce the diarization, error, rate", "timestamp": "00:03:00,605", "timestamp_s": 180.0}, {"text": "to improve the speaker identification.", "timestamp": "00:03:05,815", "timestamp_s": 185.0}, {"text": "our system also creates, dynamic speaker profiles and metrics showing, speakers", "timestamp": "00:03:08,674", "timestamp_s": 188.0}, {"text": "bio on their speaking frequency.", "timestamp": "00:03:14,635", "timestamp_s": 194.0}, {"text": "This means a listener can actually look at, all the topics that the user has, that", "timestamp": "00:03:16,434", "timestamp_s": 196.0}, {"text": "the speaker has spoken and, they could jump to a particular segment without.", "timestamp": "00:03:20,804", "timestamp_s": 200.0}, {"text": "and skip through all the sections that are not, that, that do not interest them.", "timestamp": "00:03:25,819", "timestamp_s": 205.0}, {"text": "The user could say, query with simple things like watch all segments", "timestamp": "00:03:30,609", "timestamp_s": 210.0}, {"text": "where Jill spoke, or take me to a, segment where John is speaking.", "timestamp": "00:03:35,429", "timestamp_s": 215.0}, {"text": "So these are some examples, and here is an example of how a traditional", "timestamp": "00:03:41,269", "timestamp_s": 221.0}, {"text": "audio-based system looks like with.", "timestamp": "00:03:46,399", "timestamp_s": 226.0}, {"text": "multiple speakers discussing in your, in the top part of the screen where,", "timestamp": "00:03:48,059", "timestamp_s": 228.0}, {"text": "you know they\u0027re introducing themself, talking about inflation, mortgage,", "timestamp": "00:03:53,069", "timestamp_s": 233.0}, {"text": "job market, and so on and so forth.", "timestamp": "00:03:58,149", "timestamp_s": 238.0}, {"text": "once the speaker diarization happens, you would be able to get the", "timestamp": "00:04:00,549", "timestamp_s": 240.0}, {"text": "timestamps or the speaker segments as you could see in this example", "timestamp": "00:04:03,729", "timestamp_s": 243.0}, {"text": "with, in the bottom of your screen.", "timestamp": "00:04:07,449", "timestamp_s": 247.0}, {"text": "With, Imani speaking, zero to two minutes and Jill speaking on different", "timestamp": "00:04:09,439", "timestamp_s": 249.0}, {"text": "segments at two minutes, 10 minutes, 20 minutes, and so on and so forth.", "timestamp": "00:04:14,279", "timestamp_s": 254.0}, {"text": "And, at the end of the Diarization process, you expect, a response to be", "timestamp": "00:04:17,789", "timestamp_s": 257.0}, {"text": "written with this, with this values.", "timestamp": "00:04:22,509", "timestamp_s": 262.0}, {"text": "So topic segmentation helps organize audio content into meaningful segments.", "timestamp": "00:04:24,769", "timestamp_s": 264.0}, {"text": "our system applies.", "timestamp": "00:04:29,409", "timestamp_s": 269.0}, {"text": "NLP techniques like cosign similarity or term frequency inverse document T,", "timestamp": "00:04:30,724", "timestamp_s": 270.0}, {"text": "tf, IDF, to detect the topic, boundaries and group related content together.", "timestamp": "00:04:35,765", "timestamp_s": 275.0}, {"text": "For example, in a two hour long podcast, if you wanna listen to only", "timestamp": "00:04:41,614", "timestamp_s": 281.0}, {"text": "discussions about inflation, you should be able to instantly jump", "timestamp": "00:04:45,755", "timestamp_s": 285.0}, {"text": "to the relevant sections instead of skimming through the entire episode.", "timestamp": "00:04:49,924", "timestamp_s": 289.0}, {"text": "Our multimodal search interface allows user to search for content,", "timestamp": "00:04:53,575", "timestamp_s": 293.0}, {"text": "using text or voice queries.", "timestamp": "00:04:57,465", "timestamp_s": 297.0}, {"text": "So the AI retrieves, answers, based on context instead of relying on generic", "timestamp": "00:04:59,235", "timestamp_s": 299.0}, {"text": "keyword matches, for example, a listener can ask a very, generic question.", "timestamp": "00:05:03,985", "timestamp_s": 303.0}, {"text": "Things like what\u0027s lottery starts on, rising prices.", "timestamp": "00:05:09,395", "timestamp_s": 309.0}, {"text": "The question doesn\u0027t necessarily tell you that this is about inflation, but the", "timestamp": "00:05:13,485", "timestamp_s": 313.0}, {"text": "system, since it\u0027s using, NLP and ai, it should be able to map it, and get to the.", "timestamp": "00:05:17,265", "timestamp_s": 317.0}, {"text": "relevant sections of the video that, that match with this criteria.", "timestamp": "00:05:23,600", "timestamp_s": 323.0}, {"text": "another query could be, did anyone in the panel talk about interest rates or did", "timestamp": "00:05:27,690", "timestamp_s": 327.0}, {"text": "Jill express hope for a better economy?", "timestamp": "00:05:32,880", "timestamp_s": 332.0}, {"text": "and the system, if you see, these are all generic queries and the system", "timestamp": "00:05:35,980", "timestamp_s": 335.0}, {"text": "should be robust enough to handle and give you the segments, as needed.", "timestamp": "00:05:38,830", "timestamp_s": 338.0}, {"text": "To further enhance engagement, our system includes, dynamic annotations", "timestamp": "00:05:42,780", "timestamp_s": 342.0}, {"text": "with, key points appearing during playback, follow up links so", "timestamp": "00:05:47,000", "timestamp_s": 347.0}, {"text": "that the user can explore related content without searching manually.", "timestamp": "00:05:51,230", "timestamp_s": 351.0}, {"text": "integrated note taking, listeners can add timestamp notes for future", "timestamp": "00:05:55,180", "timestamp_s": 355.0}, {"text": "references, and this whole thing transforms the passive learning", "timestamp": "00:05:58,930", "timestamp_s": 358.0}, {"text": "into a very interactive experience.", "timestamp": "00:06:03,160", "timestamp_s": 363.0}, {"text": "So the system also tries to, automatically index based on various criteria, including", "timestamp": "00:06:05,920", "timestamp_s": 365.0}, {"text": "speakers, topics, timestamps, so users can reduce structured segments efficiently.", "timestamp": "00:06:12,570", "timestamp_s": 372.0}, {"text": "For example, educators can use this for organizing their lecture recordings,", "timestamp": "00:06:17,970", "timestamp_s": 377.0}, {"text": "picking, picking topics from various videos and making them easier for the", "timestamp": "00:06:23,050", "timestamp_s": 383.0}, {"text": "students to find specific discussions.", "timestamp": "00:06:26,480", "timestamp_s": 386.0}, {"text": "User feedback is another crucial layer.", "timestamp": "00:06:28,960", "timestamp_s": 388.0}, {"text": "Our system integrates a rating system to evaluate, segment relevance.", "timestamp": "00:06:31,150", "timestamp_s": 391.0}, {"text": "As you might know, as you might wanna know how a certain segment", "timestamp": "00:06:35,490", "timestamp_s": 395.0}, {"text": "in a video is received and not base your opinion on the entire video or", "timestamp": "00:06:39,930", "timestamp_s": 399.0}, {"text": "the feedback for the entire video.", "timestamp": "00:06:43,560", "timestamp_s": 403.0}, {"text": "It happens all the time where people might like certain portions of the", "timestamp": "00:06:45,390", "timestamp_s": 405.0}, {"text": "video, but not the entire video.", "timestamp": "00:06:48,690", "timestamp_s": 408.0}, {"text": "the users would be able to rate segments of the video on not just the entire video.", "timestamp": "00:06:50,675", "timestamp_s": 410.0}, {"text": "This helps you, make much more, data driven decisions or sentiment", "timestamp": "00:06:55,145", "timestamp_s": 415.0}, {"text": "driven decisions, a common section and which is pretty standard.", "timestamp": "00:07:00,360", "timestamp_s": 420.0}, {"text": "And also an analytics dashboard for content creators to understand", "timestamp": "00:07:04,390", "timestamp_s": 424.0}, {"text": "their audience preferences.", "timestamp": "00:07:07,990", "timestamp_s": 427.0}, {"text": "Now let\u0027s dive into the technical details of this, that powers the", "timestamp": "00:07:09,720", "timestamp_s": 429.0}, {"text": "audio base or, navigation system.", "timestamp": "00:07:13,350", "timestamp_s": 433.0}, {"text": "this system essentially consists of, four layers, input layer, which converts", "timestamp": "00:07:15,740", "timestamp_s": 435.0}, {"text": "a raw audio into structured text, with timestamp, processing layer, which", "timestamp": "00:07:20,340", "timestamp_s": 440.0}, {"text": "uses the AI driven speaker diarization to identify speaker and speakers", "timestamp": "00:07:24,990", "timestamp_s": 444.0}, {"text": "and topic segmentation to break.", "timestamp": "00:07:30,300", "timestamp_s": 450.0}, {"text": "Content into meaningful sections.", "timestamp": "00:07:32,400", "timestamp_s": 452.0}, {"text": "indexing layer, it stores the structured metadata for quick search and retrieval,", "timestamp": "00:07:34,990", "timestamp_s": 454.0}, {"text": "interaction layer, which, or the feedback layer, which will enable", "timestamp": "00:07:40,270", "timestamp_s": 460.0}, {"text": "search and playback functionality using, multimodal input such as text", "timestamp": "00:07:44,310", "timestamp_s": 464.0}, {"text": "queries, voice commands, and contextual recommendations, as well as LLC users to.", "timestamp": "00:07:48,490", "timestamp_s": 468.0}, {"text": "provide, detailed feedback on, digging through various aspects", "timestamp": "00:07:54,125", "timestamp_s": 474.0}, {"text": "of a video, which will help the content recommend, content creators.", "timestamp": "00:07:58,235", "timestamp_s": 478.0}, {"text": "alright, let\u0027s talk a little bit about the, the input layer.", "timestamp": "00:08:02,155", "timestamp_s": 482.0}, {"text": "here, the audio processing is the first step in our pipeline where we convert", "timestamp": "00:08:05,405", "timestamp_s": 485.0}, {"text": "the raw audio into structured text using, a speech transcription model,", "timestamp": "00:08:09,695", "timestamp_s": 489.0}, {"text": "open AI whisper, or, Google Gemini.", "timestamp": "00:08:13,905", "timestamp_s": 493.0}, {"text": "there are quite a few other ones.", "timestamp": "00:08:16,965", "timestamp_s": 496.0}, {"text": "Now, why is this important?", "timestamp": "00:08:18,595", "timestamp_s": 498.0}, {"text": "audio files by themself are not very useful for search,", "timestamp": "00:08:19,705", "timestamp_s": 499.0}, {"text": "so they don\u0027t have structure.", "timestamp": "00:08:22,675", "timestamp_s": 502.0}, {"text": "So if we have timestamp for accurate playback, we would be able to build", "timestamp": "00:08:24,265", "timestamp_s": 504.0}, {"text": "high quality UI where the users, based on these APIs, the users could actually", "timestamp": "00:08:28,765", "timestamp_s": 508.0}, {"text": "go to a particular portion of a video, highlighting, pro providing high", "timestamp": "00:08:33,965", "timestamp_s": 513.0}, {"text": "quality speech to text transcription.", "timestamp": "00:08:38,045", "timestamp_s": 518.0}, {"text": "will definitely help.", "timestamp": "00:08:40,575", "timestamp_s": 520.0}, {"text": "if you have the transcription accurately, accurately, laid out as", "timestamp": "00:08:42,365", "timestamp_s": 522.0}, {"text": "well as the transcription playback is, is the right playback, it", "timestamp": "00:08:47,665", "timestamp_s": 527.0}, {"text": "matches with your, with the input.", "timestamp": "00:08:52,055", "timestamp_s": 532.0}, {"text": "audio speed, whisper, tends to perform better.", "timestamp": "00:08:53,625", "timestamp_s": 533.0}, {"text": "At least that\u0027s the experience that I have.", "timestamp": "00:08:57,085", "timestamp_s": 537.0}, {"text": "it gives you the exact.", "timestamp": "00:08:59,325", "timestamp_s": 539.0}, {"text": "timestamps as well as the, as well as the exact time, playback speed so that", "timestamp": "00:09:01,230", "timestamp_s": 541.0}, {"text": "if you\u0027re building experiences, you are accurately landing on the right", "timestamp": "00:09:05,750", "timestamp_s": 545.0}, {"text": "point, when you search for a keyword.", "timestamp": "00:09:10,380", "timestamp_s": 550.0}, {"text": "so.", "timestamp": "00:09:13,160", "timestamp_s": 553.0}, {"text": "let\u0027s check out the code a little bit.", "timestamp": "00:09:14,440", "timestamp_s": 554.0}, {"text": "we send the audio file to whisper API and it returns a structured text.", "timestamp": "00:09:15,880", "timestamp_s": 555.0}, {"text": "the, this is just a pseudo code example.", "timestamp": "00:09:21,170", "timestamp_s": 561.0}, {"text": "The response include, word level timestamps, which means we can align,", "timestamp": "00:09:23,930", "timestamp_s": 563.0}, {"text": "spoken words to actual audio moments.", "timestamp": "00:09:27,750", "timestamp_s": 567.0}, {"text": "And the output also has things like, an entire transcript.", "timestamp": "00:09:30,180", "timestamp_s": 570.0}, {"text": "Plus metadata, like duration, detected language, word timing, and all of these", "timestamp": "00:09:33,560", "timestamp_s": 573.0}, {"text": "would be used in the, in the next layers.", "timestamp": "00:09:38,640", "timestamp_s": 578.0}, {"text": "And why is this important?", "timestamp": "00:09:40,950", "timestamp_s": 580.0}, {"text": "Because if a user searches for a phrase, we should be able to jump straight", "timestamp": "00:09:42,360", "timestamp_s": 582.0}, {"text": "to the exact moment it was spoken.", "timestamp": "00:09:46,800", "timestamp_s": 586.0}, {"text": "And, and these step is essential for the, for the next layers.", "timestamp": "00:09:48,870", "timestamp_s": 588.0}, {"text": "let\u0027s talk about Speaker Diarization, which is another step in the,", "timestamp": "00:09:53,320", "timestamp_s": 593.0}, {"text": "processing layer and how we are making it better using the, NLPs and LLMs.", "timestamp": "00:09:57,020", "timestamp_s": 597.0}, {"text": "normally Speaker Diarization is done with, caustic, models that just", "timestamp": "00:10:03,400", "timestamp_s": 603.0}, {"text": "try to figure out who\u0027s speaking based on voice characteristics.", "timestamp": "00:10:08,030", "timestamp_s": 608.0}, {"text": "But, sometimes people.", "timestamp": "00:10:11,780", "timestamp_s": 611.0}, {"text": "multiple people sound similar or the audio quality, isn\u0027t great all the time.", "timestamp": "00:10:14,130", "timestamp_s": 614.0}, {"text": "So here\u0027s what we do instead, we start with the transcription.", "timestamp": "00:10:19,390", "timestamp_s": 619.0}, {"text": "we get the words, timestamps, and the entire, metadata that we just discussed.", "timestamp": "00:10:22,460", "timestamp_s": 622.0}, {"text": "We chunk the transcript into segments.", "timestamp": "00:10:27,010", "timestamp_s": 627.0}, {"text": "We assume that if there\u0027s, the system makes some, calculated", "timestamp": "00:10:29,650", "timestamp_s": 629.0}, {"text": "assumptions, based on pauses.", "timestamp": "00:10:33,060", "timestamp_s": 633.0}, {"text": "instead of, relying on the voice characteristics, the system also,", "timestamp": "00:10:35,370", "timestamp_s": 635.0}, {"text": "analyzes the, conversation history or, what\u0027s being spoken, based on", "timestamp": "00:10:39,580", "timestamp_s": 639.0}, {"text": "the context and things like that.", "timestamp": "00:10:44,680", "timestamp_s": 644.0}, {"text": "and this will give you, a structured JSON that tells you who spoke when, an", "timestamp": "00:10:46,790", "timestamp_s": 646.0}, {"text": "example of a query, in this layer would look something like, if you want to", "timestamp": "00:10:50,610", "timestamp_s": 650.0}, {"text": "use that, bill, UI for these APIs who spoke in each segment of this podcast.", "timestamp": "00:10:55,210", "timestamp_s": 655.0}, {"text": "This could be a simple query and that should give you a list", "timestamp": "00:11:00,610", "timestamp_s": 660.0}, {"text": "of, segments for each speaker.", "timestamp": "00:11:03,400", "timestamp_s": 663.0}, {"text": "And here\u0027s a simple pseudocode example on, how this thing works.", "timestamp": "00:11:06,070", "timestamp_s": 666.0}, {"text": "So we get the transcript, chunk it, based on, some calculated guesses.", "timestamp": "00:11:09,770", "timestamp_s": 669.0}, {"text": "and, by the LLMs and formatted, formatted, we call the LLMs with,", "timestamp": "00:11:14,690", "timestamp_s": 674.0}, {"text": "our structured prompt and it written speaker assignments, we pass that", "timestamp": "00:11:19,180", "timestamp_s": 679.0}, {"text": "output into a JSON format that\u0027s easier to use and to build any experiences.", "timestamp": "00:11:23,920", "timestamp_s": 683.0}, {"text": "so this is great for podcast meetings, interviews, basically any", "timestamp": "00:11:29,195", "timestamp_s": 689.0}, {"text": "conversation where traditional speaker diarization struggles and it\u0027s more", "timestamp": "00:11:32,495", "timestamp_s": 692.0}, {"text": "accurate when it, because it actually understands, more than just the voice.", "timestamp": "00:11:37,025", "timestamp_s": 697.0}, {"text": "but the, the context and it does a lot of analysis on what\u0027s being", "timestamp": "00:11:41,095", "timestamp_s": 701.0}, {"text": "spoken and what\u0027s being discussed.", "timestamp": "00:11:44,805", "timestamp_s": 704.0}, {"text": "topic segmentation uses, NLP and LLMs to divide and classify the topics.", "timestamp": "00:11:47,015", "timestamp_s": 707.0}, {"text": "segment them, segment transcripts using, timestamps and detect,", "timestamp": "00:11:53,465", "timestamp_s": 713.0}, {"text": "topic shifts in conversations.", "timestamp": "00:11:58,115", "timestamp_s": 718.0}, {"text": "So it can also categorize segments into themes, and use LLMs to assign", "timestamp": "00:12:00,155", "timestamp_s": 720.0}, {"text": "topic labels for audio systems and developers can build, these,", "timestamp": "00:12:05,185", "timestamp_s": 725.0}, {"text": "multifaceted UIs using these APIs.", "timestamp": "00:12:09,495", "timestamp_s": 729.0}, {"text": "an example query, of this layer.", "timestamp": "00:12:12,185", "timestamp_s": 732.0}, {"text": "how this would be useful is if you wanna find all sections", "timestamp": "00:12:14,495", "timestamp_s": 734.0}, {"text": "using AI ethics, in this podcast.", "timestamp": "00:12:18,425", "timestamp_s": 738.0}, {"text": "find all sections, during discussing AI ethics in this podcast.", "timestamp": "00:12:21,435", "timestamp_s": 741.0}, {"text": "And that should be able to get you a list of items, of all the portions or", "timestamp": "00:12:25,605", "timestamp_s": 745.0}, {"text": "sections that talk about this topic.", "timestamp": "00:12:29,915", "timestamp_s": 749.0}, {"text": "And this is, once the, once you have these APIs and the timestamps, the, the", "timestamp": "00:12:32,455", "timestamp_s": 752.0}, {"text": "next steps are usually faster because you\u0027re not analyzing the entire video.", "timestamp": "00:12:37,615", "timestamp_s": 757.0}, {"text": "You\u0027re just, referring through your metadata.", "timestamp": "00:12:41,485", "timestamp_s": 761.0}, {"text": "And you are, you\u0027re playing back based on, a certain timestamp,", "timestamp": "00:12:43,315", "timestamp_s": 763.0}, {"text": "based on the criteria that is given.", "timestamp": "00:12:47,085", "timestamp_s": 767.0}, {"text": "Either, either it\u0027s a speaker that you wanna land, it based, a speaker.", "timestamp": "00:12:48,855", "timestamp_s": 768.0}, {"text": "speaking, a particular topic that you wanna land on or a topic itself that\u0027s", "timestamp": "00:12:54,055", "timestamp_s": 774.0}, {"text": "segmented that you want to land on.", "timestamp": "00:12:57,795", "timestamp_s": 777.0}, {"text": "so it becomes much faster because you\u0027re just dealing with the metadata and not", "timestamp": "00:12:59,255", "timestamp_s": 779.0}, {"text": "analyzing the video again and again.", "timestamp": "00:13:02,875", "timestamp_s": 782.0}, {"text": "let\u0027s discuss how we handle topic segmentation, using the transcript", "timestamp": "00:13:04,985", "timestamp_s": 784.0}, {"text": "from the, from the input layer.", "timestamp": "00:13:08,525", "timestamp_s": 788.0}, {"text": "in a long form audio topics shift.", "timestamp": "00:13:11,020", "timestamp_s": 791.0}, {"text": "frequently users want to jump directly to relevant sections", "timestamp": "00:13:13,180", "timestamp_s": 793.0}, {"text": "without scrapping to recordings.", "timestamp": "00:13:17,170", "timestamp_s": 797.0}, {"text": "So our solution automates topic detection and labeling for seamless navigation.", "timestamp": "00:13:19,030", "timestamp_s": 799.0}, {"text": "So we chunk the transcript, use the, output that we received from the", "timestamp": "00:13:24,130", "timestamp_s": 804.0}, {"text": "previous layer with word timestamp, group the words together into, on", "timestamp": "00:13:27,690", "timestamp_s": 807.0}, {"text": "regular intervals for adequate context.", "timestamp": "00:13:32,470", "timestamp_s": 812.0}, {"text": "compute, text, similar, text similarity.", "timestamp": "00:13:35,305", "timestamp_s": 815.0}, {"text": "Convert the segment.", "timestamp": "00:13:38,075", "timestamp_s": 818.0}, {"text": "text into TFID effect, calculate similarity between adjucent", "timestamp": "00:13:38,915", "timestamp_s": 818.0}, {"text": "segments to assess the relevance.", "timestamp": "00:13:44,015", "timestamp_s": 824.0}, {"text": "detect the topic shifts, assign topics using, LLMs, send the segmented text", "timestamp": "00:13:46,275", "timestamp_s": 826.0}, {"text": "to GPT-4 or, or relevant, models for descriptive topic labeling and structured", "timestamp": "00:13:51,215", "timestamp_s": 831.0}, {"text": "the output for search and playback.", "timestamp": "00:13:57,535", "timestamp_s": 837.0}, {"text": "and.", "timestamp": "00:13:59,795", "timestamp_s": 839.0}, {"text": "users should be able to quickly search and jump to any topic that they like.", "timestamp": "00:14:00,330", "timestamp_s": 840.0}, {"text": "Indexing layer.", "timestamp": "00:14:04,370", "timestamp_s": 844.0}, {"text": "Once we have the structured data from processing layer, which includes,", "timestamp": "00:14:05,210", "timestamp_s": 845.0}, {"text": "sp label, text, and topic segmented content, we need a fast and scalable", "timestamp": "00:14:08,890", "timestamp_s": 848.0}, {"text": "way to search and retrieve it.", "timestamp": "00:14:13,480", "timestamp_s": 853.0}, {"text": "And this is often now done on metadata, so it should be faster.", "timestamp": "00:14:15,100", "timestamp_s": 855.0}, {"text": "So how does the indexing layer work?", "timestamp": "00:14:18,100", "timestamp_s": 858.0}, {"text": "It stores the segments efficiently.", "timestamp": "00:14:19,660", "timestamp_s": 859.0}, {"text": "Each segment is stored in a database with a topic.", "timestamp": "00:14:21,820", "timestamp_s": 861.0}, {"text": "or speaker or start end and, start date, start time and end time.", "timestamp": "00:14:24,135", "timestamp_s": 864.0}, {"text": "And this allows us to map conversation to structured metadata for easier lookup.", "timestamp": "00:14:28,440", "timestamp_s": 868.0}, {"text": "And the next step would be creating faster, indexes where we index the", "timestamp": "00:14:33,240", "timestamp_s": 873.0}, {"text": "data by topic, speaker, and timestamps.", "timestamp": "00:14:38,430", "timestamp_s": 878.0}, {"text": "And this enables quick, full text searches so users can jump to any", "timestamp": "00:14:41,725", "timestamp_s": 881.0}, {"text": "sections instantly and retrieving segments versus, multiple, filters.", "timestamp": "00:14:46,125", "timestamp_s": 886.0}, {"text": "retrieving segments, versus multiple filters.", "timestamp": "00:14:51,305", "timestamp_s": 891.0}, {"text": "users can actually search by different things like topics,", "timestamp": "00:14:53,425", "timestamp_s": 893.0}, {"text": "speaker, timestamp, et cetera.", "timestamp": "00:14:56,725", "timestamp_s": 896.0}, {"text": "And this is optimized for speed and scalability and exposing APIs, and it", "timestamp": "00:14:58,585", "timestamp_s": 898.0}, {"text": "exposes APIs for, for the clients to make, build those experiences, with", "timestamp": "00:15:02,625", "timestamp_s": 902.0}, {"text": "search, based on different criteria.", "timestamp": "00:15:07,805", "timestamp_s": 907.0}, {"text": "And why this is powerful.", "timestamp": "00:15:09,735", "timestamp_s": 909.0}, {"text": "This is powerful because users can find exactly what they need without", "timestamp": "00:15:11,085", "timestamp_s": 911.0}, {"text": "scrubbing through long videos, and they have different criteria to search from.", "timestamp": "00:15:14,835", "timestamp_s": 914.0}, {"text": "And, just a high level depiction of how, different layers of this, indexing layer.", "timestamp": "00:15:18,605", "timestamp_s": 918.0}, {"text": "So the input of this layer would be the data reiterate from the processing layer.", "timestamp": "00:15:23,275", "timestamp_s": 923.0}, {"text": "Things like topic, speaker, certain end times, et cetera.", "timestamp": "00:15:27,020", "timestamp_s": 927.0}, {"text": "the output of this layer is expected to be an index storage and for enabling", "timestamp": "00:15:30,300", "timestamp_s": 930.0}, {"text": "faster or, faster search or indexing.", "timestamp": "00:15:34,290", "timestamp_s": 934.0}, {"text": "First step would be to save the data, in, and then, index the data by key attributes", "timestamp": "00:15:36,730", "timestamp_s": 936.0}, {"text": "such as topic, speaker, and timestamps.", "timestamp": "00:15:42,270", "timestamp_s": 942.0}, {"text": "enable full tech search, capabilities to handle keyword", "timestamp": "00:15:44,980", "timestamp_s": 944.0}, {"text": "queries effectively and support.", "timestamp": "00:15:48,240", "timestamp_s": 948.0}, {"text": "Time-based, queries, so that you can jump to a particular, time in the video.", "timestamp": "00:15:50,660", "timestamp_s": 950.0}, {"text": "for optimizing performance.", "timestamp": "00:15:55,970", "timestamp_s": 955.0}, {"text": "we use the caching strategies to, accelerate, frequent queries or", "timestamp": "00:15:57,410", "timestamp_s": 957.0}, {"text": "implement ation to manage large sets of DA data efficiently.", "timestamp": "00:16:01,855", "timestamp_s": 961.0}, {"text": "Or, if you want to go advance, you can build a rag with the, data", "timestamp": "00:16:06,075", "timestamp_s": 966.0}, {"text": "to store and retrieve information from a Vector database for", "timestamp": "00:16:10,285", "timestamp_s": 970.0}, {"text": "accurate and relevant results.", "timestamp": "00:16:13,495", "timestamp_s": 973.0}, {"text": "And finally, in this layer, it provides API endpoints for external", "timestamp": "00:16:15,355", "timestamp_s": 975.0}, {"text": "facing, fetching externally, fetching the, index, segments.", "timestamp": "00:16:19,425", "timestamp_s": 979.0}, {"text": "And it enables seamless content navigation.", "timestamp": "00:16:23,755", "timestamp_s": 983.0}, {"text": "And let\u0027s go over the final layer, which is the integration,", "timestamp": "00:16:27,165", "timestamp_s": 987.0}, {"text": "interaction and the feedback layer.", "timestamp": "00:16:29,595", "timestamp_s": 989.0}, {"text": "So this layer, let\u0027s say this layer is very important because if you have,", "timestamp": "00:16:31,695", "timestamp_s": 991.0}, {"text": "let\u0027s say, a user, you know that, that is listening to an hour long podcast,", "timestamp": "00:16:35,925", "timestamp_s": 995.0}, {"text": "but they would, they have some questions that they want to answer, they could", "timestamp": "00:16:40,165", "timestamp_s": 1000.0}, {"text": "simply ask a question that says, what did John say about, AI ethics?", "timestamp": "00:16:43,695", "timestamp_s": 1003.0}, {"text": "So the multi-model interaction for seamless search will, would", "timestamp": "00:16:48,435", "timestamp_s": 1008.0}, {"text": "essentially, query, based on how you query, any, any text space system.", "timestamp": "00:16:51,865", "timestamp_s": 1011.0}, {"text": "And it provides a real time feedback to improve accuracy as well, because,", "timestamp": "00:16:57,235", "timestamp_s": 1017.0}, {"text": "you wanna learn as the, as more users are adopting the system or", "timestamp": "00:17:02,025", "timestamp_s": 1022.0}, {"text": "adopting, or watching the videos.", "timestamp": "00:17:06,185", "timestamp_s": 1026.0}, {"text": "AI powered personalization and recommendations.", "timestamp": "00:17:08,260", "timestamp_s": 1028.0}, {"text": "So over the time the system learns, user preferences as well.", "timestamp": "00:17:10,480", "timestamp_s": 1030.0}, {"text": "and you could make, data driven, decisions based on it.", "timestamp": "00:17:14,470", "timestamp_s": 1034.0}, {"text": "And here\u0027s a high level exam, high level depiction of how this", "timestamp": "00:17:18,470", "timestamp_s": 1038.0}, {"text": "feedback layer would look like.", "timestamp": "00:17:22,010", "timestamp_s": 1042.0}, {"text": "it takes the user queries, playback interaction, run ratings", "timestamp": "00:17:23,790", "timestamp_s": 1043.0}, {"text": "as input and generates enhanced recommendations using the queries", "timestamp": "00:17:26,790", "timestamp_s": 1046.0}, {"text": "and indexing from the index layer.", "timestamp": "00:17:30,360", "timestamp_s": 1050.0}, {"text": "So it also ensures, improved accuracy and facilitates, learning based on", "timestamp": "00:17:33,240", "timestamp_s": 1053.0}, {"text": "the feedback as a user interacts or searches feedback is collected", "timestamp": "00:17:37,370", "timestamp_s": 1057.0}, {"text": "real time, which will be used to adjust AI models and generate.", "timestamp": "00:17:41,120", "timestamp_s": 1061.0}, {"text": "Personalized recommendations and improved accuracy and precision", "timestamp": "00:17:45,640", "timestamp_s": 1065.0}, {"text": "over the period of time.", "timestamp": "00:17:48,550", "timestamp_s": 1068.0}, {"text": "The system can leverage these APIs to build features to expose, search", "timestamp": "00:17:49,810", "timestamp_s": 1069.0}, {"text": "and personalized playback, APIs providing, interactive user experience.", "timestamp": "00:17:53,530", "timestamp_s": 1073.0}, {"text": "So to summarize our proposed system, it offers several key benefits.", "timestamp": "00:17:58,250", "timestamp_s": 1078.0}, {"text": "It, it transforms the passive listening to an interactive and structured experience", "timestamp": "00:18:02,380", "timestamp_s": 1082.0}, {"text": "where listeners can effectively find and engage with, with the audio content.", "timestamp": "00:18:06,590", "timestamp_s": 1086.0}, {"text": "it, it is efficient, in terms of topic and speaker classification.", "timestamp": "00:18:10,900", "timestamp_s": 1090.0}, {"text": "It gives you a real time search and learning mechanism, and", "timestamp": "00:18:15,480", "timestamp_s": 1095.0}, {"text": "also a feedback system that is continuously learning and helps you", "timestamp": "00:18:18,180", "timestamp_s": 1098.0}, {"text": "with the advanced personalization.", "timestamp": "00:18:21,990", "timestamp_s": 1101.0}, {"text": "And this framework is scalable because a system is designed to accommodate", "timestamp": "00:18:23,940", "timestamp_s": 1103.0}, {"text": "various audio formats, such as podcasts and webinars, making it versatile and", "timestamp": "00:18:27,540", "timestamp_s": 1107.0}, {"text": "applicable across different use cases.", "timestamp": "00:18:31,260", "timestamp_s": 1111.0}, {"text": "Improved accessibility is often, underlooked, but the system provides", "timestamp": "00:18:33,585", "timestamp_s": 1113.0}, {"text": "features such as voice queries and easy navigation aids, supporting", "timestamp": "00:18:36,965", "timestamp_s": 1116.0}, {"text": "diverse population, user needs, and ensuring that all the listeners have", "timestamp": "00:18:40,445", "timestamp_s": 1120.0}, {"text": "the access to the audio contact.", "timestamp": "00:18:45,095", "timestamp_s": 1125.0}, {"text": "So con in con, in conclusion, there\u0027s this research from Edison", "timestamp": "00:18:47,215", "timestamp_s": 1127.0}, {"text": "that says more than 45% of the audio driven platforms, are on demand.", "timestamp": "00:18:51,805", "timestamp_s": 1131.0}, {"text": "and these are, 45% are on demand platforms, which, consumers listen", "timestamp": "00:18:57,705", "timestamp_s": 1137.0}, {"text": "to, including podcasts, meetings, education, and enterprise applications.", "timestamp": "00:19:02,555", "timestamp_s": 1142.0}, {"text": "These.", "timestamp": "00:19:06,865", "timestamp_s": 1146.0}, {"text": "You know these things.", "timestamp": "00:19:07,395", "timestamp_s": 1147.0}, {"text": "They present an opportunity for AI powered, navigation systems by", "timestamp": "00:19:08,145", "timestamp_s": 1148.0}, {"text": "transforming the unstructured speech into searchable interactive content.", "timestamp": "00:19:12,815", "timestamp_s": 1152.0}, {"text": "This approach enhances user engagement, improves accessibility, and drives", "timestamp": "00:19:17,105", "timestamp_s": 1157.0}, {"text": "intelligent content discovery at scale.", "timestamp": "00:19:21,455", "timestamp_s": 1161.0}, {"text": "So that\u0027s all from me.", "timestamp": "00:19:23,845", "timestamp_s": 1163.0}, {"text": "thank you for joining.", "timestamp": "00:19:25,185", "timestamp_s": 1165.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '03HizoTNHmM',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              LLM-Enhanced Multimodal AI: Revolutionizing Audio & Video Interaction Technologies
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Discover how LLM-enhanced AI revolutionizes audio/video media, boosting engagement with advanced speaker diarization and topic segmentation. Experience precise navigation and personalized content through sophisticated multimodal technologies to enhance user engagement and accessibility.</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/llms2025_Waseem_Syed.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,000'); seek(0.0)">
              Hi everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:00,840'); seek(0.0)">
              Welcome to my presentation today on the topic LLM Enhanced Multimodal
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:04,920'); seek(4.0)">
              AI and how it is revolutionizing the audio interaction technologies.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:10,020'); seek(10.0)">
              A little bit about me.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:11,130'); seek(11.0)">
              I'm a senior staff software engineer at Intuit with over 17 years of
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:14,790'); seek(14.0)">
              software development experience and full stack specializing
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:18,000'); seek(18.0)">
              in mobile and AI technologies.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:19,920'); seek(19.0)">
              Currently I lead the development of Gen AI mobile applications.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:23,805'); seek(23.0)">
              I'm passionate about technology and I love learning and sharing my
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:27,525'); seek(27.0)">
              knowledge through blocks, webinars, publications, and patented innovations.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:32,384'); seek(32.0)">
              Let's get started.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:33,775'); seek(33.0)">
              as we see, there's a significant search in the audio content in the
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:37,825'); seek(37.0)">
              past few years, particularly podcasts, audio, audio books, and online courses
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:42,655'); seek(42.0)">
              becoming, much more mainstream.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:44,535'); seek(44.0)">
              They emerge as an essential challenge, which is a content overload.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:48,585'); seek(48.0)">
              So with so much material available for listeners, they get.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:51,975'); seek(51.0)">
              Pretty overwhelmed with the share volume of audio content.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:55,135'); seek(55.0)">
              and this could lead to navigational difficulties.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:00:57,715'); seek(57.0)">
              Unlike text-based mediums where you can easily search or skim for a specific
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:02,665'); seek(62.0)">
              information with a simple command.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:04,465'); seek(64.0)">
              F for a control f. Audio is inherently linear, and listeners find it
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:09,580'); seek(69.0)">
              cumbersome to manually navigate through hours of content without,
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:13,770'); seek(73.0)">
              a clear way to locate a specific information that they're looking for.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:17,910'); seek(77.0)">
              Ultimately, this creates a gap between what listeners want and
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:21,450'); seek(81.0)">
              what is currently available.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:23,200'); seek(83.0)">
              users are looking for a solution that allows them to access relevant
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:26,830'); seek(86.0)">
              segments quickly, enabling them to enjoy the benefits of audio content
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:30,670'); seek(90.0)">
              without feeling lost in the noise.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:32,880'); seek(92.0)">
              Addressing these challenges is what our AI part solution aims to accomplish.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:38,240'); seek(98.0)">
              Before we get into the solution, let's take a look at what multimodal AI is.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:43,220'); seek(103.0)">
              Multimodal AI refers to a system that integrates and analyzes, multiple types
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:48,430'); seek(108.0)">
              of data, such as text, images, audio, and video simultaneously to, to enhance
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:54,660'); seek(114.0)">
              understanding or improve decision making.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:01:57,479'); seek(117.0)">
              So our multimodal AI part solution addresses, these challenges
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:02,179'); seek(122.0)">
              with the following key AI driven technologies, which is.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:05,974'); seek(125.0)">
              Speaker Diarization, which automatically identifies who spoke when in an audio file
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:13,044'); seek(133.0)">
              and topic segmentation, which divides an audio recording into meaningful segments
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:17,304'); seek(137.0)">
              based on the content and multimodal search interface allows users to interact
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:21,924'); seek(141.0)">
              with audio via text and voice queries.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:25,209'); seek(145.0)">
              we leverage the advanced AI models for this, like open AI whisper for
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:30,510'); seek(150.0)">
              speech to text transcription, or Google Gemini and various, NLP algorithms
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:36,289'); seek(156.0)">
              for content indexing and other things.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:39,129'); seek(159.0)">
              speaker Diarization is a process that determines who's speaking at a given
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:43,389'); seek(163.0)">
              point in time, and this is essential in a. In a multi-speaker setting, such
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:47,824'); seek(167.0)">
              as podcasts and panel discussions, the traditional systems, they often
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:51,864'); seek(171.0)">
              struggle with accuracy because, they're often based on, identifying based on
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:56,435'); seek(176.0)">
              the, based on the sounds, but not the context and the conversation history.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:00,605'); seek(180.0)">
              but the proposed AI part approach, aims to reduce the diarization, error, rate
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:05,815'); seek(185.0)">
              to improve the speaker identification.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:08,674'); seek(188.0)">
              our system also creates, dynamic speaker profiles and metrics showing, speakers
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:14,635'); seek(194.0)">
              bio on their speaking frequency.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:16,434'); seek(196.0)">
              This means a listener can actually look at, all the topics that the user has, that
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:20,804'); seek(200.0)">
              the speaker has spoken and, they could jump to a particular segment without.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:25,819'); seek(205.0)">
              and skip through all the sections that are not, that, that do not interest them.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:30,609'); seek(210.0)">
              The user could say, query with simple things like watch all segments
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:35,429'); seek(215.0)">
              where Jill spoke, or take me to a, segment where John is speaking.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:41,269'); seek(221.0)">
              So these are some examples, and here is an example of how a traditional
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:46,399'); seek(226.0)">
              audio-based system looks like with.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:48,059'); seek(228.0)">
              multiple speakers discussing in your, in the top part of the screen where,
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:53,069'); seek(233.0)">
              you know they're introducing themself, talking about inflation, mortgage,
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:58,149'); seek(238.0)">
              job market, and so on and so forth.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:00,549'); seek(240.0)">
              once the speaker diarization happens, you would be able to get the
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:03,729'); seek(243.0)">
              timestamps or the speaker segments as you could see in this example
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:07,449'); seek(247.0)">
              with, in the bottom of your screen.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:09,439'); seek(249.0)">
              With, Imani speaking, zero to two minutes and Jill speaking on different
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:14,279'); seek(254.0)">
              segments at two minutes, 10 minutes, 20 minutes, and so on and so forth.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:17,789'); seek(257.0)">
              And, at the end of the Diarization process, you expect, a response to be
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:22,509'); seek(262.0)">
              written with this, with this values.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:24,769'); seek(264.0)">
              So topic segmentation helps organize audio content into meaningful segments.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:29,409'); seek(269.0)">
              our system applies.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:30,724'); seek(270.0)">
              NLP techniques like cosign similarity or term frequency inverse document T,
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:35,765'); seek(275.0)">
              tf, IDF, to detect the topic, boundaries and group related content together.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:41,614'); seek(281.0)">
              For example, in a two hour long podcast, if you wanna listen to only
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:45,755'); seek(285.0)">
              discussions about inflation, you should be able to instantly jump
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:49,924'); seek(289.0)">
              to the relevant sections instead of skimming through the entire episode.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:53,575'); seek(293.0)">
              Our multimodal search interface allows user to search for content,
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:57,465'); seek(297.0)">
              using text or voice queries.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:59,235'); seek(299.0)">
              So the AI retrieves, answers, based on context instead of relying on generic
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:03,985'); seek(303.0)">
              keyword matches, for example, a listener can ask a very, generic question.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:09,395'); seek(309.0)">
              Things like what's lottery starts on, rising prices.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:13,485'); seek(313.0)">
              The question doesn't necessarily tell you that this is about inflation, but the
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:17,265'); seek(317.0)">
              system, since it's using, NLP and ai, it should be able to map it, and get to the.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:23,600'); seek(323.0)">
              relevant sections of the video that, that match with this criteria.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:27,690'); seek(327.0)">
              another query could be, did anyone in the panel talk about interest rates or did
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:32,880'); seek(332.0)">
              Jill express hope for a better economy?
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:35,980'); seek(335.0)">
              and the system, if you see, these are all generic queries and the system
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:38,830'); seek(338.0)">
              should be robust enough to handle and give you the segments, as needed.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:42,780'); seek(342.0)">
              To further enhance engagement, our system includes, dynamic annotations
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:47,000'); seek(347.0)">
              with, key points appearing during playback, follow up links so
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:51,230'); seek(351.0)">
              that the user can explore related content without searching manually.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:55,180'); seek(355.0)">
              integrated note taking, listeners can add timestamp notes for future
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:58,930'); seek(358.0)">
              references, and this whole thing transforms the passive learning
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:03,160'); seek(363.0)">
              into a very interactive experience.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:05,920'); seek(365.0)">
              So the system also tries to, automatically index based on various criteria, including
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:12,570'); seek(372.0)">
              speakers, topics, timestamps, so users can reduce structured segments efficiently.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:17,970'); seek(377.0)">
              For example, educators can use this for organizing their lecture recordings,
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:23,050'); seek(383.0)">
              picking, picking topics from various videos and making them easier for the
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:26,480'); seek(386.0)">
              students to find specific discussions.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:28,960'); seek(388.0)">
              User feedback is another crucial layer.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:31,150'); seek(391.0)">
              Our system integrates a rating system to evaluate, segment relevance.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:35,490'); seek(395.0)">
              As you might know, as you might wanna know how a certain segment
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:39,930'); seek(399.0)">
              in a video is received and not base your opinion on the entire video or
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:43,560'); seek(403.0)">
              the feedback for the entire video.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:45,390'); seek(405.0)">
              It happens all the time where people might like certain portions of the
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:48,690'); seek(408.0)">
              video, but not the entire video.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:50,675'); seek(410.0)">
              the users would be able to rate segments of the video on not just the entire video.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:55,145'); seek(415.0)">
              This helps you, make much more, data driven decisions or sentiment
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:00,360'); seek(420.0)">
              driven decisions, a common section and which is pretty standard.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:04,390'); seek(424.0)">
              And also an analytics dashboard for content creators to understand
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:07,990'); seek(427.0)">
              their audience preferences.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:09,720'); seek(429.0)">
              Now let's dive into the technical details of this, that powers the
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:13,350'); seek(433.0)">
              audio base or, navigation system.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:15,740'); seek(435.0)">
              this system essentially consists of, four layers, input layer, which converts
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:20,340'); seek(440.0)">
              a raw audio into structured text, with timestamp, processing layer, which
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:24,990'); seek(444.0)">
              uses the AI driven speaker diarization to identify speaker and speakers
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:30,300'); seek(450.0)">
              and topic segmentation to break.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:32,400'); seek(452.0)">
              Content into meaningful sections.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:34,990'); seek(454.0)">
              indexing layer, it stores the structured metadata for quick search and retrieval,
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:40,270'); seek(460.0)">
              interaction layer, which, or the feedback layer, which will enable
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:44,310'); seek(464.0)">
              search and playback functionality using, multimodal input such as text
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:48,490'); seek(468.0)">
              queries, voice commands, and contextual recommendations, as well as LLC users to.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:54,125'); seek(474.0)">
              provide, detailed feedback on, digging through various aspects
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:58,235'); seek(478.0)">
              of a video, which will help the content recommend, content creators.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:02,155'); seek(482.0)">
              alright, let's talk a little bit about the, the input layer.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:05,405'); seek(485.0)">
              here, the audio processing is the first step in our pipeline where we convert
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:09,695'); seek(489.0)">
              the raw audio into structured text using, a speech transcription model,
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:13,905'); seek(493.0)">
              open AI whisper, or, Google Gemini.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:16,965'); seek(496.0)">
              there are quite a few other ones.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:18,595'); seek(498.0)">
              Now, why is this important?
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:19,705'); seek(499.0)">
              audio files by themself are not very useful for search,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:22,675'); seek(502.0)">
              so they don't have structure.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:24,265'); seek(504.0)">
              So if we have timestamp for accurate playback, we would be able to build
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:28,765'); seek(508.0)">
              high quality UI where the users, based on these APIs, the users could actually
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:33,965'); seek(513.0)">
              go to a particular portion of a video, highlighting, pro providing high
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:38,045'); seek(518.0)">
              quality speech to text transcription.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:40,575'); seek(520.0)">
              will definitely help.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:42,365'); seek(522.0)">
              if you have the transcription accurately, accurately, laid out as
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:47,665'); seek(527.0)">
              well as the transcription playback is, is the right playback, it
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:52,055'); seek(532.0)">
              matches with your, with the input.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:53,625'); seek(533.0)">
              audio speed, whisper, tends to perform better.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:57,085'); seek(537.0)">
              At least that's the experience that I have.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:59,325'); seek(539.0)">
              it gives you the exact.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:01,230'); seek(541.0)">
              timestamps as well as the, as well as the exact time, playback speed so that
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:05,750'); seek(545.0)">
              if you're building experiences, you are accurately landing on the right
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:10,380'); seek(550.0)">
              point, when you search for a keyword.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:13,160'); seek(553.0)">
              so.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:14,440'); seek(554.0)">
              let's check out the code a little bit.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:15,880'); seek(555.0)">
              we send the audio file to whisper API and it returns a structured text.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:21,170'); seek(561.0)">
              the, this is just a pseudo code example.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:23,930'); seek(563.0)">
              The response include, word level timestamps, which means we can align,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:27,750'); seek(567.0)">
              spoken words to actual audio moments.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:30,180'); seek(570.0)">
              And the output also has things like, an entire transcript.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:33,560'); seek(573.0)">
              Plus metadata, like duration, detected language, word timing, and all of these
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:38,640'); seek(578.0)">
              would be used in the, in the next layers.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:40,950'); seek(580.0)">
              And why is this important?
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:42,360'); seek(582.0)">
              Because if a user searches for a phrase, we should be able to jump straight
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:46,800'); seek(586.0)">
              to the exact moment it was spoken.
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:48,870'); seek(588.0)">
              And, and these step is essential for the, for the next layers.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:53,320'); seek(593.0)">
              let's talk about Speaker Diarization, which is another step in the,
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:57,020'); seek(597.0)">
              processing layer and how we are making it better using the, NLPs and LLMs.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:03,400'); seek(603.0)">
              normally Speaker Diarization is done with, caustic, models that just
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:08,030'); seek(608.0)">
              try to figure out who's speaking based on voice characteristics.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:11,780'); seek(611.0)">
              But, sometimes people.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:14,130'); seek(614.0)">
              multiple people sound similar or the audio quality, isn't great all the time.
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:19,390'); seek(619.0)">
              So here's what we do instead, we start with the transcription.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:22,460'); seek(622.0)">
              we get the words, timestamps, and the entire, metadata that we just discussed.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:27,010'); seek(627.0)">
              We chunk the transcript into segments.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:29,650'); seek(629.0)">
              We assume that if there's, the system makes some, calculated
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:33,060'); seek(633.0)">
              assumptions, based on pauses.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:35,370'); seek(635.0)">
              instead of, relying on the voice characteristics, the system also,
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:39,580'); seek(639.0)">
              analyzes the, conversation history or, what's being spoken, based on
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:44,680'); seek(644.0)">
              the context and things like that.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:46,790'); seek(646.0)">
              and this will give you, a structured JSON that tells you who spoke when, an
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:50,610'); seek(650.0)">
              example of a query, in this layer would look something like, if you want to
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:55,210'); seek(655.0)">
              use that, bill, UI for these APIs who spoke in each segment of this podcast.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:00,610'); seek(660.0)">
              This could be a simple query and that should give you a list
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:03,400'); seek(663.0)">
              of, segments for each speaker.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:06,070'); seek(666.0)">
              And here's a simple pseudocode example on, how this thing works.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:09,770'); seek(669.0)">
              So we get the transcript, chunk it, based on, some calculated guesses.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:14,690'); seek(674.0)">
              and, by the LLMs and formatted, formatted, we call the LLMs with,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:19,180'); seek(679.0)">
              our structured prompt and it written speaker assignments, we pass that
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:23,920'); seek(683.0)">
              output into a JSON format that's easier to use and to build any experiences.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:29,195'); seek(689.0)">
              so this is great for podcast meetings, interviews, basically any
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:32,495'); seek(692.0)">
              conversation where traditional speaker diarization struggles and it's more
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:37,025'); seek(697.0)">
              accurate when it, because it actually understands, more than just the voice.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:41,095'); seek(701.0)">
              but the, the context and it does a lot of analysis on what's being
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:44,805'); seek(704.0)">
              spoken and what's being discussed.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:47,015'); seek(707.0)">
              topic segmentation uses, NLP and LLMs to divide and classify the topics.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:53,465'); seek(713.0)">
              segment them, segment transcripts using, timestamps and detect,
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:58,115'); seek(718.0)">
              topic shifts in conversations.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:00,155'); seek(720.0)">
              So it can also categorize segments into themes, and use LLMs to assign
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:05,185'); seek(725.0)">
              topic labels for audio systems and developers can build, these,
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:09,495'); seek(729.0)">
              multifaceted UIs using these APIs.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:12,185'); seek(732.0)">
              an example query, of this layer.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:14,495'); seek(734.0)">
              how this would be useful is if you wanna find all sections
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:18,425'); seek(738.0)">
              using AI ethics, in this podcast.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:21,435'); seek(741.0)">
              find all sections, during discussing AI ethics in this podcast.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:25,605'); seek(745.0)">
              And that should be able to get you a list of items, of all the portions or
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:29,915'); seek(749.0)">
              sections that talk about this topic.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:32,455'); seek(752.0)">
              And this is, once the, once you have these APIs and the timestamps, the, the
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:37,615'); seek(757.0)">
              next steps are usually faster because you're not analyzing the entire video.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:41,485'); seek(761.0)">
              You're just, referring through your metadata.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:43,315'); seek(763.0)">
              And you are, you're playing back based on, a certain timestamp,
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:47,085'); seek(767.0)">
              based on the criteria that is given.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:48,855'); seek(768.0)">
              Either, either it's a speaker that you wanna land, it based, a speaker.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:54,055'); seek(774.0)">
              speaking, a particular topic that you wanna land on or a topic itself that's
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:57,795'); seek(777.0)">
              segmented that you want to land on.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:59,255'); seek(779.0)">
              so it becomes much faster because you're just dealing with the metadata and not
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:02,875'); seek(782.0)">
              analyzing the video again and again.
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:04,985'); seek(784.0)">
              let's discuss how we handle topic segmentation, using the transcript
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:08,525'); seek(788.0)">
              from the, from the input layer.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:11,020'); seek(791.0)">
              in a long form audio topics shift.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:13,180'); seek(793.0)">
              frequently users want to jump directly to relevant sections
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:17,170'); seek(797.0)">
              without scrapping to recordings.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:19,030'); seek(799.0)">
              So our solution automates topic detection and labeling for seamless navigation.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:24,130'); seek(804.0)">
              So we chunk the transcript, use the, output that we received from the
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:27,690'); seek(807.0)">
              previous layer with word timestamp, group the words together into, on
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:32,470'); seek(812.0)">
              regular intervals for adequate context.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:35,305'); seek(815.0)">
              compute, text, similar, text similarity.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:38,075'); seek(818.0)">
              Convert the segment.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:38,915'); seek(818.0)">
              text into TFID effect, calculate similarity between adjucent
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:44,015'); seek(824.0)">
              segments to assess the relevance.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:46,275'); seek(826.0)">
              detect the topic shifts, assign topics using, LLMs, send the segmented text
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:13:51,215'); seek(831.0)">
              to GPT-4 or, or relevant, models for descriptive topic labeling and structured
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:13:57,535'); seek(837.0)">
              the output for search and playback.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:13:59,795'); seek(839.0)">
              and.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:00,330'); seek(840.0)">
              users should be able to quickly search and jump to any topic that they like.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:04,370'); seek(844.0)">
              Indexing layer.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:05,210'); seek(845.0)">
              Once we have the structured data from processing layer, which includes,
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:08,890'); seek(848.0)">
              sp label, text, and topic segmented content, we need a fast and scalable
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:13,480'); seek(853.0)">
              way to search and retrieve it.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:15,100'); seek(855.0)">
              And this is often now done on metadata, so it should be faster.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:18,100'); seek(858.0)">
              So how does the indexing layer work?
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:19,660'); seek(859.0)">
              It stores the segments efficiently.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:21,820'); seek(861.0)">
              Each segment is stored in a database with a topic.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:24,135'); seek(864.0)">
              or speaker or start end and, start date, start time and end time.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:28,440'); seek(868.0)">
              And this allows us to map conversation to structured metadata for easier lookup.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:33,240'); seek(873.0)">
              And the next step would be creating faster, indexes where we index the
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:38,430'); seek(878.0)">
              data by topic, speaker, and timestamps.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:14:41,725'); seek(881.0)">
              And this enables quick, full text searches so users can jump to any
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:14:46,125'); seek(886.0)">
              sections instantly and retrieving segments versus, multiple, filters.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:14:51,305'); seek(891.0)">
              retrieving segments, versus multiple filters.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:14:53,425'); seek(893.0)">
              users can actually search by different things like topics,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:14:56,725'); seek(896.0)">
              speaker, timestamp, et cetera.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:14:58,585'); seek(898.0)">
              And this is optimized for speed and scalability and exposing APIs, and it
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:02,625'); seek(902.0)">
              exposes APIs for, for the clients to make, build those experiences, with
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:07,805'); seek(907.0)">
              search, based on different criteria.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:09,735'); seek(909.0)">
              And why this is powerful.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:11,085'); seek(911.0)">
              This is powerful because users can find exactly what they need without
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:14,835'); seek(914.0)">
              scrubbing through long videos, and they have different criteria to search from.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:18,605'); seek(918.0)">
              And, just a high level depiction of how, different layers of this, indexing layer.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:23,275'); seek(923.0)">
              So the input of this layer would be the data reiterate from the processing layer.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:27,020'); seek(927.0)">
              Things like topic, speaker, certain end times, et cetera.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:30,300'); seek(930.0)">
              the output of this layer is expected to be an index storage and for enabling
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:34,290'); seek(934.0)">
              faster or, faster search or indexing.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:15:36,730'); seek(936.0)">
              First step would be to save the data, in, and then, index the data by key attributes
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:15:42,270'); seek(942.0)">
              such as topic, speaker, and timestamps.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:15:44,980'); seek(944.0)">
              enable full tech search, capabilities to handle keyword
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:15:48,240'); seek(948.0)">
              queries effectively and support.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:15:50,660'); seek(950.0)">
              Time-based, queries, so that you can jump to a particular, time in the video.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:15:55,970'); seek(955.0)">
              for optimizing performance.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:15:57,410'); seek(957.0)">
              we use the caching strategies to, accelerate, frequent queries or
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:01,855'); seek(961.0)">
              implement ation to manage large sets of DA data efficiently.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:06,075'); seek(966.0)">
              Or, if you want to go advance, you can build a rag with the, data
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:10,285'); seek(970.0)">
              to store and retrieve information from a Vector database for
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:13,495'); seek(973.0)">
              accurate and relevant results.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:15,355'); seek(975.0)">
              And finally, in this layer, it provides API endpoints for external
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:19,425'); seek(979.0)">
              facing, fetching externally, fetching the, index, segments.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:23,755'); seek(983.0)">
              And it enables seamless content navigation.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:27,165'); seek(987.0)">
              And let's go over the final layer, which is the integration,
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:16:29,595'); seek(989.0)">
              interaction and the feedback layer.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:16:31,695'); seek(991.0)">
              So this layer, let's say this layer is very important because if you have,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:16:35,925'); seek(995.0)">
              let's say, a user, you know that, that is listening to an hour long podcast,
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:16:40,165'); seek(1000.0)">
              but they would, they have some questions that they want to answer, they could
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:16:43,695'); seek(1003.0)">
              simply ask a question that says, what did John say about, AI ethics?
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:16:48,435'); seek(1008.0)">
              So the multi-model interaction for seamless search will, would
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:16:51,865'); seek(1011.0)">
              essentially, query, based on how you query, any, any text space system.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:16:57,235'); seek(1017.0)">
              And it provides a real time feedback to improve accuracy as well, because,
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:02,025'); seek(1022.0)">
              you wanna learn as the, as more users are adopting the system or
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:06,185'); seek(1026.0)">
              adopting, or watching the videos.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:08,260'); seek(1028.0)">
              AI powered personalization and recommendations.
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:10,480'); seek(1030.0)">
              So over the time the system learns, user preferences as well.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:14,470'); seek(1034.0)">
              and you could make, data driven, decisions based on it.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:18,470'); seek(1038.0)">
              And here's a high level exam, high level depiction of how this
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:22,010'); seek(1042.0)">
              feedback layer would look like.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:23,790'); seek(1043.0)">
              it takes the user queries, playback interaction, run ratings
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:17:26,790'); seek(1046.0)">
              as input and generates enhanced recommendations using the queries
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:17:30,360'); seek(1050.0)">
              and indexing from the index layer.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:17:33,240'); seek(1053.0)">
              So it also ensures, improved accuracy and facilitates, learning based on
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:17:37,370'); seek(1057.0)">
              the feedback as a user interacts or searches feedback is collected
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:17:41,120'); seek(1061.0)">
              real time, which will be used to adjust AI models and generate.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:17:45,640'); seek(1065.0)">
              Personalized recommendations and improved accuracy and precision
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:17:48,550'); seek(1068.0)">
              over the period of time.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:17:49,810'); seek(1069.0)">
              The system can leverage these APIs to build features to expose, search
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:17:53,530'); seek(1073.0)">
              and personalized playback, APIs providing, interactive user experience.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:17:58,250'); seek(1078.0)">
              So to summarize our proposed system, it offers several key benefits.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:02,380'); seek(1082.0)">
              It, it transforms the passive listening to an interactive and structured experience
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:06,590'); seek(1086.0)">
              where listeners can effectively find and engage with, with the audio content.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:10,900'); seek(1090.0)">
              it, it is efficient, in terms of topic and speaker classification.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:15,480'); seek(1095.0)">
              It gives you a real time search and learning mechanism, and
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:18,180'); seek(1098.0)">
              also a feedback system that is continuously learning and helps you
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:21,990'); seek(1101.0)">
              with the advanced personalization.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:18:23,940'); seek(1103.0)">
              And this framework is scalable because a system is designed to accommodate
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:18:27,540'); seek(1107.0)">
              various audio formats, such as podcasts and webinars, making it versatile and
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:18:31,260'); seek(1111.0)">
              applicable across different use cases.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:18:33,585'); seek(1113.0)">
              Improved accessibility is often, underlooked, but the system provides
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:18:36,965'); seek(1116.0)">
              features such as voice queries and easy navigation aids, supporting
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:18:40,445'); seek(1120.0)">
              diverse population, user needs, and ensuring that all the listeners have
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:18:45,095'); seek(1125.0)">
              the access to the audio contact.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:18:47,215'); seek(1127.0)">
              So con in con, in conclusion, there's this research from Edison
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:18:51,805'); seek(1131.0)">
              that says more than 45% of the audio driven platforms, are on demand.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:18:57,705'); seek(1137.0)">
              and these are, 45% are on demand platforms, which, consumers listen
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:02,555'); seek(1142.0)">
              to, including podcasts, meetings, education, and enterprise applications.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:06,865'); seek(1146.0)">
              These.
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:07,395'); seek(1147.0)">
              You know these things.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:08,145'); seek(1148.0)">
              They present an opportunity for AI powered, navigation systems by
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:12,815'); seek(1152.0)">
              transforming the unstructured speech into searchable interactive content.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:17,105'); seek(1157.0)">
              This approach enhances user engagement, improves accessibility, and drives
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:19:21,455'); seek(1161.0)">
              intelligent content discovery at scale.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:19:23,845'); seek(1163.0)">
              So that's all from me.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:19:25,185'); seek(1165.0)">
              thank you for joining.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Waseem%20Syed%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Waseem%20Syed%20-%20Conf42%20Large%20Language%20Models%20%28LLMs%29%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #CCB87B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/llms2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #CCB87B;">
                <i class="fe fe-grid me-2"></i>
                See all 40 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Waseem%20Syed_llm.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Waseem Syed
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Staff Software Engineer 
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/waseemasyed/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Waseem Syed's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Waseem Syed"
                  data-url="https://www.conf42.com/llms2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/llms2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4 justify-content-center">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Access to all content</b>
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Large Language Models"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe for FREE<i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2026
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2026">
                  DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2026">
                  Machine Learning 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2026">
                  Site Reliability Engineering (SRE) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2026">
                  Cloud Native 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2026">
                  Golang 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/dbd2026">
                  Database DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2026">
                  Large Language Models (LLMs) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2026">
                  Observability 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/agents2026">
                  AI Agents 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2026">
                  DevSecOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2026">
                  Prompt Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2026">
                  Platform Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2026">
                  MLOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2026">
                  Chaos Engineering 2026
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>