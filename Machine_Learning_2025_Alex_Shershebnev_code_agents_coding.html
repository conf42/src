<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: AI Coding Agents and how to code them</title>
    <meta name="description" content="Help us build a dystopian, machine-ated future!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Alex%20Shershebnev_ml.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="AI Coding Agents and how to code them | Conf42"/>
    <meta property="og:description" content="AI Agents are the next big thing everyone is talking about. They are expected to revolutionize various industries by automating routine tasks, mission critical business workflows, enhancing productivity, and enabling humans to focus on creative and strategic work"/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2025_Alex_Shershebnev_code_agents_coding"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/QUANTUM2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Quantum Computing 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-06-19
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/quantum2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2025 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2025-05-08">May 08 2025</time>
              
              - premiere 5PM GMT
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Help us build a dystopian, machine-ated future!
 -->
              <script>
                const event_date = new Date("2025-05-08T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-05-08T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "Pste7lY3oCI"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrDbH1VBaoA60lLAAVqmiLPe" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello everyone.", "timestamp": "00:00:00,750", "timestamp_s": 0.0}, {"text": "My name is Alex.", "timestamp": "00:00:01,599", "timestamp_s": 1.0}, {"text": "I\u0027m head of Ops and DevOps at Z Coder.", "timestamp": "00:00:02,559", "timestamp_s": 2.0}, {"text": "I also double l de and in general, what I like to call they have asked me anything.", "timestamp": "00:00:05,230", "timestamp_s": 5.0}, {"text": "It\u0027s a startup, so you have to wear many hats.", "timestamp": "00:00:10,200", "timestamp_s": 10.0}, {"text": "Today I will be talking with you about AI coding agents how you can code", "timestamp": "00:00:12,910", "timestamp_s": 12.0}, {"text": "them, how you can use them, how you can leverage them to make your everyday", "timestamp": "00:00:16,990", "timestamp_s": 16.0}, {"text": "life easier and be more productive Now.", "timestamp": "00:00:22,180", "timestamp_s": 22.0}, {"text": "Recently you might have come across headlines like this where", "timestamp": "00:00:26,695", "timestamp_s": 26.0}, {"text": "in this case, mark Zuckerberg said, mentioned in his interview that", "timestamp": "00:00:31,315", "timestamp_s": 31.0}, {"text": "AI will soon replace developers.", "timestamp": "00:00:35,335", "timestamp_s": 35.0}, {"text": "And in this particular case, he even went as far as saying that mid-level", "timestamp": "00:00:37,195", "timestamp_s": 37.0}, {"text": "engineers will be replaced pretty soon.", "timestamp": "00:00:42,215", "timestamp_s": 42.0}, {"text": "Now there are two main sort of sources.", "timestamp": "00:00:45,085", "timestamp_s": 45.0}, {"text": "For those headlines.", "timestamp": "00:00:49,045", "timestamp_s": 49.0}, {"text": "First of all, of course, new models.", "timestamp": "00:00:50,055", "timestamp_s": 50.0}, {"text": "New AI or LLM models are coming up being released.", "timestamp": "00:00:52,095", "timestamp_s": 52.0}, {"text": "For example here the recent release from Google of Gemini 2.5 Pro,", "timestamp": "00:00:56,665", "timestamp_s": 56.0}, {"text": "and they of course show that new they are new model beats all the", "timestamp": "00:01:01,235", "timestamp_s": 61.0}, {"text": "previous models on the benchmarks which is always the case, right?", "timestamp": "00:01:05,485", "timestamp_s": 65.0}, {"text": "Now for us for coordin agents in particular, we are mostly interested", "timestamp": "00:01:09,575", "timestamp_s": 69.0}, {"text": "in the three code related benchmarks, which I highlighted here in red.", "timestamp": "00:01:13,335", "timestamp_s": 73.0}, {"text": "Now the problem with benchmarks is while it is good to see that models", "timestamp": "00:01:18,185", "timestamp_s": 78.0}, {"text": "are becoming better on them it\u0027s a good way to compare models with each other.", "timestamp": "00:01:22,595", "timestamp_s": 82.0}, {"text": "It\u0027s all those benchmarks are not always.", "timestamp": "00:01:27,535", "timestamp_s": 87.0}, {"text": "Transferable one-to-one to the real world.", "timestamp": "00:01:31,280", "timestamp_s": 91.0}, {"text": "What I mean by that is for example, if we look at either gl the main idea behind", "timestamp": "00:01:34,160", "timestamp_s": 94.0}, {"text": "this data set is that the LLM or AI is presented with a list of tasks and it", "timestamp": "00:01:38,910", "timestamp_s": 98.0}, {"text": "essentially needs to create a function.", "timestamp": "00:01:44,760", "timestamp_s": 104.0}, {"text": "It create needs to create a class or method that would fulfill that task.", "timestamp": "00:01:46,320", "timestamp_s": 106.0}, {"text": "So essentially it\u0027s one or single file modification.", "timestamp": "00:01:50,910", "timestamp_s": 110.0}, {"text": "However reality of software development is not that simple, right?", "timestamp": "00:01:54,635", "timestamp_s": 114.0}, {"text": "So usually you need to modify at least multiple files inside the", "timestamp": "00:01:59,205", "timestamp_s": 119.0}, {"text": "repository, or sometimes you might even need to modify files across", "timestamp": "00:02:03,015", "timestamp_s": 123.0}, {"text": "multiple repositories at the same time.", "timestamp": "00:02:07,695", "timestamp_s": 127.0}, {"text": "So basically, even though there are improvements in the quality of AI of LLM.", "timestamp": "00:02:10,335", "timestamp_s": 130.0}, {"text": "They\u0027re not always transferable one-to-one on in the real life world.", "timestamp": "00:02:15,885", "timestamp_s": 135.0}, {"text": "So you might not see as big of an improvement as you", "timestamp": "00:02:20,525", "timestamp_s": 140.0}, {"text": "would see on the benchmarks.", "timestamp": "00:02:23,935", "timestamp_s": 143.0}, {"text": "So that\u0027s one source of those headlines.", "timestamp": "00:02:25,895", "timestamp_s": 145.0}, {"text": "And the second one is AI agents, which is the main topic", "timestamp": "00:02:27,975", "timestamp_s": 147.0}, {"text": "of the day of today\u0027s stock.", "timestamp": "00:02:31,305", "timestamp_s": 151.0}, {"text": "So basically, we\u0027ll, we will first cover what is AI agent.", "timestamp": "00:02:34,200", "timestamp_s": 154.0}, {"text": "Then we\u0027ll go through a live coding session where we\u0027ll see", "timestamp": "00:02:37,880", "timestamp_s": 157.0}, {"text": "how we can, how you can create the coding agent on your own right.", "timestamp": "00:02:42,230", "timestamp_s": 162.0}, {"text": "And you will see how they can also interact with each other", "timestamp": "00:02:46,519", "timestamp_s": 166.0}, {"text": "for multi agent collaboration.", "timestamp": "00:02:49,619", "timestamp_s": 169.0}, {"text": "And then briefly talk about what is next for the developers, what all those.", "timestamp": "00:02:51,429", "timestamp_s": 171.0}, {"text": "New improvements, what all those new changes mean for the", "timestamp": "00:02:57,100", "timestamp_s": 177.0}, {"text": "future of software development.", "timestamp": "00:02:59,970", "timestamp_s": 179.0}, {"text": "So yeah, basically by the end of the talk, we will potentially build an ai, which", "timestamp": "00:03:03,239", "timestamp_s": 183.0}, {"text": "might probably replace you or maybe not.", "timestamp": "00:03:08,640", "timestamp_s": 188.0}, {"text": "We\u0027ll see.", "timestamp": "00:03:10,739", "timestamp_s": 190.0}, {"text": "So first things first let\u0027s define what is AI agent.", "timestamp": "00:03:12,354", "timestamp_s": 192.0}, {"text": "Now, AI agent can be defined as a software that performs tasks on behalf of a user.", "timestamp": "00:03:16,604", "timestamp_s": 196.0}, {"text": "And you might say here that any software performs tasks", "timestamp": "00:03:22,454", "timestamp_s": 202.0}, {"text": "on behalf of the user, right?", "timestamp": "00:03:26,004", "timestamp_s": 206.0}, {"text": "Especially if we\u0027re talking about current generation of coding systems.", "timestamp": "00:03:27,684", "timestamp_s": 207.0}, {"text": "And they essentially perform tasks of code generation on your behalf.", "timestamp": "00:03:31,284", "timestamp_s": 211.0}, {"text": "They perform tasks of documentation generation on your behalf.", "timestamp": "00:03:35,304", "timestamp_s": 215.0}, {"text": "And, you can just essentially tap, tap tab get a thousand slice of code in a", "timestamp": "00:03:38,309", "timestamp_s": 218.0}, {"text": "couple minutes, and then spend some time on the bag in that the bag in that code.", "timestamp": "00:03:42,739", "timestamp_s": 222.0}, {"text": "Now the main difference between AI agents and classic software is that AI", "timestamp": "00:03:48,549", "timestamp_s": 228.0}, {"text": "agents follow multiple design patterns which you can see here on the side.", "timestamp": "00:03:53,929", "timestamp_s": 233.0}, {"text": "So first of all they have what\u0027s called tool use.", "timestamp": "00:03:57,729", "timestamp_s": 237.0}, {"text": "So they can basically, can have access to the tools, to the", "timestamp": "00:04:00,609", "timestamp_s": 240.0}, {"text": "list of tools at a disposal.", "timestamp": "00:04:04,869", "timestamp_s": 244.0}, {"text": "And those tools could be pretty much anything.", "timestamp": "00:04:06,369", "timestamp_s": 246.0}, {"text": "It could be doing the web search, it could be accessing some local file system.", "timestamp": "00:04:09,339", "timestamp_s": 249.0}, {"text": "It could be accessing restful APIs and so on.", "timestamp": "00:04:13,889", "timestamp_s": 253.0}, {"text": "So basically any tool LLM can use to gather information to", "timestamp": "00:04:17,379", "timestamp_s": 257.0}, {"text": "perform actions and so on.", "timestamp": "00:04:21,809", "timestamp_s": 261.0}, {"text": "It can use it.", "timestamp": "00:04:23,069", "timestamp_s": 263.0}, {"text": "Then of course, AI agents can also do some planning.", "timestamp": "00:04:24,494", "timestamp_s": 264.0}, {"text": "So they don\u0027t just blindly perform the task, perform code generation.", "timestamp": "00:04:27,734", "timestamp_s": 267.0}, {"text": "They can first come up with a plan on how to tackle these specific task at hand.", "timestamp": "00:04:31,804", "timestamp_s": 271.0}, {"text": "And they then will follow that plan.", "timestamp": "00:04:37,515", "timestamp_s": 277.0}, {"text": "They can also reflect on their own work, on their own planning step", "timestamp": "00:04:41,085", "timestamp_s": 281.0}, {"text": "on their, output or they can also reflect on work of other agents.", "timestamp": "00:04:45,284", "timestamp_s": 285.0}, {"text": "And this is where we come to this fourth design pattern, which", "timestamp": "00:04:51,474", "timestamp_s": 291.0}, {"text": "is multi-agent collaboration.", "timestamp": "00:04:54,394", "timestamp_s": 294.0}, {"text": "So basically you can have multiple agents working together towards the same goal.", "timestamp": "00:04:56,494", "timestamp_s": 296.0}, {"text": "And those could be either working together as in colleagues where they", "timestamp": "00:05:00,644", "timestamp_s": 300.0}, {"text": "for example, one agent, performs half of the task, and then the other agent", "timestamp": "00:05:05,794", "timestamp_s": 305.0}, {"text": "performs the second half of the task.", "timestamp": "00:05:09,604", "timestamp_s": 309.0}, {"text": "Or they can also critique each other.", "timestamp": "00:05:11,464", "timestamp_s": 311.0}, {"text": "So for example, you could have one agent, which critiques the work of the", "timestamp": "00:05:13,204", "timestamp_s": 313.0}, {"text": "second agent, and then the second agent iterates on this critique and so on.", "timestamp": "00:05:17,404", "timestamp_s": 317.0}, {"text": "But basically yeah, those patterns are what differentiates AI agents from the", "timestamp": "00:05:23,069", "timestamp_s": 323.0}, {"text": "typical or from the classical software.", "timestamp": "00:05:28,179", "timestamp_s": 328.0}, {"text": "And you can think about AI agents like a, I guess a Roomba vacuum cleaner.", "timestamp": "00:05:30,549", "timestamp_s": 330.0}, {"text": "The software itself on the vacuum cleaner is an AI agent, however, to perform.", "timestamp": "00:05:35,150", "timestamp_s": 335.0}, {"text": "To perform the task of clean the house, right?", "timestamp": "00:05:40,440", "timestamp_s": 340.0}, {"text": "It needs also multi some things on top of that.", "timestamp": "00:05:43,260", "timestamp_s": 343.0}, {"text": "So just software is not enough.", "timestamp": "00:05:46,710", "timestamp_s": 346.0}, {"text": "The vacuum cleaners, they also have tools, so that could be brushes that", "timestamp": "00:05:48,280", "timestamp_s": 348.0}, {"text": "could be wheels to move around and so on.", "timestamp": "00:05:52,440", "timestamp_s": 352.0}, {"text": "They can also do playing and for some reason charge GPT thinks that", "timestamp": "00:05:55,080", "timestamp_s": 355.0}, {"text": "robot vacuum cleaners are moving this weirdly shaped pattern.", "timestamp": "00:05:59,130", "timestamp_s": 359.0}, {"text": "But it is AI being a AI, there is no steel yet multi agent collaboration unless", "timestamp": "00:06:04,030", "timestamp_s": 364.0}, {"text": "you count these for the vacuum cleaners.", "timestamp": "00:06:09,989", "timestamp_s": 369.0}, {"text": "But maybe in the future they will be able to also talk with each other.", "timestamp": "00:06:12,759", "timestamp_s": 372.0}, {"text": "They will be able to talk with the other home appliances and so on.", "timestamp": "00:06:16,059", "timestamp_s": 376.0}, {"text": "Yeah, basically now.", "timestamp": "00:06:20,019", "timestamp_s": 380.0}, {"text": "Why is this important?", "timestamp": "00:06:23,364", "timestamp_s": 383.0}, {"text": "To answer that question, let\u0027s first talk about what we as developers spend", "timestamp": "00:06:24,784", "timestamp_s": 384.0}, {"text": "our time on during the work hours.", "timestamp": "00:06:31,384", "timestamp_s": 391.0}, {"text": "And I will give you a few seconds to think about this.", "timestamp": "00:06:34,114", "timestamp_s": 394.0}, {"text": "Spoiler alert, it\u0027s not drinking coffee in reality, and this study was", "timestamp": "00:06:36,504", "timestamp_s": 396.0}, {"text": "done actually 10 years ago, however, I don\u0027t think much has changed.", "timestamp": "00:06:42,784", "timestamp_s": 402.0}, {"text": "Since then now in reality 70% of the time developers spend on understanding", "timestamp": "00:06:47,329", "timestamp_s": 407.0}, {"text": "that could be understanding the code base, understanding", "timestamp": "00:06:53,069", "timestamp_s": 413.0}, {"text": "the requirements understanding.", "timestamp": "00:06:55,589", "timestamp_s": 415.0}, {"text": "Tasks and so on.", "timestamp": "00:06:57,629", "timestamp_s": 417.0}, {"text": "So basically most of the time developers are not spending on writing the code.", "timestamp": "00:06:58,919", "timestamp_s": 418.0}, {"text": "They are spending on understanding.", "timestamp": "00:07:03,159", "timestamp_s": 423.0}, {"text": "Now if we juxtapose this with the adjunct design patterns, which we", "timestamp": "00:07:06,049", "timestamp_s": 426.0}, {"text": "just discussed, we will see that, for example, for the tool use.", "timestamp": "00:07:09,679", "timestamp_s": 429.0}, {"text": "We of course, have editing.", "timestamp": "00:07:13,199", "timestamp_s": 433.0}, {"text": "We need to use tools to edit the code.", "timestamp": "00:07:14,739", "timestamp_s": 434.0}, {"text": "We need to use tools when we are outside of ID and on Googling something and so on.", "timestamp": "00:07:16,749", "timestamp_s": 436.0}, {"text": "And of course for UI interactions, we also need to use tools.", "timestamp": "00:07:22,079", "timestamp_s": 442.0}, {"text": "Then of course for planning we need to understand the task at hand.", "timestamp": "00:07:25,979", "timestamp_s": 445.0}, {"text": "We need to understand the requirements.", "timestamp": "00:07:30,299", "timestamp_s": 450.0}, {"text": "Because otherwise it\u0027s hard to do planning of the work, right?", "timestamp": "00:07:31,699", "timestamp_s": 451.0}, {"text": "There is also reflection.", "timestamp": "00:07:35,955", "timestamp_s": 455.0}, {"text": "Of course, we can, we don\u0027t just blindly.", "timestamp": "00:07:36,885", "timestamp_s": 456.0}, {"text": "Follow the requirements.", "timestamp": "00:07:42,175", "timestamp_s": 462.0}, {"text": "Don\u0027t just blindly follow the task.", "timestamp": "00:07:43,200", "timestamp_s": 463.0}, {"text": "I hope we also can think about different ways, solve the task.", "timestamp": "00:07:45,250", "timestamp_s": 465.0}, {"text": "We can think about different ways to tackle the problem.", "timestamp": "00:07:51,240", "timestamp_s": 471.0}, {"text": "And so on.", "timestamp": "00:07:55,060", "timestamp_s": 475.0}, {"text": "And of course we don\u0027t usually work in a vacuum.", "timestamp": "00:07:55,630", "timestamp_s": 475.0}, {"text": "We have colleagues with whom we can work together, we can collaborate.", "timestamp": "00:07:59,050", "timestamp_s": 479.0}, {"text": "And this is where basically multi collaboration comes in.", "timestamp": "00:08:03,190", "timestamp_s": 483.0}, {"text": "And of course, for that follow that you\u0027ll need to have a good understanding.", "timestamp": "00:08:06,670", "timestamp_s": 486.0}, {"text": "You probably also need to navigate the code base.", "timestamp": "00:08:11,840", "timestamp_s": 491.0}, {"text": "You need to spend something outside of ID in Slack or whatever.", "timestamp": "00:08:14,310", "timestamp_s": 494.0}, {"text": "But basically all of the design print principles can be directly juxtaposed", "timestamp": "00:08:17,775", "timestamp_s": 497.0}, {"text": "with what developers do in their free, or, sorry, not free, but of course", "timestamp": "00:08:22,535", "timestamp_s": 502.0}, {"text": "what they do in their work time.", "timestamp": "00:08:27,145", "timestamp_s": 507.0}, {"text": "Now, with that let me switch the sides and let\u0027s finally do some coding.", "timestamp": "00:08:31,055", "timestamp_s": 511.0}, {"text": "All of the code, which I will be showing today, is available", "timestamp": "00:08:37,195", "timestamp_s": 517.0}, {"text": "on this, repository over here.", "timestamp": "00:08:40,315", "timestamp_s": 520.0}, {"text": "I done Q code or the link below.", "timestamp": "00:08:42,165", "timestamp_s": 522.0}, {"text": "And the way I structure the coding session is I will go through several stages and", "timestamp": "00:08:45,555", "timestamp_s": 525.0}, {"text": "hopefully not those stages but basically I will go through several stages.", "timestamp": "00:08:50,835", "timestamp_s": 530.0}, {"text": "We\u0027ll start with a simple baseline where we won\u0027t have", "timestamp": "00:08:55,105", "timestamp_s": 535.0}, {"text": "any agenda egen patterns at all.", "timestamp": "00:08:58,720", "timestamp_s": 538.0}, {"text": "And then we will slowly build on top of, on top of the previous stages to come to", "timestamp": "00:09:02,225", "timestamp_s": 542.0}, {"text": "the final step of multi-agent multi-agent system, which will work together to,", "timestamp": "00:09:07,425", "timestamp_s": 547.0}, {"text": "to fulfill the task on our behalf.", "timestamp": "00:09:12,580", "timestamp_s": 552.0}, {"text": "So let me switch here to the to the Jupiter notebook I have here.", "timestamp": "00:09:15,670", "timestamp_s": 555.0}, {"text": "Let\u0027s see.", "timestamp": "00:09:23,215", "timestamp_s": 563.0}, {"text": "Alright,", "timestamp": "00:09:26,680", "timestamp_s": 566.0}, {"text": "so let\u0027s start with our baseline, right?", "timestamp": "00:09:29,920", "timestamp_s": 569.0}, {"text": "And if you used AI in any capacity, if you used any LLM, like open AI or", "timestamp": "00:09:32,440", "timestamp_s": 572.0}, {"text": "cloudy you probably have experienced something similar to what we will", "timestamp": "00:09:37,660", "timestamp_s": 577.0}, {"text": "see right now in the baseline.", "timestamp": "00:09:42,230", "timestamp_s": 582.0}, {"text": "But basically, and again, if you are not familiar with Python it\u0027s not a problem.", "timestamp": "00:09:44,000", "timestamp_s": 584.0}, {"text": "All of the code is pretty simple.", "timestamp": "00:09:49,560", "timestamp_s": 589.0}, {"text": "Pretty simple to it.", "timestamp": "00:09:52,080", "timestamp_s": 592.0}, {"text": "And, pretty sim pretty easy to understand.", "timestamp": "00:09:52,860", "timestamp_s": 592.0}, {"text": "Now, over here on this baseline basically what I do is I will be using the most", "timestamp": "00:09:56,030", "timestamp_s": 596.0}, {"text": "recent model from Open ai, namely GT 4.1.", "timestamp": "00:10:01,130", "timestamp_s": 601.0}, {"text": "And basically over here, I\u0027m just defining the code to query the model so", "timestamp": "00:10:05,210", "timestamp_s": 605.0}, {"text": "that this function will send the input from us, from user to the LLM and we", "timestamp": "00:10:09,530", "timestamp_s": 609.0}, {"text": "will get the response from GPT-4 0.1.", "timestamp": "00:10:15,350", "timestamp_s": 615.0}, {"text": "Now, the problem with the L LMS is that they are leaving the,", "timestamp": "00:10:19,330", "timestamp_s": 619.0}, {"text": "somewhere in the cloud and they don\u0027t have access to real life world.", "timestamp": "00:10:24,135", "timestamp_s": 624.0}, {"text": "What I mean by that is for example, they can\u0027t give us the response time for", "timestamp": "00:10:28,015", "timestamp_s": 628.0}, {"text": "Google or for any website for that matter.", "timestamp": "00:10:31,635", "timestamp_s": 631.0}, {"text": "So it does try to be helpful, and I think it probably will, yeah.", "timestamp": "00:10:34,570", "timestamp_s": 634.0}, {"text": "Does give us some command to run to GI to get the answer, unfortunately on its own.", "timestamp": "00:10:40,090", "timestamp_s": 640.0}, {"text": "The LLM in this case, GPT-4 0.1, isn\u0027t able to help.", "timestamp": "00:10:45,930", "timestamp_s": 645.0}, {"text": "The same goes with the access to local local machine.", "timestamp": "00:10:49,980", "timestamp_s": 649.0}, {"text": "This case in that it doesn\u0027t have access to my local computer.", "timestamp": "00:10:53,960", "timestamp_s": 653.0}, {"text": "Again, it does try to help me with providing some batch", "timestamp": "00:10:57,890", "timestamp_s": 657.0}, {"text": "commands to, to list the packages.", "timestamp": "00:11:01,380", "timestamp_s": 661.0}, {"text": "Unfortunately even for those simple tasks, it can\u0027t really help me.", "timestamp": "00:11:04,630", "timestamp_s": 664.0}, {"text": "And, we are especially, we are going to some more sophisticated tasks that", "timestamp": "00:11:09,180", "timestamp_s": 669.0}, {"text": "require, access to local to local machine.", "timestamp": "00:11:14,510", "timestamp_s": 674.0}, {"text": "For example, Iranian dock image.", "timestamp": "00:11:17,300", "timestamp_s": 677.0}, {"text": "The LLM would fail here and wouldn\u0027t be very helpful.", "timestamp": "00:11:19,030", "timestamp_s": 679.0}, {"text": "And the same goes within new and updated knowledge.", "timestamp": "00:11:22,540", "timestamp_s": 682.0}, {"text": "Now, in this case the GPT-4 0.1 has a more UpToDate knowledge.", "timestamp": "00:11:26,000", "timestamp_s": 686.0}, {"text": "If you try the same query with the older model, like T four O, for example,", "timestamp": "00:11:31,110", "timestamp_s": 691.0}, {"text": "it wouldn\u0027t know anything at all about Python three 14 in this case.", "timestamp": "00:11:36,210", "timestamp_s": 696.0}, {"text": "Because the knowledge cut off for the model was, I think in June, 2024.", "timestamp": "00:11:40,780", "timestamp_s": 700.0}, {"text": "It does have some knowledge about Python three 14.", "timestamp": "00:11:45,660", "timestamp_s": 705.0}, {"text": "And it does provide some links for us as well.", "timestamp": "00:11:48,310", "timestamp_s": 708.0}, {"text": "However still the knowledge is not up to date, right?", "timestamp": "00:11:51,550", "timestamp_s": 711.0}, {"text": "It is 2025, my 2025 right now.", "timestamp": "00:11:55,040", "timestamp_s": 715.0}, {"text": "And basically the gap between them.", "timestamp": "00:11:58,370", "timestamp_s": 718.0}, {"text": "Alumni knowledge and real life world is essentially one year now and a", "timestamp": "00:12:03,160", "timestamp_s": 723.0}, {"text": "lot has has happened since then.", "timestamp": "00:12:08,120", "timestamp_s": 728.0}, {"text": "So yeah, basically, even though it does try to be helpful by giving us command,", "timestamp": "00:12:10,810", "timestamp_s": 730.0}, {"text": "by giving us answers, but based on its knowledge, it\u0027s not really that helpful in", "timestamp": "00:12:16,260", "timestamp_s": 736.0}, {"text": "real life world, in real life situations.", "timestamp": "00:12:21,760", "timestamp_s": 741.0}, {"text": "Now let\u0027s see how we can improve on that by introducing the tool use.", "timestamp": "00:12:24,370", "timestamp_s": 744.0}, {"text": "To the LLM.", "timestamp": "00:12:28,920", "timestamp_s": 748.0}, {"text": "So let\u0027s let me switch for that for the basic to the basic agent.", "timestamp": "00:12:31,080", "timestamp_s": 751.0}, {"text": "Agent over here.", "timestamp": "00:12:36,600", "timestamp_s": 756.0}, {"text": "Alright, so I\u0027m again using the same model GT 4.1 for that.", "timestamp": "00:12:39,360", "timestamp_s": 759.0}, {"text": "And what we will be using on top of that is what is called react framework.", "timestamp": "00:12:44,940", "timestamp_s": 764.0}, {"text": "React stands for reasonable effect and basically we will be instructing", "timestamp": "00:12:49,755", "timestamp_s": 769.0}, {"text": "LLM to go through the loop of multiple stages, namely, thought,", "timestamp": "00:12:53,805", "timestamp_s": 773.0}, {"text": "action, post observation, and answer.", "timestamp": "00:12:58,215", "timestamp_s": 778.0}, {"text": "In the third step, the LLM would need to think about what action it needs", "timestamp": "00:13:01,145", "timestamp_s": 781.0}, {"text": "to perform to get the answer or to get the information to give us answer.", "timestamp": "00:13:05,345", "timestamp_s": 785.0}, {"text": "Then it needs to decide on the action itself basically.", "timestamp": "00:13:10,515", "timestamp_s": 790.0}, {"text": "As a response to our request, it will need to send the actual action.", "timestamp": "00:13:15,570", "timestamp_s": 795.0}, {"text": "It wants to perform with some, along with some inputs potentially.", "timestamp": "00:13:19,450", "timestamp_s": 799.0}, {"text": "Then there is a post step where basically the action should run on behalf of LLM.", "timestamp": "00:13:23,230", "timestamp_s": 803.0}, {"text": "Then during the observation step, the output from the action", "timestamp": "00:13:29,940", "timestamp_s": 809.0}, {"text": "will be sent to LLM and then.", "timestamp": "00:13:33,840", "timestamp_s": 813.0}, {"text": "Based on this observation and the initial input from the user the LLM hopefully", "timestamp": "00:13:37,540", "timestamp_s": 817.0}, {"text": "will come up with a, with an answer.", "timestamp": "00:13:42,480", "timestamp_s": 822.0}, {"text": "Or if that information is not enough, it\u0027ll go to the second loop,", "timestamp": "00:13:44,880", "timestamp_s": 824.0}, {"text": "to the third loop and so on until it gets asked the answer or until", "timestamp": "00:13:49,690", "timestamp_s": 829.0}, {"text": "it runs out of low penetrations.", "timestamp": "00:13:54,740", "timestamp_s": 834.0}, {"text": "And this can pretty easily be implemented through this.", "timestamp": "00:13:57,500", "timestamp_s": 837.0}, {"text": "System prompt over here, and basically I\u0027m instructing a LLM to do, to follow", "timestamp": "00:14:01,415", "timestamp_s": 841.0}, {"text": "the same the, to follow the loop of react framework, which I just described, right?", "timestamp": "00:14:08,645", "timestamp_s": 848.0}, {"text": "So you run in a loop of thought action post observation.", "timestamp": "00:14:13,265", "timestamp_s": 853.0}, {"text": "I use thought, I use action.", "timestamp": "00:14:16,910", "timestamp_s": 856.0}, {"text": "And then we also provide a few actions available for", "timestamp": "00:14:19,340", "timestamp_s": 859.0}, {"text": "LLM to use or to choose from.", "timestamp": "00:14:23,255", "timestamp_s": 863.0}, {"text": "In this case, those would be Ping.", "timestamp": "00:14:25,790", "timestamp_s": 865.0}, {"text": "So basically that would perform the ping command.", "timestamp": "00:14:27,830", "timestamp_s": 867.0}, {"text": "On behalf of LLM, we have bh which would allow LLM to use any,", "timestamp": "00:14:30,990", "timestamp_s": 870.0}, {"text": "to execute any batch commands.", "timestamp": "00:14:36,940", "timestamp_s": 876.0}, {"text": "And we will have web search pretty basic web search which will", "timestamp": "00:14:39,415", "timestamp_s": 879.0}, {"text": "allow LLM to well do web search.", "timestamp": "00:14:42,925", "timestamp_s": 882.0}, {"text": "We also have some example session over here for LLM to use as a reference.", "timestamp": "00:14:47,045", "timestamp_s": 887.0}, {"text": "So for example here, the question from the user could be how many", "timestamp": "00:14:52,125", "timestamp_s": 892.0}, {"text": "islands make up Madera Ali Madera.", "timestamp": "00:14:55,905", "timestamp_s": 895.0}, {"text": "So it\u0027s a sort of nice, nice small Easter egg for that.", "timestamp": "00:14:58,255", "timestamp_s": 898.0}, {"text": "And then the thought from LLM should hopefully be that it needs", "timestamp": "00:15:01,655", "timestamp_s": 901.0}, {"text": "to do a web search for the madada.", "timestamp": "00:15:05,615", "timestamp_s": 905.0}, {"text": "Then it would need to perform to, to reply with an action namely web search,", "timestamp": "00:15:08,265", "timestamp_s": 908.0}, {"text": "and then the input for that action.", "timestamp": "00:15:14,125", "timestamp_s": 914.0}, {"text": "In this case that could be just Madeira.", "timestamp": "00:15:16,505", "timestamp_s": 916.0}, {"text": "Then during the post, the actual web search will happen.", "timestamp": "00:15:19,265", "timestamp_s": 919.0}, {"text": "And then based on the web search.", "timestamp": "00:15:22,375", "timestamp_s": 922.0}, {"text": "Based on the observation from that web search the LLM should", "timestamp": "00:15:24,545", "timestamp_s": 924.0}, {"text": "hopefully come up with an answer.", "timestamp": "00:15:28,235", "timestamp_s": 928.0}, {"text": "In this case that would be four islands.", "timestamp": "00:15:30,005", "timestamp_s": 930.0}, {"text": "We are using the same code to query the LLM, we\u0027ll just directly send", "timestamp": "00:15:33,555", "timestamp_s": 933.0}, {"text": "the input from from us, from the user, along with the pro, with the", "timestamp": "00:15:39,135", "timestamp_s": 939.0}, {"text": "system prompt we\u0027ve seen above.", "timestamp": "00:15:43,605", "timestamp_s": 943.0}, {"text": "And then let\u0027s also define our three actions, three", "timestamp": "00:15:47,040", "timestamp_s": 947.0}, {"text": "commands to perform actions.", "timestamp": "00:15:50,190", "timestamp_s": 950.0}, {"text": "Name the ping bash and web search.", "timestamp": "00:15:52,000", "timestamp_s": 952.0}, {"text": "Let\u0027s test them out.", "timestamp": "00:15:55,000", "timestamp_s": 955.0}, {"text": "And ping for google.com.", "timestamp": "00:15:56,650", "timestamp_s": 956.0}, {"text": "Resource 200 milliseconds.", "timestamp": "00:15:59,340", "timestamp_s": 959.0}, {"text": "I do indeed have Python, three point 12.6 installed locally and for the web", "timestamp": "00:16:01,150", "timestamp_s": 961.0}, {"text": "search for Python three 14 it gave us a lot of information from the website.", "timestamp": "00:16:06,910", "timestamp_s": 966.0}, {"text": "So this seems to be working fine now, let\u0027s compile this in the dictionary", "timestamp": "00:16:15,140", "timestamp_s": 975.0}, {"text": "just to make it more easily accessible.", "timestamp": "00:16:20,430", "timestamp_s": 980.0}, {"text": "And then the main implementation of react framework happens basically in", "timestamp": "00:16:23,030", "timestamp_s": 983.0}, {"text": "these, and these function over here where we are going through the react loop", "timestamp": "00:16:27,310", "timestamp_s": 987.0}, {"text": "we start with the sending the, is the query of the digital query to the model.", "timestamp": "00:16:32,290", "timestamp_s": 992.0}, {"text": "Then based on the output from the model, we check if there is any action", "timestamp": "00:16:37,620", "timestamp_s": 997.0}, {"text": "that model decided to perform, which will be, signified by these actions.", "timestamp": "00:16:42,400", "timestamp_s": 1002.0}, {"text": "Semicolon prefix of the string.", "timestamp": "00:16:47,135", "timestamp_s": 1007.0}, {"text": "And if there is an action we get the list of actions.", "timestamp": "00:16:50,025", "timestamp_s": 1010.0}, {"text": "We perform that action and give the result of running that action to the", "timestamp": "00:16:53,625", "timestamp_s": 1013.0}, {"text": "LLM to hopefully give us the answer.", "timestamp": "00:16:58,315", "timestamp_s": 1018.0}, {"text": "And then of course, if it\u0027s, if that information is not enough,", "timestamp": "00:17:01,415", "timestamp_s": 1021.0}, {"text": "we will go to the second loop.", "timestamp": "00:17:05,215", "timestamp_s": 1025.0}, {"text": "To the third loop, and so on.", "timestamp": "00:17:06,625", "timestamp_s": 1026.0}, {"text": "Now let\u0027s try pretty much the same, the same prompts, the same questions", "timestamp": "00:17:09,715", "timestamp_s": 1029.0}, {"text": "we had before in the baseline, but now with these basic agent behavior.", "timestamp": "00:17:14,065", "timestamp_s": 1034.0}, {"text": "So let\u0027s first try to get the response time for Google, in this case it, the A", "timestamp": "00:17:20,585", "timestamp_s": 1040.0}, {"text": "lamp decided to perform Action Ping for google.com which is a correct action.", "timestamp": "00:17:25,235", "timestamp_s": 1045.0}, {"text": "It got the answer from the action, and then as an answer to our", "timestamp": "00:17:30,855", "timestamp_s": 1050.0}, {"text": "initial question, it gave us.", "timestamp": "00:17:36,195", "timestamp_s": 1056.0}, {"text": "The rounded number of milliseconds or seconds for the pink the same should", "timestamp": "00:17:38,175", "timestamp_s": 1058.0}, {"text": "work with the Python packages, right?", "timestamp": "00:17:44,045", "timestamp_s": 1064.0}, {"text": "So we decided to perform the action batch with the input of P list", "timestamp": "00:17:46,295", "timestamp_s": 1066.0}, {"text": "which gave the alarm a bunch of packages I have installed locally.", "timestamp": "00:17:51,465", "timestamp_s": 1071.0}, {"text": "And then based on that the answer from LLM was, I guess sort of summary", "timestamp": "00:17:57,375", "timestamp_s": 1077.0}, {"text": "of, of those Python packages which have installed locally showing a", "timestamp": "00:18:02,735", "timestamp_s": 1082.0}, {"text": "presentative sample apparently.", "timestamp": "00:18:06,545", "timestamp_s": 1086.0}, {"text": "All right.", "timestamp": "00:18:08,645", "timestamp_s": 1088.0}, {"text": "And this, let\u0027s see what will happen with the, our Python three 14 question.", "timestamp": "00:18:08,945", "timestamp_s": 1088.0}, {"text": "So the action that Ellan decided to perform is a web search,", "timestamp": "00:18:14,155", "timestamp_s": 1094.0}, {"text": "which makes sense, right?", "timestamp": "00:18:17,845", "timestamp_s": 1097.0}, {"text": "It\u0027s pretty much the actual question of ours was new by three 14.", "timestamp": "00:18:19,395", "timestamp_s": 1099.0}, {"text": "It got to the.", "timestamp": "00:18:25,015", "timestamp_s": 1105.0}, {"text": "Logical website from python.org with a bunch of information and somewhere below.", "timestamp": "00:18:27,220", "timestamp_s": 1107.0}, {"text": "Let me scroll all the way down, somewhere below it should give us the answer based", "timestamp": "00:18:33,940", "timestamp_s": 1113.0}, {"text": "on the observation from that action.", "timestamp": "00:18:40,600", "timestamp_s": 1120.0}, {"text": "Namely over here.", "timestamp": "00:18:43,150", "timestamp_s": 1123.0}, {"text": "It, it summarized some new features changes in Python three 14, a few", "timestamp": "00:18:45,505", "timestamp_s": 1125.0}, {"text": "PEPs, a few new features some changes.", "timestamp": "00:18:50,895", "timestamp_s": 1130.0}, {"text": "So basically with just a single system prompt like this.", "timestamp": "00:18:54,775", "timestamp_s": 1134.0}, {"text": "We already are able to significantly extend the capabilities of LLM beyond", "timestamp": "00:19:00,810", "timestamp_s": 1140.0}, {"text": "it just being a sort of knowledge base.", "timestamp": "00:19:06,570", "timestamp_s": 1146.0}, {"text": "We else, it, it now has access to web, it now has access to our local machine.", "timestamp": "00:19:09,420", "timestamp_s": 1149.0}, {"text": "It now has access to batch commands, right?", "timestamp": "00:19:14,810", "timestamp_s": 1154.0}, {"text": "So basically it already can be much more helpful.", "timestamp": "00:19:17,810", "timestamp_s": 1157.0}, {"text": "For us was in everyday life and in our coding coding journey.", "timestamp": "00:19:22,925", "timestamp_s": 1162.0}, {"text": "But of course it wouldn\u0027t be very convenient to.", "timestamp": "00:19:28,115", "timestamp_s": 1168.0}, {"text": "Modify this prompt every time we need to add new action.", "timestamp": "00:19:31,990", "timestamp_s": 1171.0}, {"text": "And there could be a lot of different actions depending on what tool", "timestamp": "00:19:35,440", "timestamp_s": 1175.0}, {"text": "you want LLM to be able to use.", "timestamp": "00:19:38,770", "timestamp_s": 1178.0}, {"text": "Like for example, if you think about Git right?", "timestamp": "00:19:41,260", "timestamp_s": 1181.0}, {"text": "The Git itself has a bunch of different commands like Git commit,", "timestamp": "00:19:43,790", "timestamp_s": 1183.0}, {"text": "Git checkout, Git branch, and so on.", "timestamp": "00:19:47,900", "timestamp_s": 1187.0}, {"text": "So you would potentially need to define each.", "timestamp": "00:19:50,240", "timestamp_s": 1190.0}, {"text": "Single git command as a set protection, and that probably", "timestamp": "00:19:53,990", "timestamp_s": 1193.0}, {"text": "would take quite a long time.", "timestamp": "00:19:57,920", "timestamp_s": 1197.0}, {"text": "Now, ho fortunately for us, there are ways to abstract all these tool definitions", "timestamp": "00:19:59,840", "timestamp_s": 1199.0}, {"text": "from us, from the end user, and one of those, one of these ways is MCP.", "timestamp": "00:20:06,630", "timestamp_s": 1206.0}, {"text": "So let me go back to the slides real quick over here.", "timestamp": "00:20:13,420", "timestamp_s": 1213.0}, {"text": "Let\u0027s see.", "timestamp": "00:20:18,905", "timestamp_s": 1218.0}, {"text": "So MCP stands for Model Context Protocol, and it was introduced", "timestamp": "00:20:20,165", "timestamp_s": 1220.0}, {"text": "pretty recently and the end of November last year two four by Tropic.", "timestamp": "00:20:25,445", "timestamp_s": 1225.0}, {"text": "So essentially MCP is a protocol based on JSON RPC, which, which aims to facilitate.", "timestamp": "00:20:31,095", "timestamp_s": 1231.0}, {"text": "The tool use and the development of those tools, it consists of two main", "timestamp": "00:20:38,975", "timestamp_s": 1238.0}, {"text": "counterparts, MCP server and MCP host, and MCP client, and now MCP client could", "timestamp": "00:20:43,625", "timestamp_s": 1243.0}, {"text": "be our LLM, it could be some id, it could be any AI enabled tool, basically.", "timestamp": "00:20:49,575", "timestamp_s": 1249.0}, {"text": "And then MCP server performs essentially two main functions.", "timestamp": "00:20:57,355", "timestamp_s": 1257.0}, {"text": "First, it, of course, interacts with the, with the actual tool", "timestamp": "00:21:02,295", "timestamp_s": 1262.0}, {"text": "performs the actual actions, right?", "timestamp": "00:21:05,865", "timestamp_s": 1265.0}, {"text": "So it could access some local sources.", "timestamp": "00:21:07,305", "timestamp_s": 1267.0}, {"text": "It could be MCP server for the file system, so it could manipulate files,", "timestamp": "00:21:09,965", "timestamp_s": 1269.0}, {"text": "for example, it could also be MCP server that performs some a p requests.", "timestamp": "00:21:13,565", "timestamp_s": 1273.0}, {"text": "So it could be MCP server, which provides tools to access Jira, for example.", "timestamp": "00:21:18,485", "timestamp_s": 1278.0}, {"text": "Or it could be tools to access.", "timestamp": "00:21:25,325", "timestamp_s": 1285.0}, {"text": "Flight radar, right?", "timestamp": "00:21:28,965", "timestamp_s": 1288.0}, {"text": "So basically any anything that can be coded to be accessed through", "timestamp": "00:21:29,985", "timestamp_s": 1289.0}, {"text": "code can be converted to MCP server.", "timestamp": "00:21:34,205", "timestamp_s": 1294.0}, {"text": "And then through MCP Protocol, the LLM can get the list of tools,", "timestamp": "00:21:37,215", "timestamp_s": 1297.0}, {"text": "can get any names, different descriptions, and how to use them.", "timestamp": "00:21:41,805", "timestamp_s": 1301.0}, {"text": "And then again, through MCP protocol, it would send essentially the request", "timestamp": "00:21:45,765", "timestamp_s": 1305.0}, {"text": "to perform the action to the MCP server, and then it would get the", "timestamp": "00:21:50,955", "timestamp_s": 1310.0}, {"text": "response, from NCP server with the result of running that ac that action", "timestamp": "00:21:54,705", "timestamp_s": 1314.0}, {"text": "or the result of running that tool.", "timestamp": "00:21:58,995", "timestamp_s": 1318.0}, {"text": "And it is pretty straightforward to run to create your own NCP servers.", "timestamp": "00:22:01,930", "timestamp_s": 1321.0}, {"text": "Let me switch back to our notebook over here, and let\u0027s go now to", "timestamp": "00:22:07,050", "timestamp_s": 1327.0}, {"text": "the agent with MCP directory.", "timestamp": "00:22:14,980", "timestamp_s": 1334.0}, {"text": "So first, let\u0027s see how we can implement our own MCP server.", "timestamp": "00:22:17,740", "timestamp_s": 1337.0}, {"text": "And you can do that in multiple languages.", "timestamp": "00:22:22,060", "timestamp_s": 1342.0}, {"text": "I think currently there are SDKs of Python, JavaScript, Java", "timestamp": "00:22:24,130", "timestamp_s": 1344.0}, {"text": "and Lin, if I\u0027m not mistaken.", "timestamp": "00:22:29,870", "timestamp_s": 1349.0}, {"text": "But essentially, of course, I\u0027m sure that more languages will follow, but", "timestamp": "00:22:31,890", "timestamp_s": 1351.0}, {"text": "basically over here we have the two MCP two or MCP server defined in Python", "timestamp": "00:22:36,620", "timestamp_s": 1356.0}, {"text": "and Tropic provided a nice, fast MCP class or from the MCP framework, which", "timestamp": "00:22:42,490", "timestamp_s": 1362.0}, {"text": "basically requires us to essentially just do essentially the server itself.", "timestamp": "00:22:49,760", "timestamp_s": 1369.0}, {"text": "And then through this, the curator, we can convert any function into an MCP tool.", "timestamp": "00:22:54,720", "timestamp_s": 1374.0}, {"text": "So in this case, that would be a bar tool which will perform any", "timestamp": "00:22:59,850", "timestamp_s": 1379.0}, {"text": "we will execute any batch command.", "timestamp": "00:23:03,490", "timestamp_s": 1383.0}, {"text": "For us, and of course you, ideally, you don\u0027t want to", "timestamp": "00:23:06,905", "timestamp_s": 1386.0}, {"text": "execute blindly any b command.", "timestamp": "00:23:09,155", "timestamp_s": 1389.0}, {"text": "But for the sake of the, for the presentation we we will allow that.", "timestamp": "00:23:11,835", "timestamp_s": 1391.0}, {"text": "But basically those three lines is the only thing, things that you would need", "timestamp": "00:23:18,195", "timestamp_s": 1398.0}, {"text": "this in Python to create a bar Oh, sorry.", "timestamp": "00:23:22,355", "timestamp_s": 1402.0}, {"text": "To create an MCP server for yourself.", "timestamp": "00:23:24,975", "timestamp_s": 1404.0}, {"text": "And as I said, anything that you can code can essentially", "timestamp": "00:23:28,370", "timestamp_s": 1408.0}, {"text": "be converted to MCP server.", "timestamp": "00:23:31,680", "timestamp_s": 1411.0}, {"text": "Now, along with that, we also would require a sort of description of how", "timestamp": "00:23:35,160", "timestamp_s": 1415.0}, {"text": "to call that server, that MCP server.", "timestamp": "00:23:41,460", "timestamp_s": 1421.0}, {"text": "And over here I have a. Small JSON file, which defines the MCP servers.", "timestamp": "00:23:44,340", "timestamp_s": 1424.0}, {"text": "In this case, the only MCP server is called B and it is run as", "timestamp": "00:23:50,225", "timestamp_s": 1430.0}, {"text": "python command, right with the arcs of just name of the file.", "timestamp": "00:23:55,325", "timestamp_s": 1435.0}, {"text": "\u0027cause it\u0027s essentially by Python script.", "timestamp": "00:23:59,975", "timestamp_s": 1439.0}, {"text": "So that\u0027s the only two things that needs that it needs to be executed.", "timestamp": "00:24:02,155", "timestamp_s": 1442.0}, {"text": "But we\u0027ll see later different ways.", "timestamp": "00:24:07,285", "timestamp_s": 1447.0}, {"text": "Beyond just Python script that you can execute MCP servers as.", "timestamp": "00:24:09,325", "timestamp_s": 1449.0}, {"text": "So let\u0027s now see how we can use those MCP servers along with LLM.", "timestamp": "00:24:14,665", "timestamp_s": 1454.0}, {"text": "So for that first of all, we will switch to tropic.", "timestamp": "00:24:21,965", "timestamp_s": 1461.0}, {"text": "In this case it would be cloud D 3.7, I believe.", "timestamp": "00:24:25,045", "timestamp_s": 1465.0}, {"text": "Yep, it\u0027s cloud D 3.7.", "timestamp": "00:24:28,535", "timestamp_s": 1468.0}, {"text": "The reason for this switch.", "timestamp": "00:24:31,245", "timestamp_s": 1471.0}, {"text": "Is initially tropic tropics Cloud was more was better at using tools.", "timestamp": "00:24:33,920", "timestamp_s": 1473.0}, {"text": "However, now you might have heard that even OpenAI adopted the MCP", "timestamp": "00:24:39,860", "timestamp_s": 1479.0}, {"text": "protocol from the arrivals, basically.", "timestamp": "00:24:44,630", "timestamp_s": 1484.0}, {"text": "So the recent models are also pretty good with following, with", "timestamp": "00:24:47,250", "timestamp_s": 1487.0}, {"text": "using tools defined as MCP servers.", "timestamp": "00:24:52,000", "timestamp_s": 1492.0}, {"text": "But still here we\u0027ll be using, tropics called 3.7.", "timestamp": "00:24:54,550", "timestamp_s": 1494.0}, {"text": "Now, what we essentially need to use the CP tools is we will need an MCB client.", "timestamp": "00:24:58,970", "timestamp_s": 1498.0}, {"text": "And in this case the main functions or methods of this class is, first", "timestamp": "00:25:06,170", "timestamp_s": 1506.0}, {"text": "of all, we need of course to connect to servers to get the list of tools", "timestamp": "00:25:11,410", "timestamp_s": 1511.0}, {"text": "available for us to use no for LLM to use.", "timestamp": "00:25:16,020", "timestamp_s": 1516.0}, {"text": "These function is essentially responsible for that.", "timestamp": "00:25:19,860", "timestamp_s": 1519.0}, {"text": "So we just connect to each server in the loop, in the server config, and then", "timestamp": "00:25:23,030", "timestamp_s": 1523.0}, {"text": "get a list of tools from that server.", "timestamp": "00:25:29,260", "timestamp_s": 1529.0}, {"text": "And then we also need to of course, send the request to LLM and then act", "timestamp": "00:25:32,960", "timestamp_s": 1532.0}, {"text": "accordingly to the response from LLM.", "timestamp": "00:25:39,730", "timestamp_s": 1539.0}, {"text": "So basically we attach the list of tools.", "timestamp": "00:25:42,460", "timestamp_s": 1542.0}, {"text": "I got from MCP servers in the format of tool name, tool description, and", "timestamp": "00:25:47,125", "timestamp_s": 1547.0}, {"text": "tool input schema, along with our, user input message, and those things are", "timestamp": "00:25:51,395", "timestamp_s": 1551.0}, {"text": "sent directly to CLA 3.7 in this case.", "timestamp": "00:25:57,105", "timestamp_s": 1557.0}, {"text": "And then the clo, the LLM, decides if it wants to just respond as", "timestamp": "00:26:01,035", "timestamp_s": 1561.0}, {"text": "a plain text or if it wants to perform an action or a tool use.", "timestamp": "00:26:05,995", "timestamp_s": 1565.0}, {"text": "And this is how we basically differentiate between.", "timestamp": "00:26:10,715", "timestamp_s": 1570.0}, {"text": "Between those as part of the response that would be a content type.", "timestamp": "00:26:14,650", "timestamp_s": 1574.0}, {"text": "It could be either text or a tool use in, and in the case of tool use, we will", "timestamp": "00:26:18,520", "timestamp_s": 1578.0}, {"text": "see what kind of tool it wants to use.", "timestamp": "00:26:23,080", "timestamp_s": 1583.0}, {"text": "So that will basically tool name and then what kind of input arguments, it needs to", "timestamp": "00:26:25,380", "timestamp_s": 1585.0}, {"text": "be we need to pass to that to that tool.", "timestamp": "00:26:30,190", "timestamp_s": 1590.0}, {"text": "Then we will perform that actual tool call over here.", "timestamp": "00:26:33,190", "timestamp_s": 1593.0}, {"text": "And then we\u0027ll send the result of that tool call back to LLM, and then hopefully", "timestamp": "00:26:37,300", "timestamp_s": 1597.0}, {"text": "we will get an answer to our question.", "timestamp": "00:26:44,300", "timestamp_s": 1604.0}, {"text": "And then here I have a small, a nice small chat loop.", "timestamp": "00:26:47,860", "timestamp_s": 1607.0}, {"text": "Where basically we will send the we will send the query into the into", "timestamp": "00:26:52,700", "timestamp_s": 1612.0}, {"text": "the text field, and then proceed with this chat until we type the qui word.", "timestamp": "00:26:55,970", "timestamp_s": 1615.0}, {"text": "So let\u0027s start with our, just with our bar tool over here.", "timestamp": "00:27:01,920", "timestamp_s": 1621.0}, {"text": "We got connected to the, to our server which was run as", "timestamp": "00:27:07,020", "timestamp_s": 1627.0}, {"text": "Python Bar tool, fast speed pi.", "timestamp": "00:27:10,810", "timestamp_s": 1630.0}, {"text": "We have one single tool called Barge.", "timestamp": "00:27:13,810", "timestamp_s": 1633.0}, {"text": "And let\u0027s ask LLM to do something.", "timestamp": "00:27:17,020", "timestamp_s": 1637.0}, {"text": "Let\u0027s say list all files and let\u0027s see what will come up with.", "timestamp": "00:27:19,700", "timestamp_s": 1639.0}, {"text": "So in this case, he decided to call the B command, the Bash two with", "timestamp": "00:27:27,290", "timestamp_s": 1647.0}, {"text": "a comment with a. With the comment LS dash la, which makes sense.", "timestamp": "00:27:31,990", "timestamp_s": 1651.0}, {"text": "It got the list of files and basically summarized them all.", "timestamp": "00:27:36,720", "timestamp_s": 1656.0}, {"text": "Good.", "timestamp": "00:27:42,210", "timestamp_s": 1662.0}, {"text": "Now let\u0027s see how we can extend these two multiple servers to multiple tools.", "timestamp": "00:27:43,560", "timestamp_s": 1663.0}, {"text": "And for that we will use the full J confi over here.", "timestamp": "00:27:48,400", "timestamp_s": 1668.0}, {"text": "Which basically defines four MCP servers.", "timestamp": "00:27:53,110", "timestamp_s": 1673.0}, {"text": "First of all, we have a file system, MCP server, which is essentially", "timestamp": "00:27:56,590", "timestamp_s": 1676.0}, {"text": "an NPM package which runs with few inputs, see few arguments.", "timestamp": "00:28:00,910", "timestamp_s": 1680.0}, {"text": "We also have a web search realized through Brave web search, and", "timestamp": "00:28:05,900", "timestamp_s": 1685.0}, {"text": "that is run as docker image.", "timestamp": "00:28:10,040", "timestamp_s": 1690.0}, {"text": "So here we have some end file for the tokens.", "timestamp": "00:28:12,725", "timestamp_s": 1692.0}, {"text": "We also have a fe, a web server, which would allow LLM to fetch any URL from the", "timestamp": "00:28:15,895", "timestamp_s": 1695.0}, {"text": "web, is implemented as Python package.", "timestamp": "00:28:21,245", "timestamp_s": 1701.0}, {"text": "And then of course we have our Bash MCP server, which we just", "timestamp": "00:28:24,585", "timestamp_s": 1704.0}, {"text": "defined couple seconds ago.", "timestamp": "00:28:28,025", "timestamp_s": 1708.0}, {"text": "So you can see, cP servers can come in all flavors and", "timestamp": "00:28:30,935", "timestamp_s": 1710.0}, {"text": "languages and ways to run them.", "timestamp": "00:28:34,395", "timestamp_s": 1714.0}, {"text": "Now, let\u0027s see let\u0027s not give those servers to our LLM and let\u0027s ask", "timestamp": "00:28:37,665", "timestamp_s": 1717.0}, {"text": "to perform some actions, right?", "timestamp": "00:28:45,145", "timestamp_s": 1725.0}, {"text": "First of all, let\u0027s see what\u0027s new in Python.", "timestamp": "00:28:47,115", "timestamp_s": 1727.0}, {"text": "Three 14.", "timestamp": "00:28:50,635", "timestamp_s": 1730.0}, {"text": "So let\u0027s see if it\u0027ll need to perform a web search to give us the answer.", "timestamp": "00:28:52,415", "timestamp_s": 1732.0}, {"text": "All right, so it decided to call the web search tool with the", "timestamp": "00:28:57,735", "timestamp_s": 1737.0}, {"text": "following query, Python three 14 new features through release notes.", "timestamp": "00:29:01,695", "timestamp_s": 1741.0}, {"text": "The unlike OpenAI GT 4.1, it didn\u0027t just copy the questions from us and then based", "timestamp": "00:29:05,520", "timestamp_s": 1745.0}, {"text": "on the response from the web search tool, it gave us the summary of new features.", "timestamp": "00:29:12,040", "timestamp_s": 1752.0}, {"text": "Let\u0027s also try to ask cla to create a file called Hello the text with the content.", "timestamp": "00:29:17,900", "timestamp_s": 1757.0}, {"text": "Hello world.", "timestamp": "00:29:29,240", "timestamp_s": 1769.0}, {"text": "Alright.", "timestamp": "00:29:31,040", "timestamp_s": 1771.0}, {"text": "Let\u0027s see.", "timestamp": "00:29:33,560", "timestamp_s": 1773.0}, {"text": "So hopefully it\u0027ll be able to access our local file system.", "timestamp": "00:29:34,310", "timestamp_s": 1774.0}, {"text": "So in this case, we decided to use the tool right file", "timestamp": "00:29:38,620", "timestamp_s": 1778.0}, {"text": "with the following arguments.", "timestamp": "00:29:42,040", "timestamp_s": 1782.0}, {"text": "And let\u0027s actually see, yeah, we just got the new file.", "timestamp": "00:29:43,630", "timestamp_s": 1783.0}, {"text": "We on our local file system called as Requested, hello to 60 with the content.", "timestamp": "00:29:47,670", "timestamp_s": 1787.0}, {"text": "Hello World.", "timestamp": "00:29:53,970", "timestamp_s": 1793.0}, {"text": "Great.", "timestamp": "00:29:55,785", "timestamp_s": 1795.0}, {"text": "So essentially with just a few lines of code of basically the JSON config", "timestamp": "00:29:56,475", "timestamp_s": 1796.0}, {"text": "of MCP servers, we, again extended the capabilities of LLM beyond just", "timestamp": "00:30:02,855", "timestamp_s": 1802.0}, {"text": "being able to answer questions based on its on what is seen in the tearing", "timestamp": "00:30:08,515", "timestamp_s": 1808.0}, {"text": "data, it is now also able to perform.", "timestamp": "00:30:13,055", "timestamp_s": 1813.0}, {"text": "A lot of different actions and those MCP server can come in different flavors.", "timestamp": "00:30:16,375", "timestamp_s": 1816.0}, {"text": "And there are actually a lot of different sources where you", "timestamp": "00:30:22,275", "timestamp_s": 1822.0}, {"text": "can find M CCP servers online.", "timestamp": "00:30:26,625", "timestamp_s": 1826.0}, {"text": "There are MCP registries, which contains hundreds of different M", "timestamp": "00:30:28,755", "timestamp_s": 1828.0}, {"text": "CCP servers for tools like, for example, Grafana JIRA and so on.", "timestamp": "00:30:32,985", "timestamp_s": 1832.0}, {"text": "So basically you can, give a lamb access to any tools you use in your", "timestamp": "00:30:36,555", "timestamp_s": 1836.0}, {"text": "everyday every everyday working life.", "timestamp": "00:30:42,195", "timestamp_s": 1842.0}, {"text": "And basically, as we will see later, ask it to, for example, solve the ticket.", "timestamp": "00:30:45,235", "timestamp_s": 1845.0}, {"text": "Now let\u0027s let me quickly jump back to the slides for a few more seconds.", "timestamp": "00:30:52,795", "timestamp_s": 1852.0}, {"text": "All right, so we\u0027ve seen MCP.", "timestamp": "00:31:01,685", "timestamp_s": 1861.0}, {"text": "Now let\u0027s see how we can make agents work with each other because of course,", "timestamp": "00:31:03,665", "timestamp_s": 1863.0}, {"text": "before, before that, we, all the tools we had, oh, LLM had at this disposal", "timestamp": "00:31:10,105", "timestamp_s": 1870.0}, {"text": "were essentially just a software, right?", "timestamp": "00:31:15,115", "timestamp_s": 1875.0}, {"text": "There was just API calls, it was just file system manipulations and so on.", "timestamp": "00:31:17,675", "timestamp_s": 1877.0}, {"text": "However, you can imagine those tools being agents on their own.", "timestamp": "00:31:21,925", "timestamp_s": 1881.0}, {"text": "And then one agent could potentially call another agent to delegate a task", "timestamp": "00:31:26,655", "timestamp_s": 1886.0}, {"text": "to ask it, to ask a subordinate agent to perform some small subtask and so on.", "timestamp": "00:31:31,735", "timestamp_s": 1891.0}, {"text": "And in our case, we will be building a system which contains four", "timestamp": "00:31:37,115", "timestamp_s": 1897.0}, {"text": "agents and it will be hierarchical.", "timestamp": "00:31:42,175", "timestamp_s": 1902.0}, {"text": "Hierarchical system where, we\u0027ll, where we will have supervisor,", "timestamp": "00:31:45,525", "timestamp_s": 1905.0}, {"text": "agent which you can think about as product manager, for example.", "timestamp": "00:31:48,675", "timestamp_s": 1908.0}, {"text": "And this agent will be able to call three other agents subordinate agents.", "timestamp": "00:31:52,475", "timestamp_s": 1912.0}, {"text": "And those would be frontend developer virtual frontend developer.", "timestamp": "00:31:58,035", "timestamp_s": 1918.0}, {"text": "Virtual backend developer and virtual DevOps engineer.", "timestamp": "00:32:02,174", "timestamp_s": 1922.0}, {"text": "And they also would be able to interact with us with the client to", "timestamp": "00:32:05,114", "timestamp_s": 1925.0}, {"text": "ask for any clarification if needed.", "timestamp": "00:32:09,414", "timestamp_s": 1929.0}, {"text": "But generally all of the manipulation of the all of the.", "timestamp": "00:32:12,124", "timestamp_s": 1932.0}, {"text": "Interactions between those subordinate agents should happen", "timestamp": "00:32:16,865", "timestamp_s": 1936.0}, {"text": "through a supervisor agent.", "timestamp": "00:32:19,904", "timestamp_s": 1939.0}, {"text": "There is no direct connection from one subordinate agent to another.", "timestamp": "00:32:21,444", "timestamp_s": 1941.0}, {"text": "However, of course, you can also implement this where where in the system potentially", "timestamp": "00:32:25,935", "timestamp_s": 1945.0}, {"text": "all agents would be able to talk with each other directly, not through the", "timestamp": "00:32:30,714", "timestamp_s": 1950.0}, {"text": "supervisor agent, it would really depend on what you want the system to work to do.", "timestamp": "00:32:34,854", "timestamp_s": 1954.0}, {"text": "Now let me switch back again to our Jupyter Notebook.", "timestamp": "00:32:41,484", "timestamp_s": 1961.0}, {"text": "Alright,", "timestamp": "00:32:47,314", "timestamp_s": 1967.0}, {"text": "and let\u0027s go to the final notebook of the day, which is multi-agent.", "timestamp": "00:32:49,924", "timestamp_s": 1969.0}, {"text": "Notebook.", "timestamp": "00:32:55,924", "timestamp_s": 1975.0}, {"text": "Now here I will be adding one more level of abstraction and memory,", "timestamp": "00:32:56,704", "timestamp_s": 1976.0}, {"text": "link chain and glowing graph.", "timestamp": "00:33:01,264", "timestamp_s": 1981.0}, {"text": "And the reason for that is of course you can implement all of", "timestamp": "00:33:03,004", "timestamp_s": 1983.0}, {"text": "the agent, all of the cross agent collaborate interactions on your own.", "timestamp": "00:33:06,704", "timestamp_s": 1986.0}, {"text": "It is essentially.", "timestamp": "00:33:11,934", "timestamp_s": 1991.0}, {"text": "Just the structured inputs and outputs and then some state", "timestamp": "00:33:14,409", "timestamp_s": 1994.0}, {"text": "manipulations on top of that.", "timestamp": "00:33:18,489", "timestamp_s": 1998.0}, {"text": "Why spend time on that when you can use the frameworks which", "timestamp": "00:33:20,439", "timestamp_s": 2000.0}, {"text": "do that for you basically.", "timestamp": "00:33:24,839", "timestamp_s": 2004.0}, {"text": "So again, we will use the same quality 3.7 here and.", "timestamp": "00:33:26,939", "timestamp_s": 2006.0}, {"text": "Give it three, or, sorry, four four tools.", "timestamp": "00:33:32,414", "timestamp_s": 2012.0}, {"text": "Pretty much the same tools which we\u0027ve seen before.", "timestamp": "00:33:36,664", "timestamp_s": 2016.0}, {"text": "Shell tool for the batch commands, we will, it\u0027ll also", "timestamp": "00:33:38,974", "timestamp_s": 2018.0}, {"text": "have access to brave search.", "timestamp": "00:33:42,144", "timestamp_s": 2022.0}, {"text": "Again, as we\u0027ve seen before.", "timestamp": "00:33:43,524", "timestamp_s": 2023.0}, {"text": "It\u0027ll also have access to file file system manipulation.", "timestamp": "00:33:45,504", "timestamp_s": 2025.0}, {"text": "And there is also one more new tool which I called Human, which", "timestamp": "00:33:49,064", "timestamp_s": 2029.0}, {"text": "basically would allow LLM to ask back questions to the human.", "timestamp": "00:33:54,304", "timestamp_s": 2034.0}, {"text": "And then we at the are discussed on the site.", "timestamp": "00:34:00,674", "timestamp_s": 2040.0}, {"text": "We will, we\u0027ll create four agents.", "timestamp": "00:34:03,464", "timestamp_s": 2043.0}, {"text": "First, we\u0027ll create agent supervisor, which will have access to three team", "timestamp": "00:34:06,374", "timestamp_s": 2046.0}, {"text": "members, namely frontend developer, backend developer and ops engineer, and", "timestamp": "00:34:12,884", "timestamp_s": 2052.0}, {"text": "the system run the split straightforward.", "timestamp": "00:34:17,384", "timestamp_s": 2057.0}, {"text": "We are telling the agent that it is a supervisor overseeing the following", "timestamp": "00:34:19,944", "timestamp_s": 2059.0}, {"text": "three workers, and it basically needs to decide who\u0027s who is the", "timestamp": "00:34:24,024", "timestamp_s": 2064.0}, {"text": "next agent responsible to, for, to perform the task or to act next.", "timestamp": "00:34:29,514", "timestamp_s": 2069.0}, {"text": "And then once the supervisor agent is happy with the result, it should", "timestamp": "00:34:36,144", "timestamp_s": 2076.0}, {"text": "respond with a keyword finish.", "timestamp": "00:34:40,134", "timestamp_s": 2080.0}, {"text": "Basically, we will give access to all the tools, all the available", "timestamp": "00:34:42,414", "timestamp_s": 2082.0}, {"text": "tools to these agents as well.", "timestamp": "00:34:47,604", "timestamp_s": 2087.0}, {"text": "However in real life potentially you probably would want agents to have access", "timestamp": "00:34:49,374", "timestamp_s": 2089.0}, {"text": "to different lists of tools, right?", "timestamp": "00:34:55,254", "timestamp_s": 2095.0}, {"text": "For example, you might have DevOps engineer, virtual DevOps engineer.", "timestamp": "00:34:56,544", "timestamp_s": 2096.0}, {"text": "Being able to access tools like Ana or Promeus or Datadog or whatever, right?", "timestamp": "00:35:00,494", "timestamp_s": 2100.0}, {"text": "But at the same time, you don\u0027t want, probably, you probably don\u0027t need front,", "timestamp": "00:35:07,514", "timestamp_s": 2107.0}, {"text": "end agent to be able to access that.", "timestamp": "00:35:10,984", "timestamp_s": 2110.0}, {"text": "But on the other hand, it needs to have access to other", "timestamp": "00:35:14,584", "timestamp_s": 2114.0}, {"text": "tools like Figma, for example.", "timestamp": "00:35:17,104", "timestamp_s": 2117.0}, {"text": "So the only things we basically need to create our supervisor agent is", "timestamp": "00:35:19,984", "timestamp_s": 2119.0}, {"text": "this piece of code over here where we define what what sort of nodes or what", "timestamp": "00:35:26,354", "timestamp_s": 2126.0}, {"text": "sort of hand off notes are available for these supervisor nodes to call.", "timestamp": "00:35:31,384", "timestamp_s": 2131.0}, {"text": "And those are again, our team members.", "timestamp": "00:35:37,054", "timestamp_s": 2137.0}, {"text": "And then of course, end node to finish the tasks.", "timestamp": "00:35:39,274", "timestamp_s": 2139.0}, {"text": "With that, let\u0027s also define our three agents, namely front end agent", "timestamp": "00:35:42,829", "timestamp_s": 2142.0}, {"text": "backend agent, and DevOps agent.", "timestamp": "00:35:48,209", "timestamp_s": 2148.0}, {"text": "As you can see here, we are using pretty much the same React framework.", "timestamp": "00:35:51,019", "timestamp_s": 2151.0}, {"text": "As we\u0027ve seen before, and again, we are passing all the tools, all of", "timestamp": "00:35:55,384", "timestamp_s": 2155.0}, {"text": "the available tools to those agents, and the prompts are pretty simple.", "timestamp": "00:35:59,674", "timestamp_s": 2159.0}, {"text": "Although in real life world, of course, you probably would want", "timestamp": "00:36:03,774", "timestamp_s": 2163.0}, {"text": "to be more creative or be more specific with those prompts.", "timestamp": "00:36:06,054", "timestamp_s": 2166.0}, {"text": "But in our case, we are just defining the frontend agent as a frontend developer.", "timestamp": "00:36:10,604", "timestamp_s": 2170.0}, {"text": "And this agent can also ask.", "timestamp": "00:36:17,314", "timestamp_s": 2177.0}, {"text": "Help ask for help from backend developer or DevOps engineer.", "timestamp": "00:36:20,274", "timestamp_s": 2180.0}, {"text": "And it can also ask for clarifications from the human client.", "timestamp": "00:36:24,144", "timestamp_s": 2184.0}, {"text": "The same goes with a backend backend agent.", "timestamp": "00:36:27,574", "timestamp_s": 2187.0}, {"text": "It can help, can ask for help from front end or DevOps", "timestamp": "00:36:30,744", "timestamp_s": 2190.0}, {"text": "engineer, and it can also ask for clarifications from the human client.", "timestamp": "00:36:34,554", "timestamp_s": 2194.0}, {"text": "And the same goes with a DevOps agent.", "timestamp": "00:36:39,444", "timestamp_s": 2199.0}, {"text": "It can also.", "timestamp": "00:36:41,894", "timestamp_s": 2201.0}, {"text": "Call, ask help for front end or backend developers and ask", "timestamp": "00:36:43,454", "timestamp_s": 2203.0}, {"text": "for clarifications from human.", "timestamp": "00:36:47,684", "timestamp_s": 2207.0}, {"text": "All of those agents or nodes in the terms of land graph are defined", "timestamp": "00:36:50,244", "timestamp_s": 2210.0}, {"text": "in a pretty three forward manner through these comment over here.", "timestamp": "00:36:55,924", "timestamp_s": 2215.0}, {"text": "And that\u0027s pretty much all we need to do.", "timestamp": "00:37:01,234", "timestamp_s": 2221.0}, {"text": "To define those agents.", "timestamp": "00:37:05,599", "timestamp_s": 2225.0}, {"text": "Now, with that, let\u0027s also build a graph and let\u0027s also visualize that graph.", "timestamp": "00:37:07,309", "timestamp_s": 2227.0}, {"text": "So indeed, as we\u0027ve seen before, we have the supervisor note or supervisor", "timestamp": "00:37:12,589", "timestamp_s": 2232.0}, {"text": "agent which can talk directly with our front end backend and DevOps engineers.", "timestamp": "00:37:17,659", "timestamp_s": 2237.0}, {"text": "But subordinate agents can talk to each other.", "timestamp": "00:37:23,609", "timestamp_s": 2243.0}, {"text": "They only can talk through supervisor.", "timestamp": "00:37:25,899", "timestamp_s": 2245.0}, {"text": "Over here I have just a small help helper, now helper function", "timestamp": "00:37:29,439", "timestamp_s": 2249.0}, {"text": "to color the output as we see.", "timestamp": "00:37:34,039", "timestamp_s": 2254.0}, {"text": "That\u0027s what we\u0027ll see in a few seconds, so I won\u0027t go over that piece of code.", "timestamp": "00:37:36,459", "timestamp_s": 2256.0}, {"text": "And then the task for the, for our multi-agent system would be to", "timestamp": "00:37:42,139", "timestamp_s": 2262.0}, {"text": "create a website for the conference.", "timestamp": "00:37:47,339", "timestamp_s": 2267.0}, {"text": "It needs to have three pages.", "timestamp": "00:37:49,049", "timestamp_s": 2269.0}, {"text": "Namely intro intro page page for people to submit it.", "timestamp": "00:37:51,929", "timestamp_s": 2271.0}, {"text": "There, the docs and page with the submitted docs.", "timestamp": "00:37:55,169", "timestamp_s": 2275.0}, {"text": "I want the front end in React.", "timestamp": "00:37:58,619", "timestamp_s": 2278.0}, {"text": "I want a backend test, API and the submissions should be", "timestamp": "00:38:00,709", "timestamp_s": 2280.0}, {"text": "stored in Postgres database.", "timestamp": "00:38:04,759", "timestamp_s": 2284.0}, {"text": "And also, it\u0027s always as have Docker and Docker compose.", "timestamp": "00:38:07,239", "timestamp_s": 2287.0}, {"text": "So I also ask for that.", "timestamp": "00:38:10,039", "timestamp_s": 2290.0}, {"text": "And then we also mention that they can ask the human client for any clarifications.", "timestamp": "00:38:11,779", "timestamp_s": 2291.0}, {"text": "This part over here is basically all what is needed to initiate the", "timestamp": "00:38:17,569", "timestamp_s": 2297.0}, {"text": "execution of our multi-agent system.", "timestamp": "00:38:23,529", "timestamp_s": 2303.0}, {"text": "So I actually started and see what will come up with first.", "timestamp": "00:38:25,899", "timestamp_s": 2305.0}, {"text": "Indeed we went into supervisor, which decided to call the front", "timestamp": "00:38:30,699", "timestamp_s": 2310.0}, {"text": "frontend developer the frontend developer itself decided to check", "timestamp": "00:38:34,089", "timestamp_s": 2314.0}, {"text": "what kind of tools it has installed.", "timestamp": "00:38:39,939", "timestamp_s": 2319.0}, {"text": "On the system.", "timestamp": "00:38:42,559", "timestamp_s": 2322.0}, {"text": "I got the answer and then it went ahead to check the versions the version.", "timestamp": "00:38:43,789", "timestamp_s": 2323.0}, {"text": "Alright, it decided to create a conference website directory.", "timestamp": "00:38:51,529", "timestamp_s": 2331.0}, {"text": "So here.", "timestamp": "00:38:54,709", "timestamp_s": 2334.0}, {"text": "So we already should be able to see some changes reflected locally.", "timestamp": "00:38:55,699", "timestamp_s": 2335.0}, {"text": "Indeed.", "timestamp": "00:39:00,449", "timestamp_s": 2340.0}, {"text": "We have a few directors already.", "timestamp": "00:39:00,839", "timestamp_s": 2340.0}, {"text": "We have the package on, so probably it is, yeah, it is doing.", "timestamp": "00:39:03,959", "timestamp_s": 2343.0}, {"text": "N-P-N-P-X command, which will potentially take some time because, the n payment", "timestamp": "00:39:08,419", "timestamp_s": 2348.0}, {"text": "style usually takes a few minutes.", "timestamp": "00:39:14,739", "timestamp_s": 2354.0}, {"text": "We, yeah, we can see the non models appearing for us with a bunch of packages.", "timestamp": "00:39:17,139", "timestamp_s": 2357.0}, {"text": "All right, let\u0027s okay, let\u0027s go back and we already starting to see some of", "timestamp": "00:39:23,289", "timestamp_s": 2363.0}, {"text": "the code popping up over here, right?", "timestamp": "00:39:27,999", "timestamp_s": 2367.0}, {"text": "Some CSS, some TypeScript code.", "timestamp": "00:39:30,379", "timestamp_s": 2370.0}, {"text": "Let me.", "timestamp": "00:39:32,849", "timestamp_s": 2372.0}, {"text": "Scroll scroll down here.", "timestamp": "00:39:33,989", "timestamp_s": 2373.0}, {"text": "So it did install some packages and it started to implement the code over here.", "timestamp": "00:39:37,539", "timestamp_s": 2377.0}, {"text": "So it started with the Python.", "timestamp": "00:39:43,569", "timestamp_s": 2383.0}, {"text": "Alright.", "timestamp": "00:39:46,269", "timestamp_s": 2386.0}, {"text": "Yeah.", "timestamp": "00:39:47,379", "timestamp_s": 2387.0}, {"text": "Basically it\u0027ll proceed to implement the website for us on our behalf.", "timestamp": "00:39:47,619", "timestamp_s": 2387.0}, {"text": "Now let me switch back again to the slides.", "timestamp": "00:39:53,029", "timestamp_s": 2393.0}, {"text": "All right.", "timestamp": "00:39:59,529", "timestamp_s": 2399.0}, {"text": "All right.", "timestamp": "00:40:02,859", "timestamp_s": 2402.0}, {"text": "But it is always nice to, fiddle around with the code with the", "timestamp": "00:40:03,219", "timestamp_s": 2403.0}, {"text": "agents, with the L lms and see what you can build on your own.", "timestamp": "00:40:07,229", "timestamp_s": 2407.0}, {"text": "Of course you don\u0027t always have time and still you probably would want to be able", "timestamp": "00:40:11,499", "timestamp_s": 2411.0}, {"text": "to use, those agents be able to have those agents help you with your everyday tasks.", "timestamp": "00:40:17,099", "timestamp_s": 2417.0}, {"text": "And of course there is a way for you to have them help you with your coding.", "timestamp": "00:40:22,924", "timestamp_s": 2422.0}, {"text": "Coding tasks, basically.", "timestamp": "00:40:28,264", "timestamp_s": 2428.0}, {"text": "With that, let me briefly introduce briefly talk about what we do at Z Coder.", "timestamp": "00:40:30,044", "timestamp_s": 2430.0}, {"text": "Z Coder basically is just a plugin for V Code of Brains, and this", "timestamp": "00:40:34,894", "timestamp_s": 2434.0}, {"text": "plugin brings you brings the agents to you, to your id natively.", "timestamp": "00:40:39,244", "timestamp_s": 2439.0}, {"text": "You don\u0027t need to switch to any other id outside of what you are already using.", "timestamp": "00:40:44,354", "timestamp_s": 2444.0}, {"text": "And let me briefly show showcase.", "timestamp": "00:40:49,294", "timestamp_s": 2449.0}, {"text": "Our agent basically solving the Jira task.", "timestamp": "00:40:52,374", "timestamp_s": 2452.0}, {"text": "Let me switch to this code over here.", "timestamp": "00:40:55,714", "timestamp_s": 2455.0}, {"text": "Alright,", "timestamp": "00:41:00,134", "timestamp_s": 2460.0}, {"text": "so our agent, our z coder is already natively integrated in the J So we", "timestamp": "00:41:03,374", "timestamp_s": 2463.0}, {"text": "have this encoder test over here.", "timestamp": "00:41:10,929", "timestamp_s": 2470.0}, {"text": "So basically we can tag any ticket from the j.", "timestamp": "00:41:13,149", "timestamp_s": 2473.0}, {"text": "I think that\u0027s the wrong the wrong account.", "timestamp": "00:41:19,079", "timestamp_s": 2479.0}, {"text": "Alright,", "timestamp": "00:41:21,844", "timestamp_s": 2481.0}, {"text": "base.", "timestamp": "00:41:24,904", "timestamp_s": 2484.0}, {"text": "Let\u0027s see.", "timestamp": "00:41:25,564", "timestamp_s": 2485.0}, {"text": "Alright, so let\u0027s ask our agent to solve this ticket.", "timestamp": "00:41:26,164", "timestamp_s": 2486.0}, {"text": "Solve it create a branch called 42.", "timestamp": "00:41:30,074", "timestamp_s": 2490.0}, {"text": "Check out and commit changes.", "timestamp": "00:41:36,354", "timestamp_s": 2496.0}, {"text": "All right.", "timestamp": "00:41:41,829", "timestamp_s": 2501.0}, {"text": "So the ticket itself basically requires the agent to implement", "timestamp": "00:41:42,339", "timestamp_s": 2502.0}, {"text": "changes across multiple languages across the whole repository.", "timestamp": "00:41:46,439", "timestamp_s": 2506.0}, {"text": "So what the, what our agent will do first that we\u0027ll try to analyze.", "timestamp": "00:41:50,409", "timestamp_s": 2510.0}, {"text": "The code base, it\u0027ll try to understand the project.", "timestamp": "00:41:56,214", "timestamp_s": 2516.0}, {"text": "So it will check some Python files.", "timestamp": "00:41:59,174", "timestamp_s": 2519.0}, {"text": "It decided to also check across different languages.", "timestamp": "00:42:01,244", "timestamp_s": 2521.0}, {"text": "So this repository specifically contains three languages Python, go in TypeScript.", "timestamp": "00:42:04,844", "timestamp_s": 2524.0}, {"text": "So it went ahead to check some go implementation of the repository.", "timestamp": "00:42:10,814", "timestamp_s": 2530.0}, {"text": "Yeah, so it will, it can take some time depending on the", "timestamp": "00:42:16,704", "timestamp_s": 2536.0}, {"text": "task which we have at hand.", "timestamp": "00:42:19,044", "timestamp_s": 2539.0}, {"text": "So it also create already a branch for us.", "timestamp": "00:42:20,944", "timestamp_s": 2540.0}, {"text": "Thanks to MCP support, of course, you can attach any MCP servers in this case.", "timestamp": "00:42:23,534", "timestamp_s": 2543.0}, {"text": "I have Git, MCP, which basically allows the agent to, to perform any git commands", "timestamp": "00:42:29,294", "timestamp_s": 2549.0}, {"text": "locally on your machine, and we already see some changes being implemented", "timestamp": "00:42:35,714", "timestamp_s": 2555.0}, {"text": "in our repository, first and Python.", "timestamp": "00:42:40,994", "timestamp_s": 2560.0}, {"text": "Okay?", "timestamp": "00:42:45,764", "timestamp_s": 2565.0}, {"text": "Okay.", "timestamp": "00:42:49,214", "timestamp_s": 2569.0}, {"text": "We already have modified, I believe, two files over here.", "timestamp": "00:42:49,424", "timestamp_s": 2569.0}, {"text": "Then agent decided to switch, to go implementation of the repository.", "timestamp": "00:42:54,834", "timestamp_s": 2574.0}, {"text": "All right, so yeah, we also need to introduce this name space", "timestamp": "00:42:59,694", "timestamp_s": 2579.0}, {"text": "thingy in the go go implementation server as well as in Python.", "timestamp": "00:43:05,674", "timestamp_s": 2585.0}, {"text": "Alright.", "timestamp": "00:43:10,804", "timestamp_s": 2590.0}, {"text": "Then we also, of course as instructed the GI a and Git and this small the sort of", "timestamp": "00:43:12,334", "timestamp_s": 2592.0}, {"text": "nice feature I have here is I instructed the agent through instructions to always", "timestamp": "00:43:18,864", "timestamp_s": 2598.0}, {"text": "slack me when it is done with the task.", "timestamp": "00:43:26,154", "timestamp_s": 2606.0}, {"text": "So let\u0027s go back to our chat.", "timestamp": "00:43:30,094", "timestamp_s": 2610.0}, {"text": "And yeah, basically after the combination of agen patterns and MCB servers, it", "timestamp": "00:43:33,909", "timestamp_s": 2613.0}, {"text": "was able to basically pull the JIRA JIRA ticket and then essentially do all", "timestamp": "00:43:39,119", "timestamp_s": 2619.0}, {"text": "the all the tasks surrounding the, the typical software development steps, right?", "timestamp": "00:43:45,499", "timestamp_s": 2625.0}, {"text": "So it creates, the branch created a commit for us and so on.", "timestamp": "00:43:51,819", "timestamp_s": 2631.0}, {"text": "So basically in a matter of minute, it was able to fix fix the ticket for us.", "timestamp": "00:43:55,764", "timestamp_s": 2635.0}, {"text": "Alright.", "timestamp": "00:44:02,224", "timestamp_s": 2642.0}, {"text": "Let\u0027s switch back to the slides one more time.", "timestamp": "00:44:02,524", "timestamp_s": 2642.0}, {"text": "Okay.", "timestamp": "00:44:08,124", "timestamp_s": 2648.0}, {"text": "So yeah, and if you are wondering this is how those messages from sun Coder", "timestamp": "00:44:08,664", "timestamp_s": 2648.0}, {"text": "would look like in Slack, for example.", "timestamp": "00:44:13,464", "timestamp_s": 2653.0}, {"text": "And, every time I get those messages, it feels this meme and of course, I can", "timestamp": "00:44:15,444", "timestamp_s": 2655.0}, {"text": "instruct Theod to not message you, but your PM or whoever you wanted to message", "timestamp": "00:44:22,284", "timestamp_s": 2662.0}, {"text": "and not necessarily in Slack or, you can, through MCP, you can connect to", "timestamp": "00:44:28,344", "timestamp_s": 2668.0}, {"text": "pretty much any messaging app whatsoever.", "timestamp": "00:44:31,569", "timestamp_s": 2671.0}, {"text": "And well, of course, these sort of improvements or what you\u0027ve seen now.", "timestamp": "00:44:35,259", "timestamp_s": 2675.0}, {"text": "Probably made you think if it\u0027s time to switch switch the profession, right?", "timestamp": "00:44:41,839", "timestamp_s": 2681.0}, {"text": "Is still a good time to be a software developer?", "timestamp": "00:44:47,759", "timestamp_s": 2687.0}, {"text": "And of course there are essentially two main sides to that question to,", "timestamp": "00:44:50,759", "timestamp_s": 2690.0}, {"text": "what\u0027s coming for the developers.", "timestamp": "00:44:55,719", "timestamp_s": 2695.0}, {"text": "Of course, you can think about, ai replication and.", "timestamp": "00:44:57,729", "timestamp_s": 2697.0}, {"text": "There is also some, variability as to if you see it as a negative or a positive", "timestamp": "00:45:03,329", "timestamp_s": 2703.0}, {"text": "thing because for example, maybe you always wanted to be a goose farmer.", "timestamp": "00:45:08,529", "timestamp_s": 2708.0}, {"text": "And then once you are replaced by ai, you finally would be able to", "timestamp": "00:45:12,769", "timestamp_s": 2712.0}, {"text": "chase that long lasting dream of whatever you whatever your heart", "timestamp": "00:45:17,209", "timestamp_s": 2717.0}, {"text": "wants you, what wants you to be.", "timestamp": "00:45:22,259", "timestamp_s": 2722.0}, {"text": "Now of course.", "timestamp": "00:45:25,879", "timestamp_s": 2725.0}, {"text": "At least for now, AI is not able to train itself without the data.", "timestamp": "00:45:27,499", "timestamp_s": 2727.0}, {"text": "So there is at least one job that is safe for now.", "timestamp": "00:45:32,409", "timestamp_s": 2732.0}, {"text": "Namely writing the code for AI to train on because, still it requires a", "timestamp": "00:45:35,989", "timestamp_s": 2735.0}, {"text": "bunch of data for training, for model improvements, however jokes site even", "timestamp": "00:45:41,489", "timestamp_s": 2741.0}, {"text": "with those, all of those improvements from, on the AI side, on the gen side", "timestamp": "00:45:47,109", "timestamp_s": 2747.0}, {"text": "with things like white coding, you still hopefully need to they still need to", "timestamp": "00:45:51,819", "timestamp_s": 2751.0}, {"text": "have a good knowledge of what\u0027s going on.", "timestamp": "00:45:56,969", "timestamp_s": 2756.0}, {"text": "Especially we\u0027re talking about some mission critical systems especially", "timestamp": "00:45:59,859", "timestamp_s": 2759.0}, {"text": "about putting things into production.", "timestamp": "00:46:03,649", "timestamp_s": 2763.0}, {"text": "You still want to be able to un to be able to understand what\u0027s going on.", "timestamp": "00:46:06,949", "timestamp_s": 2766.0}, {"text": "You need to still need to be able to.", "timestamp": "00:46:10,929", "timestamp_s": 2770.0}, {"text": "Read the code or know, debug the code.", "timestamp": "00:46:13,329", "timestamp_s": 2773.0}, {"text": "So what we at Zone Coder and me personally see as a sort of upcoming future for", "timestamp": "00:46:16,269", "timestamp_s": 2776.0}, {"text": "the software development is that we as developers would become more as a managers", "timestamp": "00:46:23,529", "timestamp_s": 2783.0}, {"text": "of virtual virtual agents, virtual junior developers, if you will, and.", "timestamp": "00:46:29,589", "timestamp_s": 2789.0}, {"text": "We as humans would be more for reviewers, more managers as that", "timestamp": "00:46:36,174", "timestamp_s": 2796.0}, {"text": "rather than writing the code ourselves.", "timestamp": "00:46:40,924", "timestamp_s": 2800.0}, {"text": "So basically we would be able to offload any mundane tasks.", "timestamp": "00:46:43,014", "timestamp_s": 2803.0}, {"text": "For example writing documentation, writing new in tests, and so on to our", "timestamp": "00:46:47,544", "timestamp_s": 2807.0}, {"text": "army of virtual virtual developers.", "timestamp": "00:46:52,284", "timestamp_s": 2812.0}, {"text": "We as as people would be able to focus on more creative or more high", "timestamp": "00:46:54,804", "timestamp_s": 2814.0}, {"text": "level tasks, more architecturals architectural tasks and so on.", "timestamp": "00:46:58,644", "timestamp_s": 2818.0}, {"text": "So yeah, hopefully the future, no longer doesn\u0027t look as as dark as it did before.", "timestamp": "00:47:04,554", "timestamp_s": 2824.0}, {"text": "But of course, AI moves fast.", "timestamp": "00:47:12,504", "timestamp_s": 2832.0}, {"text": "So we\u0027ll see what will happen a few years with that.", "timestamp": "00:47:14,434", "timestamp_s": 2834.0}, {"text": "A couple cure codes for you to use.", "timestamp": "00:47:18,859", "timestamp_s": 2838.0}, {"text": "On the right is my contact details.", "timestamp": "00:47:20,959", "timestamp_s": 2840.0}, {"text": "If you want to connect on LinkedIn, if you want to follow up with any", "timestamp": "00:47:23,729", "timestamp_s": 2843.0}, {"text": "questions, feel free to message me.", "timestamp": "00:47:28,439", "timestamp_s": 2848.0}, {"text": "Feel free to send the connect request.", "timestamp": "00:47:30,719", "timestamp_s": 2850.0}, {"text": "And on the left you can see the cure code for our website for encoder ai,", "timestamp": "00:47:32,849", "timestamp_s": 2852.0}, {"text": "where you can basically sign up for free and try as, try the agents in your id.", "timestamp": "00:47:38,019", "timestamp_s": 2858.0}, {"text": "Already they end with that.", "timestamp": "00:47:44,174", "timestamp_s": 2864.0}, {"text": "Thank you for your attention.", "timestamp": "00:47:47,334", "timestamp_s": 2867.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'Pste7lY3oCI',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              AI Coding Agents and how to code them
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>AI Agents are the next big thing everyone is talking about. They are expected to revolutionize various industries by automating routine tasks, mission critical business workflows, enhancing productivity, and enabling humans to focus on creative and strategic work</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/ml2025_Alex_Shershebnev.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,750'); seek(0.0)">
              Hello everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:01,599'); seek(1.0)">
              My name is Alex.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:02,559'); seek(2.0)">
              I'm head of Ops and DevOps at Z Coder.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:05,230'); seek(5.0)">
              I also double l de and in general, what I like to call they have asked me anything.
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:10,200'); seek(10.0)">
              It's a startup, so you have to wear many hats.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:12,910'); seek(12.0)">
              Today I will be talking with you about AI coding agents how you can code
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:16,990'); seek(16.0)">
              them, how you can use them, how you can leverage them to make your everyday
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:22,180'); seek(22.0)">
              life easier and be more productive Now.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:26,695'); seek(26.0)">
              Recently you might have come across headlines like this where
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:31,315'); seek(31.0)">
              in this case, mark Zuckerberg said, mentioned in his interview that
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:35,335'); seek(35.0)">
              AI will soon replace developers.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:37,195'); seek(37.0)">
              And in this particular case, he even went as far as saying that mid-level
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:42,215'); seek(42.0)">
              engineers will be replaced pretty soon.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:45,085'); seek(45.0)">
              Now there are two main sort of sources.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:49,045'); seek(49.0)">
              For those headlines.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:50,055'); seek(50.0)">
              First of all, of course, new models.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:52,095'); seek(52.0)">
              New AI or LLM models are coming up being released.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:56,665'); seek(56.0)">
              For example here the recent release from Google of Gemini 2.5 Pro,
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:01,235'); seek(61.0)">
              and they of course show that new they are new model beats all the
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:05,485'); seek(65.0)">
              previous models on the benchmarks which is always the case, right?
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:09,575'); seek(69.0)">
              Now for us for coordin agents in particular, we are mostly interested
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:13,335'); seek(73.0)">
              in the three code related benchmarks, which I highlighted here in red.
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:18,185'); seek(78.0)">
              Now the problem with benchmarks is while it is good to see that models
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:22,595'); seek(82.0)">
              are becoming better on them it's a good way to compare models with each other.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:27,535'); seek(87.0)">
              It's all those benchmarks are not always.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:31,280'); seek(91.0)">
              Transferable one-to-one to the real world.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:34,160'); seek(94.0)">
              What I mean by that is for example, if we look at either gl the main idea behind
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:38,910'); seek(98.0)">
              this data set is that the LLM or AI is presented with a list of tasks and it
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:44,760'); seek(104.0)">
              essentially needs to create a function.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:46,320'); seek(106.0)">
              It create needs to create a class or method that would fulfill that task.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:50,910'); seek(110.0)">
              So essentially it's one or single file modification.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:54,635'); seek(114.0)">
              However reality of software development is not that simple, right?
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:59,205'); seek(119.0)">
              So usually you need to modify at least multiple files inside the
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:03,015'); seek(123.0)">
              repository, or sometimes you might even need to modify files across
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:07,695'); seek(127.0)">
              multiple repositories at the same time.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:10,335'); seek(130.0)">
              So basically, even though there are improvements in the quality of AI of LLM.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:15,885'); seek(135.0)">
              They're not always transferable one-to-one on in the real life world.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:20,525'); seek(140.0)">
              So you might not see as big of an improvement as you
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:23,935'); seek(143.0)">
              would see on the benchmarks.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:25,895'); seek(145.0)">
              So that's one source of those headlines.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:27,975'); seek(147.0)">
              And the second one is AI agents, which is the main topic
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:31,305'); seek(151.0)">
              of the day of today's stock.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:34,200'); seek(154.0)">
              So basically, we'll, we will first cover what is AI agent.
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:37,880'); seek(157.0)">
              Then we'll go through a live coding session where we'll see
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:42,230'); seek(162.0)">
              how we can, how you can create the coding agent on your own right.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:46,519'); seek(166.0)">
              And you will see how they can also interact with each other
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:49,619'); seek(169.0)">
              for multi agent collaboration.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:02:51,429'); seek(171.0)">
              And then briefly talk about what is next for the developers, what all those.
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:02:57,100'); seek(177.0)">
              New improvements, what all those new changes mean for the
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:02:59,970'); seek(179.0)">
              future of software development.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:03,239'); seek(183.0)">
              So yeah, basically by the end of the talk, we will potentially build an ai, which
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:08,640'); seek(188.0)">
              might probably replace you or maybe not.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:10,739'); seek(190.0)">
              We'll see.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:12,354'); seek(192.0)">
              So first things first let's define what is AI agent.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:16,604'); seek(196.0)">
              Now, AI agent can be defined as a software that performs tasks on behalf of a user.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:22,454'); seek(202.0)">
              And you might say here that any software performs tasks
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:26,004'); seek(206.0)">
              on behalf of the user, right?
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:27,684'); seek(207.0)">
              Especially if we're talking about current generation of coding systems.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:31,284'); seek(211.0)">
              And they essentially perform tasks of code generation on your behalf.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:35,304'); seek(215.0)">
              They perform tasks of documentation generation on your behalf.
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:38,309'); seek(218.0)">
              And, you can just essentially tap, tap tab get a thousand slice of code in a
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:42,739'); seek(222.0)">
              couple minutes, and then spend some time on the bag in that the bag in that code.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:48,549'); seek(228.0)">
              Now the main difference between AI agents and classic software is that AI
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:03:53,929'); seek(233.0)">
              agents follow multiple design patterns which you can see here on the side.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:03:57,729'); seek(237.0)">
              So first of all they have what's called tool use.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:00,609'); seek(240.0)">
              So they can basically, can have access to the tools, to the
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:04,869'); seek(244.0)">
              list of tools at a disposal.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:06,369'); seek(246.0)">
              And those tools could be pretty much anything.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:09,339'); seek(249.0)">
              It could be doing the web search, it could be accessing some local file system.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:13,889'); seek(253.0)">
              It could be accessing restful APIs and so on.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:17,379'); seek(257.0)">
              So basically any tool LLM can use to gather information to
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:21,809'); seek(261.0)">
              perform actions and so on.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:23,069'); seek(263.0)">
              It can use it.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:24,494'); seek(264.0)">
              Then of course, AI agents can also do some planning.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:27,734'); seek(267.0)">
              So they don't just blindly perform the task, perform code generation.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:31,804'); seek(271.0)">
              They can first come up with a plan on how to tackle these specific task at hand.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:37,515'); seek(277.0)">
              And they then will follow that plan.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:41,085'); seek(281.0)">
              They can also reflect on their own work, on their own planning step
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:04:45,284'); seek(285.0)">
              on their, output or they can also reflect on work of other agents.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:04:51,474'); seek(291.0)">
              And this is where we come to this fourth design pattern, which
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:04:54,394'); seek(294.0)">
              is multi-agent collaboration.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:04:56,494'); seek(296.0)">
              So basically you can have multiple agents working together towards the same goal.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:00,644'); seek(300.0)">
              And those could be either working together as in colleagues where they
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:05,794'); seek(305.0)">
              for example, one agent, performs half of the task, and then the other agent
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:09,604'); seek(309.0)">
              performs the second half of the task.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:11,464'); seek(311.0)">
              Or they can also critique each other.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:13,204'); seek(313.0)">
              So for example, you could have one agent, which critiques the work of the
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:17,404'); seek(317.0)">
              second agent, and then the second agent iterates on this critique and so on.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:23,069'); seek(323.0)">
              But basically yeah, those patterns are what differentiates AI agents from the
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:28,179'); seek(328.0)">
              typical or from the classical software.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:30,549'); seek(330.0)">
              And you can think about AI agents like a, I guess a Roomba vacuum cleaner.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:35,150'); seek(335.0)">
              The software itself on the vacuum cleaner is an AI agent, however, to perform.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:40,440'); seek(340.0)">
              To perform the task of clean the house, right?
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:05:43,260'); seek(343.0)">
              It needs also multi some things on top of that.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:05:46,710'); seek(346.0)">
              So just software is not enough.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:05:48,280'); seek(348.0)">
              The vacuum cleaners, they also have tools, so that could be brushes that
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:05:52,440'); seek(352.0)">
              could be wheels to move around and so on.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:05:55,080'); seek(355.0)">
              They can also do playing and for some reason charge GPT thinks that
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:05:59,130'); seek(359.0)">
              robot vacuum cleaners are moving this weirdly shaped pattern.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:04,030'); seek(364.0)">
              But it is AI being a AI, there is no steel yet multi agent collaboration unless
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:09,989'); seek(369.0)">
              you count these for the vacuum cleaners.
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:12,759'); seek(372.0)">
              But maybe in the future they will be able to also talk with each other.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:16,059'); seek(376.0)">
              They will be able to talk with the other home appliances and so on.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:20,019'); seek(380.0)">
              Yeah, basically now.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:23,364'); seek(383.0)">
              Why is this important?
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:24,784'); seek(384.0)">
              To answer that question, let's first talk about what we as developers spend
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:31,384'); seek(391.0)">
              our time on during the work hours.
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:34,114'); seek(394.0)">
              And I will give you a few seconds to think about this.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:36,504'); seek(396.0)">
              Spoiler alert, it's not drinking coffee in reality, and this study was
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:42,784'); seek(402.0)">
              done actually 10 years ago, however, I don't think much has changed.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:06:47,329'); seek(407.0)">
              Since then now in reality 70% of the time developers spend on understanding
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:06:53,069'); seek(413.0)">
              that could be understanding the code base, understanding
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:06:55,589'); seek(415.0)">
              the requirements understanding.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:06:57,629'); seek(417.0)">
              Tasks and so on.
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:06:58,919'); seek(418.0)">
              So basically most of the time developers are not spending on writing the code.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:03,159'); seek(423.0)">
              They are spending on understanding.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:06,049'); seek(426.0)">
              Now if we juxtapose this with the adjunct design patterns, which we
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:09,679'); seek(429.0)">
              just discussed, we will see that, for example, for the tool use.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:13,199'); seek(433.0)">
              We of course, have editing.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:14,739'); seek(434.0)">
              We need to use tools to edit the code.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:16,749'); seek(436.0)">
              We need to use tools when we are outside of ID and on Googling something and so on.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:22,079'); seek(442.0)">
              And of course for UI interactions, we also need to use tools.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:25,979'); seek(445.0)">
              Then of course for planning we need to understand the task at hand.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:30,299'); seek(450.0)">
              We need to understand the requirements.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:31,699'); seek(451.0)">
              Because otherwise it's hard to do planning of the work, right?
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:35,955'); seek(455.0)">
              There is also reflection.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:07:36,885'); seek(456.0)">
              Of course, we can, we don't just blindly.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:07:42,175'); seek(462.0)">
              Follow the requirements.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:07:43,200'); seek(463.0)">
              Don't just blindly follow the task.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:07:45,250'); seek(465.0)">
              I hope we also can think about different ways, solve the task.
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:07:51,240'); seek(471.0)">
              We can think about different ways to tackle the problem.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:07:55,060'); seek(475.0)">
              And so on.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:07:55,630'); seek(475.0)">
              And of course we don't usually work in a vacuum.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:07:59,050'); seek(479.0)">
              We have colleagues with whom we can work together, we can collaborate.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:03,190'); seek(483.0)">
              And this is where basically multi collaboration comes in.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:06,670'); seek(486.0)">
              And of course, for that follow that you'll need to have a good understanding.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:11,840'); seek(491.0)">
              You probably also need to navigate the code base.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:14,310'); seek(494.0)">
              You need to spend something outside of ID in Slack or whatever.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:17,775'); seek(497.0)">
              But basically all of the design print principles can be directly juxtaposed
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:22,535'); seek(502.0)">
              with what developers do in their free, or, sorry, not free, but of course
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:27,145'); seek(507.0)">
              what they do in their work time.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:31,055'); seek(511.0)">
              Now, with that let me switch the sides and let's finally do some coding.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:08:37,195'); seek(517.0)">
              All of the code, which I will be showing today, is available
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:08:40,315'); seek(520.0)">
              on this, repository over here.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:08:42,165'); seek(522.0)">
              I done Q code or the link below.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:08:45,555'); seek(525.0)">
              And the way I structure the coding session is I will go through several stages and
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:08:50,835'); seek(530.0)">
              hopefully not those stages but basically I will go through several stages.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:08:55,105'); seek(535.0)">
              We'll start with a simple baseline where we won't have
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:08:58,720'); seek(538.0)">
              any agenda egen patterns at all.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:02,225'); seek(542.0)">
              And then we will slowly build on top of, on top of the previous stages to come to
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:07,425'); seek(547.0)">
              the final step of multi-agent multi-agent system, which will work together to,
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:12,580'); seek(552.0)">
              to fulfill the task on our behalf.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:15,670'); seek(555.0)">
              So let me switch here to the to the Jupiter notebook I have here.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:23,215'); seek(563.0)">
              Let's see.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:26,680'); seek(566.0)">
              Alright,
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:29,920'); seek(569.0)">
              so let's start with our baseline, right?
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:32,440'); seek(572.0)">
              And if you used AI in any capacity, if you used any LLM, like open AI or
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:37,660'); seek(577.0)">
              cloudy you probably have experienced something similar to what we will
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:42,230'); seek(582.0)">
              see right now in the baseline.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:44,000'); seek(584.0)">
              But basically, and again, if you are not familiar with Python it's not a problem.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:09:49,560'); seek(589.0)">
              All of the code is pretty simple.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:09:52,080'); seek(592.0)">
              Pretty simple to it.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:09:52,860'); seek(592.0)">
              And, pretty sim pretty easy to understand.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:09:56,030'); seek(596.0)">
              Now, over here on this baseline basically what I do is I will be using the most
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:01,130'); seek(601.0)">
              recent model from Open ai, namely GT 4.1.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:05,210'); seek(605.0)">
              And basically over here, I'm just defining the code to query the model so
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:09,530'); seek(609.0)">
              that this function will send the input from us, from user to the LLM and we
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:15,350'); seek(615.0)">
              will get the response from GPT-4 0.1.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:19,330'); seek(619.0)">
              Now, the problem with the L LMS is that they are leaving the,
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:24,135'); seek(624.0)">
              somewhere in the cloud and they don't have access to real life world.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:28,015'); seek(628.0)">
              What I mean by that is for example, they can't give us the response time for
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:31,635'); seek(631.0)">
              Google or for any website for that matter.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:34,570'); seek(634.0)">
              So it does try to be helpful, and I think it probably will, yeah.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:40,090'); seek(640.0)">
              Does give us some command to run to GI to get the answer, unfortunately on its own.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:45,930'); seek(645.0)">
              The LLM in this case, GPT-4 0.1, isn't able to help.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:10:49,980'); seek(649.0)">
              The same goes with the access to local local machine.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:10:53,960'); seek(653.0)">
              This case in that it doesn't have access to my local computer.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:10:57,890'); seek(657.0)">
              Again, it does try to help me with providing some batch
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:01,380'); seek(661.0)">
              commands to, to list the packages.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:04,630'); seek(664.0)">
              Unfortunately even for those simple tasks, it can't really help me.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:09,180'); seek(669.0)">
              And, we are especially, we are going to some more sophisticated tasks that
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:14,510'); seek(674.0)">
              require, access to local to local machine.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:17,300'); seek(677.0)">
              For example, Iranian dock image.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:19,030'); seek(679.0)">
              The LLM would fail here and wouldn't be very helpful.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:22,540'); seek(682.0)">
              And the same goes within new and updated knowledge.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:26,000'); seek(686.0)">
              Now, in this case the GPT-4 0.1 has a more UpToDate knowledge.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:31,110'); seek(691.0)">
              If you try the same query with the older model, like T four O, for example,
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:36,210'); seek(696.0)">
              it wouldn't know anything at all about Python three 14 in this case.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:40,780'); seek(700.0)">
              Because the knowledge cut off for the model was, I think in June, 2024.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:45,660'); seek(705.0)">
              It does have some knowledge about Python three 14.
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:48,310'); seek(708.0)">
              And it does provide some links for us as well.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:11:51,550'); seek(711.0)">
              However still the knowledge is not up to date, right?
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:11:55,040'); seek(715.0)">
              It is 2025, my 2025 right now.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:11:58,370'); seek(718.0)">
              And basically the gap between them.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:03,160'); seek(723.0)">
              Alumni knowledge and real life world is essentially one year now and a
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:08,120'); seek(728.0)">
              lot has has happened since then.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:10,810'); seek(730.0)">
              So yeah, basically, even though it does try to be helpful by giving us command,
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:16,260'); seek(736.0)">
              by giving us answers, but based on its knowledge, it's not really that helpful in
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:21,760'); seek(741.0)">
              real life world, in real life situations.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:24,370'); seek(744.0)">
              Now let's see how we can improve on that by introducing the tool use.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:28,920'); seek(748.0)">
              To the LLM.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:31,080'); seek(751.0)">
              So let's let me switch for that for the basic to the basic agent.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:36,600'); seek(756.0)">
              Agent over here.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:39,360'); seek(759.0)">
              Alright, so I'm again using the same model GT 4.1 for that.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:44,940'); seek(764.0)">
              And what we will be using on top of that is what is called react framework.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:49,755'); seek(769.0)">
              React stands for reasonable effect and basically we will be instructing
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:53,805'); seek(773.0)">
              LLM to go through the loop of multiple stages, namely, thought,
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:58,215'); seek(778.0)">
              action, post observation, and answer.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:01,145'); seek(781.0)">
              In the third step, the LLM would need to think about what action it needs
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:05,345'); seek(785.0)">
              to perform to get the answer or to get the information to give us answer.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:10,515'); seek(790.0)">
              Then it needs to decide on the action itself basically.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:15,570'); seek(795.0)">
              As a response to our request, it will need to send the actual action.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:19,450'); seek(799.0)">
              It wants to perform with some, along with some inputs potentially.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:23,230'); seek(803.0)">
              Then there is a post step where basically the action should run on behalf of LLM.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:29,940'); seek(809.0)">
              Then during the observation step, the output from the action
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:33,840'); seek(813.0)">
              will be sent to LLM and then.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:37,540'); seek(817.0)">
              Based on this observation and the initial input from the user the LLM hopefully
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:42,480'); seek(822.0)">
              will come up with a, with an answer.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:44,880'); seek(824.0)">
              Or if that information is not enough, it'll go to the second loop,
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:49,690'); seek(829.0)">
              to the third loop and so on until it gets asked the answer or until
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:54,740'); seek(834.0)">
              it runs out of low penetrations.
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:57,500'); seek(837.0)">
              And this can pretty easily be implemented through this.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:01,415'); seek(841.0)">
              System prompt over here, and basically I'm instructing a LLM to do, to follow
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:08,645'); seek(848.0)">
              the same the, to follow the loop of react framework, which I just described, right?
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:13,265'); seek(853.0)">
              So you run in a loop of thought action post observation.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:16,910'); seek(856.0)">
              I use thought, I use action.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:19,340'); seek(859.0)">
              And then we also provide a few actions available for
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:23,255'); seek(863.0)">
              LLM to use or to choose from.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:25,790'); seek(865.0)">
              In this case, those would be Ping.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:27,830'); seek(867.0)">
              So basically that would perform the ping command.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:30,990'); seek(870.0)">
              On behalf of LLM, we have bh which would allow LLM to use any,
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:36,940'); seek(876.0)">
              to execute any batch commands.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:39,415'); seek(879.0)">
              And we will have web search pretty basic web search which will
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:42,925'); seek(882.0)">
              allow LLM to well do web search.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:47,045'); seek(887.0)">
              We also have some example session over here for LLM to use as a reference.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:52,125'); seek(892.0)">
              So for example here, the question from the user could be how many
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:55,905'); seek(895.0)">
              islands make up Madera Ali Madera.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:58,255'); seek(898.0)">
              So it's a sort of nice, nice small Easter egg for that.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:01,655'); seek(901.0)">
              And then the thought from LLM should hopefully be that it needs
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:05,615'); seek(905.0)">
              to do a web search for the madada.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:08,265'); seek(908.0)">
              Then it would need to perform to, to reply with an action namely web search,
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:14,125'); seek(914.0)">
              and then the input for that action.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:16,505'); seek(916.0)">
              In this case that could be just Madeira.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:19,265'); seek(919.0)">
              Then during the post, the actual web search will happen.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:22,375'); seek(922.0)">
              And then based on the web search.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:24,545'); seek(924.0)">
              Based on the observation from that web search the LLM should
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:28,235'); seek(928.0)">
              hopefully come up with an answer.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:30,005'); seek(930.0)">
              In this case that would be four islands.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:33,555'); seek(933.0)">
              We are using the same code to query the LLM, we'll just directly send
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:39,135'); seek(939.0)">
              the input from from us, from the user, along with the pro, with the
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:43,605'); seek(943.0)">
              system prompt we've seen above.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:47,040'); seek(947.0)">
              And then let's also define our three actions, three
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:50,190'); seek(950.0)">
              commands to perform actions.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:52,000'); seek(952.0)">
              Name the ping bash and web search.
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:55,000'); seek(955.0)">
              Let's test them out.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:15:56,650'); seek(956.0)">
              And ping for google.com.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:15:59,340'); seek(959.0)">
              Resource 200 milliseconds.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:01,150'); seek(961.0)">
              I do indeed have Python, three point 12.6 installed locally and for the web
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:06,910'); seek(966.0)">
              search for Python three 14 it gave us a lot of information from the website.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:15,140'); seek(975.0)">
              So this seems to be working fine now, let's compile this in the dictionary
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:20,430'); seek(980.0)">
              just to make it more easily accessible.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:23,030'); seek(983.0)">
              And then the main implementation of react framework happens basically in
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:27,310'); seek(987.0)">
              these, and these function over here where we are going through the react loop
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:32,290'); seek(992.0)">
              we start with the sending the, is the query of the digital query to the model.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:37,620'); seek(997.0)">
              Then based on the output from the model, we check if there is any action
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:42,400'); seek(1002.0)">
              that model decided to perform, which will be, signified by these actions.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:47,135'); seek(1007.0)">
              Semicolon prefix of the string.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:50,025'); seek(1010.0)">
              And if there is an action we get the list of actions.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:53,625'); seek(1013.0)">
              We perform that action and give the result of running that action to the
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:58,315'); seek(1018.0)">
              LLM to hopefully give us the answer.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:01,415'); seek(1021.0)">
              And then of course, if it's, if that information is not enough,
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:05,215'); seek(1025.0)">
              we will go to the second loop.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:06,625'); seek(1026.0)">
              To the third loop, and so on.
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:09,715'); seek(1029.0)">
              Now let's try pretty much the same, the same prompts, the same questions
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:14,065'); seek(1034.0)">
              we had before in the baseline, but now with these basic agent behavior.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:20,585'); seek(1040.0)">
              So let's first try to get the response time for Google, in this case it, the A
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:25,235'); seek(1045.0)">
              lamp decided to perform Action Ping for google.com which is a correct action.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:30,855'); seek(1050.0)">
              It got the answer from the action, and then as an answer to our
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:36,195'); seek(1056.0)">
              initial question, it gave us.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:38,175'); seek(1058.0)">
              The rounded number of milliseconds or seconds for the pink the same should
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:44,045'); seek(1064.0)">
              work with the Python packages, right?
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:46,295'); seek(1066.0)">
              So we decided to perform the action batch with the input of P list
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:51,465'); seek(1071.0)">
              which gave the alarm a bunch of packages I have installed locally.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:57,375'); seek(1077.0)">
              And then based on that the answer from LLM was, I guess sort of summary
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:02,735'); seek(1082.0)">
              of, of those Python packages which have installed locally showing a
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:06,545'); seek(1086.0)">
              presentative sample apparently.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:08,645'); seek(1088.0)">
              All right.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:08,945'); seek(1088.0)">
              And this, let's see what will happen with the, our Python three 14 question.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:14,155'); seek(1094.0)">
              So the action that Ellan decided to perform is a web search,
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:17,845'); seek(1097.0)">
              which makes sense, right?
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:19,395'); seek(1099.0)">
              It's pretty much the actual question of ours was new by three 14.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:25,015'); seek(1105.0)">
              It got to the.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:27,220'); seek(1107.0)">
              Logical website from python.org with a bunch of information and somewhere below.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:33,940'); seek(1113.0)">
              Let me scroll all the way down, somewhere below it should give us the answer based
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:40,600'); seek(1120.0)">
              on the observation from that action.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:43,150'); seek(1123.0)">
              Namely over here.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:45,505'); seek(1125.0)">
              It, it summarized some new features changes in Python three 14, a few
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:50,895'); seek(1130.0)">
              PEPs, a few new features some changes.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:54,775'); seek(1134.0)">
              So basically with just a single system prompt like this.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:00,810'); seek(1140.0)">
              We already are able to significantly extend the capabilities of LLM beyond
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:06,570'); seek(1146.0)">
              it just being a sort of knowledge base.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:09,420'); seek(1149.0)">
              We else, it, it now has access to web, it now has access to our local machine.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:14,810'); seek(1154.0)">
              It now has access to batch commands, right?
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:17,810'); seek(1157.0)">
              So basically it already can be much more helpful.
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:22,925'); seek(1162.0)">
              For us was in everyday life and in our coding coding journey.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:28,115'); seek(1168.0)">
              But of course it wouldn't be very convenient to.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:31,990'); seek(1171.0)">
              Modify this prompt every time we need to add new action.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:35,440'); seek(1175.0)">
              And there could be a lot of different actions depending on what tool
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:38,770'); seek(1178.0)">
              you want LLM to be able to use.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:41,260'); seek(1181.0)">
              Like for example, if you think about Git right?
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:43,790'); seek(1183.0)">
              The Git itself has a bunch of different commands like Git commit,
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:47,900'); seek(1187.0)">
              Git checkout, Git branch, and so on.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:50,240'); seek(1190.0)">
              So you would potentially need to define each.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:53,990'); seek(1193.0)">
              Single git command as a set protection, and that probably
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:57,920'); seek(1197.0)">
              would take quite a long time.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:59,840'); seek(1199.0)">
              Now, ho fortunately for us, there are ways to abstract all these tool definitions
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:20:06,630'); seek(1206.0)">
              from us, from the end user, and one of those, one of these ways is MCP.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:20:13,420'); seek(1213.0)">
              So let me go back to the slides real quick over here.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:20:18,905'); seek(1218.0)">
              Let's see.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:20:20,165'); seek(1220.0)">
              So MCP stands for Model Context Protocol, and it was introduced
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:25,445'); seek(1225.0)">
              pretty recently and the end of November last year two four by Tropic.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:31,095'); seek(1231.0)">
              So essentially MCP is a protocol based on JSON RPC, which, which aims to facilitate.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:38,975'); seek(1238.0)">
              The tool use and the development of those tools, it consists of two main
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:43,625'); seek(1243.0)">
              counterparts, MCP server and MCP host, and MCP client, and now MCP client could
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:49,575'); seek(1249.0)">
              be our LLM, it could be some id, it could be any AI enabled tool, basically.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:57,355'); seek(1257.0)">
              And then MCP server performs essentially two main functions.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:02,295'); seek(1262.0)">
              First, it, of course, interacts with the, with the actual tool
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:05,865'); seek(1265.0)">
              performs the actual actions, right?
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:07,305'); seek(1267.0)">
              So it could access some local sources.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:09,965'); seek(1269.0)">
              It could be MCP server for the file system, so it could manipulate files,
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:21:13,565'); seek(1273.0)">
              for example, it could also be MCP server that performs some a p requests.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:21:18,485'); seek(1278.0)">
              So it could be MCP server, which provides tools to access Jira, for example.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:21:25,325'); seek(1285.0)">
              Or it could be tools to access.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:21:28,965'); seek(1288.0)">
              Flight radar, right?
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:21:29,985'); seek(1289.0)">
              So basically any anything that can be coded to be accessed through
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:21:34,205'); seek(1294.0)">
              code can be converted to MCP server.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:21:37,215'); seek(1297.0)">
              And then through MCP Protocol, the LLM can get the list of tools,
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:41,805'); seek(1301.0)">
              can get any names, different descriptions, and how to use them.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:45,765'); seek(1305.0)">
              And then again, through MCP protocol, it would send essentially the request
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:50,955'); seek(1310.0)">
              to perform the action to the MCP server, and then it would get the
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:54,705'); seek(1314.0)">
              response, from NCP server with the result of running that ac that action
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:58,995'); seek(1318.0)">
              or the result of running that tool.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:01,930'); seek(1321.0)">
              And it is pretty straightforward to run to create your own NCP servers.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:07,050'); seek(1327.0)">
              Let me switch back to our notebook over here, and let's go now to
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:14,980'); seek(1334.0)">
              the agent with MCP directory.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:17,740'); seek(1337.0)">
              So first, let's see how we can implement our own MCP server.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:22:22,060'); seek(1342.0)">
              And you can do that in multiple languages.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:22:24,130'); seek(1344.0)">
              I think currently there are SDKs of Python, JavaScript, Java
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:22:29,870'); seek(1349.0)">
              and Lin, if I'm not mistaken.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:22:31,890'); seek(1351.0)">
              But essentially, of course, I'm sure that more languages will follow, but
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:22:36,620'); seek(1356.0)">
              basically over here we have the two MCP two or MCP server defined in Python
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:22:42,490'); seek(1362.0)">
              and Tropic provided a nice, fast MCP class or from the MCP framework, which
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:22:49,760'); seek(1369.0)">
              basically requires us to essentially just do essentially the server itself.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:54,720'); seek(1374.0)">
              And then through this, the curator, we can convert any function into an MCP tool.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:59,850'); seek(1379.0)">
              So in this case, that would be a bar tool which will perform any
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:03,490'); seek(1383.0)">
              we will execute any batch command.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:06,905'); seek(1386.0)">
              For us, and of course you, ideally, you don't want to
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:09,155'); seek(1389.0)">
              execute blindly any b command.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:11,835'); seek(1391.0)">
              But for the sake of the, for the presentation we we will allow that.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:18,195'); seek(1398.0)">
              But basically those three lines is the only thing, things that you would need
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:22,355'); seek(1402.0)">
              this in Python to create a bar Oh, sorry.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:23:24,975'); seek(1404.0)">
              To create an MCP server for yourself.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:23:28,370'); seek(1408.0)">
              And as I said, anything that you can code can essentially
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:23:31,680'); seek(1411.0)">
              be converted to MCP server.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:23:35,160'); seek(1415.0)">
              Now, along with that, we also would require a sort of description of how
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:23:41,460'); seek(1421.0)">
              to call that server, that MCP server.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:23:44,340'); seek(1424.0)">
              And over here I have a. Small JSON file, which defines the MCP servers.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:23:50,225'); seek(1430.0)">
              In this case, the only MCP server is called B and it is run as
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:23:55,325'); seek(1435.0)">
              python command, right with the arcs of just name of the file.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:23:59,975'); seek(1439.0)">
              'cause it's essentially by Python script.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:02,155'); seek(1442.0)">
              So that's the only two things that needs that it needs to be executed.
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:07,285'); seek(1447.0)">
              But we'll see later different ways.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:09,325'); seek(1449.0)">
              Beyond just Python script that you can execute MCP servers as.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:14,665'); seek(1454.0)">
              So let's now see how we can use those MCP servers along with LLM.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:21,965'); seek(1461.0)">
              So for that first of all, we will switch to tropic.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:25,045'); seek(1465.0)">
              In this case it would be cloud D 3.7, I believe.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:24:28,535'); seek(1468.0)">
              Yep, it's cloud D 3.7.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:24:31,245'); seek(1471.0)">
              The reason for this switch.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:24:33,920'); seek(1473.0)">
              Is initially tropic tropics Cloud was more was better at using tools.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:24:39,860'); seek(1479.0)">
              However, now you might have heard that even OpenAI adopted the MCP
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:24:44,630'); seek(1484.0)">
              protocol from the arrivals, basically.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:24:47,250'); seek(1487.0)">
              So the recent models are also pretty good with following, with
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:24:52,000'); seek(1492.0)">
              using tools defined as MCP servers.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:24:54,550'); seek(1494.0)">
              But still here we'll be using, tropics called 3.7.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:24:58,970'); seek(1498.0)">
              Now, what we essentially need to use the CP tools is we will need an MCB client.
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:06,170'); seek(1506.0)">
              And in this case the main functions or methods of this class is, first
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:11,410'); seek(1511.0)">
              of all, we need of course to connect to servers to get the list of tools
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:16,020'); seek(1516.0)">
              available for us to use no for LLM to use.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:19,860'); seek(1519.0)">
              These function is essentially responsible for that.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:23,030'); seek(1523.0)">
              So we just connect to each server in the loop, in the server config, and then
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:29,260'); seek(1529.0)">
              get a list of tools from that server.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:25:32,960'); seek(1532.0)">
              And then we also need to of course, send the request to LLM and then act
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:25:39,730'); seek(1539.0)">
              accordingly to the response from LLM.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:25:42,460'); seek(1542.0)">
              So basically we attach the list of tools.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:25:47,125'); seek(1547.0)">
              I got from MCP servers in the format of tool name, tool description, and
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:25:51,395'); seek(1551.0)">
              tool input schema, along with our, user input message, and those things are
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:25:57,105'); seek(1557.0)">
              sent directly to CLA 3.7 in this case.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:01,035'); seek(1561.0)">
              And then the clo, the LLM, decides if it wants to just respond as
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:05,995'); seek(1565.0)">
              a plain text or if it wants to perform an action or a tool use.
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:10,715'); seek(1570.0)">
              And this is how we basically differentiate between.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:14,650'); seek(1574.0)">
              Between those as part of the response that would be a content type.
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:18,520'); seek(1578.0)">
              It could be either text or a tool use in, and in the case of tool use, we will
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:23,080'); seek(1583.0)">
              see what kind of tool it wants to use.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:25,380'); seek(1585.0)">
              So that will basically tool name and then what kind of input arguments, it needs to
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:30,190'); seek(1590.0)">
              be we need to pass to that to that tool.
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:33,190'); seek(1593.0)">
              Then we will perform that actual tool call over here.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:37,300'); seek(1597.0)">
              And then we'll send the result of that tool call back to LLM, and then hopefully
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:26:44,300'); seek(1604.0)">
              we will get an answer to our question.
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:26:47,860'); seek(1607.0)">
              And then here I have a small, a nice small chat loop.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:26:52,700'); seek(1612.0)">
              Where basically we will send the we will send the query into the into
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:26:55,970'); seek(1615.0)">
              the text field, and then proceed with this chat until we type the qui word.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:01,920'); seek(1621.0)">
              So let's start with our, just with our bar tool over here.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:07,020'); seek(1627.0)">
              We got connected to the, to our server which was run as
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:10,810'); seek(1630.0)">
              Python Bar tool, fast speed pi.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:13,810'); seek(1633.0)">
              We have one single tool called Barge.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:17,020'); seek(1637.0)">
              And let's ask LLM to do something.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:19,700'); seek(1639.0)">
              Let's say list all files and let's see what will come up with.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:27,290'); seek(1647.0)">
              So in this case, he decided to call the B command, the Bash two with
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:27:31,990'); seek(1651.0)">
              a comment with a. With the comment LS dash la, which makes sense.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:27:36,720'); seek(1656.0)">
              It got the list of files and basically summarized them all.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:42,210'); seek(1662.0)">
              Good.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:43,560'); seek(1663.0)">
              Now let's see how we can extend these two multiple servers to multiple tools.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:27:48,400'); seek(1668.0)">
              And for that we will use the full J confi over here.
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:27:53,110'); seek(1673.0)">
              Which basically defines four MCP servers.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:27:56,590'); seek(1676.0)">
              First of all, we have a file system, MCP server, which is essentially
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:28:00,910'); seek(1680.0)">
              an NPM package which runs with few inputs, see few arguments.
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:28:05,900'); seek(1685.0)">
              We also have a web search realized through Brave web search, and
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:28:10,040'); seek(1690.0)">
              that is run as docker image.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:12,725'); seek(1692.0)">
              So here we have some end file for the tokens.
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:15,895'); seek(1695.0)">
              We also have a fe, a web server, which would allow LLM to fetch any URL from the
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:21,245'); seek(1701.0)">
              web, is implemented as Python package.
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:28:24,585'); seek(1704.0)">
              And then of course we have our Bash MCP server, which we just
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:28:28,025'); seek(1708.0)">
              defined couple seconds ago.
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:28:30,935'); seek(1710.0)">
              So you can see, cP servers can come in all flavors and
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:34,395'); seek(1714.0)">
              languages and ways to run them.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:37,665'); seek(1717.0)">
              Now, let's see let's not give those servers to our LLM and let's ask
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:45,145'); seek(1725.0)">
              to perform some actions, right?
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:47,115'); seek(1727.0)">
              First of all, let's see what's new in Python.
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:28:50,635'); seek(1730.0)">
              Three 14.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:28:52,415'); seek(1732.0)">
              So let's see if it'll need to perform a web search to give us the answer.
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:28:57,735'); seek(1737.0)">
              All right, so it decided to call the web search tool with the
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:29:01,695'); seek(1741.0)">
              following query, Python three 14 new features through release notes.
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:29:05,520'); seek(1745.0)">
              The unlike OpenAI GT 4.1, it didn't just copy the questions from us and then based
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:29:12,040'); seek(1752.0)">
              on the response from the web search tool, it gave us the summary of new features.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:17,900'); seek(1757.0)">
              Let's also try to ask cla to create a file called Hello the text with the content.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:29,240'); seek(1769.0)">
              Hello world.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:31,040'); seek(1771.0)">
              Alright.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:29:33,560'); seek(1773.0)">
              Let's see.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:29:34,310'); seek(1774.0)">
              So hopefully it'll be able to access our local file system.
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:29:38,620'); seek(1778.0)">
              So in this case, we decided to use the tool right file
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:42,040'); seek(1782.0)">
              with the following arguments.
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:43,630'); seek(1783.0)">
              And let's actually see, yeah, we just got the new file.
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:47,670'); seek(1787.0)">
              We on our local file system called as Requested, hello to 60 with the content.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:53,970'); seek(1793.0)">
              Hello World.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:55,785'); seek(1795.0)">
              Great.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:29:56,475'); seek(1796.0)">
              So essentially with just a few lines of code of basically the JSON config
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:30:02,855'); seek(1802.0)">
              of MCP servers, we, again extended the capabilities of LLM beyond just
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:30:08,515'); seek(1808.0)">
              being able to answer questions based on its on what is seen in the tearing
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:30:13,055'); seek(1813.0)">
              data, it is now also able to perform.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:16,375'); seek(1816.0)">
              A lot of different actions and those MCP server can come in different flavors.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:22,275'); seek(1822.0)">
              And there are actually a lot of different sources where you
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:26,625'); seek(1826.0)">
              can find M CCP servers online.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:28,755'); seek(1828.0)">
              There are MCP registries, which contains hundreds of different M
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:30:32,985'); seek(1832.0)">
              CCP servers for tools like, for example, Grafana JIRA and so on.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:30:36,555'); seek(1836.0)">
              So basically you can, give a lamb access to any tools you use in your
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:30:42,195'); seek(1842.0)">
              everyday every everyday working life.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:45,235'); seek(1845.0)">
              And basically, as we will see later, ask it to, for example, solve the ticket.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:52,795'); seek(1852.0)">
              Now let's let me quickly jump back to the slides for a few more seconds.
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:31:01,685'); seek(1861.0)">
              All right, so we've seen MCP.
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:31:03,665'); seek(1863.0)">
              Now let's see how we can make agents work with each other because of course,
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:31:10,105'); seek(1870.0)">
              before, before that, we, all the tools we had, oh, LLM had at this disposal
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:31:15,115'); seek(1875.0)">
              were essentially just a software, right?
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:31:17,675'); seek(1877.0)">
              There was just API calls, it was just file system manipulations and so on.
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:31:21,925'); seek(1881.0)">
              However, you can imagine those tools being agents on their own.
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:31:26,655'); seek(1886.0)">
              And then one agent could potentially call another agent to delegate a task
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:31,735'); seek(1891.0)">
              to ask it, to ask a subordinate agent to perform some small subtask and so on.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:37,115'); seek(1897.0)">
              And in our case, we will be building a system which contains four
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:42,175'); seek(1902.0)">
              agents and it will be hierarchical.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:45,525'); seek(1905.0)">
              Hierarchical system where, we'll, where we will have supervisor,
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:31:48,675'); seek(1908.0)">
              agent which you can think about as product manager, for example.
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:52,475'); seek(1912.0)">
              And this agent will be able to call three other agents subordinate agents.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:58,035'); seek(1918.0)">
              And those would be frontend developer virtual frontend developer.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:32:02,174'); seek(1922.0)">
              Virtual backend developer and virtual DevOps engineer.
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:32:05,114'); seek(1925.0)">
              And they also would be able to interact with us with the client to
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:32:09,414'); seek(1929.0)">
              ask for any clarification if needed.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:32:12,124'); seek(1932.0)">
              But generally all of the manipulation of the all of the.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:32:16,865'); seek(1936.0)">
              Interactions between those subordinate agents should happen
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:32:19,904'); seek(1939.0)">
              through a supervisor agent.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:32:21,444'); seek(1941.0)">
              There is no direct connection from one subordinate agent to another.
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:32:25,935'); seek(1945.0)">
              However, of course, you can also implement this where where in the system potentially
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:30,714'); seek(1950.0)">
              all agents would be able to talk with each other directly, not through the
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:34,854'); seek(1954.0)">
              supervisor agent, it would really depend on what you want the system to work to do.
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:41,484'); seek(1961.0)">
              Now let me switch back again to our Jupyter Notebook.
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:32:47,314'); seek(1967.0)">
              Alright,
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:32:49,924'); seek(1969.0)">
              and let's go to the final notebook of the day, which is multi-agent.
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:55,924'); seek(1975.0)">
              Notebook.
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:56,704'); seek(1976.0)">
              Now here I will be adding one more level of abstraction and memory,
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:33:01,264'); seek(1981.0)">
              link chain and glowing graph.
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:33:03,004'); seek(1983.0)">
              And the reason for that is of course you can implement all of
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:33:06,704'); seek(1986.0)">
              the agent, all of the cross agent collaborate interactions on your own.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:33:11,934'); seek(1991.0)">
              It is essentially.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:33:14,409'); seek(1994.0)">
              Just the structured inputs and outputs and then some state
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:33:18,489'); seek(1998.0)">
              manipulations on top of that.
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:33:20,439'); seek(2000.0)">
              Why spend time on that when you can use the frameworks which
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:33:24,839'); seek(2004.0)">
              do that for you basically.
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:33:26,939'); seek(2006.0)">
              So again, we will use the same quality 3.7 here and.
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:33:32,414'); seek(2012.0)">
              Give it three, or, sorry, four four tools.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:33:36,664'); seek(2016.0)">
              Pretty much the same tools which we've seen before.
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:33:38,974'); seek(2018.0)">
              Shell tool for the batch commands, we will, it'll also
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:33:42,144'); seek(2022.0)">
              have access to brave search.
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:43,524'); seek(2023.0)">
              Again, as we've seen before.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:45,504'); seek(2025.0)">
              It'll also have access to file file system manipulation.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:49,064'); seek(2029.0)">
              And there is also one more new tool which I called Human, which
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:54,304'); seek(2034.0)">
              basically would allow LLM to ask back questions to the human.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:34:00,674'); seek(2040.0)">
              And then we at the are discussed on the site.
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:34:03,464'); seek(2043.0)">
              We will, we'll create four agents.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:34:06,374'); seek(2046.0)">
              First, we'll create agent supervisor, which will have access to three team
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:34:12,884'); seek(2052.0)">
              members, namely frontend developer, backend developer and ops engineer, and
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:34:17,384'); seek(2057.0)">
              the system run the split straightforward.
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:34:19,944'); seek(2059.0)">
              We are telling the agent that it is a supervisor overseeing the following
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:34:24,024'); seek(2064.0)">
              three workers, and it basically needs to decide who's who is the
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:34:29,514'); seek(2069.0)">
              next agent responsible to, for, to perform the task or to act next.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:34:36,144'); seek(2076.0)">
              And then once the supervisor agent is happy with the result, it should
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:34:40,134'); seek(2080.0)">
              respond with a keyword finish.
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:34:42,414'); seek(2082.0)">
              Basically, we will give access to all the tools, all the available
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:34:47,604'); seek(2087.0)">
              tools to these agents as well.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:34:49,374'); seek(2089.0)">
              However in real life potentially you probably would want agents to have access
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:34:55,254'); seek(2095.0)">
              to different lists of tools, right?
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:56,544'); seek(2096.0)">
              For example, you might have DevOps engineer, virtual DevOps engineer.
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:35:00,494'); seek(2100.0)">
              Being able to access tools like Ana or Promeus or Datadog or whatever, right?
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:35:07,514'); seek(2107.0)">
              But at the same time, you don't want, probably, you probably don't need front,
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:35:10,984'); seek(2110.0)">
              end agent to be able to access that.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:35:14,584'); seek(2114.0)">
              But on the other hand, it needs to have access to other
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:35:17,104'); seek(2117.0)">
              tools like Figma, for example.
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:35:19,984'); seek(2119.0)">
              So the only things we basically need to create our supervisor agent is
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:35:26,354'); seek(2126.0)">
              this piece of code over here where we define what what sort of nodes or what
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:35:31,384'); seek(2131.0)">
              sort of hand off notes are available for these supervisor nodes to call.
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:35:37,054'); seek(2137.0)">
              And those are again, our team members.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:35:39,274'); seek(2139.0)">
              And then of course, end node to finish the tasks.
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:35:42,829'); seek(2142.0)">
              With that, let's also define our three agents, namely front end agent
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:35:48,209'); seek(2148.0)">
              backend agent, and DevOps agent.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:35:51,019'); seek(2151.0)">
              As you can see here, we are using pretty much the same React framework.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:35:55,384'); seek(2155.0)">
              As we've seen before, and again, we are passing all the tools, all of
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:35:59,674'); seek(2159.0)">
              the available tools to those agents, and the prompts are pretty simple.
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:36:03,774'); seek(2163.0)">
              Although in real life world, of course, you probably would want
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:36:06,054'); seek(2166.0)">
              to be more creative or be more specific with those prompts.
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:36:10,604'); seek(2170.0)">
              But in our case, we are just defining the frontend agent as a frontend developer.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:36:17,314'); seek(2177.0)">
              And this agent can also ask.
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:36:20,274'); seek(2180.0)">
              Help ask for help from backend developer or DevOps engineer.
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:36:24,144'); seek(2184.0)">
              And it can also ask for clarifications from the human client.
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:36:27,574'); seek(2187.0)">
              The same goes with a backend backend agent.
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:36:30,744'); seek(2190.0)">
              It can help, can ask for help from front end or DevOps
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:36:34,554'); seek(2194.0)">
              engineer, and it can also ask for clarifications from the human client.
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:36:39,444'); seek(2199.0)">
              And the same goes with a DevOps agent.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:36:41,894'); seek(2201.0)">
              It can also.
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:36:43,454'); seek(2203.0)">
              Call, ask help for front end or backend developers and ask
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:36:47,684'); seek(2207.0)">
              for clarifications from human.
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:36:50,244'); seek(2210.0)">
              All of those agents or nodes in the terms of land graph are defined
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:36:55,924'); seek(2215.0)">
              in a pretty three forward manner through these comment over here.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:37:01,234'); seek(2221.0)">
              And that's pretty much all we need to do.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:37:05,599'); seek(2225.0)">
              To define those agents.
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:37:07,309'); seek(2227.0)">
              Now, with that, let's also build a graph and let's also visualize that graph.
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:37:12,589'); seek(2232.0)">
              So indeed, as we've seen before, we have the supervisor note or supervisor
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:37:17,659'); seek(2237.0)">
              agent which can talk directly with our front end backend and DevOps engineers.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:37:23,609'); seek(2243.0)">
              But subordinate agents can talk to each other.
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:37:25,899'); seek(2245.0)">
              They only can talk through supervisor.
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:37:29,439'); seek(2249.0)">
              Over here I have just a small help helper, now helper function
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:37:34,039'); seek(2254.0)">
              to color the output as we see.
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:37:36,459'); seek(2256.0)">
              That's what we'll see in a few seconds, so I won't go over that piece of code.
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:37:42,139'); seek(2262.0)">
              And then the task for the, for our multi-agent system would be to
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:37:47,339'); seek(2267.0)">
              create a website for the conference.
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:37:49,049'); seek(2269.0)">
              It needs to have three pages.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:37:51,929'); seek(2271.0)">
              Namely intro intro page page for people to submit it.
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:37:55,169'); seek(2275.0)">
              There, the docs and page with the submitted docs.
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:37:58,619'); seek(2278.0)">
              I want the front end in React.
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:38:00,709'); seek(2280.0)">
              I want a backend test, API and the submissions should be
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:38:04,759'); seek(2284.0)">
              stored in Postgres database.
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:38:07,239'); seek(2287.0)">
              And also, it's always as have Docker and Docker compose.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:38:10,039'); seek(2290.0)">
              So I also ask for that.
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:38:11,779'); seek(2291.0)">
              And then we also mention that they can ask the human client for any clarifications.
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:38:17,569'); seek(2297.0)">
              This part over here is basically all what is needed to initiate the
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:38:23,529'); seek(2303.0)">
              execution of our multi-agent system.
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:38:25,899'); seek(2305.0)">
              So I actually started and see what will come up with first.
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:38:30,699'); seek(2310.0)">
              Indeed we went into supervisor, which decided to call the front
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:38:34,089'); seek(2314.0)">
              frontend developer the frontend developer itself decided to check
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:38:39,939'); seek(2319.0)">
              what kind of tools it has installed.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:38:42,559'); seek(2322.0)">
              On the system.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:38:43,789'); seek(2323.0)">
              I got the answer and then it went ahead to check the versions the version.
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:38:51,529'); seek(2331.0)">
              Alright, it decided to create a conference website directory.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:38:54,709'); seek(2334.0)">
              So here.
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:38:55,699'); seek(2335.0)">
              So we already should be able to see some changes reflected locally.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:39:00,449'); seek(2340.0)">
              Indeed.
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:39:00,839'); seek(2340.0)">
              We have a few directors already.
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:39:03,959'); seek(2343.0)">
              We have the package on, so probably it is, yeah, it is doing.
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:39:08,419'); seek(2348.0)">
              N-P-N-P-X command, which will potentially take some time because, the n payment
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:39:14,739'); seek(2354.0)">
              style usually takes a few minutes.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:39:17,139'); seek(2357.0)">
              We, yeah, we can see the non models appearing for us with a bunch of packages.
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:39:23,289'); seek(2363.0)">
              All right, let's okay, let's go back and we already starting to see some of
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:39:27,999'); seek(2367.0)">
              the code popping up over here, right?
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:39:30,379'); seek(2370.0)">
              Some CSS, some TypeScript code.
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:39:32,849'); seek(2372.0)">
              Let me.
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:39:33,989'); seek(2373.0)">
              Scroll scroll down here.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:39:37,539'); seek(2377.0)">
              So it did install some packages and it started to implement the code over here.
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:39:43,569'); seek(2383.0)">
              So it started with the Python.
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:39:46,269'); seek(2386.0)">
              Alright.
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:39:47,379'); seek(2387.0)">
              Yeah.
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:39:47,619'); seek(2387.0)">
              Basically it'll proceed to implement the website for us on our behalf.
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:39:53,029'); seek(2393.0)">
              Now let me switch back again to the slides.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:39:59,529'); seek(2399.0)">
              All right.
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:40:02,859'); seek(2402.0)">
              All right.
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:40:03,219'); seek(2403.0)">
              But it is always nice to, fiddle around with the code with the
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:40:07,229'); seek(2407.0)">
              agents, with the L lms and see what you can build on your own.
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:40:11,499'); seek(2411.0)">
              Of course you don't always have time and still you probably would want to be able
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:40:17,099'); seek(2417.0)">
              to use, those agents be able to have those agents help you with your everyday tasks.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:40:22,924'); seek(2422.0)">
              And of course there is a way for you to have them help you with your coding.
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:40:28,264'); seek(2428.0)">
              Coding tasks, basically.
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:40:30,044'); seek(2430.0)">
              With that, let me briefly introduce briefly talk about what we do at Z Coder.
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:40:34,894'); seek(2434.0)">
              Z Coder basically is just a plugin for V Code of Brains, and this
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:40:39,244'); seek(2439.0)">
              plugin brings you brings the agents to you, to your id natively.
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:40:44,354'); seek(2444.0)">
              You don't need to switch to any other id outside of what you are already using.
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:40:49,294'); seek(2449.0)">
              And let me briefly show showcase.
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:40:52,374'); seek(2452.0)">
              Our agent basically solving the Jira task.
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:40:55,714'); seek(2455.0)">
              Let me switch to this code over here.
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:41:00,134'); seek(2460.0)">
              Alright,
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:41:03,374'); seek(2463.0)">
              so our agent, our z coder is already natively integrated in the J So we
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:41:10,929'); seek(2470.0)">
              have this encoder test over here.
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:41:13,149'); seek(2473.0)">
              So basically we can tag any ticket from the j.
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:41:19,079'); seek(2479.0)">
              I think that's the wrong the wrong account.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:41:21,844'); seek(2481.0)">
              Alright,
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:41:24,904'); seek(2484.0)">
              base.
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:41:25,564'); seek(2485.0)">
              Let's see.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:41:26,164'); seek(2486.0)">
              Alright, so let's ask our agent to solve this ticket.
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:41:30,074'); seek(2490.0)">
              Solve it create a branch called 42.
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:41:36,354'); seek(2496.0)">
              Check out and commit changes.
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:41:41,829'); seek(2501.0)">
              All right.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:41:42,339'); seek(2502.0)">
              So the ticket itself basically requires the agent to implement
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:41:46,439'); seek(2506.0)">
              changes across multiple languages across the whole repository.
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:41:50,409'); seek(2510.0)">
              So what the, what our agent will do first that we'll try to analyze.
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:41:56,214'); seek(2516.0)">
              The code base, it'll try to understand the project.
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:41:59,174'); seek(2519.0)">
              So it will check some Python files.
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:42:01,244'); seek(2521.0)">
              It decided to also check across different languages.
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:42:04,844'); seek(2524.0)">
              So this repository specifically contains three languages Python, go in TypeScript.
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:42:10,814'); seek(2530.0)">
              So it went ahead to check some go implementation of the repository.
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:42:16,704'); seek(2536.0)">
              Yeah, so it will, it can take some time depending on the
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:42:19,044'); seek(2539.0)">
              task which we have at hand.
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:42:20,944'); seek(2540.0)">
              So it also create already a branch for us.
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:42:23,534'); seek(2543.0)">
              Thanks to MCP support, of course, you can attach any MCP servers in this case.
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:42:29,294'); seek(2549.0)">
              I have Git, MCP, which basically allows the agent to, to perform any git commands
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:42:35,714'); seek(2555.0)">
              locally on your machine, and we already see some changes being implemented
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:42:40,994'); seek(2560.0)">
              in our repository, first and Python.
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:42:45,764'); seek(2565.0)">
              Okay?
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:42:49,214'); seek(2569.0)">
              Okay.
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:42:49,424'); seek(2569.0)">
              We already have modified, I believe, two files over here.
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:42:54,834'); seek(2574.0)">
              Then agent decided to switch, to go implementation of the repository.
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:42:59,694'); seek(2579.0)">
              All right, so yeah, we also need to introduce this name space
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:43:05,674'); seek(2585.0)">
              thingy in the go go implementation server as well as in Python.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:43:10,804'); seek(2590.0)">
              Alright.
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:43:12,334'); seek(2592.0)">
              Then we also, of course as instructed the GI a and Git and this small the sort of
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:43:18,864'); seek(2598.0)">
              nice feature I have here is I instructed the agent through instructions to always
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:43:26,154'); seek(2606.0)">
              slack me when it is done with the task.
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:43:30,094'); seek(2610.0)">
              So let's go back to our chat.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:43:33,909'); seek(2613.0)">
              And yeah, basically after the combination of agen patterns and MCB servers, it
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:43:39,119'); seek(2619.0)">
              was able to basically pull the JIRA JIRA ticket and then essentially do all
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:43:45,499'); seek(2625.0)">
              the all the tasks surrounding the, the typical software development steps, right?
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:43:51,819'); seek(2631.0)">
              So it creates, the branch created a commit for us and so on.
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:43:55,764'); seek(2635.0)">
              So basically in a matter of minute, it was able to fix fix the ticket for us.
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:44:02,224'); seek(2642.0)">
              Alright.
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:44:02,524'); seek(2642.0)">
              Let's switch back to the slides one more time.
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:44:08,124'); seek(2648.0)">
              Okay.
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:44:08,664'); seek(2648.0)">
              So yeah, and if you are wondering this is how those messages from sun Coder
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:44:13,464'); seek(2653.0)">
              would look like in Slack, for example.
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:44:15,444'); seek(2655.0)">
              And, every time I get those messages, it feels this meme and of course, I can
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:44:22,284'); seek(2662.0)">
              instruct Theod to not message you, but your PM or whoever you wanted to message
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:44:28,344'); seek(2668.0)">
              and not necessarily in Slack or, you can, through MCP, you can connect to
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:44:31,569'); seek(2671.0)">
              pretty much any messaging app whatsoever.
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:44:35,259'); seek(2675.0)">
              And well, of course, these sort of improvements or what you've seen now.
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:44:41,839'); seek(2681.0)">
              Probably made you think if it's time to switch switch the profession, right?
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:44:47,759'); seek(2687.0)">
              Is still a good time to be a software developer?
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:44:50,759'); seek(2690.0)">
              And of course there are essentially two main sides to that question to,
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:44:55,719'); seek(2695.0)">
              what's coming for the developers.
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:44:57,729'); seek(2697.0)">
              Of course, you can think about, ai replication and.
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:45:03,329'); seek(2703.0)">
              There is also some, variability as to if you see it as a negative or a positive
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:45:08,529'); seek(2708.0)">
              thing because for example, maybe you always wanted to be a goose farmer.
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:45:12,769'); seek(2712.0)">
              And then once you are replaced by ai, you finally would be able to
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:45:17,209'); seek(2717.0)">
              chase that long lasting dream of whatever you whatever your heart
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:45:22,259'); seek(2722.0)">
              wants you, what wants you to be.
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:45:25,879'); seek(2725.0)">
              Now of course.
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:45:27,499'); seek(2727.0)">
              At least for now, AI is not able to train itself without the data.
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:45:32,409'); seek(2732.0)">
              So there is at least one job that is safe for now.
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:45:35,989'); seek(2735.0)">
              Namely writing the code for AI to train on because, still it requires a
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:45:41,489'); seek(2741.0)">
              bunch of data for training, for model improvements, however jokes site even
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:45:47,109'); seek(2747.0)">
              with those, all of those improvements from, on the AI side, on the gen side
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:45:51,819'); seek(2751.0)">
              with things like white coding, you still hopefully need to they still need to
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:45:56,969'); seek(2756.0)">
              have a good knowledge of what's going on.
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:45:59,859'); seek(2759.0)">
              Especially we're talking about some mission critical systems especially
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:46:03,649'); seek(2763.0)">
              about putting things into production.
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:46:06,949'); seek(2766.0)">
              You still want to be able to un to be able to understand what's going on.
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:46:10,929'); seek(2770.0)">
              You need to still need to be able to.
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:46:13,329'); seek(2773.0)">
              Read the code or know, debug the code.
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:46:16,269'); seek(2776.0)">
              So what we at Zone Coder and me personally see as a sort of upcoming future for
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:46:23,529'); seek(2783.0)">
              the software development is that we as developers would become more as a managers
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:46:29,589'); seek(2789.0)">
              of virtual virtual agents, virtual junior developers, if you will, and.
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:46:36,174'); seek(2796.0)">
              We as humans would be more for reviewers, more managers as that
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:46:40,924'); seek(2800.0)">
              rather than writing the code ourselves.
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:46:43,014'); seek(2803.0)">
              So basically we would be able to offload any mundane tasks.
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:46:47,544'); seek(2807.0)">
              For example writing documentation, writing new in tests, and so on to our
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:46:52,284'); seek(2812.0)">
              army of virtual virtual developers.
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:46:54,804'); seek(2814.0)">
              We as as people would be able to focus on more creative or more high
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:46:58,644'); seek(2818.0)">
              level tasks, more architecturals architectural tasks and so on.
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:47:04,554'); seek(2824.0)">
              So yeah, hopefully the future, no longer doesn't look as as dark as it did before.
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:47:12,504'); seek(2832.0)">
              But of course, AI moves fast.
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:47:14,434'); seek(2834.0)">
              So we'll see what will happen a few years with that.
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:47:18,859'); seek(2838.0)">
              A couple cure codes for you to use.
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:47:20,959'); seek(2840.0)">
              On the right is my contact details.
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:47:23,729'); seek(2843.0)">
              If you want to connect on LinkedIn, if you want to follow up with any
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:47:28,439'); seek(2848.0)">
              questions, feel free to message me.
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:47:30,719'); seek(2850.0)">
              Feel free to send the connect request.
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:47:32,849'); seek(2852.0)">
              And on the left you can see the cure code for our website for encoder ai,
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:47:38,019'); seek(2858.0)">
              where you can basically sign up for free and try as, try the agents in your id.
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:47:44,174'); seek(2864.0)">
              Already they end with that.
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:47:47,334'); seek(2867.0)">
              Thank you for your attention.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Alex%20Shershebnev%20-%20Conf42%20Machine%20Learning%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Alex%20Shershebnev%20-%20Conf42%20Machine%20Learning%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 137 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Alex%20Shershebnev_ml.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Alex Shershebnev
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    ML / DevOps Lead @ Zencoder
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/shershebnev/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Alex Shershebnev's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Alex Shershebnev"
                  data-url="https://www.conf42.com/ml2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>