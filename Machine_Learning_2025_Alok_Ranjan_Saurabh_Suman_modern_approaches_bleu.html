<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Beyond BLEU and ROUGE — Modern Approaches to Evaluating LLMs and AI Systems</title>
    <meta name="description" content="Help us build a dystopian, machine-ated future!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Alok%20Ranjan%20%26%20Saurabh%20Suman_ml.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Beyond BLEU and ROUGE — Modern Approaches to Evaluating LLMs and AI Systems | Conf42"/>
    <meta property="og:description" content="Traditional metrics like BLEU and ROUGE fall short in capturing advanced LLM capabilities. In this talk, discover modern methods—from benchmarks like MMLU and TruthfulQA to real-world evaluations and human-in-the-loop insights—that better assess AI performance. Join us to rethink AI evaluation—now!"/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2025_Alok_Ranjan_Saurabh_Suman_modern_approaches_bleu"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/IOT2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Internet of Things (IoT) 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-12-18
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/iot2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2026
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2026">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2026">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2026">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2026">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2026">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/dbd2026">
                            Database DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2026">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2026">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/agents2026">
                            AI Agents
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2026">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2026">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2026">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2026">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2026">
                            Chaos Engineering
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <!-- <a class="dropdown-item" href="None">
                            <b>Community platform login</b>
                          </a> -->
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2025 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2025-05-08">May 08 2025</time>
              
              - premiere 5PM GMT
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Help us build a dystopian, machine-ated future!
 -->
              <script>
                const event_date = new Date("2025-05-08T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-05-08T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "Q4iyw1miXaY"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrDbH1VBaoA60lLAAVqmiLPe" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hello everyone and welcome to our session here at Con 42.", "timestamp": "00:00:01,440", "timestamp_s": 1.0}, {"text": "Today we are diving into a crucial but often overlooked aspect of working with", "timestamp": "00:00:06,660", "timestamp_s": 6.0}, {"text": "large language models and AI systems.", "timestamp": "00:00:12,480", "timestamp_s": 12.0}, {"text": "How do we evaluate the meaningfully traditional metrics like Blue and Rouge?", "timestamp": "00:00:16,050", "timestamp_s": 16.0}, {"text": "Were a good starting point, but as AI systems grow more powerful", "timestamp": "00:00:22,170", "timestamp_s": 22.0}, {"text": "and complex, we need smarter.", "timestamp": "00:00:27,270", "timestamp_s": 27.0}, {"text": "More human-centric approaches to truly measure their effectiveness.", "timestamp": "00:00:29,910", "timestamp_s": 29.0}, {"text": "So in this talk, we\u0027ll explore what\u0027s beyond blue and rules, how the evaluation", "timestamp": "00:00:34,710", "timestamp_s": 34.0}, {"text": "landscape is evolving, and what modern techniques are emerging to keep pace", "timestamp": "00:00:41,010", "timestamp_s": 41.0}, {"text": "with rapid advancement in generative ai.", "timestamp": "00:00:46,350", "timestamp_s": 46.0}, {"text": "Before we dive deeper into our presentation, let me give.", "timestamp": "00:00:49,780", "timestamp_s": 49.0}, {"text": "A quick introduction about ourselves.", "timestamp": "00:00:54,370", "timestamp_s": 54.0}, {"text": "I\u0027m aloen, currently leading engineering at Dropbox, where I work on storage", "timestamp": "00:00:56,800", "timestamp_s": 56.0}, {"text": "systems, scalable infrastructure, and the AI ML platforms that powers", "timestamp": "00:01:01,900", "timestamp_s": 61.0}, {"text": "some of our internal tooling.", "timestamp": "00:01:06,970", "timestamp_s": 66.0}, {"text": "I completed my masters from Carnegie Mellon University, and much of", "timestamp": "00:01:09,070", "timestamp_s": 69.0}, {"text": "my work today involves balancing performance, observability, and scale.", "timestamp": "00:01:13,000", "timestamp_s": 73.0}, {"text": "And I\u0027m, I work as a applied AI engineer.", "timestamp": "00:01:18,910", "timestamp_s": 78.0}, {"text": "I build scalable machine learning solutions which", "timestamp": "00:01:22,300", "timestamp_s": 82.0}, {"text": "focus on real world impact.", "timestamp": "00:01:24,640", "timestamp_s": 84.0}, {"text": "I specialize in working in education technology.", "timestamp": "00:01:26,350", "timestamp_s": 86.0}, {"text": "My current focus lies in distributed machine learning and the world of", "timestamp": "00:01:29,380", "timestamp_s": 89.0}, {"text": "agent ai, where I\u0027m trying to create systems that doesn\u0027t just respond to", "timestamp": "00:01:33,971", "timestamp_s": 93.0}, {"text": "you, but it keeps reasoning and adapt.", "timestamp": "00:01:37,030", "timestamp_s": 97.0}, {"text": "So together, me and Alo, we bring a shared passion for making AI", "timestamp": "00:01:39,820", "timestamp_s": 99.0}, {"text": "systems not just smarter, but more accountable and more measurable.", "timestamp": "00:01:43,300", "timestamp_s": 103.0}, {"text": "Let\u0027s begin with a simple scenario.", "timestamp": "00:01:47,600", "timestamp_s": 107.0}, {"text": "Imagine you\u0027re a part of a startup launching an AI powered", "timestamp": "00:01:50,150", "timestamp_s": 110.0}, {"text": "customer service chat bot.", "timestamp": "00:01:53,810", "timestamp_s": 113.0}, {"text": "Sounds familiar, right?", "timestamp": "00:01:56,120", "timestamp_s": 116.0}, {"text": "It\u0027s a classic use case, automate support, cut costs, and improved response times.", "timestamp": "00:01:57,950", "timestamp_s": 117.0}, {"text": "Now think about what your customers expect from this chat bot.", "timestamp": "00:02:04,850", "timestamp_s": 124.0}, {"text": "It\u0027s not just about answering queries.", "timestamp": "00:02:09,380", "timestamp_s": 129.0}, {"text": "They want answers that are fast, relevant, and feel human.", "timestamp": "00:02:11,870", "timestamp_s": 131.0}, {"text": "So how do you evaluate whether your model is doing a good job?", "timestamp": "00:02:17,390", "timestamp_s": 137.0}, {"text": "This is where the problem begins.", "timestamp": "00:02:21,820", "timestamp_s": 141.0}, {"text": "We can\u0027t rely solely on word overlap or rigid rules.", "timestamp": "00:02:23,920", "timestamp_s": 143.0}, {"text": "We need to measure effectiveness across three key dimensions.", "timestamp": "00:02:28,870", "timestamp_s": 148.0}, {"text": "Accuracy.", "timestamp": "00:02:32,725", "timestamp_s": 152.0}, {"text": "Is the information factually correct?", "timestamp": "00:02:34,135", "timestamp_s": 154.0}, {"text": "Usability is the response phrased in a way the user can understand and act on.", "timestamp": "00:02:36,865", "timestamp_s": 156.0}, {"text": "And reliability does.", "timestamp": "00:02:43,135", "timestamp_s": 163.0}, {"text": "The system performs consistently across different user inputs,", "timestamp": "00:02:45,055", "timestamp_s": 165.0}, {"text": "context, and each cases.", "timestamp": "00:02:49,225", "timestamp_s": 169.0}, {"text": "This sets the foundation for why we need to go beyond traditional metrics.", "timestamp": "00:02:51,955", "timestamp_s": 171.0}, {"text": "It\u0027s no longer just about language similarity.", "timestamp": "00:02:56,845", "timestamp_s": 176.0}, {"text": "It\u0027s about actual performance, trust and impact.", "timestamp": "00:03:00,010", "timestamp_s": 180.0}, {"text": "Now that we have set the stage, let\u0027s define what we are actually aiming to", "timestamp": "00:03:05,590", "timestamp_s": 185.0}, {"text": "evaluate when it comes to AI systems, especially large language models.", "timestamp": "00:03:10,000", "timestamp_s": 190.0}, {"text": "Traditionally, we have been good at measuring things like grammar", "timestamp": "00:03:16,240", "timestamp_s": 196.0}, {"text": "or overlap with reference answers.", "timestamp": "00:03:20,080", "timestamp_s": 200.0}, {"text": "But today\u0027s AI systems operate in open-ended real world context, so we", "timestamp": "00:03:22,585", "timestamp_s": 202.0}, {"text": "need a much richer set of objectives.", "timestamp": "00:03:27,985", "timestamp_s": 207.0}, {"text": "Here is what we believe.", "timestamp": "00:03:30,955", "timestamp_s": 210.0}, {"text": "Every modern evaluation framework should aim to capture first accuracy.", "timestamp": "00:03:32,515", "timestamp_s": 212.0}, {"text": "This one\u0027s obvious.", "timestamp": "00:03:38,875", "timestamp_s": 218.0}, {"text": "The AI should get facts right.", "timestamp": "00:03:40,255", "timestamp_s": 220.0}, {"text": "A model generating confident but wrong information is dangerous, not useful.", "timestamp": "00:03:42,625", "timestamp_s": 222.0}, {"text": "Second bias mitigation.", "timestamp": "00:03:48,295", "timestamp_s": 228.0}, {"text": "We want systems that generate inclusive and fair outputs, and that means actively", "timestamp": "00:03:51,025", "timestamp_s": 231.0}, {"text": "identifying and minimizing harmful stereotypes or skewed viewpoints.", "timestamp": "00:03:57,055", "timestamp_s": 237.0}, {"text": "Third coherence, it\u0027s not enough for an answer to be correct.", "timestamp": "00:04:02,785", "timestamp_s": 242.0}, {"text": "It needs to make sense in the flow of a conversation.", "timestamp": "00:04:07,225", "timestamp_s": 247.0}, {"text": "This is Es especially critical for applications like tutoring.", "timestamp": "00:04:11,145", "timestamp_s": 251.0}, {"text": "Therapy or customer service.", "timestamp": "00:04:15,135", "timestamp_s": 255.0}, {"text": "And finally, reliability.", "timestamp": "00:04:17,745", "timestamp_s": 257.0}, {"text": "The AI should perform consistently across different prompts, languages,", "timestamp": "00:04:19,905", "timestamp_s": 259.0}, {"text": "domains, and even user personas.", "timestamp": "00:04:24,915", "timestamp_s": 264.0}, {"text": "No surprises, no hallucinations, no brittle behavior.", "timestamp": "00:04:28,155", "timestamp_s": 268.0}, {"text": "These four accuracy, fairness, coherence, and reliability together form a much", "timestamp": "00:04:32,625", "timestamp_s": 272.0}, {"text": "more complete picture of what good AI actually means in the real world.", "timestamp": "00:04:38,985", "timestamp_s": 278.0}, {"text": "And me measuring these effectively is where the challenge begins.", "timestamp": "00:04:44,205", "timestamp_s": 284.0}, {"text": "Before we talk about what\u0027s next, let\u0027s take a step back and quickly", "timestamp": "00:04:50,865", "timestamp_s": 290.0}, {"text": "revisit what Blue and Rules actually are and why they have been so dominant", "timestamp": "00:04:55,275", "timestamp_s": 295.0}, {"text": "in NLP evaluation for so long.", "timestamp": "00:05:01,155", "timestamp_s": 301.0}, {"text": "Blue or bilingual evaluation under study is essentially a precision based score.", "timestamp": "00:05:03,975", "timestamp_s": 303.0}, {"text": "It compares the ngrams or short chunk of words in a model\u0027s output.", "timestamp": "00:05:10,725", "timestamp_s": 310.0}, {"text": "To those in a reference sentence.", "timestamp": "00:05:16,410", "timestamp_s": 316.0}, {"text": "It\u0027s been a staple in machine translation tasks for years.", "timestamp": "00:05:18,510", "timestamp_s": 318.0}, {"text": "Rules on the other hand, is more recall oriented.", "timestamp": "00:05:23,740", "timestamp_s": 323.0}, {"text": "It looks at how much of the reference text is captured in the model\u0027s output.", "timestamp": "00:05:27,730", "timestamp_s": 327.0}, {"text": "It\u0027s widely used for evaluating summarization, where the goal", "timestamp": "00:05:32,650", "timestamp_s": 332.0}, {"text": "is to see whether the generated summary includes the important bits.", "timestamp": "00:05:36,370", "timestamp_s": 336.0}, {"text": "Now, why were these metrics adopted so widely?", "timestamp": "00:05:41,020", "timestamp_s": 341.0}, {"text": "They\u0027re fast language agnostic and they don\u0027t require any human label data.", "timestamp": "00:05:45,040", "timestamp_s": 345.0}, {"text": "You can just run them over a corpus and get numeric scores.", "timestamp": "00:05:50,530", "timestamp_s": 350.0}, {"text": "It\u0027s clean and scalable.", "timestamp": "00:05:54,760", "timestamp_s": 354.0}, {"text": "But, and here\u0027s the catch.", "timestamp": "00:05:57,580", "timestamp_s": 357.0}, {"text": "Just because something is easy to compute doesn\u0027t mean it truly", "timestamp": "00:06:00,160", "timestamp_s": 360.0}, {"text": "captures what quality looks like.", "timestamp": "00:06:03,820", "timestamp_s": 363.0}, {"text": "Blue and Rose don\u0027t understand meaning intent tone or factual correctness.", "timestamp": "00:06:06,460", "timestamp_s": 366.0}, {"text": "That\u0027s the real gap we need to fill.", "timestamp": "00:06:12,430", "timestamp_s": 372.0}, {"text": "Let\u0027s bring this down to earth with a real world example that", "timestamp": "00:06:16,450", "timestamp_s": 376.0}, {"text": "highlights just how fragile these tradition traditional metrics can be.", "timestamp": "00:06:19,940", "timestamp_s": 379.0}, {"text": "Say we have built a customer support chat bot for an e-commerce store,", "timestamp": "00:06:25,760", "timestamp_s": 385.0}, {"text": "and the user asks a simple question, what\u0027s the size of this jacket?", "timestamp": "00:06:30,380", "timestamp_s": 390.0}, {"text": "The chat bot response correctly, with just one word, 34.", "timestamp": "00:06:35,510", "timestamp_s": 395.0}, {"text": "That\u0027s perfectly valid answer.", "timestamp": "00:06:40,910", "timestamp_s": 400.0}, {"text": "It\u0027s concise, accurate, and exactly what the user needs, but here is the catch.", "timestamp": "00:06:42,890", "timestamp_s": 402.0}, {"text": "The blue score for this response is just 0.016.", "timestamp": "00:06:49,190", "timestamp_s": 409.0}, {"text": "That\u0027s extremely low and completely misleading.", "timestamp": "00:06:54,440", "timestamp_s": 414.0}, {"text": "Why?", "timestamp": "00:06:58,190", "timestamp_s": 418.0}, {"text": "Because Blue is comparing Ngram overlaps with reference sentences", "timestamp": "00:06:59,240", "timestamp_s": 419.0}, {"text": "like it\u0027s XXL, or it\u0027s small, or it is 34, and since 34 doesn\u0027t share enough", "timestamp": "00:07:03,380", "timestamp_s": 423.0}, {"text": "bigrams or trigrams with any of these.", "timestamp": "00:07:10,820", "timestamp_s": 430.0}, {"text": "It gets penalized even though it\u0027s semantically perfect.", "timestamp": "00:07:14,495", "timestamp_s": 434.0}, {"text": "This is the kind of disconnect that makes blue and ruse unreliable in real", "timestamp": "00:07:19,595", "timestamp_s": 439.0}, {"text": "dialogue or open domain scenarios.", "timestamp": "00:07:24,575", "timestamp_s": 444.0}, {"text": "They care more about surface level similarity than actual meaning,", "timestamp": "00:07:27,485", "timestamp_s": 447.0}, {"text": "and if we are not careful, we end up punishing good responses.", "timestamp": "00:07:32,090", "timestamp_s": 452.0}, {"text": "Just because they\u0027re phrased differently.", "timestamp": "00:07:36,755", "timestamp_s": 456.0}, {"text": "Here is another example that really drives home the limitation of these", "timestamp": "00:07:40,205", "timestamp_s": 460.0}, {"text": "surface level metrics like Blue.", "timestamp": "00:07:44,315", "timestamp_s": 464.0}, {"text": "Imagine we are evaluating a chat bot designed to explain HR policies, in", "timestamp": "00:07:46,925", "timestamp_s": 466.0}, {"text": "this case, remote work guidelines.", "timestamp": "00:07:52,745", "timestamp_s": 472.0}, {"text": "The reference sentence says employees are permitted to work", "timestamp": "00:07:56,165", "timestamp_s": 476.0}, {"text": "remotely up to three days per week, subject to manager approval.", "timestamp": "00:07:59,585", "timestamp_s": 479.0}, {"text": "The model response with staff members are allowed to telecommute for a", "timestamp": "00:08:04,970", "timestamp_s": 484.0}, {"text": "maximum of three days, weekly pending approval from their supervisor.", "timestamp": "00:08:09,350", "timestamp_s": 489.0}, {"text": "Now, pause for a second.", "timestamp": "00:08:14,600", "timestamp_s": 494.0}, {"text": "That response is perfectly accurate.", "timestamp": "00:08:16,610", "timestamp_s": 496.0}, {"text": "It conveys the exact same meaning just using slightly different phrasing, but", "timestamp": "00:08:19,460", "timestamp_s": 499.0}, {"text": "play it gives this a score of zero.", "timestamp": "00:08:25,160", "timestamp_s": 505.0}, {"text": "That\u0027s right.", "timestamp": "00:08:28,550", "timestamp_s": 508.0}, {"text": "Zero y. Because Blue is looking for direct overlaps, exact words and ngram matches.", "timestamp": "00:08:29,270", "timestamp_s": 509.0}, {"text": "It doesn\u0027t understand that staff members and employees mean the same", "timestamp": "00:08:37,604", "timestamp_s": 517.0}, {"text": "thing, or that supervisor are just managers with a different label.", "timestamp": "00:08:41,804", "timestamp_s": 521.0}, {"text": "This is the core flaw blue and rules semantic equivalence", "timestamp": "00:08:46,724", "timestamp_s": 526.0}, {"text": "and conversation quality.", "timestamp": "00:08:52,155", "timestamp_s": 532.0}, {"text": "And if we are going to build LMS that actually communicate well,", "timestamp": "00:08:54,435", "timestamp_s": 534.0}, {"text": "we need to evaluate methods.", "timestamp": "00:08:58,964", "timestamp_s": 538.0}, {"text": "That reward, meaning not just matching.", "timestamp": "00:09:01,094", "timestamp_s": 541.0}, {"text": "Let\u0027s take a moment to summarize what we have seen so far about traditional", "timestamp": "00:09:06,464", "timestamp_s": 546.0}, {"text": "metrics like blue and rules.", "timestamp": "00:09:10,785", "timestamp_s": 550.0}, {"text": "First, both of these metrics are built around n gram oral lab,", "timestamp": "00:09:12,915", "timestamp_s": 552.0}, {"text": "essentially counting how many words or phrases match between the morals,", "timestamp": "00:09:17,505", "timestamp_s": 557.0}, {"text": "response and a reference answer.", "timestamp": "00:09:21,344", "timestamp_s": 561.0}, {"text": "This works well with the task.", "timestamp": "00:09:24,990", "timestamp_s": 564.0}, {"text": "Is rigid, like translating a sentence, word for word or", "timestamp": "00:09:26,700", "timestamp_s": 566.0}, {"text": "summarizing with fixed phrasing.", "timestamp": "00:09:30,270", "timestamp_s": 570.0}, {"text": "And to be fair, blue and rules have excelled in domains like machine", "timestamp": "00:09:32,670", "timestamp_s": 572.0}, {"text": "translation and text summarization.", "timestamp": "00:09:37,650", "timestamp_s": 577.0}, {"text": "They\u0027re efficient, widely adopted, and they helped", "timestamp": "00:09:40,140", "timestamp_s": 580.0}, {"text": "standardize benchmarks early on.", "timestamp": "00:09:43,650", "timestamp_s": 583.0}, {"text": "But this is the key.", "timestamp": "00:09:47,280", "timestamp_s": 587.0}, {"text": "They completely struggle when it comes to contextual understanding", "timestamp": "00:09:48,780", "timestamp_s": 588.0}, {"text": "or semantic variation.", "timestamp": "00:09:52,650", "timestamp_s": 592.0}, {"text": "They can\u0027t tell if a response makes sense in a conversation or if it\u0027s phrased", "timestamp": "00:09:54,780", "timestamp_s": 594.0}, {"text": "differently, but means the same thing.", "timestamp": "00:09:59,700", "timestamp_s": 599.0}, {"text": "In other words, blue and ruse rewards surface similarity, not actual quality.", "timestamp": "00:10:02,670", "timestamp_s": 602.0}, {"text": "And that\u0027s why we need to evolve our evaluation toolkit as our", "timestamp": "00:10:09,000", "timestamp_s": 609.0}, {"text": "models get more sophisticated.", "timestamp": "00:10:13,200", "timestamp_s": 613.0}, {"text": "So what do we mean when the, when we say Ngram overlap, let\u0027s quickly", "timestamp": "00:10:17,865", "timestamp_s": 617.0}, {"text": "unpack that because it\u0027s the foundation of both blue and rules, and ngram", "timestamp": "00:10:23,625", "timestamp_s": 623.0}, {"text": "is simply a sequence of N words, A one gram, or unigram just means", "timestamp": "00:10:28,814", "timestamp_s": 628.0}, {"text": "individual words like cat runs or fast.", "timestamp": "00:10:34,155", "timestamp_s": 634.0}, {"text": "A two gram or bi gram is a pair of cons, security words like the cat or", "timestamp": "00:10:38,385", "timestamp_s": 638.0}, {"text": "runs fast, and a three gram or tri gram combines three words, for example,", "timestamp": "00:10:43,454", "timestamp_s": 643.0}, {"text": "the black cat or runs very fast.", "timestamp": "00:10:48,194", "timestamp_s": 648.0}, {"text": "The move, the more overlap you gen your generated text has with these", "timestamp": "00:10:51,285", "timestamp_s": 651.0}, {"text": "kind of sequences from a reference sentence, the higher your blue", "timestamp": "00:10:56,620", "timestamp_s": 656.0}, {"text": "or rose score are going to be.", "timestamp": "00:11:00,824", "timestamp_s": 660.0}, {"text": "It\u0027s a way to measure fluency.", "timestamp": "00:11:03,645", "timestamp_s": 663.0}, {"text": "And similarity without needing deep understanding, just matching patterns.", "timestamp": "00:11:05,505", "timestamp_s": 665.0}, {"text": "Now this diagram below shows how we move from basic word representation", "timestamp": "00:11:11,985", "timestamp_s": 671.0}, {"text": "to increasing contextual complexity from individual overlapping", "timestamp": "00:11:16,815", "timestamp_s": 676.0}, {"text": "words to longer shared sequences.", "timestamp": "00:11:21,525", "timestamp_s": 681.0}, {"text": "But here is the limitation.", "timestamp": "00:11:23,835", "timestamp_s": 683.0}, {"text": "As we have seen earlier, this structure can completely mis meaning intent,", "timestamp": "00:11:26,340", "timestamp_s": 686.0}, {"text": "or even factual accuracy if the phrasing is just slightly different.", "timestamp": "00:11:31,620", "timestamp_s": 691.0}, {"text": "So while gram overlap gives us something measurable, it\u0027s not the whole picture.", "timestamp": "00:11:36,450", "timestamp_s": 696.0}, {"text": "So now that we have seen what Ngram overlap actually measures,", "timestamp": "00:11:44,790", "timestamp_s": 704.0}, {"text": "let\u0027s talk about why it\u0027s not enough for today\u0027s AI systems.", "timestamp": "00:11:48,960", "timestamp_s": 708.0}, {"text": "Especially large language models.", "timestamp": "00:11:53,475", "timestamp_s": 713.0}, {"text": "First, it\u0027s a surface level measure.", "timestamp": "00:11:56,895", "timestamp_s": 716.0}, {"text": "It doesn\u0027t understand what a sentence means.", "timestamp": "00:11:59,535", "timestamp_s": 719.0}, {"text": "It just checks.", "timestamp": "00:12:02,055", "timestamp_s": 722.0}, {"text": "If the word looks similar, this is fine for basic translation task,", "timestamp": "00:12:02,865", "timestamp_s": 722.0}, {"text": "but it breaks down when the language gets more flexible or nuanced.", "timestamp": "00:12:07,214", "timestamp_s": 727.0}, {"text": "Second, it\u0027s easy to game.", "timestamp": "00:12:11,895", "timestamp_s": 731.0}, {"text": "You can bump up your blue score by repeating parts of the reference answer.", "timestamp": "00:12:14,385", "timestamp_s": 734.0}, {"text": "Or adding boilerplate phrases even if your actual output is poor.", "timestamp": "00:12:18,720", "timestamp_s": 738.0}, {"text": "Third, and this one\u0027s huge, it ignores factuality and coherence.", "timestamp": "00:12:23,700", "timestamp_s": 743.0}, {"text": "Your model might say something romantically perfect, but factually", "timestamp": "00:12:29,040", "timestamp_s": 749.0}, {"text": "wrong, and blue won\u0027t catch it.", "timestamp": "00:12:32,550", "timestamp_s": 752.0}, {"text": "Or it might output something semantically spot on, but still get a low score", "timestamp": "00:12:35,220", "timestamp_s": 755.0}, {"text": "because the phrasing was different.", "timestamp": "00:12:40,290", "timestamp_s": 760.0}, {"text": "And finally, these metrics often penalize longer or more fluent responses.", "timestamp": "00:12:42,210", "timestamp_s": 762.0}, {"text": "If your model rephrases an idea eloquently or adds context, it can", "timestamp": "00:12:48,390", "timestamp_s": 768.0}, {"text": "actually hurt the score because the Ngram pattern don\u0027t match the reference", "timestamp": "00:12:53,610", "timestamp_s": 773.0}, {"text": "exactly in short, blue and Ruse gives us a quick answer, but not a deep one.", "timestamp": "00:12:58,650", "timestamp_s": 778.0}, {"text": "And with modern lms, that\u0027s just not good enough anymore.", "timestamp": "00:13:05,730", "timestamp_s": 785.0}, {"text": "So now that we have the, we have seen the limitations of traditional metrics,", "timestamp": "00:13:12,150", "timestamp_s": 792.0}, {"text": "let\u0027s shift gears and look at what modern evaluation frameworks actually focuses on.", "timestamp": "00:13:16,500", "timestamp_s": 796.0}, {"text": "Instead of counting word overlaps, these new methods try to assess what", "timestamp": "00:13:22,590", "timestamp_s": 802.0}, {"text": "really matters in a model\u0027s response.", "timestamp": "00:13:27,540", "timestamp_s": 807.0}, {"text": "Qualities that are more aligned with how humans judge quality.", "timestamp": "00:13:30,420", "timestamp_s": 810.0}, {"text": "The first and arguably most important is factual accuracy.", "timestamp": "00:13:34,770", "timestamp_s": 814.0}, {"text": "Is the information actually correct?", "timestamp": "00:13:39,780", "timestamp_s": 819.0}, {"text": "Especially in domains like healthcare, finance, or education?", "timestamp": "00:13:42,210", "timestamp_s": 822.0}, {"text": "This isn\u0027t just nice to have, it\u0027s critical.", "timestamp": "00:13:46,710", "timestamp_s": 826.0}, {"text": "Then we have semantic coherence.", "timestamp": "00:13:50,370", "timestamp_s": 830.0}, {"text": "Does the response flow well?", "timestamp": "00:13:52,365", "timestamp_s": 832.0}, {"text": "Is it logically structured and grammatically sound?", "timestamp": "00:13:54,240", "timestamp_s": 834.0}, {"text": "Or does it feel like a random text bump?", "timestamp": "00:13:57,719", "timestamp_s": 837.0}, {"text": "Next comes answer, relevance.", "timestamp": "00:14:00,989", "timestamp_s": 840.0}, {"text": "Does the model stay on topic and directly address the question being asked?", "timestamp": "00:14:03,149", "timestamp_s": 843.0}, {"text": "This is especially important for systems like chatbots, tutors,", "timestamp": "00:14:08,519", "timestamp_s": 848.0}, {"text": "or customer service tools.", "timestamp": "00:14:12,060", "timestamp_s": 852.0}, {"text": "We also evaluate context precision.", "timestamp": "00:14:14,699", "timestamp_s": 854.0}, {"text": "Did the model respond with the most accurate detail from", "timestamp": "00:14:16,829", "timestamp_s": 856.0}, {"text": "the context it was given?", "timestamp": "00:14:20,189", "timestamp_s": 860.0}, {"text": "And conversely.", "timestamp": "00:14:21,930", "timestamp_s": 861.0}, {"text": "Context recall, did it include all the key elements that were", "timestamp": "00:14:23,384", "timestamp_s": 863.0}, {"text": "necessary to build a complete answer?", "timestamp": "00:14:27,854", "timestamp_s": 867.0}, {"text": "Together these dimensions form a far more comprehensive and human aligned way of", "timestamp": "00:14:30,794", "timestamp_s": 870.0}, {"text": "judging model output, and they are setting the foundation for NextGen AI benchmarks.", "timestamp": "00:14:36,614", "timestamp_s": 876.0}, {"text": "Now let\u0027s talk about how we evaluate the factual accuracy of responses", "timestamp": "00:14:44,354", "timestamp_s": 884.0}, {"text": "using a method called fact score.", "timestamp": "00:14:48,944", "timestamp_s": 888.0}, {"text": "The core idea here is to break down a generated response into atomic facts.", "timestamp": "00:14:51,569", "timestamp_s": 891.0}, {"text": "That is small, standalone pieces of information that", "timestamp": "00:14:57,270", "timestamp_s": 897.0}, {"text": "can be independently verified.", "timestamp": "00:15:01,079", "timestamp_s": 901.0}, {"text": "Each atomic fact is then checked against a reliable external knowledge", "timestamp": "00:15:03,839", "timestamp_s": 903.0}, {"text": "source, like a trusted database.", "timestamp": "00:15:07,949", "timestamp_s": 907.0}, {"text": "Verify document or reference corpus.", "timestamp": "00:15:10,364", "timestamp_s": 910.0}, {"text": "For example, if the model says the Eiffel Tower is in Paris and it was built in", "timestamp": "00:15:13,484", "timestamp_s": 913.0}, {"text": "1889, that\u0027s two separate atomic facts, and we check each of them individually.", "timestamp": "00:15:18,374", "timestamp_s": 918.0}, {"text": "Once this checking is done, we compute a score based on the proportion of", "timestamp": "00:15:25,314", "timestamp_s": 925.0}, {"text": "facts that are supported by the source, and that becomes the fact score.", "timestamp": "00:15:29,425", "timestamp_s": 929.0}, {"text": "This approach provides a granular, interpretable view of factual", "timestamp": "00:15:34,899", "timestamp_s": 934.0}, {"text": "factuality instead of just evaluating the sentence as a whole.", "timestamp": "00:15:39,699", "timestamp_s": 939.0}, {"text": "Alright, let\u0027s take a closer look at how factuality evaluation", "timestamp": "00:15:46,269", "timestamp_s": 946.0}, {"text": "actually works in a practice, especially with model grade systems.", "timestamp": "00:15:50,540", "timestamp_s": 950.0}, {"text": "This approach typically relies on three core inputs.", "timestamp": "00:15:55,655", "timestamp_s": 955.0}, {"text": "The prompt, the output, and reference answer, the first input is the prompt.", "timestamp": "00:15:58,655", "timestamp_s": 958.0}, {"text": "That\u0027s what we send to the LLM.", "timestamp": "00:16:04,385", "timestamp_s": 964.0}, {"text": "It could be a question, a task instruction, or a real work query like", "timestamp": "00:16:06,485", "timestamp_s": 966.0}, {"text": "what is the capital of Switzerland?", "timestamp": "00:16:11,855", "timestamp_s": 971.0}, {"text": "The second input is the output.", "timestamp": "00:16:14,000", "timestamp_s": 974.0}, {"text": "This is the model\u0027s response to that prompt.", "timestamp": "00:16:16,550", "timestamp_s": 976.0}, {"text": "For example, it might say Zurich or Burn, depending on how it was", "timestamp": "00:16:19,550", "timestamp_s": 979.0}, {"text": "trained or what it retrieved.", "timestamp": "00:16:23,780", "timestamp_s": 983.0}, {"text": "The third component is the reference.", "timestamp": "00:16:26,270", "timestamp_s": 986.0}, {"text": "This is the ideal response that a model should be should have given,", "timestamp": "00:16:28,730", "timestamp_s": 988.0}, {"text": "and this is typically crafted by the author of the evaluation.", "timestamp": "00:16:32,420", "timestamp_s": 992.0}, {"text": "Usually a human or another trusted system.", "timestamp": "00:16:37,280", "timestamp_s": 997.0}, {"text": "The factuality check is then done by comparing the model\u0027s", "timestamp": "00:16:40,895", "timestamp_s": 1000.0}, {"text": "output to the reference.", "timestamp": "00:16:44,225", "timestamp_s": 1004.0}, {"text": "Does the answer aligned with the verified facts?", "timestamp": "00:16:46,655", "timestamp_s": 1006.0}, {"text": "Was the reasoning sound, did it hallucinate or go off topic?", "timestamp": "00:16:49,955", "timestamp_s": 1009.0}, {"text": "This approach gives us a more targeted lens.", "timestamp": "00:16:55,355", "timestamp_s": 1015.0}, {"text": "We are no longer scoring for linguistic overlap.", "timestamp": "00:16:58,265", "timestamp_s": 1018.0}, {"text": "But for truthfulness and correctness.", "timestamp": "00:17:01,594", "timestamp_s": 1021.0}, {"text": "Now let\u0027s dive into a more advanced model-based approach for evaluating", "timestamp": "00:17:06,185", "timestamp_s": 1026.0}, {"text": "factuality One that goes far beyond keyword matching or basic overlap.", "timestamp": "00:17:10,715", "timestamp_s": 1030.0}, {"text": "What you are seeing here is a factuality scoring pipeline that leverages", "timestamp": "00:17:17,435", "timestamp_s": 1037.0}, {"text": "semantic alignment, entailment classification, and weighted aggregation", "timestamp": "00:17:22,174", "timestamp_s": 1042.0}, {"text": "to generate what\u0027s called a fact score.", "timestamp": "00:17:27,755", "timestamp_s": 1047.0}, {"text": "We begin with the input text.", "timestamp": "00:17:30,545", "timestamp_s": 1050.0}, {"text": "We use something like S-B-E-R-T-A sentence Bert model to identify how well the output", "timestamp": "00:17:32,795", "timestamp_s": 1052.0}, {"text": "semantic aligns with the reference facts.", "timestamp": "00:17:40,475", "timestamp_s": 1060.0}, {"text": "The next step is to break the reference answer into atomic facts.", "timestamp": "00:17:43,295", "timestamp_s": 1063.0}, {"text": "Labeled a one and then possibly reframe or relocate them in", "timestamp": "00:17:47,389", "timestamp_s": 1067.0}, {"text": "different forms marked as a two.", "timestamp": "00:17:51,800", "timestamp_s": 1071.0}, {"text": "This ensures we are not overly strict about phrasing.", "timestamp": "00:17:55,159", "timestamp_s": 1075.0}, {"text": "Now we introduce NLI classification, natural language inference.", "timestamp": "00:17:58,880", "timestamp_s": 1078.0}, {"text": "This checks whether the models output entails, contradicts, or is", "timestamp": "00:18:04,250", "timestamp_s": 1084.0}, {"text": "natural towards each atomic fact.", "timestamp": "00:18:08,720", "timestamp_s": 1088.0}, {"text": "This is where the green and red boxes come in.", "timestamp": "00:18:11,330", "timestamp_s": 1091.0}, {"text": "Green for support, red for contradiction.", "timestamp": "00:18:14,300", "timestamp_s": 1094.0}, {"text": "Then comes the aggregation phase where all of this gets pulled together.", "timestamp": "00:18:17,930", "timestamp_s": 1097.0}, {"text": "We apply different weights to different fact types.", "timestamp": "00:18:22,550", "timestamp_s": 1102.0}, {"text": "For example, facts classified as a gets a weight of 0.9, whereas", "timestamp": "00:18:25,580", "timestamp_s": 1105.0}, {"text": "contradictions like D two gets a lower score or even a zero penalty.", "timestamp": "00:18:30,920", "timestamp_s": 1110.0}, {"text": "The final result is a fact score, a weighted structured view of how", "timestamp": "00:18:36,500", "timestamp_s": 1116.0}, {"text": "factual the LM LMS output really is.", "timestamp": "00:18:41,389", "timestamp_s": 1121.0}, {"text": "It\u0027s nuanced, interpretable, and much more robust than traditional method,", "timestamp": "00:18:44,600", "timestamp_s": 1124.0}, {"text": "and most importantly, this method adapts well across domains and languages.", "timestamp": "00:18:50,180", "timestamp_s": 1130.0}, {"text": "It evaluates not just what the model says, but how well it aligns with the truth.", "timestamp": "00:18:55,880", "timestamp_s": 1135.0}, {"text": "Let\u0027s now talk about a modern metric that actually goes beyond surface level.", "timestamp": "00:19:03,860", "timestamp_s": 1143.0}, {"text": "Word overlaps birth score.", "timestamp": "00:19:08,239", "timestamp_s": 1148.0}, {"text": "Birth score is built on top of contextual embeddings.", "timestamp": "00:19:11,480", "timestamp_s": 1151.0}, {"text": "It uses models like Bert to assign vector implantation to each token,", "timestamp": "00:19:14,810", "timestamp_s": 1154.0}, {"text": "not just based on the word itself, but how it is used in context.", "timestamp": "00:19:20,060", "timestamp_s": 1160.0}, {"text": "That\u0027s key.", "timestamp": "00:19:24,920", "timestamp_s": 1164.0}, {"text": "In the example below, we have two sentences.", "timestamp": "00:19:26,090", "timestamp_s": 1166.0}, {"text": "The reference says, the weather is cold today.", "timestamp": "00:19:28,850", "timestamp_s": 1168.0}, {"text": "The candidate says it\u0027s freezing today.", "timestamp": "00:19:31,759", "timestamp_s": 1171.0}, {"text": "Now, even though there is little direct overlap, a human would agree.", "timestamp": "00:19:34,310", "timestamp_s": 1174.0}, {"text": "These two say almost the same thing.", "timestamp": "00:19:39,259", "timestamp_s": 1179.0}, {"text": "So instead of relying on ngrams, we generate contextual embeddings", "timestamp": "00:19:42,110", "timestamp_s": 1182.0}, {"text": "for each word using bird.", "timestamp": "00:19:46,250", "timestamp_s": 1186.0}, {"text": "These embeddings capture the meaning of each token in its context.", "timestamp": "00:19:48,380", "timestamp_s": 1188.0}, {"text": "Then we calculate Pairwise co-sign similarity between tokens across the", "timestamp": "00:19:53,195", "timestamp_s": 1193.0}, {"text": "reference and the candidate sentence.", "timestamp": "00:19:58,295", "timestamp_s": 1198.0}, {"text": "From these, we select the best matching pairs, aggregate their similarity", "timestamp": "00:20:00,755", "timestamp_s": 1200.0}, {"text": "scores, and compute a final bird score.", "timestamp": "00:20:05,045", "timestamp_s": 1205.0}, {"text": "This gives us a much richer sense of how well the semantic flow is preserved.", "timestamp": "00:20:08,225", "timestamp_s": 1208.0}, {"text": "Regardless of wordings.", "timestamp": "00:20:12,995", "timestamp_s": 1212.0}, {"text": "B score excels at evaluating coherence, paraphrasing, and even subtle rephrasing.", "timestamp": "00:20:15,065", "timestamp_s": 1215.0}, {"text": "Areas where blue and rules simply fall short.", "timestamp": "00:20:21,080", "timestamp_s": 1221.0}, {"text": "In other words, B score helps us evaluate what the model means,", "timestamp": "00:20:24,469", "timestamp_s": 1224.0}, {"text": "not just what word it uses.", "timestamp": "00:20:28,790", "timestamp_s": 1228.0}, {"text": "One of the most critical areas in AI evaluation today is", "timestamp": "00:20:32,989", "timestamp_s": 1232.0}, {"text": "addressing toxicity and bias.", "timestamp": "00:20:37,190", "timestamp_s": 1237.0}, {"text": "Why?", "timestamp": "00:20:40,040", "timestamp_s": 1240.0}, {"text": "Because even a single harmful response from an LLM can damage trust.", "timestamp": "00:20:41,120", "timestamp_s": 1241.0}, {"text": "Safety and inclusivity in the user experience.", "timestamp": "00:20:46,114", "timestamp_s": 1246.0}, {"text": "Bias can creep in from training data, prompt phrasing, or even subtle", "timestamp": "00:20:50,385", "timestamp_s": 1250.0}, {"text": "model behavior, and without careful evaluation, it often goes undetected.", "timestamp": "00:20:54,615", "timestamp_s": 1254.0}, {"text": "To help tackle this, we have tools like Lang Bite, which stands for", "timestamp": "00:21:01,095", "timestamp_s": 1261.0}, {"text": "language bias testing environment.", "timestamp": "00:21:06,555", "timestamp_s": 1266.0}, {"text": "Lang Byte works in a systematic and scalable way.", "timestamp": "00:21:09,585", "timestamp_s": 1269.0}, {"text": "First, it selects prompt templates from a predefined library, for example,", "timestamp": "00:21:13,065", "timestamp_s": 1273.0}, {"text": "prompts about race, gender, or religion.", "timestamp": "00:21:18,765", "timestamp_s": 1278.0}, {"text": "Then it generates test cases based on these templates.", "timestamp": "00:21:21,375", "timestamp_s": 1281.0}, {"text": "These are structured prompts designed to pro for biased or toxic behavior.", "timestamp": "00:21:25,035", "timestamp_s": 1285.0}, {"text": "Next, it executes those prompts across different LMS and carefully", "timestamp": "00:21:30,405", "timestamp_s": 1290.0}, {"text": "analyzes the response Finally.", "timestamp": "00:21:35,205", "timestamp_s": 1295.0}, {"text": "It generates insights highlighting areas where the model may have shown bias,", "timestamp": "00:21:38,340", "timestamp_s": 1298.0}, {"text": "tendencies, either overt or subtle.", "timestamp": "00:21:43,350", "timestamp_s": 1303.0}, {"text": "This lets developers pinpoint specific weakness and re and retrain", "timestamp": "00:21:46,890", "timestamp_s": 1306.0}, {"text": "or fine tune models to be more inclusive, respectful, and safe.", "timestamp": "00:21:51,420", "timestamp_s": 1311.0}, {"text": "Bias and toxicity aren\u0027t just bugs.", "timestamp": "00:21:56,460", "timestamp_s": 1316.0}, {"text": "They\u0027re ethical risks.", "timestamp": "00:21:59,580", "timestamp_s": 1319.0}, {"text": "And tools like Lang Byte help us bring transparency and", "timestamp": "00:22:01,185", "timestamp_s": 1321.0}, {"text": "accountability to the space.", "timestamp": "00:22:04,605", "timestamp_s": 1324.0}, {"text": "Let\u0027s now look at how this evaluation process works.", "timestamp": "00:22:07,305", "timestamp_s": 1327.0}, {"text": "In practice using Lang Byte structured pipeline, the flow starts with", "timestamp": "00:22:10,425", "timestamp_s": 1330.0}, {"text": "understanding ethical concerns.", "timestamp": "00:22:15,435", "timestamp_s": 1335.0}, {"text": "I. This includes input from sensitive communities and domain experts, which", "timestamp": "00:22:18,045", "timestamp_s": 1338.0}, {"text": "help define what types of harmful or biased behavior we need to test for.", "timestamp": "00:22:22,470", "timestamp_s": 1342.0}, {"text": "This leads to the ethical requirement specification, which creates a formal", "timestamp": "00:22:27,510", "timestamp_s": 1347.0}, {"text": "model of what needs to be avoided, such as hate, speech, stereotyping, or toxicity.", "timestamp": "00:22:32,040", "timestamp_s": 1352.0}, {"text": "Next, we move to test generation here.", "timestamp": "00:22:39,000", "timestamp_s": 1359.0}, {"text": "We use prompt templates designed to target those ethical concerns.", "timestamp": "00:22:42,450", "timestamp_s": 1362.0}, {"text": "From these templates, we generate real prompt instances, specific test cases.", "timestamp": "00:22:46,665", "timestamp_s": 1366.0}, {"text": "These prompts are then fed into the L lms.", "timestamp": "00:22:53,145", "timestamp_s": 1373.0}, {"text": "In the test execution phase, the model responses are collected, and", "timestamp": "00:22:55,815", "timestamp_s": 1375.0}, {"text": "these outputs we want to evaluate for signs of toxicity or bias.", "timestamp": "00:23:01,065", "timestamp_s": 1381.0}, {"text": "The final step is reporting.", "timestamp": "00:23:06,185", "timestamp_s": 1386.0}, {"text": "Here the responses are analyzed using prompt articles or even an evaluator LLM.", "timestamp": "00:23:08,240", "timestamp_s": 1388.0}, {"text": "The goal is to interpret the outputs and produce structured evaluation reports.", "timestamp": "00:23:14,420", "timestamp_s": 1394.0}, {"text": "This end-to-end flow ensures that bias detection is not just an afterthought.", "timestamp": "00:23:19,430", "timestamp_s": 1399.0}, {"text": "It\u0027s built into the system from the ground up, guided by real ethical priorities.", "timestamp": "00:23:24,950", "timestamp_s": 1404.0}, {"text": "Despite advances in automated metrics, human judgment remains irreplaceable.", "timestamp": "00:23:31,970", "timestamp_s": 1411.0}, {"text": "Especially in evaluating tone, coherence, and helpfulness, which", "timestamp": "00:23:37,220", "timestamp_s": 1417.0}, {"text": "current metrics can\u0027t always capture.", "timestamp": "00:23:41,570", "timestamp_s": 1421.0}, {"text": "That\u0027s why we use Pairwise comparison, where two outputs are shown side by side,", "timestamp": "00:23:44,000", "timestamp_s": 1424.0}, {"text": "and human judges select the better one.", "timestamp": "00:23:49,250", "timestamp_s": 1429.0}, {"text": "This is more reliable than assigning absolute numeric scores.", "timestamp": "00:23:53,330", "timestamp_s": 1433.0}, {"text": "We then apply probabilistic ranking models like Bradley Terry, or elo.", "timestamp": "00:23:57,200", "timestamp_s": 1437.0}, {"text": "To convert these comparisons into meaningful rankings.", "timestamp": "00:24:02,585", "timestamp_s": 1442.0}, {"text": "These methods are widely used in platforms like Chat Botina, and they consistently", "timestamp": "00:24:06,035", "timestamp_s": 1446.0}, {"text": "reveal gaps that automated metrics like Blue and Ruse fail to detect.", "timestamp": "00:24:11,015", "timestamp_s": 1451.0}, {"text": "In fact, two outputs might score equally in blue, but humans may", "timestamp": "00:24:15,935", "timestamp_s": 1455.0}, {"text": "strongly prefer one over the other due to clarity, style, or tone.", "timestamp": "00:24:19,925", "timestamp_s": 1459.0}, {"text": "So human-centric evaluation.", "timestamp": "00:24:24,545", "timestamp_s": 1464.0}, {"text": "Does not just validate models, it helps us uncover what really", "timestamp": "00:24:26,600", "timestamp_s": 1466.0}, {"text": "matters in user experience.", "timestamp": "00:24:30,350", "timestamp_s": 1470.0}, {"text": "Let\u0027s bring it all together.", "timestamp": "00:24:35,390", "timestamp_s": 1475.0}, {"text": "We want, we start with fact verification, breaking model response into atomic facts.", "timestamp": "00:24:37,460", "timestamp_s": 1477.0}, {"text": "Then verifying each one against trusted sources to generate an accuracy score.", "timestamp": "00:24:43,205", "timestamp_s": 1483.0}, {"text": "In parallel, we conduct pairwise comparison, A versus B, C", "timestamp": "00:24:48,455", "timestamp_s": 1488.0}, {"text": "versus A, where humans simply judge which response is better.", "timestamp": "00:24:52,205", "timestamp_s": 1492.0}, {"text": "Using models like Bradley Terry, these judgments are aggregated", "timestamp": "00:24:57,665", "timestamp_s": 1497.0}, {"text": "into a global ranking offering a probabilistic view of model quality.", "timestamp": "00:25:02,075", "timestamp_s": 1502.0}, {"text": "We then compared this human ranking against scores from automated metric.", "timestamp": "00:25:06,905", "timestamp_s": 1506.0}, {"text": "To identify where our evaluation system align and more", "timestamp": "00:25:11,270", "timestamp_s": 1511.0}, {"text": "importantly, where they don\u0027t.", "timestamp": "00:25:15,350", "timestamp_s": 1515.0}, {"text": "Human evaluation are increasingly taking central stage in measuring", "timestamp": "00:25:18,170", "timestamp_s": 1518.0}, {"text": "conversational AI quality, not just contemplating, but also correcting", "timestamp": "00:25:23,090", "timestamp_s": 1523.0}, {"text": "what automated metrics miss.", "timestamp": "00:25:28,220", "timestamp_s": 1528.0}, {"text": "With the, with that foundation lay laid, I\u0027ll now hand it over", "timestamp": "00:25:30,665", "timestamp_s": 1530.0}, {"text": "to Soro who will take us deeper into how modern metric systems.", "timestamp": "00:25:34,610", "timestamp_s": 1534.0}, {"text": "Like gal and real world task evaluations are changing the landscape.", "timestamp": "00:25:38,735", "timestamp_s": 1538.0}, {"text": "Alright, let\u0027s talk about one of the most promising shifts in", "timestamp": "00:25:44,885", "timestamp_s": 1544.0}, {"text": "evaluation using the l and m itself.", "timestamp": "00:25:48,365", "timestamp_s": 1548.0}, {"text": "As a judge, large language models bring in three very powerful strengths as a result.", "timestamp": "00:25:50,765", "timestamp_s": 1550.0}, {"text": "The first is context.", "timestamp": "00:25:56,015", "timestamp_s": 1556.0}, {"text": "Awareness means they can interpret the nuanced meaning and adapt to the domain.", "timestamp": "00:25:57,455", "timestamp_s": 1557.0}, {"text": "Scalability, since they can evaluate massive datasets quickly and very", "timestamp": "00:26:02,615", "timestamp_s": 1562.0}, {"text": "efficiently, and consistency, eliminating the subjectivity and the", "timestamp": "00:26:06,455", "timestamp_s": 1566.0}, {"text": "fatigue human evaluators often bring.", "timestamp": "00:26:10,595", "timestamp_s": 1570.0}, {"text": "So here is how it works.", "timestamp": "00:26:13,205", "timestamp_s": 1573.0}, {"text": "A benchmark dataset provides both input.", "timestamp": "00:26:14,885", "timestamp_s": 1574.0}, {"text": "Prompts and the correct outputs.", "timestamp": "00:26:17,195", "timestamp_s": 1577.0}, {"text": "The L lms, indeed as suggested output, and then using a judge", "timestamp": "00:26:19,265", "timestamp_s": 1579.0}, {"text": "prompt, we ask another LLM, given the input and the correct output.", "timestamp": "00:26:22,145", "timestamp_s": 1582.0}, {"text": "Is this the suggested output acceptable to make sure the judge stays reliable?", "timestamp": "00:26:25,985", "timestamp_s": 1585.0}, {"text": "We loop in human experts to assess the S judgment and refine", "timestamp": "00:26:30,245", "timestamp_s": 1590.0}, {"text": "the judge through feedback.", "timestamp": "00:26:34,175", "timestamp_s": 1594.0}, {"text": "This feedback loop from LLM response to LM Judgment to export", "timestamp": "00:26:36,035", "timestamp_s": 1596.0}, {"text": "audit, which help us continually improve and the evaluator itself.", "timestamp": "00:26:39,605", "timestamp_s": 1599.0}, {"text": "So to wrap up the discussion on evaluation, let\u0027s talk", "timestamp": "00:26:44,445", "timestamp_s": 1604.0}, {"text": "about why automated evaluation.", "timestamp": "00:26:47,445", "timestamp_s": 1607.0}, {"text": "It is not just helpful, it\u0027s very essential.", "timestamp": "00:26:49,200", "timestamp_s": 1609.0}, {"text": "First, it ensures we maintain consistent quality across multiple model versions.", "timestamp": "00:26:52,020", "timestamp_s": 1612.0}, {"text": "Whether we are fine tuning a base model or it trading on prompts, we need", "timestamp": "00:26:56,850", "timestamp_s": 1616.0}, {"text": "stability in how we assess outputs.", "timestamp": "00:27:00,270", "timestamp_s": 1620.0}, {"text": "Second, it provides an objective and reproducible performance signal,", "timestamp": "00:27:02,850", "timestamp_s": 1622.0}, {"text": "removing the human bias and the ambiguity from the evaluation loop.", "timestamp": "00:27:06,450", "timestamp_s": 1626.0}, {"text": "Third, it enables rapid testing at scale.", "timestamp": "00:27:10,340", "timestamp_s": 1630.0}, {"text": "Something manual methods simply cannot match.", "timestamp": "00:27:13,280", "timestamp_s": 1633.0}, {"text": "And finally, it supports continuous improvement cycles, which are foundation", "timestamp": "00:27:15,950", "timestamp_s": 1635.0}, {"text": "for the modern ML ops workflows.", "timestamp": "00:27:19,760", "timestamp_s": 1639.0}, {"text": "So now that we have seen why automated evaluation matters, let\u0027s", "timestamp": "00:27:24,255", "timestamp_s": 1644.0}, {"text": "also to take a look at the key technologies powering the shift.", "timestamp": "00:27:27,495", "timestamp_s": 1647.0}, {"text": "And whenever we talk about lms, the first thing that comes to our mind is", "timestamp": "00:27:31,335", "timestamp_s": 1651.0}, {"text": "open ai, the Open AI Evolve framework.", "timestamp": "00:27:34,785", "timestamp_s": 1654.0}, {"text": "This is a standardized way to define and run evaluation on", "timestamp": "00:27:37,515", "timestamp_s": 1657.0}, {"text": "large language model outputs.", "timestamp": "00:27:40,995", "timestamp_s": 1660.0}, {"text": "It\u0027s very extensible, modular, and integrates really well with other", "timestamp": "00:27:42,735", "timestamp_s": 1662.0}, {"text": "components of the open AI ecosystem.", "timestamp": "00:27:45,945", "timestamp_s": 1665.0}, {"text": "Then we have GE or generative evaluation.", "timestamp": "00:27:48,675", "timestamp_s": 1668.0}, {"text": "This goes beyond fixing test cases.", "timestamp": "00:27:51,165", "timestamp_s": 1671.0}, {"text": "It leverages generative prompts to dynamically evaluate model", "timestamp": "00:27:53,505", "timestamp_s": 1673.0}, {"text": "performance across a variety of tasks.", "timestamp": "00:27:56,535", "timestamp_s": 1676.0}, {"text": "It is especially useful for edge cases or nuance reasoning.", "timestamp": "00:27:59,175", "timestamp_s": 1679.0}, {"text": "And then we have REG evaluation frameworks.", "timestamp": "00:28:02,835", "timestamp_s": 1682.0}, {"text": "These are specifically tailored for retrieval augmented generation.", "timestamp": "00:28:05,595", "timestamp_s": 1685.0}, {"text": "They\u0027re not just assessing the output, but how well the model grounds its answers.", "timestamp": "00:28:09,315", "timestamp_s": 1689.0}, {"text": "And retrieving context.", "timestamp": "00:28:14,010", "timestamp_s": 1694.0}, {"text": "So it\u0027s about both the what and the why behind the answer.", "timestamp": "00:28:15,870", "timestamp_s": 1695.0}, {"text": "And finally, we rely heavily on evaluation data sets or eval sets.", "timestamp": "00:28:19,290", "timestamp_s": 1699.0}, {"text": "These include curated prompts, gold standard outputs, and even", "timestamp": "00:28:23,880", "timestamp_s": 1703.0}, {"text": "adversarial examples to rigorously stress test the moral behavior.", "timestamp": "00:28:27,120", "timestamp_s": 1707.0}, {"text": "Together, these tools form the backbone of how we benchmark an element scale.", "timestamp": "00:28:31,260", "timestamp_s": 1711.0}, {"text": "So let\u0027s dive a bit deeper and see how this prominent tool in this space,", "timestamp": "00:28:35,530", "timestamp_s": 1715.0}, {"text": "the open AI valve framework works.", "timestamp": "00:28:39,490", "timestamp_s": 1719.0}, {"text": "So this framework allows us to, simplify all of these things, like it helps us", "timestamp": "00:28:41,500", "timestamp_s": 1721.0}, {"text": "to build custom evaluation pipelines.", "timestamp": "00:28:45,280", "timestamp_s": 1725.0}, {"text": "It lets us summarize, code generation reasoning and dialogue.", "timestamp": "00:28:47,830", "timestamp_s": 1727.0}, {"text": "But one of the most important strength and standardizing test methodology is", "timestamp": "00:28:51,460", "timestamp_s": 1731.0}, {"text": "that you can benchmark across models and iterations using consistent.", "timestamp": "00:28:55,810", "timestamp_s": 1735.0}, {"text": "Metrics and it helps ensure reproducibility.", "timestamp": "00:28:59,829", "timestamp_s": 1739.0}, {"text": "It\u0027s also very natively integrated into the opening dashboard.", "timestamp": "00:29:03,069", "timestamp_s": 1743.0}, {"text": "It makes it very seamless to set up evaluation, view the results,", "timestamp": "00:29:06,159", "timestamp_s": 1746.0}, {"text": "and monitor change over time.", "timestamp": "00:29:09,819", "timestamp_s": 1749.0}, {"text": "So if you can see the screenshot below, you can see you can choose from a", "timestamp": "00:29:11,439", "timestamp_s": 1751.0}, {"text": "multiple data sources importing chart completion, uploading a recent NEL", "timestamp": "00:29:15,219", "timestamp_s": 1755.0}, {"text": "file, creating prompts manually, or even building custom evaluation logic.", "timestamp": "00:29:18,879", "timestamp_s": 1758.0}, {"text": "So this flexibility allows team to quickly spin up robust evaluation workflows", "timestamp": "00:29:22,899", "timestamp_s": 1762.0}, {"text": "without even reinventing the wheel.", "timestamp": "00:29:27,249", "timestamp_s": 1767.0}, {"text": "So one of the most powerful aspect of the open AI valve framework is the", "timestamp": "00:29:30,865", "timestamp_s": 1770.0}, {"text": "flexibility in defining the criteria.", "timestamp": "00:29:34,225", "timestamp_s": 1774.0}, {"text": "So you aren\u0027t limited to just accuracy.", "timestamp": "00:29:36,475", "timestamp_s": 1776.0}, {"text": "You can choose what matters for your application the most.", "timestamp": "00:29:38,365", "timestamp_s": 1778.0}, {"text": "Let\u0027s walk through some of this buildin options, right?", "timestamp": "00:29:41,215", "timestamp_s": 1781.0}, {"text": "So you have factuality and semantic similarity, which s assesses whether", "timestamp": "00:29:43,315", "timestamp_s": 1783.0}, {"text": "the response is both factually correct and align in meaning", "timestamp": "00:29:46,435", "timestamp_s": 1786.0}, {"text": "with the res reference, answer.", "timestamp": "00:29:49,975", "timestamp_s": 1789.0}, {"text": "For task that requires more of emotional intelligence, the sentiment evaluation", "timestamp": "00:29:51,699", "timestamp_s": 1791.0}, {"text": "can flag toxic or very often responses.", "timestamp": "00:29:55,239", "timestamp_s": 1795.0}, {"text": "Now, let\u0027s say you need structural validation, so we can use schema", "timestamp": "00:29:58,120", "timestamp_s": 1798.0}, {"text": "matching or check with the output is a valid, decent format or XML format.", "timestamp": "00:30:01,840", "timestamp_s": 1801.0}, {"text": "It\u0027s basically function calling.", "timestamp": "00:30:05,799", "timestamp_s": 1805.0}, {"text": "So string check and criteria match lets you test the presence", "timestamp": "00:30:08,049", "timestamp_s": 1808.0}, {"text": "or absence of specific tokens or features you can afford.", "timestamp": "00:30:11,229", "timestamp_s": 1811.0}, {"text": "Forbidden freezes or required formats.", "timestamp": "00:30:13,870", "timestamp_s": 1813.0}, {"text": "And if you\u0027re building custom metrics, you can define your own logic.", "timestamp": "00:30:16,330", "timestamp_s": 1816.0}, {"text": "Using the custom prompt option.", "timestamp": "00:30:20,939", "timestamp_s": 1820.0}, {"text": "And finally, if you have the need for the classic, NLP evaluation, there is always", "timestamp": "00:30:22,339", "timestamp_s": 1822.0}, {"text": "this text qualities that supports blue and rouge scores or something as simple", "timestamp": "00:30:26,329", "timestamp_s": 1826.0}, {"text": "as score sign, similarity based scoring.", "timestamp": "00:30:30,099", "timestamp_s": 1830.0}, {"text": "So all of these F frame, all of these tools included in the open a L framework.", "timestamp": "00:30:32,199", "timestamp_s": 1832.0}, {"text": "And that is something that we, highly recommend use it.", "timestamp": "00:30:35,739", "timestamp_s": 1835.0}, {"text": "So now let\u0027s take it, how easy was it actually for us to run an", "timestamp": "00:30:39,354", "timestamp_s": 1839.0}, {"text": "evaluation test with the open air framework using this one line code?", "timestamp": "00:30:43,049", "timestamp_s": 1843.0}, {"text": "Okay, in this scenario, we were using OI EAL combined, which uses GPD 3.5", "timestamp": "00:30:46,350", "timestamp_s": 1846.0}, {"text": "turbo on the spider SQL benchmarks, and we took a, maximum of 25 samples.", "timestamp": "00:30:51,749", "timestamp_s": 1851.0}, {"text": "The framework sends each prompt to the EPI and evaluates the responses in real time.", "timestamp": "00:30:56,939", "timestamp_s": 1856.0}, {"text": "And as you can see in the log it logs every single TTP requires and", "timestamp": "00:31:01,799", "timestamp_s": 1861.0}, {"text": "tracks a progress sample with sample.", "timestamp": "00:31:05,069", "timestamp_s": 1865.0}, {"text": "Once all the samples are processed, pick it a summary of report, in", "timestamp": "00:31:07,259", "timestamp_s": 1867.0}, {"text": "this case, 20, 20 as responses were correct and five were incorrect.", "timestamp": "00:31:10,709", "timestamp_s": 1870.0}, {"text": "A s giving us a score of 80% accuracy.", "timestamp": "00:31:14,849", "timestamp_s": 1874.0}, {"text": "This output is in saved to these in a log, which makes it very easy", "timestamp": "00:31:17,519", "timestamp_s": 1877.0}, {"text": "to review, compare across, model, or visualize performance later.", "timestamp": "00:31:20,549", "timestamp_s": 1880.0}, {"text": "And the best part about this, it\u0027s reproducible, testable, and scalable,", "timestamp": "00:31:24,149", "timestamp_s": 1884.0}, {"text": "all from a single CLA command.", "timestamp": "00:31:29,159", "timestamp_s": 1889.0}, {"text": "So let\u0027s work through a real evaluation sample from the SQL benchmark.", "timestamp": "00:31:33,030", "timestamp_s": 1893.0}, {"text": "Yeah, the prompt of the question here was how many country has a republic", "timestamp": "00:31:36,600", "timestamp_s": 1896.0}, {"text": "as their former for government?", "timestamp": "00:31:41,189", "timestamp_s": 1901.0}, {"text": "So the expected SL query is shown green, select star account from", "timestamp": "00:31:42,689", "timestamp_s": 1902.0}, {"text": "country where the country is a firm of government, which is equal to republic.", "timestamp": "00:31:46,570", "timestamp_s": 1906.0}, {"text": "So a precise match using equality.", "timestamp": "00:31:50,199", "timestamp_s": 1910.0}, {"text": "The model submission is in the orange, which use a slightly broad, broader", "timestamp": "00:31:51,939", "timestamp_s": 1911.0}, {"text": "pattern like, like republic, which also matches values like a federal", "timestamp": "00:31:55,060", "timestamp_s": 1915.0}, {"text": "republic system or a Republican system, which actually introduces", "timestamp": "00:31:59,169", "timestamp_s": 1919.0}, {"text": "some ambiguity in the result.", "timestamp": "00:32:02,620", "timestamp_s": 1922.0}, {"text": "So while the model might technically be correct, in many cases, it\u0027s", "timestamp": "00:32:04,209", "timestamp_s": 1924.0}, {"text": "not aligned with a strict expected output, and this will be flagged", "timestamp": "00:32:07,449", "timestamp_s": 1927.0}, {"text": "as incorrect by the eval framework.", "timestamp": "00:32:11,080", "timestamp_s": 1931.0}, {"text": "The small variations help us understand not whether just the", "timestamp": "00:32:13,170", "timestamp_s": 1933.0}, {"text": "model is right, but how closely it aligns with the exact semantic", "timestamp": "00:32:16,290", "timestamp_s": 1936.0}, {"text": "and precision, which is especially critical in structured tasks like SQL.", "timestamp": "00:32:20,040", "timestamp_s": 1940.0}, {"text": "So below you can see the next test case queued up.", "timestamp": "00:32:24,430", "timestamp_s": 1944.0}, {"text": "This happens automatically and repeatedly over the whole data set.", "timestamp": "00:32:28,180", "timestamp_s": 1948.0}, {"text": "So this is how we stress test the model with granular feedback,", "timestamp": "00:32:31,000", "timestamp_s": 1951.0}, {"text": "especially in domain, something, as complex, a structured query.", "timestamp": "00:32:33,940", "timestamp_s": 1953.0}, {"text": "So now we can look.", "timestamp": "00:32:38,819", "timestamp_s": 1958.0}, {"text": "Now let\u0027s take a look at GE value short for generative evaluation.", "timestamp": "00:32:40,469", "timestamp_s": 1960.0}, {"text": "It is used as an LLM that evaluates another LL M\u0027S output.", "timestamp": "00:32:43,924", "timestamp_s": 1963.0}, {"text": "So GAL has very simple three steps.", "timestamp": "00:32:48,899", "timestamp_s": 1968.0}, {"text": "First, we define a task.", "timestamp": "00:32:51,149", "timestamp_s": 1971.0}, {"text": "The evaluation criteria.", "timestamp": "00:32:53,009", "timestamp_s": 1973.0}, {"text": "For example, you might ask the model to judge a answer based on", "timestamp": "00:32:54,269", "timestamp_s": 1974.0}, {"text": "the clarity or the correctness.", "timestamp": "00:32:57,269", "timestamp_s": 1977.0}, {"text": "Then the models reads its own evaluation steps using chain of thought reasoning.", "timestamp": "00:32:59,039", "timestamp_s": 1979.0}, {"text": "This is what gives GE value, structure and explainability.", "timestamp": "00:33:03,239", "timestamp_s": 1983.0}, {"text": "Next, it\u0027ll use these steps to analyze the output and produce a detailed judgment.", "timestamp": "00:33:06,689", "timestamp_s": 1986.0}, {"text": "And finally, it applies a structured scoring function.", "timestamp": "00:33:11,429", "timestamp_s": 1991.0}, {"text": "Usually something that like structure score from the violation text and what.", "timestamp": "00:33:14,219", "timestamp_s": 1994.0}, {"text": "What is a powerful part here is that LLM becomes both the evaluator and the", "timestamp": "00:33:20,069", "timestamp_s": 2000.0}, {"text": "analyst and is very rich, interpretable feedback, not just a random number.", "timestamp": "00:33:24,090", "timestamp_s": 2004.0}, {"text": "So let\u0027s take a look at how the GE vial actually applies score", "timestamp": "00:33:30,225", "timestamp_s": 2010.0}, {"text": "and criteria using assertion.", "timestamp": "00:33:33,495", "timestamp_s": 2013.0}, {"text": "So each of these assertion define a specific example and expectation that is", "timestamp": "00:33:35,144", "timestamp_s": 2015.0}, {"text": "set for the large language model output.", "timestamp": "00:33:39,044", "timestamp_s": 2019.0}, {"text": "So in the first one, we are going to use a model graded rubric to ensure", "timestamp": "00:33:40,995", "timestamp_s": 2020.0}, {"text": "the response is not apologetic.", "timestamp": "00:33:44,504", "timestamp_s": 2024.0}, {"text": "Apologetic.", "timestamp": "00:33:46,034", "timestamp_s": 2026.0}, {"text": "This could be used in scenarios where you want the model to answer", "timestamp": "00:33:47,274", "timestamp_s": 2027.0}, {"text": "confidently, like in technical support scenarios or policy decision scenario.", "timestamp": "00:33:50,125", "timestamp_s": 2030.0}, {"text": "Use.", "timestamp": "00:33:53,965", "timestamp_s": 2033.0}, {"text": "And in the second use case, we use a factuality check.", "timestamp": "00:33:54,745", "timestamp_s": 2034.0}, {"text": "Verify whether the model output aligns with the specific known fact, like", "timestamp": "00:33:57,485", "timestamp_s": 2037.0}, {"text": "Sacramento is the capital of California.", "timestamp": "00:34:01,445", "timestamp_s": 2041.0}, {"text": "These assertion provide more modular composable test that can", "timestamp": "00:34:03,785", "timestamp_s": 2043.0}, {"text": "be reused across prompts and tasks.", "timestamp": "00:34:07,685", "timestamp_s": 2047.0}, {"text": "And this is what gives GE valves flexibility.", "timestamp": "00:34:09,845", "timestamp_s": 2049.0}, {"text": "So it\u0027s, think of it as a unit test, but for large language models.", "timestamp": "00:34:12,635", "timestamp_s": 2052.0}, {"text": "So here is a practical use case where ge y helps enforce behavior", "timestamp": "00:34:17,720", "timestamp_s": 2057.0}, {"text": "constraints across customer meetings.", "timestamp": "00:34:21,350", "timestamp_s": 2061.0}, {"text": "We have taken a common support prompt.", "timestamp": "00:34:23,510", "timestamp_s": 2063.0}, {"text": "And from audit tracking to product recommendation and it attach a very", "timestamp": "00:34:26,300", "timestamp_s": 2066.0}, {"text": "simple grading rule, do not mention that you are an AI chat bot or AI assistant.", "timestamp": "00:34:29,870", "timestamp_s": 2069.0}, {"text": "This is very useful in brand settings.", "timestamp": "00:34:35,390", "timestamp_s": 2075.0}, {"text": "So Anthrop izing the AI in my conflict design choices, tone", "timestamp": "00:34:37,220", "timestamp_s": 2077.0}, {"text": "guidelines, or, compliance policies.", "timestamp": "00:34:40,880", "timestamp_s": 2080.0}, {"text": "So instead of managing each output, we can automate these tests and get instant", "timestamp": "00:34:42,950", "timestamp_s": 2082.0}, {"text": "evaluation at scale using GE value.", "timestamp": "00:34:46,850", "timestamp_s": 2086.0}, {"text": "This will ensure brand alliance responses without needing a human", "timestamp": "00:34:49,370", "timestamp_s": 2089.0}, {"text": "in the loop every single time.", "timestamp": "00:34:52,880", "timestamp_s": 2092.0}, {"text": "So now let\u0027s look at the, some of the same task prompt evaluated on the GE", "timestamp": "00:34:56,105", "timestamp_s": 2096.0}, {"text": "file and can show pass, fail outcome depending on the wording and the tone.", "timestamp": "00:34:59,525", "timestamp_s": 2099.0}, {"text": "In the left side column, we see AI.", "timestamp": "00:35:03,215", "timestamp_s": 2103.0}, {"text": "Responding correctly in terms of information, but feeling due to which", "timestamp": "00:35:05,780", "timestamp_s": 2105.0}, {"text": "phrases like as a AI language model or a e-commerce assistant, these ed, the", "timestamp": "00:35:09,650", "timestamp_s": 2109.0}, {"text": "grading constraint that we saw earlier.", "timestamp": "00:35:14,810", "timestamp_s": 2114.0}, {"text": "In contrast, the right side column use a very different persona prompt,", "timestamp": "00:35:16,520", "timestamp_s": 2116.0}, {"text": "a smart, bubbly customer service rep, and gives answers that are", "timestamp": "00:35:20,210", "timestamp_s": 2120.0}, {"text": "contextually aligned and brand safe.", "timestamp": "00:35:23,600", "timestamp_s": 2123.0}, {"text": "Thus PAs the evaluation.", "timestamp": "00:35:25,700", "timestamp_s": 2125.0}, {"text": "So this shows how geal is adjusted, judging accuracy, but also behavioral", "timestamp": "00:35:27,490", "timestamp_s": 2127.0}, {"text": "consistency and how even minor prompt engineering choices can", "timestamp": "00:35:31,480", "timestamp_s": 2131.0}, {"text": "flip a result from fail to a pass.", "timestamp": "00:35:34,510", "timestamp_s": 2134.0}, {"text": "So it\u0027s a very important reminder for us that evaluation is not just what is", "timestamp": "00:35:36,910", "timestamp_s": 2136.0}, {"text": "being said, but the way it is being said.", "timestamp": "00:35:40,330", "timestamp_s": 2140.0}, {"text": "So now let\u0027s shift gears and look at how evaluation retrieval argumented", "timestamp": "00:35:44,525", "timestamp_s": 2144.0}, {"text": "generation or REG systems work.", "timestamp": "00:35:48,425", "timestamp_s": 2148.0}, {"text": "So in A REG, which is a retrieval argumented generation", "timestamp": "00:35:50,765", "timestamp_s": 2150.0}, {"text": "pipeline, has two components.", "timestamp": "00:35:53,225", "timestamp_s": 2153.0}, {"text": "A retrieval, which factors relevant context from a knowledge base and", "timestamp": "00:35:54,905", "timestamp_s": 2154.0}, {"text": "a generator, which formulates the final response using that context.", "timestamp": "00:35:57,785", "timestamp_s": 2157.0}, {"text": "So in evaluating REG, it requires looking at both the stages separately.", "timestamp": "00:36:01,835", "timestamp_s": 2161.0}, {"text": "For the retrieval, we use metrics like contextual recall.", "timestamp": "00:36:06,245", "timestamp_s": 2166.0}, {"text": "They data retrieve all the relevant documents and contextual precision,", "timestamp": "00:36:09,125", "timestamp_s": 2169.0}, {"text": "which means whether retrieve document actually useful to us or not.", "timestamp": "00:36:13,115", "timestamp_s": 2173.0}, {"text": "And then we look at generators, which is metric as answer,", "timestamp": "00:36:16,895", "timestamp_s": 2176.0}, {"text": "relevant as the response.", "timestamp": "00:36:19,625", "timestamp_s": 2179.0}, {"text": "Address the user questions and faithfulness.", "timestamp": "00:36:21,185", "timestamp_s": 2181.0}, {"text": "Checks if the output actually sticks to the fact in the retrieved context, this", "timestamp": "00:36:23,830", "timestamp_s": 2183.0}, {"text": "two part evaluation is very essential because a great generator can still", "timestamp": "00:36:28,000", "timestamp_s": 2188.0}, {"text": "hallucinate the retriever fields, and a perfect retriever would not help if", "timestamp": "00:36:31,570", "timestamp_s": 2191.0}, {"text": "the generation steps misinterprets it.", "timestamp": "00:36:35,350", "timestamp_s": 2195.0}, {"text": "So now let me understand the re architecture.", "timestamp": "00:36:39,695", "timestamp_s": 2199.0}, {"text": "Let\u0027s quickly zoom in and see how we actually evaluate the retriever component.", "timestamp": "00:36:41,675", "timestamp_s": 2201.0}, {"text": "We use three very important metrics here, the contextual position.", "timestamp": "00:36:45,265", "timestamp_s": 2205.0}, {"text": "This tells us whether retriever is ranked relevant.", "timestamp": "00:36:48,385", "timestamp_s": 2208.0}, {"text": "Is ranking relevant information higher than in relevant ones, which", "timestamp": "00:36:51,485", "timestamp_s": 2211.0}, {"text": "actually means there\u0027s a higher score, would prioritize the right context.", "timestamp": "00:36:54,845", "timestamp_s": 2214.0}, {"text": "So as you can see, G PT 3.5 performed best with the 92.23% using very basic IG.", "timestamp": "00:36:58,115", "timestamp_s": 2218.0}, {"text": "While multi queries with GPD, it struggles a bit.", "timestamp": "00:37:04,805", "timestamp_s": 2224.0}, {"text": "So showing how query expansion doesn\u0027t always help if not tuned properly.", "timestamp": "00:37:07,775", "timestamp_s": 2227.0}, {"text": "Next very important part is contextual recall.", "timestamp": "00:37:11,435", "timestamp_s": 2231.0}, {"text": "This will check how much relevant information your", "timestamp": "00:37:13,775", "timestamp_s": 2233.0}, {"text": "retriever can actually fetch.", "timestamp": "00:37:15,605", "timestamp_s": 2235.0}, {"text": "Think of it as coverage, alarm to scores, an impress of 90% with basic IEG", "timestamp": "00:37:17,465", "timestamp_s": 2237.0}, {"text": "while again, multi query falls short.", "timestamp": "00:37:22,125", "timestamp_s": 2242.0}, {"text": "A very interesting pattern that we just saw here is RD Fusion", "timestamp": "00:37:24,435", "timestamp_s": 2244.0}, {"text": "with GP PT four, or GPT 3 1 5.", "timestamp": "00:37:27,705", "timestamp_s": 2247.0}, {"text": "In this case also hits 90%, which shows how fusion based approach improves", "timestamp": "00:37:29,835", "timestamp_s": 2249.0}, {"text": "recall through multi retrieval.", "timestamp": "00:37:34,425", "timestamp_s": 2254.0}, {"text": "And then we have contextual relevancy.", "timestamp": "00:37:36,675", "timestamp_s": 2256.0}, {"text": "So this combines both of precision and recall, but it adds a layer of nuance.", "timestamp": "00:37:38,715", "timestamp_s": 2258.0}, {"text": "I was retrieving chunks that are both relevant and not bloated with noise.", "timestamp": "00:37:42,945", "timestamp_s": 2262.0}, {"text": "So RAG fusion with LAMA two leads here with 83.46% follow close following", "timestamp": "00:37:46,575", "timestamp_s": 2266.0}, {"text": "very closely, G PT 3.5 is at 87.22.", "timestamp": "00:37:51,855", "timestamp_s": 2271.0}, {"text": "The Delta fusion approach helps balance precis precision and recall", "timestamp": "00:37:55,305", "timestamp_s": 2275.0}, {"text": "while filtering irrelevant text.", "timestamp": "00:37:58,545", "timestamp_s": 2278.0}, {"text": "So the very important key takeaway is no single metric is enough.", "timestamp": "00:38:00,555", "timestamp_s": 2280.0}, {"text": "You need to monitor all three, especially when choosing between basic", "timestamp": "00:38:04,075", "timestamp_s": 2284.0}, {"text": "multi query and the fusion strategies.", "timestamp": "00:38:07,255", "timestamp_s": 2287.0}, {"text": "So while selecting an LLM, it\u0027s very important.", "timestamp": "00:38:09,145", "timestamp_s": 2289.0}, {"text": "You need to fig figure out these steps as well, like backends, which", "timestamp": "00:38:11,035", "timestamp_s": 2291.0}, {"text": "have elements like GP 3.5 or LA two.", "timestamp": "00:38:14,185", "timestamp_s": 2294.0}, {"text": "So let\u0027s take a closer look at how different evaluation metrics aligns", "timestamp": "00:38:19,785", "timestamp_s": 2299.0}, {"text": "with human judgment across four very key important points, coherence,", "timestamp": "00:38:23,295", "timestamp_s": 2303.0}, {"text": "consistency, fluency, and relevance.", "timestamp": "00:38:27,315", "timestamp_s": 2307.0}, {"text": "So basic what basically what it is seeing is, bench benchmarking, compiles and", "timestamp": "00:38:29,355", "timestamp_s": 2309.0}, {"text": "using two very important correlation statistics, spear zero and NDL tower,", "timestamp": "00:38:33,465", "timestamp_s": 2313.0}, {"text": "both of which relevant is relevant for us to measure how well a metrics scores.", "timestamp": "00:38:38,805", "timestamp_s": 2318.0}, {"text": "Agree with human ratings.", "timestamp": "00:38:43,430", "timestamp_s": 2323.0}, {"text": "We\u0027ll start of course, with something very traditional,", "timestamp": "00:38:45,350", "timestamp_s": 2325.0}, {"text": "Rouge one, Rouge two, and rouge.", "timestamp": "00:38:47,280", "timestamp_s": 2327.0}, {"text": "You\u0027ll notice they consistently perform very poorly, especially on", "timestamp": "00:38:49,350", "timestamp_s": 2329.0}, {"text": "the coherence and fluency because they doesn\u0027t really, can correlate on these.", "timestamp": "00:38:52,290", "timestamp_s": 2332.0}, {"text": "Semantic qualities of generated responses there is focus on engram overlaps.", "timestamp": "00:38:57,285", "timestamp_s": 2337.0}, {"text": "So next we have a set of basic embedding metrics like the bird score or the mover", "timestamp": "00:39:01,605", "timestamp_s": 2341.0}, {"text": "score, which shows these improvements.", "timestamp": "00:39:05,715", "timestamp_s": 2345.0}, {"text": "They still fall short of truly understanding the meaning", "timestamp": "00:39:08,955", "timestamp_s": 2348.0}, {"text": "across diverse responses.", "timestamp": "00:39:11,510", "timestamp_s": 2351.0}, {"text": "But now let\u0027s look at Uni eal.", "timestamp": "00:39:13,085", "timestamp_s": 2353.0}, {"text": "It\u0027s a learning evaluation metric.", "timestamp": "00:39:14,705", "timestamp_s": 2354.0}, {"text": "It performs noticeably better, especially in the coherence.", "timestamp": "00:39:16,295", "timestamp_s": 2356.0}, {"text": "I fluency still, it\u0027s not the top performer of all.", "timestamp": "00:39:19,025", "timestamp_s": 2359.0}, {"text": "The real breakthrough comes from l LM based evaluators like GPT SCORE and geal.", "timestamp": "00:39:22,025", "timestamp_s": 2362.0}, {"text": "Let\u0027s take a look at the score at GE eal.", "timestamp": "00:39:26,855", "timestamp_s": 2366.0}, {"text": "You\u0027re right, so we\u0027ll see.", "timestamp": "00:39:28,535", "timestamp_s": 2368.0}, {"text": "The GE EAL has the high correlation score.", "timestamp": "00:39:30,035", "timestamp_s": 2370.0}, {"text": "It has the strongest overall average score.", "timestamp": "00:39:32,065", "timestamp_s": 2372.0}, {"text": "Point by one, and these all matters because it shows the model cannot", "timestamp": "00:39:34,535", "timestamp_s": 2374.0}, {"text": "evaluate other models in a way.", "timestamp": "00:39:38,005", "timestamp_s": 2378.0}, {"text": "And it is very remarkable.", "timestamp": "00:39:40,435", "timestamp_s": 2380.0}, {"text": "It\u0027s very remarkably close to human reasoning, especially when we prompt", "timestamp": "00:39:42,544", "timestamp_s": 2382.0}, {"text": "them with structural criteria and we enable chain of thought reasoning.", "timestamp": "00:39:45,424", "timestamp_s": 2385.0}, {"text": "So we also, we should also note this, you using probability,", "timestamp": "00:39:49,145", "timestamp_s": 2389.0}, {"text": "you are using chain of thoughts.", "timestamp": "00:39:52,654", "timestamp_s": 2392.0}, {"text": "It performs slightly worse, but combining both of these things", "timestamp": "00:39:54,305", "timestamp_s": 2394.0}, {"text": "gives us really strong signals.", "timestamp": "00:39:57,095", "timestamp_s": 2397.0}, {"text": "So the key takeaway that we have there is gval four with both chain", "timestamp": "00:39:58,955", "timestamp_s": 2398.0}, {"text": "of thought and scoring probabilities currently lead the pack and", "timestamp": "00:40:02,464", "timestamp_s": 2402.0}, {"text": "automating evaluation for elements.", "timestamp": "00:40:05,515", "timestamp_s": 2405.0}, {"text": "So now we see that you know the pipeline for generating synthetic evaluation", "timestamp": "00:40:08,934", "timestamp_s": 2408.0}, {"text": "data sets, especially for retrieval, augmented generation re systems.", "timestamp": "00:40:12,834", "timestamp_s": 2412.0}, {"text": "We begin this by uploading documents that can be in PDF format and", "timestamp": "00:40:17,214", "timestamp_s": 2417.0}, {"text": "docx format, or in any, RX format.", "timestamp": "00:40:20,905", "timestamp_s": 2420.0}, {"text": "These documents are then chunked or broken down into smaller segments.", "timestamp": "00:40:23,065", "timestamp_s": 2423.0}, {"text": "Some chunks may be unqualified, a bit lack useful information, or it is too noisy.", "timestamp": "00:40:25,930", "timestamp_s": 2425.0}, {"text": "Next, we generate contextual frame from disqualified chunks and essentially", "timestamp": "00:40:31,060", "timestamp_s": 2431.0}, {"text": "prepare passages that would serve us as a grounding evidence from those contexts.", "timestamp": "00:40:34,569", "timestamp_s": 2434.0}, {"text": "We now generate goldens.", "timestamp": "00:40:38,500", "timestamp_s": 2438.0}, {"text": "That is gold ground truth, that the answer should ideally produce if it had", "timestamp": "00:40:39,770", "timestamp_s": 2439.0}, {"text": "right access to the right information.", "timestamp": "00:40:44,390", "timestamp_s": 2444.0}, {"text": "Any ambiguous or low quality goldens are discarded and unqualified.", "timestamp": "00:40:46,490", "timestamp_s": 2446.0}, {"text": "Once goldens are finalized, we evolve queries by increasing their complexity", "timestamp": "00:40:50,245", "timestamp_s": 2450.0}, {"text": "and difficulty to stress test the system retrievals and reusing capabilities.", "timestamp": "00:40:54,080", "timestamp_s": 2454.0}, {"text": "The result of this entire pipeline is a synthetic evaluation data sets that can", "timestamp": "00:40:58,760", "timestamp_s": 2458.0}, {"text": "use, that can be used to benchmark both retrieval and generated performance.", "timestamp": "00:41:02,720", "timestamp_s": 2462.0}, {"text": "And very importantly, this processes itrate.", "timestamp": "00:41:06,980", "timestamp_s": 2466.0}, {"text": "We can loop back and forth and define edits and ly improve the dataset.", "timestamp": "00:41:09,650", "timestamp_s": 2469.0}, {"text": "So this kind of synthetic dataset creation allows us to simulate real", "timestamp": "00:41:14,765", "timestamp_s": 2474.0}, {"text": "world scenarios while we maintain full control over evaluation quality.", "timestamp": "00:41:18,125", "timestamp_s": 2478.0}, {"text": "So as we wrap up the discussion on evaluation, let\u0027s quickly go over what", "timestamp": "00:41:23,404", "timestamp_s": 2483.0}, {"text": "practical checklist do we have for building very robust landmark ecosystems?", "timestamp": "00:41:27,725", "timestamp_s": 2487.0}, {"text": "First, we need to clearly identify our objectives.", "timestamp": "00:41:31,415", "timestamp_s": 2491.0}, {"text": "We need to ask what are we measuring?", "timestamp": "00:41:34,625", "timestamp_s": 2494.0}, {"text": "Why are we measuring it?", "timestamp": "00:41:36,665", "timestamp_s": 2496.0}, {"text": "Is it really accurate?", "timestamp": "00:41:37,984", "timestamp_s": 2497.0}, {"text": "We do we need accuracy.", "timestamp": "00:41:39,605", "timestamp_s": 2499.0}, {"text": "Is it factually correct?", "timestamp": "00:41:41,044", "timestamp_s": 2501.0}, {"text": "Is it safe?", "timestamp": "00:41:42,424", "timestamp_s": 2502.0}, {"text": "And so that we could reach on a clear goal that aligns us with our metric and method.", "timestamp": "00:41:43,535", "timestamp_s": 2503.0}, {"text": "Second, develop and diverse evaluation method.", "timestamp": "00:41:48,259", "timestamp_s": 2508.0}, {"text": "Not a one single metric is never going to be enough.", "timestamp": "00:41:51,350", "timestamp_s": 2511.0}, {"text": "We need a mix of automated automatic scoring, human", "timestamp": "00:41:54,200", "timestamp_s": 2514.0}, {"text": "review, and model based grading.", "timestamp": "00:41:56,930", "timestamp_s": 2516.0}, {"text": "Third, you must.", "timestamp": "00:41:59,210", "timestamp_s": 2519.0}, {"text": "Represent, we must create representative data sets.", "timestamp": "00:42:00,450", "timestamp_s": 2520.0}, {"text": "The dataset should represent and reflect the actual complexity and", "timestamp": "00:42:03,400", "timestamp_s": 2523.0}, {"text": "diversity of real world inputs that the model will face during in production.", "timestamp": "00:42:06,610", "timestamp_s": 2526.0}, {"text": "The fourth point is evaluation.", "timestamp": "00:42:11,050", "timestamp_s": 2531.0}, {"text": "That evaluation has to be rated.", "timestamp": "00:42:12,730", "timestamp_s": 2532.0}, {"text": "You can never, I.", "timestamp": "00:42:14,500", "timestamp_s": 2534.0}, {"text": "Have a one chart solution for everything you have to evaluate.", "timestamp": "00:42:16,145", "timestamp_s": 2536.0}, {"text": "As the world, moves forward, you have to evaluate as the data has a drift in it.", "timestamp": "00:42:19,174", "timestamp_s": 2539.0}, {"text": "You have to redefine your test cases, redefine your edge cases, your what", "timestamp": "00:42:23,994", "timestamp_s": 2543.0}, {"text": "causes a failure, what is meant by failure and the user feedback.", "timestamp": "00:42:28,194", "timestamp_s": 2548.0}, {"text": "And then the fifth point is establishing baseline comparison.", "timestamp": "00:42:32,574", "timestamp_s": 2552.0}, {"text": "Always compare your model against the strong baseline.", "timestamp": "00:42:35,214", "timestamp_s": 2555.0}, {"text": "This helps quantify improvement and spot regression early.", "timestamp": "00:42:38,225", "timestamp_s": 2558.0}, {"text": "And finally, we need to leverage AI rate evaluation.", "timestamp": "00:42:41,315", "timestamp_s": 2561.0}, {"text": "We need to use frameworks like Gval, open AI evaluation, or custom LM based", "timestamp": "00:42:45,455", "timestamp_s": 2565.0}, {"text": "grad to scale evaluation efficiently without compromising on that.", "timestamp": "00:42:49,785", "timestamp_s": 2569.0}, {"text": "So if you follow the stick list that helps you move along from ad hoc testing", "timestamp": "00:42:55,695", "timestamp_s": 2575.0}, {"text": "to systematic, defensible, and a scalable solution for the violation process.", "timestamp": "00:42:59,685", "timestamp_s": 2579.0}, {"text": "So now let\u0027s look at a real world scenario, evaluating a", "timestamp": "00:43:05,860", "timestamp_s": 2585.0}, {"text": "customer service AI system.", "timestamp": "00:43:08,410", "timestamp_s": 2588.0}, {"text": "Traditionally, we might have defaulted to blue or rouge", "timestamp": "00:43:10,600", "timestamp_s": 2590.0}, {"text": "scores for the model evaluation.", "timestamp": "00:43:13,570", "timestamp_s": 2593.0}, {"text": "For this use case, it\u0027s not, it\u0027s simply that\u0027s not enough, right?", "timestamp": "00:43:15,310", "timestamp_s": 2595.0}, {"text": "These metrics do not capture the user satisfaction, business", "timestamp": "00:43:19,360", "timestamp_s": 2599.0}, {"text": "outcome, or operational efficiency.", "timestamp": "00:43:22,210", "timestamp_s": 2602.0}, {"text": "So instead, we break down the evaluation into three critical layer first.", "timestamp": "00:43:24,130", "timestamp_s": 2604.0}, {"text": "The technical performance system and assessment, we start with building blocks.", "timestamp": "00:43:28,975", "timestamp_s": 2608.0}, {"text": "It\u0027s so simple as LLU component.", "timestamp": "00:43:32,995", "timestamp_s": 2612.0}, {"text": "How will the system handle the dialogue management and the quality of the", "timestamp": "00:43:35,070", "timestamp_s": 2615.0}, {"text": "response in ratio Here we can still use some LLM focus metrics, but they need", "timestamp": "00:43:38,009", "timestamp_s": 2618.0}, {"text": "to be task aligned in context of error.", "timestamp": "00:43:42,330", "timestamp_s": 2622.0}, {"text": "Second, the shift to customer experience metrics.", "timestamp": "00:43:44,805", "timestamp_s": 2624.0}, {"text": "This is where many AI models stumble.", "timestamp": "00:43:47,775", "timestamp_s": 2627.0}, {"text": "We need to take a look at the actual response team, whether the conversation", "timestamp": "00:43:49,605", "timestamp_s": 2629.0}, {"text": "feels natural, high quality, and how well the system handles follow, especially when", "timestamp": "00:43:52,935", "timestamp_s": 2632.0}, {"text": "multiple turns are needed for evaluation.", "timestamp": "00:43:58,035", "timestamp_s": 2638.0}, {"text": "And finally, the business impact.", "timestamp": "00:44:00,674", "timestamp_s": 2640.0}, {"text": "This is the bottom line.", "timestamp": "00:44:02,564", "timestamp_s": 2642.0}, {"text": "The bottom line of all of these problems are, is the AI", "timestamp": "00:44:04,245", "timestamp_s": 2644.0}, {"text": "improving the conversion rates?", "timestamp": "00:44:06,555", "timestamp_s": 2646.0}, {"text": "Is it actually reducing the resolution time?", "timestamp": "00:44:08,234", "timestamp_s": 2648.0}, {"text": "And most importantly, is it delivering cost savings at scale?", "timestamp": "00:44:10,754", "timestamp_s": 2650.0}, {"text": "So why do we need this evaluation techniques?", "timestamp": "00:44:16,004", "timestamp_s": 2656.0}, {"text": "What do they give us?", "timestamp": "00:44:17,924", "timestamp_s": 2657.0}, {"text": "They give us trustworthy output.", "timestamp": "00:44:19,574", "timestamp_s": 2659.0}, {"text": "They make.", "timestamp": "00:44:21,404", "timestamp_s": 2661.0}, {"text": "Our answers factually correct.", "timestamp": "00:44:22,679", "timestamp_s": 2662.0}, {"text": "They help us catch hallucination early on, even before they reach", "timestamp": "00:44:24,689", "timestamp_s": 2664.0}, {"text": "a user or go into production.", "timestamp": "00:44:28,049", "timestamp_s": 2668.0}, {"text": "We get readable logical answers.", "timestamp": "00:44:29,909", "timestamp_s": 2669.0}, {"text": "By enforcing semantic coherence, we ensure the model response are clear,", "timestamp": "00:44:31,709", "timestamp_s": 2671.0}, {"text": "internally consistent, and actually makes sense like a sounding good, right?", "timestamp": "00:44:35,729", "timestamp_s": 2675.0}, {"text": "The third point is, the techniques brings us strong task alignment.", "timestamp": "00:44:39,899", "timestamp_s": 2679.0}, {"text": "The model doesn\u0027t just respond to you because it has to.", "timestamp": "00:44:43,679", "timestamp_s": 2683.0}, {"text": "It has to focus on the intent of the prompt.", "timestamp": "00:44:46,739", "timestamp_s": 2686.0}, {"text": "It should be no wandering.", "timestamp": "00:44:48,719", "timestamp_s": 2688.0}, {"text": "There should be no going off topic.", "timestamp": "00:44:49,829", "timestamp_s": 2689.0}, {"text": "And then with is we also have a signal to noise control, right?", "timestamp": "00:44:51,960", "timestamp_s": 2691.0}, {"text": "The context precision metrics can penalize irrelevant or irrelevant, or", "timestamp": "00:44:55,170", "timestamp_s": 2695.0}, {"text": "made up information, which helps us trim the fluff and boost, content fidelity.", "timestamp": "00:44:59,040", "timestamp_s": 2699.0}, {"text": "And then finally we get the complete coverage.", "timestamp": "00:45:04,390", "timestamp_s": 2704.0}, {"text": "Context recall, ensure the model captures all the critical facts from the source.", "timestamp": "00:45:06,305", "timestamp_s": 2706.0}, {"text": "So nothing important gets left behind with these evaluation upgrades.", "timestamp": "00:45:10,205", "timestamp_s": 2710.0}, {"text": "We don\u0027t just optimize performance, we optimize trust, clarity, and we", "timestamp": "00:45:13,745", "timestamp_s": 2713.0}, {"text": "have real world reliability right now.", "timestamp": "00:45:17,645", "timestamp_s": 2717.0}, {"text": "So was the real p of all of these new violation methods.", "timestamp": "00:45:22,024", "timestamp_s": 2722.0}, {"text": "It\u0027s this, we now have a multi scorecard, not just a single number or a static", "timestamp": "00:45:25,625", "timestamp_s": 2725.0}, {"text": "metrics, but a fully diagnostic that tells us exactly what to fix.", "timestamp": "00:45:30,695", "timestamp_s": 2730.0}, {"text": "Whether the model is struggling and how we can improve.", "timestamp": "00:45:34,480", "timestamp_s": 2734.0}, {"text": "And here\u0027s the best part.", "timestamp": "00:45:37,900", "timestamp_s": 2737.0}, {"text": "It is not just for academic benchmarking anymore.", "timestamp": "00:45:38,860", "timestamp_s": 2738.0}, {"text": "This approach directly boost real world user satisfaction because the", "timestamp": "00:45:41,260", "timestamp_s": 2741.0}, {"text": "feedback is granular, actionable, and it ties to our actual experience.", "timestamp": "00:45:45,610", "timestamp_s": 2745.0}, {"text": "So in short, better evaluation means better models and better", "timestamp": "00:45:50,440", "timestamp_s": 2750.0}, {"text": "models means happy user.", "timestamp": "00:45:54,250", "timestamp_s": 2754.0}, {"text": "That is the future we\u0027re trying to build with, right?", "timestamp": "00:45:55,690", "timestamp_s": 2755.0}, {"text": "All right folks, so that is a wrap.", "timestamp": "00:46:00,015", "timestamp_s": 2760.0}, {"text": "Thank you so much for listening to us, and feel free to contact us if", "timestamp": "00:46:02,379", "timestamp_s": 2762.0}, {"text": "you have any of your evaluation needs that you need or you want to work on.", "timestamp": "00:46:06,069", "timestamp_s": 2766.0}, {"text": "If you are any specific use cases that you want the evaluation frameworks", "timestamp": "00:46:10,299", "timestamp_s": 2770.0}, {"text": "to support you or any kind of AA problems, we\u0027re happy to help you out.", "timestamp": "00:46:13,990", "timestamp_s": 2773.0}, {"text": "Thank you for listening in.", "timestamp": "00:46:17,830", "timestamp_s": 2777.0}, {"text": "Have a good day.", "timestamp": "00:46:19,540", "timestamp_s": 2779.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'Q4iyw1miXaY',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Beyond BLEU and ROUGE — Modern Approaches to Evaluating LLMs and AI Systems
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Traditional metrics like BLEU and ROUGE fall short in capturing advanced LLM capabilities. In this talk, discover modern methods—from benchmarks like MMLU and TruthfulQA to real-world evaluations and human-in-the-loop insights—that better assess AI performance. Join us to rethink AI evaluation—now!</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/ml2025_Alok_Ranjan.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:01,440'); seek(1.0)">
              Hello everyone and welcome to our session here at Con 42.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:06,660'); seek(6.0)">
              Today we are diving into a crucial but often overlooked aspect of working with
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:12,480'); seek(12.0)">
              large language models and AI systems.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:16,050'); seek(16.0)">
              How do we evaluate the meaningfully traditional metrics like Blue and Rouge?
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:22,170'); seek(22.0)">
              Were a good starting point, but as AI systems grow more powerful
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:27,270'); seek(27.0)">
              and complex, we need smarter.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:29,910'); seek(29.0)">
              More human-centric approaches to truly measure their effectiveness.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:34,710'); seek(34.0)">
              So in this talk, we'll explore what's beyond blue and rules, how the evaluation
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:41,010'); seek(41.0)">
              landscape is evolving, and what modern techniques are emerging to keep pace
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:46,350'); seek(46.0)">
              with rapid advancement in generative ai.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:49,780'); seek(49.0)">
              Before we dive deeper into our presentation, let me give.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:54,370'); seek(54.0)">
              A quick introduction about ourselves.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:56,800'); seek(56.0)">
              I'm aloen, currently leading engineering at Dropbox, where I work on storage
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:01,900'); seek(61.0)">
              systems, scalable infrastructure, and the AI ML platforms that powers
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:06,970'); seek(66.0)">
              some of our internal tooling.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:09,070'); seek(69.0)">
              I completed my masters from Carnegie Mellon University, and much of
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:13,000'); seek(73.0)">
              my work today involves balancing performance, observability, and scale.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:18,910'); seek(78.0)">
              And I'm, I work as a applied AI engineer.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:22,300'); seek(82.0)">
              I build scalable machine learning solutions which
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:24,640'); seek(84.0)">
              focus on real world impact.
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:26,350'); seek(86.0)">
              I specialize in working in education technology.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:29,380'); seek(89.0)">
              My current focus lies in distributed machine learning and the world of
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:33,971'); seek(93.0)">
              agent ai, where I'm trying to create systems that doesn't just respond to
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:37,030'); seek(97.0)">
              you, but it keeps reasoning and adapt.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:39,820'); seek(99.0)">
              So together, me and Alo, we bring a shared passion for making AI
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:43,300'); seek(103.0)">
              systems not just smarter, but more accountable and more measurable.
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:47,600'); seek(107.0)">
              Let's begin with a simple scenario.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:50,150'); seek(110.0)">
              Imagine you're a part of a startup launching an AI powered
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:53,810'); seek(113.0)">
              customer service chat bot.
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:56,120'); seek(116.0)">
              Sounds familiar, right?
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:57,950'); seek(117.0)">
              It's a classic use case, automate support, cut costs, and improved response times.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:04,850'); seek(124.0)">
              Now think about what your customers expect from this chat bot.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:09,380'); seek(129.0)">
              It's not just about answering queries.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:11,870'); seek(131.0)">
              They want answers that are fast, relevant, and feel human.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:17,390'); seek(137.0)">
              So how do you evaluate whether your model is doing a good job?
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:21,820'); seek(141.0)">
              This is where the problem begins.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:23,920'); seek(143.0)">
              We can't rely solely on word overlap or rigid rules.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:28,870'); seek(148.0)">
              We need to measure effectiveness across three key dimensions.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:32,725'); seek(152.0)">
              Accuracy.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:34,135'); seek(154.0)">
              Is the information factually correct?
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:36,865'); seek(156.0)">
              Usability is the response phrased in a way the user can understand and act on.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:43,135'); seek(163.0)">
              And reliability does.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:45,055'); seek(165.0)">
              The system performs consistently across different user inputs,
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:49,225'); seek(169.0)">
              context, and each cases.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:51,955'); seek(171.0)">
              This sets the foundation for why we need to go beyond traditional metrics.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:56,845'); seek(176.0)">
              It's no longer just about language similarity.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:00,010'); seek(180.0)">
              It's about actual performance, trust and impact.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:05,590'); seek(185.0)">
              Now that we have set the stage, let's define what we are actually aiming to
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:10,000'); seek(190.0)">
              evaluate when it comes to AI systems, especially large language models.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:16,240'); seek(196.0)">
              Traditionally, we have been good at measuring things like grammar
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:20,080'); seek(200.0)">
              or overlap with reference answers.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:22,585'); seek(202.0)">
              But today's AI systems operate in open-ended real world context, so we
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:27,985'); seek(207.0)">
              need a much richer set of objectives.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:30,955'); seek(210.0)">
              Here is what we believe.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:32,515'); seek(212.0)">
              Every modern evaluation framework should aim to capture first accuracy.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:38,875'); seek(218.0)">
              This one's obvious.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:40,255'); seek(220.0)">
              The AI should get facts right.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:42,625'); seek(222.0)">
              A model generating confident but wrong information is dangerous, not useful.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:48,295'); seek(228.0)">
              Second bias mitigation.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:51,025'); seek(231.0)">
              We want systems that generate inclusive and fair outputs, and that means actively
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:57,055'); seek(237.0)">
              identifying and minimizing harmful stereotypes or skewed viewpoints.
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:02,785'); seek(242.0)">
              Third coherence, it's not enough for an answer to be correct.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:07,225'); seek(247.0)">
              It needs to make sense in the flow of a conversation.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:11,145'); seek(251.0)">
              This is Es especially critical for applications like tutoring.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:15,135'); seek(255.0)">
              Therapy or customer service.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:17,745'); seek(257.0)">
              And finally, reliability.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:19,905'); seek(259.0)">
              The AI should perform consistently across different prompts, languages,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:24,915'); seek(264.0)">
              domains, and even user personas.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:28,155'); seek(268.0)">
              No surprises, no hallucinations, no brittle behavior.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:32,625'); seek(272.0)">
              These four accuracy, fairness, coherence, and reliability together form a much
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:38,985'); seek(278.0)">
              more complete picture of what good AI actually means in the real world.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:44,205'); seek(284.0)">
              And me measuring these effectively is where the challenge begins.
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:50,865'); seek(290.0)">
              Before we talk about what's next, let's take a step back and quickly
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:55,275'); seek(295.0)">
              revisit what Blue and Rules actually are and why they have been so dominant
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:01,155'); seek(301.0)">
              in NLP evaluation for so long.
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:03,975'); seek(303.0)">
              Blue or bilingual evaluation under study is essentially a precision based score.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:10,725'); seek(310.0)">
              It compares the ngrams or short chunk of words in a model's output.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:16,410'); seek(316.0)">
              To those in a reference sentence.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:18,510'); seek(318.0)">
              It's been a staple in machine translation tasks for years.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:23,740'); seek(323.0)">
              Rules on the other hand, is more recall oriented.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:27,730'); seek(327.0)">
              It looks at how much of the reference text is captured in the model's output.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:32,650'); seek(332.0)">
              It's widely used for evaluating summarization, where the goal
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:36,370'); seek(336.0)">
              is to see whether the generated summary includes the important bits.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:41,020'); seek(341.0)">
              Now, why were these metrics adopted so widely?
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:45,040'); seek(345.0)">
              They're fast language agnostic and they don't require any human label data.
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:50,530'); seek(350.0)">
              You can just run them over a corpus and get numeric scores.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:54,760'); seek(354.0)">
              It's clean and scalable.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:57,580'); seek(357.0)">
              But, and here's the catch.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:00,160'); seek(360.0)">
              Just because something is easy to compute doesn't mean it truly
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:03,820'); seek(363.0)">
              captures what quality looks like.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:06,460'); seek(366.0)">
              Blue and Rose don't understand meaning intent tone or factual correctness.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:12,430'); seek(372.0)">
              That's the real gap we need to fill.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:16,450'); seek(376.0)">
              Let's bring this down to earth with a real world example that
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:19,940'); seek(379.0)">
              highlights just how fragile these tradition traditional metrics can be.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:25,760'); seek(385.0)">
              Say we have built a customer support chat bot for an e-commerce store,
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:30,380'); seek(390.0)">
              and the user asks a simple question, what's the size of this jacket?
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:35,510'); seek(395.0)">
              The chat bot response correctly, with just one word, 34.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:40,910'); seek(400.0)">
              That's perfectly valid answer.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:42,890'); seek(402.0)">
              It's concise, accurate, and exactly what the user needs, but here is the catch.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:49,190'); seek(409.0)">
              The blue score for this response is just 0.016.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:54,440'); seek(414.0)">
              That's extremely low and completely misleading.
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:58,190'); seek(418.0)">
              Why?
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:59,240'); seek(419.0)">
              Because Blue is comparing Ngram overlaps with reference sentences
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:03,380'); seek(423.0)">
              like it's XXL, or it's small, or it is 34, and since 34 doesn't share enough
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:10,820'); seek(430.0)">
              bigrams or trigrams with any of these.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:14,495'); seek(434.0)">
              It gets penalized even though it's semantically perfect.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:19,595'); seek(439.0)">
              This is the kind of disconnect that makes blue and ruse unreliable in real
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:24,575'); seek(444.0)">
              dialogue or open domain scenarios.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:27,485'); seek(447.0)">
              They care more about surface level similarity than actual meaning,
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:32,090'); seek(452.0)">
              and if we are not careful, we end up punishing good responses.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:36,755'); seek(456.0)">
              Just because they're phrased differently.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:40,205'); seek(460.0)">
              Here is another example that really drives home the limitation of these
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:44,315'); seek(464.0)">
              surface level metrics like Blue.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:46,925'); seek(466.0)">
              Imagine we are evaluating a chat bot designed to explain HR policies, in
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:52,745'); seek(472.0)">
              this case, remote work guidelines.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:56,165'); seek(476.0)">
              The reference sentence says employees are permitted to work
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:59,585'); seek(479.0)">
              remotely up to three days per week, subject to manager approval.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:04,970'); seek(484.0)">
              The model response with staff members are allowed to telecommute for a
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:09,350'); seek(489.0)">
              maximum of three days, weekly pending approval from their supervisor.
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:14,600'); seek(494.0)">
              Now, pause for a second.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:16,610'); seek(496.0)">
              That response is perfectly accurate.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:19,460'); seek(499.0)">
              It conveys the exact same meaning just using slightly different phrasing, but
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:25,160'); seek(505.0)">
              play it gives this a score of zero.
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:28,550'); seek(508.0)">
              That's right.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:29,270'); seek(509.0)">
              Zero y. Because Blue is looking for direct overlaps, exact words and ngram matches.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:37,604'); seek(517.0)">
              It doesn't understand that staff members and employees mean the same
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:41,804'); seek(521.0)">
              thing, or that supervisor are just managers with a different label.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:46,724'); seek(526.0)">
              This is the core flaw blue and rules semantic equivalence
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:52,155'); seek(532.0)">
              and conversation quality.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:54,435'); seek(534.0)">
              And if we are going to build LMS that actually communicate well,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:58,964'); seek(538.0)">
              we need to evaluate methods.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:09:01,094'); seek(541.0)">
              That reward, meaning not just matching.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:09:06,464'); seek(546.0)">
              Let's take a moment to summarize what we have seen so far about traditional
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:10,785'); seek(550.0)">
              metrics like blue and rules.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:12,915'); seek(552.0)">
              First, both of these metrics are built around n gram oral lab,
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:17,505'); seek(557.0)">
              essentially counting how many words or phrases match between the morals,
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:21,344'); seek(561.0)">
              response and a reference answer.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:24,990'); seek(564.0)">
              This works well with the task.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:26,700'); seek(566.0)">
              Is rigid, like translating a sentence, word for word or
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:30,270'); seek(570.0)">
              summarizing with fixed phrasing.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:32,670'); seek(572.0)">
              And to be fair, blue and rules have excelled in domains like machine
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:37,650'); seek(577.0)">
              translation and text summarization.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:40,140'); seek(580.0)">
              They're efficient, widely adopted, and they helped
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:43,650'); seek(583.0)">
              standardize benchmarks early on.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:47,280'); seek(587.0)">
              But this is the key.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:48,780'); seek(588.0)">
              They completely struggle when it comes to contextual understanding
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:52,650'); seek(592.0)">
              or semantic variation.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:54,780'); seek(594.0)">
              They can't tell if a response makes sense in a conversation or if it's phrased
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:59,700'); seek(599.0)">
              differently, but means the same thing.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:02,670'); seek(602.0)">
              In other words, blue and ruse rewards surface similarity, not actual quality.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:09,000'); seek(609.0)">
              And that's why we need to evolve our evaluation toolkit as our
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:13,200'); seek(613.0)">
              models get more sophisticated.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:17,865'); seek(617.0)">
              So what do we mean when the, when we say Ngram overlap, let's quickly
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:23,625'); seek(623.0)">
              unpack that because it's the foundation of both blue and rules, and ngram
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:28,814'); seek(628.0)">
              is simply a sequence of N words, A one gram, or unigram just means
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:34,155'); seek(634.0)">
              individual words like cat runs or fast.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:38,385'); seek(638.0)">
              A two gram or bi gram is a pair of cons, security words like the cat or
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:43,454'); seek(643.0)">
              runs fast, and a three gram or tri gram combines three words, for example,
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:48,194'); seek(648.0)">
              the black cat or runs very fast.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:51,285'); seek(651.0)">
              The move, the more overlap you gen your generated text has with these
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:56,620'); seek(656.0)">
              kind of sequences from a reference sentence, the higher your blue
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:11:00,824'); seek(660.0)">
              or rose score are going to be.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:11:03,645'); seek(663.0)">
              It's a way to measure fluency.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:05,505'); seek(665.0)">
              And similarity without needing deep understanding, just matching patterns.
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:11,985'); seek(671.0)">
              Now this diagram below shows how we move from basic word representation
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:16,815'); seek(676.0)">
              to increasing contextual complexity from individual overlapping
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:21,525'); seek(681.0)">
              words to longer shared sequences.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:23,835'); seek(683.0)">
              But here is the limitation.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:26,340'); seek(686.0)">
              As we have seen earlier, this structure can completely mis meaning intent,
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:31,620'); seek(691.0)">
              or even factual accuracy if the phrasing is just slightly different.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:36,450'); seek(696.0)">
              So while gram overlap gives us something measurable, it's not the whole picture.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:44,790'); seek(704.0)">
              So now that we have seen what Ngram overlap actually measures,
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:48,960'); seek(708.0)">
              let's talk about why it's not enough for today's AI systems.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:53,475'); seek(713.0)">
              Especially large language models.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:56,895'); seek(716.0)">
              First, it's a surface level measure.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:59,535'); seek(719.0)">
              It doesn't understand what a sentence means.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:12:02,055'); seek(722.0)">
              It just checks.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:12:02,865'); seek(722.0)">
              If the word looks similar, this is fine for basic translation task,
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:07,214'); seek(727.0)">
              but it breaks down when the language gets more flexible or nuanced.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:11,895'); seek(731.0)">
              Second, it's easy to game.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:14,385'); seek(734.0)">
              You can bump up your blue score by repeating parts of the reference answer.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:18,720'); seek(738.0)">
              Or adding boilerplate phrases even if your actual output is poor.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:23,700'); seek(743.0)">
              Third, and this one's huge, it ignores factuality and coherence.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:29,040'); seek(749.0)">
              Your model might say something romantically perfect, but factually
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:32,550'); seek(752.0)">
              wrong, and blue won't catch it.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:35,220'); seek(755.0)">
              Or it might output something semantically spot on, but still get a low score
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:40,290'); seek(760.0)">
              because the phrasing was different.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:42,210'); seek(762.0)">
              And finally, these metrics often penalize longer or more fluent responses.
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:48,390'); seek(768.0)">
              If your model rephrases an idea eloquently or adds context, it can
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:53,610'); seek(773.0)">
              actually hurt the score because the Ngram pattern don't match the reference
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:58,650'); seek(778.0)">
              exactly in short, blue and Ruse gives us a quick answer, but not a deep one.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:13:05,730'); seek(785.0)">
              And with modern lms, that's just not good enough anymore.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:13:12,150'); seek(792.0)">
              So now that we have the, we have seen the limitations of traditional metrics,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:16,500'); seek(796.0)">
              let's shift gears and look at what modern evaluation frameworks actually focuses on.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:22,590'); seek(802.0)">
              Instead of counting word overlaps, these new methods try to assess what
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:27,540'); seek(807.0)">
              really matters in a model's response.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:30,420'); seek(810.0)">
              Qualities that are more aligned with how humans judge quality.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:34,770'); seek(814.0)">
              The first and arguably most important is factual accuracy.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:39,780'); seek(819.0)">
              Is the information actually correct?
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:42,210'); seek(822.0)">
              Especially in domains like healthcare, finance, or education?
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:46,710'); seek(826.0)">
              This isn't just nice to have, it's critical.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:50,370'); seek(830.0)">
              Then we have semantic coherence.
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:52,365'); seek(832.0)">
              Does the response flow well?
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:54,240'); seek(834.0)">
              Is it logically structured and grammatically sound?
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:57,719'); seek(837.0)">
              Or does it feel like a random text bump?
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:14:00,989'); seek(840.0)">
              Next comes answer, relevance.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:14:03,149'); seek(843.0)">
              Does the model stay on topic and directly address the question being asked?
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:14:08,519'); seek(848.0)">
              This is especially important for systems like chatbots, tutors,
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:12,060'); seek(852.0)">
              or customer service tools.
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:14,699'); seek(854.0)">
              We also evaluate context precision.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:16,829'); seek(856.0)">
              Did the model respond with the most accurate detail from
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:20,189'); seek(860.0)">
              the context it was given?
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:21,930'); seek(861.0)">
              And conversely.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:23,384'); seek(863.0)">
              Context recall, did it include all the key elements that were
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:27,854'); seek(867.0)">
              necessary to build a complete answer?
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:30,794'); seek(870.0)">
              Together these dimensions form a far more comprehensive and human aligned way of
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:36,614'); seek(876.0)">
              judging model output, and they are setting the foundation for NextGen AI benchmarks.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:44,354'); seek(884.0)">
              Now let's talk about how we evaluate the factual accuracy of responses
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:48,944'); seek(888.0)">
              using a method called fact score.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:51,569'); seek(891.0)">
              The core idea here is to break down a generated response into atomic facts.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:57,270'); seek(897.0)">
              That is small, standalone pieces of information that
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:15:01,079'); seek(901.0)">
              can be independently verified.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:15:03,839'); seek(903.0)">
              Each atomic fact is then checked against a reliable external knowledge
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:07,949'); seek(907.0)">
              source, like a trusted database.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:10,364'); seek(910.0)">
              Verify document or reference corpus.
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:13,484'); seek(913.0)">
              For example, if the model says the Eiffel Tower is in Paris and it was built in
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:18,374'); seek(918.0)">
              1889, that's two separate atomic facts, and we check each of them individually.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:25,314'); seek(925.0)">
              Once this checking is done, we compute a score based on the proportion of
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:29,425'); seek(929.0)">
              facts that are supported by the source, and that becomes the fact score.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:34,899'); seek(934.0)">
              This approach provides a granular, interpretable view of factual
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:39,699'); seek(939.0)">
              factuality instead of just evaluating the sentence as a whole.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:46,269'); seek(946.0)">
              Alright, let's take a closer look at how factuality evaluation
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:50,540'); seek(950.0)">
              actually works in a practice, especially with model grade systems.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:55,655'); seek(955.0)">
              This approach typically relies on three core inputs.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:58,655'); seek(958.0)">
              The prompt, the output, and reference answer, the first input is the prompt.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:16:04,385'); seek(964.0)">
              That's what we send to the LLM.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:16:06,485'); seek(966.0)">
              It could be a question, a task instruction, or a real work query like
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:16:11,855'); seek(971.0)">
              what is the capital of Switzerland?
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:14,000'); seek(974.0)">
              The second input is the output.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:16,550'); seek(976.0)">
              This is the model's response to that prompt.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:19,550'); seek(979.0)">
              For example, it might say Zurich or Burn, depending on how it was
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:23,780'); seek(983.0)">
              trained or what it retrieved.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:26,270'); seek(986.0)">
              The third component is the reference.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:28,730'); seek(988.0)">
              This is the ideal response that a model should be should have given,
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:32,420'); seek(992.0)">
              and this is typically crafted by the author of the evaluation.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:37,280'); seek(997.0)">
              Usually a human or another trusted system.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:40,895'); seek(1000.0)">
              The factuality check is then done by comparing the model's
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:44,225'); seek(1004.0)">
              output to the reference.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:46,655'); seek(1006.0)">
              Does the answer aligned with the verified facts?
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:49,955'); seek(1009.0)">
              Was the reasoning sound, did it hallucinate or go off topic?
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:55,355'); seek(1015.0)">
              This approach gives us a more targeted lens.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:58,265'); seek(1018.0)">
              We are no longer scoring for linguistic overlap.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:17:01,594'); seek(1021.0)">
              But for truthfulness and correctness.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:17:06,185'); seek(1026.0)">
              Now let's dive into a more advanced model-based approach for evaluating
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:10,715'); seek(1030.0)">
              factuality One that goes far beyond keyword matching or basic overlap.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:17,435'); seek(1037.0)">
              What you are seeing here is a factuality scoring pipeline that leverages
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:22,174'); seek(1042.0)">
              semantic alignment, entailment classification, and weighted aggregation
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:27,755'); seek(1047.0)">
              to generate what's called a fact score.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:30,545'); seek(1050.0)">
              We begin with the input text.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:32,795'); seek(1052.0)">
              We use something like S-B-E-R-T-A sentence Bert model to identify how well the output
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:40,475'); seek(1060.0)">
              semantic aligns with the reference facts.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:43,295'); seek(1063.0)">
              The next step is to break the reference answer into atomic facts.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:47,389'); seek(1067.0)">
              Labeled a one and then possibly reframe or relocate them in
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:51,800'); seek(1071.0)">
              different forms marked as a two.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:55,159'); seek(1075.0)">
              This ensures we are not overly strict about phrasing.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:58,880'); seek(1078.0)">
              Now we introduce NLI classification, natural language inference.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:18:04,250'); seek(1084.0)">
              This checks whether the models output entails, contradicts, or is
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:18:08,720'); seek(1088.0)">
              natural towards each atomic fact.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:18:11,330'); seek(1091.0)">
              This is where the green and red boxes come in.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:18:14,300'); seek(1094.0)">
              Green for support, red for contradiction.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:17,930'); seek(1097.0)">
              Then comes the aggregation phase where all of this gets pulled together.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:22,550'); seek(1102.0)">
              We apply different weights to different fact types.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:25,580'); seek(1105.0)">
              For example, facts classified as a gets a weight of 0.9, whereas
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:30,920'); seek(1110.0)">
              contradictions like D two gets a lower score or even a zero penalty.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:36,500'); seek(1116.0)">
              The final result is a fact score, a weighted structured view of how
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:41,389'); seek(1121.0)">
              factual the LM LMS output really is.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:44,600'); seek(1124.0)">
              It's nuanced, interpretable, and much more robust than traditional method,
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:50,180'); seek(1130.0)">
              and most importantly, this method adapts well across domains and languages.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:55,880'); seek(1135.0)">
              It evaluates not just what the model says, but how well it aligns with the truth.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:19:03,860'); seek(1143.0)">
              Let's now talk about a modern metric that actually goes beyond surface level.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:19:08,239'); seek(1148.0)">
              Word overlaps birth score.
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:19:11,480'); seek(1151.0)">
              Birth score is built on top of contextual embeddings.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:19:14,810'); seek(1154.0)">
              It uses models like Bert to assign vector implantation to each token,
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:19:20,060'); seek(1160.0)">
              not just based on the word itself, but how it is used in context.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:24,920'); seek(1164.0)">
              That's key.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:26,090'); seek(1166.0)">
              In the example below, we have two sentences.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:28,850'); seek(1168.0)">
              The reference says, the weather is cold today.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:31,759'); seek(1171.0)">
              The candidate says it's freezing today.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:34,310'); seek(1174.0)">
              Now, even though there is little direct overlap, a human would agree.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:39,259'); seek(1179.0)">
              These two say almost the same thing.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:42,110'); seek(1182.0)">
              So instead of relying on ngrams, we generate contextual embeddings
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:46,250'); seek(1186.0)">
              for each word using bird.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:48,380'); seek(1188.0)">
              These embeddings capture the meaning of each token in its context.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:53,195'); seek(1193.0)">
              Then we calculate Pairwise co-sign similarity between tokens across the
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:58,295'); seek(1198.0)">
              reference and the candidate sentence.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:20:00,755'); seek(1200.0)">
              From these, we select the best matching pairs, aggregate their similarity
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:20:05,045'); seek(1205.0)">
              scores, and compute a final bird score.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:20:08,225'); seek(1208.0)">
              This gives us a much richer sense of how well the semantic flow is preserved.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:20:12,995'); seek(1212.0)">
              Regardless of wordings.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:15,065'); seek(1215.0)">
              B score excels at evaluating coherence, paraphrasing, and even subtle rephrasing.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:21,080'); seek(1221.0)">
              Areas where blue and rules simply fall short.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:24,469'); seek(1224.0)">
              In other words, B score helps us evaluate what the model means,
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:28,790'); seek(1228.0)">
              not just what word it uses.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:32,989'); seek(1232.0)">
              One of the most critical areas in AI evaluation today is
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:37,190'); seek(1237.0)">
              addressing toxicity and bias.
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:40,040'); seek(1240.0)">
              Why?
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:41,120'); seek(1241.0)">
              Because even a single harmful response from an LLM can damage trust.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:46,114'); seek(1246.0)">
              Safety and inclusivity in the user experience.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:50,385'); seek(1250.0)">
              Bias can creep in from training data, prompt phrasing, or even subtle
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:54,615'); seek(1254.0)">
              model behavior, and without careful evaluation, it often goes undetected.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:21:01,095'); seek(1261.0)">
              To help tackle this, we have tools like Lang Bite, which stands for
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:21:06,555'); seek(1266.0)">
              language bias testing environment.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:21:09,585'); seek(1269.0)">
              Lang Byte works in a systematic and scalable way.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:21:13,065'); seek(1273.0)">
              First, it selects prompt templates from a predefined library, for example,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:18,765'); seek(1278.0)">
              prompts about race, gender, or religion.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:21,375'); seek(1281.0)">
              Then it generates test cases based on these templates.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:25,035'); seek(1285.0)">
              These are structured prompts designed to pro for biased or toxic behavior.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:30,405'); seek(1290.0)">
              Next, it executes those prompts across different LMS and carefully
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:35,205'); seek(1295.0)">
              analyzes the response Finally.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:38,340'); seek(1298.0)">
              It generates insights highlighting areas where the model may have shown bias,
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:43,350'); seek(1303.0)">
              tendencies, either overt or subtle.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:46,890'); seek(1306.0)">
              This lets developers pinpoint specific weakness and re and retrain
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:51,420'); seek(1311.0)">
              or fine tune models to be more inclusive, respectful, and safe.
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:56,460'); seek(1316.0)">
              Bias and toxicity aren't just bugs.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:59,580'); seek(1319.0)">
              They're ethical risks.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:22:01,185'); seek(1321.0)">
              And tools like Lang Byte help us bring transparency and
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:22:04,605'); seek(1324.0)">
              accountability to the space.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:22:07,305'); seek(1327.0)">
              Let's now look at how this evaluation process works.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:22:10,425'); seek(1330.0)">
              In practice using Lang Byte structured pipeline, the flow starts with
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:22:15,435'); seek(1335.0)">
              understanding ethical concerns.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:22:18,045'); seek(1338.0)">
              I. This includes input from sensitive communities and domain experts, which
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:22:22,470'); seek(1342.0)">
              help define what types of harmful or biased behavior we need to test for.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:27,510'); seek(1347.0)">
              This leads to the ethical requirement specification, which creates a formal
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:32,040'); seek(1352.0)">
              model of what needs to be avoided, such as hate, speech, stereotyping, or toxicity.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:39,000'); seek(1359.0)">
              Next, we move to test generation here.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:42,450'); seek(1362.0)">
              We use prompt templates designed to target those ethical concerns.
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:46,665'); seek(1366.0)">
              From these templates, we generate real prompt instances, specific test cases.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:53,145'); seek(1373.0)">
              These prompts are then fed into the L lms.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:55,815'); seek(1375.0)">
              In the test execution phase, the model responses are collected, and
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:23:01,065'); seek(1381.0)">
              these outputs we want to evaluate for signs of toxicity or bias.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:23:06,185'); seek(1386.0)">
              The final step is reporting.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:23:08,240'); seek(1388.0)">
              Here the responses are analyzed using prompt articles or even an evaluator LLM.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:23:14,420'); seek(1394.0)">
              The goal is to interpret the outputs and produce structured evaluation reports.
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:23:19,430'); seek(1399.0)">
              This end-to-end flow ensures that bias detection is not just an afterthought.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:23:24,950'); seek(1404.0)">
              It's built into the system from the ground up, guided by real ethical priorities.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:23:31,970'); seek(1411.0)">
              Despite advances in automated metrics, human judgment remains irreplaceable.
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:37,220'); seek(1417.0)">
              Especially in evaluating tone, coherence, and helpfulness, which
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:23:41,570'); seek(1421.0)">
              current metrics can't always capture.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:44,000'); seek(1424.0)">
              That's why we use Pairwise comparison, where two outputs are shown side by side,
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:49,250'); seek(1429.0)">
              and human judges select the better one.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:53,330'); seek(1433.0)">
              This is more reliable than assigning absolute numeric scores.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:57,200'); seek(1437.0)">
              We then apply probabilistic ranking models like Bradley Terry, or elo.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:24:02,585'); seek(1442.0)">
              To convert these comparisons into meaningful rankings.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:24:06,035'); seek(1446.0)">
              These methods are widely used in platforms like Chat Botina, and they consistently
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:24:11,015'); seek(1451.0)">
              reveal gaps that automated metrics like Blue and Ruse fail to detect.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:24:15,935'); seek(1455.0)">
              In fact, two outputs might score equally in blue, but humans may
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:24:19,925'); seek(1459.0)">
              strongly prefer one over the other due to clarity, style, or tone.
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:24:24,545'); seek(1464.0)">
              So human-centric evaluation.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:24:26,600'); seek(1466.0)">
              Does not just validate models, it helps us uncover what really
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:24:30,350'); seek(1470.0)">
              matters in user experience.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:24:35,390'); seek(1475.0)">
              Let's bring it all together.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:24:37,460'); seek(1477.0)">
              We want, we start with fact verification, breaking model response into atomic facts.
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:43,205'); seek(1483.0)">
              Then verifying each one against trusted sources to generate an accuracy score.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:24:48,455'); seek(1488.0)">
              In parallel, we conduct pairwise comparison, A versus B, C
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:52,205'); seek(1492.0)">
              versus A, where humans simply judge which response is better.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:57,665'); seek(1497.0)">
              Using models like Bradley Terry, these judgments are aggregated
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:25:02,075'); seek(1502.0)">
              into a global ranking offering a probabilistic view of model quality.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:25:06,905'); seek(1506.0)">
              We then compared this human ranking against scores from automated metric.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:25:11,270'); seek(1511.0)">
              To identify where our evaluation system align and more
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:25:15,350'); seek(1515.0)">
              importantly, where they don't.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:25:18,170'); seek(1518.0)">
              Human evaluation are increasingly taking central stage in measuring
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:25:23,090'); seek(1523.0)">
              conversational AI quality, not just contemplating, but also correcting
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:25:28,220'); seek(1528.0)">
              what automated metrics miss.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:25:30,665'); seek(1530.0)">
              With the, with that foundation lay laid, I'll now hand it over
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:25:34,610'); seek(1534.0)">
              to Soro who will take us deeper into how modern metric systems.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:25:38,735'); seek(1538.0)">
              Like gal and real world task evaluations are changing the landscape.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:25:44,885'); seek(1544.0)">
              Alright, let's talk about one of the most promising shifts in
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:25:48,365'); seek(1548.0)">
              evaluation using the l and m itself.
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:25:50,765'); seek(1550.0)">
              As a judge, large language models bring in three very powerful strengths as a result.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:25:56,015'); seek(1556.0)">
              The first is context.
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:57,455'); seek(1557.0)">
              Awareness means they can interpret the nuanced meaning and adapt to the domain.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:26:02,615'); seek(1562.0)">
              Scalability, since they can evaluate massive datasets quickly and very
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:26:06,455'); seek(1566.0)">
              efficiently, and consistency, eliminating the subjectivity and the
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:26:10,595'); seek(1570.0)">
              fatigue human evaluators often bring.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:26:13,205'); seek(1573.0)">
              So here is how it works.
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:26:14,885'); seek(1574.0)">
              A benchmark dataset provides both input.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:26:17,195'); seek(1577.0)">
              Prompts and the correct outputs.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:26:19,265'); seek(1579.0)">
              The L lms, indeed as suggested output, and then using a judge
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:26:22,145'); seek(1582.0)">
              prompt, we ask another LLM, given the input and the correct output.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:26:25,985'); seek(1585.0)">
              Is this the suggested output acceptable to make sure the judge stays reliable?
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:26:30,245'); seek(1590.0)">
              We loop in human experts to assess the S judgment and refine
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:26:34,175'); seek(1594.0)">
              the judge through feedback.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:26:36,035'); seek(1596.0)">
              This feedback loop from LLM response to LM Judgment to export
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:26:39,605'); seek(1599.0)">
              audit, which help us continually improve and the evaluator itself.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:26:44,445'); seek(1604.0)">
              So to wrap up the discussion on evaluation, let's talk
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:26:47,445'); seek(1607.0)">
              about why automated evaluation.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:26:49,200'); seek(1609.0)">
              It is not just helpful, it's very essential.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:52,020'); seek(1612.0)">
              First, it ensures we maintain consistent quality across multiple model versions.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:56,850'); seek(1616.0)">
              Whether we are fine tuning a base model or it trading on prompts, we need
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:27:00,270'); seek(1620.0)">
              stability in how we assess outputs.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:27:02,850'); seek(1622.0)">
              Second, it provides an objective and reproducible performance signal,
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:27:06,450'); seek(1626.0)">
              removing the human bias and the ambiguity from the evaluation loop.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:27:10,340'); seek(1630.0)">
              Third, it enables rapid testing at scale.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:27:13,280'); seek(1633.0)">
              Something manual methods simply cannot match.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:27:15,950'); seek(1635.0)">
              And finally, it supports continuous improvement cycles, which are foundation
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:27:19,760'); seek(1639.0)">
              for the modern ML ops workflows.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:27:24,255'); seek(1644.0)">
              So now that we have seen why automated evaluation matters, let's
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:27:27,495'); seek(1647.0)">
              also to take a look at the key technologies powering the shift.
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:27:31,335'); seek(1651.0)">
              And whenever we talk about lms, the first thing that comes to our mind is
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:27:34,785'); seek(1654.0)">
              open ai, the Open AI Evolve framework.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:27:37,515'); seek(1657.0)">
              This is a standardized way to define and run evaluation on
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:40,995'); seek(1660.0)">
              large language model outputs.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:42,735'); seek(1662.0)">
              It's very extensible, modular, and integrates really well with other
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:45,945'); seek(1665.0)">
              components of the open AI ecosystem.
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:48,675'); seek(1668.0)">
              Then we have GE or generative evaluation.
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:51,165'); seek(1671.0)">
              This goes beyond fixing test cases.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:53,505'); seek(1673.0)">
              It leverages generative prompts to dynamically evaluate model
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:56,535'); seek(1676.0)">
              performance across a variety of tasks.
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:27:59,175'); seek(1679.0)">
              It is especially useful for edge cases or nuance reasoning.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:28:02,835'); seek(1682.0)">
              And then we have REG evaluation frameworks.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:28:05,595'); seek(1685.0)">
              These are specifically tailored for retrieval augmented generation.
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:28:09,315'); seek(1689.0)">
              They're not just assessing the output, but how well the model grounds its answers.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:28:14,010'); seek(1694.0)">
              And retrieving context.
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:28:15,870'); seek(1695.0)">
              So it's about both the what and the why behind the answer.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:28:19,290'); seek(1699.0)">
              And finally, we rely heavily on evaluation data sets or eval sets.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:28:23,880'); seek(1703.0)">
              These include curated prompts, gold standard outputs, and even
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:28:27,120'); seek(1707.0)">
              adversarial examples to rigorously stress test the moral behavior.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:28:31,260'); seek(1711.0)">
              Together, these tools form the backbone of how we benchmark an element scale.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:35,530'); seek(1715.0)">
              So let's dive a bit deeper and see how this prominent tool in this space,
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:39,490'); seek(1719.0)">
              the open AI valve framework works.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:41,500'); seek(1721.0)">
              So this framework allows us to, simplify all of these things, like it helps us
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:28:45,280'); seek(1725.0)">
              to build custom evaluation pipelines.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:28:47,830'); seek(1727.0)">
              It lets us summarize, code generation reasoning and dialogue.
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:28:51,460'); seek(1731.0)">
              But one of the most important strength and standardizing test methodology is
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:55,810'); seek(1735.0)">
              that you can benchmark across models and iterations using consistent.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:59,829'); seek(1739.0)">
              Metrics and it helps ensure reproducibility.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:29:03,069'); seek(1743.0)">
              It's also very natively integrated into the opening dashboard.
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:29:06,159'); seek(1746.0)">
              It makes it very seamless to set up evaluation, view the results,
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:29:09,819'); seek(1749.0)">
              and monitor change over time.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:29:11,439'); seek(1751.0)">
              So if you can see the screenshot below, you can see you can choose from a
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:29:15,219'); seek(1755.0)">
              multiple data sources importing chart completion, uploading a recent NEL
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:29:18,879'); seek(1758.0)">
              file, creating prompts manually, or even building custom evaluation logic.
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:29:22,899'); seek(1762.0)">
              So this flexibility allows team to quickly spin up robust evaluation workflows
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:29:27,249'); seek(1767.0)">
              without even reinventing the wheel.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:30,865'); seek(1770.0)">
              So one of the most powerful aspect of the open AI valve framework is the
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:34,225'); seek(1774.0)">
              flexibility in defining the criteria.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:36,475'); seek(1776.0)">
              So you aren't limited to just accuracy.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:29:38,365'); seek(1778.0)">
              You can choose what matters for your application the most.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:29:41,215'); seek(1781.0)">
              Let's walk through some of this buildin options, right?
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:29:43,315'); seek(1783.0)">
              So you have factuality and semantic similarity, which s assesses whether
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:46,435'); seek(1786.0)">
              the response is both factually correct and align in meaning
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:49,975'); seek(1789.0)">
              with the res reference, answer.
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:51,699'); seek(1791.0)">
              For task that requires more of emotional intelligence, the sentiment evaluation
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:55,239'); seek(1795.0)">
              can flag toxic or very often responses.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:29:58,120'); seek(1798.0)">
              Now, let's say you need structural validation, so we can use schema
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:30:01,840'); seek(1801.0)">
              matching or check with the output is a valid, decent format or XML format.
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:30:05,799'); seek(1805.0)">
              It's basically function calling.
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:30:08,049'); seek(1808.0)">
              So string check and criteria match lets you test the presence
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:30:11,229'); seek(1811.0)">
              or absence of specific tokens or features you can afford.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:13,870'); seek(1813.0)">
              Forbidden freezes or required formats.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:16,330'); seek(1816.0)">
              And if you're building custom metrics, you can define your own logic.
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:20,939'); seek(1820.0)">
              Using the custom prompt option.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:22,339'); seek(1822.0)">
              And finally, if you have the need for the classic, NLP evaluation, there is always
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:30:26,329'); seek(1826.0)">
              this text qualities that supports blue and rouge scores or something as simple
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:30:30,099'); seek(1830.0)">
              as score sign, similarity based scoring.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:30:32,199'); seek(1832.0)">
              So all of these F frame, all of these tools included in the open a L framework.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:35,739'); seek(1835.0)">
              And that is something that we, highly recommend use it.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:39,354'); seek(1839.0)">
              So now let's take it, how easy was it actually for us to run an
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:30:43,049'); seek(1843.0)">
              evaluation test with the open air framework using this one line code?
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:30:46,350'); seek(1846.0)">
              Okay, in this scenario, we were using OI EAL combined, which uses GPD 3.5
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:30:51,749'); seek(1851.0)">
              turbo on the spider SQL benchmarks, and we took a, maximum of 25 samples.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:30:56,939'); seek(1856.0)">
              The framework sends each prompt to the EPI and evaluates the responses in real time.
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:31:01,799'); seek(1861.0)">
              And as you can see in the log it logs every single TTP requires and
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:31:05,069'); seek(1865.0)">
              tracks a progress sample with sample.
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:31:07,259'); seek(1867.0)">
              Once all the samples are processed, pick it a summary of report, in
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:10,709'); seek(1870.0)">
              this case, 20, 20 as responses were correct and five were incorrect.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:14,849'); seek(1874.0)">
              A s giving us a score of 80% accuracy.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:17,519'); seek(1877.0)">
              This output is in saved to these in a log, which makes it very easy
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:20,549'); seek(1880.0)">
              to review, compare across, model, or visualize performance later.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:31:24,149'); seek(1884.0)">
              And the best part about this, it's reproducible, testable, and scalable,
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:29,159'); seek(1889.0)">
              all from a single CLA command.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:33,030'); seek(1893.0)">
              So let's work through a real evaluation sample from the SQL benchmark.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:36,600'); seek(1896.0)">
              Yeah, the prompt of the question here was how many country has a republic
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:31:41,189'); seek(1901.0)">
              as their former for government?
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:31:42,689'); seek(1902.0)">
              So the expected SL query is shown green, select star account from
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:31:46,570'); seek(1906.0)">
              country where the country is a firm of government, which is equal to republic.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:31:50,199'); seek(1910.0)">
              So a precise match using equality.
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:31:51,939'); seek(1911.0)">
              The model submission is in the orange, which use a slightly broad, broader
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:31:55,060'); seek(1915.0)">
              pattern like, like republic, which also matches values like a federal
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:31:59,169'); seek(1919.0)">
              republic system or a Republican system, which actually introduces
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:02,620'); seek(1922.0)">
              some ambiguity in the result.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:04,209'); seek(1924.0)">
              So while the model might technically be correct, in many cases, it's
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:07,449'); seek(1927.0)">
              not aligned with a strict expected output, and this will be flagged
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:32:11,080'); seek(1931.0)">
              as incorrect by the eval framework.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:32:13,170'); seek(1933.0)">
              The small variations help us understand not whether just the
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:16,290'); seek(1936.0)">
              model is right, but how closely it aligns with the exact semantic
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:20,040'); seek(1940.0)">
              and precision, which is especially critical in structured tasks like SQL.
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:32:24,430'); seek(1944.0)">
              So below you can see the next test case queued up.
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:28,180'); seek(1948.0)">
              This happens automatically and repeatedly over the whole data set.
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:32:31,000'); seek(1951.0)">
              So this is how we stress test the model with granular feedback,
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:32:33,940'); seek(1953.0)">
              especially in domain, something, as complex, a structured query.
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:32:38,819'); seek(1958.0)">
              So now we can look.
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:32:40,469'); seek(1960.0)">
              Now let's take a look at GE value short for generative evaluation.
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:32:43,924'); seek(1963.0)">
              It is used as an LLM that evaluates another LL M'S output.
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:32:48,899'); seek(1968.0)">
              So GAL has very simple three steps.
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:32:51,149'); seek(1971.0)">
              First, we define a task.
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:32:53,009'); seek(1973.0)">
              The evaluation criteria.
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:32:54,269'); seek(1974.0)">
              For example, you might ask the model to judge a answer based on
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:32:57,269'); seek(1977.0)">
              the clarity or the correctness.
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:32:59,039'); seek(1979.0)">
              Then the models reads its own evaluation steps using chain of thought reasoning.
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:03,239'); seek(1983.0)">
              This is what gives GE value, structure and explainability.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:06,689'); seek(1986.0)">
              Next, it'll use these steps to analyze the output and produce a detailed judgment.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:11,429'); seek(1991.0)">
              And finally, it applies a structured scoring function.
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:14,219'); seek(1994.0)">
              Usually something that like structure score from the violation text and what.
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:33:20,069'); seek(2000.0)">
              What is a powerful part here is that LLM becomes both the evaluator and the
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:33:24,090'); seek(2004.0)">
              analyst and is very rich, interpretable feedback, not just a random number.
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:33:30,225'); seek(2010.0)">
              So let's take a look at how the GE vial actually applies score
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:33:33,495'); seek(2013.0)">
              and criteria using assertion.
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:33:35,144'); seek(2015.0)">
              So each of these assertion define a specific example and expectation that is
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:33:39,044'); seek(2019.0)">
              set for the large language model output.
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:33:40,995'); seek(2020.0)">
              So in the first one, we are going to use a model graded rubric to ensure
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:33:44,504'); seek(2024.0)">
              the response is not apologetic.
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:33:46,034'); seek(2026.0)">
              Apologetic.
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:33:47,274'); seek(2027.0)">
              This could be used in scenarios where you want the model to answer
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:33:50,125'); seek(2030.0)">
              confidently, like in technical support scenarios or policy decision scenario.
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:33:53,965'); seek(2033.0)">
              Use.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:33:54,745'); seek(2034.0)">
              And in the second use case, we use a factuality check.
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:33:57,485'); seek(2037.0)">
              Verify whether the model output aligns with the specific known fact, like
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:01,445'); seek(2041.0)">
              Sacramento is the capital of California.
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:34:03,785'); seek(2043.0)">
              These assertion provide more modular composable test that can
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:34:07,685'); seek(2047.0)">
              be reused across prompts and tasks.
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:34:09,845'); seek(2049.0)">
              And this is what gives GE valves flexibility.
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:34:12,635'); seek(2052.0)">
              So it's, think of it as a unit test, but for large language models.
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:34:17,720'); seek(2057.0)">
              So here is a practical use case where ge y helps enforce behavior
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:34:21,350'); seek(2061.0)">
              constraints across customer meetings.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:34:23,510'); seek(2063.0)">
              We have taken a common support prompt.
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:34:26,300'); seek(2066.0)">
              And from audit tracking to product recommendation and it attach a very
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:34:29,870'); seek(2069.0)">
              simple grading rule, do not mention that you are an AI chat bot or AI assistant.
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:34:35,390'); seek(2075.0)">
              This is very useful in brand settings.
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:34:37,220'); seek(2077.0)">
              So Anthrop izing the AI in my conflict design choices, tone
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:34:40,880'); seek(2080.0)">
              guidelines, or, compliance policies.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:34:42,950'); seek(2082.0)">
              So instead of managing each output, we can automate these tests and get instant
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:34:46,850'); seek(2086.0)">
              evaluation at scale using GE value.
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:34:49,370'); seek(2089.0)">
              This will ensure brand alliance responses without needing a human
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:34:52,880'); seek(2092.0)">
              in the loop every single time.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:34:56,105'); seek(2096.0)">
              So now let's look at the, some of the same task prompt evaluated on the GE
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:34:59,525'); seek(2099.0)">
              file and can show pass, fail outcome depending on the wording and the tone.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:35:03,215'); seek(2103.0)">
              In the left side column, we see AI.
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:35:05,780'); seek(2105.0)">
              Responding correctly in terms of information, but feeling due to which
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:35:09,650'); seek(2109.0)">
              phrases like as a AI language model or a e-commerce assistant, these ed, the
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:35:14,810'); seek(2114.0)">
              grading constraint that we saw earlier.
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:35:16,520'); seek(2116.0)">
              In contrast, the right side column use a very different persona prompt,
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:35:20,210'); seek(2120.0)">
              a smart, bubbly customer service rep, and gives answers that are
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:35:23,600'); seek(2123.0)">
              contextually aligned and brand safe.
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:35:25,700'); seek(2125.0)">
              Thus PAs the evaluation.
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:35:27,490'); seek(2127.0)">
              So this shows how geal is adjusted, judging accuracy, but also behavioral
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:35:31,480'); seek(2131.0)">
              consistency and how even minor prompt engineering choices can
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:35:34,510'); seek(2134.0)">
              flip a result from fail to a pass.
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:35:36,910'); seek(2136.0)">
              So it's a very important reminder for us that evaluation is not just what is
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:35:40,330'); seek(2140.0)">
              being said, but the way it is being said.
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:35:44,525'); seek(2144.0)">
              So now let's shift gears and look at how evaluation retrieval argumented
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:35:48,425'); seek(2148.0)">
              generation or REG systems work.
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:35:50,765'); seek(2150.0)">
              So in A REG, which is a retrieval argumented generation
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:35:53,225'); seek(2153.0)">
              pipeline, has two components.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:35:54,905'); seek(2154.0)">
              A retrieval, which factors relevant context from a knowledge base and
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:35:57,785'); seek(2157.0)">
              a generator, which formulates the final response using that context.
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:36:01,835'); seek(2161.0)">
              So in evaluating REG, it requires looking at both the stages separately.
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:36:06,245'); seek(2166.0)">
              For the retrieval, we use metrics like contextual recall.
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:36:09,125'); seek(2169.0)">
              They data retrieve all the relevant documents and contextual precision,
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:36:13,115'); seek(2173.0)">
              which means whether retrieve document actually useful to us or not.
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:36:16,895'); seek(2176.0)">
              And then we look at generators, which is metric as answer,
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:36:19,625'); seek(2179.0)">
              relevant as the response.
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:36:21,185'); seek(2181.0)">
              Address the user questions and faithfulness.
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:36:23,830'); seek(2183.0)">
              Checks if the output actually sticks to the fact in the retrieved context, this
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:36:28,000'); seek(2188.0)">
              two part evaluation is very essential because a great generator can still
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:36:31,570'); seek(2191.0)">
              hallucinate the retriever fields, and a perfect retriever would not help if
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:36:35,350'); seek(2195.0)">
              the generation steps misinterprets it.
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:36:39,695'); seek(2199.0)">
              So now let me understand the re architecture.
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:36:41,675'); seek(2201.0)">
              Let's quickly zoom in and see how we actually evaluate the retriever component.
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:36:45,265'); seek(2205.0)">
              We use three very important metrics here, the contextual position.
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:36:48,385'); seek(2208.0)">
              This tells us whether retriever is ranked relevant.
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:36:51,485'); seek(2211.0)">
              Is ranking relevant information higher than in relevant ones, which
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:36:54,845'); seek(2214.0)">
              actually means there's a higher score, would prioritize the right context.
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:36:58,115'); seek(2218.0)">
              So as you can see, G PT 3.5 performed best with the 92.23% using very basic IG.
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:37:04,805'); seek(2224.0)">
              While multi queries with GPD, it struggles a bit.
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:37:07,775'); seek(2227.0)">
              So showing how query expansion doesn't always help if not tuned properly.
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:37:11,435'); seek(2231.0)">
              Next very important part is contextual recall.
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:37:13,775'); seek(2233.0)">
              This will check how much relevant information your
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:37:15,605'); seek(2235.0)">
              retriever can actually fetch.
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:37:17,465'); seek(2237.0)">
              Think of it as coverage, alarm to scores, an impress of 90% with basic IEG
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:37:22,125'); seek(2242.0)">
              while again, multi query falls short.
            </span>
            
            <span id="chunk-591" class="transcript-chunks" onclick="console.log('00:37:24,435'); seek(2244.0)">
              A very interesting pattern that we just saw here is RD Fusion
            </span>
            
            <span id="chunk-592" class="transcript-chunks" onclick="console.log('00:37:27,705'); seek(2247.0)">
              with GP PT four, or GPT 3 1 5.
            </span>
            
            <span id="chunk-593" class="transcript-chunks" onclick="console.log('00:37:29,835'); seek(2249.0)">
              In this case also hits 90%, which shows how fusion based approach improves
            </span>
            
            <span id="chunk-594" class="transcript-chunks" onclick="console.log('00:37:34,425'); seek(2254.0)">
              recall through multi retrieval.
            </span>
            
            <span id="chunk-595" class="transcript-chunks" onclick="console.log('00:37:36,675'); seek(2256.0)">
              And then we have contextual relevancy.
            </span>
            
            <span id="chunk-596" class="transcript-chunks" onclick="console.log('00:37:38,715'); seek(2258.0)">
              So this combines both of precision and recall, but it adds a layer of nuance.
            </span>
            
            <span id="chunk-597" class="transcript-chunks" onclick="console.log('00:37:42,945'); seek(2262.0)">
              I was retrieving chunks that are both relevant and not bloated with noise.
            </span>
            
            <span id="chunk-598" class="transcript-chunks" onclick="console.log('00:37:46,575'); seek(2266.0)">
              So RAG fusion with LAMA two leads here with 83.46% follow close following
            </span>
            
            <span id="chunk-599" class="transcript-chunks" onclick="console.log('00:37:51,855'); seek(2271.0)">
              very closely, G PT 3.5 is at 87.22.
            </span>
            
            <span id="chunk-600" class="transcript-chunks" onclick="console.log('00:37:55,305'); seek(2275.0)">
              The Delta fusion approach helps balance precis precision and recall
            </span>
            
            <span id="chunk-601" class="transcript-chunks" onclick="console.log('00:37:58,545'); seek(2278.0)">
              while filtering irrelevant text.
            </span>
            
            <span id="chunk-602" class="transcript-chunks" onclick="console.log('00:38:00,555'); seek(2280.0)">
              So the very important key takeaway is no single metric is enough.
            </span>
            
            <span id="chunk-603" class="transcript-chunks" onclick="console.log('00:38:04,075'); seek(2284.0)">
              You need to monitor all three, especially when choosing between basic
            </span>
            
            <span id="chunk-604" class="transcript-chunks" onclick="console.log('00:38:07,255'); seek(2287.0)">
              multi query and the fusion strategies.
            </span>
            
            <span id="chunk-605" class="transcript-chunks" onclick="console.log('00:38:09,145'); seek(2289.0)">
              So while selecting an LLM, it's very important.
            </span>
            
            <span id="chunk-606" class="transcript-chunks" onclick="console.log('00:38:11,035'); seek(2291.0)">
              You need to fig figure out these steps as well, like backends, which
            </span>
            
            <span id="chunk-607" class="transcript-chunks" onclick="console.log('00:38:14,185'); seek(2294.0)">
              have elements like GP 3.5 or LA two.
            </span>
            
            <span id="chunk-608" class="transcript-chunks" onclick="console.log('00:38:19,785'); seek(2299.0)">
              So let's take a closer look at how different evaluation metrics aligns
            </span>
            
            <span id="chunk-609" class="transcript-chunks" onclick="console.log('00:38:23,295'); seek(2303.0)">
              with human judgment across four very key important points, coherence,
            </span>
            
            <span id="chunk-610" class="transcript-chunks" onclick="console.log('00:38:27,315'); seek(2307.0)">
              consistency, fluency, and relevance.
            </span>
            
            <span id="chunk-611" class="transcript-chunks" onclick="console.log('00:38:29,355'); seek(2309.0)">
              So basic what basically what it is seeing is, bench benchmarking, compiles and
            </span>
            
            <span id="chunk-612" class="transcript-chunks" onclick="console.log('00:38:33,465'); seek(2313.0)">
              using two very important correlation statistics, spear zero and NDL tower,
            </span>
            
            <span id="chunk-613" class="transcript-chunks" onclick="console.log('00:38:38,805'); seek(2318.0)">
              both of which relevant is relevant for us to measure how well a metrics scores.
            </span>
            
            <span id="chunk-614" class="transcript-chunks" onclick="console.log('00:38:43,430'); seek(2323.0)">
              Agree with human ratings.
            </span>
            
            <span id="chunk-615" class="transcript-chunks" onclick="console.log('00:38:45,350'); seek(2325.0)">
              We'll start of course, with something very traditional,
            </span>
            
            <span id="chunk-616" class="transcript-chunks" onclick="console.log('00:38:47,280'); seek(2327.0)">
              Rouge one, Rouge two, and rouge.
            </span>
            
            <span id="chunk-617" class="transcript-chunks" onclick="console.log('00:38:49,350'); seek(2329.0)">
              You'll notice they consistently perform very poorly, especially on
            </span>
            
            <span id="chunk-618" class="transcript-chunks" onclick="console.log('00:38:52,290'); seek(2332.0)">
              the coherence and fluency because they doesn't really, can correlate on these.
            </span>
            
            <span id="chunk-619" class="transcript-chunks" onclick="console.log('00:38:57,285'); seek(2337.0)">
              Semantic qualities of generated responses there is focus on engram overlaps.
            </span>
            
            <span id="chunk-620" class="transcript-chunks" onclick="console.log('00:39:01,605'); seek(2341.0)">
              So next we have a set of basic embedding metrics like the bird score or the mover
            </span>
            
            <span id="chunk-621" class="transcript-chunks" onclick="console.log('00:39:05,715'); seek(2345.0)">
              score, which shows these improvements.
            </span>
            
            <span id="chunk-622" class="transcript-chunks" onclick="console.log('00:39:08,955'); seek(2348.0)">
              They still fall short of truly understanding the meaning
            </span>
            
            <span id="chunk-623" class="transcript-chunks" onclick="console.log('00:39:11,510'); seek(2351.0)">
              across diverse responses.
            </span>
            
            <span id="chunk-624" class="transcript-chunks" onclick="console.log('00:39:13,085'); seek(2353.0)">
              But now let's look at Uni eal.
            </span>
            
            <span id="chunk-625" class="transcript-chunks" onclick="console.log('00:39:14,705'); seek(2354.0)">
              It's a learning evaluation metric.
            </span>
            
            <span id="chunk-626" class="transcript-chunks" onclick="console.log('00:39:16,295'); seek(2356.0)">
              It performs noticeably better, especially in the coherence.
            </span>
            
            <span id="chunk-627" class="transcript-chunks" onclick="console.log('00:39:19,025'); seek(2359.0)">
              I fluency still, it's not the top performer of all.
            </span>
            
            <span id="chunk-628" class="transcript-chunks" onclick="console.log('00:39:22,025'); seek(2362.0)">
              The real breakthrough comes from l LM based evaluators like GPT SCORE and geal.
            </span>
            
            <span id="chunk-629" class="transcript-chunks" onclick="console.log('00:39:26,855'); seek(2366.0)">
              Let's take a look at the score at GE eal.
            </span>
            
            <span id="chunk-630" class="transcript-chunks" onclick="console.log('00:39:28,535'); seek(2368.0)">
              You're right, so we'll see.
            </span>
            
            <span id="chunk-631" class="transcript-chunks" onclick="console.log('00:39:30,035'); seek(2370.0)">
              The GE EAL has the high correlation score.
            </span>
            
            <span id="chunk-632" class="transcript-chunks" onclick="console.log('00:39:32,065'); seek(2372.0)">
              It has the strongest overall average score.
            </span>
            
            <span id="chunk-633" class="transcript-chunks" onclick="console.log('00:39:34,535'); seek(2374.0)">
              Point by one, and these all matters because it shows the model cannot
            </span>
            
            <span id="chunk-634" class="transcript-chunks" onclick="console.log('00:39:38,005'); seek(2378.0)">
              evaluate other models in a way.
            </span>
            
            <span id="chunk-635" class="transcript-chunks" onclick="console.log('00:39:40,435'); seek(2380.0)">
              And it is very remarkable.
            </span>
            
            <span id="chunk-636" class="transcript-chunks" onclick="console.log('00:39:42,544'); seek(2382.0)">
              It's very remarkably close to human reasoning, especially when we prompt
            </span>
            
            <span id="chunk-637" class="transcript-chunks" onclick="console.log('00:39:45,424'); seek(2385.0)">
              them with structural criteria and we enable chain of thought reasoning.
            </span>
            
            <span id="chunk-638" class="transcript-chunks" onclick="console.log('00:39:49,145'); seek(2389.0)">
              So we also, we should also note this, you using probability,
            </span>
            
            <span id="chunk-639" class="transcript-chunks" onclick="console.log('00:39:52,654'); seek(2392.0)">
              you are using chain of thoughts.
            </span>
            
            <span id="chunk-640" class="transcript-chunks" onclick="console.log('00:39:54,305'); seek(2394.0)">
              It performs slightly worse, but combining both of these things
            </span>
            
            <span id="chunk-641" class="transcript-chunks" onclick="console.log('00:39:57,095'); seek(2397.0)">
              gives us really strong signals.
            </span>
            
            <span id="chunk-642" class="transcript-chunks" onclick="console.log('00:39:58,955'); seek(2398.0)">
              So the key takeaway that we have there is gval four with both chain
            </span>
            
            <span id="chunk-643" class="transcript-chunks" onclick="console.log('00:40:02,464'); seek(2402.0)">
              of thought and scoring probabilities currently lead the pack and
            </span>
            
            <span id="chunk-644" class="transcript-chunks" onclick="console.log('00:40:05,515'); seek(2405.0)">
              automating evaluation for elements.
            </span>
            
            <span id="chunk-645" class="transcript-chunks" onclick="console.log('00:40:08,934'); seek(2408.0)">
              So now we see that you know the pipeline for generating synthetic evaluation
            </span>
            
            <span id="chunk-646" class="transcript-chunks" onclick="console.log('00:40:12,834'); seek(2412.0)">
              data sets, especially for retrieval, augmented generation re systems.
            </span>
            
            <span id="chunk-647" class="transcript-chunks" onclick="console.log('00:40:17,214'); seek(2417.0)">
              We begin this by uploading documents that can be in PDF format and
            </span>
            
            <span id="chunk-648" class="transcript-chunks" onclick="console.log('00:40:20,905'); seek(2420.0)">
              docx format, or in any, RX format.
            </span>
            
            <span id="chunk-649" class="transcript-chunks" onclick="console.log('00:40:23,065'); seek(2423.0)">
              These documents are then chunked or broken down into smaller segments.
            </span>
            
            <span id="chunk-650" class="transcript-chunks" onclick="console.log('00:40:25,930'); seek(2425.0)">
              Some chunks may be unqualified, a bit lack useful information, or it is too noisy.
            </span>
            
            <span id="chunk-651" class="transcript-chunks" onclick="console.log('00:40:31,060'); seek(2431.0)">
              Next, we generate contextual frame from disqualified chunks and essentially
            </span>
            
            <span id="chunk-652" class="transcript-chunks" onclick="console.log('00:40:34,569'); seek(2434.0)">
              prepare passages that would serve us as a grounding evidence from those contexts.
            </span>
            
            <span id="chunk-653" class="transcript-chunks" onclick="console.log('00:40:38,500'); seek(2438.0)">
              We now generate goldens.
            </span>
            
            <span id="chunk-654" class="transcript-chunks" onclick="console.log('00:40:39,770'); seek(2439.0)">
              That is gold ground truth, that the answer should ideally produce if it had
            </span>
            
            <span id="chunk-655" class="transcript-chunks" onclick="console.log('00:40:44,390'); seek(2444.0)">
              right access to the right information.
            </span>
            
            <span id="chunk-656" class="transcript-chunks" onclick="console.log('00:40:46,490'); seek(2446.0)">
              Any ambiguous or low quality goldens are discarded and unqualified.
            </span>
            
            <span id="chunk-657" class="transcript-chunks" onclick="console.log('00:40:50,245'); seek(2450.0)">
              Once goldens are finalized, we evolve queries by increasing their complexity
            </span>
            
            <span id="chunk-658" class="transcript-chunks" onclick="console.log('00:40:54,080'); seek(2454.0)">
              and difficulty to stress test the system retrievals and reusing capabilities.
            </span>
            
            <span id="chunk-659" class="transcript-chunks" onclick="console.log('00:40:58,760'); seek(2458.0)">
              The result of this entire pipeline is a synthetic evaluation data sets that can
            </span>
            
            <span id="chunk-660" class="transcript-chunks" onclick="console.log('00:41:02,720'); seek(2462.0)">
              use, that can be used to benchmark both retrieval and generated performance.
            </span>
            
            <span id="chunk-661" class="transcript-chunks" onclick="console.log('00:41:06,980'); seek(2466.0)">
              And very importantly, this processes itrate.
            </span>
            
            <span id="chunk-662" class="transcript-chunks" onclick="console.log('00:41:09,650'); seek(2469.0)">
              We can loop back and forth and define edits and ly improve the dataset.
            </span>
            
            <span id="chunk-663" class="transcript-chunks" onclick="console.log('00:41:14,765'); seek(2474.0)">
              So this kind of synthetic dataset creation allows us to simulate real
            </span>
            
            <span id="chunk-664" class="transcript-chunks" onclick="console.log('00:41:18,125'); seek(2478.0)">
              world scenarios while we maintain full control over evaluation quality.
            </span>
            
            <span id="chunk-665" class="transcript-chunks" onclick="console.log('00:41:23,404'); seek(2483.0)">
              So as we wrap up the discussion on evaluation, let's quickly go over what
            </span>
            
            <span id="chunk-666" class="transcript-chunks" onclick="console.log('00:41:27,725'); seek(2487.0)">
              practical checklist do we have for building very robust landmark ecosystems?
            </span>
            
            <span id="chunk-667" class="transcript-chunks" onclick="console.log('00:41:31,415'); seek(2491.0)">
              First, we need to clearly identify our objectives.
            </span>
            
            <span id="chunk-668" class="transcript-chunks" onclick="console.log('00:41:34,625'); seek(2494.0)">
              We need to ask what are we measuring?
            </span>
            
            <span id="chunk-669" class="transcript-chunks" onclick="console.log('00:41:36,665'); seek(2496.0)">
              Why are we measuring it?
            </span>
            
            <span id="chunk-670" class="transcript-chunks" onclick="console.log('00:41:37,984'); seek(2497.0)">
              Is it really accurate?
            </span>
            
            <span id="chunk-671" class="transcript-chunks" onclick="console.log('00:41:39,605'); seek(2499.0)">
              We do we need accuracy.
            </span>
            
            <span id="chunk-672" class="transcript-chunks" onclick="console.log('00:41:41,044'); seek(2501.0)">
              Is it factually correct?
            </span>
            
            <span id="chunk-673" class="transcript-chunks" onclick="console.log('00:41:42,424'); seek(2502.0)">
              Is it safe?
            </span>
            
            <span id="chunk-674" class="transcript-chunks" onclick="console.log('00:41:43,535'); seek(2503.0)">
              And so that we could reach on a clear goal that aligns us with our metric and method.
            </span>
            
            <span id="chunk-675" class="transcript-chunks" onclick="console.log('00:41:48,259'); seek(2508.0)">
              Second, develop and diverse evaluation method.
            </span>
            
            <span id="chunk-676" class="transcript-chunks" onclick="console.log('00:41:51,350'); seek(2511.0)">
              Not a one single metric is never going to be enough.
            </span>
            
            <span id="chunk-677" class="transcript-chunks" onclick="console.log('00:41:54,200'); seek(2514.0)">
              We need a mix of automated automatic scoring, human
            </span>
            
            <span id="chunk-678" class="transcript-chunks" onclick="console.log('00:41:56,930'); seek(2516.0)">
              review, and model based grading.
            </span>
            
            <span id="chunk-679" class="transcript-chunks" onclick="console.log('00:41:59,210'); seek(2519.0)">
              Third, you must.
            </span>
            
            <span id="chunk-680" class="transcript-chunks" onclick="console.log('00:42:00,450'); seek(2520.0)">
              Represent, we must create representative data sets.
            </span>
            
            <span id="chunk-681" class="transcript-chunks" onclick="console.log('00:42:03,400'); seek(2523.0)">
              The dataset should represent and reflect the actual complexity and
            </span>
            
            <span id="chunk-682" class="transcript-chunks" onclick="console.log('00:42:06,610'); seek(2526.0)">
              diversity of real world inputs that the model will face during in production.
            </span>
            
            <span id="chunk-683" class="transcript-chunks" onclick="console.log('00:42:11,050'); seek(2531.0)">
              The fourth point is evaluation.
            </span>
            
            <span id="chunk-684" class="transcript-chunks" onclick="console.log('00:42:12,730'); seek(2532.0)">
              That evaluation has to be rated.
            </span>
            
            <span id="chunk-685" class="transcript-chunks" onclick="console.log('00:42:14,500'); seek(2534.0)">
              You can never, I.
            </span>
            
            <span id="chunk-686" class="transcript-chunks" onclick="console.log('00:42:16,145'); seek(2536.0)">
              Have a one chart solution for everything you have to evaluate.
            </span>
            
            <span id="chunk-687" class="transcript-chunks" onclick="console.log('00:42:19,174'); seek(2539.0)">
              As the world, moves forward, you have to evaluate as the data has a drift in it.
            </span>
            
            <span id="chunk-688" class="transcript-chunks" onclick="console.log('00:42:23,994'); seek(2543.0)">
              You have to redefine your test cases, redefine your edge cases, your what
            </span>
            
            <span id="chunk-689" class="transcript-chunks" onclick="console.log('00:42:28,194'); seek(2548.0)">
              causes a failure, what is meant by failure and the user feedback.
            </span>
            
            <span id="chunk-690" class="transcript-chunks" onclick="console.log('00:42:32,574'); seek(2552.0)">
              And then the fifth point is establishing baseline comparison.
            </span>
            
            <span id="chunk-691" class="transcript-chunks" onclick="console.log('00:42:35,214'); seek(2555.0)">
              Always compare your model against the strong baseline.
            </span>
            
            <span id="chunk-692" class="transcript-chunks" onclick="console.log('00:42:38,225'); seek(2558.0)">
              This helps quantify improvement and spot regression early.
            </span>
            
            <span id="chunk-693" class="transcript-chunks" onclick="console.log('00:42:41,315'); seek(2561.0)">
              And finally, we need to leverage AI rate evaluation.
            </span>
            
            <span id="chunk-694" class="transcript-chunks" onclick="console.log('00:42:45,455'); seek(2565.0)">
              We need to use frameworks like Gval, open AI evaluation, or custom LM based
            </span>
            
            <span id="chunk-695" class="transcript-chunks" onclick="console.log('00:42:49,785'); seek(2569.0)">
              grad to scale evaluation efficiently without compromising on that.
            </span>
            
            <span id="chunk-696" class="transcript-chunks" onclick="console.log('00:42:55,695'); seek(2575.0)">
              So if you follow the stick list that helps you move along from ad hoc testing
            </span>
            
            <span id="chunk-697" class="transcript-chunks" onclick="console.log('00:42:59,685'); seek(2579.0)">
              to systematic, defensible, and a scalable solution for the violation process.
            </span>
            
            <span id="chunk-698" class="transcript-chunks" onclick="console.log('00:43:05,860'); seek(2585.0)">
              So now let's look at a real world scenario, evaluating a
            </span>
            
            <span id="chunk-699" class="transcript-chunks" onclick="console.log('00:43:08,410'); seek(2588.0)">
              customer service AI system.
            </span>
            
            <span id="chunk-700" class="transcript-chunks" onclick="console.log('00:43:10,600'); seek(2590.0)">
              Traditionally, we might have defaulted to blue or rouge
            </span>
            
            <span id="chunk-701" class="transcript-chunks" onclick="console.log('00:43:13,570'); seek(2593.0)">
              scores for the model evaluation.
            </span>
            
            <span id="chunk-702" class="transcript-chunks" onclick="console.log('00:43:15,310'); seek(2595.0)">
              For this use case, it's not, it's simply that's not enough, right?
            </span>
            
            <span id="chunk-703" class="transcript-chunks" onclick="console.log('00:43:19,360'); seek(2599.0)">
              These metrics do not capture the user satisfaction, business
            </span>
            
            <span id="chunk-704" class="transcript-chunks" onclick="console.log('00:43:22,210'); seek(2602.0)">
              outcome, or operational efficiency.
            </span>
            
            <span id="chunk-705" class="transcript-chunks" onclick="console.log('00:43:24,130'); seek(2604.0)">
              So instead, we break down the evaluation into three critical layer first.
            </span>
            
            <span id="chunk-706" class="transcript-chunks" onclick="console.log('00:43:28,975'); seek(2608.0)">
              The technical performance system and assessment, we start with building blocks.
            </span>
            
            <span id="chunk-707" class="transcript-chunks" onclick="console.log('00:43:32,995'); seek(2612.0)">
              It's so simple as LLU component.
            </span>
            
            <span id="chunk-708" class="transcript-chunks" onclick="console.log('00:43:35,070'); seek(2615.0)">
              How will the system handle the dialogue management and the quality of the
            </span>
            
            <span id="chunk-709" class="transcript-chunks" onclick="console.log('00:43:38,009'); seek(2618.0)">
              response in ratio Here we can still use some LLM focus metrics, but they need
            </span>
            
            <span id="chunk-710" class="transcript-chunks" onclick="console.log('00:43:42,330'); seek(2622.0)">
              to be task aligned in context of error.
            </span>
            
            <span id="chunk-711" class="transcript-chunks" onclick="console.log('00:43:44,805'); seek(2624.0)">
              Second, the shift to customer experience metrics.
            </span>
            
            <span id="chunk-712" class="transcript-chunks" onclick="console.log('00:43:47,775'); seek(2627.0)">
              This is where many AI models stumble.
            </span>
            
            <span id="chunk-713" class="transcript-chunks" onclick="console.log('00:43:49,605'); seek(2629.0)">
              We need to take a look at the actual response team, whether the conversation
            </span>
            
            <span id="chunk-714" class="transcript-chunks" onclick="console.log('00:43:52,935'); seek(2632.0)">
              feels natural, high quality, and how well the system handles follow, especially when
            </span>
            
            <span id="chunk-715" class="transcript-chunks" onclick="console.log('00:43:58,035'); seek(2638.0)">
              multiple turns are needed for evaluation.
            </span>
            
            <span id="chunk-716" class="transcript-chunks" onclick="console.log('00:44:00,674'); seek(2640.0)">
              And finally, the business impact.
            </span>
            
            <span id="chunk-717" class="transcript-chunks" onclick="console.log('00:44:02,564'); seek(2642.0)">
              This is the bottom line.
            </span>
            
            <span id="chunk-718" class="transcript-chunks" onclick="console.log('00:44:04,245'); seek(2644.0)">
              The bottom line of all of these problems are, is the AI
            </span>
            
            <span id="chunk-719" class="transcript-chunks" onclick="console.log('00:44:06,555'); seek(2646.0)">
              improving the conversion rates?
            </span>
            
            <span id="chunk-720" class="transcript-chunks" onclick="console.log('00:44:08,234'); seek(2648.0)">
              Is it actually reducing the resolution time?
            </span>
            
            <span id="chunk-721" class="transcript-chunks" onclick="console.log('00:44:10,754'); seek(2650.0)">
              And most importantly, is it delivering cost savings at scale?
            </span>
            
            <span id="chunk-722" class="transcript-chunks" onclick="console.log('00:44:16,004'); seek(2656.0)">
              So why do we need this evaluation techniques?
            </span>
            
            <span id="chunk-723" class="transcript-chunks" onclick="console.log('00:44:17,924'); seek(2657.0)">
              What do they give us?
            </span>
            
            <span id="chunk-724" class="transcript-chunks" onclick="console.log('00:44:19,574'); seek(2659.0)">
              They give us trustworthy output.
            </span>
            
            <span id="chunk-725" class="transcript-chunks" onclick="console.log('00:44:21,404'); seek(2661.0)">
              They make.
            </span>
            
            <span id="chunk-726" class="transcript-chunks" onclick="console.log('00:44:22,679'); seek(2662.0)">
              Our answers factually correct.
            </span>
            
            <span id="chunk-727" class="transcript-chunks" onclick="console.log('00:44:24,689'); seek(2664.0)">
              They help us catch hallucination early on, even before they reach
            </span>
            
            <span id="chunk-728" class="transcript-chunks" onclick="console.log('00:44:28,049'); seek(2668.0)">
              a user or go into production.
            </span>
            
            <span id="chunk-729" class="transcript-chunks" onclick="console.log('00:44:29,909'); seek(2669.0)">
              We get readable logical answers.
            </span>
            
            <span id="chunk-730" class="transcript-chunks" onclick="console.log('00:44:31,709'); seek(2671.0)">
              By enforcing semantic coherence, we ensure the model response are clear,
            </span>
            
            <span id="chunk-731" class="transcript-chunks" onclick="console.log('00:44:35,729'); seek(2675.0)">
              internally consistent, and actually makes sense like a sounding good, right?
            </span>
            
            <span id="chunk-732" class="transcript-chunks" onclick="console.log('00:44:39,899'); seek(2679.0)">
              The third point is, the techniques brings us strong task alignment.
            </span>
            
            <span id="chunk-733" class="transcript-chunks" onclick="console.log('00:44:43,679'); seek(2683.0)">
              The model doesn't just respond to you because it has to.
            </span>
            
            <span id="chunk-734" class="transcript-chunks" onclick="console.log('00:44:46,739'); seek(2686.0)">
              It has to focus on the intent of the prompt.
            </span>
            
            <span id="chunk-735" class="transcript-chunks" onclick="console.log('00:44:48,719'); seek(2688.0)">
              It should be no wandering.
            </span>
            
            <span id="chunk-736" class="transcript-chunks" onclick="console.log('00:44:49,829'); seek(2689.0)">
              There should be no going off topic.
            </span>
            
            <span id="chunk-737" class="transcript-chunks" onclick="console.log('00:44:51,960'); seek(2691.0)">
              And then with is we also have a signal to noise control, right?
            </span>
            
            <span id="chunk-738" class="transcript-chunks" onclick="console.log('00:44:55,170'); seek(2695.0)">
              The context precision metrics can penalize irrelevant or irrelevant, or
            </span>
            
            <span id="chunk-739" class="transcript-chunks" onclick="console.log('00:44:59,040'); seek(2699.0)">
              made up information, which helps us trim the fluff and boost, content fidelity.
            </span>
            
            <span id="chunk-740" class="transcript-chunks" onclick="console.log('00:45:04,390'); seek(2704.0)">
              And then finally we get the complete coverage.
            </span>
            
            <span id="chunk-741" class="transcript-chunks" onclick="console.log('00:45:06,305'); seek(2706.0)">
              Context recall, ensure the model captures all the critical facts from the source.
            </span>
            
            <span id="chunk-742" class="transcript-chunks" onclick="console.log('00:45:10,205'); seek(2710.0)">
              So nothing important gets left behind with these evaluation upgrades.
            </span>
            
            <span id="chunk-743" class="transcript-chunks" onclick="console.log('00:45:13,745'); seek(2713.0)">
              We don't just optimize performance, we optimize trust, clarity, and we
            </span>
            
            <span id="chunk-744" class="transcript-chunks" onclick="console.log('00:45:17,645'); seek(2717.0)">
              have real world reliability right now.
            </span>
            
            <span id="chunk-745" class="transcript-chunks" onclick="console.log('00:45:22,024'); seek(2722.0)">
              So was the real p of all of these new violation methods.
            </span>
            
            <span id="chunk-746" class="transcript-chunks" onclick="console.log('00:45:25,625'); seek(2725.0)">
              It's this, we now have a multi scorecard, not just a single number or a static
            </span>
            
            <span id="chunk-747" class="transcript-chunks" onclick="console.log('00:45:30,695'); seek(2730.0)">
              metrics, but a fully diagnostic that tells us exactly what to fix.
            </span>
            
            <span id="chunk-748" class="transcript-chunks" onclick="console.log('00:45:34,480'); seek(2734.0)">
              Whether the model is struggling and how we can improve.
            </span>
            
            <span id="chunk-749" class="transcript-chunks" onclick="console.log('00:45:37,900'); seek(2737.0)">
              And here's the best part.
            </span>
            
            <span id="chunk-750" class="transcript-chunks" onclick="console.log('00:45:38,860'); seek(2738.0)">
              It is not just for academic benchmarking anymore.
            </span>
            
            <span id="chunk-751" class="transcript-chunks" onclick="console.log('00:45:41,260'); seek(2741.0)">
              This approach directly boost real world user satisfaction because the
            </span>
            
            <span id="chunk-752" class="transcript-chunks" onclick="console.log('00:45:45,610'); seek(2745.0)">
              feedback is granular, actionable, and it ties to our actual experience.
            </span>
            
            <span id="chunk-753" class="transcript-chunks" onclick="console.log('00:45:50,440'); seek(2750.0)">
              So in short, better evaluation means better models and better
            </span>
            
            <span id="chunk-754" class="transcript-chunks" onclick="console.log('00:45:54,250'); seek(2754.0)">
              models means happy user.
            </span>
            
            <span id="chunk-755" class="transcript-chunks" onclick="console.log('00:45:55,690'); seek(2755.0)">
              That is the future we're trying to build with, right?
            </span>
            
            <span id="chunk-756" class="transcript-chunks" onclick="console.log('00:46:00,015'); seek(2760.0)">
              All right folks, so that is a wrap.
            </span>
            
            <span id="chunk-757" class="transcript-chunks" onclick="console.log('00:46:02,379'); seek(2762.0)">
              Thank you so much for listening to us, and feel free to contact us if
            </span>
            
            <span id="chunk-758" class="transcript-chunks" onclick="console.log('00:46:06,069'); seek(2766.0)">
              you have any of your evaluation needs that you need or you want to work on.
            </span>
            
            <span id="chunk-759" class="transcript-chunks" onclick="console.log('00:46:10,299'); seek(2770.0)">
              If you are any specific use cases that you want the evaluation frameworks
            </span>
            
            <span id="chunk-760" class="transcript-chunks" onclick="console.log('00:46:13,990'); seek(2773.0)">
              to support you or any kind of AA problems, we're happy to help you out.
            </span>
            
            <span id="chunk-761" class="transcript-chunks" onclick="console.log('00:46:17,830'); seek(2777.0)">
              Thank you for listening in.
            </span>
            
            <span id="chunk-762" class="transcript-chunks" onclick="console.log('00:46:19,540'); seek(2779.0)">
              Have a good day.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Alok%20Ranjan%20%26%20Saurabh%20Suman%20-%20Conf42%20Machine%20Learning%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Alok%20Ranjan%20%26%20Saurabh%20Suman%20-%20Conf42%20Machine%20Learning%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 136 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Alok%20Ranjan%20%26%20Saurabh%20Suman_ml.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Alok Ranjan
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Engineering Manager @ Dropbox
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/alok-g-ranjan/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Alok Ranjan's LinkedIn account" />
                  </a>
                  
                  
                </p>
                
                <!-- Author 2 -->
                <h2 class="me-2">
                  Saurabh Suman
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Instructional Student Assistant @ San José State University
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-8">
                  
                  <a href="https://www.linkedin.com/in/saurabhsuman25/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Saurabh Suman's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Alok Ranjan"
                  data-url="https://www.conf42.com/ml2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4 justify-content-center">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Access to all content</b>
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe for FREE<i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2026
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2026">
                  DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2026">
                  Machine Learning 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2026">
                  Site Reliability Engineering (SRE) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2026">
                  Cloud Native 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2026">
                  Golang 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/dbd2026">
                  Database DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2026">
                  Large Language Models (LLMs) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2026">
                  Observability 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/agents2026">
                  AI Agents 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2026">
                  DevSecOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2026">
                  Prompt Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2026">
                  Platform Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2026">
                  MLOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2026">
                  Chaos Engineering 2026
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>