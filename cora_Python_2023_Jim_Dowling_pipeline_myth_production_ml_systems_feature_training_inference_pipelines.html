<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: The machine learning pipeline is a myth - build production ML systems with feature/training/inference pipelines</title>
    <meta name="description" content="Get inspired by fellow Pythonistas, Snakes and Pandas united!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/python_jim_dowling.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="The machine learning pipeline is a myth - build production ML systems with feature/training/inference pipelines | Conf42"/>
    <meta property="og:description" content="Developers often erroneously talk about ML pipelines. But real-world ML systems have many moving components, not a single monolithic ML pipeline. In this talk, we show how to build ML systems as a composition of feature pipelines, training pipelines, and inference pipelines with a shared data layer."/>
    <meta property="og:url" content="https://conf42.com/Python_2023_Jim_Dowling_pipeline_myth_production_ml_systems_feature_training_inference_pipelines"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PYTHON2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Python 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-02-29
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/python2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/aiml2024">
                            Artificial Intelligence & Machine Learning (AI & ML)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.sreday.com/">
                            SREday London
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/DnyHgrC7jC" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #69811f;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Python 2023 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Get inspired by fellow Pythonistas, Snakes and Pandas united!
 -->
              <script>
                const event_date = new Date("2023-03-09T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2023-03-09T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "nQR3fz1KD3g"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "1NPgN91FrPU"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrAQvOGI7luETNU9nsDlXeT1" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, welcome to this talk on the mythical machine learning", "timestamp": "00:00:24,410", "timestamp_s": 24.0}, {"text": "pipeline. My name\u0027s Jim Dowling, and I\u0027m going to talk about", "timestamp": "00:00:28,684", "timestamp_s": 28.0}, {"text": "how we can refactor this monolithic machine learning pipeline that many", "timestamp": "00:00:32,988", "timestamp_s": 32.0}, {"text": "of you may have heard about before into what we call", "timestamp": "00:00:36,924", "timestamp_s": 36.0}, {"text": "feature training and inference pipelines. We\u0027re going to do it all in Python,", "timestamp": "00:00:40,316", "timestamp_s": 40.0}, {"text": "and we\u0027re going to decompose the machine learning pipelines into", "timestamp": "00:00:44,114", "timestamp_s": 44.0}, {"text": "these smaller, more manageable parts to build machine learning systems.", "timestamp": "00:00:48,188", "timestamp_s": 48.0}, {"text": "So I\u0027m going to start by making a claim that mlops, or machine", "timestamp": "00:00:52,930", "timestamp_s": 52.0}, {"text": "learning operations as it exists today, is too hard. It\u0027s kind", "timestamp": "00:00:56,874", "timestamp_s": 56.0}, {"text": "of like this telecom tower here. It\u0027s a very brittle set", "timestamp": "00:01:00,084", "timestamp_s": 60.0}, {"text": "of systems that we\u0027re plugging together to try and put machine learning at production.", "timestamp": "00:01:03,492", "timestamp_s": 63.0}, {"text": "But really it\u0027s too complex to make anything which is", "timestamp": "00:01:07,950", "timestamp_s": 67.0}, {"text": "going to be either easy for developers and in particular python", "timestamp": "00:01:11,368", "timestamp_s": 71.0}, {"text": "developers to put in production or for people to", "timestamp": "00:01:14,718", "timestamp_s": 74.0}, {"text": "maintain. So if we look at mlops according to Google on", "timestamp": "00:01:18,248", "timestamp_s": 78.0}, {"text": "this diagram, we can see here a lot of boxes. So this notion that you", "timestamp": "00:01:21,852", "timestamp_s": 81.0}, {"text": "start at data and you go through many stages of processing the", "timestamp": "00:01:25,772", "timestamp_s": 85.0}, {"text": "data, validating it, preparing it, training models, validating models,", "timestamp": "00:01:29,488", "timestamp_s": 89.0}, {"text": "and all of this happens in one big, monolithic,", "timestamp": "00:01:33,478", "timestamp_s": 93.0}, {"text": "orchestrated ML pipeline. I\u0027m going to show you that", "timestamp": "00:01:36,550", "timestamp_s": 96.0}, {"text": "we don\u0027t need to do it that way. Databricks are following a similar", "timestamp": "00:01:40,128", "timestamp_s": 100.0}, {"text": "pattern for how to encourage people to what they", "timestamp": "00:01:43,860", "timestamp_s": 103.0}, {"text": "say is follow Mlox best practice.", "timestamp": "00:01:47,412", "timestamp_s": 107.0}, {"text": "I see this really as being an overcomplication of something which is much", "timestamp": "00:01:51,090", "timestamp_s": 111.0}, {"text": "easier to do, which is just to build machine learning systems", "timestamp": "00:01:54,792", "timestamp_s": 114.0}, {"text": "and do it to the principles of decomposing complexity and", "timestamp": "00:01:58,790", "timestamp_s": 118.0}, {"text": "then putting those parts together again. And for ML ops", "timestamp": "00:02:02,728", "timestamp_s": 122.0}, {"text": "in particular, which is really about building systems", "timestamp": "00:02:05,998", "timestamp_s": 125.0}, {"text": "that we can incrementally improve and automatically test", "timestamp": "00:02:09,634", "timestamp_s": 129.0}, {"text": "and version and so on, we don\u0027t need to go down to the infrastructure", "timestamp": "00:02:13,292", "timestamp_s": 133.0}, {"text": "level, we can stay in Python. That\u0027s one of the key points I want to", "timestamp": "00:02:17,058", "timestamp_s": 137.0}, {"text": "make here. You don\u0027t need to become a dockers or a Kubernetes expert", "timestamp": "00:02:19,744", "timestamp_s": 139.0}, {"text": "in order to do ML ops.", "timestamp": "00:02:23,718", "timestamp_s": 143.0}, {"text": "This is classic tensorflow extended. This is what", "timestamp": "00:02:28,110", "timestamp_s": 148.0}, {"text": "many people learn in courses that they take in machine learning operations,", "timestamp": "00:02:31,712", "timestamp_s": 151.0}, {"text": "that you need to go from the very beginning to the very end in one", "timestamp": "00:02:35,546", "timestamp_s": 155.0}, {"text": "big m to ML pipeline. So machine learning pipeline,", "timestamp": "00:02:38,836", "timestamp_s": 158.0}, {"text": "I say it\u0027s mythical, because in practice, I\u0027ve never seen", "timestamp": "00:02:42,874", "timestamp_s": 162.0}, {"text": "an end to end pipeline written like this. Where the data comes", "timestamp": "00:02:46,120", "timestamp_s": 166.0}, {"text": "in, it\u0027s validated, transformed into features,", "timestamp": "00:02:49,352", "timestamp_s": 169.0}, {"text": "models are trained, models are analyzed, then they\u0027re validated,", "timestamp": "00:02:53,070", "timestamp_s": 173.0}, {"text": "and then they\u0027re served all in one big monolithic directed", "timestamp": "00:02:57,006", "timestamp_s": 177.0}, {"text": "acyclic graph. That\u0027s not typically the way it works. And the", "timestamp": "00:03:01,038", "timestamp_s": 181.0}, {"text": "reason why it doesn\u0027t work like that is because monolithic ML", "timestamp": "00:03:04,588", "timestamp_s": 184.0}, {"text": "pipelines, they couple different natural stages", "timestamp": "00:03:07,986", "timestamp_s": 187.0}, {"text": "of machine learning systems. So you have what\u0027s called", "timestamp": "00:03:12,278", "timestamp_s": 192.0}, {"text": "feature engineering, where we take the raw data and turn it into the data,", "timestamp": "00:03:15,472", "timestamp_s": 195.0}, {"text": "the features that we\u0027re going to use to train models, but also", "timestamp": "00:03:19,136", "timestamp_s": 199.0}, {"text": "to make predictions with. Now, if you couple that phase", "timestamp": "00:03:22,212", "timestamp_s": 202.0}, {"text": "with the model training phase, training might require", "timestamp": "00:03:25,642", "timestamp_s": 205.0}, {"text": "gpus. If you\u0027re using deep learning, feature engineering does not require", "timestamp": "00:03:29,402", "timestamp_s": 209.0}, {"text": "gpus. You put it all into one large system,", "timestamp": "00:03:33,322", "timestamp_s": 213.0}, {"text": "and then suddenly you\u0027re using maybe gpus for feature engineering,", "timestamp": "00:03:36,520", "timestamp_s": 216.0}, {"text": "which is quite wasteful in terms of resources. If your feature engineering", "timestamp": "00:03:39,758", "timestamp_s": 219.0}, {"text": "is done once a day, because your new data arrives every day, but you", "timestamp": "00:03:43,678", "timestamp_s": 223.0}, {"text": "need to predict every hour, why would you couple those two things together?", "timestamp": "00:03:46,968", "timestamp_s": 226.0}, {"text": "Inference should not be coupled to feature engineering when they run at", "timestamp": "00:03:50,588", "timestamp_s": 230.0}, {"text": "different cadences. By coupling them all together, you\u0027re adding development", "timestamp": "00:03:54,108", "timestamp_s": 234.0}, {"text": "and operational complexity. You\u0027re also not reusing any", "timestamp": "00:03:58,214", "timestamp_s": 238.0}, {"text": "of the data or features that have been created by your", "timestamp": "00:04:02,432", "timestamp_s": 242.0}, {"text": "feature pipelines, and it\u0027s too hard to build", "timestamp": "00:04:05,808", "timestamp_s": 245.0}, {"text": "these systems in such a way to get to a minimal viable product.", "timestamp": "00:04:08,912", "timestamp_s": 248.0}, {"text": "I\u0027ll give you an example of one, Kubeflow pipelines, just to pick on one", "timestamp": "00:04:12,512", "timestamp_s": 252.0}, {"text": "could have picked on many different systems. They claim on their website", "timestamp": "00:04:16,436", "timestamp_s": 256.0}, {"text": "that it enables you to reuse components and pipelines", "timestamp": "00:04:20,372", "timestamp_s": 260.0}, {"text": "quickly, easily, to create end to end solutions", "timestamp": "00:04:24,190", "timestamp_s": 264.0}, {"text": "without having to rebuild each time. I\u0027ve never seen this happen in practice.", "timestamp": "00:04:27,982", "timestamp_s": 267.0}, {"text": "So mlops, we still want to follow", "timestamp": "00:04:31,990", "timestamp_s": 271.0}, {"text": "the principles of mlops, and that means testing your software.", "timestamp": "00:04:36,056", "timestamp_s": 276.0}, {"text": "And you can think of it as being a hierarchy of needs. You have raw", "timestamp": "00:04:40,098", "timestamp_s": 280.0}, {"text": "data which needs to be tested to create features. Features are", "timestamp": "00:04:43,698", "timestamp_s": 283.0}, {"text": "used to create models, so the features need to be tested in order to create", "timestamp": "00:04:47,308", "timestamp_s": 287.0}, {"text": "the models, and the models need to be tested in", "timestamp": "00:04:50,588", "timestamp_s": 290.0}, {"text": "order to use them by the ML enabled applications. And typically your ML", "timestamp": "00:04:54,128", "timestamp_s": 294.0}, {"text": "enabled application will want to a b test a model before it then uses", "timestamp": "00:04:58,246", "timestamp_s": 298.0}, {"text": "and switches over to a new version of a model. But that\u0027s where we want", "timestamp": "00:05:02,582", "timestamp_s": 302.0}, {"text": "to get on the top of the pyramid of needs, if we will,", "timestamp": "00:05:06,228", "timestamp_s": 306.0}, {"text": "for mlops. But we need to start somewhere. And the place", "timestamp": "00:05:10,228", "timestamp_s": 310.0}, {"text": "to start, as any software developer will tell you, is with", "timestamp": "00:05:13,332", "timestamp_s": 313.0}, {"text": "a working system. And in this case we\u0027re building a machine learning system. So we", "timestamp": "00:05:16,452", "timestamp_s": 316.0}, {"text": "need to get to a working machine learning system as quickly as possible.", "timestamp": "00:05:19,848", "timestamp_s": 319.0}, {"text": "And that means we need to have some code which will create the features", "timestamp": "00:05:23,496", "timestamp_s": 323.0}, {"text": "we need to have some code to train the model, and we need to have", "timestamp": "00:05:27,262", "timestamp_s": 327.0}, {"text": "some code to make predictions or inference on new data that", "timestamp": "00:05:30,284", "timestamp_s": 330.0}, {"text": "arrives using our model. So ML", "timestamp": "00:05:33,548", "timestamp_s": 333.0}, {"text": "Ops as a set of principles helps you to get through", "timestamp": "00:05:37,218", "timestamp_s": 337.0}, {"text": "a working system as quickly as possible with a baseline and", "timestamp": "00:05:40,748", "timestamp_s": 340.0}, {"text": "iteratively improve it. And the reason why you should be able to iteratively improve", "timestamp": "00:05:44,112", "timestamp_s": 344.0}, {"text": "your software, if you\u0027re following DevOps or ML Ops principles,", "timestamp": "00:05:47,558", "timestamp_s": 347.0}, {"text": "is that you\u0027re testing. We\u0027re testing the features, the models,", "timestamp": "00:05:50,662", "timestamp_s": 350.0}, {"text": "and we\u0027re versioning the features and models. So if we\u0027re going to do upgrades,", "timestamp": "00:05:54,794", "timestamp_s": 354.0}, {"text": "if we\u0027re going to deploy a new model that\u0027s connected to some new features,", "timestamp": "00:05:58,698", "timestamp_s": 358.0}, {"text": "if they\u0027re both not versioned, we\u0027ll have a terrible time", "timestamp": "00:06:02,618", "timestamp_s": 362.0}, {"text": "connecting those two things together and ensuring that things can be safely upgraded.", "timestamp": "00:06:06,344", "timestamp_s": 366.0}, {"text": "So once you have testing and versioning in place for", "timestamp": "00:06:10,398", "timestamp_s": 370.0}, {"text": "the two main assets that we see in machine learning systems, features and models,", "timestamp": "00:06:13,992", "timestamp_s": 373.0}, {"text": "then you\u0027re able to move quickly, you\u0027re able to make small changes", "timestamp": "00:06:18,514", "timestamp_s": 378.0}, {"text": "and improve your iteration speed, and you\u0027re testing your", "timestamp": "00:06:22,700", "timestamp_s": 382.0}, {"text": "models and you\u0027re testing your features. So you\u0027re improving the quality of your software,", "timestamp": "00:06:26,412", "timestamp_s": 386.0}, {"text": "and that\u0027s ultimately where you want to get to where you can move more quickly,", "timestamp": "00:06:30,162", "timestamp_s": 390.0}, {"text": "make small changes to iteratively improve your systems,", "timestamp": "00:06:33,600", "timestamp_s": 393.0}, {"text": "and be confident that the changes that you make will not break everything.", "timestamp": "00:06:37,142", "timestamp_s": 397.0}, {"text": "So that\u0027s the goal of Mlops, and that\u0027s what we as developers would", "timestamp": "00:06:41,232", "timestamp_s": 401.0}, {"text": "like to use to make our code better. Let\u0027s jump", "timestamp": "00:06:44,868", "timestamp_s": 404.0}, {"text": "into ML Ops. In Python, we\u0027re not going to use infrastructure.", "timestamp": "00:06:48,714", "timestamp_s": 408.0}, {"text": "There\u0027ll be no docker or Kubernetes or we\u0027re not", "timestamp": "00:06:52,154", "timestamp_s": 412.0}, {"text": "going to talk cloud infrastructure. We\u0027re going to talk about the way", "timestamp": "00:06:55,684", "timestamp_s": 415.0}, {"text": "in which we advocate, and particularly I advocate for structuring these", "timestamp": "00:06:59,128", "timestamp_s": 419.0}, {"text": "machine learning systems to make it easier to manage them.", "timestamp": "00:07:02,760", "timestamp_s": 422.0}, {"text": "So what we typically have are these three main components, the feature pipeline,", "timestamp": "00:07:05,896", "timestamp_s": 425.0}, {"text": "the training pipeline, the inference pipeline. I call this the FTI", "timestamp": "00:07:10,322", "timestamp_s": 430.0}, {"text": "pattern to make it easier to remember you have one program. In this", "timestamp": "00:07:14,226", "timestamp_s": 434.0}, {"text": "case, we\u0027re looking to look at Python programs, which takes data from our", "timestamp": "00:07:18,188", "timestamp_s": 438.0}, {"text": "data sources. This program will be typically an operational program,", "timestamp": "00:07:21,468", "timestamp_s": 441.0}, {"text": "so it might need to be scheduled. It could be airflow if it\u0027s Python,", "timestamp": "00:07:24,896", "timestamp_s": 444.0}, {"text": "or it could be a Python program that\u0027s scheduled to run", "timestamp": "00:07:27,910", "timestamp_s": 447.0}, {"text": "in the cloud. So there\u0027s some pretty nice tooling out there, like modal,", "timestamp": "00:07:31,348", "timestamp_s": 451.0}, {"text": "who allow you to schedule these Python programs", "timestamp": "00:07:34,826", "timestamp_s": 454.0}, {"text": "with a cron like hourly run or daily", "timestamp": "00:07:41,090", "timestamp_s": 461.0}, {"text": "run. And those programs are basically going to read your", "timestamp": "00:07:45,102", "timestamp_s": 465.0}, {"text": "raw data, compute, features. If you\u0027ve got supervised", "timestamp": "00:07:49,032", "timestamp_s": 469.0}, {"text": "machine learning, you may need to create labels as well. And rather than", "timestamp": "00:07:52,558", "timestamp_s": 472.0}, {"text": "store that data in an object store or in a distributed file", "timestamp": "00:07:56,152", "timestamp_s": 476.0}, {"text": "system, we\u0027re going to look at a feature store as a way", "timestamp": "00:08:00,018", "timestamp_s": 480.0}, {"text": "to store that data. And that\u0027s because the feature store will provide", "timestamp": "00:08:03,388", "timestamp_s": 483.0}, {"text": "us with a very nice data frame API. Much feature engineering and feature", "timestamp": "00:08:06,572", "timestamp_s": 486.0}, {"text": "pipelines are written in frameworks like pandas. If you need more performance,", "timestamp": "00:08:10,098", "timestamp_s": 490.0}, {"text": "you might move to polars. If you have a lot of data, you might move", "timestamp": "00:08:14,182", "timestamp_s": 494.0}, {"text": "to Pyspark. But the output of all of", "timestamp": "00:08:16,928", "timestamp_s": 496.0}, {"text": "those is a data frame. So if you can write that data frame, and you", "timestamp": "00:08:20,288", "timestamp_s": 500.0}, {"text": "can obviously do that in a secure manner. So we\u0027ll use API keys.", "timestamp": "00:08:24,388", "timestamp_s": 504.0}, {"text": "For example, when we write to Hopsworks, then you don\u0027t", "timestamp": "00:08:28,378", "timestamp_s": 508.0}, {"text": "have to worry about the complexity of if you\u0027re in a cloud environment,", "timestamp": "00:08:32,154", "timestamp_s": 512.0}, {"text": "getting access to a particular bucket, an IAM role that gives", "timestamp": "00:08:35,386", "timestamp_s": 515.0}, {"text": "you permissions to do that. It\u0027s basically going to be an", "timestamp": "00:08:38,888", "timestamp_s": 518.0}, {"text": "API key, some privileges associated with it, and then write", "timestamp": "00:08:42,232", "timestamp_s": 522.0}, {"text": "your data frame. So your training pipeline should be able to use the", "timestamp": "00:08:45,528", "timestamp_s": 525.0}, {"text": "feature store in the same way. We\u0027ll be able to say, okay,", "timestamp": "00:08:48,604", "timestamp_s": 528.0}, {"text": "I\u0027m going to select features from all of the available features,", "timestamp": "00:08:51,628", "timestamp_s": 531.0}, {"text": "create some training data, select labels as well, train my", "timestamp": "00:08:55,266", "timestamp_s": 535.0}, {"text": "model, and when my model has been trained, I\u0027ll need to store it somewhere.", "timestamp": "00:08:59,372", "timestamp_s": 539.0}, {"text": "So typically where we would store models is in some place called a model registry.", "timestamp": "00:09:02,182", "timestamp_s": 542.0}, {"text": "There are many model registries out there, some of them are hosted", "timestamp": "00:09:06,118", "timestamp_s": 546.0}, {"text": "over the Internet. Hopsteryx is also hosted over the Internet.", "timestamp": "00:09:09,318", "timestamp_s": 549.0}, {"text": "We can call that serverless model registry or serverless feature store.", "timestamp": "00:09:12,742", "timestamp_s": 552.0}, {"text": "But it basically means at least when you\u0027re getting started, you can write", "timestamp": "00:09:16,610", "timestamp_s": 556.0}, {"text": "a python program on your laptop or in colab, and it", "timestamp": "00:09:19,988", "timestamp_s": 559.0}, {"text": "can read from a feature store and write your model back into a model", "timestamp": "00:09:23,556", "timestamp_s": 563.0}, {"text": "registry. So Hopsrix also is a model registry. We\u0027ll look at that later.", "timestamp": "00:09:27,476", "timestamp_s": 567.0}, {"text": "And then finally, when you have an inference pipeline, this is when you want to", "timestamp": "00:09:31,270", "timestamp_s": 571.0}, {"text": "generate value for your model. And this is where most machine learning courses", "timestamp": "00:09:34,424", "timestamp_s": 574.0}, {"text": "stop. They\u0027ll train a model they\u0027ll evaluate on a static", "timestamp": "00:09:37,938", "timestamp_s": 577.0}, {"text": "test set. So a holdout data set to see how the", "timestamp": "00:09:43,650", "timestamp_s": 583.0}, {"text": "model generalizes on data it hasn\u0027t seen before, which is", "timestamp": "00:09:46,844", "timestamp_s": 586.0}, {"text": "great. But if you want to see your model in the natural environment where", "timestamp": "00:09:50,012", "timestamp_s": 590.0}, {"text": "it\u0027s creating value, you should write an end to end system", "timestamp": "00:09:54,048", "timestamp_s": 594.0}, {"text": "so that new data can come in through the feature pipelines. And for a batch", "timestamp": "00:09:57,248", "timestamp_s": 597.0}, {"text": "inference application it can take that new data that\u0027s been written via", "timestamp": "00:10:00,982", "timestamp_s": 600.0}, {"text": "the feature pipeline. Read it up as features, read up the model from the", "timestamp": "00:10:04,458", "timestamp_s": 604.0}, {"text": "model registry, generate the predictions, and store them somewhere", "timestamp": "00:10:07,988", "timestamp_s": 607.0}, {"text": "where maybe a downstream dashboard or an operational", "timestamp": "00:10:12,074", "timestamp_s": 612.0}, {"text": "system will consume those production to make those applications", "timestamp": "00:10:15,630", "timestamp_s": 615.0}, {"text": "AI enabled. Of course, this generates logs. You typically want to save", "timestamp": "00:10:19,182", "timestamp_s": 619.0}, {"text": "those to help improve your observability and monitoring of the system.", "timestamp": "00:10:22,856", "timestamp_s": 622.0}, {"text": "So I\u0027m going to look at a little demo later on. The code is available", "timestamp": "00:10:27,450", "timestamp_s": 627.0}, {"text": "on the link below. It\u0027s basically", "timestamp": "00:10:30,668", "timestamp_s": 630.0}, {"text": "looking at credit scoring as a machine learning system. This is quite a popular", "timestamp": "00:10:34,748", "timestamp_s": 634.0}, {"text": "type of machine learning system we see at financial", "timestamp": "00:10:38,562", "timestamp_s": 638.0}, {"text": "institutions. You may have information about people", "timestamp": "00:10:42,022", "timestamp_s": 642.0}, {"text": "who would like to apply for credit, and we\u0027d like to give them a score", "timestamp": "00:10:46,192", "timestamp_s": 646.0}, {"text": "to decide on whether we\u0027re going to give that person credit or", "timestamp": "00:10:49,542", "timestamp_s": 649.0}, {"text": "not. So typically what you\u0027ll need to have is data", "timestamp": "00:10:53,184", "timestamp_s": 653.0}, {"text": "from different sources. And you can see there\u0027s some sources on the left", "timestamp": "00:10:56,532", "timestamp_s": 656.0}, {"text": "here. A feature pipeline will create the features from those", "timestamp": "00:10:59,876", "timestamp_s": 659.0}, {"text": "data sources. Training pipeline will train your model. We look", "timestamp": "00:11:03,368", "timestamp_s": 663.0}, {"text": "at an Xgboost model and then inference pipeline will take", "timestamp": "00:11:06,552", "timestamp_s": 666.0}, {"text": "this XgBoost model and then some new credits.", "timestamp": "00:11:09,928", "timestamp_s": 669.0}, {"text": "So credit applications to score and that could be done in a batch manner.", "timestamp": "00:11:14,870", "timestamp_s": 674.0}, {"text": "You could have like a batch that arrive and once a day you score them", "timestamp": "00:11:18,878", "timestamp_s": 678.0}, {"text": "and then you send an email out the next day to say you\u0027re approved.", "timestamp": "00:11:22,268", "timestamp_s": 682.0}, {"text": "But even better would be an interactive application. So as the user goes", "timestamp": "00:11:25,698", "timestamp_s": 685.0}, {"text": "to a website and fills in their details, then we can have an online", "timestamp": "00:11:29,868", "timestamp_s": 689.0}, {"text": "system which can read those features back and the feature store and", "timestamp": "00:11:33,790", "timestamp_s": 693.0}, {"text": "hopsearch in particular enables that. We\u0027re going to look at the batch case", "timestamp": "00:11:37,648", "timestamp_s": 697.0}, {"text": "today and the training pipeline. It can", "timestamp": "00:11:40,864", "timestamp_s": 700.0}, {"text": "be run in any kind of training environment, any Python", "timestamp": "00:11:44,148", "timestamp_s": 704.0}, {"text": "enabled environment. And our pipelines can also be run in any", "timestamp": "00:11:47,626", "timestamp_s": 707.0}, {"text": "Python environment. So today we\u0027ll look at running it in my notebook,", "timestamp": "00:11:50,932", "timestamp_s": 710.0}, {"text": "but of course you can schedule them to run in any Python", "timestamp": "00:11:54,450", "timestamp_s": 714.0}, {"text": "environment. So let\u0027s start and look at feature pipelines", "timestamp": "00:11:58,238", "timestamp_s": 718.0}, {"text": "and have a look at a little bit of the code that we need to", "timestamp": "00:12:02,790", "timestamp_s": 722.0}, {"text": "create a feature pipeline. So the feature pipeline will take your raw data,", "timestamp": "00:12:05,688", "timestamp_s": 725.0}, {"text": "it\u0027ll compute features from it that\u0027s compressed signal that we\u0027re going to use to train", "timestamp": "00:12:09,016", "timestamp_s": 729.0}, {"text": "our models with and also to make predictions with. So there\u0027s an example here", "timestamp": "00:12:12,796", "timestamp_s": 732.0}, {"text": "we\u0027re using pandas to do our transformations. So we", "timestamp": "00:12:16,588", "timestamp_s": 736.0}, {"text": "call these model independent transformations because the features we store in the", "timestamp": "00:12:20,192", "timestamp_s": 740.0}, {"text": "features store should be reusable across many different models.", "timestamp": "00:12:23,344", "timestamp_s": 743.0}, {"text": "We can see here that here we\u0027re doing a classic aggregation", "timestamp": "00:12:27,790", "timestamp_s": 747.0}, {"text": "where we\u0027re counting the number of events happening in a four hour window.", "timestamp": "00:12:31,882", "timestamp_s": 751.0}, {"text": "We can see here that when we\u0027ve created", "timestamp": "00:12:36,290", "timestamp_s": 756.0}, {"text": "a data frame window AGSDF here with our features", "timestamp": "00:12:39,738", "timestamp_s": 759.0}, {"text": "that we\u0027d like to use in our feature store, we\u0027d like to", "timestamp": "00:12:43,258", "timestamp_s": 763.0}, {"text": "store them in the feature store. And these features here are related to the credit", "timestamp": "00:12:47,128", "timestamp_s": 767.0}, {"text": "card, the number of transactions, or the frequency of the transactions in", "timestamp": "00:12:50,616", "timestamp_s": 770.0}, {"text": "that four hour period of time. But basically with this", "timestamp": "00:12:54,488", "timestamp_s": 774.0}, {"text": "window AGS data frame, what we\u0027re going to do is we\u0027re going", "timestamp": "00:12:58,184", "timestamp_s": 778.0}, {"text": "to insert it into this thing called a feature store. So here we\u0027re creating the", "timestamp": "00:13:01,804", "timestamp_s": 781.0}, {"text": "feature store. We\u0027re giving it a name and a version, a description.", "timestamp": "00:13:04,748", "timestamp_s": 784.0}, {"text": "We\u0027re identifying which column is the primary key. So the unique row level identifier", "timestamp": "00:13:07,794", "timestamp_s": 787.0}, {"text": "column that uniquely identifies each row in this data frame.", "timestamp": "00:13:12,422", "timestamp_s": 792.0}, {"text": "If there is a unique timestamp column", "timestamp": "00:13:16,214", "timestamp_s": 796.0}, {"text": "within that particular data", "timestamp": "00:13:19,606", "timestamp_s": 799.0}, {"text": "frame, it doesn\u0027t need to be unique. Of course, they can be", "timestamp": "00:13:23,296", "timestamp_s": 803.0}, {"text": "the same across many different rows, but if there is an event time at which", "timestamp": "00:13:26,388", "timestamp_s": 806.0}, {"text": "that particular row was generated as a column, you can specify", "timestamp": "00:13:29,780", "timestamp_s": 809.0}, {"text": "it here, because what we\u0027ll see is that in feature stores,", "timestamp": "00:13:33,322", "timestamp_s": 813.0}, {"text": "if I have many different tables of features that have different event times on them,", "timestamp": "00:13:36,954", "timestamp_s": 816.0}, {"text": "we need to line those up so that we don\u0027t get what we call data", "timestamp": "00:13:41,256", "timestamp_s": 821.0}, {"text": "leakage. So we don\u0027t get future data. When we join these columns", "timestamp": "00:13:44,936", "timestamp_s": 824.0}, {"text": "of features together from different tables, we don\u0027t want to have data that\u0027s", "timestamp": "00:13:48,910", "timestamp_s": 828.0}, {"text": "in the future because then our model will be able to learn from future data", "timestamp": "00:13:52,594", "timestamp_s": 832.0}, {"text": "which we don\u0027t want to do. So that\u0027s called data leakage. We want to avoid", "timestamp": "00:13:56,076", "timestamp_s": 836.0}, {"text": "it. So if you specify the event time column in your feature group that", "timestamp": "00:13:58,738", "timestamp_s": 838.0}, {"text": "can be used by the feature store to do what\u0027s", "timestamp": "00:14:03,248", "timestamp_s": 843.0}, {"text": "called a point in time correct join, so there\u0027s no data leakage. So once", "timestamp": "00:14:06,614", "timestamp_s": 846.0}, {"text": "you\u0027ve created this feature group object, you can just insert your pandas data frame.", "timestamp": "00:14:10,768", "timestamp_s": 850.0}, {"text": "So you just call insert on it, it\u0027ll write it to the feature store and", "timestamp": "00:14:14,458", "timestamp_s": 854.0}, {"text": "your data will end up there. Now,", "timestamp": "00:14:17,908", "timestamp_s": 857.0}, {"text": "Python is great for that smaller scale of data. If you have", "timestamp": "00:14:20,930", "timestamp_s": 860.0}, {"text": "larger volumes of data, you may want to use to Pyspark. It\u0027s great", "timestamp": "00:14:24,852", "timestamp_s": 864.0}, {"text": "for scale and testing, but it\u0027s obviously a bit more challenging to develop with,", "timestamp": "00:14:28,168", "timestamp_s": 868.0}, {"text": "more challenging to debug with and operate. SQL is also", "timestamp": "00:14:32,424", "timestamp_s": 872.0}, {"text": "quite popular. SQL has low operational", "timestamp": "00:14:36,008", "timestamp_s": 876.0}, {"text": "overhead. It can scale quite well. There are many different features, as you know,", "timestamp": "00:14:39,986", "timestamp_s": 879.0}, {"text": "that are very difficult to implement in SQL.", "timestamp": "00:14:43,772", "timestamp_s": 883.0}, {"text": "Even if you embed udfs in your data warehouse,", "timestamp": "00:14:47,042", "timestamp_s": 887.0}, {"text": "things like embeddings and there\u0027s many libraries", "timestamp": "00:14:50,670", "timestamp_s": 890.0}, {"text": "of course, in pandas we use to compute features that are not particularly suitable", "timestamp": "00:14:54,118", "timestamp_s": 894.0}, {"text": "in SQL. Now Python is obviously", "timestamp": "00:14:57,366", "timestamp_s": 897.0}, {"text": "a great and popular language to develop", "timestamp": "00:15:01,236", "timestamp_s": 901.0}, {"text": "features in, so it has low operational overhead.", "timestamp": "00:15:04,628", "timestamp_s": 904.0}, {"text": "Pandas is very popular, Polars has become popular.", "timestamp": "00:15:08,138", "timestamp_s": 908.0}, {"text": "It scales to larger data volumes than pandas,", "timestamp": "00:15:11,546", "timestamp_s": 911.0}, {"text": "but they\u0027re all good choices. Now if you need stream processing,", "timestamp": "00:15:15,490", "timestamp_s": 915.0}, {"text": "so very low latency features that are computed on real time data,", "timestamp": "00:15:19,022", "timestamp_s": 919.0}, {"text": "then you might want to look at a streaming framework like Flink or", "timestamp": "00:15:22,632", "timestamp_s": 922.0}, {"text": "Pyspark, which also has spark streaming.", "timestamp": "00:15:26,556", "timestamp_s": 926.0}, {"text": "So if you want to write that code in Python, probably Pyspark is your best.", "timestamp": "00:15:29,442", "timestamp_s": 929.0}, {"text": "But Flink is very Java centric.", "timestamp": "00:15:32,908", "timestamp_s": 932.0}, {"text": "So in hopsworks we can write the data", "timestamp": "00:15:36,650", "timestamp_s": 936.0}, {"text": "to the feature store from Python in what we call a streaming API", "timestamp": "00:15:40,236", "timestamp_s": 940.0}, {"text": "or a batch API. The batch API will store the data offline. It\u0027s only", "timestamp": "00:15:43,942", "timestamp_s": 943.0}, {"text": "historical data, so it\u0027ll only be available via this offline API.", "timestamp": "00:15:47,552", "timestamp_s": 947.0}, {"text": "So the offline API is to get training data or batch data", "timestamp": "00:15:51,366", "timestamp_s": 951.0}, {"text": "that you\u0027d like to do inference on. But if you have an online application,", "timestamp": "00:15:54,848", "timestamp_s": 954.0}, {"text": "you need low latency access to your features. So if we", "timestamp": "00:15:58,324", "timestamp_s": 958.0}, {"text": "have for example the credit scoring application that needs to look up your", "timestamp": "00:16:01,588", "timestamp_s": 961.0}, {"text": "features within a few milliseconds because it\u0027s going to do a live prediction", "timestamp": "00:16:05,188", "timestamp_s": 965.0}, {"text": "of your credit score, then you need the online", "timestamp": "00:16:09,646", "timestamp_s": 969.0}, {"text": "API. So in that case you write using the streaming API.", "timestamp": "00:16:13,160", "timestamp_s": 973.0}, {"text": "Now in Hopster\u0027s the default is a streaming API.", "timestamp": "00:16:16,710", "timestamp_s": 976.0}, {"text": "So when I called insert on my feature group, it wrote the data via", "timestamp": "00:16:19,918", "timestamp_s": 979.0}, {"text": "this API. It\u0027ll be stored both an online offline store and", "timestamp": "00:16:23,058", "timestamp_s": 983.0}, {"text": "it\u0027ll be available via both the online and offline APIs.", "timestamp": "00:16:34,444", "timestamp_s": 994.0}, {"text": "Now what we can see here is that the tables of features", "timestamp": "00:16:38,750", "timestamp_s": 998.0}, {"text": "are called feature groups, and then we have something called a feature view.", "timestamp": "00:16:42,438", "timestamp_s": 1002.0}, {"text": "So in hopsworks you\u0027re able to reuse features across many", "timestamp": "00:16:45,970", "timestamp_s": 1005.0}, {"text": "different models. And the way you do that is by selecting features into something called", "timestamp": "00:16:49,812", "timestamp_s": 1009.0}, {"text": "a feature view. So you can select from many different feature groups, all updated potentially", "timestamp": "00:16:53,348", "timestamp_s": 1013.0}, {"text": "by different feature pipelines, and then the feature store will perform", "timestamp": "00:16:57,166", "timestamp_s": 1017.0}, {"text": "this point in time correct join for you.", "timestamp": "00:17:01,000", "timestamp_s": 1021.0}, {"text": "So if we\u0027re able to reuse features across many different models,", "timestamp": "00:17:05,590", "timestamp_s": 1025.0}, {"text": "we can see here one model at the top it has a feature view selecting", "timestamp": "00:17:08,878", "timestamp_s": 1028.0}, {"text": "a certain set of features, another feature view down here selecting different features,", "timestamp": "00:17:12,418", "timestamp_s": 1032.0}, {"text": "and each one can create their own training data sets. Train your models on", "timestamp": "00:17:16,066", "timestamp_s": 1036.0}, {"text": "and each one can pull out. Then if we\u0027re doing batch inference, you\u0027ll pull the", "timestamp": "00:17:19,788", "timestamp_s": 1039.0}, {"text": "features by the feature view, say well, the data that arrived in the last 24", "timestamp": "00:17:23,552", "timestamp_s": 1043.0}, {"text": "hours, for example, and then you\u0027ll", "timestamp": "00:17:27,088", "timestamp_s": 1047.0}, {"text": "do inference on those with your model.", "timestamp": "00:17:30,442", "timestamp_s": 1050.0}, {"text": "Now training pipelines use these feature views to", "timestamp": "00:17:34,450", "timestamp_s": 1054.0}, {"text": "read data to train models with. So it", "timestamp": "00:17:38,388", "timestamp_s": 1058.0}, {"text": "uses this offline API. You can get your data back as files,", "timestamp": "00:17:41,588", "timestamp_s": 1061.0}, {"text": "maybe CSV or parquet or TF records", "timestamp": "00:17:45,482", "timestamp_s": 1065.0}, {"text": "even. Or you can get in the back as a pandas data frame if the", "timestamp": "00:17:49,518", "timestamp_s": 1069.0}, {"text": "data is not too large. And you can train directly with", "timestamp": "00:17:52,424", "timestamp_s": 1072.0}, {"text": "your data. And it has if support written nice things like random splits and", "timestamp": "00:17:55,592", "timestamp_s": 1075.0}, {"text": "time series splits of your data. So you don\u0027t need to do that. Even in", "timestamp": "00:17:59,048", "timestamp_s": 1079.0}, {"text": "Scikitlearn you can just read the ready made split data", "timestamp": "00:18:01,628", "timestamp_s": 1081.0}, {"text": "frames with your features and labels.", "timestamp": "00:18:05,596", "timestamp_s": 1085.0}, {"text": "So the feature view itself is an API for model development and also", "timestamp": "00:18:09,130", "timestamp_s": 1089.0}, {"text": "for operations. In the online case, you basically select", "timestamp": "00:18:12,880", "timestamp_s": 1092.0}, {"text": "your features. You say what label it is for this particular feature", "timestamp": "00:18:16,576", "timestamp_s": 1096.0}, {"text": "view. One other thing that you might want to do is features", "timestamp": "00:18:20,486", "timestamp_s": 1100.0}, {"text": "are typically shared untransformed. So what that means", "timestamp": "00:18:24,218", "timestamp_s": 1104.0}, {"text": "is if you have a categorical variable, store it in the feature store unencoded,", "timestamp": "00:18:27,908", "timestamp_s": 1107.0}, {"text": "and then when your model is selected, it can encode it, because some models", "timestamp": "00:18:32,138", "timestamp_s": 1112.0}, {"text": "will need to encode categorical variables.", "timestamp": "00:18:35,806", "timestamp_s": 1115.0}, {"text": "So for example gradient descent based models, but other", "timestamp": "00:18:39,670", "timestamp_s": 1119.0}, {"text": "models, so cat boost for example,", "timestamp": "00:18:42,952", "timestamp_s": 1122.0}, {"text": "can work directly with the categorical data. And the same", "timestamp": "00:18:46,550", "timestamp_s": 1126.0}, {"text": "is true for numerical variables. So we call those model specific transformations.", "timestamp": "00:18:50,348", "timestamp_s": 1130.0}, {"text": "They can be associated with features in the feature view so that you don\u0027t have", "timestamp": "00:18:53,842", "timestamp_s": 1133.0}, {"text": "to write that code separately yourself.", "timestamp": "00:18:57,372", "timestamp_s": 1137.0}, {"text": "Because there is a potential that if you write the code in the training pipeline", "timestamp": "00:19:00,944", "timestamp_s": 1140.0}, {"text": "to transform features like encode them", "timestamp": "00:19:04,022", "timestamp_s": 1144.0}, {"text": "or normalize numerical features, you need to do the same thing in the", "timestamp": "00:19:07,536", "timestamp_s": 1147.0}, {"text": "inference pipeline. And there is a potential for what we call SKU there.", "timestamp": "00:19:11,344", "timestamp_s": 1151.0}, {"text": "So the feature view will help you avoid that potential problem,", "timestamp": "00:19:14,628", "timestamp_s": 1154.0}, {"text": "feature view. Then once you have it, it can apply the model", "timestamp": "00:19:18,628", "timestamp_s": 1158.0}, {"text": "specific transformations on the data, create training data, batch inference data,", "timestamp": "00:19:22,452", "timestamp_s": 1162.0}, {"text": "and it\u0027ll apply those transformations consistently.", "timestamp": "00:19:25,832", "timestamp_s": 1165.0}, {"text": "So the point in time correct join I mentioned already, you take tables from", "timestamp": "00:19:29,510", "timestamp_s": 1169.0}, {"text": "features from different tables, ensure that they\u0027re lined up on", "timestamp": "00:19:33,768", "timestamp_s": 1173.0}, {"text": "the correct transaction event time here. So this value", "timestamp": "00:19:37,068", "timestamp_s": 1177.0}, {"text": "of this category at this point", "timestamp": "00:19:40,524", "timestamp_s": 1180.0}, {"text": "in time, we can look up the amount", "timestamp": "00:19:43,788", "timestamp_s": 1183.0}, {"text": "for that particular week and month, and we\u0027re not going to get future values in", "timestamp": "00:19:47,020", "timestamp_s": 1187.0}, {"text": "here. There\u0027d be no data leakage. Now, if you", "timestamp": "00:19:50,508", "timestamp_s": 1190.0}, {"text": "were to write this join this point in time correct join yourself. It\u0027s going to", "timestamp": "00:19:53,888", "timestamp_s": 1193.0}, {"text": "be quite complex. For that example, we can see there\u0027s quite a lot of SQL", "timestamp": "00:19:57,264", "timestamp_s": 1197.0}, {"text": "code for it, but in Python you just write the following code below.", "timestamp": "00:20:00,902", "timestamp_s": 1200.0}, {"text": "You select the features that you\u0027d like from the different feature groups.", "timestamp": "00:20:04,436", "timestamp_s": 1204.0}, {"text": "You join them together in pandas like syntax,", "timestamp": "00:20:07,658", "timestamp_s": 1207.0}, {"text": "and you then get back what\u0027s called a query", "timestamp": "00:20:11,098", "timestamp_s": 1211.0}, {"text": "object. This is our selection of features, and then we can create our", "timestamp": "00:20:14,762", "timestamp_s": 1214.0}, {"text": "feature view with that particular selection of features.", "timestamp": "00:20:18,088", "timestamp_s": 1218.0}, {"text": "Now once we\u0027ve created our feature view, we can see we\u0027ve got a feature view", "timestamp": "00:20:21,830", "timestamp_s": 1221.0}, {"text": "object here, we can create training data from it, and we can", "timestamp": "00:20:25,512", "timestamp_s": 1225.0}, {"text": "ready split that train data into random sets, a test", "timestamp": "00:20:28,840", "timestamp_s": 1228.0}, {"text": "set and a training set, and a validation set as well, even, and you", "timestamp": "00:20:32,332", "timestamp_s": 1232.0}, {"text": "can say what the file format you\u0027d like to store that train data is.", "timestamp": "00:20:36,124", "timestamp_s": 1236.0}, {"text": "You can also get the train data back directly as pandas data", "timestamp": "00:20:39,276", "timestamp_s": 1239.0}, {"text": "frames. So here we can get our features in the training,", "timestamp": "00:20:43,008", "timestamp_s": 1243.0}, {"text": "test and validation sets and the labels in the training,", "timestamp": "00:20:47,150", "timestamp_s": 1247.0}, {"text": "validation and test sets back. And I don\u0027t need to run it through scikitlearn", "timestamp": "00:20:50,352", "timestamp_s": 1250.0}, {"text": "splitting algorithm. This is going to be a random split, but there is also a", "timestamp": "00:20:54,666", "timestamp_s": 1254.0}, {"text": "time series split. So you can say if I\u0027ve got a", "timestamp": "00:20:57,684", "timestamp_s": 1257.0}, {"text": "time series model and time series data, I\u0027ll train on maybe", "timestamp": "00:21:01,428", "timestamp_s": 1261.0}, {"text": "the data here up to version two, and then I\u0027ll predict", "timestamp": "00:21:05,352", "timestamp_s": 1265.0}, {"text": "how my test set will be the data that came after the", "timestamp": "00:21:09,910", "timestamp_s": 1269.0}, {"text": "end of this particular point in time.", "timestamp": "00:21:13,720", "timestamp_s": 1273.0}, {"text": "Now what you can also do with a feature view is you can get training", "timestamp": "00:21:17,830", "timestamp_s": 1277.0}, {"text": "data, for example for version one of your model, or get training data for version", "timestamp": "00:21:21,516", "timestamp_s": 1281.0}, {"text": "two. New data will keep training in the system, the feature pipelines will keep", "timestamp": "00:21:24,882", "timestamp_s": 1284.0}, {"text": "training new features, and then you can read that", "timestamp": "00:21:29,196", "timestamp_s": 1289.0}, {"text": "data and make predictions on it. So we can do batch inference with", "timestamp": "00:21:32,512", "timestamp_s": 1292.0}, {"text": "the feature view as well. We create batch inference data and", "timestamp": "00:21:35,648", "timestamp_s": 1295.0}, {"text": "finally for feature views we can specify specific features", "timestamp": "00:21:40,032", "timestamp_s": 1300.0}, {"text": "that we\u0027d like to transform. So here we\u0027re saying the amount of money last month", "timestamp": "00:21:43,594", "timestamp_s": 1303.0}, {"text": "we\u0027re going to apply the standard scalar, the category", "timestamp": "00:21:47,332", "timestamp_s": 1307.0}, {"text": "variable. We\u0027re going to encode it, it\u0027s categorical variable,", "timestamp": "00:21:50,858", "timestamp_s": 1310.0}, {"text": "apply a label encoder on it, and the same for amount last week,", "timestamp": "00:21:54,042", "timestamp_s": 1314.0}, {"text": "the standard scalar. So when we read the training data, the batch", "timestamp": "00:21:57,268", "timestamp_s": 1317.0}, {"text": "inference data, or in this case the online inference data, the feature", "timestamp": "00:22:00,862", "timestamp_s": 1320.0}, {"text": "vector, it\u0027ll apply these transformations after it\u0027s read the", "timestamp": "00:22:04,446", "timestamp_s": 1324.0}, {"text": "data in the feature store, but before it\u0027s returned to the client. And this ensures", "timestamp": "00:22:08,044", "timestamp_s": 1328.0}, {"text": "consistency of these transformation functions between this training pipeline", "timestamp": "00:22:11,874", "timestamp_s": 1331.0}, {"text": "and this inference pipeline. You can do it yourself in scikitlearn pipelines,", "timestamp": "00:22:15,634", "timestamp_s": 1335.0}, {"text": "and then you need to make sure that both of these are consistent.", "timestamp": "00:22:19,954", "timestamp_s": 1339.0}, {"text": "So let\u0027s move over to inference pipelines and we\u0027ll", "timestamp": "00:22:24,590", "timestamp_s": 1344.0}, {"text": "have a look at some of the code. This is a predictor", "timestamp": "00:22:28,358", "timestamp_s": 1348.0}, {"text": "class. So this is a model that you will be deployed in a model", "timestamp": "00:22:31,990", "timestamp_s": 1351.0}, {"text": "serving server. We can see here the method called predict.", "timestamp": "00:22:35,316", "timestamp_s": 1355.0}, {"text": "But before we predict, we need to initialize this object. So when it\u0027s", "timestamp": "00:22:39,210", "timestamp_s": 1359.0}, {"text": "loaded into our model serving server, init will be called", "timestamp": "00:22:42,378", "timestamp_s": 1362.0}, {"text": "we\u0027ll connect to the feature store that we can see here. We\u0027ll initialize the feature", "timestamp": "00:22:45,876", "timestamp_s": 1365.0}, {"text": "store. And what we need to do is we need to tell it what", "timestamp": "00:22:49,646", "timestamp_s": 1369.0}, {"text": "the version of the training data was that we trained", "timestamp": "00:22:53,192", "timestamp_s": 1373.0}, {"text": "our model on, because we can create many different train data sets from a feature", "timestamp": "00:22:56,734", "timestamp_s": 1376.0}, {"text": "view. So here it was version number one. So we say, okay, I\u0027m going to", "timestamp": "00:22:59,902", "timestamp_s": 1379.0}, {"text": "initialize my feature view on version number one. The reason we need to do that", "timestamp": "00:23:03,452", "timestamp_s": 1383.0}, {"text": "is the transformations often need the state from", "timestamp": "00:23:06,588", "timestamp_s": 1386.0}, {"text": "that training data set version. So if I\u0027m normalizing a numerical feature,", "timestamp": "00:23:10,028", "timestamp_s": 1390.0}, {"text": "I\u0027ll need to know what the mean value of that feature was in", "timestamp": "00:23:13,750", "timestamp_s": 1393.0}, {"text": "the training data set the model was training on. So that", "timestamp": "00:23:17,248", "timestamp_s": 1397.0}, {"text": "information is captured in the feature view. You don\u0027t need to supply train data set", "timestamp": "00:23:20,688", "timestamp_s": 1400.0}, {"text": "when you\u0027re deploying your model for serving here.", "timestamp": "00:23:24,356", "timestamp_s": 1404.0}, {"text": "And then you can see we\u0027re loading the model from the model registry and it\u0027s", "timestamp": "00:23:27,810", "timestamp_s": 1407.0}, {"text": "now available in our predict object. So when a request comes in to make a", "timestamp": "00:23:31,754", "timestamp_s": 1411.0}, {"text": "prediction, the model is loaded, the connection to the feature store has been established,", "timestamp": "00:23:34,584", "timestamp_s": 1414.0}, {"text": "and we can just call self dot model", "timestamp": "00:23:38,718", "timestamp_s": 1418.0}, {"text": "predict, return the pre computed features from the", "timestamp": "00:23:42,680", "timestamp_s": 1422.0}, {"text": "feature store here and then send them to the model to make the prediction.", "timestamp": "00:23:45,784", "timestamp_s": 1425.0}, {"text": "So this is going to go to the feature store, return our precomputed features.", "timestamp": "00:23:49,458", "timestamp_s": 1429.0}, {"text": "We\u0027re going to cast them to a numpy array, and then the", "timestamp": "00:23:52,978", "timestamp_s": 1432.0}, {"text": "model predict method will be applied to that numpy array to make our prediction,", "timestamp": "00:23:56,332", "timestamp_s": 1436.0}, {"text": "which is returned to the client. Let\u0027s have", "timestamp": "00:23:59,734", "timestamp_s": 1439.0}, {"text": "a quick look at a demo. So this", "timestamp": "00:24:03,648", "timestamp_s": 1443.0}, {"text": "particular demo, the way that we often see", "timestamp": "00:24:07,712", "timestamp_s": 1447.0}, {"text": "a lot of these machine learning systems built when", "timestamp": "00:24:11,072", "timestamp_s": 1451.0}, {"text": "people are starting out, when you want to use get started as", "timestamp": "00:24:14,148", "timestamp_s": 1454.0}, {"text": "quickly as possible, is you can write Python programs in a very", "timestamp": "00:24:17,732", "timestamp_s": 1457.0}, {"text": "nice tool called modal. So modal has a very generous", "timestamp": "00:24:21,732", "timestamp_s": 1461.0}, {"text": "free tier. It basically can schedule Python programs", "timestamp": "00:24:25,502", "timestamp_s": 1465.0}, {"text": "for you. And if you need to install libraries, you just annotate the functions", "timestamp": "00:24:29,118", "timestamp_s": 1469.0}, {"text": "and say Pip, install hopsworks, for example.", "timestamp": "00:24:33,198", "timestamp_s": 1473.0}, {"text": "And in that modal code we can write our feature engineering pipeline that we", "timestamp": "00:24:37,190", "timestamp_s": 1477.0}, {"text": "saw earlier. It\u0027ll read the data and write data frames to hopsworks.", "timestamp": "00:24:40,908", "timestamp_s": 1480.0}, {"text": "And then modal can also train. You may want to train because training is", "timestamp": "00:24:45,042", "timestamp_s": 1485.0}, {"text": "not an operational system. You can train on colab and do it", "timestamp": "00:24:48,908", "timestamp_s": 1488.0}, {"text": "offline, if you will, or on demand, or when the", "timestamp": "00:24:53,950", "timestamp_s": 1493.0}, {"text": "model has become stale. You don\u0027t necessarily need to do it every day as you", "timestamp": "00:24:57,408", "timestamp_s": 1497.0}, {"text": "would when in a feature pipeline if new data was arriving every day,", "timestamp": "00:25:00,896", "timestamp_s": 1500.0}, {"text": "and then for inference. Again, it\u0027s an operational system.", "timestamp": "00:25:04,628", "timestamp_s": 1504.0}, {"text": "So maybe it\u0027s going to be either on demand when the user", "timestamp": "00:25:08,404", "timestamp_s": 1508.0}, {"text": "goes into the website in an interactive system, makes a prediction,", "timestamp": "00:25:11,866", "timestamp_s": 1511.0}, {"text": "or maybe it\u0027s going to be a dashboard that gets updated", "timestamp": "00:25:15,198", "timestamp_s": 1515.0}, {"text": "at some cadence. So hugging faces is a really nice way of", "timestamp": "00:25:19,198", "timestamp_s": 1519.0}, {"text": "doing a lot of inference, because it has, again, a very generous", "timestamp": "00:25:22,872", "timestamp_s": 1522.0}, {"text": "free tier where you can use hugging face spaces to", "timestamp": "00:25:26,462", "timestamp_s": 1526.0}, {"text": "do some really nice uis for dashboards or for interactive applications,", "timestamp": "00:25:30,844", "timestamp_s": 1530.0}, {"text": "in this case from hopsearch. They can read the models and the", "timestamp": "00:25:35,122", "timestamp_s": 1535.0}, {"text": "data frames. This is the data that you want to make your predictions with.", "timestamp": "00:25:38,812", "timestamp_s": 1538.0}, {"text": "And we can also even save the logs back to hopsearch", "timestamp": "00:25:42,016", "timestamp_s": 1542.0}, {"text": "and even do user interfaces in hugging", "timestamp": "00:25:45,542", "timestamp_s": 1545.0}, {"text": "face for monitoring our models in production. So hopsearch in this", "timestamp": "00:25:49,318", "timestamp_s": 1549.0}, {"text": "case, again, has another free serverless tier.", "timestamp": "00:25:53,184", "timestamp_s": 1553.0}, {"text": "You don\u0027t need to install anything, you get 25gb of free storage.", "timestamp": "00:25:56,378", "timestamp_s": 1556.0}, {"text": "This is a really nice way to build what we call serverless machine learning", "timestamp": "00:26:00,314", "timestamp_s": 1560.0}, {"text": "systems. And here\u0027s some examples. There\u0027s a bunch of these on the", "timestamp": "00:26:03,876", "timestamp_s": 1563.0}, {"text": "Internet. I think there\u0027s about 40 or 50 of them now. Some really nice ones", "timestamp": "00:26:07,384", "timestamp_s": 1567.0}, {"text": "are air quality predictions. In Poland, this is a streamlet application.", "timestamp": "00:26:10,536", "timestamp_s": 1570.0}, {"text": "It runs the feature pipelines daily on mobile,", "timestamp": "00:26:16,550", "timestamp_s": 1576.0}, {"text": "and it stores then these features and hopsworks. And then", "timestamp": "00:26:19,950", "timestamp_s": 1579.0}, {"text": "when you go to the dashboard here, it can redraw with the", "timestamp": "00:26:24,012", "timestamp_s": 1584.0}, {"text": "predictions of the air quality in the different cities. So this is for", "timestamp": "00:26:27,084", "timestamp_s": 1587.0}, {"text": "today in early, this is actually early March,", "timestamp": "00:26:30,416", "timestamp_s": 1590.0}, {"text": "and you can look at different days and it will connect to hopsworks, read down", "timestamp": "00:26:34,678", "timestamp_s": 1594.0}, {"text": "new data to score and redraw this particular UI", "timestamp": "00:26:37,792", "timestamp_s": 1597.0}, {"text": "and streamlit. And there\u0027s another one here that will predict whether", "timestamp": "00:26:41,558", "timestamp_s": 1601.0}, {"text": "your post on Reddit will be liked or not. So it\u0027s using sentiment analysis", "timestamp": "00:26:45,364", "timestamp_s": 1605.0}, {"text": "and it\u0027s very interesting. Another one on Tesla, stock price production.", "timestamp": "00:26:49,754", "timestamp_s": 1609.0}, {"text": "So I think it\u0027s using sentiment from Twitter, amongst other", "timestamp": "00:26:53,678", "timestamp_s": 1613.0}, {"text": "places, and then another one using New York electricity.", "timestamp": "00:26:57,592", "timestamp_s": 1617.0}, {"text": "A lot of services globally have been digitalized and a lot of data is", "timestamp": "00:27:03,830", "timestamp_s": 1623.0}, {"text": "available now for us to build these prediction services with.", "timestamp": "00:27:07,144", "timestamp_s": 1627.0}, {"text": "So you can write a Python program which will go to the", "timestamp": "00:27:10,460", "timestamp_s": 1630.0}, {"text": "New York electricity market. And if you follow this link,", "timestamp": "00:27:13,708", "timestamp_s": 1633.0}, {"text": "you\u0027ll see where they get the data from. And you can see in many", "timestamp": "00:27:16,972", "timestamp_s": 1636.0}, {"text": "cases, it\u0027s actually outperforming the ETA\u0027s forecast or", "timestamp": "00:27:20,192", "timestamp_s": 1640.0}, {"text": "the EIA\u0027s daily forecast, which it\u0027s doing here.", "timestamp": "00:27:24,048", "timestamp_s": 1644.0}, {"text": "So there\u0027s a lot of cool things you can build. I\u0027m going to show you", "timestamp": "00:27:28,350", "timestamp_s": 1648.0}, {"text": "briefly this one that I mentioned here. There\u0027s a ton", "timestamp": "00:27:30,608", "timestamp_s": 1650.0}, {"text": "of them here in Hopsterick\u0027s tutorials. The one I\u0027m going to show you briefly", "timestamp": "00:27:34,288", "timestamp_s": 1654.0}, {"text": "here is called credit scores. Now, I\u0027ve actually opened", "timestamp": "00:27:37,818", "timestamp_s": 1657.0}, {"text": "up the notebooks already, so this is just running on my laptop here. This is", "timestamp": "00:27:41,498", "timestamp_s": 1661.0}, {"text": "the hopster tutorials that I\u0027ve checked out locally.", "timestamp": "00:27:45,476", "timestamp_s": 1665.0}, {"text": "Do I need quick start? No, I don\u0027t. Let\u0027s move to the first", "timestamp": "00:27:49,030", "timestamp_s": 1669.0}, {"text": "one. So in this case we\u0027ve got the advanced tutorials,", "timestamp": "00:27:52,376", "timestamp_s": 1672.0}, {"text": "credit scores. So what this is going to do is I actually have two feature", "timestamp": "00:27:55,998", "timestamp_s": 1675.0}, {"text": "pipelines at the beginning. Sometimes you\u0027ll have two, one for historical data to create your", "timestamp": "00:27:59,422", "timestamp_s": 1679.0}, {"text": "feature groups and add all the metadata. And this is a backfill", "timestamp": "00:28:02,988", "timestamp_s": 1682.0}, {"text": "one. So what this one is doing is basically reading some csv files", "timestamp": "00:28:06,722", "timestamp_s": 1686.0}, {"text": "with our loan applications, bureau balance,", "timestamp": "00:28:10,358", "timestamp_s": 1690.0}, {"text": "credit card data, payment installments and a lot of other data,", "timestamp": "00:28:13,398", "timestamp_s": 1693.0}, {"text": "doing some feature engineering. It\u0027s also", "timestamp": "00:28:17,040", "timestamp_s": 1697.0}, {"text": "showing you doing some EDA as well, which you typically would do,", "timestamp": "00:28:20,432", "timestamp_s": 1700.0}, {"text": "and then creating the feature groups.", "timestamp": "00:28:24,068", "timestamp_s": 1704.0}, {"text": "This is where I ran it, I think, earlier on. So there might be some", "timestamp": "00:28:27,730", "timestamp_s": 1707.0}, {"text": "diagrams in here. You can see we\u0027re trying to understand basically", "timestamp": "00:28:30,468", "timestamp_s": 1710.0}, {"text": "the data before we get into the process of modeling.", "timestamp": "00:28:35,270", "timestamp_s": 1715.0}, {"text": "But obviously the kind of things you do here is clean up the data,", "timestamp": "00:28:38,910", "timestamp_s": 1718.0}, {"text": "extract any features that you need to extract or create.", "timestamp": "00:28:43,270", "timestamp_s": 1723.0}, {"text": "And then what we can have is a feature pipeline. So this is a much", "timestamp": "00:28:46,790", "timestamp_s": 1726.0}, {"text": "simpler program. It\u0027s going to read the data,", "timestamp": "00:28:50,092", "timestamp_s": 1730.0}, {"text": "it\u0027s going to read the new data. And this should run on a", "timestamp": "00:28:53,530", "timestamp_s": 1733.0}, {"text": "cadence. Now, it\u0027s a notebook, so it\u0027s really just for learning. But it\u0027ll connect to", "timestamp": "00:28:57,148", "timestamp_s": 1737.0}, {"text": "the feature store. We can see here that it\u0027s getting a reference to", "timestamp": "00:29:00,604", "timestamp_s": 1740.0}, {"text": "the feature groups. And in this case, we\u0027re not reading new data", "timestamp": "00:29:04,208", "timestamp_s": 1744.0}, {"text": "from the Internet because this is credit card loans and so", "timestamp": "00:29:08,112", "timestamp_s": 1748.0}, {"text": "on. That information is not available. So what we\u0027re doing is generating data.", "timestamp": "00:29:11,328", "timestamp_s": 1751.0}, {"text": "So this is a really good way of doing synthetic feature pipelines", "timestamp": "00:29:14,916", "timestamp_s": 1754.0}, {"text": "if you can\u0027t access the actual data. So we\u0027re just generating some", "timestamp": "00:29:18,442", "timestamp_s": 1758.0}, {"text": "random data in this case, or not random, but based on the distribution of", "timestamp": "00:29:21,908", "timestamp_s": 1761.0}, {"text": "the historical data. So it\u0027s generating new feature values", "timestamp": "00:29:26,310", "timestamp_s": 1766.0}, {"text": "based on those distributions. And then we\u0027re just going to write to", "timestamp": "00:29:30,238", "timestamp_s": 1770.0}, {"text": "the feature story. So you\u0027re just basically going to call insert on these data frames.", "timestamp": "00:29:33,528", "timestamp_s": 1773.0}, {"text": "And now you\u0027ll have some feature groups in here. So let\u0027s have a look at", "timestamp": "00:29:36,990", "timestamp_s": 1776.0}, {"text": "what the feature groups look like. We can see here,", "timestamp": "00:29:39,868", "timestamp_s": 1779.0}, {"text": "this is hopsearch here, and we\u0027ve got a bunch of projects. And this is app", "timestamp": "00:29:43,612", "timestamp_s": 1783.0}, {"text": "hopsearch AI. So it\u0027s free to create an account. It\u0027s time unlimited.", "timestamp": "00:29:47,404", "timestamp_s": 1787.0}, {"text": "You can build systems on it, and you can see there\u0027s a bunch of these", "timestamp": "00:29:50,882", "timestamp_s": 1790.0}, {"text": "feature groups that have been created. One of them is", "timestamp": "00:29:54,032", "timestamp_s": 1794.0}, {"text": "called application. We can see all the features that are in here.", "timestamp": "00:29:57,248", "timestamp_s": 1797.0}, {"text": "There\u0027s quite a lot of features, 72 in total.", "timestamp": "00:30:00,528", "timestamp_s": 1800.0}, {"text": "We can see how it\u0027s being used as a feature view created from it.", "timestamp": "00:30:05,250", "timestamp_s": 1805.0}, {"text": "You can have expectations, if you want to use great expectations to do data validation", "timestamp": "00:30:08,900", "timestamp_s": 1808.0}, {"text": "before you write to the feature store. And you can see the results of those", "timestamp": "00:30:13,162", "timestamp_s": 1813.0}, {"text": "expectations here, the same, you can create alerts if bad", "timestamp": "00:30:16,232", "timestamp_s": 1816.0}, {"text": "data is being ingested. We can preview some of the data that\u0027s", "timestamp": "00:30:19,512", "timestamp_s": 1819.0}, {"text": "in there to just do some EDA. You can see, have a look at some", "timestamp": "00:30:22,974", "timestamp_s": 1822.0}, {"text": "of the data, quite a lot in there. So just give me a random sample", "timestamp": "00:30:26,488", "timestamp_s": 1826.0}, {"text": "of some rows there. We can pre compute statistics", "timestamp": "00:30:29,538", "timestamp_s": 1829.0}, {"text": "over the data so you can understand the distribution. In this case, we got descriptive", "timestamp": "00:30:33,442", "timestamp_s": 1833.0}, {"text": "statistics of the features, and we can see what\u0027s happened in this feature group", "timestamp": "00:30:36,978", "timestamp_s": 1836.0}, {"text": "over time. So we had some data written to it earlier,", "timestamp": "00:30:40,652", "timestamp_s": 1840.0}, {"text": "and then we wrote some more data to it later on.", "timestamp": "00:30:43,942", "timestamp_s": 1843.0}, {"text": "So the feature view you can create is the selection of features.", "timestamp": "00:30:46,830", "timestamp_s": 1846.0}, {"text": "So this is what it looks like here, and I\u0027ll show you the notebook in", "timestamp": "00:30:50,726", "timestamp_s": 1850.0}, {"text": "a second. We can see the provenance of those features.", "timestamp": "00:30:53,988", "timestamp_s": 1853.0}, {"text": "This one came from this particular feature group bureau. Another one came from", "timestamp": "00:30:57,322", "timestamp_s": 1857.0}, {"text": "application. This is the target column that our supervised machine learning", "timestamp": "00:31:00,772", "timestamp_s": 1860.0}, {"text": "model is going to use as the label. And then", "timestamp": "00:31:04,932", "timestamp_s": 1864.0}, {"text": "we can see any training data sets created from it. So I only created one", "timestamp": "00:31:08,424", "timestamp_s": 1868.0}, {"text": "training data set from it, but let\u0027s look at the", "timestamp": "00:31:11,768", "timestamp_s": 1871.0}, {"text": "code for that. So in our feature view, what we do is we just get", "timestamp": "00:31:15,208", "timestamp_s": 1875.0}, {"text": "a reference to these feature groups first, and then we need to select", "timestamp": "00:31:18,424", "timestamp_s": 1878.0}, {"text": "our features. And that\u0027s what\u0027s happening in here. It calls a query preparation, but really", "timestamp": "00:31:22,556", "timestamp_s": 1882.0}, {"text": "what it\u0027s doing is feature selection. So let\u0027s call it that,", "timestamp": "00:31:26,444", "timestamp_s": 1886.0}, {"text": "it\u0027s feature selection. We\u0027re selecting features", "timestamp": "00:31:29,548", "timestamp_s": 1889.0}, {"text": "from a bunch of different feature groups or tables, and we", "timestamp": "00:31:34,294", "timestamp_s": 1894.0}, {"text": "join them together. You can add filters and things in here as well.", "timestamp": "00:31:37,408", "timestamp_s": 1897.0}, {"text": "Now, the point in time correct join is very complex, as you see, but the", "timestamp": "00:31:41,550", "timestamp_s": 1901.0}, {"text": "only code we had to write was this relatively straightforward", "timestamp": "00:31:44,964", "timestamp_s": 1904.0}, {"text": "code in Python. What we can do then is", "timestamp": "00:31:48,410", "timestamp_s": 1908.0}, {"text": "we can add transformation functions. And here what we", "timestamp": "00:31:52,550", "timestamp_s": 1912.0}, {"text": "do is we can see, we\u0027re saying, okay,", "timestamp": "00:31:56,408", "timestamp_s": 1916.0}, {"text": "in this particular case we\u0027re looking at a mapping", "timestamp": "00:32:00,310", "timestamp_s": 1920.0}, {"text": "transformer here, a label encoder and a standard encoder and we\u0027re", "timestamp": "00:32:04,302", "timestamp_s": 1924.0}, {"text": "basically applying those transformation functions then to those select", "timestamp": "00:32:09,762", "timestamp_s": 1929.0}, {"text": "set of features that are defined in here.", "timestamp": "00:32:13,180", "timestamp_s": 1933.0}, {"text": "So basically what it\u0027s saying is all the columns that are categorical we\u0027re", "timestamp": "00:32:17,050", "timestamp_s": 1937.0}, {"text": "going to apply the label encoder to and all the columns that are numerical we\u0027re", "timestamp": "00:32:20,818", "timestamp_s": 1940.0}, {"text": "going to apply the standard encoder to. And that\u0027s", "timestamp": "00:32:23,974", "timestamp_s": 1943.0}, {"text": "all going to be captured in this mapping transformer object.", "timestamp": "00:32:27,654", "timestamp_s": 1947.0}, {"text": "So the feature view is created with this selection of features called FG Query.", "timestamp": "00:32:31,310", "timestamp_s": 1951.0}, {"text": "We\u0027re applying these transformations to them. We\u0027ve identified the target column,", "timestamp": "00:32:35,094", "timestamp_s": 1955.0}, {"text": "which is called target funnily enough, and then we\u0027ve given", "timestamp": "00:32:38,538", "timestamp_s": 1958.0}, {"text": "a name and version so the feature views and the feature groups can both", "timestamp": "00:32:41,812", "timestamp_s": 1961.0}, {"text": "be versioned to enable you to apply ML Ops best principles.", "timestamp": "00:32:45,252", "timestamp_s": 1965.0}, {"text": "Of course, once we have a reference to it and here we\u0027re just getting a", "timestamp": "00:32:48,958", "timestamp_s": 1968.0}, {"text": "reference to the feature group again, we don\u0027t need to January. It\u0027s just if", "timestamp": "00:32:52,504", "timestamp_s": 1972.0}, {"text": "I start my notebook from here it\u0027s nice and handy, then what", "timestamp": "00:32:55,608", "timestamp_s": 1975.0}, {"text": "I can do is I can create training data here. I didn\u0027t specify the", "timestamp": "00:32:59,308", "timestamp_s": 1979.0}, {"text": "version train data so it just defaulted to version one.", "timestamp": "00:33:02,668", "timestamp_s": 1982.0}, {"text": "And I\u0027ve created the training data as files and it\u0027s", "timestamp": "00:33:06,410", "timestamp_s": 1986.0}, {"text": "a random split with 20% test data and 80% training", "timestamp": "00:33:09,634", "timestamp_s": 1989.0}, {"text": "data. Now the train data", "timestamp": "00:33:13,056", "timestamp_s": 1993.0}, {"text": "sets being created so I could have kept in the same notebook and just", "timestamp": "00:33:16,352", "timestamp_s": 1996.0}, {"text": "gone ahead and read the train data and train. My model I separated into", "timestamp": "00:33:20,128", "timestamp_s": 2000.0}, {"text": "two notebooks. So these two notebooks really make up the training pipeline.", "timestamp": "00:33:23,552", "timestamp_s": 2003.0}, {"text": "In a production system you typically have a single pipeline.", "timestamp": "00:33:26,698", "timestamp_s": 2006.0}, {"text": "But what we can do here is we can get back our feature view and", "timestamp": "00:33:29,626", "timestamp_s": 2009.0}, {"text": "say, hey, that train data has been created as files. I just want to read", "timestamp": "00:33:32,628", "timestamp_s": 2012.0}, {"text": "it up. And I want to read it up, split into my features,", "timestamp": "00:33:35,588", "timestamp_s": 2015.0}, {"text": "the training and test set and then my labels, the Y train and", "timestamp": "00:33:39,486", "timestamp_s": 2019.0}, {"text": "y test from the training and test set. So that\u0027s great.", "timestamp": "00:33:42,888", "timestamp_s": 2022.0}, {"text": "Now I can do some messing with the data here,", "timestamp": "00:33:46,696", "timestamp_s": 2026.0}, {"text": "just cleaning up a little bit. Then I can use just a simple model so", "timestamp": "00:33:50,236", "timestamp_s": 2030.0}, {"text": "I can use scikitlearn random forest classifier, I can use", "timestamp": "00:33:53,708", "timestamp_s": 2033.0}, {"text": "XgBoost. I\u0027m just going to fit to my training", "timestamp": "00:33:56,988", "timestamp_s": 2036.0}, {"text": "features, sorry, my features in the", "timestamp": "00:34:00,860", "timestamp_s": 2040.0}, {"text": "training set and my labels in the training set. And now I\u0027ve got my model", "timestamp": "00:34:04,288", "timestamp_s": 2044.0}, {"text": "and I can predict on the test set and check the accuracy of the model", "timestamp": "00:34:07,616", "timestamp_s": 2047.0}, {"text": "and save the model to the model registry. Then I have an inference", "timestamp": "00:34:10,352", "timestamp_s": 2050.0}, {"text": "pipeline, in this case the batch prediction pipeline. It\u0027s going to go", "timestamp": "00:34:14,442", "timestamp_s": 2054.0}, {"text": "to the feature store, connect to the model registry", "timestamp": "00:34:18,164", "timestamp_s": 2058.0}, {"text": "as well, download our model, get some batch data that\u0027s", "timestamp": "00:34:21,978", "timestamp_s": 2061.0}, {"text": "going to score with in this case it\u0027s getting all the data. But we can", "timestamp": "00:34:25,434", "timestamp_s": 2065.0}, {"text": "specify a time range or a set of ids that we\u0027d like to score for,", "timestamp": "00:34:28,408", "timestamp_s": 2068.0}, {"text": "and then we can go ahead and make our predictions,", "timestamp": "00:34:32,552", "timestamp_s": 2072.0}, {"text": "and then we can save those predictions. So what we\u0027re doing is downloading the model", "timestamp": "00:34:36,078", "timestamp_s": 2076.0}, {"text": "first. But once we have the model, then we can make predictions on our", "timestamp": "00:34:39,580", "timestamp_s": 2079.0}, {"text": "data frame and we can save those then predictions to", "timestamp": "00:34:42,908", "timestamp_s": 2082.0}, {"text": "a data store and we\u0027re done. So that\u0027s it. That\u0027s the kind of end to", "timestamp": "00:34:47,052", "timestamp_s": 2087.0}, {"text": "end machine learning system that you can have and build with", "timestamp": "00:34:50,528", "timestamp_s": 2090.0}, {"text": "this feature training inference pipeline", "timestamp": "00:34:55,040", "timestamp_s": 2095.0}, {"text": "architecture. And we do the feature store model registry as the data layer,", "timestamp": "00:34:58,678", "timestamp_s": 2098.0}, {"text": "pulling it all together. If you\u0027re curious to find out more,", "timestamp": "00:35:02,362", "timestamp_s": 2102.0}, {"text": "I work with Hopsirix, which is a core part of this new serverless", "timestamp": "00:35:06,610", "timestamp_s": 2106.0}, {"text": "machine training stack. You can go to app hopsearch AI and create", "timestamp": "00:35:10,538", "timestamp_s": 2110.0}, {"text": "a free account or join our slack. But if you really want to learn more", "timestamp": "00:35:14,388", "timestamp_s": 2114.0}, {"text": "about building these service machine learning systems, I recommend you take", "timestamp": "00:35:17,928", "timestamp_s": 2117.0}, {"text": "a course that I developed called serverless ML. It\u0027s all Python,", "timestamp": "00:35:22,152", "timestamp_s": 2122.0}, {"text": "pure Python. The course came out in the fall last year,", "timestamp": "00:35:25,742", "timestamp_s": 2125.0}, {"text": "so we weren\u0027t using modal or hugging face. There is no hugging face there,", "timestamp": "00:35:29,356", "timestamp_s": 2129.0}, {"text": "I should admit, but it uses GitHub actions instead of modal.", "timestamp": "00:35:32,748", "timestamp_s": 2132.0}, {"text": "But they\u0027re both great tools for orchestrating and running Python", "timestamp": "00:35:36,722", "timestamp_s": 2136.0}, {"text": "programs. If you want to learn more, go to serverlessml.org,", "timestamp": "00:35:40,498", "timestamp_s": 2140.0}, {"text": "give it a whirl, and good luck on your journey on serverless machine learning.", "timestamp": "00:35:45,474", "timestamp_s": 2145.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'nQR3fz1KD3g',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              The machine learning pipeline is a myth - build production ML systems with feature/training/inference pipelines
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Developers often erroneously talk about ML pipelines. But real-world ML systems have many moving components, not a single monolithic ML pipeline. In this talk, we show how to build ML systems as a composition of feature pipelines, training pipelines, and inference pipelines with a shared data layer.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Jim Dowling: How we can refactor this monolithic machine learning pipeline that many of you may have heard about before into what we call feature training and inference pipelines. He says it's too complex to make anything easy for developers to put in production or for people to maintain.

              </li>
              
              <li>
                In Python, we're not going to use infrastructure. We're going to talk about the way in which we advocate for structuring these machine learning systems to make it easier to manage them. What we typically have are three main components, the feature pipeline, the training pipeline, and the inference pipeline.

              </li>
              
              <li>
                The feature pipeline will take your raw data, it'll compute features from it that's compressed signal that we're going to use to train our models with and also to make predictions with. Features can be stored online and offline via both the online and streaming API.

              </li>
              
              <li>
                We can do batch inference with the feature view as well. For feature views we can specify specific features that we'd like to transform. This ensures consistency of these transformation functions between this training pipeline and this inference pipeline.

              </li>
              
              <li>
                You can write Python programs in a very nice tool called modal. It basically can schedule Python programs for you. This is a really nice way to build what we call serverless machine learning systems. There's a bunch of these on the Internet.

              </li>
              
              <li>
                There's a ton of them here in Hopsterick's tutorials. The one I'm going to show you briefly here is called credit scores. This is a really good way of doing synthetic feature pipelines if you can't access the actual data.

              </li>
              
              <li>
                 app hopsearch AI is free to create an account. It's time unlimited. You can build systems on it. The feature view you can create is the selection of features. And then we can see any training data sets created from it. These two notebooks really make the two the production system.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/assemblyai/nQR3fz1KD3g.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:24,410'); seek(24.0)">
              Hi, welcome to this talk on the mythical machine learning
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:28,684'); seek(28.0)">
              pipeline. My name's Jim Dowling, and I'm going to talk about
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:32,988'); seek(32.0)">
              how we can refactor this monolithic machine learning pipeline that many
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:36,924'); seek(36.0)">
              of you may have heard about before into what we call
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:40,316'); seek(40.0)">
              feature training and inference pipelines. We're going to do it all in Python,
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:44,114'); seek(44.0)">
              and we're going to decompose the machine learning pipelines into
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:48,188'); seek(48.0)">
              these smaller, more manageable parts to build machine learning systems.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:52,930'); seek(52.0)">
              So I'm going to start by making a claim that mlops, or machine
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:56,874'); seek(56.0)">
              learning operations as it exists today, is too hard. It's kind
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:01:00,084'); seek(60.0)">
              of like this telecom tower here. It's a very brittle set
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:03,492'); seek(63.0)">
              of systems that we're plugging together to try and put machine learning at production.
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:07,950'); seek(67.0)">
              But really it's too complex to make anything which is
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:11,368'); seek(71.0)">
              going to be either easy for developers and in particular python
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:14,718'); seek(74.0)">
              developers to put in production or for people to
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:18,248'); seek(78.0)">
              maintain. So if we look at mlops according to Google on
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:21,852'); seek(81.0)">
              this diagram, we can see here a lot of boxes. So this notion that you
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:25,772'); seek(85.0)">
              start at data and you go through many stages of processing the
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:29,488'); seek(89.0)">
              data, validating it, preparing it, training models, validating models,
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:33,478'); seek(93.0)">
              and all of this happens in one big, monolithic,
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:36,550'); seek(96.0)">
              orchestrated ML pipeline. I'm going to show you that
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:40,128'); seek(100.0)">
              we don't need to do it that way. Databricks are following a similar
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:43,860'); seek(103.0)">
              pattern for how to encourage people to what they
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:47,412'); seek(107.0)">
              say is follow Mlox best practice.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:51,090'); seek(111.0)">
              I see this really as being an overcomplication of something which is much
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:54,792'); seek(114.0)">
              easier to do, which is just to build machine learning systems
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:58,790'); seek(118.0)">
              and do it to the principles of decomposing complexity and
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:02,728'); seek(122.0)">
              then putting those parts together again. And for ML ops
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:05,998'); seek(125.0)">
              in particular, which is really about building systems
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:09,634'); seek(129.0)">
              that we can incrementally improve and automatically test
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:13,292'); seek(133.0)">
              and version and so on, we don't need to go down to the infrastructure
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:17,058'); seek(137.0)">
              level, we can stay in Python. That's one of the key points I want to
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:19,744'); seek(139.0)">
              make here. You don't need to become a dockers or a Kubernetes expert
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:23,718'); seek(143.0)">
              in order to do ML ops.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:28,110'); seek(148.0)">
              This is classic tensorflow extended. This is what
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:31,712'); seek(151.0)">
              many people learn in courses that they take in machine learning operations,
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:35,546'); seek(155.0)">
              that you need to go from the very beginning to the very end in one
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:38,836'); seek(158.0)">
              big m to ML pipeline. So machine learning pipeline,
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:42,874'); seek(162.0)">
              I say it's mythical, because in practice, I've never seen
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:46,120'); seek(166.0)">
              an end to end pipeline written like this. Where the data comes
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:49,352'); seek(169.0)">
              in, it's validated, transformed into features,
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:53,070'); seek(173.0)">
              models are trained, models are analyzed, then they're validated,
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:57,006'); seek(177.0)">
              and then they're served all in one big monolithic directed
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:01,038'); seek(181.0)">
              acyclic graph. That's not typically the way it works. And the
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:04,588'); seek(184.0)">
              reason why it doesn't work like that is because monolithic ML
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:07,986'); seek(187.0)">
              pipelines, they couple different natural stages
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:12,278'); seek(192.0)">
              of machine learning systems. So you have what's called
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:15,472'); seek(195.0)">
              feature engineering, where we take the raw data and turn it into the data,
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:19,136'); seek(199.0)">
              the features that we're going to use to train models, but also
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:22,212'); seek(202.0)">
              to make predictions with. Now, if you couple that phase
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:25,642'); seek(205.0)">
              with the model training phase, training might require
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:29,402'); seek(209.0)">
              gpus. If you're using deep learning, feature engineering does not require
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:33,322'); seek(213.0)">
              gpus. You put it all into one large system,
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:36,520'); seek(216.0)">
              and then suddenly you're using maybe gpus for feature engineering,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:39,758'); seek(219.0)">
              which is quite wasteful in terms of resources. If your feature engineering
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:43,678'); seek(223.0)">
              is done once a day, because your new data arrives every day, but you
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:46,968'); seek(226.0)">
              need to predict every hour, why would you couple those two things together?
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:50,588'); seek(230.0)">
              Inference should not be coupled to feature engineering when they run at
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:54,108'); seek(234.0)">
              different cadences. By coupling them all together, you're adding development
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:58,214'); seek(238.0)">
              and operational complexity. You're also not reusing any
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:02,432'); seek(242.0)">
              of the data or features that have been created by your
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:05,808'); seek(245.0)">
              feature pipelines, and it's too hard to build
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:08,912'); seek(248.0)">
              these systems in such a way to get to a minimal viable product.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:12,512'); seek(252.0)">
              I'll give you an example of one, Kubeflow pipelines, just to pick on one
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:16,436'); seek(256.0)">
              could have picked on many different systems. They claim on their website
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:20,372'); seek(260.0)">
              that it enables you to reuse components and pipelines
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:24,190'); seek(264.0)">
              quickly, easily, to create end to end solutions
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:27,982'); seek(267.0)">
              without having to rebuild each time. I've never seen this happen in practice.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:31,990'); seek(271.0)">
              So mlops, we still want to follow
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:36,056'); seek(276.0)">
              the principles of mlops, and that means testing your software.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:40,098'); seek(280.0)">
              And you can think of it as being a hierarchy of needs. You have raw
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:43,698'); seek(283.0)">
              data which needs to be tested to create features. Features are
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:47,308'); seek(287.0)">
              used to create models, so the features need to be tested in order to create
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:50,588'); seek(290.0)">
              the models, and the models need to be tested in
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:54,128'); seek(294.0)">
              order to use them by the ML enabled applications. And typically your ML
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:58,246'); seek(298.0)">
              enabled application will want to a b test a model before it then uses
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:02,582'); seek(302.0)">
              and switches over to a new version of a model. But that's where we want
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:06,228'); seek(306.0)">
              to get on the top of the pyramid of needs, if we will,
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:10,228'); seek(310.0)">
              for mlops. But we need to start somewhere. And the place
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:13,332'); seek(313.0)">
              to start, as any software developer will tell you, is with
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:16,452'); seek(316.0)">
              a working system. And in this case we're building a machine learning system. So we
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:19,848'); seek(319.0)">
              need to get to a working machine learning system as quickly as possible.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:23,496'); seek(323.0)">
              And that means we need to have some code which will create the features
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:27,262'); seek(327.0)">
              we need to have some code to train the model, and we need to have
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:30,284'); seek(330.0)">
              some code to make predictions or inference on new data that
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:33,548'); seek(333.0)">
              arrives using our model. So ML
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:37,218'); seek(337.0)">
              Ops as a set of principles helps you to get through
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:40,748'); seek(340.0)">
              a working system as quickly as possible with a baseline and
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:44,112'); seek(344.0)">
              iteratively improve it. And the reason why you should be able to iteratively improve
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:47,558'); seek(347.0)">
              your software, if you're following DevOps or ML Ops principles,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:50,662'); seek(350.0)">
              is that you're testing. We're testing the features, the models,
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:54,794'); seek(354.0)">
              and we're versioning the features and models. So if we're going to do upgrades,
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:58,698'); seek(358.0)">
              if we're going to deploy a new model that's connected to some new features,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:02,618'); seek(362.0)">
              if they're both not versioned, we'll have a terrible time
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:06,344'); seek(366.0)">
              connecting those two things together and ensuring that things can be safely upgraded.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:10,398'); seek(370.0)">
              So once you have testing and versioning in place for
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:13,992'); seek(373.0)">
              the two main assets that we see in machine learning systems, features and models,
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:18,514'); seek(378.0)">
              then you're able to move quickly, you're able to make small changes
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:22,700'); seek(382.0)">
              and improve your iteration speed, and you're testing your
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:26,412'); seek(386.0)">
              models and you're testing your features. So you're improving the quality of your software,
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:30,162'); seek(390.0)">
              and that's ultimately where you want to get to where you can move more quickly,
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:33,600'); seek(393.0)">
              make small changes to iteratively improve your systems,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:37,142'); seek(397.0)">
              and be confident that the changes that you make will not break everything.
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:41,232'); seek(401.0)">
              So that's the goal of Mlops, and that's what we as developers would
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:44,868'); seek(404.0)">
              like to use to make our code better. Let's jump
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:48,714'); seek(408.0)">
              into ML Ops. In Python, we're not going to use infrastructure.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:52,154'); seek(412.0)">
              There'll be no docker or Kubernetes or we're not
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:55,684'); seek(415.0)">
              going to talk cloud infrastructure. We're going to talk about the way
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:59,128'); seek(419.0)">
              in which we advocate, and particularly I advocate for structuring these
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:02,760'); seek(422.0)">
              machine learning systems to make it easier to manage them.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:05,896'); seek(425.0)">
              So what we typically have are these three main components, the feature pipeline,
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:10,322'); seek(430.0)">
              the training pipeline, the inference pipeline. I call this the FTI
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:14,226'); seek(434.0)">
              pattern to make it easier to remember you have one program. In this
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:18,188'); seek(438.0)">
              case, we're looking to look at Python programs, which takes data from our
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:21,468'); seek(441.0)">
              data sources. This program will be typically an operational program,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:24,896'); seek(444.0)">
              so it might need to be scheduled. It could be airflow if it's Python,
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:27,910'); seek(447.0)">
              or it could be a Python program that's scheduled to run
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:31,348'); seek(451.0)">
              in the cloud. So there's some pretty nice tooling out there, like modal,
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:34,826'); seek(454.0)">
              who allow you to schedule these Python programs
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:41,090'); seek(461.0)">
              with a cron like hourly run or daily
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:45,102'); seek(465.0)">
              run. And those programs are basically going to read your
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:49,032'); seek(469.0)">
              raw data, compute, features. If you've got supervised
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:52,558'); seek(472.0)">
              machine learning, you may need to create labels as well. And rather than
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:56,152'); seek(476.0)">
              store that data in an object store or in a distributed file
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:00,018'); seek(480.0)">
              system, we're going to look at a feature store as a way
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:03,388'); seek(483.0)">
              to store that data. And that's because the feature store will provide
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:06,572'); seek(486.0)">
              us with a very nice data frame API. Much feature engineering and feature
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:10,098'); seek(490.0)">
              pipelines are written in frameworks like pandas. If you need more performance,
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:14,182'); seek(494.0)">
              you might move to polars. If you have a lot of data, you might move
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:16,928'); seek(496.0)">
              to Pyspark. But the output of all of
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:20,288'); seek(500.0)">
              those is a data frame. So if you can write that data frame, and you
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:24,388'); seek(504.0)">
              can obviously do that in a secure manner. So we'll use API keys.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:28,378'); seek(508.0)">
              For example, when we write to Hopsworks, then you don't
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:32,154'); seek(512.0)">
              have to worry about the complexity of if you're in a cloud environment,
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:35,386'); seek(515.0)">
              getting access to a particular bucket, an IAM role that gives
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:38,888'); seek(518.0)">
              you permissions to do that. It's basically going to be an
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:42,232'); seek(522.0)">
              API key, some privileges associated with it, and then write
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:45,528'); seek(525.0)">
              your data frame. So your training pipeline should be able to use the
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:48,604'); seek(528.0)">
              feature store in the same way. We'll be able to say, okay,
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:51,628'); seek(531.0)">
              I'm going to select features from all of the available features,
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:55,266'); seek(535.0)">
              create some training data, select labels as well, train my
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:59,372'); seek(539.0)">
              model, and when my model has been trained, I'll need to store it somewhere.
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:02,182'); seek(542.0)">
              So typically where we would store models is in some place called a model registry.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:06,118'); seek(546.0)">
              There are many model registries out there, some of them are hosted
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:09,318'); seek(549.0)">
              over the Internet. Hopsteryx is also hosted over the Internet.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:12,742'); seek(552.0)">
              We can call that serverless model registry or serverless feature store.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:16,610'); seek(556.0)">
              But it basically means at least when you're getting started, you can write
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:19,988'); seek(559.0)">
              a python program on your laptop or in colab, and it
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:23,556'); seek(563.0)">
              can read from a feature store and write your model back into a model
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:27,476'); seek(567.0)">
              registry. So Hopsrix also is a model registry. We'll look at that later.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:31,270'); seek(571.0)">
              And then finally, when you have an inference pipeline, this is when you want to
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:34,424'); seek(574.0)">
              generate value for your model. And this is where most machine learning courses
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:37,938'); seek(577.0)">
              stop. They'll train a model they'll evaluate on a static
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:43,650'); seek(583.0)">
              test set. So a holdout data set to see how the
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:46,844'); seek(586.0)">
              model generalizes on data it hasn't seen before, which is
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:50,012'); seek(590.0)">
              great. But if you want to see your model in the natural environment where
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:54,048'); seek(594.0)">
              it's creating value, you should write an end to end system
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:57,248'); seek(597.0)">
              so that new data can come in through the feature pipelines. And for a batch
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:00,982'); seek(600.0)">
              inference application it can take that new data that's been written via
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:04,458'); seek(604.0)">
              the feature pipeline. Read it up as features, read up the model from the
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:07,988'); seek(607.0)">
              model registry, generate the predictions, and store them somewhere
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:12,074'); seek(612.0)">
              where maybe a downstream dashboard or an operational
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:15,630'); seek(615.0)">
              system will consume those production to make those applications
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:19,182'); seek(619.0)">
              AI enabled. Of course, this generates logs. You typically want to save
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:22,856'); seek(622.0)">
              those to help improve your observability and monitoring of the system.
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:27,450'); seek(627.0)">
              So I'm going to look at a little demo later on. The code is available
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:30,668'); seek(630.0)">
              on the link below. It's basically
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:34,748'); seek(634.0)">
              looking at credit scoring as a machine learning system. This is quite a popular
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:38,562'); seek(638.0)">
              type of machine learning system we see at financial
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:42,022'); seek(642.0)">
              institutions. You may have information about people
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:46,192'); seek(646.0)">
              who would like to apply for credit, and we'd like to give them a score
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:49,542'); seek(649.0)">
              to decide on whether we're going to give that person credit or
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:53,184'); seek(653.0)">
              not. So typically what you'll need to have is data
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:56,532'); seek(656.0)">
              from different sources. And you can see there's some sources on the left
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:59,876'); seek(659.0)">
              here. A feature pipeline will create the features from those
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:03,368'); seek(663.0)">
              data sources. Training pipeline will train your model. We look
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:06,552'); seek(666.0)">
              at an Xgboost model and then inference pipeline will take
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:09,928'); seek(669.0)">
              this XgBoost model and then some new credits.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:14,870'); seek(674.0)">
              So credit applications to score and that could be done in a batch manner.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:18,878'); seek(678.0)">
              You could have like a batch that arrive and once a day you score them
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:22,268'); seek(682.0)">
              and then you send an email out the next day to say you're approved.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:25,698'); seek(685.0)">
              But even better would be an interactive application. So as the user goes
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:29,868'); seek(689.0)">
              to a website and fills in their details, then we can have an online
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:33,790'); seek(693.0)">
              system which can read those features back and the feature store and
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:37,648'); seek(697.0)">
              hopsearch in particular enables that. We're going to look at the batch case
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:40,864'); seek(700.0)">
              today and the training pipeline. It can
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:44,148'); seek(704.0)">
              be run in any kind of training environment, any Python
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:47,626'); seek(707.0)">
              enabled environment. And our pipelines can also be run in any
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:50,932'); seek(710.0)">
              Python environment. So today we'll look at running it in my notebook,
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:54,450'); seek(714.0)">
              but of course you can schedule them to run in any Python
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:58,238'); seek(718.0)">
              environment. So let's start and look at feature pipelines
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:02,790'); seek(722.0)">
              and have a look at a little bit of the code that we need to
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:05,688'); seek(725.0)">
              create a feature pipeline. So the feature pipeline will take your raw data,
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:09,016'); seek(729.0)">
              it'll compute features from it that's compressed signal that we're going to use to train
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:12,796'); seek(732.0)">
              our models with and also to make predictions with. So there's an example here
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:16,588'); seek(736.0)">
              we're using pandas to do our transformations. So we
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:20,192'); seek(740.0)">
              call these model independent transformations because the features we store in the
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:23,344'); seek(743.0)">
              features store should be reusable across many different models.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:27,790'); seek(747.0)">
              We can see here that here we're doing a classic aggregation
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:31,882'); seek(751.0)">
              where we're counting the number of events happening in a four hour window.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:36,290'); seek(756.0)">
              We can see here that when we've created
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:39,738'); seek(759.0)">
              a data frame window AGSDF here with our features
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:43,258'); seek(763.0)">
              that we'd like to use in our feature store, we'd like to
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:47,128'); seek(767.0)">
              store them in the feature store. And these features here are related to the credit
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:50,616'); seek(770.0)">
              card, the number of transactions, or the frequency of the transactions in
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:54,488'); seek(774.0)">
              that four hour period of time. But basically with this
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:58,184'); seek(778.0)">
              window AGS data frame, what we're going to do is we're going
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:01,804'); seek(781.0)">
              to insert it into this thing called a feature store. So here we're creating the
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:04,748'); seek(784.0)">
              feature store. We're giving it a name and a version, a description.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:07,794'); seek(787.0)">
              We're identifying which column is the primary key. So the unique row level identifier
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:12,422'); seek(792.0)">
              column that uniquely identifies each row in this data frame.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:16,214'); seek(796.0)">
              If there is a unique timestamp column
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:19,606'); seek(799.0)">
              within that particular data
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:23,296'); seek(803.0)">
              frame, it doesn't need to be unique. Of course, they can be
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:26,388'); seek(806.0)">
              the same across many different rows, but if there is an event time at which
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:29,780'); seek(809.0)">
              that particular row was generated as a column, you can specify
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:33,322'); seek(813.0)">
              it here, because what we'll see is that in feature stores,
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:36,954'); seek(816.0)">
              if I have many different tables of features that have different event times on them,
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:41,256'); seek(821.0)">
              we need to line those up so that we don't get what we call data
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:44,936'); seek(824.0)">
              leakage. So we don't get future data. When we join these columns
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:48,910'); seek(828.0)">
              of features together from different tables, we don't want to have data that's
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:52,594'); seek(832.0)">
              in the future because then our model will be able to learn from future data
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:56,076'); seek(836.0)">
              which we don't want to do. So that's called data leakage. We want to avoid
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:58,738'); seek(838.0)">
              it. So if you specify the event time column in your feature group that
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:03,248'); seek(843.0)">
              can be used by the feature store to do what's
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:06,614'); seek(846.0)">
              called a point in time correct join, so there's no data leakage. So once
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:10,768'); seek(850.0)">
              you've created this feature group object, you can just insert your pandas data frame.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:14,458'); seek(854.0)">
              So you just call insert on it, it'll write it to the feature store and
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:17,908'); seek(857.0)">
              your data will end up there. Now,
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:20,930'); seek(860.0)">
              Python is great for that smaller scale of data. If you have
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:24,852'); seek(864.0)">
              larger volumes of data, you may want to use to Pyspark. It's great
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:28,168'); seek(868.0)">
              for scale and testing, but it's obviously a bit more challenging to develop with,
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:32,424'); seek(872.0)">
              more challenging to debug with and operate. SQL is also
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:36,008'); seek(876.0)">
              quite popular. SQL has low operational
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:39,986'); seek(879.0)">
              overhead. It can scale quite well. There are many different features, as you know,
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:43,772'); seek(883.0)">
              that are very difficult to implement in SQL.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:47,042'); seek(887.0)">
              Even if you embed udfs in your data warehouse,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:50,670'); seek(890.0)">
              things like embeddings and there's many libraries
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:54,118'); seek(894.0)">
              of course, in pandas we use to compute features that are not particularly suitable
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:57,366'); seek(897.0)">
              in SQL. Now Python is obviously
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:01,236'); seek(901.0)">
              a great and popular language to develop
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:04,628'); seek(904.0)">
              features in, so it has low operational overhead.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:08,138'); seek(908.0)">
              Pandas is very popular, Polars has become popular.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:11,546'); seek(911.0)">
              It scales to larger data volumes than pandas,
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:15,490'); seek(915.0)">
              but they're all good choices. Now if you need stream processing,
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:19,022'); seek(919.0)">
              so very low latency features that are computed on real time data,
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:22,632'); seek(922.0)">
              then you might want to look at a streaming framework like Flink or
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:26,556'); seek(926.0)">
              Pyspark, which also has spark streaming.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:29,442'); seek(929.0)">
              So if you want to write that code in Python, probably Pyspark is your best.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:32,908'); seek(932.0)">
              But Flink is very Java centric.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:36,650'); seek(936.0)">
              So in hopsworks we can write the data
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:40,236'); seek(940.0)">
              to the feature store from Python in what we call a streaming API
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:43,942'); seek(943.0)">
              or a batch API. The batch API will store the data offline. It's only
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:47,552'); seek(947.0)">
              historical data, so it'll only be available via this offline API.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:51,366'); seek(951.0)">
              So the offline API is to get training data or batch data
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:54,848'); seek(954.0)">
              that you'd like to do inference on. But if you have an online application,
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:15:58,324'); seek(958.0)">
              you need low latency access to your features. So if we
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:01,588'); seek(961.0)">
              have for example the credit scoring application that needs to look up your
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:05,188'); seek(965.0)">
              features within a few milliseconds because it's going to do a live prediction
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:09,646'); seek(969.0)">
              of your credit score, then you need the online
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:13,160'); seek(973.0)">
              API. So in that case you write using the streaming API.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:16,710'); seek(976.0)">
              Now in Hopster's the default is a streaming API.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:19,918'); seek(979.0)">
              So when I called insert on my feature group, it wrote the data via
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:23,058'); seek(983.0)">
              this API. It'll be stored both an online offline store and
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:34,444'); seek(994.0)">
              it'll be available via both the online and offline APIs.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:38,750'); seek(998.0)">
              Now what we can see here is that the tables of features
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:42,438'); seek(1002.0)">
              are called feature groups, and then we have something called a feature view.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:45,970'); seek(1005.0)">
              So in hopsworks you're able to reuse features across many
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:49,812'); seek(1009.0)">
              different models. And the way you do that is by selecting features into something called
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:53,348'); seek(1013.0)">
              a feature view. So you can select from many different feature groups, all updated potentially
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:57,166'); seek(1017.0)">
              by different feature pipelines, and then the feature store will perform
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:01,000'); seek(1021.0)">
              this point in time correct join for you.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:05,590'); seek(1025.0)">
              So if we're able to reuse features across many different models,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:08,878'); seek(1028.0)">
              we can see here one model at the top it has a feature view selecting
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:12,418'); seek(1032.0)">
              a certain set of features, another feature view down here selecting different features,
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:16,066'); seek(1036.0)">
              and each one can create their own training data sets. Train your models on
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:19,788'); seek(1039.0)">
              and each one can pull out. Then if we're doing batch inference, you'll pull the
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:23,552'); seek(1043.0)">
              features by the feature view, say well, the data that arrived in the last 24
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:27,088'); seek(1047.0)">
              hours, for example, and then you'll
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:30,442'); seek(1050.0)">
              do inference on those with your model.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:34,450'); seek(1054.0)">
              Now training pipelines use these feature views to
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:38,388'); seek(1058.0)">
              read data to train models with. So it
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:41,588'); seek(1061.0)">
              uses this offline API. You can get your data back as files,
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:45,482'); seek(1065.0)">
              maybe CSV or parquet or TF records
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:49,518'); seek(1069.0)">
              even. Or you can get in the back as a pandas data frame if the
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:52,424'); seek(1072.0)">
              data is not too large. And you can train directly with
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:55,592'); seek(1075.0)">
              your data. And it has if support written nice things like random splits and
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:17:59,048'); seek(1079.0)">
              time series splits of your data. So you don't need to do that. Even in
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:01,628'); seek(1081.0)">
              Scikitlearn you can just read the ready made split data
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:05,596'); seek(1085.0)">
              frames with your features and labels.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:09,130'); seek(1089.0)">
              So the feature view itself is an API for model development and also
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:12,880'); seek(1092.0)">
              for operations. In the online case, you basically select
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:16,576'); seek(1096.0)">
              your features. You say what label it is for this particular feature
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:20,486'); seek(1100.0)">
              view. One other thing that you might want to do is features
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:24,218'); seek(1104.0)">
              are typically shared untransformed. So what that means
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:27,908'); seek(1107.0)">
              is if you have a categorical variable, store it in the feature store unencoded,
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:32,138'); seek(1112.0)">
              and then when your model is selected, it can encode it, because some models
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:35,806'); seek(1115.0)">
              will need to encode categorical variables.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:39,670'); seek(1119.0)">
              So for example gradient descent based models, but other
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:42,952'); seek(1122.0)">
              models, so cat boost for example,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:46,550'); seek(1126.0)">
              can work directly with the categorical data. And the same
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:50,348'); seek(1130.0)">
              is true for numerical variables. So we call those model specific transformations.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:53,842'); seek(1133.0)">
              They can be associated with features in the feature view so that you don't have
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:18:57,372'); seek(1137.0)">
              to write that code separately yourself.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:00,944'); seek(1140.0)">
              Because there is a potential that if you write the code in the training pipeline
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:04,022'); seek(1144.0)">
              to transform features like encode them
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:07,536'); seek(1147.0)">
              or normalize numerical features, you need to do the same thing in the
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:11,344'); seek(1151.0)">
              inference pipeline. And there is a potential for what we call SKU there.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:14,628'); seek(1154.0)">
              So the feature view will help you avoid that potential problem,
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:18,628'); seek(1158.0)">
              feature view. Then once you have it, it can apply the model
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:22,452'); seek(1162.0)">
              specific transformations on the data, create training data, batch inference data,
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:25,832'); seek(1165.0)">
              and it'll apply those transformations consistently.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:29,510'); seek(1169.0)">
              So the point in time correct join I mentioned already, you take tables from
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:33,768'); seek(1173.0)">
              features from different tables, ensure that they're lined up on
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:37,068'); seek(1177.0)">
              the correct transaction event time here. So this value
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:40,524'); seek(1180.0)">
              of this category at this point
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:43,788'); seek(1183.0)">
              in time, we can look up the amount
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:47,020'); seek(1187.0)">
              for that particular week and month, and we're not going to get future values in
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:50,508'); seek(1190.0)">
              here. There'd be no data leakage. Now, if you
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:19:53,888'); seek(1193.0)">
              were to write this join this point in time correct join yourself. It's going to
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:19:57,264'); seek(1197.0)">
              be quite complex. For that example, we can see there's quite a lot of SQL
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:20:00,902'); seek(1200.0)">
              code for it, but in Python you just write the following code below.
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:20:04,436'); seek(1204.0)">
              You select the features that you'd like from the different feature groups.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:20:07,658'); seek(1207.0)">
              You join them together in pandas like syntax,
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:11,098'); seek(1211.0)">
              and you then get back what's called a query
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:14,762'); seek(1214.0)">
              object. This is our selection of features, and then we can create our
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:18,088'); seek(1218.0)">
              feature view with that particular selection of features.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:21,830'); seek(1221.0)">
              Now once we've created our feature view, we can see we've got a feature view
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:25,512'); seek(1225.0)">
              object here, we can create training data from it, and we can
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:28,840'); seek(1228.0)">
              ready split that train data into random sets, a test
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:32,332'); seek(1232.0)">
              set and a training set, and a validation set as well, even, and you
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:36,124'); seek(1236.0)">
              can say what the file format you'd like to store that train data is.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:39,276'); seek(1239.0)">
              You can also get the train data back directly as pandas data
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:43,008'); seek(1243.0)">
              frames. So here we can get our features in the training,
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:47,150'); seek(1247.0)">
              test and validation sets and the labels in the training,
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:20:50,352'); seek(1250.0)">
              validation and test sets back. And I don't need to run it through scikitlearn
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:20:54,666'); seek(1254.0)">
              splitting algorithm. This is going to be a random split, but there is also a
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:20:57,684'); seek(1257.0)">
              time series split. So you can say if I've got a
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:21:01,428'); seek(1261.0)">
              time series model and time series data, I'll train on maybe
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:21:05,352'); seek(1265.0)">
              the data here up to version two, and then I'll predict
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:21:09,910'); seek(1269.0)">
              how my test set will be the data that came after the
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:13,720'); seek(1273.0)">
              end of this particular point in time.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:17,830'); seek(1277.0)">
              Now what you can also do with a feature view is you can get training
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:21,516'); seek(1281.0)">
              data, for example for version one of your model, or get training data for version
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:24,882'); seek(1284.0)">
              two. New data will keep training in the system, the feature pipelines will keep
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:29,196'); seek(1289.0)">
              training new features, and then you can read that
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:32,512'); seek(1292.0)">
              data and make predictions on it. So we can do batch inference with
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:35,648'); seek(1295.0)">
              the feature view as well. We create batch inference data and
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:40,032'); seek(1300.0)">
              finally for feature views we can specify specific features
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:43,594'); seek(1303.0)">
              that we'd like to transform. So here we're saying the amount of money last month
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:47,332'); seek(1307.0)">
              we're going to apply the standard scalar, the category
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:50,858'); seek(1310.0)">
              variable. We're going to encode it, it's categorical variable,
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:21:54,042'); seek(1314.0)">
              apply a label encoder on it, and the same for amount last week,
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:21:57,268'); seek(1317.0)">
              the standard scalar. So when we read the training data, the batch
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:22:00,862'); seek(1320.0)">
              inference data, or in this case the online inference data, the feature
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:22:04,446'); seek(1324.0)">
              vector, it'll apply these transformations after it's read the
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:22:08,044'); seek(1328.0)">
              data in the feature store, but before it's returned to the client. And this ensures
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:11,874'); seek(1331.0)">
              consistency of these transformation functions between this training pipeline
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:15,634'); seek(1335.0)">
              and this inference pipeline. You can do it yourself in scikitlearn pipelines,
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:19,954'); seek(1339.0)">
              and then you need to make sure that both of these are consistent.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:24,590'); seek(1344.0)">
              So let's move over to inference pipelines and we'll
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:28,358'); seek(1348.0)">
              have a look at some of the code. This is a predictor
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:31,990'); seek(1351.0)">
              class. So this is a model that you will be deployed in a model
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:35,316'); seek(1355.0)">
              serving server. We can see here the method called predict.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:39,210'); seek(1359.0)">
              But before we predict, we need to initialize this object. So when it's
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:42,378'); seek(1362.0)">
              loaded into our model serving server, init will be called
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:45,876'); seek(1365.0)">
              we'll connect to the feature store that we can see here. We'll initialize the feature
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:49,646'); seek(1369.0)">
              store. And what we need to do is we need to tell it what
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:22:53,192'); seek(1373.0)">
              the version of the training data was that we trained
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:22:56,734'); seek(1376.0)">
              our model on, because we can create many different train data sets from a feature
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:22:59,902'); seek(1379.0)">
              view. So here it was version number one. So we say, okay, I'm going to
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:23:03,452'); seek(1383.0)">
              initialize my feature view on version number one. The reason we need to do that
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:23:06,588'); seek(1386.0)">
              is the transformations often need the state from
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:10,028'); seek(1390.0)">
              that training data set version. So if I'm normalizing a numerical feature,
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:13,750'); seek(1393.0)">
              I'll need to know what the mean value of that feature was in
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:17,248'); seek(1397.0)">
              the training data set the model was training on. So that
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:20,688'); seek(1400.0)">
              information is captured in the feature view. You don't need to supply train data set
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:24,356'); seek(1404.0)">
              when you're deploying your model for serving here.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:27,810'); seek(1407.0)">
              And then you can see we're loading the model from the model registry and it's
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:31,754'); seek(1411.0)">
              now available in our predict object. So when a request comes in to make a
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:34,584'); seek(1414.0)">
              prediction, the model is loaded, the connection to the feature store has been established,
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:38,718'); seek(1418.0)">
              and we can just call self dot model
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:42,680'); seek(1422.0)">
              predict, return the pre computed features from the
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:23:45,784'); seek(1425.0)">
              feature store here and then send them to the model to make the prediction.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:23:49,458'); seek(1429.0)">
              So this is going to go to the feature store, return our precomputed features.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:23:52,978'); seek(1432.0)">
              We're going to cast them to a numpy array, and then the
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:23:56,332'); seek(1436.0)">
              model predict method will be applied to that numpy array to make our prediction,
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:23:59,734'); seek(1439.0)">
              which is returned to the client. Let's have
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:24:03,648'); seek(1443.0)">
              a quick look at a demo. So this
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:24:07,712'); seek(1447.0)">
              particular demo, the way that we often see
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:11,072'); seek(1451.0)">
              a lot of these machine learning systems built when
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:14,148'); seek(1454.0)">
              people are starting out, when you want to use get started as
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:17,732'); seek(1457.0)">
              quickly as possible, is you can write Python programs in a very
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:21,732'); seek(1461.0)">
              nice tool called modal. So modal has a very generous
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:25,502'); seek(1465.0)">
              free tier. It basically can schedule Python programs
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:29,118'); seek(1469.0)">
              for you. And if you need to install libraries, you just annotate the functions
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:33,198'); seek(1473.0)">
              and say Pip, install hopsworks, for example.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:37,190'); seek(1477.0)">
              And in that modal code we can write our feature engineering pipeline that we
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:40,908'); seek(1480.0)">
              saw earlier. It'll read the data and write data frames to hopsworks.
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:45,042'); seek(1485.0)">
              And then modal can also train. You may want to train because training is
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:24:48,908'); seek(1488.0)">
              not an operational system. You can train on colab and do it
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:24:53,950'); seek(1493.0)">
              offline, if you will, or on demand, or when the
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:24:57,408'); seek(1497.0)">
              model has become stale. You don't necessarily need to do it every day as you
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:25:00,896'); seek(1500.0)">
              would when in a feature pipeline if new data was arriving every day,
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:25:04,628'); seek(1504.0)">
              and then for inference. Again, it's an operational system.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:08,404'); seek(1508.0)">
              So maybe it's going to be either on demand when the user
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:11,866'); seek(1511.0)">
              goes into the website in an interactive system, makes a prediction,
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:15,198'); seek(1515.0)">
              or maybe it's going to be a dashboard that gets updated
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:19,198'); seek(1519.0)">
              at some cadence. So hugging faces is a really nice way of
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:22,872'); seek(1522.0)">
              doing a lot of inference, because it has, again, a very generous
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:26,462'); seek(1526.0)">
              free tier where you can use hugging face spaces to
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:30,844'); seek(1530.0)">
              do some really nice uis for dashboards or for interactive applications,
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:35,122'); seek(1535.0)">
              in this case from hopsearch. They can read the models and the
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:38,812'); seek(1538.0)">
              data frames. This is the data that you want to make your predictions with.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:42,016'); seek(1542.0)">
              And we can also even save the logs back to hopsearch
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:45,542'); seek(1545.0)">
              and even do user interfaces in hugging
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:25:49,318'); seek(1549.0)">
              face for monitoring our models in production. So hopsearch in this
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:25:53,184'); seek(1553.0)">
              case, again, has another free serverless tier.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:25:56,378'); seek(1556.0)">
              You don't need to install anything, you get 25gb of free storage.
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:26:00,314'); seek(1560.0)">
              This is a really nice way to build what we call serverless machine learning
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:26:03,876'); seek(1563.0)">
              systems. And here's some examples. There's a bunch of these on the
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:07,384'); seek(1567.0)">
              Internet. I think there's about 40 or 50 of them now. Some really nice ones
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:10,536'); seek(1570.0)">
              are air quality predictions. In Poland, this is a streamlet application.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:16,550'); seek(1576.0)">
              It runs the feature pipelines daily on mobile,
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:19,950'); seek(1579.0)">
              and it stores then these features and hopsworks. And then
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:24,012'); seek(1584.0)">
              when you go to the dashboard here, it can redraw with the
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:27,084'); seek(1587.0)">
              predictions of the air quality in the different cities. So this is for
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:30,416'); seek(1590.0)">
              today in early, this is actually early March,
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:34,678'); seek(1594.0)">
              and you can look at different days and it will connect to hopsworks, read down
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:37,792'); seek(1597.0)">
              new data to score and redraw this particular UI
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:26:41,558'); seek(1601.0)">
              and streamlit. And there's another one here that will predict whether
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:26:45,364'); seek(1605.0)">
              your post on Reddit will be liked or not. So it's using sentiment analysis
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:26:49,754'); seek(1609.0)">
              and it's very interesting. Another one on Tesla, stock price production.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:26:53,678'); seek(1613.0)">
              So I think it's using sentiment from Twitter, amongst other
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:26:57,592'); seek(1617.0)">
              places, and then another one using New York electricity.
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:27:03,830'); seek(1623.0)">
              A lot of services globally have been digitalized and a lot of data is
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:27:07,144'); seek(1627.0)">
              available now for us to build these prediction services with.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:10,460'); seek(1630.0)">
              So you can write a Python program which will go to the
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:13,708'); seek(1633.0)">
              New York electricity market. And if you follow this link,
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:16,972'); seek(1636.0)">
              you'll see where they get the data from. And you can see in many
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:20,192'); seek(1640.0)">
              cases, it's actually outperforming the ETA's forecast or
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:24,048'); seek(1644.0)">
              the EIA's daily forecast, which it's doing here.
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:28,350'); seek(1648.0)">
              So there's a lot of cool things you can build. I'm going to show you
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:30,608'); seek(1650.0)">
              briefly this one that I mentioned here. There's a ton
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:34,288'); seek(1654.0)">
              of them here in Hopsterick's tutorials. The one I'm going to show you briefly
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:37,818'); seek(1657.0)">
              here is called credit scores. Now, I've actually opened
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:41,498'); seek(1661.0)">
              up the notebooks already, so this is just running on my laptop here. This is
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:27:45,476'); seek(1665.0)">
              the hopster tutorials that I've checked out locally.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:27:49,030'); seek(1669.0)">
              Do I need quick start? No, I don't. Let's move to the first
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:27:52,376'); seek(1672.0)">
              one. So in this case we've got the advanced tutorials,
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:27:55,998'); seek(1675.0)">
              credit scores. So what this is going to do is I actually have two feature
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:27:59,422'); seek(1679.0)">
              pipelines at the beginning. Sometimes you'll have two, one for historical data to create your
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:28:02,988'); seek(1682.0)">
              feature groups and add all the metadata. And this is a backfill
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:06,722'); seek(1686.0)">
              one. So what this one is doing is basically reading some csv files
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:10,358'); seek(1690.0)">
              with our loan applications, bureau balance,
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:13,398'); seek(1693.0)">
              credit card data, payment installments and a lot of other data,
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:17,040'); seek(1697.0)">
              doing some feature engineering. It's also
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:20,432'); seek(1700.0)">
              showing you doing some EDA as well, which you typically would do,
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:24,068'); seek(1704.0)">
              and then creating the feature groups.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:27,730'); seek(1707.0)">
              This is where I ran it, I think, earlier on. So there might be some
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:30,468'); seek(1710.0)">
              diagrams in here. You can see we're trying to understand basically
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:35,270'); seek(1715.0)">
              the data before we get into the process of modeling.
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:38,910'); seek(1718.0)">
              But obviously the kind of things you do here is clean up the data,
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:28:43,270'); seek(1723.0)">
              extract any features that you need to extract or create.
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:28:46,790'); seek(1726.0)">
              And then what we can have is a feature pipeline. So this is a much
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:28:50,092'); seek(1730.0)">
              simpler program. It's going to read the data,
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:28:53,530'); seek(1733.0)">
              it's going to read the new data. And this should run on a
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:28:57,148'); seek(1737.0)">
              cadence. Now, it's a notebook, so it's really just for learning. But it'll connect to
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:29:00,604'); seek(1740.0)">
              the feature store. We can see here that it's getting a reference to
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:04,208'); seek(1744.0)">
              the feature groups. And in this case, we're not reading new data
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:08,112'); seek(1748.0)">
              from the Internet because this is credit card loans and so
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:11,328'); seek(1751.0)">
              on. That information is not available. So what we're doing is generating data.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:14,916'); seek(1754.0)">
              So this is a really good way of doing synthetic feature pipelines
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:18,442'); seek(1758.0)">
              if you can't access the actual data. So we're just generating some
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:21,908'); seek(1761.0)">
              random data in this case, or not random, but based on the distribution of
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:26,310'); seek(1766.0)">
              the historical data. So it's generating new feature values
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:30,238'); seek(1770.0)">
              based on those distributions. And then we're just going to write to
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:33,528'); seek(1773.0)">
              the feature story. So you're just basically going to call insert on these data frames.
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:36,990'); seek(1776.0)">
              And now you'll have some feature groups in here. So let's have a look at
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:29:39,868'); seek(1779.0)">
              what the feature groups look like. We can see here,
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:29:43,612'); seek(1783.0)">
              this is hopsearch here, and we've got a bunch of projects. And this is app
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:29:47,404'); seek(1787.0)">
              hopsearch AI. So it's free to create an account. It's time unlimited.
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:29:50,882'); seek(1790.0)">
              You can build systems on it, and you can see there's a bunch of these
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:29:54,032'); seek(1794.0)">
              feature groups that have been created. One of them is
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:29:57,248'); seek(1797.0)">
              called application. We can see all the features that are in here.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:00,528'); seek(1800.0)">
              There's quite a lot of features, 72 in total.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:05,250'); seek(1805.0)">
              We can see how it's being used as a feature view created from it.
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:08,900'); seek(1808.0)">
              You can have expectations, if you want to use great expectations to do data validation
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:13,162'); seek(1813.0)">
              before you write to the feature store. And you can see the results of those
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:16,232'); seek(1816.0)">
              expectations here, the same, you can create alerts if bad
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:19,512'); seek(1819.0)">
              data is being ingested. We can preview some of the data that's
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:22,974'); seek(1822.0)">
              in there to just do some EDA. You can see, have a look at some
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:26,488'); seek(1826.0)">
              of the data, quite a lot in there. So just give me a random sample
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:29,538'); seek(1829.0)">
              of some rows there. We can pre compute statistics
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:33,442'); seek(1833.0)">
              over the data so you can understand the distribution. In this case, we got descriptive
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:30:36,978'); seek(1836.0)">
              statistics of the features, and we can see what's happened in this feature group
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:30:40,652'); seek(1840.0)">
              over time. So we had some data written to it earlier,
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:30:43,942'); seek(1843.0)">
              and then we wrote some more data to it later on.
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:30:46,830'); seek(1846.0)">
              So the feature view you can create is the selection of features.
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:30:50,726'); seek(1850.0)">
              So this is what it looks like here, and I'll show you the notebook in
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:30:53,988'); seek(1853.0)">
              a second. We can see the provenance of those features.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:30:57,322'); seek(1857.0)">
              This one came from this particular feature group bureau. Another one came from
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:00,772'); seek(1860.0)">
              application. This is the target column that our supervised machine learning
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:04,932'); seek(1864.0)">
              model is going to use as the label. And then
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:08,424'); seek(1868.0)">
              we can see any training data sets created from it. So I only created one
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:11,768'); seek(1871.0)">
              training data set from it, but let's look at the
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:15,208'); seek(1875.0)">
              code for that. So in our feature view, what we do is we just get
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:31:18,424'); seek(1878.0)">
              a reference to these feature groups first, and then we need to select
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:31:22,556'); seek(1882.0)">
              our features. And that's what's happening in here. It calls a query preparation, but really
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:31:26,444'); seek(1886.0)">
              what it's doing is feature selection. So let's call it that,
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:31:29,548'); seek(1889.0)">
              it's feature selection. We're selecting features
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:31:34,294'); seek(1894.0)">
              from a bunch of different feature groups or tables, and we
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:31:37,408'); seek(1897.0)">
              join them together. You can add filters and things in here as well.
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:31:41,550'); seek(1901.0)">
              Now, the point in time correct join is very complex, as you see, but the
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:31:44,964'); seek(1904.0)">
              only code we had to write was this relatively straightforward
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:31:48,410'); seek(1908.0)">
              code in Python. What we can do then is
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:31:52,550'); seek(1912.0)">
              we can add transformation functions. And here what we
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:31:56,408'); seek(1916.0)">
              do is we can see, we're saying, okay,
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:32:00,310'); seek(1920.0)">
              in this particular case we're looking at a mapping
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:32:04,302'); seek(1924.0)">
              transformer here, a label encoder and a standard encoder and we're
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:32:09,762'); seek(1929.0)">
              basically applying those transformation functions then to those select
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:32:13,180'); seek(1933.0)">
              set of features that are defined in here.
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:32:17,050'); seek(1937.0)">
              So basically what it's saying is all the columns that are categorical we're
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:32:20,818'); seek(1940.0)">
              going to apply the label encoder to and all the columns that are numerical we're
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:32:23,974'); seek(1943.0)">
              going to apply the standard encoder to. And that's
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:32:27,654'); seek(1947.0)">
              all going to be captured in this mapping transformer object.
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:32:31,310'); seek(1951.0)">
              So the feature view is created with this selection of features called FG Query.
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:32:35,094'); seek(1955.0)">
              We're applying these transformations to them. We've identified the target column,
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:32:38,538'); seek(1958.0)">
              which is called target funnily enough, and then we've given
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:32:41,812'); seek(1961.0)">
              a name and version so the feature views and the feature groups can both
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:32:45,252'); seek(1965.0)">
              be versioned to enable you to apply ML Ops best principles.
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:32:48,958'); seek(1968.0)">
              Of course, once we have a reference to it and here we're just getting a
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:32:52,504'); seek(1972.0)">
              reference to the feature group again, we don't need to January. It's just if
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:32:55,608'); seek(1975.0)">
              I start my notebook from here it's nice and handy, then what
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:32:59,308'); seek(1979.0)">
              I can do is I can create training data here. I didn't specify the
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:33:02,668'); seek(1982.0)">
              version train data so it just defaulted to version one.
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:33:06,410'); seek(1986.0)">
              And I've created the training data as files and it's
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:33:09,634'); seek(1989.0)">
              a random split with 20% test data and 80% training
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:33:13,056'); seek(1993.0)">
              data. Now the train data
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:33:16,352'); seek(1996.0)">
              sets being created so I could have kept in the same notebook and just
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:33:20,128'); seek(2000.0)">
              gone ahead and read the train data and train. My model I separated into
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:33:23,552'); seek(2003.0)">
              two notebooks. So these two notebooks really make up the training pipeline.
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:33:26,698'); seek(2006.0)">
              In a production system you typically have a single pipeline.
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:33:29,626'); seek(2009.0)">
              But what we can do here is we can get back our feature view and
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:33:32,628'); seek(2012.0)">
              say, hey, that train data has been created as files. I just want to read
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:33:35,588'); seek(2015.0)">
              it up. And I want to read it up, split into my features,
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:33:39,486'); seek(2019.0)">
              the training and test set and then my labels, the Y train and
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:33:42,888'); seek(2022.0)">
              y test from the training and test set. So that's great.
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:33:46,696'); seek(2026.0)">
              Now I can do some messing with the data here,
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:33:50,236'); seek(2030.0)">
              just cleaning up a little bit. Then I can use just a simple model so
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:33:53,708'); seek(2033.0)">
              I can use scikitlearn random forest classifier, I can use
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:33:56,988'); seek(2036.0)">
              XgBoost. I'm just going to fit to my training
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:34:00,860'); seek(2040.0)">
              features, sorry, my features in the
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:34:04,288'); seek(2044.0)">
              training set and my labels in the training set. And now I've got my model
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:34:07,616'); seek(2047.0)">
              and I can predict on the test set and check the accuracy of the model
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:34:10,352'); seek(2050.0)">
              and save the model to the model registry. Then I have an inference
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:34:14,442'); seek(2054.0)">
              pipeline, in this case the batch prediction pipeline. It's going to go
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:34:18,164'); seek(2058.0)">
              to the feature store, connect to the model registry
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:34:21,978'); seek(2061.0)">
              as well, download our model, get some batch data that's
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:34:25,434'); seek(2065.0)">
              going to score with in this case it's getting all the data. But we can
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:34:28,408'); seek(2068.0)">
              specify a time range or a set of ids that we'd like to score for,
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:34:32,552'); seek(2072.0)">
              and then we can go ahead and make our predictions,
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:34:36,078'); seek(2076.0)">
              and then we can save those predictions. So what we're doing is downloading the model
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:34:39,580'); seek(2079.0)">
              first. But once we have the model, then we can make predictions on our
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:34:42,908'); seek(2082.0)">
              data frame and we can save those then predictions to
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:34:47,052'); seek(2087.0)">
              a data store and we're done. So that's it. That's the kind of end to
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:34:50,528'); seek(2090.0)">
              end machine learning system that you can have and build with
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:34:55,040'); seek(2095.0)">
              this feature training inference pipeline
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:34:58,678'); seek(2098.0)">
              architecture. And we do the feature store model registry as the data layer,
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:35:02,362'); seek(2102.0)">
              pulling it all together. If you're curious to find out more,
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:35:06,610'); seek(2106.0)">
              I work with Hopsirix, which is a core part of this new serverless
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:35:10,538'); seek(2110.0)">
              machine training stack. You can go to app hopsearch AI and create
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:35:14,388'); seek(2114.0)">
              a free account or join our slack. But if you really want to learn more
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:35:17,928'); seek(2117.0)">
              about building these service machine learning systems, I recommend you take
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:35:22,152'); seek(2122.0)">
              a course that I developed called serverless ML. It's all Python,
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:35:25,742'); seek(2125.0)">
              pure Python. The course came out in the fall last year,
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:35:29,356'); seek(2129.0)">
              so we weren't using modal or hugging face. There is no hugging face there,
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:35:32,748'); seek(2132.0)">
              I should admit, but it uses GitHub actions instead of modal.
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:35:36,722'); seek(2136.0)">
              But they're both great tools for orchestrating and running Python
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:35:40,498'); seek(2140.0)">
              programs. If you want to learn more, go to serverlessml.org,
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:35:45,474'); seek(2145.0)">
              give it a whirl, and good luck on your journey on serverless machine learning.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Conf42%20Python%202023%20-%20Jim%20Dowling.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Conf42%20Python%202023%20-%20Jim%20Dowling.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #69811f;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/python2023" class="btn btn-sm btn-danger shadow lift" style="background-color: #69811f;">
                <i class="fe fe-grid me-2"></i>
                See all 19 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/python_jim_dowling.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Jim Dowling
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    CEO @ Hopsworks
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/jim-dowling-206a98/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Jim Dowling's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@jim_dowling" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Jim Dowling's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @jim_dowling"
                  data-url="https://www.conf42.com/python2023"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/python2023"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Python"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/aiml2024">
                  Artificial Intelligence & Machine Learning (AI & ML) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.sreday.com/">
                  SREday London 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

  </body>
</html>