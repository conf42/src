<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: From Slow to Go: Boosting your code with Profile-Guided Optimization</title>
    <meta name="description" content="Say hello to the Gophers from outer space!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Yashvardhan%20Kukreja_golang.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="From Slow to Go: Boosting your code with Profile-Guided Optimization | Conf42"/>
    <meta property="og:description" content="This talk would uncover the performance boosts PGO offers to Go apps, from streamlining hot paths to minimizing resource consumption. Not only a theoretical explainer but we'd practically instrument Go binaries to depict the real powers of PGO while touching base with its industrial implications."/>
    <meta property="og:url" content="https://conf42.com/Golang_2024_Yashvardhan_Kukreja_profileguided_optimization"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PROMPT2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Prompt Engineering 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-11-14
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://sreday.com/2024-amsterdam/">
                            SREday Amsterdam
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #881E4B;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Golang 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Say hello to the Gophers from outer space!
 -->
              <script>
                const event_date = new Date("2024-04-25T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-04-25T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "8yrhrtZOfgM"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "0y_ts8oh36o"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrCPeN0GQy__eEHaihV8TVmY" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone, welcome to Con 42 Golang. I hope you had", "timestamp": "00:00:20,600", "timestamp_s": 20.0}, {"text": "a great time with all the talks until now. I am Yash and today I", "timestamp": "00:00:24,030", "timestamp_s": 24.0}, {"text": "am extremely excited to be talking about profile guided optimization", "timestamp": "00:00:26,806", "timestamp_s": 26.0}, {"text": "and how it can boost your code and your compiler. So moving", "timestamp": "00:00:30,374", "timestamp_s": 30.0}, {"text": "on, let me first of all introduce myself. I am Yash and currently", "timestamp": "00:00:33,726", "timestamp_s": 33.0}, {"text": "I am working as a software engineer at Red Hat. I am also pursuing a", "timestamp": "00:00:37,118", "timestamp_s": 37.0}, {"text": "masters at University of Waterloo in Canada and", "timestamp": "00:00:40,798", "timestamp_s": 40.0}, {"text": "around my work I deal with Openshift, kubernetes,", "timestamp": "00:00:44,310", "timestamp_s": 44.0}, {"text": "Golang, containers, docker, cloud, native stuff.", "timestamp": "00:00:47,126", "timestamp_s": 47.0}, {"text": "Apart from that, in my free time, whenever I get some time I", "timestamp": "00:00:51,724", "timestamp_s": 51.0}, {"text": "do open source dev. I love to do long distance running and I like to", "timestamp": "00:00:55,428", "timestamp_s": 55.0}, {"text": "just build stuff. So moving on, let\u0027s first of all talk", "timestamp": "00:00:58,756", "timestamp_s": 58.0}, {"text": "about compilation, right? So computers, as you all know, don\u0027t understand", "timestamp": "00:01:02,140", "timestamp_s": 62.0}, {"text": "Golang, python, Java, all that stuff.", "timestamp": "00:01:07,044", "timestamp_s": 67.0}, {"text": "Computers only know zeros and ones, that\u0027s the binary language.", "timestamp": "00:01:10,324", "timestamp_s": 70.0}, {"text": "So there is, there should be an entity which translates a", "timestamp": "00:01:14,124", "timestamp_s": 74.0}, {"text": "Golang code to zeros and ones so that the computer can execute", "timestamp": "00:01:17,588", "timestamp_s": 77.0}, {"text": "it. And that entity, as most of you would know it,", "timestamp": "00:01:21,318", "timestamp_s": 81.0}, {"text": "is called the compiler as shown in the image below. You can see", "timestamp": "00:01:25,006", "timestamp_s": 85.0}, {"text": "that on the left hand side there\u0027s a Golang code printing hello world and there\u0027s", "timestamp": "00:01:28,550", "timestamp_s": 88.0}, {"text": "some compiler magic happening which produces the machine code which is", "timestamp": "00:01:32,310", "timestamp_s": 92.0}, {"text": "the binary or assembly, and that is fed to the linker to", "timestamp": "00:01:35,838", "timestamp_s": 95.0}, {"text": "produce the actual binary or the executable which", "timestamp": "00:01:39,390", "timestamp_s": 99.0}, {"text": "you execute to print hello World. Across this talk,", "timestamp": "00:01:42,710", "timestamp_s": 102.0}, {"text": "we won\u0027t talk much about the linker, we would care and talk more about", "timestamp": "00:01:45,734", "timestamp_s": 105.0}, {"text": "the compiler. So let\u0027s move on and let\u0027s dive a little bit into", "timestamp": "00:01:49,500", "timestamp_s": 109.0}, {"text": "the magic inside the compiler. Magic. So compiler is an", "timestamp": "00:01:53,244", "timestamp_s": 113.0}, {"text": "amazing piece of tech. I mean it\u0027s doing so many things so gracefully and", "timestamp": "00:01:57,236", "timestamp_s": 117.0}, {"text": "beautifully, so behind the scenes it does a bunch", "timestamp": "00:02:01,268", "timestamp_s": 121.0}, {"text": "of steps. Firstly, it breaks down the code into a bunch of tokens through", "timestamp": "00:02:04,420", "timestamp_s": 124.0}, {"text": "the means of a lexer. That\u0027s that process is tokenization and", "timestamp": "00:02:07,900", "timestamp_s": 127.0}, {"text": "then that is fed and a tree is created out of", "timestamp": "00:02:11,860", "timestamp_s": 131.0}, {"text": "that set of tokens and that tree is called abstract syntax tree,", "timestamp": "00:02:15,540", "timestamp_s": 135.0}, {"text": "which is a representation of your code. That tree then goes", "timestamp": "00:02:19,100", "timestamp_s": 139.0}, {"text": "through a phase of semantic analysis to determine whether the", "timestamp": "00:02:22,620", "timestamp_s": 142.0}, {"text": "type checking is happening correctly, whether a code is correct, all that stuff.", "timestamp": "00:02:26,140", "timestamp_s": 146.0}, {"text": "And after that a code is converted into a platform", "timestamp": "00:02:30,460", "timestamp_s": 150.0}, {"text": "independent representation called IR, which is intermediate", "timestamp": "00:02:34,388", "timestamp_s": 154.0}, {"text": "representation, and that is fed to the backend of the compiler", "timestamp": "00:02:37,516", "timestamp_s": 157.0}, {"text": "where a bunch of optimizations happening happen and a lot of", "timestamp": "00:02:41,548", "timestamp_s": 161.0}, {"text": "magic happens, which by the way, we will dive further into the talk.", "timestamp": "00:02:44,764", "timestamp_s": 164.0}, {"text": "And finally, this optimized IR is fed to", "timestamp": "00:02:48,844", "timestamp_s": 168.0}, {"text": "the machine code generator which actually produces the machine code and", "timestamp": "00:02:52,428", "timestamp_s": 172.0}, {"text": "yeah, feeds it to the linker to generate the executable.", "timestamp": "00:02:57,444", "timestamp_s": 177.0}, {"text": "So let\u0027s talk about the optimizations. Sorry, the magic we care", "timestamp": "00:03:01,044", "timestamp_s": 181.0}, {"text": "about which is the compiler optimizations. So the thing", "timestamp": "00:03:04,364", "timestamp_s": 184.0}, {"text": "is that the code which you write, the code which I write it", "timestamp": "00:03:07,890", "timestamp_s": 187.0}, {"text": "might not be the most efficient piece of code behind the scenes,", "timestamp": "00:03:11,274", "timestamp_s": 191.0}, {"text": "meaning that there can be a bunch of efficient optimizations", "timestamp": "00:03:14,754", "timestamp_s": 194.0}, {"text": "which can be made to it, and compiler takes care", "timestamp": "00:03:18,330", "timestamp_s": 198.0}, {"text": "of it for us. So if I give you an example, imagine your", "timestamp": "00:03:21,522", "timestamp_s": 201.0}, {"text": "code has an if statement which will never be executed. For example,", "timestamp": "00:03:24,962", "timestamp_s": 204.0}, {"text": "it says if false print hello world.", "timestamp": "00:03:29,202", "timestamp_s": 209.0}, {"text": "Now you and I, we both know that this if statement is", "timestamp": "00:03:32,538", "timestamp_s": 212.0}, {"text": "absolutely useless. And the compiler also is smart enough", "timestamp": "00:03:36,132", "timestamp_s": 216.0}, {"text": "to go through these lines of code and see that hey, this if statement", "timestamp": "00:03:39,908", "timestamp_s": 219.0}, {"text": "would never execute, so let\u0027s not even include it during the compilation.", "timestamp": "00:03:43,540", "timestamp_s": 223.0}, {"text": "So in this manner, the compiler actually ends up ignoring", "timestamp": "00:03:47,612", "timestamp_s": 227.0}, {"text": "this small chunk of code and ends up producing a much lighter executable", "timestamp": "00:03:51,452", "timestamp_s": 231.0}, {"text": "or binary. Now this was one trivial example, but the compiler actually", "timestamp": "00:03:55,564", "timestamp_s": 235.0}, {"text": "like applies a bunch of crazy optimizations, and the ultimate", "timestamp": "00:03:59,892", "timestamp_s": 239.0}, {"text": "benefit is that you end up with the lower executable, sorry, lower size", "timestamp": "00:04:03,380", "timestamp_s": 243.0}, {"text": "of the executable. There are lesser number of instructions and code", "timestamp": "00:04:06,860", "timestamp_s": 246.0}, {"text": "jumps happening in runtime because of lower number of instructions.", "timestamp": "00:04:10,460", "timestamp_s": 250.0}, {"text": "And also the compiler can optimize your code during", "timestamp": "00:04:14,564", "timestamp_s": 254.0}, {"text": "the compilation on the basis of the underlying hardware on top of which your code", "timestamp": "00:04:18,404", "timestamp_s": 258.0}, {"text": "would run. For example, if your code is doing a lot of GPU programming and", "timestamp": "00:04:22,300", "timestamp_s": 262.0}, {"text": "the hardware on top of which the compiler is running", "timestamp": "00:04:25,860", "timestamp_s": 265.0}, {"text": "is also based out of a lot of GPU hardware,", "timestamp": "00:04:29,500", "timestamp_s": 269.0}, {"text": "then the compiler can really make use of", "timestamp": "00:04:32,756", "timestamp_s": 272.0}, {"text": "this information and optimize your code accordingly. With the help of the", "timestamp": "00:04:36,040", "timestamp_s": 276.0}, {"text": "this power of compiler and optimizations, you can actually", "timestamp": "00:04:40,344", "timestamp_s": 280.0}, {"text": "write a very clean piece of in a very beautiful and readable piece of code", "timestamp": "00:04:43,928", "timestamp_s": 283.0}, {"text": "in an abstracted manner, and you won\u0027t have to be at", "timestamp": "00:04:47,528", "timestamp_s": 287.0}, {"text": "the performance over it because the compiler would deconstruct these abstractions", "timestamp": "00:04:50,928", "timestamp_s": 290.0}, {"text": "behind the scenes. So let me give you some", "timestamp": "00:04:54,824", "timestamp_s": 294.0}, {"text": "examples of these optimizations. One optimization is pre calculation of constants", "timestamp": "00:04:58,272", "timestamp_s": 298.0}, {"text": "where if you have an expression like a is equal to two multiplied by", "timestamp": "00:05:02,008", "timestamp_s": 302.0}, {"text": "three plus five, the compiler during the compile time itself", "timestamp": "00:05:05,680", "timestamp_s": 305.0}, {"text": "can calculate this and say that hey, there is no need", "timestamp": "00:05:09,544", "timestamp_s": 309.0}, {"text": "to compute this again and again in runtime. Let me just compute it and", "timestamp": "00:05:13,200", "timestamp_s": 313.0}, {"text": "straightaway feed it in the compilation phase itself.", "timestamp": "00:05:16,760", "timestamp_s": 316.0}, {"text": "Similarly, there\u0027s a process of loop unrolling where the for", "timestamp": "00:05:19,904", "timestamp_s": 319.0}, {"text": "loop is unrolled further. So that in runtime, when the", "timestamp": "00:05:23,376", "timestamp_s": 323.0}, {"text": "for loop runs, it does not have to check the condition phase of the", "timestamp": "00:05:27,368", "timestamp_s": 327.0}, {"text": "for loop multiple times. That also saves in a bunch of cpu cycles.", "timestamp": "00:05:30,640", "timestamp_s": 330.0}, {"text": "And finally, there\u0027s a an optimization called Dead Star elimination where a bunch", "timestamp": "00:05:34,344", "timestamp_s": 334.0}, {"text": "of useless code is ignored.", "timestamp": "00:05:38,260", "timestamp_s": 338.0}, {"text": "For example, in the right hand image you can see that the", "timestamp": "00:05:41,724", "timestamp_s": 341.0}, {"text": "variable is constantly getting updated. But all of those updates", "timestamp": "00:05:45,748", "timestamp_s": 345.0}, {"text": "don\u0027t matter because the last update is going to overwrite all", "timestamp": "00:05:49,796", "timestamp_s": 349.0}, {"text": "of the previous updates. So the compiler is smart enough to notice", "timestamp": "00:05:53,268", "timestamp_s": 353.0}, {"text": "this, and it ignores all the above two lines and only considers", "timestamp": "00:05:56,676", "timestamp_s": 356.0}, {"text": "the last line during the compilation. So the compiler does a lot of", "timestamp": "00:06:00,628", "timestamp_s": 360.0}, {"text": "these cool optimizations, but we are interested in", "timestamp": "00:06:04,344", "timestamp_s": 364.0}, {"text": "one optimization, and that is inlining.", "timestamp": "00:06:08,048", "timestamp_s": 368.0}, {"text": "And this talk is going to be centered around this optimization.", "timestamp": "00:06:11,064", "timestamp_s": 371.0}, {"text": "So inlining originates from a problem. The problem", "timestamp": "00:06:14,904", "timestamp_s": 374.0}, {"text": "is the act of calling a function. All of us", "timestamp": "00:06:18,784", "timestamp_s": 378.0}, {"text": "write a code in a pretty functional manner. We define functions, we call those functions", "timestamp": "00:06:22,072", "timestamp_s": 382.0}, {"text": "multiple times. The problem is that in runtime,", "timestamp": "00:06:25,648", "timestamp_s": 385.0}, {"text": "the act of calling a function is a slow operation, because when", "timestamp": "00:06:29,420", "timestamp_s": 389.0}, {"text": "you just call the function, when you just invoke the function, a bunch", "timestamp": "00:06:32,948", "timestamp_s": 392.0}, {"text": "of stuff happens behind the scenes which adds up to the runtime over it.", "timestamp": "00:06:36,628", "timestamp_s": 396.0}, {"text": "For example, a new stack is like dedicated for the scope", "timestamp": "00:06:40,068", "timestamp_s": 400.0}, {"text": "of the function. The parameters are pushed onto that stack whenever the", "timestamp": "00:06:43,860", "timestamp_s": 403.0}, {"text": "function is completed with the execution, the returned", "timestamp": "00:06:47,332", "timestamp_s": 407.0}, {"text": "values are returned back to the caller. So all of these things add", "timestamp": "00:06:50,972", "timestamp_s": 410.0}, {"text": "up to the performance overhead in runtime. So the what the compiler", "timestamp": "00:06:54,420", "timestamp_s": 414.0}, {"text": "does is compiler performs this optimization called inlining,", "timestamp": "00:06:58,320", "timestamp_s": 418.0}, {"text": "where the compiler takes the body and implementation of the", "timestamp": "00:07:01,808", "timestamp_s": 421.0}, {"text": "function and just places it wherever", "timestamp": "00:07:04,960", "timestamp_s": 424.0}, {"text": "that function is invoked. So if you look at the image below,", "timestamp": "00:07:08,064", "timestamp_s": 428.0}, {"text": "we have a function called sum, which sums up two parameters,", "timestamp": "00:07:11,488", "timestamp_s": 431.0}, {"text": "x and y, and we have a main function where we are invoking this function", "timestamp": "00:07:15,480", "timestamp_s": 435.0}, {"text": "twice. So if we perform inlining here,", "timestamp": "00:07:19,232", "timestamp_s": 439.0}, {"text": "the compiler can actually just strip off the definition of the sum", "timestamp": "00:07:22,176", "timestamp_s": 442.0}, {"text": "function and just replace the invocations of the sum", "timestamp": "00:07:25,642", "timestamp_s": 445.0}, {"text": "function with their actual implementation. So sum one", "timestamp": "00:07:28,882", "timestamp_s": 448.0}, {"text": "comma two becomes one plus two, some two comma four becomes", "timestamp": "00:07:32,722", "timestamp_s": 452.0}, {"text": "two plus four. And the beautiful part is that this", "timestamp": "00:07:36,002", "timestamp_s": 456.0}, {"text": "newly inlined piece of code can be further optimized through,", "timestamp": "00:07:40,210", "timestamp_s": 460.0}, {"text": "say, pre calculation of constants to actually know", "timestamp": "00:07:43,666", "timestamp_s": 463.0}, {"text": "in the compilation phase itself that res one is equal to three,", "timestamp": "00:07:47,082", "timestamp_s": 467.0}, {"text": "res two is equal to six. So from a runtime perspective, things become very much", "timestamp": "00:07:50,546", "timestamp_s": 470.0}, {"text": "more efficient, and that ends up elimination, eliminating the functional", "timestamp": "00:07:54,168", "timestamp_s": 474.0}, {"text": "colleagues as well. But we have a problem.", "timestamp": "00:07:57,544", "timestamp_s": 477.0}, {"text": "Nothing is perfect in word. What if you have", "timestamp": "00:08:00,664", "timestamp_s": 480.0}, {"text": "defined a function and it has too many invocations?", "timestamp": "00:08:04,000", "timestamp_s": 484.0}, {"text": "If there are too many invocations, then the inlining process will be", "timestamp": "00:08:07,864", "timestamp_s": 487.0}, {"text": "too much if we perform the inlining blindly, and that would lead to", "timestamp": "00:08:11,448", "timestamp_s": 491.0}, {"text": "too many new lines of code. This means that the code size would", "timestamp": "00:08:14,760", "timestamp_s": 494.0}, {"text": "increase massively and that would lead to a bloated binary,", "timestamp": "00:08:18,344", "timestamp_s": 498.0}, {"text": "and that ends up having some bad consequences in the runtime.", "timestamp": "00:08:22,104", "timestamp_s": 502.0}, {"text": "For example, if I really go into the depth, then uploaded", "timestamp": "00:08:25,248", "timestamp_s": 505.0}, {"text": "binary, basically behind the scenes means more number of static instructions", "timestamp": "00:08:29,680", "timestamp_s": 509.0}, {"text": "and the higher number of static instructions in a binary in an executable,", "timestamp": "00:08:33,584", "timestamp_s": 513.0}, {"text": "the bigger the instruction caches, and that leads to a bad", "timestamp": "00:08:38,784", "timestamp_s": 518.0}, {"text": "cache hit ratio or cache it rate, and that leads", "timestamp": "00:08:43,296", "timestamp_s": 523.0}, {"text": "to instruction cache message, which is quite bad in runtime. Moreover, a bloated", "timestamp": "00:08:46,880", "timestamp_s": 526.0}, {"text": "binary causes page faults and whatnot. And if you are running your binary on", "timestamp": "00:08:50,736", "timestamp_s": 530.0}, {"text": "a small device like a raspberry PI or something, even thrashing", "timestamp": "00:08:54,544", "timestamp_s": 534.0}, {"text": "could happen. So blindly inlining a piece of code can be a bad", "timestamp": "00:08:58,120", "timestamp_s": 538.0}, {"text": "situation. I have shown that as an example on the right hand image as well,", "timestamp": "00:09:01,832", "timestamp_s": 541.0}, {"text": "that inlining a 506 lines of code,", "timestamp": "00:09:04,960", "timestamp_s": 544.0}, {"text": "uh, can result in a 1000 lines of code result.", "timestamp": "00:09:08,072", "timestamp_s": 548.0}, {"text": "So we have a weird problem here. Now if we do less in line inlining,", "timestamp": "00:09:12,324", "timestamp_s": 552.0}, {"text": "we have a bad runtime performance because of the overhead introduced", "timestamp": "00:09:16,036", "timestamp_s": 556.0}, {"text": "due to those function calls. And if we do more inlining,", "timestamp": "00:09:19,356", "timestamp_s": 559.0}, {"text": "then we have a bad runtime performance due to the bigger executable,", "timestamp": "00:09:23,060", "timestamp_s": 563.0}, {"text": "the page faults, the instruction cache misses and whatnot.", "timestamp": "00:09:26,588", "timestamp_s": 566.0}, {"text": "So what to do then? That is frustrating.", "timestamp": "00:09:29,924", "timestamp_s": 569.0}, {"text": "Well, we just need the right amount of inlining.", "timestamp": "00:09:32,924", "timestamp_s": 572.0}, {"text": "So what does it mean? Ideally, we want to inline", "timestamp": "00:09:36,204", "timestamp_s": 576.0}, {"text": "only the hot functions and not inline the cold functions.", "timestamp": "00:09:39,788", "timestamp_s": 579.0}, {"text": "So the hot functions are the one which happen to execute a lot more frequently", "timestamp": "00:09:43,148", "timestamp_s": 583.0}, {"text": "in runtime, while the cold functions are the one which don\u0027t execute", "timestamp": "00:09:47,180", "timestamp_s": 587.0}, {"text": "that often in runtime. So the benefit of inlining hot functions is that", "timestamp": "00:09:50,780", "timestamp_s": 590.0}, {"text": "these functions would execute a lot of times in runtime. This means that if you", "timestamp": "00:09:54,644", "timestamp_s": 594.0}, {"text": "inline these functions, then you end up avoiding the function", "timestamp": "00:09:58,332", "timestamp_s": 598.0}, {"text": "call overhead in runtime. So this gives you the benefit, the runtime benefit of", "timestamp": "00:10:01,884", "timestamp_s": 601.0}, {"text": "inlining. You don\u0027t need to inline the cold functions", "timestamp": "00:10:05,748", "timestamp_s": 605.0}, {"text": "because they are not executing enough amount of time, so there\u0027s no", "timestamp": "00:10:09,028", "timestamp_s": 609.0}, {"text": "benefit in lining them. So by avoiding to", "timestamp": "00:10:13,052", "timestamp_s": 613.0}, {"text": "inlining the cold functions, you actually end up saving on the", "timestamp": "00:10:16,332", "timestamp_s": 616.0}, {"text": "binary size and the instruction count, and save yourself from", "timestamp": "00:10:19,908", "timestamp_s": 619.0}, {"text": "all those bad stuff associated with excessive inlining.", "timestamp": "00:10:23,900", "timestamp_s": 623.0}, {"text": "So ultimately we just need a sprinkle of inlining. And the", "timestamp": "00:10:27,630", "timestamp_s": 627.0}, {"text": "problem is that compilers don\u0027t know a lot. When a compiler is compiling your", "timestamp": "00:10:31,358", "timestamp_s": 631.0}, {"text": "code, it\u0027s literally reading across your code, it does not know", "timestamp": "00:10:34,950", "timestamp_s": 634.0}, {"text": "a lot more information. So. And just your written code", "timestamp": "00:10:39,094", "timestamp_s": 639.0}, {"text": "is not enough to tell how frequently a function would execute in runtime.", "timestamp": "00:10:43,214", "timestamp_s": 643.0}, {"text": "Clearly compilers in more info. And what if we", "timestamp": "00:10:47,254", "timestamp_s": 647.0}, {"text": "have a solution? The solution is that what if the compilers could look", "timestamp": "00:10:51,190", "timestamp_s": 651.0}, {"text": "at the application in runtime and learn from that application,", "timestamp": "00:10:54,532", "timestamp_s": 654.0}, {"text": "learn that which functions are hot and which functions are called?", "timestamp": "00:10:58,148", "timestamp_s": 658.0}, {"text": "Or in other words, from a more implementation perspective, what if", "timestamp": "00:11:01,204", "timestamp_s": 661.0}, {"text": "your applications runs in runtime and some somehow", "timestamp": "00:11:04,868", "timestamp_s": 664.0}, {"text": "you collect various numbers and metrics about its behavior in runtime", "timestamp": "00:11:08,892", "timestamp_s": 668.0}, {"text": "and finally feed those numbers and behavior as an information", "timestamp": "00:11:12,924", "timestamp_s": 672.0}, {"text": "to the compiler. Next time you compile our code.", "timestamp": "00:11:16,820", "timestamp_s": 676.0}, {"text": "So this with the next time you compile our code, the compiler would know that", "timestamp": "00:11:20,202", "timestamp_s": 680.0}, {"text": "hey, this function is hot and that function is called. So let me just", "timestamp": "00:11:23,362", "timestamp_s": 683.0}, {"text": "inline this function. So this kind of looks like a feedback loop,", "timestamp": "00:11:27,162", "timestamp_s": 687.0}, {"text": "right? And that brings us to feedback driven", "timestamp": "00:11:30,714", "timestamp_s": 690.0}, {"text": "optimization. So as the name suggests, it just", "timestamp": "00:11:33,938", "timestamp_s": 693.0}, {"text": "teaches the compilers how and where to optimize the code", "timestamp": "00:11:37,234", "timestamp_s": 697.0}, {"text": "on the basis of a feedback. Now that feedback can be benchmarks,", "timestamp": "00:11:40,714", "timestamp_s": 700.0}, {"text": "user traffic profiles, all that kind of stuff. That feedback", "timestamp": "00:11:44,274", "timestamp_s": 704.0}, {"text": "ultimately tells the compiler that which function is hot, which function is cold,", "timestamp": "00:11:47,674", "timestamp_s": 707.0}, {"text": "and ultimately the compiler just does the right amount of inlining.", "timestamp": "00:11:51,810", "timestamp_s": 711.0}, {"text": "Now the early days of feedback driven optimization were kind of", "timestamp": "00:11:56,834", "timestamp_s": 716.0}, {"text": "governed by instrumentation based process. So what", "timestamp": "00:12:00,362", "timestamp_s": 720.0}, {"text": "is instrumentation? It\u0027s very simple. With instrumentation,", "timestamp": "00:12:03,570", "timestamp_s": 723.0}, {"text": "what happens is that whenever a code is compiled by the compiler,", "timestamp": "00:12:06,914", "timestamp_s": 726.0}, {"text": "the compiler actually injects extra lines of code within your", "timestamp": "00:12:10,426", "timestamp_s": 730.0}, {"text": "code. And what are these extra lines of code? Some timers,", "timestamp": "00:12:14,232", "timestamp_s": 734.0}, {"text": "some call counters, all that kind of stuff. And the purpose of these", "timestamp": "00:12:17,976", "timestamp_s": 737.0}, {"text": "additional lines of code is to track and instrument the behavior of your", "timestamp": "00:12:21,200", "timestamp_s": 741.0}, {"text": "code in runtime. So once your code is compiled with these extra", "timestamp": "00:12:24,760", "timestamp_s": 744.0}, {"text": "lines of code, a bunch of benchmarks are run against your application or", "timestamp": "00:12:28,232", "timestamp_s": 748.0}, {"text": "code. And through the means of these extra lines of code, while these benchmarks", "timestamp": "00:12:31,920", "timestamp_s": 751.0}, {"text": "are running, a bunch of information gets instrumented and collected,", "timestamp": "00:12:35,944", "timestamp_s": 755.0}, {"text": "and this information becomes the feedback for the next build of the compiler.", "timestamp": "00:12:39,544", "timestamp_s": 759.0}, {"text": "This information ends up representing how your application is performing in runtime.", "timestamp": "00:12:43,818", "timestamp_s": 763.0}, {"text": "Now this sounds good, but is it really that efficient or that reliable?", "timestamp": "00:12:48,594", "timestamp_s": 768.0}, {"text": "Because the thing is that now with this whole process, the code becomes", "timestamp": "00:12:52,938", "timestamp_s": 772.0}, {"text": "much more bloated with all those compiler introduced instrumentation.", "timestamp": "00:12:56,482", "timestamp_s": 776.0}, {"text": "And we have an extra benchmarking step, which just like makes", "timestamp": "00:13:00,330", "timestamp_s": 780.0}, {"text": "the entire process of compilation and building", "timestamp": "00:13:04,474", "timestamp_s": 784.0}, {"text": "quite slower and boring. And the biggest problem is that what", "timestamp": "00:13:08,266", "timestamp_s": 788.0}, {"text": "if the benchmarks don\u0027t even resemble the reality of how your code", "timestamp": "00:13:11,720", "timestamp_s": 791.0}, {"text": "runs in production, for example, right?", "timestamp": "00:13:15,280", "timestamp_s": 795.0}, {"text": "What if it\u0027s actually quite opposite. And the benchmarks", "timestamp": "00:13:18,744", "timestamp_s": 798.0}, {"text": "might end up introducing some wrongfully assumed optimizations and", "timestamp": "00:13:22,544", "timestamp_s": 802.0}, {"text": "that can cause some really bad performance degradation.", "timestamp": "00:13:26,584", "timestamp_s": 806.0}, {"text": "So a potentially hot function might be perceived as a cold function by the benchmark,", "timestamp": "00:13:29,448", "timestamp_s": 809.0}, {"text": "and your compiler would not optimize it rightfully.", "timestamp": "00:13:33,872", "timestamp_s": 813.0}, {"text": "So what do you want? Let\u0027s talk first principles.", "timestamp": "00:13:37,374", "timestamp_s": 817.0}, {"text": "We want faster build times. We want realistic runtime data instead", "timestamp": "00:13:40,614", "timestamp_s": 820.0}, {"text": "of benchmarks pretending to be real. And finally, we want light", "timestamp": "00:13:44,310", "timestamp_s": 824.0}, {"text": "and small executables with no extra lines of code due to instrumentation.", "timestamp": "00:13:48,206", "timestamp_s": 828.0}, {"text": "If you hate benchmarks, don\u0027t use them. So what", "timestamp": "00:13:52,534", "timestamp_s": 832.0}, {"text": "we can do is that instead of benchmarks we can actually use the actual", "timestamp": "00:13:57,230", "timestamp_s": 837.0}, {"text": "behavior of your code as a feedback to your compiler. And the", "timestamp": "00:14:00,758", "timestamp_s": 840.0}, {"text": "beauty is that if you do that, you have now become independent", "timestamp": "00:14:04,498", "timestamp_s": 844.0}, {"text": "of the benchmarking process as well, with which now you can just compile our", "timestamp": "00:14:07,850", "timestamp_s": 847.0}, {"text": "code and that\u0027s what you are done. You don\u0027t have to execute the benchmarks,", "timestamp": "00:14:11,650", "timestamp_s": 851.0}, {"text": "and this gives you the faster build times. Also, this is more realistic because you\u0027re", "timestamp": "00:14:14,914", "timestamp_s": 854.0}, {"text": "not relying on any pretentious benchmarks pretending to be real users.", "timestamp": "00:14:19,202", "timestamp_s": 859.0}, {"text": "So how do you do that? To be specific,", "timestamp": "00:14:23,434", "timestamp_s": 863.0}, {"text": "it\u0027s sample based profiling. So the beauty of profiling is that it tracks the runtime", "timestamp": "00:14:27,194", "timestamp_s": 867.0}, {"text": "behavior of your code without needing those extra lines of", "timestamp": "00:14:31,050", "timestamp_s": 871.0}, {"text": "code inserted during for the sake of", "timestamp": "00:14:34,630", "timestamp_s": 874.0}, {"text": "instrumentation. And when I say profiling, I mean sample based", "timestamp": "00:14:37,990", "timestamp_s": 877.0}, {"text": "profiling, because like if we go really technical,", "timestamp": "00:14:41,662", "timestamp_s": 881.0}, {"text": "then instrumentation is also a type of profiling. So what I\u0027m talking about here is", "timestamp": "00:14:44,894", "timestamp_s": 884.0}, {"text": "actually sample based profiling. But across this talk,", "timestamp": "00:14:48,542", "timestamp_s": 888.0}, {"text": "whenever I say profiling, just here, sample based profiling.", "timestamp": "00:14:51,886", "timestamp_s": 891.0}, {"text": "Alright, so yeah, how does it work? It\u0027s pretty simple.", "timestamp": "00:14:55,014", "timestamp_s": 895.0}, {"text": "Now, just because we don\u0027t have those additional extra lines of", "timestamp": "00:14:58,702", "timestamp_s": 898.0}, {"text": "code in the, in our code during the compilation", "timestamp": "00:15:02,482", "timestamp_s": 902.0}, {"text": "phase, we need some external entity to poke and monitor", "timestamp": "00:15:06,026", "timestamp_s": 906.0}, {"text": "and profile your application. And this is where the kernel and enters", "timestamp": "00:15:09,698", "timestamp_s": 909.0}, {"text": "into the picture. So imagine an application is running in user", "timestamp": "00:15:13,210", "timestamp_s": 913.0}, {"text": "space. How does it get profiled? Well, the kernel has a beautiful component", "timestamp": "00:15:16,554", "timestamp_s": 916.0}, {"text": "called Linux perf, and the Linux perf schedules a bunch", "timestamp": "00:15:20,722", "timestamp_s": 920.0}, {"text": "of interrupt events with the cpu hardware,", "timestamp": "00:15:24,130", "timestamp_s": 924.0}, {"text": "and that\u0027s that hardware inside the cpu ends up scheduling", "timestamp": "00:15:27,596", "timestamp_s": 927.0}, {"text": "and triggering those interrupts. And whenever those interrupts are triggered,", "timestamp": "00:15:31,332", "timestamp_s": 931.0}, {"text": "the interrupt handler captures them inside the kernel, and the", "timestamp": "00:15:34,796", "timestamp_s": 934.0}, {"text": "interrupt handler correspondingly pokes your application in", "timestamp": "00:15:38,332", "timestamp_s": 938.0}, {"text": "user space and gets the runtime data at that point", "timestamp": "00:15:42,180", "timestamp_s": 942.0}, {"text": "in time. Now that runtime data includes instruction pointer and", "timestamp": "00:15:45,612", "timestamp_s": 945.0}, {"text": "call stack, which is enough to tell which function", "timestamp": "00:15:48,948", "timestamp_s": 948.0}, {"text": "is executing at that time, which parameters are allocated in", "timestamp": "00:15:52,104", "timestamp_s": 952.0}, {"text": "that function, what is the memory footprint? What is the resource footprint", "timestamp": "00:15:55,328", "timestamp_s": 955.0}, {"text": "of that function? So a bunch of good profileable data,", "timestamp": "00:15:58,880", "timestamp_s": 958.0}, {"text": "right? And that\u0027s it. Once all of this data has", "timestamp": "00:16:02,168", "timestamp_s": 962.0}, {"text": "been gotten, this data is stored somewhere to be", "timestamp": "00:16:05,360", "timestamp_s": 965.0}, {"text": "ultimately used by, for whatever purposes.", "timestamp": "00:16:08,528", "timestamp_s": 968.0}, {"text": "And how we leverage that into the feedback driven optimization", "timestamp": "00:16:12,744", "timestamp_s": 972.0}, {"text": "situation, we get profile guided optimization.", "timestamp": "00:16:17,072", "timestamp_s": 977.0}, {"text": "PGO is compiler optimizations, which are", "timestamp": "00:16:21,894", "timestamp_s": 981.0}, {"text": "guided by the profiles of your code collected during its runtime.", "timestamp": "00:16:25,542", "timestamp_s": 985.0}, {"text": "So again, the same thing. Compiler is going through a feedback loop", "timestamp": "00:16:29,102", "timestamp_s": 989.0}, {"text": "of, you know, the application runs, collects runtime behavior and feeds that", "timestamp": "00:16:33,350", "timestamp_s": 993.0}, {"text": "to the compiler, and compiler optimizes it accordingly.", "timestamp": "00:16:36,750", "timestamp_s": 996.0}, {"text": "Here the feedback is just the profiles, sample based profiles collected during runtime,", "timestamp": "00:16:40,134", "timestamp_s": 1000.0}, {"text": "right? So now talk is deep, let\u0027s walk inside the code.", "timestamp": "00:16:44,994", "timestamp_s": 1004.0}, {"text": "So let\u0027s take an example. Let\u0027s say we have a very simple server which exposes", "timestamp": "00:16:48,794", "timestamp_s": 1008.0}, {"text": "a post endpoint and which is called slash render.", "timestamp": "00:16:52,770", "timestamp_s": 1012.0}, {"text": "And whenever you call the post endpoint where the body is the markdown file,", "timestamp": "00:16:56,714", "timestamp_s": 1016.0}, {"text": "you get a rendered markdown in response. So an HTML", "timestamp": "00:17:01,290", "timestamp_s": 1021.0}, {"text": "rendered markdown, let\u0027s say this server is running, serving a bunch of", "timestamp": "00:17:04,882", "timestamp_s": 1024.0}, {"text": "users out there, and you want to compile to optimize", "timestamp": "00:17:08,642", "timestamp_s": 1028.0}, {"text": "just rightfully to it, depending on the usage", "timestamp": "00:17:12,292", "timestamp_s": 1032.0}, {"text": "patterns. So first of all, let\u0027s just", "timestamp": "00:17:15,652", "timestamp_s": 1035.0}, {"text": "compile this code without PGO, without profile guide optimization,", "timestamp": "00:17:19,988", "timestamp_s": 1039.0}, {"text": "and see what are the inlining decisions it takes. So after compiling", "timestamp": "00:17:24,364", "timestamp_s": 1044.0}, {"text": "this code, you can see that it\u0027s performing a bunch of inlining. I mean,", "timestamp": "00:17:28,132", "timestamp_s": 1048.0}, {"text": "it\u0027s quite readable here, but if I expand it further,", "timestamp": "00:17:31,460", "timestamp_s": 1051.0}, {"text": "specifically these method calls, these function calls are getting inlined.", "timestamp": "00:17:34,612", "timestamp_s": 1054.0}, {"text": "But if you notice carefully, there are two places where this inlining", "timestamp": "00:17:38,614", "timestamp_s": 1058.0}, {"text": "is not happening. Now, the decision to not inline a", "timestamp": "00:17:42,390", "timestamp_s": 1062.0}, {"text": "function is a consequence of multiple factors. One reason", "timestamp": "00:17:45,918", "timestamp_s": 1065.0}, {"text": "is that if a function is a non leaf function, it\u0027s like imagine a tree", "timestamp": "00:17:49,726", "timestamp_s": 1069.0}, {"text": "where each function leads to a child node. Each function call leads to a child", "timestamp": "00:17:53,262", "timestamp_s": 1073.0}, {"text": "node. If a function is a non leaf function,", "timestamp": "00:17:56,766", "timestamp_s": 1076.0}, {"text": "there\u0027s a good chance it won\u0027t get in line. Not necessarily, but a good chance.", "timestamp": "00:18:00,054", "timestamp_s": 1080.0}, {"text": "So probably that might be the reason why these two functions are not getting in", "timestamp": "00:18:03,998", "timestamp_s": 1083.0}, {"text": "line. But if you really think about it,", "timestamp": "00:18:07,278", "timestamp_s": 1087.0}, {"text": "inlining could have been useful here because these functions happen", "timestamp": "00:18:10,398", "timestamp_s": 1090.0}, {"text": "to be a part of the render function, which get", "timestamp": "00:18:13,934", "timestamp_s": 1093.0}, {"text": "always executed whenever the API is hit, whenever that endpoint is", "timestamp": "00:18:17,406", "timestamp_s": 1097.0}, {"text": "hit. And imagine thousands of users hitting that API", "timestamp": "00:18:20,550", "timestamp_s": 1100.0}, {"text": "again and again and again the function call over", "timestamp": "00:18:23,854", "timestamp_s": 1103.0}, {"text": "it. The overhead associated with calling the function and invoking the,", "timestamp": "00:18:26,982", "timestamp_s": 1106.0}, {"text": "for example, IO dot read all function not getting inlander", "timestamp": "00:18:30,954", "timestamp_s": 1110.0}, {"text": "can be huge, so it would be quite nice to inline the", "timestamp": "00:18:34,714", "timestamp_s": 1114.0}, {"text": "I o readall function, for example,", "timestamp": "00:18:38,642", "timestamp_s": 1118.0}, {"text": "and accordingly leverage the runtime benefits of it.", "timestamp": "00:18:41,514", "timestamp_s": 1121.0}, {"text": "But again, this is a piece of information which only,", "timestamp": "00:18:44,786", "timestamp_s": 1124.0}, {"text": "which can be only known if you perform the code in runtime. Actually, if there", "timestamp": "00:18:48,402", "timestamp_s": 1128.0}, {"text": "are barely any users, then it doesn\u0027t make sense to inline this function,", "timestamp": "00:18:51,930", "timestamp_s": 1131.0}, {"text": "right? So, so let\u0027s proceed and let\u0027s run", "timestamp": "00:18:55,002", "timestamp_s": 1135.0}, {"text": "and profile the program. So in the first image I built the program,", "timestamp": "00:18:58,350", "timestamp_s": 1138.0}, {"text": "then I built the binary without PGO,", "timestamp": "00:19:01,814", "timestamp_s": 1141.0}, {"text": "and I exported the binary as main nopigo.", "timestamp": "00:19:05,238", "timestamp_s": 1145.0}, {"text": "I ran the no pgo binary, and then I ran the", "timestamp": "00:19:08,446", "timestamp_s": 1148.0}, {"text": "server by this binary, and then I ran a load", "timestamp": "00:19:12,014", "timestamp_s": 1152.0}, {"text": "test generator against this markdown. And once", "timestamp": "00:19:15,494", "timestamp_s": 1155.0}, {"text": "I started executing the load behind the scenes, I opened up a new terminal,", "timestamp": "00:19:18,942", "timestamp_s": 1158.0}, {"text": "new session, and I just started profiling the server", "timestamp": "00:19:22,858", "timestamp_s": 1162.0}, {"text": "for 30 seconds just to collect the data associated with it. And finally,", "timestamp": "00:19:27,002", "timestamp_s": 1167.0}, {"text": "when the new set of profiles were generated after the 30 seconds", "timestamp": "00:19:30,682", "timestamp_s": 1170.0}, {"text": "of profiling, I stored it in a file called default PGO.", "timestamp": "00:19:33,890", "timestamp_s": 1173.0}, {"text": "Now the so ultimately we ended up with these files like main dot", "timestamp": "00:19:37,994", "timestamp_s": 1177.0}, {"text": "PGO, which was the binary, roughly 8.5 megabits large,", "timestamp": "00:19:42,066", "timestamp_s": 1182.0}, {"text": "and we have now cpu, nope, go pprof of,", "timestamp": "00:19:46,026", "timestamp_s": 1186.0}, {"text": "or the default PGO files. Both of these are the same files. These represent the", "timestamp": "00:19:49,466", "timestamp_s": 1189.0}, {"text": "profile of our application running in runtime facing", "timestamp": "00:19:52,902", "timestamp_s": 1192.0}, {"text": "alleged user load. Now let\u0027s compile our program with", "timestamp": "00:19:56,998", "timestamp_s": 1196.0}, {"text": "PGO, and as soon as you notice the dash PGO", "timestamp": "00:20:00,478", "timestamp_s": 1200.0}, {"text": "auto flag here, this basically tells the Go tool chain to", "timestamp": "00:20:03,990", "timestamp_s": 1203.0}, {"text": "use the default PGO profile as a", "timestamp": "00:20:07,782", "timestamp_s": 1207.0}, {"text": "feedback to compile the code. So this default PGO", "timestamp": "00:20:11,190", "timestamp_s": 1211.0}, {"text": "actually told the Go tool chain that how, you know,", "timestamp": "00:20:15,134", "timestamp_s": 1215.0}, {"text": "how frequently the load was hitting the render function", "timestamp": "00:20:18,314", "timestamp_s": 1218.0}, {"text": "and the IO dot redole. And as you can see,", "timestamp": "00:20:22,114", "timestamp_s": 1222.0}, {"text": "Golang now finally decided, the compiler finally decided that", "timestamp": "00:20:26,074", "timestamp_s": 1226.0}, {"text": "it should inline the I O dot read all function as well, which wasn\u0027t getting", "timestamp": "00:20:29,794", "timestamp_s": 1229.0}, {"text": "inland previously, by the way. And, and to", "timestamp": "00:20:33,234", "timestamp_s": 1233.0}, {"text": "be honest, this is not that, I mean behind the scenes, a lot", "timestamp": "00:20:36,770", "timestamp_s": 1236.0}, {"text": "of other internal functions which might be getting called by internal", "timestamp": "00:20:40,058", "timestamp_s": 1240.0}, {"text": "libraries might be getting further in line because of this profile", "timestamp": "00:20:43,532", "timestamp_s": 1243.0}, {"text": "guided optimization. And we can actually confirm that if", "timestamp": "00:20:47,644", "timestamp_s": 1247.0}, {"text": "you list the both the binaries before and after PGO,", "timestamp": "00:20:50,940", "timestamp_s": 1250.0}, {"text": "you can see that the previous binary was smaller and the larger. And this newer", "timestamp": "00:20:54,500", "timestamp_s": 1254.0}, {"text": "one is larger in size, roughly, I mean,", "timestamp": "00:20:58,660", "timestamp_s": 1258.0}, {"text": "0.2 megabytes size larger. That\u0027s because", "timestamp": "00:21:02,132", "timestamp_s": 1262.0}, {"text": "the new binary has more amount of inlining into it for the sake", "timestamp": "00:21:07,704", "timestamp_s": 1267.0}, {"text": "of better runtime benefits. So of course its size is going to be larger as", "timestamp": "00:21:11,200", "timestamp_s": 1271.0}, {"text": "well, because with inlining the code size increases, which is getting in line,", "timestamp": "00:21:14,528", "timestamp_s": 1274.0}, {"text": "right? Because instead of function invocations into", "timestamp": "00:21:17,992", "timestamp_s": 1277.0}, {"text": "your binary present, in your binary, instead of function invocations,", "timestamp": "00:21:21,184", "timestamp_s": 1281.0}, {"text": "you would actually have the definitions of function,", "timestamp": "00:21:25,224", "timestamp_s": 1285.0}, {"text": "which wherever the functions are in line. Alright,", "timestamp": "00:21:28,240", "timestamp_s": 1288.0}, {"text": "so now let\u0027s load test the old and new binaries. Again,", "timestamp": "00:21:31,704", "timestamp_s": 1291.0}, {"text": "as a part of first step, I ran the old binary,", "timestamp": "00:21:35,606", "timestamp_s": 1295.0}, {"text": "which is the main nopigo, and I ran a bunch of benchmarks", "timestamp": "00:21:38,838", "timestamp_s": 1298.0}, {"text": "and I basically dumped those benchmarks into a text file,", "timestamp": "00:21:43,894", "timestamp_s": 1303.0}, {"text": "which is a Nopigo test file. I did the similar thing with the binary", "timestamp": "00:21:47,430", "timestamp_s": 1307.0}, {"text": "with PgO and I dumped its benchmark into a", "timestamp": "00:21:51,614", "timestamp_s": 1311.0}, {"text": "separate text file called withpego. Txt. So ultimately we have two", "timestamp": "00:21:55,382", "timestamp_s": 1315.0}, {"text": "txt files. One, one file contains the results", "timestamp": "00:21:59,030", "timestamp_s": 1319.0}, {"text": "of the benchmarks of old binary, and the other", "timestamp": "00:22:02,170", "timestamp_s": 1322.0}, {"text": "one contains the benchmarks of the new binary. And one", "timestamp": "00:22:05,314", "timestamp_s": 1325.0}, {"text": "thing to be noted here, there is no change of code in both these", "timestamp": "00:22:08,730", "timestamp_s": 1328.0}, {"text": "binaries. No change of code. You I did not change", "timestamp": "00:22:12,010", "timestamp_s": 1332.0}, {"text": "anything. So it is just the magic of profile guided optimization,", "timestamp": "00:22:15,346", "timestamp_s": 1335.0}, {"text": "which we are about to witness. So as you proceed further,", "timestamp": "00:22:19,722", "timestamp_s": 1339.0}, {"text": "if we use benchtack to compare all of these, both of these text files,", "timestamp": "00:22:23,266", "timestamp_s": 1343.0}, {"text": "you would actually notice that with PGO, the runtime,", "timestamp": "00:22:26,930", "timestamp_s": 1346.0}, {"text": "the average runtime actually reduced. Runtime performance actually reduced", "timestamp": "00:22:30,286", "timestamp_s": 1350.0}, {"text": "or improved by roughly 2%, 1.88%.", "timestamp": "00:22:34,486", "timestamp_s": 1354.0}, {"text": "Now, I know it\u0027s not much, but the thing is that", "timestamp": "00:22:38,318", "timestamp_s": 1358.0}, {"text": "we just simulated a very slight amount of load and this was", "timestamp": "00:22:42,230", "timestamp_s": 1362.0}, {"text": "a very random, simple application. But imagine a fully fledged server", "timestamp": "00:22:45,718", "timestamp_s": 1365.0}, {"text": "with thousands and millions of users. In that case, some serious", "timestamp": "00:22:49,166", "timestamp_s": 1369.0}, {"text": "optimizations can be performed and this, this small difference of", "timestamp": "00:22:53,298", "timestamp_s": 1373.0}, {"text": "2% can be substantiated further to even five", "timestamp": "00:22:57,122", "timestamp_s": 1377.0}, {"text": "or 10%. You never know, right? And the best part is", "timestamp": "00:23:00,722", "timestamp_s": 1380.0}, {"text": "that the amount of effort involved with this improvement was nothing,", "timestamp": "00:23:04,178", "timestamp_s": 1384.0}, {"text": "it was negligible. I did not have to change a single line of code and", "timestamp": "00:23:07,514", "timestamp_s": 1387.0}, {"text": "I got this benefit out of the box, right?", "timestamp": "00:23:10,882", "timestamp_s": 1390.0}, {"text": "So let\u0027s do one thing, let\u0027s get", "timestamp": "00:23:13,906", "timestamp_s": 1393.0}, {"text": "our hands dirty. I mean, slides and all are fine, but let\u0027s get our hands", "timestamp": "00:23:17,930", "timestamp_s": 1397.0}, {"text": "dirty and actually play with profile guided optimization, right?", "timestamp": "00:23:20,530", "timestamp_s": 1400.0}, {"text": "On terminal. Alright, so pop", "timestamp": "00:23:23,722", "timestamp_s": 1403.0}, {"text": "open my terminal and you can see that I have a bunch", "timestamp": "00:23:27,994", "timestamp_s": 1407.0}, {"text": "of files here. So, alright, so let", "timestamp": "00:23:31,418", "timestamp_s": 1411.0}, {"text": "me do one thing, let me clean up this stuff, let me just clean up", "timestamp": "00:23:34,938", "timestamp_s": 1414.0}, {"text": "this stuff here, let me clean up this stuff. And so", "timestamp": "00:23:37,698", "timestamp_s": 1417.0}, {"text": "I\u0027ll first of all clean up all the text files. We don\u0027t care about those", "timestamp": "00:23:43,514", "timestamp_s": 1423.0}, {"text": "results anymore. I\u0027ll clean up the old binaries.", "timestamp": "00:23:46,210", "timestamp_s": 1426.0}, {"text": "All right. Main with big.", "timestamp": "00:23:50,614", "timestamp_s": 1430.0}, {"text": "Oh, I\u0027m just cleaning up all the old binaries.", "timestamp": "00:23:54,246", "timestamp_s": 1434.0}, {"text": "And let me clean up all the old profiles as well. All right,", "timestamp": "00:23:57,174", "timestamp_s": 1437.0}, {"text": "so we have nothing. Now we have just, and of course let me remove the", "timestamp": "00:24:03,334", "timestamp_s": 1443.0}, {"text": "default p o file as well.", "timestamp": "00:24:06,670", "timestamp_s": 1446.0}, {"text": "So we are at scratch now. Okay, we are at scratch. We don\u0027t have anything.", "timestamp": "00:24:10,054", "timestamp_s": 1450.0}, {"text": "Now let\u0027s first build our code with nothing, with the,", "timestamp": "00:24:13,590", "timestamp_s": 1453.0}, {"text": "let\u0027s call it main. With, sorry, main,", "timestamp": "00:24:17,838", "timestamp_s": 1457.0}, {"text": "no pgo. And we are compiling the", "timestamp": "00:24:21,494", "timestamp_s": 1461.0}, {"text": "main door go file. Simple. Now with this we have", "timestamp": "00:24:25,974", "timestamp_s": 1465.0}, {"text": "compiled a code and if I run this,", "timestamp": "00:24:29,590", "timestamp_s": 1469.0}, {"text": "sorry, if I run this as this", "timestamp": "00:24:32,646", "timestamp_s": 1472.0}, {"text": "is running. Alright, now let\u0027s go", "timestamp": "00:24:37,758", "timestamp_s": 1477.0}, {"text": "to separate terminal again into a separate session. And actually let\u0027s", "timestamp": "00:24:40,878", "timestamp_s": 1480.0}, {"text": "run the load test. Okay, let\u0027s run the load test", "timestamp": "00:24:45,844", "timestamp_s": 1485.0}, {"text": "now here the load test is running behind the scenes against an application. All right.", "timestamp": "00:24:49,964", "timestamp_s": 1489.0}, {"text": "Now if I go here and if I further start", "timestamp": "00:24:54,484", "timestamp_s": 1494.0}, {"text": "the profiling process, let\u0027s say 30 seconds.", "timestamp": "00:24:57,956", "timestamp_s": 1497.0}, {"text": "Now for 30 seconds I\u0027m, I\u0027ve started the compilation or profiling process.", "timestamp": "00:25:02,284", "timestamp_s": 1502.0}, {"text": "And with this profiling process, what\u0027s happening is that behind the scenes,", "timestamp": "00:25:06,964", "timestamp_s": 1506.0}, {"text": "my binary, my server is getting hit by requests", "timestamp": "00:25:10,212", "timestamp_s": 1510.0}, {"text": "by this load. This means that is actually facing real time user traffic", "timestamp": "00:25:14,392", "timestamp_s": 1514.0}, {"text": "and that\u0027s actually simulating real time user traffic.", "timestamp": "00:25:18,872", "timestamp_s": 1518.0}, {"text": "And the profiling process is capturing all of the information about, you know,", "timestamp": "00:25:21,720", "timestamp_s": 1521.0}, {"text": "at each and every time. What is the memory footprint, what is the", "timestamp": "00:25:25,296", "timestamp_s": 1525.0}, {"text": "cpu footprint, what is the resource footprint of the binary execution.", "timestamp": "00:25:28,568", "timestamp_s": 1528.0}, {"text": "So as you can see, we are done and we have the profile ready", "timestamp": "00:25:32,184", "timestamp_s": 1532.0}, {"text": "here. Let\u0027s just rename our profile to know", "timestamp": "00:25:35,952", "timestamp_s": 1535.0}, {"text": "to default P O because that\u0027s something which is recommended by the", "timestamp": "00:25:41,604", "timestamp_s": 1541.0}, {"text": "Go tool chain. Of course you can have a custom name as well, but just", "timestamp": "00:25:45,492", "timestamp_s": 1545.0}, {"text": "for the sake of convenience, I put it up here. Now let\u0027s do one thing.", "timestamp": "00:25:48,860", "timestamp_s": 1548.0}, {"text": "As you can see, we have the default p go here. Now let\u0027s compile it", "timestamp": "00:25:52,540", "timestamp_s": 1552.0}, {"text": "again main. If I do the", "timestamp": "00:25:56,068", "timestamp_s": 1556.0}, {"text": "compilation process again, this time let\u0027s", "timestamp": "00:25:59,500", "timestamp_s": 1559.0}, {"text": "call the output binary as main. With PGO, we\u0027re doing main", "timestamp": "00:26:02,824", "timestamp_s": 1562.0}, {"text": "go and we will introduce the PGO automatic", "timestamp": "00:26:06,280", "timestamp_s": 1566.0}, {"text": "flag. This basically tells the compiler to read", "timestamp": "00:26:09,384", "timestamp_s": 1569.0}, {"text": "the default PGO file as a feedback for performing the", "timestamp": "00:26:14,104", "timestamp_s": 1574.0}, {"text": "compilation. And let\u0027s see, it\u0027s definitely taking some more time as", "timestamp": "00:26:17,560", "timestamp_s": 1577.0}, {"text": "compared to last time because again, now it\u0027s just going through more", "timestamp": "00:26:20,992", "timestamp_s": 1580.0}, {"text": "amount of scanning through the profiles and accordingly taking the rightful", "timestamp": "00:26:24,272", "timestamp_s": 1584.0}, {"text": "amount of optimization decisions.", "timestamp": "00:26:28,264", "timestamp_s": 1588.0}, {"text": "And yeah, it\u0027s just waiting, it\u0027s building a lot of suspense.", "timestamp": "00:26:31,104", "timestamp_s": 1591.0}, {"text": "But as you can see, it\u0027s doing a lot of compilation and whatnot.", "timestamp": "00:26:35,784", "timestamp_s": 1595.0}, {"text": "And yeah, it\u0027s taking a", "timestamp": "00:26:39,024", "timestamp_s": 1599.0}, {"text": "lot of time. So behind the scenes.", "timestamp": "00:26:42,256", "timestamp_s": 1602.0}, {"text": "Yep, we have stopped all the stuff. So yeah, yeah,", "timestamp": "00:26:47,144", "timestamp_s": 1607.0}, {"text": "it\u0027s not built and if I do a version M dot", "timestamp": "00:26:50,904", "timestamp_s": 1610.0}, {"text": "with ego you can actually see that it did.", "timestamp": "00:26:56,164", "timestamp_s": 1616.0}, {"text": "Consider this default PGO file while doing the compilation.", "timestamp": "00:26:59,604", "timestamp_s": 1619.0}, {"text": "Alright, now let\u0027s run this main with PGO", "timestamp": "00:27:03,076", "timestamp_s": 1623.0}, {"text": "file. But before that let me show you something interesting as", "timestamp": "00:27:06,764", "timestamp_s": 1626.0}, {"text": "well. So let\u0027s look at the sizes.", "timestamp": "00:27:10,100", "timestamp_s": 1630.0}, {"text": "I want to do an ls. Why do list? Yeah, just notice", "timestamp": "00:27:13,204", "timestamp_s": 1633.0}, {"text": "the size of actually,", "timestamp": "00:27:17,764", "timestamp_s": 1637.0}, {"text": "let\u0027s do a grep main as well. Then notice how", "timestamp": "00:27:21,068", "timestamp_s": 1641.0}, {"text": "the size of the one with PGO is actually larger and the one without Pigo", "timestamp": "00:27:24,358", "timestamp_s": 1644.0}, {"text": "is smaller because the one with Pigo actually told the compiler", "timestamp": "00:27:27,510", "timestamp_s": 1647.0}, {"text": "to perform more inlining, which led to the increase in", "timestamp": "00:27:31,062", "timestamp_s": 1651.0}, {"text": "the binary size. And finally let\u0027s execute", "timestamp": "00:27:34,326", "timestamp_s": 1654.0}, {"text": "main with PGO. This time let\u0027s", "timestamp": "00:27:38,422", "timestamp_s": 1658.0}, {"text": "actually perform a bunch of. No, let\u0027s perform benchmarks.", "timestamp": "00:27:42,702", "timestamp_s": 1662.0}, {"text": "Let\u0027s do some benchmarking here. So I\u0027ll", "timestamp": "00:27:46,094", "timestamp_s": 1666.0}, {"text": "actually start the benchmarks here and", "timestamp": "00:27:49,482", "timestamp_s": 1669.0}, {"text": "these benchmarks while these benchmarks are happening, let me tell you what\u0027s happening. The benchmarks", "timestamp": "00:27:53,570", "timestamp_s": 1673.0}, {"text": "are running and they\u0027re basically firing a bunch of load against binary", "timestamp": "00:27:56,802", "timestamp_s": 1676.0}, {"text": "with PGO and they\u0027re storing the", "timestamp": "00:28:00,394", "timestamp_s": 1680.0}, {"text": "results. The benchmarks are storing the results inside this file called with", "timestamp": "00:28:03,810", "timestamp_s": 1683.0}, {"text": "Pigo Txt. So right now we are doing this with PGO.", "timestamp": "00:28:08,282", "timestamp_s": 1688.0}, {"text": "Once these benchmarks are done, we will do these ones without PGO", "timestamp": "00:28:11,954", "timestamp_s": 1691.0}, {"text": "and then we can use a tool called benchtat to compare", "timestamp": "00:28:16,258", "timestamp_s": 1696.0}, {"text": "our results. Alright, so let\u0027s wait for a few", "timestamp": "00:28:20,382", "timestamp_s": 1700.0}, {"text": "seconds and this should be done in anytime soon. And there\u0027s", "timestamp": "00:28:24,174", "timestamp_s": 1704.0}, {"text": "nothing running in the second terminal that the way we generated the load", "timestamp": "00:28:27,990", "timestamp_s": 1707.0}, {"text": "previously was only for the sake of generating profiles that said nothing else.", "timestamp": "00:28:31,734", "timestamp_s": 1711.0}, {"text": "Right now we are doing benchmarking. So we are doing it in a different manner.", "timestamp": "00:28:36,022", "timestamp_s": 1716.0}, {"text": "And as you can see the benchmarks are executed.", "timestamp": "00:28:39,014", "timestamp_s": 1719.0}, {"text": "Now let\u0027s close this binary and run", "timestamp": "00:28:42,166", "timestamp_s": 1722.0}, {"text": "the one without PGO. And as soon as we run here,", "timestamp": "00:28:45,680", "timestamp_s": 1725.0}, {"text": "let me just name this file as nope.", "timestamp": "00:28:49,784", "timestamp_s": 1729.0}, {"text": "And again, this time as well we are running but this time across", "timestamp": "00:28:53,624", "timestamp_s": 1733.0}, {"text": "these benchmarks we will snapshot these benchmarks in", "timestamp": "00:28:57,912", "timestamp_s": 1737.0}, {"text": "a separate file called not nope Exe. And as I said,", "timestamp": "00:29:01,448", "timestamp_s": 1741.0}, {"text": "we will separate out these files and then benchtat against them", "timestamp": "00:29:05,240", "timestamp_s": 1745.0}, {"text": "to compare the real numbers that how things happen in runtime.", "timestamp": "00:29:09,040", "timestamp_s": 1749.0}, {"text": "They might be slightly different from what I showed in the PPT because", "timestamp": "00:29:13,434", "timestamp_s": 1753.0}, {"text": "again the load is kind of non deterministic", "timestamp": "00:29:17,202", "timestamp_s": 1757.0}, {"text": "in that manner. But yeah, let\u0027s see how it, how it happens.", "timestamp": "00:29:21,010", "timestamp_s": 1761.0}, {"text": "So it should be done anytime soon.", "timestamp": "00:29:25,154", "timestamp_s": 1765.0}, {"text": "We have nothing here and the no PBo file is running here.", "timestamp": "00:29:28,754", "timestamp_s": 1768.0}, {"text": "Yep, it\u0027s done. Now if you do bend status,", "timestamp": "00:29:32,954", "timestamp_s": 1772.0}, {"text": "no pgo txt and with", "timestamp": "00:29:37,106", "timestamp_s": 1777.0}, {"text": "pgo txt you can see what a beautiful", "timestamp": "00:29:40,754", "timestamp_s": 1780.0}, {"text": "difference it is. The one with no PGO, your average time was", "timestamp": "00:29:44,330", "timestamp_s": 1784.0}, {"text": "309 microseconds. With PGO it was 301. This is", "timestamp": "00:29:48,202", "timestamp_s": 1788.0}, {"text": "even a higher significant difference,", "timestamp": "00:29:52,210", "timestamp_s": 1792.0}, {"text": "even even a more significant difference with PGO,", "timestamp": "00:29:54,794", "timestamp_s": 1794.0}, {"text": "which is 2.33 as compared to the slides. So let\u0027s go", "timestamp": "00:29:58,362", "timestamp_s": 1798.0}, {"text": "back to the slides and just make some concluding notes.", "timestamp": "00:30:01,650", "timestamp_s": 1801.0}, {"text": "So that\u0027s pretty much it. I guess we learned quite a lot and see", "timestamp": "00:30:06,234", "timestamp_s": 1806.0}, {"text": "how profile guided optimization can actually benefit us a lot. So we", "timestamp": "00:30:09,482", "timestamp_s": 1809.0}, {"text": "explored the process of compilation, how compilation can be made more", "timestamp": "00:30:12,890", "timestamp_s": 1812.0}, {"text": "effective with feedback driven way by feeding it some", "timestamp": "00:30:16,522", "timestamp_s": 1816.0}, {"text": "runtime data and our sampling profiles based. Profile guided optimization", "timestamp": "00:30:19,962", "timestamp_s": 1819.0}, {"text": "works even more effectively in our favor and", "timestamp": "00:30:24,578", "timestamp_s": 1824.0}, {"text": "we actually got a very practical perspective by", "timestamp": "00:30:28,010", "timestamp_s": 1828.0}, {"text": "getting our hands dirty by playing with profile guided optimization", "timestamp": "00:30:31,448", "timestamp_s": 1831.0}, {"text": "with a server like code resembling a real life scenario.", "timestamp": "00:30:35,048", "timestamp_s": 1835.0}, {"text": "And you can find all of these slides and all of the associated content", "timestamp": "00:30:39,024", "timestamp_s": 1839.0}, {"text": "at the link below in my GitHub under my GitHub profile and", "timestamp": "00:30:42,120", "timestamp_s": 1842.0}, {"text": "let me share the references. So there\u0027s a bunch of references I used", "timestamp": "00:30:46,824", "timestamp_s": 1846.0}, {"text": "to learn about this topic and to inherit the content of these slides.", "timestamp": "00:30:50,904", "timestamp_s": 1850.0}, {"text": "Of course, this was just meant like I just sat on the shoulders", "timestamp": "00:30:54,688", "timestamp_s": 1854.0}, {"text": "of these giants who implemented all of this cool stuff.", "timestamp": "00:30:58,412", "timestamp_s": 1858.0}, {"text": "Finally, feel free to connect with me. All of my handles are", "timestamp": "00:31:01,884", "timestamp_s": 1861.0}, {"text": "given here. And that\u0027s all folks. Thanks a", "timestamp": "00:31:05,580", "timestamp_s": 1865.0}, {"text": "lot for your time. I appreciate you giving me your time and", "timestamp": "00:31:09,276", "timestamp_s": 1869.0}, {"text": "attention for this, for attending this talk, and feel absolutely", "timestamp": "00:31:13,324", "timestamp_s": 1873.0}, {"text": "free to raise any questions or reach out to me whenever. Hope you have a", "timestamp": "00:31:17,412", "timestamp_s": 1877.0}, {"text": "great day.", "timestamp": "00:31:20,756", "timestamp_s": 1880.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '8yrhrtZOfgM',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              From Slow to Go: Boosting your code with Profile-Guided Optimization
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>This talk would uncover the performance boosts PGO offers to Go apps, from streamlining hot paths to minimizing resource consumption. Not only a theoretical explainer but we&rsquo;d practically instrument Go binaries to depict the real powers of PGO while touching base with its industrial implications.</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                Yash is a software engineer at Red Hat and pursuing a masters at University of Waterloo in Canada. Today he will talk about profile guided optimization and how it can boost your code. In his free time he likes to do long distance running and build stuff.

              </li>
              
              <li>
                The magic inside the compiler is behind the scenes. Behind the scenes it does a bunch of steps to make code more efficient. With the help of the this power of compiler and optimizations, you can write a very clean piece of code in an abstracted manner.

              </li>
              
              <li>
                Inlining originates from a problem. The act of calling a function is a slow operation in runtime. If there are too many invocations, then the inlining process will be too much. This can lead to a bloated binary. The solution is that compilers could learn more from application code.

              </li>
              
              <li>
                Well, the kernel has a beautiful component called Linux perf, and the Linux perf schedules a bunch of interrupt events with the cpu hardware. PGO is compiler optimizations, which are guided by the profiles of your code collected during its runtime.

              </li>
              
              <li>
                The decision to not inline a function is a consequence of multiple factors. The overhead associated with calling the function and invoking the IO dot read all function not getting inlander can be huge. It would be quite nice to inline the I o readall function and accordingly leverage the runtime benefits of it.

              </li>
              
              <li>
                The new binary has more amount of inlining into it for the sake of better runtime benefits. With PGO, the average runtime actually reduced or improved by roughly 2%, 1.88%. Behind the scenes, a lot of other internal functions might be getting further in line because of this profile guided optimization.

              </li>
              
              <li>
                Let's play with profile guided optimization. Let's first build our code with nothing, with the, let's call it main. With, sorry, main, no pgo. And finally execute main with PGO. This time let's actually perform benchmarks.

              </li>
              
              <li>
                So we explored the process of compilation, how compilation can be made more effective with feedback driven way. You can find all of these slides and all of the associated content at the link below in my GitHub under my GitHub profile and let me share the references. Finally, feel free to connect with me.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/8yrhrtZOfgM.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:20,600'); seek(20.0)">
              Hi everyone, welcome to Con 42 Golang. I hope you had
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:24,030'); seek(24.0)">
              a great time with all the talks until now. I am Yash and today I
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:26,806'); seek(26.0)">
              am extremely excited to be talking about profile guided optimization
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:30,374'); seek(30.0)">
              and how it can boost your code and your compiler. So moving
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:33,726'); seek(33.0)">
              on, let me first of all introduce myself. I am Yash and currently
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:37,118'); seek(37.0)">
              I am working as a software engineer at Red Hat. I am also pursuing a
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:40,798'); seek(40.0)">
              masters at University of Waterloo in Canada and
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:44,310'); seek(44.0)">
              around my work I deal with Openshift, kubernetes,
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:47,126'); seek(47.0)">
              Golang, containers, docker, cloud, native stuff.
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:51,724'); seek(51.0)">
              Apart from that, in my free time, whenever I get some time I
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:55,428'); seek(55.0)">
              do open source dev. I love to do long distance running and I like to
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:58,756'); seek(58.0)">
              just build stuff. So moving on, let's first of all talk
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:02,140'); seek(62.0)">
              about compilation, right? So computers, as you all know, don't understand
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:07,044'); seek(67.0)">
              Golang, python, Java, all that stuff.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:10,324'); seek(70.0)">
              Computers only know zeros and ones, that's the binary language.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:14,124'); seek(74.0)">
              So there is, there should be an entity which translates a
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:17,588'); seek(77.0)">
              Golang code to zeros and ones so that the computer can execute
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:21,318'); seek(81.0)">
              it. And that entity, as most of you would know it,
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:25,006'); seek(85.0)">
              is called the compiler as shown in the image below. You can see
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:28,550'); seek(88.0)">
              that on the left hand side there's a Golang code printing hello world and there's
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:32,310'); seek(92.0)">
              some compiler magic happening which produces the machine code which is
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:35,838'); seek(95.0)">
              the binary or assembly, and that is fed to the linker to
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:39,390'); seek(99.0)">
              produce the actual binary or the executable which
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:42,710'); seek(102.0)">
              you execute to print hello World. Across this talk,
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:45,734'); seek(105.0)">
              we won't talk much about the linker, we would care and talk more about
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:49,500'); seek(109.0)">
              the compiler. So let's move on and let's dive a little bit into
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:53,244'); seek(113.0)">
              the magic inside the compiler. Magic. So compiler is an
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:57,236'); seek(117.0)">
              amazing piece of tech. I mean it's doing so many things so gracefully and
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:01,268'); seek(121.0)">
              beautifully, so behind the scenes it does a bunch
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:04,420'); seek(124.0)">
              of steps. Firstly, it breaks down the code into a bunch of tokens through
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:07,900'); seek(127.0)">
              the means of a lexer. That's that process is tokenization and
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:11,860'); seek(131.0)">
              then that is fed and a tree is created out of
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:15,540'); seek(135.0)">
              that set of tokens and that tree is called abstract syntax tree,
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:19,100'); seek(139.0)">
              which is a representation of your code. That tree then goes
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:22,620'); seek(142.0)">
              through a phase of semantic analysis to determine whether the
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:26,140'); seek(146.0)">
              type checking is happening correctly, whether a code is correct, all that stuff.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:30,460'); seek(150.0)">
              And after that a code is converted into a platform
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:34,388'); seek(154.0)">
              independent representation called IR, which is intermediate
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:37,516'); seek(157.0)">
              representation, and that is fed to the backend of the compiler
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:41,548'); seek(161.0)">
              where a bunch of optimizations happening happen and a lot of
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:44,764'); seek(164.0)">
              magic happens, which by the way, we will dive further into the talk.
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:48,844'); seek(168.0)">
              And finally, this optimized IR is fed to
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:52,428'); seek(172.0)">
              the machine code generator which actually produces the machine code and
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:57,444'); seek(177.0)">
              yeah, feeds it to the linker to generate the executable.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:01,044'); seek(181.0)">
              So let's talk about the optimizations. Sorry, the magic we care
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:04,364'); seek(184.0)">
              about which is the compiler optimizations. So the thing
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:07,890'); seek(187.0)">
              is that the code which you write, the code which I write it
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:11,274'); seek(191.0)">
              might not be the most efficient piece of code behind the scenes,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:14,754'); seek(194.0)">
              meaning that there can be a bunch of efficient optimizations
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:18,330'); seek(198.0)">
              which can be made to it, and compiler takes care
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:21,522'); seek(201.0)">
              of it for us. So if I give you an example, imagine your
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:24,962'); seek(204.0)">
              code has an if statement which will never be executed. For example,
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:29,202'); seek(209.0)">
              it says if false print hello world.
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:32,538'); seek(212.0)">
              Now you and I, we both know that this if statement is
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:36,132'); seek(216.0)">
              absolutely useless. And the compiler also is smart enough
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:39,908'); seek(219.0)">
              to go through these lines of code and see that hey, this if statement
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:43,540'); seek(223.0)">
              would never execute, so let's not even include it during the compilation.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:47,612'); seek(227.0)">
              So in this manner, the compiler actually ends up ignoring
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:51,452'); seek(231.0)">
              this small chunk of code and ends up producing a much lighter executable
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:55,564'); seek(235.0)">
              or binary. Now this was one trivial example, but the compiler actually
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:59,892'); seek(239.0)">
              like applies a bunch of crazy optimizations, and the ultimate
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:03,380'); seek(243.0)">
              benefit is that you end up with the lower executable, sorry, lower size
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:06,860'); seek(246.0)">
              of the executable. There are lesser number of instructions and code
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:10,460'); seek(250.0)">
              jumps happening in runtime because of lower number of instructions.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:14,564'); seek(254.0)">
              And also the compiler can optimize your code during
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:18,404'); seek(258.0)">
              the compilation on the basis of the underlying hardware on top of which your code
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:22,300'); seek(262.0)">
              would run. For example, if your code is doing a lot of GPU programming and
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:25,860'); seek(265.0)">
              the hardware on top of which the compiler is running
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:29,500'); seek(269.0)">
              is also based out of a lot of GPU hardware,
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:32,756'); seek(272.0)">
              then the compiler can really make use of
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:36,040'); seek(276.0)">
              this information and optimize your code accordingly. With the help of the
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:40,344'); seek(280.0)">
              this power of compiler and optimizations, you can actually
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:43,928'); seek(283.0)">
              write a very clean piece of in a very beautiful and readable piece of code
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:47,528'); seek(287.0)">
              in an abstracted manner, and you won't have to be at
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:50,928'); seek(290.0)">
              the performance over it because the compiler would deconstruct these abstractions
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:54,824'); seek(294.0)">
              behind the scenes. So let me give you some
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:58,272'); seek(298.0)">
              examples of these optimizations. One optimization is pre calculation of constants
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:02,008'); seek(302.0)">
              where if you have an expression like a is equal to two multiplied by
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:05,680'); seek(305.0)">
              three plus five, the compiler during the compile time itself
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:09,544'); seek(309.0)">
              can calculate this and say that hey, there is no need
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:13,200'); seek(313.0)">
              to compute this again and again in runtime. Let me just compute it and
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:16,760'); seek(316.0)">
              straightaway feed it in the compilation phase itself.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:19,904'); seek(319.0)">
              Similarly, there's a process of loop unrolling where the for
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:23,376'); seek(323.0)">
              loop is unrolled further. So that in runtime, when the
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:27,368'); seek(327.0)">
              for loop runs, it does not have to check the condition phase of the
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:30,640'); seek(330.0)">
              for loop multiple times. That also saves in a bunch of cpu cycles.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:34,344'); seek(334.0)">
              And finally, there's a an optimization called Dead Star elimination where a bunch
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:38,260'); seek(338.0)">
              of useless code is ignored.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:41,724'); seek(341.0)">
              For example, in the right hand image you can see that the
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:45,748'); seek(345.0)">
              variable is constantly getting updated. But all of those updates
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:49,796'); seek(349.0)">
              don't matter because the last update is going to overwrite all
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:53,268'); seek(353.0)">
              of the previous updates. So the compiler is smart enough to notice
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:56,676'); seek(356.0)">
              this, and it ignores all the above two lines and only considers
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:00,628'); seek(360.0)">
              the last line during the compilation. So the compiler does a lot of
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:04,344'); seek(364.0)">
              these cool optimizations, but we are interested in
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:08,048'); seek(368.0)">
              one optimization, and that is inlining.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:11,064'); seek(371.0)">
              And this talk is going to be centered around this optimization.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:14,904'); seek(374.0)">
              So inlining originates from a problem. The problem
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:18,784'); seek(378.0)">
              is the act of calling a function. All of us
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:22,072'); seek(382.0)">
              write a code in a pretty functional manner. We define functions, we call those functions
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:25,648'); seek(385.0)">
              multiple times. The problem is that in runtime,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:29,420'); seek(389.0)">
              the act of calling a function is a slow operation, because when
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:32,948'); seek(392.0)">
              you just call the function, when you just invoke the function, a bunch
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:36,628'); seek(396.0)">
              of stuff happens behind the scenes which adds up to the runtime over it.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:40,068'); seek(400.0)">
              For example, a new stack is like dedicated for the scope
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:43,860'); seek(403.0)">
              of the function. The parameters are pushed onto that stack whenever the
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:47,332'); seek(407.0)">
              function is completed with the execution, the returned
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:50,972'); seek(410.0)">
              values are returned back to the caller. So all of these things add
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:54,420'); seek(414.0)">
              up to the performance overhead in runtime. So the what the compiler
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:58,320'); seek(418.0)">
              does is compiler performs this optimization called inlining,
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:01,808'); seek(421.0)">
              where the compiler takes the body and implementation of the
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:04,960'); seek(424.0)">
              function and just places it wherever
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:08,064'); seek(428.0)">
              that function is invoked. So if you look at the image below,
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:11,488'); seek(431.0)">
              we have a function called sum, which sums up two parameters,
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:15,480'); seek(435.0)">
              x and y, and we have a main function where we are invoking this function
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:19,232'); seek(439.0)">
              twice. So if we perform inlining here,
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:22,176'); seek(442.0)">
              the compiler can actually just strip off the definition of the sum
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:25,642'); seek(445.0)">
              function and just replace the invocations of the sum
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:28,882'); seek(448.0)">
              function with their actual implementation. So sum one
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:32,722'); seek(452.0)">
              comma two becomes one plus two, some two comma four becomes
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:36,002'); seek(456.0)">
              two plus four. And the beautiful part is that this
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:07:40,210'); seek(460.0)">
              newly inlined piece of code can be further optimized through,
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:43,666'); seek(463.0)">
              say, pre calculation of constants to actually know
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:47,082'); seek(467.0)">
              in the compilation phase itself that res one is equal to three,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:50,546'); seek(470.0)">
              res two is equal to six. So from a runtime perspective, things become very much
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:54,168'); seek(474.0)">
              more efficient, and that ends up elimination, eliminating the functional
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:07:57,544'); seek(477.0)">
              colleagues as well. But we have a problem.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:00,664'); seek(480.0)">
              Nothing is perfect in word. What if you have
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:04,000'); seek(484.0)">
              defined a function and it has too many invocations?
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:07,864'); seek(487.0)">
              If there are too many invocations, then the inlining process will be
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:11,448'); seek(491.0)">
              too much if we perform the inlining blindly, and that would lead to
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:14,760'); seek(494.0)">
              too many new lines of code. This means that the code size would
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:18,344'); seek(498.0)">
              increase massively and that would lead to a bloated binary,
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:22,104'); seek(502.0)">
              and that ends up having some bad consequences in the runtime.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:25,248'); seek(505.0)">
              For example, if I really go into the depth, then uploaded
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:29,680'); seek(509.0)">
              binary, basically behind the scenes means more number of static instructions
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:33,584'); seek(513.0)">
              and the higher number of static instructions in a binary in an executable,
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:38,784'); seek(518.0)">
              the bigger the instruction caches, and that leads to a bad
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:08:43,296'); seek(523.0)">
              cache hit ratio or cache it rate, and that leads
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:08:46,880'); seek(526.0)">
              to instruction cache message, which is quite bad in runtime. Moreover, a bloated
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:50,736'); seek(530.0)">
              binary causes page faults and whatnot. And if you are running your binary on
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:54,544'); seek(534.0)">
              a small device like a raspberry PI or something, even thrashing
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:08:58,120'); seek(538.0)">
              could happen. So blindly inlining a piece of code can be a bad
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:01,832'); seek(541.0)">
              situation. I have shown that as an example on the right hand image as well,
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:04,960'); seek(544.0)">
              that inlining a 506 lines of code,
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:08,072'); seek(548.0)">
              uh, can result in a 1000 lines of code result.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:12,324'); seek(552.0)">
              So we have a weird problem here. Now if we do less in line inlining,
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:16,036'); seek(556.0)">
              we have a bad runtime performance because of the overhead introduced
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:19,356'); seek(559.0)">
              due to those function calls. And if we do more inlining,
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:23,060'); seek(563.0)">
              then we have a bad runtime performance due to the bigger executable,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:26,588'); seek(566.0)">
              the page faults, the instruction cache misses and whatnot.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:29,924'); seek(569.0)">
              So what to do then? That is frustrating.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:32,924'); seek(572.0)">
              Well, we just need the right amount of inlining.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:36,204'); seek(576.0)">
              So what does it mean? Ideally, we want to inline
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:09:39,788'); seek(579.0)">
              only the hot functions and not inline the cold functions.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:43,148'); seek(583.0)">
              So the hot functions are the one which happen to execute a lot more frequently
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:47,180'); seek(587.0)">
              in runtime, while the cold functions are the one which don't execute
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:50,780'); seek(590.0)">
              that often in runtime. So the benefit of inlining hot functions is that
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:54,644'); seek(594.0)">
              these functions would execute a lot of times in runtime. This means that if you
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:58,332'); seek(598.0)">
              inline these functions, then you end up avoiding the function
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:01,884'); seek(601.0)">
              call overhead in runtime. So this gives you the benefit, the runtime benefit of
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:05,748'); seek(605.0)">
              inlining. You don't need to inline the cold functions
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:09,028'); seek(609.0)">
              because they are not executing enough amount of time, so there's no
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:13,052'); seek(613.0)">
              benefit in lining them. So by avoiding to
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:16,332'); seek(616.0)">
              inlining the cold functions, you actually end up saving on the
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:19,908'); seek(619.0)">
              binary size and the instruction count, and save yourself from
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:23,900'); seek(623.0)">
              all those bad stuff associated with excessive inlining.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:27,630'); seek(627.0)">
              So ultimately we just need a sprinkle of inlining. And the
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:31,358'); seek(631.0)">
              problem is that compilers don't know a lot. When a compiler is compiling your
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:34,950'); seek(634.0)">
              code, it's literally reading across your code, it does not know
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:10:39,094'); seek(639.0)">
              a lot more information. So. And just your written code
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:10:43,214'); seek(643.0)">
              is not enough to tell how frequently a function would execute in runtime.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:47,254'); seek(647.0)">
              Clearly compilers in more info. And what if we
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:51,190'); seek(651.0)">
              have a solution? The solution is that what if the compilers could look
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:54,532'); seek(654.0)">
              at the application in runtime and learn from that application,
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:10:58,148'); seek(658.0)">
              learn that which functions are hot and which functions are called?
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:01,204'); seek(661.0)">
              Or in other words, from a more implementation perspective, what if
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:04,868'); seek(664.0)">
              your applications runs in runtime and some somehow
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:08,892'); seek(668.0)">
              you collect various numbers and metrics about its behavior in runtime
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:12,924'); seek(672.0)">
              and finally feed those numbers and behavior as an information
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:16,820'); seek(676.0)">
              to the compiler. Next time you compile our code.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:20,202'); seek(680.0)">
              So this with the next time you compile our code, the compiler would know that
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:23,362'); seek(683.0)">
              hey, this function is hot and that function is called. So let me just
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:27,162'); seek(687.0)">
              inline this function. So this kind of looks like a feedback loop,
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:30,714'); seek(690.0)">
              right? And that brings us to feedback driven
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:33,938'); seek(693.0)">
              optimization. So as the name suggests, it just
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:11:37,234'); seek(697.0)">
              teaches the compilers how and where to optimize the code
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:11:40,714'); seek(700.0)">
              on the basis of a feedback. Now that feedback can be benchmarks,
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:11:44,274'); seek(704.0)">
              user traffic profiles, all that kind of stuff. That feedback
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:11:47,674'); seek(707.0)">
              ultimately tells the compiler that which function is hot, which function is cold,
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:51,810'); seek(711.0)">
              and ultimately the compiler just does the right amount of inlining.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:11:56,834'); seek(716.0)">
              Now the early days of feedback driven optimization were kind of
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:00,362'); seek(720.0)">
              governed by instrumentation based process. So what
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:03,570'); seek(723.0)">
              is instrumentation? It's very simple. With instrumentation,
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:06,914'); seek(726.0)">
              what happens is that whenever a code is compiled by the compiler,
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:10,426'); seek(730.0)">
              the compiler actually injects extra lines of code within your
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:14,232'); seek(734.0)">
              code. And what are these extra lines of code? Some timers,
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:17,976'); seek(737.0)">
              some call counters, all that kind of stuff. And the purpose of these
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:21,200'); seek(741.0)">
              additional lines of code is to track and instrument the behavior of your
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:24,760'); seek(744.0)">
              code in runtime. So once your code is compiled with these extra
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:28,232'); seek(748.0)">
              lines of code, a bunch of benchmarks are run against your application or
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:31,920'); seek(751.0)">
              code. And through the means of these extra lines of code, while these benchmarks
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:12:35,944'); seek(755.0)">
              are running, a bunch of information gets instrumented and collected,
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:12:39,544'); seek(759.0)">
              and this information becomes the feedback for the next build of the compiler.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:12:43,818'); seek(763.0)">
              This information ends up representing how your application is performing in runtime.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:12:48,594'); seek(768.0)">
              Now this sounds good, but is it really that efficient or that reliable?
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:12:52,938'); seek(772.0)">
              Because the thing is that now with this whole process, the code becomes
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:12:56,482'); seek(776.0)">
              much more bloated with all those compiler introduced instrumentation.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:00,330'); seek(780.0)">
              And we have an extra benchmarking step, which just like makes
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:04,474'); seek(784.0)">
              the entire process of compilation and building
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:08,266'); seek(788.0)">
              quite slower and boring. And the biggest problem is that what
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:11,720'); seek(791.0)">
              if the benchmarks don't even resemble the reality of how your code
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:15,280'); seek(795.0)">
              runs in production, for example, right?
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:18,744'); seek(798.0)">
              What if it's actually quite opposite. And the benchmarks
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:22,544'); seek(802.0)">
              might end up introducing some wrongfully assumed optimizations and
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:26,584'); seek(806.0)">
              that can cause some really bad performance degradation.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:29,448'); seek(809.0)">
              So a potentially hot function might be perceived as a cold function by the benchmark,
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:33,872'); seek(813.0)">
              and your compiler would not optimize it rightfully.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:37,374'); seek(817.0)">
              So what do you want? Let's talk first principles.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:13:40,614'); seek(820.0)">
              We want faster build times. We want realistic runtime data instead
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:13:44,310'); seek(824.0)">
              of benchmarks pretending to be real. And finally, we want light
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:13:48,206'); seek(828.0)">
              and small executables with no extra lines of code due to instrumentation.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:13:52,534'); seek(832.0)">
              If you hate benchmarks, don't use them. So what
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:13:57,230'); seek(837.0)">
              we can do is that instead of benchmarks we can actually use the actual
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:00,758'); seek(840.0)">
              behavior of your code as a feedback to your compiler. And the
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:04,498'); seek(844.0)">
              beauty is that if you do that, you have now become independent
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:07,850'); seek(847.0)">
              of the benchmarking process as well, with which now you can just compile our
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:11,650'); seek(851.0)">
              code and that's what you are done. You don't have to execute the benchmarks,
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:14,914'); seek(854.0)">
              and this gives you the faster build times. Also, this is more realistic because you're
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:19,202'); seek(859.0)">
              not relying on any pretentious benchmarks pretending to be real users.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:23,434'); seek(863.0)">
              So how do you do that? To be specific,
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:27,194'); seek(867.0)">
              it's sample based profiling. So the beauty of profiling is that it tracks the runtime
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:31,050'); seek(871.0)">
              behavior of your code without needing those extra lines of
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:34,630'); seek(874.0)">
              code inserted during for the sake of
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:37,990'); seek(877.0)">
              instrumentation. And when I say profiling, I mean sample based
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:14:41,662'); seek(881.0)">
              profiling, because like if we go really technical,
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:14:44,894'); seek(884.0)">
              then instrumentation is also a type of profiling. So what I'm talking about here is
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:14:48,542'); seek(888.0)">
              actually sample based profiling. But across this talk,
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:14:51,886'); seek(891.0)">
              whenever I say profiling, just here, sample based profiling.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:14:55,014'); seek(895.0)">
              Alright, so yeah, how does it work? It's pretty simple.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:14:58,702'); seek(898.0)">
              Now, just because we don't have those additional extra lines of
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:02,482'); seek(902.0)">
              code in the, in our code during the compilation
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:06,026'); seek(906.0)">
              phase, we need some external entity to poke and monitor
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:09,698'); seek(909.0)">
              and profile your application. And this is where the kernel and enters
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:13,210'); seek(913.0)">
              into the picture. So imagine an application is running in user
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:16,554'); seek(916.0)">
              space. How does it get profiled? Well, the kernel has a beautiful component
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:20,722'); seek(920.0)">
              called Linux perf, and the Linux perf schedules a bunch
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:24,130'); seek(924.0)">
              of interrupt events with the cpu hardware,
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:27,596'); seek(927.0)">
              and that's that hardware inside the cpu ends up scheduling
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:31,332'); seek(931.0)">
              and triggering those interrupts. And whenever those interrupts are triggered,
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:34,796'); seek(934.0)">
              the interrupt handler captures them inside the kernel, and the
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:15:38,332'); seek(938.0)">
              interrupt handler correspondingly pokes your application in
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:15:42,180'); seek(942.0)">
              user space and gets the runtime data at that point
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:15:45,612'); seek(945.0)">
              in time. Now that runtime data includes instruction pointer and
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:15:48,948'); seek(948.0)">
              call stack, which is enough to tell which function
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:15:52,104'); seek(952.0)">
              is executing at that time, which parameters are allocated in
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:15:55,328'); seek(955.0)">
              that function, what is the memory footprint? What is the resource footprint
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:15:58,880'); seek(958.0)">
              of that function? So a bunch of good profileable data,
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:02,168'); seek(962.0)">
              right? And that's it. Once all of this data has
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:05,360'); seek(965.0)">
              been gotten, this data is stored somewhere to be
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:08,528'); seek(968.0)">
              ultimately used by, for whatever purposes.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:12,744'); seek(972.0)">
              And how we leverage that into the feedback driven optimization
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:17,072'); seek(977.0)">
              situation, we get profile guided optimization.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:21,894'); seek(981.0)">
              PGO is compiler optimizations, which are
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:25,542'); seek(985.0)">
              guided by the profiles of your code collected during its runtime.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:29,102'); seek(989.0)">
              So again, the same thing. Compiler is going through a feedback loop
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:33,350'); seek(993.0)">
              of, you know, the application runs, collects runtime behavior and feeds that
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:16:36,750'); seek(996.0)">
              to the compiler, and compiler optimizes it accordingly.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:16:40,134'); seek(1000.0)">
              Here the feedback is just the profiles, sample based profiles collected during runtime,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:16:44,994'); seek(1004.0)">
              right? So now talk is deep, let's walk inside the code.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:16:48,794'); seek(1008.0)">
              So let's take an example. Let's say we have a very simple server which exposes
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:16:52,770'); seek(1012.0)">
              a post endpoint and which is called slash render.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:16:56,714'); seek(1016.0)">
              And whenever you call the post endpoint where the body is the markdown file,
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:01,290'); seek(1021.0)">
              you get a rendered markdown in response. So an HTML
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:04,882'); seek(1024.0)">
              rendered markdown, let's say this server is running, serving a bunch of
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:08,642'); seek(1028.0)">
              users out there, and you want to compile to optimize
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:12,292'); seek(1032.0)">
              just rightfully to it, depending on the usage
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:15,652'); seek(1035.0)">
              patterns. So first of all, let's just
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:19,988'); seek(1039.0)">
              compile this code without PGO, without profile guide optimization,
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:24,364'); seek(1044.0)">
              and see what are the inlining decisions it takes. So after compiling
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:28,132'); seek(1048.0)">
              this code, you can see that it's performing a bunch of inlining. I mean,
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:31,460'); seek(1051.0)">
              it's quite readable here, but if I expand it further,
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:34,612'); seek(1054.0)">
              specifically these method calls, these function calls are getting inlined.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:38,614'); seek(1058.0)">
              But if you notice carefully, there are two places where this inlining
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:17:42,390'); seek(1062.0)">
              is not happening. Now, the decision to not inline a
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:17:45,918'); seek(1065.0)">
              function is a consequence of multiple factors. One reason
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:17:49,726'); seek(1069.0)">
              is that if a function is a non leaf function, it's like imagine a tree
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:17:53,262'); seek(1073.0)">
              where each function leads to a child node. Each function call leads to a child
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:17:56,766'); seek(1076.0)">
              node. If a function is a non leaf function,
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:00,054'); seek(1080.0)">
              there's a good chance it won't get in line. Not necessarily, but a good chance.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:03,998'); seek(1083.0)">
              So probably that might be the reason why these two functions are not getting in
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:07,278'); seek(1087.0)">
              line. But if you really think about it,
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:10,398'); seek(1090.0)">
              inlining could have been useful here because these functions happen
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:13,934'); seek(1093.0)">
              to be a part of the render function, which get
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:17,406'); seek(1097.0)">
              always executed whenever the API is hit, whenever that endpoint is
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:20,550'); seek(1100.0)">
              hit. And imagine thousands of users hitting that API
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:23,854'); seek(1103.0)">
              again and again and again the function call over
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:18:26,982'); seek(1106.0)">
              it. The overhead associated with calling the function and invoking the,
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:18:30,954'); seek(1110.0)">
              for example, IO dot read all function not getting inlander
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:18:34,714'); seek(1114.0)">
              can be huge, so it would be quite nice to inline the
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:18:38,642'); seek(1118.0)">
              I o readall function, for example,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:18:41,514'); seek(1121.0)">
              and accordingly leverage the runtime benefits of it.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:18:44,786'); seek(1124.0)">
              But again, this is a piece of information which only,
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:18:48,402'); seek(1128.0)">
              which can be only known if you perform the code in runtime. Actually, if there
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:18:51,930'); seek(1131.0)">
              are barely any users, then it doesn't make sense to inline this function,
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:18:55,002'); seek(1135.0)">
              right? So, so let's proceed and let's run
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:18:58,350'); seek(1138.0)">
              and profile the program. So in the first image I built the program,
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:01,814'); seek(1141.0)">
              then I built the binary without PGO,
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:05,238'); seek(1145.0)">
              and I exported the binary as main nopigo.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:08,446'); seek(1148.0)">
              I ran the no pgo binary, and then I ran the
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:19:12,014'); seek(1152.0)">
              server by this binary, and then I ran a load
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:19:15,494'); seek(1155.0)">
              test generator against this markdown. And once
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:19:18,942'); seek(1158.0)">
              I started executing the load behind the scenes, I opened up a new terminal,
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:19:22,858'); seek(1162.0)">
              new session, and I just started profiling the server
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:19:27,002'); seek(1167.0)">
              for 30 seconds just to collect the data associated with it. And finally,
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:19:30,682'); seek(1170.0)">
              when the new set of profiles were generated after the 30 seconds
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:19:33,890'); seek(1173.0)">
              of profiling, I stored it in a file called default PGO.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:19:37,994'); seek(1177.0)">
              Now the so ultimately we ended up with these files like main dot
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:19:42,066'); seek(1182.0)">
              PGO, which was the binary, roughly 8.5 megabits large,
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:19:46,026'); seek(1186.0)">
              and we have now cpu, nope, go pprof of,
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:19:49,466'); seek(1189.0)">
              or the default PGO files. Both of these are the same files. These represent the
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:19:52,902'); seek(1192.0)">
              profile of our application running in runtime facing
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:19:56,998'); seek(1196.0)">
              alleged user load. Now let's compile our program with
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:20:00,478'); seek(1200.0)">
              PGO, and as soon as you notice the dash PGO
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:20:03,990'); seek(1203.0)">
              auto flag here, this basically tells the Go tool chain to
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:20:07,782'); seek(1207.0)">
              use the default PGO profile as a
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:20:11,190'); seek(1211.0)">
              feedback to compile the code. So this default PGO
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:20:15,134'); seek(1215.0)">
              actually told the Go tool chain that how, you know,
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:20:18,314'); seek(1218.0)">
              how frequently the load was hitting the render function
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:20:22,114'); seek(1222.0)">
              and the IO dot redole. And as you can see,
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:20:26,074'); seek(1226.0)">
              Golang now finally decided, the compiler finally decided that
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:20:29,794'); seek(1229.0)">
              it should inline the I O dot read all function as well, which wasn't getting
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:20:33,234'); seek(1233.0)">
              inland previously, by the way. And, and to
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:20:36,770'); seek(1236.0)">
              be honest, this is not that, I mean behind the scenes, a lot
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:20:40,058'); seek(1240.0)">
              of other internal functions which might be getting called by internal
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:20:43,532'); seek(1243.0)">
              libraries might be getting further in line because of this profile
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:20:47,644'); seek(1247.0)">
              guided optimization. And we can actually confirm that if
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:20:50,940'); seek(1250.0)">
              you list the both the binaries before and after PGO,
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:20:54,500'); seek(1254.0)">
              you can see that the previous binary was smaller and the larger. And this newer
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:20:58,660'); seek(1258.0)">
              one is larger in size, roughly, I mean,
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:21:02,132'); seek(1262.0)">
              0.2 megabytes size larger. That's because
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:21:07,704'); seek(1267.0)">
              the new binary has more amount of inlining into it for the sake
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:21:11,200'); seek(1271.0)">
              of better runtime benefits. So of course its size is going to be larger as
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:21:14,528'); seek(1274.0)">
              well, because with inlining the code size increases, which is getting in line,
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:21:17,992'); seek(1277.0)">
              right? Because instead of function invocations into
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:21:21,184'); seek(1281.0)">
              your binary present, in your binary, instead of function invocations,
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:21:25,224'); seek(1285.0)">
              you would actually have the definitions of function,
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:21:28,240'); seek(1288.0)">
              which wherever the functions are in line. Alright,
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:21:31,704'); seek(1291.0)">
              so now let's load test the old and new binaries. Again,
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:21:35,606'); seek(1295.0)">
              as a part of first step, I ran the old binary,
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:21:38,838'); seek(1298.0)">
              which is the main nopigo, and I ran a bunch of benchmarks
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:21:43,894'); seek(1303.0)">
              and I basically dumped those benchmarks into a text file,
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:21:47,430'); seek(1307.0)">
              which is a Nopigo test file. I did the similar thing with the binary
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:21:51,614'); seek(1311.0)">
              with PgO and I dumped its benchmark into a
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:21:55,382'); seek(1315.0)">
              separate text file called withpego. Txt. So ultimately we have two
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:21:59,030'); seek(1319.0)">
              txt files. One, one file contains the results
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:22:02,170'); seek(1322.0)">
              of the benchmarks of old binary, and the other
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:22:05,314'); seek(1325.0)">
              one contains the benchmarks of the new binary. And one
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:22:08,730'); seek(1328.0)">
              thing to be noted here, there is no change of code in both these
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:22:12,010'); seek(1332.0)">
              binaries. No change of code. You I did not change
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:22:15,346'); seek(1335.0)">
              anything. So it is just the magic of profile guided optimization,
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:22:19,722'); seek(1339.0)">
              which we are about to witness. So as you proceed further,
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:22:23,266'); seek(1343.0)">
              if we use benchtack to compare all of these, both of these text files,
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:22:26,930'); seek(1346.0)">
              you would actually notice that with PGO, the runtime,
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:22:30,286'); seek(1350.0)">
              the average runtime actually reduced. Runtime performance actually reduced
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:22:34,486'); seek(1354.0)">
              or improved by roughly 2%, 1.88%.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:22:38,318'); seek(1358.0)">
              Now, I know it's not much, but the thing is that
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:22:42,230'); seek(1362.0)">
              we just simulated a very slight amount of load and this was
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:22:45,718'); seek(1365.0)">
              a very random, simple application. But imagine a fully fledged server
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:22:49,166'); seek(1369.0)">
              with thousands and millions of users. In that case, some serious
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:22:53,298'); seek(1373.0)">
              optimizations can be performed and this, this small difference of
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:22:57,122'); seek(1377.0)">
              2% can be substantiated further to even five
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:23:00,722'); seek(1380.0)">
              or 10%. You never know, right? And the best part is
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:23:04,178'); seek(1384.0)">
              that the amount of effort involved with this improvement was nothing,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:23:07,514'); seek(1387.0)">
              it was negligible. I did not have to change a single line of code and
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:23:10,882'); seek(1390.0)">
              I got this benefit out of the box, right?
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:23:13,906'); seek(1393.0)">
              So let's do one thing, let's get
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:23:17,930'); seek(1397.0)">
              our hands dirty. I mean, slides and all are fine, but let's get our hands
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:23:20,530'); seek(1400.0)">
              dirty and actually play with profile guided optimization, right?
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:23:23,722'); seek(1403.0)">
              On terminal. Alright, so pop
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:23:27,994'); seek(1407.0)">
              open my terminal and you can see that I have a bunch
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:23:31,418'); seek(1411.0)">
              of files here. So, alright, so let
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:23:34,938'); seek(1414.0)">
              me do one thing, let me clean up this stuff, let me just clean up
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:23:37,698'); seek(1417.0)">
              this stuff here, let me clean up this stuff. And so
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:23:43,514'); seek(1423.0)">
              I'll first of all clean up all the text files. We don't care about those
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:23:46,210'); seek(1426.0)">
              results anymore. I'll clean up the old binaries.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:23:50,614'); seek(1430.0)">
              All right. Main with big.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:23:54,246'); seek(1434.0)">
              Oh, I'm just cleaning up all the old binaries.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:23:57,174'); seek(1437.0)">
              And let me clean up all the old profiles as well. All right,
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:24:03,334'); seek(1443.0)">
              so we have nothing. Now we have just, and of course let me remove the
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:24:06,670'); seek(1446.0)">
              default p o file as well.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:24:10,054'); seek(1450.0)">
              So we are at scratch now. Okay, we are at scratch. We don't have anything.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:24:13,590'); seek(1453.0)">
              Now let's first build our code with nothing, with the,
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:24:17,838'); seek(1457.0)">
              let's call it main. With, sorry, main,
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:24:21,494'); seek(1461.0)">
              no pgo. And we are compiling the
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:24:25,974'); seek(1465.0)">
              main door go file. Simple. Now with this we have
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:24:29,590'); seek(1469.0)">
              compiled a code and if I run this,
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:24:32,646'); seek(1472.0)">
              sorry, if I run this as this
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:24:37,758'); seek(1477.0)">
              is running. Alright, now let's go
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:24:40,878'); seek(1480.0)">
              to separate terminal again into a separate session. And actually let's
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:24:45,844'); seek(1485.0)">
              run the load test. Okay, let's run the load test
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:24:49,964'); seek(1489.0)">
              now here the load test is running behind the scenes against an application. All right.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:24:54,484'); seek(1494.0)">
              Now if I go here and if I further start
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:24:57,956'); seek(1497.0)">
              the profiling process, let's say 30 seconds.
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:25:02,284'); seek(1502.0)">
              Now for 30 seconds I'm, I've started the compilation or profiling process.
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:25:06,964'); seek(1506.0)">
              And with this profiling process, what's happening is that behind the scenes,
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:25:10,212'); seek(1510.0)">
              my binary, my server is getting hit by requests
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:25:14,392'); seek(1514.0)">
              by this load. This means that is actually facing real time user traffic
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:25:18,872'); seek(1518.0)">
              and that's actually simulating real time user traffic.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:25:21,720'); seek(1521.0)">
              And the profiling process is capturing all of the information about, you know,
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:25:25,296'); seek(1525.0)">
              at each and every time. What is the memory footprint, what is the
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:25:28,568'); seek(1528.0)">
              cpu footprint, what is the resource footprint of the binary execution.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:25:32,184'); seek(1532.0)">
              So as you can see, we are done and we have the profile ready
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:25:35,952'); seek(1535.0)">
              here. Let's just rename our profile to know
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:25:41,604'); seek(1541.0)">
              to default P O because that's something which is recommended by the
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:25:45,492'); seek(1545.0)">
              Go tool chain. Of course you can have a custom name as well, but just
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:25:48,860'); seek(1548.0)">
              for the sake of convenience, I put it up here. Now let's do one thing.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:25:52,540'); seek(1552.0)">
              As you can see, we have the default p go here. Now let's compile it
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:25:56,068'); seek(1556.0)">
              again main. If I do the
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:25:59,500'); seek(1559.0)">
              compilation process again, this time let's
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:26:02,824'); seek(1562.0)">
              call the output binary as main. With PGO, we're doing main
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:26:06,280'); seek(1566.0)">
              go and we will introduce the PGO automatic
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:26:09,384'); seek(1569.0)">
              flag. This basically tells the compiler to read
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:26:14,104'); seek(1574.0)">
              the default PGO file as a feedback for performing the
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:26:17,560'); seek(1577.0)">
              compilation. And let's see, it's definitely taking some more time as
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:26:20,992'); seek(1580.0)">
              compared to last time because again, now it's just going through more
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:26:24,272'); seek(1584.0)">
              amount of scanning through the profiles and accordingly taking the rightful
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:26:28,264'); seek(1588.0)">
              amount of optimization decisions.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:26:31,104'); seek(1591.0)">
              And yeah, it's just waiting, it's building a lot of suspense.
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:26:35,784'); seek(1595.0)">
              But as you can see, it's doing a lot of compilation and whatnot.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:26:39,024'); seek(1599.0)">
              And yeah, it's taking a
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:26:42,256'); seek(1602.0)">
              lot of time. So behind the scenes.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:26:47,144'); seek(1607.0)">
              Yep, we have stopped all the stuff. So yeah, yeah,
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:26:50,904'); seek(1610.0)">
              it's not built and if I do a version M dot
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:26:56,164'); seek(1616.0)">
              with ego you can actually see that it did.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:26:59,604'); seek(1619.0)">
              Consider this default PGO file while doing the compilation.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:27:03,076'); seek(1623.0)">
              Alright, now let's run this main with PGO
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:27:06,764'); seek(1626.0)">
              file. But before that let me show you something interesting as
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:27:10,100'); seek(1630.0)">
              well. So let's look at the sizes.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:27:13,204'); seek(1633.0)">
              I want to do an ls. Why do list? Yeah, just notice
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:27:17,764'); seek(1637.0)">
              the size of actually,
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:27:21,068'); seek(1641.0)">
              let's do a grep main as well. Then notice how
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:27:24,358'); seek(1644.0)">
              the size of the one with PGO is actually larger and the one without Pigo
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:27:27,510'); seek(1647.0)">
              is smaller because the one with Pigo actually told the compiler
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:27:31,062'); seek(1651.0)">
              to perform more inlining, which led to the increase in
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:27:34,326'); seek(1654.0)">
              the binary size. And finally let's execute
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:27:38,422'); seek(1658.0)">
              main with PGO. This time let's
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:27:42,702'); seek(1662.0)">
              actually perform a bunch of. No, let's perform benchmarks.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:27:46,094'); seek(1666.0)">
              Let's do some benchmarking here. So I'll
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:27:49,482'); seek(1669.0)">
              actually start the benchmarks here and
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:27:53,570'); seek(1673.0)">
              these benchmarks while these benchmarks are happening, let me tell you what's happening. The benchmarks
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:27:56,802'); seek(1676.0)">
              are running and they're basically firing a bunch of load against binary
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:28:00,394'); seek(1680.0)">
              with PGO and they're storing the
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:28:03,810'); seek(1683.0)">
              results. The benchmarks are storing the results inside this file called with
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:28:08,282'); seek(1688.0)">
              Pigo Txt. So right now we are doing this with PGO.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:28:11,954'); seek(1691.0)">
              Once these benchmarks are done, we will do these ones without PGO
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:28:16,258'); seek(1696.0)">
              and then we can use a tool called benchtat to compare
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:28:20,382'); seek(1700.0)">
              our results. Alright, so let's wait for a few
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:28:24,174'); seek(1704.0)">
              seconds and this should be done in anytime soon. And there's
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:28:27,990'); seek(1707.0)">
              nothing running in the second terminal that the way we generated the load
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:28:31,734'); seek(1711.0)">
              previously was only for the sake of generating profiles that said nothing else.
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:28:36,022'); seek(1716.0)">
              Right now we are doing benchmarking. So we are doing it in a different manner.
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:28:39,014'); seek(1719.0)">
              And as you can see the benchmarks are executed.
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:28:42,166'); seek(1722.0)">
              Now let's close this binary and run
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:28:45,680'); seek(1725.0)">
              the one without PGO. And as soon as we run here,
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:28:49,784'); seek(1729.0)">
              let me just name this file as nope.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:28:53,624'); seek(1733.0)">
              And again, this time as well we are running but this time across
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:28:57,912'); seek(1737.0)">
              these benchmarks we will snapshot these benchmarks in
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:29:01,448'); seek(1741.0)">
              a separate file called not nope Exe. And as I said,
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:29:05,240'); seek(1745.0)">
              we will separate out these files and then benchtat against them
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:29:09,040'); seek(1749.0)">
              to compare the real numbers that how things happen in runtime.
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:29:13,434'); seek(1753.0)">
              They might be slightly different from what I showed in the PPT because
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:29:17,202'); seek(1757.0)">
              again the load is kind of non deterministic
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:29:21,010'); seek(1761.0)">
              in that manner. But yeah, let's see how it, how it happens.
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:29:25,154'); seek(1765.0)">
              So it should be done anytime soon.
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:29:28,754'); seek(1768.0)">
              We have nothing here and the no PBo file is running here.
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:29:32,954'); seek(1772.0)">
              Yep, it's done. Now if you do bend status,
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:29:37,106'); seek(1777.0)">
              no pgo txt and with
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:29:40,754'); seek(1780.0)">
              pgo txt you can see what a beautiful
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:29:44,330'); seek(1784.0)">
              difference it is. The one with no PGO, your average time was
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:29:48,202'); seek(1788.0)">
              309 microseconds. With PGO it was 301. This is
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:29:52,210'); seek(1792.0)">
              even a higher significant difference,
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:29:54,794'); seek(1794.0)">
              even even a more significant difference with PGO,
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:29:58,362'); seek(1798.0)">
              which is 2.33 as compared to the slides. So let's go
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:30:01,650'); seek(1801.0)">
              back to the slides and just make some concluding notes.
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:30:06,234'); seek(1806.0)">
              So that's pretty much it. I guess we learned quite a lot and see
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:30:09,482'); seek(1809.0)">
              how profile guided optimization can actually benefit us a lot. So we
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:30:12,890'); seek(1812.0)">
              explored the process of compilation, how compilation can be made more
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:30:16,522'); seek(1816.0)">
              effective with feedback driven way by feeding it some
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:30:19,962'); seek(1819.0)">
              runtime data and our sampling profiles based. Profile guided optimization
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:30:24,578'); seek(1824.0)">
              works even more effectively in our favor and
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:30:28,010'); seek(1828.0)">
              we actually got a very practical perspective by
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:30:31,448'); seek(1831.0)">
              getting our hands dirty by playing with profile guided optimization
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:30:35,048'); seek(1835.0)">
              with a server like code resembling a real life scenario.
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:30:39,024'); seek(1839.0)">
              And you can find all of these slides and all of the associated content
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:30:42,120'); seek(1842.0)">
              at the link below in my GitHub under my GitHub profile and
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:30:46,824'); seek(1846.0)">
              let me share the references. So there's a bunch of references I used
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:30:50,904'); seek(1850.0)">
              to learn about this topic and to inherit the content of these slides.
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:30:54,688'); seek(1854.0)">
              Of course, this was just meant like I just sat on the shoulders
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:30:58,412'); seek(1858.0)">
              of these giants who implemented all of this cool stuff.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:31:01,884'); seek(1861.0)">
              Finally, feel free to connect with me. All of my handles are
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:31:05,580'); seek(1865.0)">
              given here. And that's all folks. Thanks a
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:31:09,276'); seek(1869.0)">
              lot for your time. I appreciate you giving me your time and
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:31:13,324'); seek(1873.0)">
              attention for this, for attending this talk, and feel absolutely
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:31:17,412'); seek(1877.0)">
              free to raise any questions or reach out to me whenever. Hope you have a
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:31:20,756'); seek(1880.0)">
              great day.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Yashvardhan%20Kukreja%20-%20Conf42%20Golang%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Yashvardhan%20Kukreja%20-%20Conf42%20Golang%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #881E4B;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/golang2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #881E4B;">
                <i class="fe fe-grid me-2"></i>
                See all 21 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Yashvardhan%20Kukreja_golang.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Yashvardhan Kukreja
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Software Engineer (SRE) @ Red Hat
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/yashvardhan-kukreja/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Yashvardhan Kukreja's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@yashkukreja98" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Yashvardhan Kukreja's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @yashkukreja98"
                  data-url="https://www.conf42.com/golang2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/golang2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Golang"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://sreday.com/2024-amsterdam/">
                  SREday Amsterdam 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>