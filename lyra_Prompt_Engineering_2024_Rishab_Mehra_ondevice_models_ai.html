<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: The Disruptive Potential of On-Device Large Language Models</title>
    <meta name="description" content="Master your prompt-fu!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Rishab%20Mehra_prompt.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="The Disruptive Potential of On-Device Large Language Models | Conf42"/>
    <meta property="og:description" content="Discover the game-changing potential of on-device large language models! Learn how innovations from Apple, Mistral AI, and Google Gemma 2B are reshaping AI, optimizing performance, reducing costs, and enhancing privacy. Imagine a world with human-like conversationsâ€”right on your device!"/>
    <meta property="og:url" content="https://conf42.com/Prompt_Engineering_2024_Rishab_Mehra_ondevice_models_ai"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/DEVSECOPS2024_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        DevSecOps 2024
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2024-12-05
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/devsecops2024" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="./support">
                            Support us
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Subscribe for FREE
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #749BC2;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Prompt Engineering 2024 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Master your prompt-fu!
 -->
              <script>
                const event_date = new Date("2024-11-14T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-11-14T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "PIqfZwQHjB8"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrAVCqb1r_qSxiIxgr09QRvk" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone, I\u0027m Rishabh Mehra and today I\u0027ll be talking about on device large", "timestamp": "00:00:00,049", "timestamp_s": 0.0}, {"text": "language models, which I believe is a path to safer and more efficient AI systems.", "timestamp": "00:00:05,760", "timestamp_s": 5.0}, {"text": "Let me start by describing who I am and why I\u0027m talking about this topic.", "timestamp": "00:00:12,400", "timestamp_s": 12.0}, {"text": "So I studied computer science at Stanford where I was researching on computer", "timestamp": "00:00:17,890", "timestamp_s": 17.0}, {"text": "vision systems under Professor Fei Li.", "timestamp": "00:00:22,660", "timestamp_s": 22.0}, {"text": "We worked on publishing papers in MLHC and NeurIPS.", "timestamp": "00:00:25,809", "timestamp_s": 25.0}, {"text": "in the computer vision and healthcare field.", "timestamp": "00:00:29,550", "timestamp_s": 29.0}, {"text": "From there, I went to Apple, where I worked on device machine learning models", "timestamp": "00:00:32,000", "timestamp_s": 32.0}, {"text": "to make iOS smarter as a system, as well as prototyping efforts for Apple", "timestamp": "00:00:36,950", "timestamp_s": 36.0}, {"text": "Intelligence, which was a large language modeling system Apple launched recently.", "timestamp": "00:00:41,700", "timestamp_s": 41.0}, {"text": "Now I\u0027m working on Pinnacle, which is a startup in the intersection", "timestamp": "00:00:47,410", "timestamp_s": 47.0}, {"text": "of all three of those fields.", "timestamp": "00:00:51,140", "timestamp_s": 51.0}, {"text": "Also, as a fun fact, I have, an interest in rock climbing and that\u0027s", "timestamp": "00:00:53,060", "timestamp_s": 53.0}, {"text": "why it shows up in the pie chart there.", "timestamp": "00:00:56,760", "timestamp_s": 56.0}, {"text": "Alright, now let\u0027s look at the table of contents for today and what we\u0027ll cover.", "timestamp": "00:00:58,970", "timestamp_s": 58.0}, {"text": "We\u0027ll start with why on device LLMs matter, why we\u0027re talking about these.", "timestamp": "00:01:03,080", "timestamp_s": 63.0}, {"text": "We\u0027ll talk about state of the art, what\u0027s out there, and we\u0027ll see", "timestamp": "00:01:08,260", "timestamp_s": 68.0}, {"text": "some examples of how they perform.", "timestamp": "00:01:11,620", "timestamp_s": 71.0}, {"text": "We\u0027ll go through some real world use cases which are already deployed.", "timestamp": "00:01:13,960", "timestamp_s": 73.0}, {"text": "Then we\u0027ll talk about what MVP is and what the path to this", "timestamp": "00:01:18,320", "timestamp_s": 78.0}, {"text": "MVP would be in my opinion.", "timestamp": "00:01:22,290", "timestamp_s": 82.0}, {"text": "And we\u0027ll conclude with where I see these models in the next five years", "timestamp": "00:01:24,770", "timestamp_s": 84.0}, {"text": "and the applications they\u0027ll enable.", "timestamp": "00:01:29,000", "timestamp_s": 89.0}, {"text": "All right, let\u0027s start with the first topic, why on device LLMs matter.", "timestamp": "00:01:31,240", "timestamp_s": 91.0}, {"text": "Let\u0027s start by first understanding what large language models are.", "timestamp": "00:01:36,160", "timestamp_s": 96.0}, {"text": "The way I like to define large language models, of course at a very high level,", "timestamp": "00:01:39,760", "timestamp_s": 99.0}, {"text": "is through a three word game I used to play with my sister when I was young.", "timestamp": "00:01:44,150", "timestamp_s": 104.0}, {"text": "I would say three words, my sister would follow up with the three most", "timestamp": "00:01:48,200", "timestamp_s": 108.0}, {"text": "likely words she think would be best, and then I would say three words, and", "timestamp": "00:01:52,570", "timestamp_s": 112.0}, {"text": "so on until we formed a full story.", "timestamp": "00:01:56,800", "timestamp_s": 116.0}, {"text": "Interestingly, large language models are trying to do the same thing.", "timestamp": "00:01:59,460", "timestamp_s": 119.0}, {"text": "You give them a bunch of words, And they reply with a bunch of words", "timestamp": "00:02:03,100", "timestamp_s": 123.0}, {"text": "which they think make the most logical sense, given what you said.", "timestamp": "00:02:06,825", "timestamp_s": 126.0}, {"text": "Of course, this is a very high level definition, but that\u0027s the", "timestamp": "00:02:10,715", "timestamp_s": 130.0}, {"text": "task they\u0027re trying to perform.", "timestamp": "00:02:13,905", "timestamp_s": 133.0}, {"text": "Now let\u0027s talk about three major problems I believe there", "timestamp": "00:02:15,815", "timestamp_s": 135.0}, {"text": "are with large language models.", "timestamp": "00:02:18,735", "timestamp_s": 138.0}, {"text": "The first is privacy evasion, invasion.", "timestamp": "00:02:20,865", "timestamp_s": 140.0}, {"text": "Privacy invasion occurs because the types of applications that use large", "timestamp": "00:02:24,125", "timestamp_s": 144.0}, {"text": "language models need personal data.", "timestamp": "00:02:28,375", "timestamp_s": 148.0}, {"text": "They\u0027re often you telling it information or providing it", "timestamp": "00:02:31,695", "timestamp_s": 151.0}, {"text": "information through your computer screen, et cetera, which they process.", "timestamp": "00:02:34,875", "timestamp_s": 154.0}, {"text": "This raises major privacy concerns because you might be sharing your data", "timestamp": "00:02:38,805", "timestamp_s": 158.0}, {"text": "with an LLM provider like OpenAI, but also an intermediary like a startup.", "timestamp": "00:02:43,585", "timestamp_s": 163.0}, {"text": "So you need to trust both those companies.", "timestamp": "00:02:48,665", "timestamp_s": 168.0}, {"text": "Large language models also have a massive carbon footprint.", "timestamp": "00:02:51,065", "timestamp_s": 171.0}, {"text": "For example, just training GPT 4 in an article was shown to have emissions", "timestamp": "00:02:54,945", "timestamp_s": 174.0}, {"text": "equivalent to driving 18 million miles in a gasoline car and a single", "timestamp": "00:03:01,205", "timestamp_s": 181.0}, {"text": "inference call to GPT 4, again in an article, was shown to be equivalent of", "timestamp": "00:03:05,955", "timestamp_s": 185.0}, {"text": "charging a mobile phone 60 times over.", "timestamp": "00:03:11,015", "timestamp_s": 191.0}, {"text": "Then also another problem with large language models is", "timestamp": "00:03:13,885", "timestamp_s": 193.0}, {"text": "their ability to mimic humans.", "timestamp": "00:03:17,675", "timestamp_s": 197.0}, {"text": "This is because large language models are essentially producing", "timestamp": "00:03:20,245", "timestamp_s": 200.0}, {"text": "language similar to humans and this leads to problems such as deepfakes.", "timestamp": "00:03:23,785", "timestamp_s": 203.0}, {"text": "The internet is flooded with deepfakes, but also the possibility", "timestamp": "00:03:29,095", "timestamp_s": 209.0}, {"text": "of fraud increasing a lot.", "timestamp": "00:03:32,905", "timestamp_s": 212.0}, {"text": "For example, imagine getting a call in the voice of your mother and your mother tells", "timestamp": "00:03:35,185", "timestamp_s": 215.0}, {"text": "you she\u0027s hurt and she needs some money.", "timestamp": "00:03:39,425", "timestamp_s": 219.0}, {"text": "You\u0027ll probably transfer the money, but later you\u0027ll realize that this", "timestamp": "00:03:41,765", "timestamp_s": 221.0}, {"text": "was just a large language model talking in your mother\u0027s voice.", "timestamp": "00:03:46,115", "timestamp_s": 226.0}, {"text": "This is a very big concern, but we won\u0027t talk about this today", "timestamp": "00:03:50,435", "timestamp_s": 230.0}, {"text": "because this is a whole other talk.", "timestamp": "00:03:53,865", "timestamp_s": 233.0}, {"text": "We\u0027ll cover the first and the second points today.", "timestamp": "00:03:55,745", "timestamp_s": 235.0}, {"text": "So moving these large language models from the internet to on", "timestamp": "00:03:58,515", "timestamp_s": 238.0}, {"text": "device solves the first two problems.", "timestamp": "00:04:02,405", "timestamp_s": 242.0}, {"text": "This is because on device models are off the grid.", "timestamp": "00:04:05,825", "timestamp_s": 245.0}, {"text": "They don\u0027t need internet.", "timestamp": "00:04:09,335", "timestamp_s": 249.0}, {"text": "They don\u0027t need any external connection.", "timestamp": "00:04:10,755", "timestamp_s": 250.0}, {"text": "There is no middleman.", "timestamp": "00:04:13,185", "timestamp_s": 253.0}, {"text": "Everything is on your device.", "timestamp": "00:04:14,225", "timestamp_s": 254.0}, {"text": "So there\u0027s no privacy risk anymore.", "timestamp": "00:04:15,955", "timestamp_s": 255.0}, {"text": "And as a result of these models having to run on device, they\u0027re automatically", "timestamp": "00:04:18,255", "timestamp_s": 258.0}, {"text": "smaller, and smaller means that they\u0027re greener, and they essentially have,", "timestamp": "00:04:23,235", "timestamp_s": 263.0}, {"text": "will have a lesser carbon footprint.", "timestamp": "00:04:28,165", "timestamp_s": 268.0}, {"text": "And this is again, just by design that you have to make them", "timestamp": "00:04:31,125", "timestamp_s": 271.0}, {"text": "smaller to run on the computer.", "timestamp": "00:04:34,305", "timestamp_s": 274.0}, {"text": "All right, now let\u0027s talk about state of the art LLMs.", "timestamp": "00:04:36,605", "timestamp_s": 276.0}, {"text": "Where is this technology today?", "timestamp": "00:04:40,815", "timestamp_s": 280.0}, {"text": "What does it look like?", "timestamp": "00:04:42,345", "timestamp_s": 282.0}, {"text": "And we\u0027ll do this through two demos.", "timestamp": "00:04:43,840", "timestamp_s": 283.0}, {"text": "So for the first demo, I\u0027ll give the following prompt to the LLM.", "timestamp": "00:04:46,050", "timestamp_s": 286.0}, {"text": "Hello, I\u0027ll be giving a presentation with the topic on device LLMs, a path to", "timestamp": "00:04:50,160", "timestamp_s": 290.0}, {"text": "a safer and more efficient AI systems.", "timestamp": "00:04:55,290", "timestamp_s": 295.0}, {"text": "Can you give me a one line opener, make it engaging and thought provoking?", "timestamp": "00:04:58,620", "timestamp_s": 298.0}, {"text": "So I take this prompt and I will Copy the prompt and then I\u0027ll use", "timestamp": "00:05:03,430", "timestamp_s": 303.0}, {"text": "OLAMA, which is a way to essentially run large language models on device.", "timestamp": "00:05:09,575", "timestamp_s": 309.0}, {"text": "The model I\u0027m running is LAMA 3.", "timestamp": "00:05:14,895", "timestamp_s": 314.0}, {"text": "1.", "timestamp": "00:05:17,585", "timestamp_s": 317.0}, {"text": "This is a model by Meta and it has 8 billion parameters.", "timestamp": "00:05:17,585", "timestamp_s": 317.0}, {"text": "This is now loading into the memory of my computer.", "timestamp": "00:05:21,835", "timestamp_s": 321.0}, {"text": "I paste the prompt and run it and it gives me a reasonable response.", "timestamp": "00:05:24,855", "timestamp_s": 324.0}, {"text": "Let\u0027s read the first one.", "timestamp": "00:05:30,095", "timestamp_s": 330.0}, {"text": "As we increasingly rely on AI, Can we afford not to rethink the way", "timestamp": "00:05:31,945", "timestamp_s": 331.0}, {"text": "we build models from edges of our networks to edges of our devices?", "timestamp": "00:05:37,000", "timestamp_s": 337.0}, {"text": "Makes sense.", "timestamp": "00:05:42,380", "timestamp_s": 342.0}, {"text": "It\u0027s nice.", "timestamp": "00:05:43,080", "timestamp_s": 343.0}, {"text": "It\u0027s not perfect, but it\u0027s a good start.", "timestamp": "00:05:43,690", "timestamp_s": 343.0}, {"text": "All right.", "timestamp": "00:05:46,840", "timestamp_s": 346.0}, {"text": "Now just to get a baseline, sorry, before we get the baseline, we try", "timestamp": "00:05:47,060", "timestamp_s": 347.0}, {"text": "to run this on Lama billion, which is a much bigger model by Facebook.", "timestamp": "00:05:50,740", "timestamp_s": 350.0}, {"text": "And this is now loading into memory.", "timestamp": "00:05:56,220", "timestamp_s": 356.0}, {"text": "But as I\u0027ll soon realize this doesn\u0027t actually load into", "timestamp": "00:05:59,040", "timestamp_s": 359.0}, {"text": "the memory of my computer.", "timestamp": "00:06:01,800", "timestamp_s": 361.0}, {"text": "I open activity monitor and I see this model is taking tons of memory.", "timestamp": "00:06:03,435", "timestamp_s": 363.0}, {"text": "It\u0027s already taking 32 gigs, which is more than what this computer has.", "timestamp": "00:06:09,065", "timestamp_s": 369.0}, {"text": "So this model essentially cannot run on my device.", "timestamp": "00:06:13,625", "timestamp_s": 373.0}, {"text": "so we\u0027ve seen that the model size on device is seven to 10", "timestamp": "00:06:17,555", "timestamp_s": 377.0}, {"text": "billion, somewhere around there.", "timestamp": "00:06:21,245", "timestamp_s": 381.0}, {"text": "now just to get a baseline, we run the same prompt in GPD 4.", "timestamp": "00:06:23,294", "timestamp_s": 383.0}, {"text": "0.", "timestamp": "00:06:27,025", "timestamp_s": 387.0}, {"text": "So I paste the prompt, run it.", "timestamp": "00:06:28,364", "timestamp_s": 388.0}, {"text": "And I get the response, which is, imagine smartphone is not just smart,", "timestamp": "00:06:31,460", "timestamp_s": 391.0}, {"text": "but a powerhouse of intelligent privacy.", "timestamp": "00:06:37,140", "timestamp_s": 397.0}, {"text": "Welcome to the new frontier with on device LLMs.", "timestamp": "00:06:39,960", "timestamp_s": 399.0}, {"text": "So perfect opening, exactly what I wanted.", "timestamp": "00:06:43,420", "timestamp_s": 403.0}, {"text": "And that\u0027s what we have come to expect from GPD 4.", "timestamp": "00:06:46,389", "timestamp_s": 406.0}, {"text": "0.", "timestamp": "00:06:48,840", "timestamp_s": 408.0}, {"text": "But of course, this is still running in the cloud.", "timestamp": "00:06:50,090", "timestamp_s": 410.0}, {"text": "And as we saw, Lama 8, we produced a response, which made sense, but", "timestamp": "00:06:52,580", "timestamp_s": 412.0}, {"text": "it\u0027s not at the level of GPD 4.", "timestamp": "00:06:56,689", "timestamp_s": 416.0}, {"text": "0 yet.", "timestamp": "00:06:58,919", "timestamp_s": 418.0}, {"text": "All right, now for the second test, we\u0027ll do a coding challenge where", "timestamp": "00:06:59,730", "timestamp_s": 419.0}, {"text": "we\u0027ll get these models to create Minesweeper, a popular game, and", "timestamp": "00:07:03,230", "timestamp_s": 423.0}, {"text": "we\u0027ll see how the different models do.", "timestamp": "00:07:07,480", "timestamp_s": 427.0}, {"text": "So let\u0027s start by copying this prompt I created to write, make", "timestamp": "00:07:10,280", "timestamp_s": 430.0}, {"text": "the models write Minesweeper.", "timestamp": "00:07:14,769", "timestamp_s": 434.0}, {"text": "And we\u0027ll again start with Llama8B, the tiny model by Meta", "timestamp": "00:07:16,439", "timestamp_s": 436.0}, {"text": "that runs fully on my device.", "timestamp": "00:07:21,270", "timestamp_s": 441.0}, {"text": "As you can see, it produces code which makes sense.", "timestamp": "00:07:23,200", "timestamp_s": 443.0}, {"text": "It\u0027s calling the init function, print board, create mines,", "timestamp": "00:07:25,530", "timestamp_s": 445.0}, {"text": "count adjacent mines, reveal.", "timestamp": "00:07:29,760", "timestamp_s": 449.0}, {"text": "All of this makes sense for a typical minesweeper game.", "timestamp": "00:07:31,429", "timestamp_s": 451.0}, {"text": "So now, it\u0027s, Finishing producing this code, it\u0027s written the play", "timestamp": "00:07:34,570", "timestamp_s": 454.0}, {"text": "function, which is a while loop to play this game indefinitely", "timestamp": "00:07:38,869", "timestamp_s": 458.0}, {"text": "until you hit a mine, of course.", "timestamp": "00:07:41,769", "timestamp_s": 461.0}, {"text": "now I can go ahead and copy the code.", "timestamp": "00:07:43,839", "timestamp_s": 463.0}, {"text": "I\u0027ll paste the code into a Python file called minesweeper llama8b.", "timestamp": "00:07:46,479", "timestamp_s": 466.0}, {"text": "py.", "timestamp": "00:07:52,170", "timestamp_s": 472.0}, {"text": "And then I\u0027ll go ahead and run the code.", "timestamp": "00:07:56,089", "timestamp_s": 476.0}, {"text": "Unfortunately for Llama, it doesn\u0027t run.", "timestamp": "00:07:58,944", "timestamp_s": 478.0}, {"text": "it only took me 15 to 20 minutes to correct it so it wasn\u0027t too off and", "timestamp": "00:08:02,014", "timestamp_s": 482.0}, {"text": "other iterations produce slightly better code which sometimes even compiled.", "timestamp": "00:08:05,644", "timestamp_s": 485.0}, {"text": "okay now to get a baseline let\u0027s go to GPT 4.", "timestamp": "00:08:10,054", "timestamp_s": 490.0}, {"text": "0, paste the prompt and as you can see it very quickly generates the code.", "timestamp": "00:08:12,904", "timestamp_s": 492.0}, {"text": "Of course this is again running on the server and we expect this", "timestamp": "00:08:17,894", "timestamp_s": 497.0}, {"text": "to be great but just to get a baseline let\u0027s see what it does.", "timestamp": "00:08:20,554", "timestamp_s": 500.0}, {"text": "The code looks similar to what was produced by Lama, but of", "timestamp": "00:08:24,424", "timestamp_s": 504.0}, {"text": "course, as we know, the quality is expected to be a lot better.", "timestamp": "00:08:28,394", "timestamp_s": 508.0}, {"text": "So I do the same thing.", "timestamp": "00:08:33,164", "timestamp_s": 513.0}, {"text": "I copy the code, go back to the terminal, create a file called minesweeper gpt40.", "timestamp": "00:08:34,174", "timestamp_s": 514.0}, {"text": "py, paste the code, and now I run it.", "timestamp": "00:08:40,644", "timestamp_s": 520.0}, {"text": "And here we get a perfectly working version of Minesweeper.", "timestamp": "00:08:45,084", "timestamp_s": 525.0}, {"text": "I type 3 4, hit a mine, and lose in the first turn.", "timestamp": "00:08:47,834", "timestamp_s": 527.0}, {"text": "So let\u0027s go ahead and play once more.", "timestamp": "00:08:51,584", "timestamp_s": 531.0}, {"text": "And here I can essentially run through the entire game of Minesweeper where I\u0027m going", "timestamp": "00:08:54,044", "timestamp_s": 534.0}, {"text": "through different options I\u0027ve chosen.", "timestamp": "00:09:00,274", "timestamp_s": 540.0}, {"text": "This is fast forwarded and then eventually I write 3 3.", "timestamp": "00:09:03,454", "timestamp_s": 543.0}, {"text": "hit a mine and the game ends.", "timestamp": "00:09:07,749", "timestamp_s": 547.0}, {"text": "All right, now the interesting part.", "timestamp": "00:09:09,929", "timestamp_s": 549.0}, {"text": "We\u0027re going to paste the same prompt, but in a very different model.", "timestamp": "00:09:12,029", "timestamp_s": 552.0}, {"text": "This model is called CodeQuin.", "timestamp": "00:09:16,619", "timestamp_s": 556.0}, {"text": "This is by the Alibaba group in China.", "timestamp": "00:09:19,069", "timestamp_s": 559.0}, {"text": "this model is only a 7 billion parameter model.", "timestamp": "00:09:22,719", "timestamp_s": 562.0}, {"text": "So it\u0027s a much smaller model than even, or not much smaller, but a smaller model", "timestamp": "00:09:26,329", "timestamp_s": 566.0}, {"text": "than the Lama model we saw earlier.", "timestamp": "00:09:30,929", "timestamp_s": 570.0}, {"text": "So it\u0027s able to run fully on device.", "timestamp": "00:09:33,859", "timestamp_s": 573.0}, {"text": "But the interesting thing about this model is it\u0027s customized and", "timestamp": "00:09:36,239", "timestamp_s": 576.0}, {"text": "tuned to do well on coding tasks.", "timestamp": "00:09:40,169", "timestamp_s": 580.0}, {"text": "So its strength is coding and it outperforms LLAMA as we\u0027ll see soon.", "timestamp": "00:09:42,189", "timestamp_s": 582.0}, {"text": "So right now it\u0027s writing code, it creates the board, counts the", "timestamp": "00:09:48,039", "timestamp_s": 588.0}, {"text": "mines, reveals a similar structure to what LLAMA was producing.", "timestamp": "00:09:51,899", "timestamp_s": 591.0}, {"text": "It\u0027s a bit slower running on memory, even though it\u0027s a smaller parameter model.", "timestamp": "00:09:56,749", "timestamp_s": 596.0}, {"text": "Presumably it\u0027s not as optimized as Llama for MacBooks.", "timestamp": "00:10:01,119", "timestamp_s": 601.0}, {"text": "so I\u0027ll give it a second to just finish coding.", "timestamp": "00:10:05,699", "timestamp_s": 605.0}, {"text": "Almost there.", "timestamp": "00:10:08,479", "timestamp_s": 608.0}, {"text": "Alright.", "timestamp": "00:10:09,969", "timestamp_s": 609.0}, {"text": "There we go.", "timestamp": "00:10:11,079", "timestamp_s": 611.0}, {"text": "It\u0027s finished the setup.", "timestamp": "00:10:11,859", "timestamp_s": 611.0}, {"text": "code given some description.", "timestamp": "00:10:12,724", "timestamp_s": 612.0}, {"text": "I will go ahead, copy the code and follow the same procedure where I\u0027ll create,", "timestamp": "00:10:14,264", "timestamp_s": 614.0}, {"text": "I\u0027ll copy the code, create a Python file called Minesweeper code or q7b.", "timestamp": "00:10:20,954", "timestamp_s": 620.0}, {"text": "py, paste the code", "timestamp": "00:10:28,344", "timestamp_s": 628.0}, {"text": "and then I run it.", "timestamp": "00:10:30,064", "timestamp_s": 630.0}, {"text": "Interestingly, it shows me the locations of the mines visibly, which is a bit", "timestamp": "00:10:31,554", "timestamp_s": 631.0}, {"text": "weird, but it at least runs the code.", "timestamp": "00:10:36,104", "timestamp_s": 636.0}, {"text": "Then we write the location of a mine 03, but it doesn\u0027t end the game.", "timestamp": "00:10:39,024", "timestamp_s": 639.0}, {"text": "Then I write 00, which is not the location of the mine, and that, that works well.", "timestamp": "00:10:43,559", "timestamp_s": 643.0}, {"text": "So essentially it\u0027s playing Minesweeper correctly, except that it shows the", "timestamp": "00:10:49,189", "timestamp_s": 649.0}, {"text": "mines at the beginning and hitting the mines do not end the game.", "timestamp": "00:10:53,039", "timestamp_s": 653.0}, {"text": "I played around with this code after the demo and it took me less than five", "timestamp": "00:10:57,679", "timestamp_s": 657.0}, {"text": "minutes to make it fully functional.", "timestamp": "00:11:01,049", "timestamp_s": 661.0}, {"text": "So it was definitely higher quality than what Llama8B had created for me.", "timestamp": "00:11:03,209", "timestamp_s": 663.0}, {"text": "All right, we have looked at, these models qualitatively,", "timestamp": "00:11:08,439", "timestamp_s": 668.0}, {"text": "but let\u0027s look at some numbers.", "timestamp": "00:11:12,829", "timestamp_s": 672.0}, {"text": "sorry, the bottom right number is hidden because of my video, but it\u0027s 78.", "timestamp": "00:11:15,149", "timestamp_s": 675.0}, {"text": "So let\u0027s start from the top left, LAMA 3.", "timestamp": "00:11:19,939", "timestamp_s": 679.0}, {"text": "1, the 8 billion parameter model.", "timestamp": "00:11:22,779", "timestamp_s": 682.0}, {"text": "let\u0027s look at the chat reasoning task, so how well it performs", "timestamp": "00:11:26,329", "timestamp_s": 686.0}, {"text": "on chat tasks and coding tasks.", "timestamp": "00:11:28,869", "timestamp_s": 688.0}, {"text": "So for LAMA 3.", "timestamp": "00:11:31,979", "timestamp_s": 691.0}, {"text": "1, The 8 billion parameter model got a 73 on chat and about the same on coding.", "timestamp": "00:11:33,059", "timestamp_s": 693.0}, {"text": "The 70 billion got 86 on chats, an amazing score for such a small", "timestamp": "00:11:39,039", "timestamp_s": 699.0}, {"text": "model and the same on coding.", "timestamp": "00:11:43,399", "timestamp_s": 703.0}, {"text": "GPT 4.", "timestamp": "00:11:46,149", "timestamp_s": 706.0}, {"text": "0 got 86.", "timestamp": "00:11:47,164", "timestamp_s": 707.0}, {"text": "7 on chat and 87.", "timestamp": "00:11:48,459", "timestamp_s": 708.0}, {"text": "8 on coding.", "timestamp": "00:11:50,809", "timestamp_s": 710.0}, {"text": "So again, close to each other.", "timestamp": "00:11:52,319", "timestamp_s": 712.0}, {"text": "But CodeGrend, the tiny model by the Alibaba group, got", "timestamp": "00:11:54,659", "timestamp_s": 714.0}, {"text": "78 on the coding challenge.", "timestamp": "00:11:58,209", "timestamp_s": 718.0}, {"text": "So much higher than the 8 billion parameter Lama model like we saw earlier.", "timestamp": "00:12:00,559", "timestamp_s": 720.0}, {"text": "And this shows us the importance of having task specific models, which we\u0027ll talk", "timestamp": "00:12:04,939", "timestamp_s": 724.0}, {"text": "about more in the coming slides as well.", "timestamp": "00:12:11,099", "timestamp_s": 731.0}, {"text": "Next, let\u0027s explore the current real world use cases for on", "timestamp": "00:12:13,599", "timestamp_s": 733.0}, {"text": "device large language models.", "timestamp": "00:12:18,279", "timestamp_s": 738.0}, {"text": "So these are use cases already out there in the wild.", "timestamp": "00:12:20,489", "timestamp_s": 740.0}, {"text": "Here\u0027s a list of these use cases.", "timestamp": "00:12:23,489", "timestamp_s": 743.0}, {"text": "Some of these are large language models and some of these are related", "timestamp": "00:12:25,819", "timestamp_s": 745.0}, {"text": "technologies, which use similar tech to large language models.", "timestamp": "00:12:29,009", "timestamp_s": 749.0}, {"text": "So style transfer, this is already out there.", "timestamp": "00:12:33,429", "timestamp_s": 753.0}, {"text": "If you want to convert your email to a more friendly email", "timestamp": "00:12:36,029", "timestamp_s": 756.0}, {"text": "or a more professional email.", "timestamp": "00:12:39,749", "timestamp_s": 759.0}, {"text": "This is already possible today with large language models.", "timestamp": "00:12:41,449", "timestamp_s": 761.0}, {"text": "Speech to text.", "timestamp": "00:12:44,939", "timestamp_s": 764.0}, {"text": "Converting, your audio to text is a very important task and this actually works", "timestamp": "00:12:46,479", "timestamp_s": 766.0}, {"text": "really well fully on device today already.", "timestamp": "00:12:52,219", "timestamp_s": 772.0}, {"text": "probably almost as good as the server side model to be honest.", "timestamp": "00:12:55,919", "timestamp_s": 775.0}, {"text": "Summarization.", "timestamp": "00:12:59,739", "timestamp_s": 779.0}, {"text": "summarization does work on device today.", "timestamp": "00:13:01,399", "timestamp_s": 781.0}, {"text": "It\u0027s not as good as server side, but it\u0027s pretty good.", "timestamp": "00:13:04,429", "timestamp_s": 784.0}, {"text": "You can get 80 percent of the value you\u0027ll want out of it.", "timestamp": "00:13:06,839", "timestamp_s": 786.0}, {"text": "And finally, translation, same as summarization, works really well", "timestamp": "00:13:11,049", "timestamp_s": 791.0}, {"text": "on device, slightly worse than server side, but it\u0027s almost there.", "timestamp": "00:13:14,489", "timestamp_s": 794.0}, {"text": "Now let\u0027s actually look at some of these use cases in action through a demo.", "timestamp": "00:13:18,879", "timestamp_s": 798.0}, {"text": "All right, so let\u0027s go through the use cases which we saw before through", "timestamp": "00:13:23,299", "timestamp_s": 803.0}, {"text": "the eyes of Apple Intelligence.", "timestamp": "00:13:27,889", "timestamp_s": 807.0}, {"text": "Apple Intelligence is a suite of features Apple launched in iOS 18.", "timestamp": "00:13:29,989", "timestamp_s": 809.0}, {"text": "1.", "timestamp": "00:13:34,519", "timestamp_s": 814.0}, {"text": "Some of the features in this demo also came before that.", "timestamp": "00:13:35,019", "timestamp_s": 815.0}, {"text": "As you can see, the phone is on airplane mode, so there\u0027s no internet.", "timestamp": "00:13:38,759", "timestamp_s": 818.0}, {"text": "This is fully on device, not running a model on the server or anything.", "timestamp": "00:13:42,564", "timestamp_s": 822.0}, {"text": "So what I\u0027m doing here is I\u0027m in the notes app, and I\u0027m typing an email.", "timestamp": "00:13:46,674", "timestamp_s": 826.0}, {"text": "Hi Alex, reached this site.", "timestamp": "00:13:50,664", "timestamp_s": 830.0}, {"text": "Good to meet you, but I don\u0027t think now is the right time to collaborate.", "timestamp": "00:13:53,304", "timestamp_s": 833.0}, {"text": "While I love your vision question mark, the product", "timestamp": "00:13:57,394", "timestamp_s": 837.0}, {"text": "isn\u0027t the right fit, right now.", "timestamp": "00:14:00,054", "timestamp_s": 840.0}, {"text": "Hope to collaborate, someday.", "timestamp": "00:14:03,074", "timestamp_s": 843.0}, {"text": "RISH.", "timestamp": "00:14:06,424", "timestamp_s": 846.0}, {"text": "So not great English, but it\u0027s a start.", "timestamp": "00:14:07,284", "timestamp_s": 847.0}, {"text": "So I can go ahead and select this.", "timestamp": "00:14:10,174", "timestamp_s": 850.0}, {"text": "I can go to writing tools, which is one of the new features Apple", "timestamp": "00:14:12,354", "timestamp_s": 852.0}, {"text": "launched, and I can click on proofread.", "timestamp": "00:14:15,124", "timestamp_s": 855.0}, {"text": "So here Apple suggests me change a couple of words.", "timestamp": "00:14:18,214", "timestamp_s": 858.0}, {"text": "RISH comma this side, good to meet, and then some days", "timestamp": "00:14:22,264", "timestamp_s": 862.0}, {"text": "combined into a single word.", "timestamp": "00:14:26,684", "timestamp_s": 866.0}, {"text": "Not super helpful, but it\u0027s okay.", "timestamp": "00:14:28,629", "timestamp_s": 868.0}, {"text": "So let\u0027s try some other writing tool.", "timestamp": "00:14:31,439", "timestamp_s": 871.0}, {"text": "this time I select writing tools and I click rewrite.", "timestamp": "00:14:33,949", "timestamp_s": 873.0}, {"text": "So rewrite is now going to rewrite the message as expected.", "timestamp": "00:14:37,739", "timestamp_s": 877.0}, {"text": "So it says, Rish, it\u0027s great to meet you on this side.", "timestamp": "00:14:41,264", "timestamp_s": 881.0}, {"text": "So I think Rish is the other person instead of me, which is incorrect,", "timestamp": "00:14:44,264", "timestamp_s": 884.0}, {"text": "but let\u0027s look at the second sentence.", "timestamp": "00:14:47,744", "timestamp_s": 887.0}, {"text": "However, I don\u0027t believe this is the appropriate time to collaborate.", "timestamp": "00:14:49,654", "timestamp_s": 889.0}, {"text": "So this sentence and the rest of the email is a lot better than before.", "timestamp": "00:14:53,784", "timestamp_s": 893.0}, {"text": "So it\u0027s getting there.", "timestamp": "00:14:58,124", "timestamp_s": 898.0}, {"text": "It\u0027s actually improving it the way I want.", "timestamp": "00:14:58,904", "timestamp_s": 898.0}, {"text": "Let\u0027s just remove RISC to make the job simpler for the LLM.", "timestamp": "00:15:00,694", "timestamp_s": 900.0}, {"text": "And this time when I select the email, I\u0027ll go to writing tools, but", "timestamp": "00:15:04,624", "timestamp_s": 904.0}, {"text": "I\u0027ll just change it to a friendly tone, so style transfer this time.", "timestamp": "00:15:09,134", "timestamp_s": 909.0}, {"text": "And I get the response, Hi Alex.", "timestamp": "00:15:13,134", "timestamp_s": 913.0}, {"text": "It\u0027s great to meet you.", "timestamp": "00:15:15,124", "timestamp_s": 915.0}, {"text": "I think we\u0027re both on the same page about wanting to collaborate in the future.", "timestamp": "00:15:16,174", "timestamp_s": 916.0}, {"text": "I just don\u0027t think now is the right time to work together", "timestamp": "00:15:19,764", "timestamp_s": 919.0}, {"text": "on this particular project.", "timestamp": "00:15:22,484", "timestamp_s": 922.0}, {"text": "I hope we can still find a way to work with each other in the future.", "timestamp": "00:15:24,104", "timestamp_s": 924.0}, {"text": "So work flawlessly.", "timestamp": "00:15:27,234", "timestamp_s": 927.0}, {"text": "Next let\u0027s test dictation.", "timestamp": "00:15:28,994", "timestamp_s": 928.0}, {"text": "Dictation is essentially, speech to text.", "timestamp": "00:15:30,964", "timestamp_s": 930.0}, {"text": "I\u0027m seeing the sentence.", "timestamp": "00:15:33,864", "timestamp_s": 933.0}, {"text": "You can\u0027t hear it.", "timestamp": "00:15:34,864", "timestamp_s": 934.0}, {"text": "Hi, this is a test for seeing how the dictation works.", "timestamp": "00:15:36,524", "timestamp_s": 936.0}, {"text": "And it again worked flawlessly, fully on device, airplane mode is still on.", "timestamp": "00:15:39,614", "timestamp_s": 939.0}, {"text": "Next, let\u0027s try selecting this entire email.", "timestamp": "00:15:44,044", "timestamp_s": 944.0}, {"text": "And we\u0027ll try to create a summary of this email.", "timestamp": "00:15:47,424", "timestamp_s": 947.0}, {"text": "I don\u0027t want to go through this whole email.", "timestamp": "00:15:49,814", "timestamp_s": 949.0}, {"text": "So I\u0027ll go to writing tools and click on summary.", "timestamp": "00:15:52,344", "timestamp_s": 952.0}, {"text": "Unfortunately, that does not work without the internet.", "timestamp": "00:15:57,504", "timestamp_s": 957.0}, {"text": "So just to make sure it works with the internet, let\u0027s turn", "timestamp": "00:16:01,054", "timestamp_s": 961.0}, {"text": "on the internet, writing tools.", "timestamp": "00:16:03,574", "timestamp_s": 963.0}, {"text": "And I click on Summary.", "timestamp": "00:16:05,694", "timestamp_s": 965.0}, {"text": "And I got a summary telling me the events with Uber, Bloomberg, Citadel, etc.", "timestamp": "00:16:08,164", "timestamp_s": 968.0}, {"text": "And RSVPs are required for all these events.", "timestamp": "00:16:12,014", "timestamp_s": 972.0}, {"text": "So I got all the information I needed perfectly there.", "timestamp": "00:16:15,584", "timestamp_s": 975.0}, {"text": "Next, let\u0027s look at Spotlight.", "timestamp": "00:16:18,389", "timestamp_s": 978.0}, {"text": "Meet Alex at 10 a.", "timestamp": "00:16:19,839", "timestamp_s": 979.0}, {"text": "m.", "timestamp": "00:16:21,289", "timestamp_s": 981.0}, {"text": "Airplane mode is on again, and I got a meeting invite.", "timestamp": "00:16:21,539", "timestamp_s": 981.0}, {"text": "So there\u0027s NLP matching going on here, even if it may not be", "timestamp": "00:16:24,419", "timestamp_s": 984.0}, {"text": "fully large language models.", "timestamp": "00:16:28,509", "timestamp_s": 988.0}, {"text": "That\u0027s unknown.", "timestamp": "00:16:29,729", "timestamp_s": 989.0}, {"text": "Next, let\u0027s look at Translate.", "timestamp": "00:16:31,069", "timestamp_s": 991.0}, {"text": "So I try to translate hello.", "timestamp": "00:16:32,669", "timestamp_s": 992.0}, {"text": "It doesn\u0027t work without the internet.", "timestamp": "00:16:34,479", "timestamp_s": 994.0}, {"text": "So I turn on the internet and what I can do now is I can click the three dots and", "timestamp": "00:16:36,409", "timestamp_s": 996.0}, {"text": "click on download languages, scroll down, And I can simply download Spanish onto my,", "timestamp": "00:16:40,479", "timestamp_s": 1000.0}, {"text": "iPhone, so now it should work on device.", "timestamp": "00:16:47,799", "timestamp_s": 1007.0}, {"text": "It also downloads English.", "timestamp": "00:16:50,709", "timestamp_s": 1010.0}, {"text": "So now I go back into airplane mode and I write, can I get the churros?", "timestamp": "00:16:52,609", "timestamp_s": 1012.0}, {"text": "And it translates to Spanish without the internet because airplane mode is on.", "timestamp": "00:16:57,279", "timestamp_s": 1017.0}, {"text": "And presumably this is correct.", "timestamp": "00:17:01,314", "timestamp_s": 1021.0}, {"text": "And I write thank you and it says gracias, which I know is correct.", "timestamp": "00:17:03,444", "timestamp_s": 1023.0}, {"text": "Next I have all these lists of notifications.", "timestamp": "00:17:07,424", "timestamp_s": 1027.0}, {"text": "I can click show less airplane mode is on And I get a summary of the notifications.", "timestamp": "00:17:09,804", "timestamp_s": 1029.0}, {"text": "So summary in this context seems to work without the internet as well", "timestamp": "00:17:14,724", "timestamp_s": 1034.0}, {"text": "All right, that\u0027s just a rapid fire of a bunch of features in apple", "timestamp": "00:17:18,744", "timestamp_s": 1038.0}, {"text": "intelligence that work without the internet hence running fully on device", "timestamp": "00:17:22,804", "timestamp_s": 1042.0}, {"text": "Next, let\u0027s talk about the path to MVP.", "timestamp": "00:17:27,224", "timestamp_s": 1047.0}, {"text": "MVP, in my opinion, if we can reach GPD 4.", "timestamp": "00:17:30,984", "timestamp_s": 1050.0}, {"text": "0 level performance being the accuracy on device, that would be game changing.", "timestamp": "00:17:34,544", "timestamp_s": 1054.0}, {"text": "That would be a product that will actually be extremely valuable in everyday life.", "timestamp": "00:17:40,284", "timestamp_s": 1060.0}, {"text": "To reach this target, I believe we\u0027ll have to improve the hardware to be able", "timestamp": "00:17:46,374", "timestamp_s": 1066.0}, {"text": "to run 30 billion parameters on device.", "timestamp": "00:17:51,094", "timestamp_s": 1071.0}, {"text": "I think these 8 to 10 billion parameter models are still too small to have enough", "timestamp": "00:17:53,574", "timestamp_s": 1073.0}, {"text": "information, but we see promising results from 60, 70 billion parameter models.", "timestamp": "00:17:57,764", "timestamp_s": 1077.0}, {"text": "I\u0027m sure we can make them smaller, perhaps to the size of around 30 billion.", "timestamp": "00:18:02,954", "timestamp_s": 1082.0}, {"text": "Models need to be more specialized.", "timestamp": "00:18:08,924", "timestamp_s": 1088.0}, {"text": "So like we saw CodeGwent absolutely outperformed, Lama 3.", "timestamp": "00:18:11,104", "timestamp_s": 1091.0}, {"text": "18 billion, despite having similar number of parameters, just", "timestamp": "00:18:15,939", "timestamp_s": 1095.0}, {"text": "because it was coding specific.", "timestamp": "00:18:20,099", "timestamp_s": 1100.0}, {"text": "You can go one level deeper.", "timestamp": "00:18:22,299", "timestamp_s": 1102.0}, {"text": "You can make it Python specific instead of coding in general,", "timestamp": "00:18:23,759", "timestamp_s": 1103.0}, {"text": "and that might be even better.", "timestamp": "00:18:27,689", "timestamp_s": 1107.0}, {"text": "Next, we need to improve adapters.", "timestamp": "00:18:29,190", "timestamp_s": 1109.0}, {"text": "So adapters are things like LoRa adapters, which can.", "timestamp": "00:18:32,729", "timestamp_s": 1112.0}, {"text": "Which again, I can\u0027t go into details, that would be a whole other talk,", "timestamp": "00:18:36,759", "timestamp_s": 1116.0}, {"text": "but essentially can add a layer of specialization without having", "timestamp": "00:18:40,049", "timestamp_s": 1120.0}, {"text": "to recreate a whole new model.", "timestamp": "00:18:44,299", "timestamp_s": 1124.0}, {"text": "So let\u0027s say you have a Python specialized model, you can then use", "timestamp": "00:18:46,309", "timestamp_s": 1126.0}, {"text": "a LoRa adapter to make it a model for creating games using Python.", "timestamp": "00:18:50,579", "timestamp_s": 1130.0}, {"text": "So we\u0027ve become even more specialized using adapters.", "timestamp": "00:18:55,349", "timestamp_s": 1135.0}, {"text": "So in terms of software innovations, we already talked about, the second", "timestamp": "00:18:58,329", "timestamp_s": 1138.0}, {"text": "and third point, which is adapter mechanisms and specializations.", "timestamp": "00:19:03,589", "timestamp_s": 1143.0}, {"text": "But one more thing that needs to be innovated is enhanced", "timestamp": "00:19:07,509", "timestamp_s": 1147.0}, {"text": "compression techniques.", "timestamp": "00:19:11,079", "timestamp_s": 1151.0}, {"text": "so not only on the hardware side can we reduce the parameters, but", "timestamp": "00:19:12,819", "timestamp_s": 1152.0}, {"text": "we can start compressing these models into smaller and smaller", "timestamp": "00:19:16,749", "timestamp_s": 1156.0}, {"text": "models, pulling out the parameters.", "timestamp": "00:19:20,769", "timestamp_s": 1160.0}, {"text": "by using better compression techniques.", "timestamp": "00:19:23,485", "timestamp_s": 1163.0}, {"text": "And then on the hardware side, we need optimized processing units", "timestamp": "00:19:26,145", "timestamp_s": 1166.0}, {"text": "to run bigger and bigger models.", "timestamp": "00:19:30,755", "timestamp_s": 1170.0}, {"text": "Instead of 10 billion models, we should be able to run 30 billion or higher models.", "timestamp": "00:19:32,255", "timestamp_s": 1172.0}, {"text": "But also we need an enhanced memory architecture.", "timestamp": "00:19:37,085", "timestamp_s": 1177.0}, {"text": "This would be the RAM system.", "timestamp": "00:19:39,525", "timestamp_s": 1179.0}, {"text": "because these models need to be extremely quick, so they need a", "timestamp": "00:19:41,935", "timestamp_s": 1181.0}, {"text": "really solid memory architecture.", "timestamp": "00:19:45,775", "timestamp_s": 1185.0}, {"text": "I\u0027m not a hardware expert, so I can\u0027t go into details about these topics,", "timestamp": "00:19:48,445", "timestamp_s": 1188.0}, {"text": "but at a high level with, in what I\u0027ve discussed with hardware experts, these are", "timestamp": "00:19:52,085", "timestamp_s": 1192.0}, {"text": "the two main frontiers we need to push.", "timestamp": "00:19:57,305", "timestamp_s": 1197.0}, {"text": "All right, and then finally, let\u0027s say all of this happens.", "timestamp": "00:20:00,135", "timestamp_s": 1200.0}, {"text": "We have 30 billion parameters.", "timestamp": "00:20:03,055", "timestamp_s": 1203.0}, {"text": "These models are running fully on devices, specialized, have adapters.", "timestamp": "00:20:04,625", "timestamp_s": 1204.0}, {"text": "What\u0027s the outcome?", "timestamp": "00:20:08,645", "timestamp_s": 1208.0}, {"text": "Let\u0027s talk about the real world use cases these models will enable.", "timestamp": "00:20:10,025", "timestamp_s": 1210.0}, {"text": "So the first is augmented workflows.", "timestamp": "00:20:13,845", "timestamp_s": 1213.0}, {"text": "These models will become deeply integrated into everyone\u0027s work life.", "timestamp": "00:20:16,825", "timestamp_s": 1216.0}, {"text": "You\u0027ll be able to share your entire work context with these models because they\u0027re", "timestamp": "00:20:20,575", "timestamp_s": 1220.0}, {"text": "not sending any data to the server and they\u0027ll streamline every single task", "timestamp": "00:20:24,565", "timestamp_s": 1224.0}, {"text": "in your life, whether it\u0027s emails, data analysis, presentations, or even like", "timestamp": "00:20:29,105", "timestamp_s": 1229.0}, {"text": "filling out Excel sheets or writing code.", "timestamp": "00:20:33,995", "timestamp_s": 1233.0}, {"text": "The next is On Device Therapy.", "timestamp": "00:20:36,595", "timestamp_s": 1236.0}, {"text": "On Device Therapy will become better with these models because you\u0027ll be", "timestamp": "00:20:39,545", "timestamp_s": 1239.0}, {"text": "able to share more and you\u0027ll have advice available at all times, in", "timestamp": "00:20:42,785", "timestamp_s": 1242.0}, {"text": "your pocket or on your computer.", "timestamp": "00:20:47,310", "timestamp_s": 1247.0}, {"text": "Legal assistance.", "timestamp": "00:20:49,810", "timestamp_s": 1249.0}, {"text": "This will help both lawyers, because they\u0027ll be able to share", "timestamp": "00:20:51,530", "timestamp_s": 1251.0}, {"text": "client data with these models, at any time to get information.", "timestamp": "00:20:54,890", "timestamp_s": 1254.0}, {"text": "And they can trust these models because they\u0027re running fully on device,", "timestamp": "00:20:59,520", "timestamp_s": 1259.0}, {"text": "but they can also help the layman to get legal assistance quickly,", "timestamp": "00:21:02,940", "timestamp_s": 1262.0}, {"text": "without having to engage a lawyer.", "timestamp": "00:21:07,660", "timestamp_s": 1267.0}, {"text": "And again, they can trust this model because it\u0027s fully on their device.", "timestamp": "00:21:09,200", "timestamp_s": 1269.0}, {"text": "So they can have that same, lawyer client, relationship.", "timestamp": "00:21:12,910", "timestamp_s": 1272.0}, {"text": "with this model where they know the model will not breach their trust.", "timestamp": "00:21:17,645", "timestamp_s": 1277.0}, {"text": "And then finally medical diagnosis.", "timestamp": "00:21:22,285", "timestamp_s": 1282.0}, {"text": "Medical diagnosis will again be empowered by these models because you\u0027ll again", "timestamp": "00:21:25,205", "timestamp_s": 1285.0}, {"text": "be more willing to share your personal data and you\u0027ll be willing to share", "timestamp": "00:21:30,195", "timestamp_s": 1290.0}, {"text": "your entire medical history with these models because they\u0027re fully on your", "timestamp": "00:21:33,245", "timestamp_s": 1293.0}, {"text": "device so you don\u0027t have to worry about where your data goes and you can get", "timestamp": "00:21:36,765", "timestamp_s": 1296.0}, {"text": "really accessible healthcare diagnosis.", "timestamp": "00:21:40,625", "timestamp_s": 1300.0}, {"text": "and potentially even treatment using these models.", "timestamp": "00:21:44,265", "timestamp_s": 1304.0}, {"text": "That\u0027s all I have for today.", "timestamp": "00:21:48,235", "timestamp_s": 1308.0}, {"text": "Thank you for coming to the talk.", "timestamp": "00:21:49,805", "timestamp_s": 1309.0}, {"text": "If you have any questions or follow ups, please feel free to", "timestamp": "00:21:52,095", "timestamp_s": 1312.0}, {"text": "email me at rish at pinnacle.", "timestamp": "00:21:56,045", "timestamp_s": 1316.0}, {"text": "co.", "timestamp": "00:21:58,655", "timestamp_s": 1318.0}, {"text": "Thank you so much.", "timestamp": "00:21:59,675", "timestamp_s": 1319.0}, {"text": "Bye.", "timestamp": "00:22:01,275", "timestamp_s": 1321.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'PIqfZwQHjB8',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              The Disruptive Potential of On-Device Large Language Models
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Discover the game-changing potential of on-device large language models! Learn how innovations from Apple, Mistral AI, and Google Gemma 2B are reshaping AI, optimizing performance, reducing costs, and enhancing privacy. Imagine a world with human-like conversationsâ€”right on your device!</p>
<!-- End Text -->
          </div>

          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/prompt2024_Rishab_Mehra.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:00,049'); seek(0.0)">
              Hi everyone, I'm Rishabh Mehra and today I'll be talking about on device large
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:05,760'); seek(5.0)">
              language models, which I believe is a path to safer and more efficient AI systems.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:12,400'); seek(12.0)">
              Let me start by describing who I am and why I'm talking about this topic.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:17,890'); seek(17.0)">
              So I studied computer science at Stanford where I was researching on computer
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:22,660'); seek(22.0)">
              vision systems under Professor Fei Li.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:25,809'); seek(25.0)">
              We worked on publishing papers in MLHC and NeurIPS.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:29,550'); seek(29.0)">
              in the computer vision and healthcare field.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:32,000'); seek(32.0)">
              From there, I went to Apple, where I worked on device machine learning models
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:36,950'); seek(36.0)">
              to make iOS smarter as a system, as well as prototyping efforts for Apple
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:41,700'); seek(41.0)">
              Intelligence, which was a large language modeling system Apple launched recently.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:47,410'); seek(47.0)">
              Now I'm working on Pinnacle, which is a startup in the intersection
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:51,140'); seek(51.0)">
              of all three of those fields.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:53,060'); seek(53.0)">
              Also, as a fun fact, I have, an interest in rock climbing and that's
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:56,760'); seek(56.0)">
              why it shows up in the pie chart there.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:58,970'); seek(58.0)">
              Alright, now let's look at the table of contents for today and what we'll cover.
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:03,080'); seek(63.0)">
              We'll start with why on device LLMs matter, why we're talking about these.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:08,260'); seek(68.0)">
              We'll talk about state of the art, what's out there, and we'll see
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:11,620'); seek(71.0)">
              some examples of how they perform.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:13,960'); seek(73.0)">
              We'll go through some real world use cases which are already deployed.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:18,320'); seek(78.0)">
              Then we'll talk about what MVP is and what the path to this
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:22,290'); seek(82.0)">
              MVP would be in my opinion.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:24,770'); seek(84.0)">
              And we'll conclude with where I see these models in the next five years
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:29,000'); seek(89.0)">
              and the applications they'll enable.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:31,240'); seek(91.0)">
              All right, let's start with the first topic, why on device LLMs matter.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:36,160'); seek(96.0)">
              Let's start by first understanding what large language models are.
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:39,760'); seek(99.0)">
              The way I like to define large language models, of course at a very high level,
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:44,150'); seek(104.0)">
              is through a three word game I used to play with my sister when I was young.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:48,200'); seek(108.0)">
              I would say three words, my sister would follow up with the three most
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:52,570'); seek(112.0)">
              likely words she think would be best, and then I would say three words, and
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:56,800'); seek(116.0)">
              so on until we formed a full story.
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:59,460'); seek(119.0)">
              Interestingly, large language models are trying to do the same thing.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:03,100'); seek(123.0)">
              You give them a bunch of words, And they reply with a bunch of words
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:06,825'); seek(126.0)">
              which they think make the most logical sense, given what you said.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:10,715'); seek(130.0)">
              Of course, this is a very high level definition, but that's the
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:13,905'); seek(133.0)">
              task they're trying to perform.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:15,815'); seek(135.0)">
              Now let's talk about three major problems I believe there
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:18,735'); seek(138.0)">
              are with large language models.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:20,865'); seek(140.0)">
              The first is privacy evasion, invasion.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:24,125'); seek(144.0)">
              Privacy invasion occurs because the types of applications that use large
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:28,375'); seek(148.0)">
              language models need personal data.
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:31,695'); seek(151.0)">
              They're often you telling it information or providing it
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:34,875'); seek(154.0)">
              information through your computer screen, et cetera, which they process.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:38,805'); seek(158.0)">
              This raises major privacy concerns because you might be sharing your data
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:43,585'); seek(163.0)">
              with an LLM provider like OpenAI, but also an intermediary like a startup.
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:48,665'); seek(168.0)">
              So you need to trust both those companies.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:51,065'); seek(171.0)">
              Large language models also have a massive carbon footprint.
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:54,945'); seek(174.0)">
              For example, just training GPT 4 in an article was shown to have emissions
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:01,205'); seek(181.0)">
              equivalent to driving 18 million miles in a gasoline car and a single
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:05,955'); seek(185.0)">
              inference call to GPT 4, again in an article, was shown to be equivalent of
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:11,015'); seek(191.0)">
              charging a mobile phone 60 times over.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:13,885'); seek(193.0)">
              Then also another problem with large language models is
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:17,675'); seek(197.0)">
              their ability to mimic humans.
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:20,245'); seek(200.0)">
              This is because large language models are essentially producing
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:23,785'); seek(203.0)">
              language similar to humans and this leads to problems such as deepfakes.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:29,095'); seek(209.0)">
              The internet is flooded with deepfakes, but also the possibility
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:32,905'); seek(212.0)">
              of fraud increasing a lot.
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:35,185'); seek(215.0)">
              For example, imagine getting a call in the voice of your mother and your mother tells
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:39,425'); seek(219.0)">
              you she's hurt and she needs some money.
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:41,765'); seek(221.0)">
              You'll probably transfer the money, but later you'll realize that this
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:46,115'); seek(226.0)">
              was just a large language model talking in your mother's voice.
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:50,435'); seek(230.0)">
              This is a very big concern, but we won't talk about this today
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:53,865'); seek(233.0)">
              because this is a whole other talk.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:55,745'); seek(235.0)">
              We'll cover the first and the second points today.
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:03:58,515'); seek(238.0)">
              So moving these large language models from the internet to on
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:02,405'); seek(242.0)">
              device solves the first two problems.
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:05,825'); seek(245.0)">
              This is because on device models are off the grid.
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:09,335'); seek(249.0)">
              They don't need internet.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:10,755'); seek(250.0)">
              They don't need any external connection.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:13,185'); seek(253.0)">
              There is no middleman.
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:14,225'); seek(254.0)">
              Everything is on your device.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:15,955'); seek(255.0)">
              So there's no privacy risk anymore.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:18,255'); seek(258.0)">
              And as a result of these models having to run on device, they're automatically
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:23,235'); seek(263.0)">
              smaller, and smaller means that they're greener, and they essentially have,
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:04:28,165'); seek(268.0)">
              will have a lesser carbon footprint.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:31,125'); seek(271.0)">
              And this is again, just by design that you have to make them
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:34,305'); seek(274.0)">
              smaller to run on the computer.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:36,605'); seek(276.0)">
              All right, now let's talk about state of the art LLMs.
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:40,815'); seek(280.0)">
              Where is this technology today?
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:04:42,345'); seek(282.0)">
              What does it look like?
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:04:43,840'); seek(283.0)">
              And we'll do this through two demos.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:04:46,050'); seek(286.0)">
              So for the first demo, I'll give the following prompt to the LLM.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:04:50,160'); seek(290.0)">
              Hello, I'll be giving a presentation with the topic on device LLMs, a path to
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:04:55,290'); seek(295.0)">
              a safer and more efficient AI systems.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:04:58,620'); seek(298.0)">
              Can you give me a one line opener, make it engaging and thought provoking?
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:03,430'); seek(303.0)">
              So I take this prompt and I will Copy the prompt and then I'll use
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:09,575'); seek(309.0)">
              OLAMA, which is a way to essentially run large language models on device.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:14,895'); seek(314.0)">
              The model I'm running is LAMA 3.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:17,585'); seek(317.0)">
              1.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:17,585'); seek(317.0)">
              This is a model by Meta and it has 8 billion parameters.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:05:21,835'); seek(321.0)">
              This is now loading into the memory of my computer.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:05:24,855'); seek(324.0)">
              I paste the prompt and run it and it gives me a reasonable response.
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:30,095'); seek(330.0)">
              Let's read the first one.
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:31,945'); seek(331.0)">
              As we increasingly rely on AI, Can we afford not to rethink the way
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:05:37,000'); seek(337.0)">
              we build models from edges of our networks to edges of our devices?
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:05:42,380'); seek(342.0)">
              Makes sense.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:05:43,080'); seek(343.0)">
              It's nice.
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:05:43,690'); seek(343.0)">
              It's not perfect, but it's a good start.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:05:46,840'); seek(346.0)">
              All right.
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:05:47,060'); seek(347.0)">
              Now just to get a baseline, sorry, before we get the baseline, we try
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:05:50,740'); seek(350.0)">
              to run this on Lama billion, which is a much bigger model by Facebook.
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:05:56,220'); seek(356.0)">
              And this is now loading into memory.
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:05:59,040'); seek(359.0)">
              But as I'll soon realize this doesn't actually load into
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:01,800'); seek(361.0)">
              the memory of my computer.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:03,435'); seek(363.0)">
              I open activity monitor and I see this model is taking tons of memory.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:09,065'); seek(369.0)">
              It's already taking 32 gigs, which is more than what this computer has.
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:06:13,625'); seek(373.0)">
              So this model essentially cannot run on my device.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:06:17,555'); seek(377.0)">
              so we've seen that the model size on device is seven to 10
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:06:21,245'); seek(381.0)">
              billion, somewhere around there.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:06:23,294'); seek(383.0)">
              now just to get a baseline, we run the same prompt in GPD 4.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:27,025'); seek(387.0)">
              0.
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:06:28,364'); seek(388.0)">
              So I paste the prompt, run it.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:06:31,460'); seek(391.0)">
              And I get the response, which is, imagine smartphone is not just smart,
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:06:37,140'); seek(397.0)">
              but a powerhouse of intelligent privacy.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:06:39,960'); seek(399.0)">
              Welcome to the new frontier with on device LLMs.
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:06:43,420'); seek(403.0)">
              So perfect opening, exactly what I wanted.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:06:46,389'); seek(406.0)">
              And that's what we have come to expect from GPD 4.
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:06:48,840'); seek(408.0)">
              0.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:06:50,090'); seek(410.0)">
              But of course, this is still running in the cloud.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:06:52,580'); seek(412.0)">
              And as we saw, Lama 8, we produced a response, which made sense, but
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:06:56,689'); seek(416.0)">
              it's not at the level of GPD 4.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:06:58,919'); seek(418.0)">
              0 yet.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:06:59,730'); seek(419.0)">
              All right, now for the second test, we'll do a coding challenge where
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:07:03,230'); seek(423.0)">
              we'll get these models to create Minesweeper, a popular game, and
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:07:07,480'); seek(427.0)">
              we'll see how the different models do.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:07:10,280'); seek(430.0)">
              So let's start by copying this prompt I created to write, make
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:14,769'); seek(434.0)">
              the models write Minesweeper.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:07:16,439'); seek(436.0)">
              And we'll again start with Llama8B, the tiny model by Meta
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:07:21,270'); seek(441.0)">
              that runs fully on my device.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:07:23,200'); seek(443.0)">
              As you can see, it produces code which makes sense.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:07:25,530'); seek(445.0)">
              It's calling the init function, print board, create mines,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:07:29,760'); seek(449.0)">
              count adjacent mines, reveal.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:07:31,429'); seek(451.0)">
              All of this makes sense for a typical minesweeper game.
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:07:34,570'); seek(454.0)">
              So now, it's, Finishing producing this code, it's written the play
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:07:38,869'); seek(458.0)">
              function, which is a while loop to play this game indefinitely
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:07:41,769'); seek(461.0)">
              until you hit a mine, of course.
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:07:43,839'); seek(463.0)">
              now I can go ahead and copy the code.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:07:46,479'); seek(466.0)">
              I'll paste the code into a Python file called minesweeper llama8b.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:07:52,170'); seek(472.0)">
              py.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:07:56,089'); seek(476.0)">
              And then I'll go ahead and run the code.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:07:58,944'); seek(478.0)">
              Unfortunately for Llama, it doesn't run.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:08:02,014'); seek(482.0)">
              it only took me 15 to 20 minutes to correct it so it wasn't too off and
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:08:05,644'); seek(485.0)">
              other iterations produce slightly better code which sometimes even compiled.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:08:10,054'); seek(490.0)">
              okay now to get a baseline let's go to GPT 4.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:08:12,904'); seek(492.0)">
              0, paste the prompt and as you can see it very quickly generates the code.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:08:17,894'); seek(497.0)">
              Of course this is again running on the server and we expect this
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:08:20,554'); seek(500.0)">
              to be great but just to get a baseline let's see what it does.
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:08:24,424'); seek(504.0)">
              The code looks similar to what was produced by Lama, but of
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:08:28,394'); seek(508.0)">
              course, as we know, the quality is expected to be a lot better.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:08:33,164'); seek(513.0)">
              So I do the same thing.
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:08:34,174'); seek(514.0)">
              I copy the code, go back to the terminal, create a file called minesweeper gpt40.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:08:40,644'); seek(520.0)">
              py, paste the code, and now I run it.
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:08:45,084'); seek(525.0)">
              And here we get a perfectly working version of Minesweeper.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:08:47,834'); seek(527.0)">
              I type 3 4, hit a mine, and lose in the first turn.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:08:51,584'); seek(531.0)">
              So let's go ahead and play once more.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:08:54,044'); seek(534.0)">
              And here I can essentially run through the entire game of Minesweeper where I'm going
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:09:00,274'); seek(540.0)">
              through different options I've chosen.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:09:03,454'); seek(543.0)">
              This is fast forwarded and then eventually I write 3 3.
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:09:07,749'); seek(547.0)">
              hit a mine and the game ends.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:09:09,929'); seek(549.0)">
              All right, now the interesting part.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:09:12,029'); seek(552.0)">
              We're going to paste the same prompt, but in a very different model.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:09:16,619'); seek(556.0)">
              This model is called CodeQuin.
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:09:19,069'); seek(559.0)">
              This is by the Alibaba group in China.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:09:22,719'); seek(562.0)">
              this model is only a 7 billion parameter model.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:09:26,329'); seek(566.0)">
              So it's a much smaller model than even, or not much smaller, but a smaller model
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:09:30,929'); seek(570.0)">
              than the Lama model we saw earlier.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:09:33,859'); seek(573.0)">
              So it's able to run fully on device.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:09:36,239'); seek(576.0)">
              But the interesting thing about this model is it's customized and
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:09:40,169'); seek(580.0)">
              tuned to do well on coding tasks.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:09:42,189'); seek(582.0)">
              So its strength is coding and it outperforms LLAMA as we'll see soon.
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:09:48,039'); seek(588.0)">
              So right now it's writing code, it creates the board, counts the
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:09:51,899'); seek(591.0)">
              mines, reveals a similar structure to what LLAMA was producing.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:09:56,749'); seek(596.0)">
              It's a bit slower running on memory, even though it's a smaller parameter model.
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:10:01,119'); seek(601.0)">
              Presumably it's not as optimized as Llama for MacBooks.
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:10:05,699'); seek(605.0)">
              so I'll give it a second to just finish coding.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:10:08,479'); seek(608.0)">
              Almost there.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:10:09,969'); seek(609.0)">
              Alright.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:10:11,079'); seek(611.0)">
              There we go.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:10:11,859'); seek(611.0)">
              It's finished the setup.
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:10:12,724'); seek(612.0)">
              code given some description.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:10:14,264'); seek(614.0)">
              I will go ahead, copy the code and follow the same procedure where I'll create,
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:10:20,954'); seek(620.0)">
              I'll copy the code, create a Python file called Minesweeper code or q7b.
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:10:28,344'); seek(628.0)">
              py, paste the code
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:10:30,064'); seek(630.0)">
              and then I run it.
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:10:31,554'); seek(631.0)">
              Interestingly, it shows me the locations of the mines visibly, which is a bit
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:10:36,104'); seek(636.0)">
              weird, but it at least runs the code.
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:10:39,024'); seek(639.0)">
              Then we write the location of a mine 03, but it doesn't end the game.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:10:43,559'); seek(643.0)">
              Then I write 00, which is not the location of the mine, and that, that works well.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:10:49,189'); seek(649.0)">
              So essentially it's playing Minesweeper correctly, except that it shows the
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:10:53,039'); seek(653.0)">
              mines at the beginning and hitting the mines do not end the game.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:10:57,679'); seek(657.0)">
              I played around with this code after the demo and it took me less than five
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:11:01,049'); seek(661.0)">
              minutes to make it fully functional.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:11:03,209'); seek(663.0)">
              So it was definitely higher quality than what Llama8B had created for me.
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:11:08,439'); seek(668.0)">
              All right, we have looked at, these models qualitatively,
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:11:12,829'); seek(672.0)">
              but let's look at some numbers.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:11:15,149'); seek(675.0)">
              sorry, the bottom right number is hidden because of my video, but it's 78.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:11:19,939'); seek(679.0)">
              So let's start from the top left, LAMA 3.
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:11:22,779'); seek(682.0)">
              1, the 8 billion parameter model.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:11:26,329'); seek(686.0)">
              let's look at the chat reasoning task, so how well it performs
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:11:28,869'); seek(688.0)">
              on chat tasks and coding tasks.
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:11:31,979'); seek(691.0)">
              So for LAMA 3.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:11:33,059'); seek(693.0)">
              1, The 8 billion parameter model got a 73 on chat and about the same on coding.
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:11:39,039'); seek(699.0)">
              The 70 billion got 86 on chats, an amazing score for such a small
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:11:43,399'); seek(703.0)">
              model and the same on coding.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:11:46,149'); seek(706.0)">
              GPT 4.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:11:47,164'); seek(707.0)">
              0 got 86.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:11:48,459'); seek(708.0)">
              7 on chat and 87.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:11:50,809'); seek(710.0)">
              8 on coding.
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:11:52,319'); seek(712.0)">
              So again, close to each other.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:11:54,659'); seek(714.0)">
              But CodeGrend, the tiny model by the Alibaba group, got
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:11:58,209'); seek(718.0)">
              78 on the coding challenge.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:12:00,559'); seek(720.0)">
              So much higher than the 8 billion parameter Lama model like we saw earlier.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:12:04,939'); seek(724.0)">
              And this shows us the importance of having task specific models, which we'll talk
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:12:11,099'); seek(731.0)">
              about more in the coming slides as well.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:12:13,599'); seek(733.0)">
              Next, let's explore the current real world use cases for on
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:12:18,279'); seek(738.0)">
              device large language models.
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:12:20,489'); seek(740.0)">
              So these are use cases already out there in the wild.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:12:23,489'); seek(743.0)">
              Here's a list of these use cases.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:12:25,819'); seek(745.0)">
              Some of these are large language models and some of these are related
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:12:29,009'); seek(749.0)">
              technologies, which use similar tech to large language models.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:12:33,429'); seek(753.0)">
              So style transfer, this is already out there.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:12:36,029'); seek(756.0)">
              If you want to convert your email to a more friendly email
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:12:39,749'); seek(759.0)">
              or a more professional email.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:12:41,449'); seek(761.0)">
              This is already possible today with large language models.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:12:44,939'); seek(764.0)">
              Speech to text.
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:12:46,479'); seek(766.0)">
              Converting, your audio to text is a very important task and this actually works
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:12:52,219'); seek(772.0)">
              really well fully on device today already.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:12:55,919'); seek(775.0)">
              probably almost as good as the server side model to be honest.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:12:59,739'); seek(779.0)">
              Summarization.
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:13:01,399'); seek(781.0)">
              summarization does work on device today.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:13:04,429'); seek(784.0)">
              It's not as good as server side, but it's pretty good.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:13:06,839'); seek(786.0)">
              You can get 80 percent of the value you'll want out of it.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:13:11,049'); seek(791.0)">
              And finally, translation, same as summarization, works really well
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:13:14,489'); seek(794.0)">
              on device, slightly worse than server side, but it's almost there.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:13:18,879'); seek(798.0)">
              Now let's actually look at some of these use cases in action through a demo.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:13:23,299'); seek(803.0)">
              All right, so let's go through the use cases which we saw before through
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:13:27,889'); seek(807.0)">
              the eyes of Apple Intelligence.
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:13:29,989'); seek(809.0)">
              Apple Intelligence is a suite of features Apple launched in iOS 18.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:13:34,519'); seek(814.0)">
              1.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:13:35,019'); seek(815.0)">
              Some of the features in this demo also came before that.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:13:38,759'); seek(818.0)">
              As you can see, the phone is on airplane mode, so there's no internet.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:13:42,564'); seek(822.0)">
              This is fully on device, not running a model on the server or anything.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:13:46,674'); seek(826.0)">
              So what I'm doing here is I'm in the notes app, and I'm typing an email.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:13:50,664'); seek(830.0)">
              Hi Alex, reached this site.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:13:53,304'); seek(833.0)">
              Good to meet you, but I don't think now is the right time to collaborate.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:13:57,394'); seek(837.0)">
              While I love your vision question mark, the product
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:14:00,054'); seek(840.0)">
              isn't the right fit, right now.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:14:03,074'); seek(843.0)">
              Hope to collaborate, someday.
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:14:06,424'); seek(846.0)">
              RISH.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:14:07,284'); seek(847.0)">
              So not great English, but it's a start.
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:14:10,174'); seek(850.0)">
              So I can go ahead and select this.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:14:12,354'); seek(852.0)">
              I can go to writing tools, which is one of the new features Apple
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:14:15,124'); seek(855.0)">
              launched, and I can click on proofread.
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:14:18,214'); seek(858.0)">
              So here Apple suggests me change a couple of words.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:14:22,264'); seek(862.0)">
              RISH comma this side, good to meet, and then some days
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:14:26,684'); seek(866.0)">
              combined into a single word.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:14:28,629'); seek(868.0)">
              Not super helpful, but it's okay.
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:14:31,439'); seek(871.0)">
              So let's try some other writing tool.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:14:33,949'); seek(873.0)">
              this time I select writing tools and I click rewrite.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:14:37,739'); seek(877.0)">
              So rewrite is now going to rewrite the message as expected.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:14:41,264'); seek(881.0)">
              So it says, Rish, it's great to meet you on this side.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:14:44,264'); seek(884.0)">
              So I think Rish is the other person instead of me, which is incorrect,
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:14:47,744'); seek(887.0)">
              but let's look at the second sentence.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:14:49,654'); seek(889.0)">
              However, I don't believe this is the appropriate time to collaborate.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:14:53,784'); seek(893.0)">
              So this sentence and the rest of the email is a lot better than before.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:14:58,124'); seek(898.0)">
              So it's getting there.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:14:58,904'); seek(898.0)">
              It's actually improving it the way I want.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:15:00,694'); seek(900.0)">
              Let's just remove RISC to make the job simpler for the LLM.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:15:04,624'); seek(904.0)">
              And this time when I select the email, I'll go to writing tools, but
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:15:09,134'); seek(909.0)">
              I'll just change it to a friendly tone, so style transfer this time.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:15:13,134'); seek(913.0)">
              And I get the response, Hi Alex.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:15:15,124'); seek(915.0)">
              It's great to meet you.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:15:16,174'); seek(916.0)">
              I think we're both on the same page about wanting to collaborate in the future.
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:15:19,764'); seek(919.0)">
              I just don't think now is the right time to work together
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:15:22,484'); seek(922.0)">
              on this particular project.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:15:24,104'); seek(924.0)">
              I hope we can still find a way to work with each other in the future.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:15:27,234'); seek(927.0)">
              So work flawlessly.
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:15:28,994'); seek(928.0)">
              Next let's test dictation.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:15:30,964'); seek(930.0)">
              Dictation is essentially, speech to text.
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:15:33,864'); seek(933.0)">
              I'm seeing the sentence.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:15:34,864'); seek(934.0)">
              You can't hear it.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:15:36,524'); seek(936.0)">
              Hi, this is a test for seeing how the dictation works.
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:15:39,614'); seek(939.0)">
              And it again worked flawlessly, fully on device, airplane mode is still on.
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:15:44,044'); seek(944.0)">
              Next, let's try selecting this entire email.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:15:47,424'); seek(947.0)">
              And we'll try to create a summary of this email.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:15:49,814'); seek(949.0)">
              I don't want to go through this whole email.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:15:52,344'); seek(952.0)">
              So I'll go to writing tools and click on summary.
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:15:57,504'); seek(957.0)">
              Unfortunately, that does not work without the internet.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:16:01,054'); seek(961.0)">
              So just to make sure it works with the internet, let's turn
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:16:03,574'); seek(963.0)">
              on the internet, writing tools.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:16:05,694'); seek(965.0)">
              And I click on Summary.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:16:08,164'); seek(968.0)">
              And I got a summary telling me the events with Uber, Bloomberg, Citadel, etc.
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:16:12,014'); seek(972.0)">
              And RSVPs are required for all these events.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:16:15,584'); seek(975.0)">
              So I got all the information I needed perfectly there.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:16:18,389'); seek(978.0)">
              Next, let's look at Spotlight.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:16:19,839'); seek(979.0)">
              Meet Alex at 10 a.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:16:21,289'); seek(981.0)">
              m.
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:16:21,539'); seek(981.0)">
              Airplane mode is on again, and I got a meeting invite.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:16:24,419'); seek(984.0)">
              So there's NLP matching going on here, even if it may not be
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:16:28,509'); seek(988.0)">
              fully large language models.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:16:29,729'); seek(989.0)">
              That's unknown.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:16:31,069'); seek(991.0)">
              Next, let's look at Translate.
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:16:32,669'); seek(992.0)">
              So I try to translate hello.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:16:34,479'); seek(994.0)">
              It doesn't work without the internet.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:16:36,409'); seek(996.0)">
              So I turn on the internet and what I can do now is I can click the three dots and
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:16:40,479'); seek(1000.0)">
              click on download languages, scroll down, And I can simply download Spanish onto my,
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:16:47,799'); seek(1007.0)">
              iPhone, so now it should work on device.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:16:50,709'); seek(1010.0)">
              It also downloads English.
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:16:52,609'); seek(1012.0)">
              So now I go back into airplane mode and I write, can I get the churros?
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:16:57,279'); seek(1017.0)">
              And it translates to Spanish without the internet because airplane mode is on.
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:17:01,314'); seek(1021.0)">
              And presumably this is correct.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:17:03,444'); seek(1023.0)">
              And I write thank you and it says gracias, which I know is correct.
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:17:07,424'); seek(1027.0)">
              Next I have all these lists of notifications.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:17:09,804'); seek(1029.0)">
              I can click show less airplane mode is on And I get a summary of the notifications.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:17:14,724'); seek(1034.0)">
              So summary in this context seems to work without the internet as well
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:17:18,744'); seek(1038.0)">
              All right, that's just a rapid fire of a bunch of features in apple
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:17:22,804'); seek(1042.0)">
              intelligence that work without the internet hence running fully on device
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:17:27,224'); seek(1047.0)">
              Next, let's talk about the path to MVP.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:17:30,984'); seek(1050.0)">
              MVP, in my opinion, if we can reach GPD 4.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:17:34,544'); seek(1054.0)">
              0 level performance being the accuracy on device, that would be game changing.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:17:40,284'); seek(1060.0)">
              That would be a product that will actually be extremely valuable in everyday life.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:17:46,374'); seek(1066.0)">
              To reach this target, I believe we'll have to improve the hardware to be able
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:17:51,094'); seek(1071.0)">
              to run 30 billion parameters on device.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:17:53,574'); seek(1073.0)">
              I think these 8 to 10 billion parameter models are still too small to have enough
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:17:57,764'); seek(1077.0)">
              information, but we see promising results from 60, 70 billion parameter models.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:18:02,954'); seek(1082.0)">
              I'm sure we can make them smaller, perhaps to the size of around 30 billion.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:18:08,924'); seek(1088.0)">
              Models need to be more specialized.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:18:11,104'); seek(1091.0)">
              So like we saw CodeGwent absolutely outperformed, Lama 3.
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:18:15,939'); seek(1095.0)">
              18 billion, despite having similar number of parameters, just
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:18:20,099'); seek(1100.0)">
              because it was coding specific.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:18:22,299'); seek(1102.0)">
              You can go one level deeper.
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:18:23,759'); seek(1103.0)">
              You can make it Python specific instead of coding in general,
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:18:27,689'); seek(1107.0)">
              and that might be even better.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:18:29,190'); seek(1109.0)">
              Next, we need to improve adapters.
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:18:32,729'); seek(1112.0)">
              So adapters are things like LoRa adapters, which can.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:18:36,759'); seek(1116.0)">
              Which again, I can't go into details, that would be a whole other talk,
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:18:40,049'); seek(1120.0)">
              but essentially can add a layer of specialization without having
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:18:44,299'); seek(1124.0)">
              to recreate a whole new model.
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:18:46,309'); seek(1126.0)">
              So let's say you have a Python specialized model, you can then use
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:18:50,579'); seek(1130.0)">
              a LoRa adapter to make it a model for creating games using Python.
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:18:55,349'); seek(1135.0)">
              So we've become even more specialized using adapters.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:18:58,329'); seek(1138.0)">
              So in terms of software innovations, we already talked about, the second
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:19:03,589'); seek(1143.0)">
              and third point, which is adapter mechanisms and specializations.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:19:07,509'); seek(1147.0)">
              But one more thing that needs to be innovated is enhanced
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:19:11,079'); seek(1151.0)">
              compression techniques.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:19:12,819'); seek(1152.0)">
              so not only on the hardware side can we reduce the parameters, but
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:19:16,749'); seek(1156.0)">
              we can start compressing these models into smaller and smaller
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:19:20,769'); seek(1160.0)">
              models, pulling out the parameters.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:19:23,485'); seek(1163.0)">
              by using better compression techniques.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:19:26,145'); seek(1166.0)">
              And then on the hardware side, we need optimized processing units
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:19:30,755'); seek(1170.0)">
              to run bigger and bigger models.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:19:32,255'); seek(1172.0)">
              Instead of 10 billion models, we should be able to run 30 billion or higher models.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:19:37,085'); seek(1177.0)">
              But also we need an enhanced memory architecture.
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:19:39,525'); seek(1179.0)">
              This would be the RAM system.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:19:41,935'); seek(1181.0)">
              because these models need to be extremely quick, so they need a
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:19:45,775'); seek(1185.0)">
              really solid memory architecture.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:19:48,445'); seek(1188.0)">
              I'm not a hardware expert, so I can't go into details about these topics,
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:19:52,085'); seek(1192.0)">
              but at a high level with, in what I've discussed with hardware experts, these are
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:19:57,305'); seek(1197.0)">
              the two main frontiers we need to push.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:20:00,135'); seek(1200.0)">
              All right, and then finally, let's say all of this happens.
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:20:03,055'); seek(1203.0)">
              We have 30 billion parameters.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:20:04,625'); seek(1204.0)">
              These models are running fully on devices, specialized, have adapters.
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:20:08,645'); seek(1208.0)">
              What's the outcome?
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:20:10,025'); seek(1210.0)">
              Let's talk about the real world use cases these models will enable.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:20:13,845'); seek(1213.0)">
              So the first is augmented workflows.
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:20:16,825'); seek(1216.0)">
              These models will become deeply integrated into everyone's work life.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:20:20,575'); seek(1220.0)">
              You'll be able to share your entire work context with these models because they're
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:20:24,565'); seek(1224.0)">
              not sending any data to the server and they'll streamline every single task
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:20:29,105'); seek(1229.0)">
              in your life, whether it's emails, data analysis, presentations, or even like
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:20:33,995'); seek(1233.0)">
              filling out Excel sheets or writing code.
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:20:36,595'); seek(1236.0)">
              The next is On Device Therapy.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:20:39,545'); seek(1239.0)">
              On Device Therapy will become better with these models because you'll be
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:20:42,785'); seek(1242.0)">
              able to share more and you'll have advice available at all times, in
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:20:47,310'); seek(1247.0)">
              your pocket or on your computer.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:20:49,810'); seek(1249.0)">
              Legal assistance.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:20:51,530'); seek(1251.0)">
              This will help both lawyers, because they'll be able to share
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:20:54,890'); seek(1254.0)">
              client data with these models, at any time to get information.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:20:59,520'); seek(1259.0)">
              And they can trust these models because they're running fully on device,
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:21:02,940'); seek(1262.0)">
              but they can also help the layman to get legal assistance quickly,
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:21:07,660'); seek(1267.0)">
              without having to engage a lawyer.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:21:09,200'); seek(1269.0)">
              And again, they can trust this model because it's fully on their device.
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:21:12,910'); seek(1272.0)">
              So they can have that same, lawyer client, relationship.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:21:17,645'); seek(1277.0)">
              with this model where they know the model will not breach their trust.
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:21:22,285'); seek(1282.0)">
              And then finally medical diagnosis.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:21:25,205'); seek(1285.0)">
              Medical diagnosis will again be empowered by these models because you'll again
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:21:30,195'); seek(1290.0)">
              be more willing to share your personal data and you'll be willing to share
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:21:33,245'); seek(1293.0)">
              your entire medical history with these models because they're fully on your
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:21:36,765'); seek(1296.0)">
              device so you don't have to worry about where your data goes and you can get
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:21:40,625'); seek(1300.0)">
              really accessible healthcare diagnosis.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:21:44,265'); seek(1304.0)">
              and potentially even treatment using these models.
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:21:48,235'); seek(1308.0)">
              That's all I have for today.
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:21:49,805'); seek(1309.0)">
              Thank you for coming to the talk.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:21:52,095'); seek(1312.0)">
              If you have any questions or follow ups, please feel free to
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:21:56,045'); seek(1316.0)">
              email me at rish at pinnacle.
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:21:58,655'); seek(1318.0)">
              co.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:21:59,675'); seek(1319.0)">
              Thank you so much.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:22:01,275'); seek(1321.0)">
              Bye.
            </span>
            
            </div>
          </div>
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Rishab%20Mehra%20-%20Conf42%20Prompt%20Engineering%202024.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Rishab%20Mehra%20-%20Conf42%20Prompt%20Engineering%202024.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #749BC2;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/prompt2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #749BC2;">
                <i class="fe fe-grid me-2"></i>
                See all 40 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Rishab%20Mehra_prompt.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Rishab Mehra
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Founder & CTO @ Pinnacle
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/mehrarishab/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Rishab Mehra's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Rishab Mehra"
                  data-url="https://www.conf42.com/prompt2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/prompt2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>





  <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
    </script>
    <!-- SUBSCRIBE -->
    <section class="pt-8 pt-md-11 bg-gradient-light-white" id="register">
        <div class="container">
          <div class="row align-items-center justify-content-between mb-8 mb-md-11">
            <div class="col-12 col-md-6 order-md-2" data-aos="fade-left">
  
              <!-- Heading -->
              <h2>
                Awesome tech events for <br>
                <span class="text-success"><span data-typed='{"strings": ["software engineers.", "tech leaders.", "SREs.", "DevOps.", "CTOs.",  "managers.", "architects.", "QAs.", "developers.", "coders.", "founders.", "CEOs.", "students.", "geeks.", "ethical hackers.", "educators.", "enthusiasts.", "directors.", "researchers.", "PHDs.", "evangelists.", "tech authors."]}'></span></span>
              </h2>
  
              <!-- Text -->
              <p class="fs-lg text-muted mb-6">
  
              </p>
  
              <!-- List -->
              <div class="row">
                <div class="col-12 col-lg-12">
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <!-- Text -->
                    <p class="text-success">
                      Priority access to all content
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Video hallway track
                    </p>
                  </div>

                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Community chat
                    </p>
                  </div>
  
                  <!-- Item -->
                  <div class="d-flex">
                    <!-- Check -->
                    <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                      <i class="fe fe-check"></i>
                    </div>
                    <p class="text-success">
                      Exclusive promotions and giveaways
                    </p>
                  </div>
  
                </div>
              </div> <!-- / .row -->
  
            </div>
            <div class="col-12 col-md-6 col-lg-5 order-md-1">
  
              <!-- Card -->
              <div class="card shadow-light-lg">
  
                <!-- Body -->
                <div class="card-body">
  
                  <!-- Form -->
                  <link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
                  <p class="emailoctopus-success-message text-success"></p>
                  <p class="emailoctopus-error-message text-danger"></p>
                  <form
                    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
                    method="post"
                    data-message-success="Thanks! Check your email for further directions!"
                    data-message-missing-email-address="Your email address is required."
                    data-message-invalid-email-address="Your email address looks incorrect, please try again."
                    data-message-bot-submission-error="This doesn't look like a human submission."
                    data-message-consent-required="Please check the checkbox to indicate your consent."
                    data-message-invalid-parameters-error="This form has missing or invalid fields."
                    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
                    class="emailoctopus-form"
                    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
                  >
                    <div class="form-floating emailoctopus-form-row">
                      <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
                      <label for="field_0">Email address</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
                      <label for="field_1">First Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
                      <label for="field_2">Last Name</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
                      <label for="field_4">Company</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
                      <label for="field_5">Job Title</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
                      <label for="field_3">Phone Number</label>
                    </div>
                    <div class="form-floating emailoctopus-form-row">
                      <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
                        oninput="updateCountry()"
                      >
                        <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
                      </select>
                      <label for="field_7">Country</label>
                    </div>
                    <input id="country-destination" name="field_7" type="hidden">
                    <input id="tz-country" name="field_8" type="hidden">
                    
                    <input
                      name="field_6"
                      type="hidden"
                      value="Prompt Engineering"
                    >
                    
                    <div class="emailoctopus-form-row-consent">
                      <input
                        type="checkbox"
                        id="consent"
                        name="consent"
                      >
                      <label for="consent">
                        I consent to the following terms:
                      </label>
                      <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
                        Terms and Conditions
                      </a>
                      &amp;
                      <a href="./code-of-conduct" target="_blank">
                        Code of Conduct
                      </a>
                    </div>
                    <div
                      aria-hidden="true"
                      class="emailoctopus-form-row-hp"
                    >
                      <input
                        type="text"
                        name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
                        tabindex="-1"
                        autocomplete="nope"
                      >
                    </div>
                    <div class="mt-6 emailoctopus-form-row-subscribe">
                      <input
                        type="hidden"
                        name="successRedirectUrl"
                      >
                      <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
                        Subscribe
                      </button>
                    </div>
                  </form>
  
                </div>
  
              </div>
  
            </div>
  
          </div> <!-- / .row -->
        </div> <!-- / .container -->
      </section>

      <!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
      <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>