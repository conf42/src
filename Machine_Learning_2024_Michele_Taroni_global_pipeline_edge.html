<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Global Intelligence Pipeline: How We’re Crafting Inference at the Edge</title>
    <meta name="description" content="Help build a dystopian, machine-ated future!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Michele%20Taroni_ml.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Global Intelligence Pipeline: How We’re Crafting Inference at the Edge | Conf42"/>
    <meta property="og:description" content="AI is a hot and rapidly developing topic in the cloud space. In this session, topics covered will include market trends, future directions, training, and inference. Get up to date on the latest AI trends and news, including the value cloud can deliver to AI and Gcore's Inference at the Edge, including real-life scenarios where the company helped customers using AI"/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2024_Michele_Taroni_global_pipeline_edge"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/PLATFORM2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Platform Engineering 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-09-04
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/platform2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2024
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2024">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2024">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2024">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2024">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2024">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2024">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2024">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2024">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2024">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2024">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2024">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2024">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2024">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2024">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2024">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2024">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2024">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2024">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a>
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2024 - Online
            </h1>

            <h2 class="text-white">
              
              <time datetime="2024-05-30">May 30 2024</time>
              
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Help build a dystopian, machine-ated future!
 -->
              <script>
                const event_date = new Date("2024-05-30T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2024-05-30T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              <a href="#register" class="btn btn-primary shadow lift me-1 mb-3">
                <i class="fe fe-user-check me-2"></i>
                Subscribe to watch
              </a>
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "jyM0f5Gy9gA"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "hB92yML_Ni8"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrDQ9kU-TbooKutrP-8IVE0r" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone, my name is Nikhil Taroni, head of AI products", "timestamp": "00:00:27,320", "timestamp_s": 27.0}, {"text": "at GCor. First of all, thank you very much to the organizer of", "timestamp": "00:00:31,168", "timestamp_s": 31.0}, {"text": "Conf 42 for having me here today, and I\u0027m really", "timestamp": "00:00:34,608", "timestamp_s": 34.0}, {"text": "excited to talk to you about our pioneering work building our global", "timestamp": "00:00:37,752", "timestamp_s": 37.0}, {"text": "intelligence pipeline and its cornerstone technology inference", "timestamp": "00:00:41,400", "timestamp_s": 41.0}, {"text": "at the edge. And during the talk, feel free", "timestamp": "00:00:45,704", "timestamp_s": 45.0}, {"text": "to ping me on slack with any questions or comments and I\u0027ll do", "timestamp": "00:00:48,912", "timestamp_s": 48.0}, {"text": "my best to answer. But for now, let\u0027s dive in.", "timestamp": "00:00:52,160", "timestamp_s": 52.0}, {"text": "As I\u0027m here on behalf of GCor, let me begin by telling", "timestamp": "00:00:56,444", "timestamp_s": 56.0}, {"text": "you a little bit more about us. We are a global", "timestamp": "00:00:59,972", "timestamp_s": 59.0}, {"text": "cloud edge and AI solutions provider headquartered", "timestamp": "00:01:03,812", "timestamp_s": 63.0}, {"text": "in Luxembourg, but with a global presence and", "timestamp": "00:01:08,332", "timestamp_s": 68.0}, {"text": "our vision is to connect the world to AI anywhere,", "timestamp": "00:01:11,980", "timestamp_s": 71.0}, {"text": "anytime. The cornerstone of the company is", "timestamp": "00:01:15,940", "timestamp_s": 75.0}, {"text": "our secure low latency network, which consists of over 180", "timestamp": "00:01:19,790", "timestamp_s": 79.0}, {"text": "CDN points of presence and 25 cloud locations,", "timestamp": "00:01:24,534", "timestamp_s": 84.0}, {"text": "giving us an average response time of just 30 milliseconds.", "timestamp": "00:01:28,974", "timestamp_s": 88.0}, {"text": "We offer a range of cloud services covering infrastructure", "timestamp": "00:01:33,494", "timestamp_s": 93.0}, {"text": "as a service, multi platform as a service.", "timestamp": "00:01:37,038", "timestamp_s": 97.0}, {"text": "But today, as we go at a machine learning conference,", "timestamp": "00:01:40,534", "timestamp_s": 100.0}, {"text": "I\u0027m going to focus on our AI as a service offerings and some of", "timestamp": "00:01:43,846", "timestamp_s": 103.0}, {"text": "the work we\u0027ve done there. To begin, we offer a range of", "timestamp": "00:01:47,186", "timestamp_s": 107.0}, {"text": "AI services including GPU, bare metal", "timestamp": "00:01:51,634", "timestamp_s": 111.0}, {"text": "and virtual machine instances, managed kubernetes clusters,", "timestamp": "00:01:54,882", "timestamp_s": 114.0}, {"text": "and also a 5g platform that helps reduce the latency between", "timestamp": "00:01:58,642", "timestamp_s": 118.0}, {"text": "your device and the model. But all of these services", "timestamp": "00:02:02,338", "timestamp_s": 122.0}, {"text": "underpins what we call our global intelligence pipeline,", "timestamp": "00:02:05,858", "timestamp_s": 125.0}, {"text": "which is designed to follow the steps taken by machine learning practitioners to", "timestamp": "00:02:10,314", "timestamp_s": 130.0}, {"text": "train, deploy and scale AI applications", "timestamp": "00:02:14,344", "timestamp_s": 134.0}, {"text": "in production. So starting on the left there,", "timestamp": "00:02:17,720", "timestamp_s": 137.0}, {"text": "you can see that we offer direct access to high performance", "timestamp": "00:02:21,504", "timestamp_s": 141.0}, {"text": "AI infrastructure acted by Nvidia GPU\u0027s.", "timestamp": "00:02:24,968", "timestamp_s": 144.0}, {"text": "This provides the raw computing power needed for intense AI training", "timestamp": "00:02:29,144", "timestamp_s": 149.0}, {"text": "workloads. We then also offer a managed Kubernetes", "timestamp": "00:02:32,696", "timestamp_s": 152.0}, {"text": "service which can also then utilize the GPU", "timestamp": "00:02:36,264", "timestamp_s": 156.0}, {"text": "nodes to help you orchestrate your machine learning and AI workloads.", "timestamp": "00:02:39,784", "timestamp_s": 159.0}, {"text": "So we then enable the deployment of workspaces in mlots platforms", "timestamp": "00:02:44,254", "timestamp_s": 164.0}, {"text": "from our vendor partners and this helps you manage your machine learning lifecycle.", "timestamp": "00:02:48,350", "timestamp_s": 168.0}, {"text": "And finally, we specialize in the serving and inference of pre", "timestamp": "00:02:53,414", "timestamp_s": 173.0}, {"text": "trained AI models and that\u0027s going to be the focus of my", "timestamp": "00:02:57,094", "timestamp_s": 177.0}, {"text": "talk today. So, as many of you know, when it comes", "timestamp": "00:03:00,550", "timestamp_s": 180.0}, {"text": "to training your large machine learning AI models,", "timestamp": "00:03:03,974", "timestamp_s": 183.0}, {"text": "you really care about compute performance in order to accelerate", "timestamp": "00:03:06,918", "timestamp_s": 186.0}, {"text": "your research and development. So to give you the best possible performance,", "timestamp": "00:03:10,746", "timestamp_s": 190.0}, {"text": "we partner with Nvidia so that all of our", "timestamp": "00:03:14,962", "timestamp_s": 194.0}, {"text": "GPU clusters are powered by 800 way a 100 or H", "timestamp": "00:03:18,106", "timestamp_s": 198.0}, {"text": "100 gpu\u0027s within Vlink.", "timestamp": "00:03:21,954", "timestamp_s": 201.0}, {"text": "But for really large training jobs that span multiple compute nodes,", "timestamp": "00:03:25,114", "timestamp_s": 205.0}, {"text": "it\u0027s equally important to have a very fast interconnect, providing direct", "timestamp": "00:03:29,274", "timestamp_s": 209.0}, {"text": "GPU connection across multiple nodes.", "timestamp": "00:03:33,582", "timestamp_s": 213.0}, {"text": "All of our clusters are also connected with the latest Infiniband.", "timestamp": "00:03:37,214", "timestamp_s": 217.0}, {"text": "But now, once you\u0027ve trained or perhaps fine tuned a large model", "timestamp": "00:03:41,094", "timestamp_s": 221.0}, {"text": "for your use case, the question arises,", "timestamp": "00:03:44,830", "timestamp_s": 224.0}, {"text": "where can I serve my model with low latency?", "timestamp": "00:03:48,254", "timestamp_s": 228.0}, {"text": "This is a really important question for several reasons,", "timestamp": "00:03:51,774", "timestamp_s": 231.0}, {"text": "the main one being because as you go from research and development to", "timestamp": "00:03:55,094", "timestamp_s": 235.0}, {"text": "production of a business application of AI,", "timestamp": "00:03:59,192", "timestamp_s": 239.0}, {"text": "your primary compute workload will move from training to", "timestamp": "00:04:02,384", "timestamp_s": 242.0}, {"text": "inference. For many business critical applications,", "timestamp": "00:04:06,224", "timestamp_s": 246.0}, {"text": "the end user needs a real time response, no matter", "timestamp": "00:04:10,104", "timestamp_s": 250.0}, {"text": "where they are in the world. And this is becoming more and more important", "timestamp": "00:04:14,088", "timestamp_s": 254.0}, {"text": "as the market is, of course rapidly evolving,", "timestamp": "00:04:18,592", "timestamp_s": 258.0}, {"text": "with an increasing number of businesses not only testing out AI", "timestamp": "00:04:21,520", "timestamp_s": 261.0}, {"text": "in pilots or group concepts, actually adopting", "timestamp": "00:04:25,144", "timestamp_s": 265.0}, {"text": "AI applications in full scale production at", "timestamp": "00:04:28,732", "timestamp_s": 268.0}, {"text": "enterprise scale. So as an example of that,", "timestamp": "00:04:32,692", "timestamp_s": 272.0}, {"text": "you can see here a survey last year from McKinsey,", "timestamp": "00:04:35,756", "timestamp_s": 275.0}, {"text": "from enterprise leaders, and it showcased how", "timestamp": "00:04:39,644", "timestamp_s": 279.0}, {"text": "over half of them are already adopting AI. And again,", "timestamp": "00:04:43,004", "timestamp_s": 283.0}, {"text": "it just showcases just how prevalent AI", "timestamp": "00:04:46,300", "timestamp_s": 286.0}, {"text": "is becoming, not only in pilots, but in actual production.", "timestamp": "00:04:49,772", "timestamp_s": 289.0}, {"text": "This not only drives the demand for inference compute,", "timestamp": "00:04:53,464", "timestamp_s": 293.0}, {"text": "but also the need for scalable, reliable, and secure", "timestamp": "00:04:56,720", "timestamp_s": 296.0}, {"text": "infrastructure that can maintain a very high level of service availability.", "timestamp": "00:05:00,104", "timestamp_s": 300.0}, {"text": "So, to give you an example, the application most of us are most familiar", "timestamp": "00:05:04,904", "timestamp_s": 304.0}, {"text": "with is probably chatbots. So take", "timestamp": "00:05:08,520", "timestamp_s": 308.0}, {"text": "an example here. You can see that if you take an", "timestamp": "00:05:11,712", "timestamp_s": 311.0}, {"text": "off the shelf model such as Mistral Seven B and", "timestamp": "00:05:15,248", "timestamp_s": 315.0}, {"text": "Runva locally, and I\u0027ve taken a reasonably", "timestamp": "00:05:19,020", "timestamp_s": 319.0}, {"text": "standard question around about 200 tokens, and got", "timestamp": "00:05:23,348", "timestamp_s": 323.0}, {"text": "an answer around 20 tokens back and running", "timestamp": "00:05:27,020", "timestamp_s": 327.0}, {"text": "that locally took around about 250 milliseconds.", "timestamp": "00:05:30,420", "timestamp_s": 330.0}, {"text": "Now, to an end user, that really feels like real time.", "timestamp": "00:05:34,604", "timestamp_s": 334.0}, {"text": "But now, supposing you were sitting, say, in Tokyo, and you were submitting", "timestamp": "00:05:38,284", "timestamp_s": 338.0}, {"text": "that request to a data center in the cloud in, say, the United States,", "timestamp": "00:05:42,172", "timestamp_s": 342.0}, {"text": "then just the network latency could easily double", "timestamp": "00:05:46,974", "timestamp_s": 346.0}, {"text": "or treble that at that time.", "timestamp": "00:05:50,270", "timestamp_s": 350.0}, {"text": "So that when you then add in all sort of the inference time, the end", "timestamp": "00:05:53,374", "timestamp_s": 353.0}, {"text": "to end processing could get close to a second,", "timestamp": "00:05:57,206", "timestamp_s": 357.0}, {"text": "which would really damage the user experience.", "timestamp": "00:06:00,694", "timestamp_s": 360.0}, {"text": "Of course, there are many other use cases where you really", "timestamp": "00:06:03,534", "timestamp_s": 363.0}, {"text": "care about a real time response, whether that\u0027s,", "timestamp": "00:06:06,838", "timestamp_s": 366.0}, {"text": "for example, autonomous driving or any sort of virtual live", "timestamp": "00:06:09,942", "timestamp_s": 369.0}, {"text": "streaming or even quality inspection use cases in industries", "timestamp": "00:06:13,514", "timestamp_s": 373.0}, {"text": "such as mining or manufacturing. For all these applications,", "timestamp": "00:06:17,578", "timestamp_s": 377.0}, {"text": "you of course need high performance compute for", "timestamp": "00:06:21,338", "timestamp_s": 381.0}, {"text": "the fast inference, but you also need very low", "timestamp": "00:06:25,642", "timestamp_s": 385.0}, {"text": "latency, and in many cases, it\u0027s also important for", "timestamp": "00:06:29,354", "timestamp_s": 389.0}, {"text": "regulatory or privacy reasons, that the data is processed locally.", "timestamp": "00:06:33,042", "timestamp_s": 393.0}, {"text": "And for us that means in an edge location that", "timestamp": "00:06:38,004", "timestamp_s": 398.0}, {"text": "is geographically close to the end user. So now,", "timestamp": "00:06:41,788", "timestamp_s": 401.0}, {"text": "supposing you\u0027re looking to run infront of", "timestamp": "00:06:45,108", "timestamp_s": 405.0}, {"text": "your model, if you want to achieve that in real time, then there are", "timestamp": "00:06:48,708", "timestamp_s": 408.0}, {"text": "three core requirements you have to work on.", "timestamp": "00:06:52,716", "timestamp_s": 412.0}, {"text": "The first of those is you need a distributed,", "timestamp": "00:06:56,044", "timestamp_s": 416.0}, {"text": "powerful compute infrastructure around the world.", "timestamp": "00:07:00,068", "timestamp_s": 420.0}, {"text": "But also you then need a very low latency backbone which", "timestamp": "00:07:03,704", "timestamp_s": 423.0}, {"text": "connects a compute. You then also need", "timestamp": "00:07:07,264", "timestamp_s": 427.0}, {"text": "runtime deployment and reconfigurability.", "timestamp": "00:07:10,728", "timestamp_s": 430.0}, {"text": "So let\u0027s start with the inference. And when", "timestamp": "00:07:13,984", "timestamp_s": 433.0}, {"text": "we looked at running inference at the edge here at", "timestamp": "00:07:17,560", "timestamp_s": 437.0}, {"text": "G core, we faced several challenges that required innovative solutions", "timestamp": "00:07:20,888", "timestamp_s": 440.0}, {"text": "to help optimize performance and efficiency.", "timestamp": "00:07:25,128", "timestamp_s": 445.0}, {"text": "I\u0027ll focus on LLMs here, as they are the technology", "timestamp": "00:07:28,524", "timestamp_s": 448.0}, {"text": "that gets the most attention in a minute. But of course, these techniques are", "timestamp": "00:07:33,292", "timestamp_s": 453.0}, {"text": "also relevant to other technologies. So the first strategy", "timestamp": "00:07:36,612", "timestamp_s": 456.0}, {"text": "that we used was operator fusion,", "timestamp": "00:07:40,388", "timestamp_s": 460.0}, {"text": "and by merging edge and operators, this helps streamline computational", "timestamp": "00:07:43,924", "timestamp_s": 463.0}, {"text": "tasks, which often leads to better latency and enhancing", "timestamp": "00:07:48,172", "timestamp_s": 468.0}, {"text": "the responsiveness of AI models. We also employed quantization,", "timestamp": "00:07:52,044", "timestamp_s": 472.0}, {"text": "which involves compressing the activations and weights of neural networks", "timestamp": "00:07:56,744", "timestamp_s": 476.0}, {"text": "so they require fewer bits. Another strategy", "timestamp": "00:08:00,448", "timestamp_s": 480.0}, {"text": "is compression with techniques such as Sparta T,", "timestamp": "00:08:03,744", "timestamp_s": 483.0}, {"text": "where we trim unnecessary connections, or distillation,", "timestamp": "00:08:07,184", "timestamp_s": 487.0}, {"text": "where we train smaller models to mimic larger ones.", "timestamp": "00:08:10,952", "timestamp_s": 490.0}, {"text": "Of course, with all these techniques, you\u0027ve also got to balance", "timestamp": "00:08:14,384", "timestamp_s": 494.0}, {"text": "the performance of the model with the accuracy and", "timestamp": "00:08:18,112", "timestamp_s": 498.0}, {"text": "making sure you don\u0027t lose too much accuracy. And finally,", "timestamp": "00:08:21,788", "timestamp_s": 501.0}, {"text": "the fourth technique, of course, is very well suited to", "timestamp": "00:08:25,444", "timestamp_s": 505.0}, {"text": "GPU\u0027s is parallelization. Typically,", "timestamp": "00:08:28,740", "timestamp_s": 508.0}, {"text": "we\u0027ve implemented tense parallelism, distributing computation across", "timestamp": "00:08:31,724", "timestamp_s": 511.0}, {"text": "multiple devices, and also pipeline parallelism to help", "timestamp": "00:08:35,444", "timestamp_s": 515.0}, {"text": "efficiently manage larger models and help scale up our", "timestamp": "00:08:39,252", "timestamp_s": 519.0}, {"text": "AI capabilities. So once we\u0027ve optimized", "timestamp": "00:08:42,564", "timestamp_s": 522.0}, {"text": "a computer model, the second piece of the puzzle is", "timestamp": "00:08:45,892", "timestamp_s": 525.0}, {"text": "a network latency. Now, on this slide, I\u0027m just", "timestamp": "00:08:49,470", "timestamp_s": 529.0}, {"text": "showing you a map which shows the growth of 5G", "timestamp": "00:08:53,214", "timestamp_s": 533.0}, {"text": "around the globe. And the reason I\u0027m sharing that is,", "timestamp": "00:08:57,118", "timestamp_s": 537.0}, {"text": "of course, over the last few years, 5G has enabled", "timestamp": "00:09:00,342", "timestamp_s": 540.0}, {"text": "many of us, perhaps all of us, to stream really high", "timestamp": "00:09:05,062", "timestamp_s": 545.0}, {"text": "quality content, such as videos, straight to our mobile devices,", "timestamp": "00:09:08,222", "timestamp_s": 548.0}, {"text": "because of the ultra low latency that 5G", "timestamp": "00:09:13,294", "timestamp_s": 553.0}, {"text": "provides. So we\u0027ve taken those learnings,", "timestamp": "00:09:16,726", "timestamp_s": 556.0}, {"text": "look to apply them also to AI. And so by", "timestamp": "00:09:21,014", "timestamp_s": 561.0}, {"text": "leveraging our CDN network with 180 points of", "timestamp": "00:09:24,734", "timestamp_s": 564.0}, {"text": "presence, what that means is that a user request will", "timestamp": "00:09:28,198", "timestamp_s": 568.0}, {"text": "take just an average of 30 milliseconds end to end, to get", "timestamp": "00:09:32,110", "timestamp_s": 572.0}, {"text": "to our network and back, and then perhaps a total of around 50", "timestamp": "00:09:35,438", "timestamp_s": 575.0}, {"text": "milliseconds to then get to an inference node where the actual", "timestamp": "00:09:38,846", "timestamp_s": 578.0}, {"text": "machine inference takes place. And so that round trip", "timestamp": "00:09:42,800", "timestamp_s": 582.0}, {"text": "of around 50 milliseconds very fast", "timestamp": "00:09:46,152", "timestamp_s": 586.0}, {"text": "compared to perhaps a few hundred milliseconds in a typical public", "timestamp": "00:09:49,616", "timestamp_s": 589.0}, {"text": "cloud setting. So what that means is that provided you\u0027ve also optimized", "timestamp": "00:09:53,368", "timestamp_s": 593.0}, {"text": "the model inference, so that it takes perhaps between 104", "timestamp": "00:09:58,280", "timestamp_s": 598.0}, {"text": "hundred milliseconds, you can achieve an end to", "timestamp": "00:10:01,928", "timestamp_s": 601.0}, {"text": "end processing time of under half a second.", "timestamp": "00:10:05,296", "timestamp_s": 605.0}, {"text": "And that\u0027s important because around half a second is around", "timestamp": "00:10:09,144", "timestamp_s": 609.0}, {"text": "about the time which as a human we perceive that to", "timestamp": "00:10:12,784", "timestamp_s": 612.0}, {"text": "be in real time. Any slower, you start to notice that lag.", "timestamp": "00:10:15,880", "timestamp_s": 615.0}, {"text": "So again, to put that into more context, I said if you", "timestamp": "00:10:20,424", "timestamp_s": 620.0}, {"text": "combine a very low latency network combined with", "timestamp": "00:10:23,952", "timestamp_s": 623.0}, {"text": "an optimized inference round trip in under half a second,", "timestamp": "00:10:27,448", "timestamp_s": 627.0}, {"text": "and that\u0027s applicable to a number of technologies.", "timestamp": "00:10:31,824", "timestamp_s": 631.0}, {"text": "So for example, automatic speech recognition,", "timestamp": "00:10:35,080", "timestamp_s": 635.0}, {"text": "object detection, or text speech are all", "timestamp": "00:10:38,244", "timestamp_s": 638.0}, {"text": "examples where this enables a real time", "timestamp": "00:10:41,684", "timestamp_s": 641.0}, {"text": "response. So then the final piece of the puzzle,", "timestamp": "00:10:45,556", "timestamp_s": 645.0}, {"text": "we\u0027ve had to work on runtime deployment", "timestamp": "00:10:48,676", "timestamp_s": 648.0}, {"text": "and reconfigurability in a simple and scalable", "timestamp": "00:10:52,308", "timestamp_s": 652.0}, {"text": "manner to really enable this inference at the edge, at scale.", "timestamp": "00:10:55,428", "timestamp_s": 655.0}, {"text": "So to do this, we achieved this using a container", "timestamp": "00:11:00,124", "timestamp_s": 660.0}, {"text": "as a service technology, so that we provide a single", "timestamp": "00:11:03,394", "timestamp_s": 663.0}, {"text": "anycast endpoint that can be easily connected to a developer\u0027s", "timestamp": "00:11:07,298", "timestamp_s": 667.0}, {"text": "application. So what that means is that", "timestamp": "00:11:11,402", "timestamp_s": 671.0}, {"text": "no matter where in the world an end user is, the request to that", "timestamp": "00:11:14,554", "timestamp_s": 674.0}, {"text": "endpoint is routed to the nearest CDN node and from", "timestamp": "00:11:18,602", "timestamp_s": 678.0}, {"text": "there to the nearest inference node. So if we delve", "timestamp": "00:11:22,114", "timestamp_s": 682.0}, {"text": "into a little bit more detail, you can see what\u0027s happening here under", "timestamp": "00:11:25,914", "timestamp_s": 685.0}, {"text": "the hood. I apologize, a little bit small, but hopefully you can follow it.", "timestamp": "00:11:29,626", "timestamp_s": 689.0}, {"text": "So at the top here, supposing you have a two end", "timestamp": "00:11:34,244", "timestamp_s": 694.0}, {"text": "users, and let\u0027s say one of those is in rear vision Aero", "timestamp": "00:11:38,052", "timestamp_s": 698.0}, {"text": "and one of those in say Kyoto. Now, the anycast", "timestamp": "00:11:41,996", "timestamp_s": 701.0}, {"text": "endpoint is available globally. When each of those", "timestamp": "00:11:45,620", "timestamp_s": 705.0}, {"text": "users sends the request, that request will go to their local CDN", "timestamp": "00:11:49,140", "timestamp_s": 709.0}, {"text": "node, the user in Kyoto. There might be a CDN node in", "timestamp": "00:11:53,244", "timestamp_s": 713.0}, {"text": "Kyoto itself. And similarly for revision Arrow, that request", "timestamp": "00:11:56,828", "timestamp_s": 716.0}, {"text": "would go to the revision Arrow CDN node. Now after that", "timestamp": "00:12:00,526", "timestamp_s": 720.0}, {"text": "we developed smart routing technology,", "timestamp": "00:12:04,926", "timestamp_s": 724.0}, {"text": "and what that does is it routes the request to", "timestamp": "00:12:08,494", "timestamp_s": 728.0}, {"text": "the nearest available inference region. So that\u0027s where we have some", "timestamp": "00:12:12,390", "timestamp_s": 732.0}, {"text": "high performance compute, typically gpu\u0027s that will do the actual", "timestamp": "00:12:16,830", "timestamp_s": 736.0}, {"text": "optimized inference. Now what that means is", "timestamp": "00:12:21,102", "timestamp_s": 741.0}, {"text": "that not only does it guarantee the fastest response time for each", "timestamp": "00:12:24,258", "timestamp_s": 744.0}, {"text": "of these individually, but it also ensures that the", "timestamp": "00:12:28,082", "timestamp_s": 748.0}, {"text": "processing and the model itself also stay locally.", "timestamp": "00:12:31,634", "timestamp_s": 751.0}, {"text": "So in particular, the user in Kyoto, the inference", "timestamp": "00:12:35,682", "timestamp_s": 755.0}, {"text": "will be in state Tokyo and their data, and that model", "timestamp": "00:12:39,474", "timestamp_s": 759.0}, {"text": "will only ever be in Tokyo. And likewise for the user", "timestamp": "00:12:43,546", "timestamp_s": 763.0}, {"text": "in Rio, in Brazil, their model and their arrangement would also take place", "timestamp": "00:12:46,906", "timestamp_s": 766.0}, {"text": "locally in Brazil. That also actually means you", "timestamp": "00:12:51,108", "timestamp_s": 771.0}, {"text": "could potentially have a different model in each region. So, for example,", "timestamp": "00:12:54,468", "timestamp_s": 774.0}, {"text": "you could have a model that was trained only on japanese user data", "timestamp": "00:12:58,276", "timestamp_s": 778.0}, {"text": "in Japan, and similarly for other world regions.", "timestamp": "00:13:01,796", "timestamp_s": 781.0}, {"text": "And so that also helps maintain that sort of data privacy and", "timestamp": "00:13:05,884", "timestamp_s": 785.0}, {"text": "locality that I was talking about earlier. The final piece", "timestamp": "00:13:09,268", "timestamp_s": 789.0}, {"text": "of puzzle that I want to talk about here is that in each of these", "timestamp": "00:13:12,948", "timestamp_s": 792.0}, {"text": "regions, we also have developed auto scaling", "timestamp": "00:13:16,036", "timestamp_s": 796.0}, {"text": "autoscaling functionality.", "timestamp": "00:13:19,672", "timestamp_s": 799.0}, {"text": "So what that means is that the amount of compute scales", "timestamp": "00:13:22,624", "timestamp_s": 802.0}, {"text": "up and down with demand. And that\u0027s really important because", "timestamp": "00:13:26,000", "timestamp_s": 806.0}, {"text": "it means that you can scale up the compute when you need it, when there\u0027s", "timestamp": "00:13:29,552", "timestamp_s": 809.0}, {"text": "lots of demand. But equally importantly, you can scale back down again when there", "timestamp": "00:13:32,248", "timestamp_s": 812.0}, {"text": "isn\u0027t. And also that means you\u0027re not then paying for compute", "timestamp": "00:13:36,040", "timestamp_s": 816.0}, {"text": "when you don\u0027t use it. So, tying all these things together,", "timestamp": "00:13:40,120", "timestamp_s": 820.0}, {"text": "I\u0027ll just summarize by putting together our sort of full end to end", "timestamp": "00:13:44,464", "timestamp_s": 824.0}, {"text": "architecture, and you\u0027ll see that we\u0027ve combined high", "timestamp": "00:13:48,680", "timestamp_s": 828.0}, {"text": "performance AI training infrastructure, and then that", "timestamp": "00:13:51,880", "timestamp_s": 831.0}, {"text": "could be in a public cloud setting. Thus, for some customers where", "timestamp": "00:13:55,072", "timestamp_s": 835.0}, {"text": "privacy is really important, we could also offer it in a private cloud setting.", "timestamp": "00:13:58,640", "timestamp_s": 838.0}, {"text": "And then if you combine that with this infinite set, this low network,", "timestamp": "00:14:02,944", "timestamp_s": 842.0}, {"text": "and the infinite edge technology we\u0027re talking about today,", "timestamp": "00:14:06,944", "timestamp_s": 846.0}, {"text": "you have a comprehensive global AIoT", "timestamp": "00:14:10,284", "timestamp_s": 850.0}, {"text": "architecture that we believe is fit for today\u0027s most demanding and", "timestamp": "00:14:14,020", "timestamp_s": 854.0}, {"text": "scalable AI applications. So with that,", "timestamp": "00:14:17,812", "timestamp_s": 857.0}, {"text": "that\u0027s probably enough of me talking. What I\u0027ll showcase here,", "timestamp": "00:14:21,356", "timestamp_s": 861.0}, {"text": "a few demos that showcase technology in action.", "timestamp": "00:14:24,932", "timestamp_s": 864.0}, {"text": "So the first of those is an example with a real time face", "timestamp": "00:14:28,524", "timestamp_s": 868.0}, {"text": "avatar. And what you\u0027ll see here is at the top here, I\u0027ll be entering", "timestamp": "00:14:32,412", "timestamp_s": 872.0}, {"text": "in some prompts. And what you should look out for is the", "timestamp": "00:14:36,588", "timestamp_s": 876.0}, {"text": "way that the avatar of the person changes", "timestamp": "00:14:40,226", "timestamp_s": 880.0}, {"text": "in real time as I type in those prompts.", "timestamp": "00:14:43,658", "timestamp_s": 883.0}, {"text": "So for example, here, I\u0027m going to type in portrait of Elon Musk.", "timestamp": "00:14:47,154", "timestamp_s": 887.0}, {"text": "And you see that the face has changed, Elon Musk", "timestamp": "00:14:50,322", "timestamp_s": 890.0}, {"text": "almost immediately. And now as I type Bill Gates again, that change", "timestamp": "00:14:53,874", "timestamp_s": 893.0}, {"text": "was done in real time. And now moving on to Madonna", "timestamp": "00:14:58,106", "timestamp_s": 898.0}, {"text": "and a few more examples here. But again, what\u0027s really impressive", "timestamp": "00:15:02,354", "timestamp_s": 902.0}, {"text": "is the way that the change is done in real time compared", "timestamp": "00:15:05,932", "timestamp_s": 905.0}, {"text": "to the typing of the prompt there. There\u0027s a Jeff Bezos", "timestamp": "00:15:09,852", "timestamp_s": 909.0}, {"text": "when he had hair. So, another example I", "timestamp": "00:15:13,916", "timestamp_s": 913.0}, {"text": "can show you here is of real time translation from English", "timestamp": "00:15:17,228", "timestamp_s": 917.0}, {"text": "to Luxembourgish. Now, like most", "timestamp": "00:15:21,268", "timestamp_s": 921.0}, {"text": "people in the world, I don\u0027t speak Luxembourgish, which is a", "timestamp": "00:15:24,412", "timestamp_s": 924.0}, {"text": "local language of Luxembourg. But if I was in", "timestamp": "00:15:28,052", "timestamp_s": 928.0}, {"text": "our head office and I needed to quickly translate something,", "timestamp": "00:15:31,568", "timestamp_s": 931.0}, {"text": "then no problem. I could use a typical translation", "timestamp": "00:15:34,672", "timestamp_s": 934.0}, {"text": "tool. Hello there. Allow me to introduce myself.", "timestamp": "00:15:38,608", "timestamp_s": 938.0}, {"text": "I am an advanced machine learning model specifically designed for", "timestamp": "00:15:43,024", "timestamp_s": 943.0}, {"text": "voice to text translation from English to Luxembourgish.", "timestamp": "00:15:46,504", "timestamp_s": 946.0}, {"text": "I have been created and powered by the cutting edge technology of G", "timestamp": "00:15:50,424", "timestamp_s": 950.0}, {"text": "core AI cloud. Great. And I\u0027ll press send,", "timestamp": "00:15:54,344", "timestamp_s": 954.0}, {"text": "and you\u0027ll see that again in less than a second.", "timestamp": "00:15:59,084", "timestamp_s": 959.0}, {"text": "Less half a second, I\u0027d say. The translation happened,", "timestamp": "00:16:02,252", "timestamp_s": 962.0}, {"text": "and I\u0027ve received the luxembourgish translation", "timestamp": "00:16:06,044", "timestamp_s": 966.0}, {"text": "of those words again, I really showcased, from the minute", "timestamp": "00:16:09,740", "timestamp_s": 969.0}, {"text": "I pressed send, the processing was in almost real time.", "timestamp": "00:16:13,220", "timestamp_s": 973.0}, {"text": "So, in the final example I\u0027ll show you today is some work", "timestamp": "00:16:17,364", "timestamp_s": 977.0}, {"text": "we\u0027ve done with our colleagues at let\u0027s AI.", "timestamp": "00:16:20,852", "timestamp_s": 980.0}, {"text": "Let\u0027s AI are a creative platform that allows you to generate images for", "timestamp": "00:16:24,564", "timestamp_s": 984.0}, {"text": "anything, you know, simply by tagging it in a text.", "timestamp": "00:16:28,132", "timestamp_s": 988.0}, {"text": "We\u0027ve worked with, let\u0027s see, I over the last few months, and they\u0027ve been utilizing", "timestamp": "00:16:31,604", "timestamp_s": 991.0}, {"text": "our H 100 AI infrastructure and inference", "timestamp": "00:16:34,956", "timestamp_s": 994.0}, {"text": "services to both train their Generali models and", "timestamp": "00:16:38,852", "timestamp_s": 998.0}, {"text": "also serve them to their customers worldwide.", "timestamp": "00:16:42,100", "timestamp_s": 1002.0}, {"text": "So what you see here is an example of a single image that was generated", "timestamp": "00:16:45,764", "timestamp_s": 1005.0}, {"text": "by the platform. But I think what\u0027s really impressive", "timestamp": "00:16:49,452", "timestamp_s": 1009.0}, {"text": "is that you can actually take a series of images", "timestamp": "00:16:52,722", "timestamp_s": 1012.0}, {"text": "generated by the platform and then combine", "timestamp": "00:16:56,490", "timestamp_s": 1016.0}, {"text": "together to form a video. So this is", "timestamp": "00:17:00,026", "timestamp_s": 1020.0}, {"text": "an example of a video generated with Lepsey Eye,", "timestamp": "00:17:03,266", "timestamp_s": 1023.0}, {"text": "which I think really shows the power of generative AI powered", "timestamp": "00:17:06,874", "timestamp_s": 1026.0}, {"text": "by GPU infrastructure.", "timestamp": "00:17:10,538", "timestamp_s": 1030.0}, {"text": "The rookie sensation Ricky Malone says surprises with an unbelievable", "timestamp": "00:17:16,874", "timestamp_s": 1036.0}, {"text": "pole position at silver. It looks like Ricky Malone is joining forces with the", "timestamp": "00:17:20,468", "timestamp_s": 1040.0}, {"text": "legendary f one team for the 1986 season.", "timestamp": "00:17:23,860", "timestamp_s": 1043.0}, {"text": "Ricky, after our crash, watching you lose yourself", "timestamp": "00:17:26,860", "timestamp_s": 1046.0}, {"text": "was hard. Not just because of us, but seeing you", "timestamp": "00:17:30,076", "timestamp_s": 1050.0}, {"text": "give into darkness. It wasn\u0027t only about you.", "timestamp": "00:17:33,308", "timestamp_s": 1053.0}, {"text": "I was hurt, too, trapped by resentment,", "timestamp": "00:17:37,188", "timestamp_s": 1057.0}, {"text": "encouraging you to race again, to face that trauma.", "timestamp": "00:17:40,524", "timestamp_s": 1060.0}, {"text": "It\u0027s for both of us. Us. I need to see you conquer this.", "timestamp": "00:17:43,844", "timestamp_s": 1063.0}, {"text": "Not to go back to what we had, but to find closure", "timestamp": "00:17:47,934", "timestamp_s": 1067.0}, {"text": "for both of us to move on. This is about letting go,", "timestamp": "00:17:51,550", "timestamp_s": 1071.0}, {"text": "forgiving each other, healing. By helping you return", "timestamp": "00:17:55,222", "timestamp_s": 1075.0}, {"text": "to the track, I\u0027m also finding my way back. It\u0027s about finding", "timestamp": "00:17:58,926", "timestamp_s": 1078.0}, {"text": "peace, Ricky, for you and for me.", "timestamp": "00:18:03,142", "timestamp_s": 1083.0}, {"text": "So there you go. A completely generated video that I", "timestamp": "00:18:16,234", "timestamp_s": 1096.0}, {"text": "certainly found very impressive. So we\u0027re almost at the end of the talk", "timestamp": "00:18:20,674", "timestamp_s": 1100.0}, {"text": "here, and just want to let you know that if", "timestamp": "00:18:24,234", "timestamp_s": 1104.0}, {"text": "you\u0027re interested in learning more about technology, our infrastructure, the edge", "timestamp": "00:18:27,802", "timestamp_s": 1107.0}, {"text": "product is actually being launched in beta this week.", "timestamp": "00:18:31,690", "timestamp_s": 1111.0}, {"text": "So this lets you deploy your model globally with", "timestamp": "00:18:35,274", "timestamp_s": 1115.0}, {"text": "a single endpoint, as I explained. Or you can also", "timestamp": "00:18:38,538", "timestamp_s": 1118.0}, {"text": "choose an open source model out of the box from a model catalog,", "timestamp": "00:18:41,938", "timestamp_s": 1121.0}, {"text": "which includes popular models such as mistral unstable", "timestamp": "00:18:46,018", "timestamp_s": 1126.0}, {"text": "diffusion. So this gives you a serverless AI compute with", "timestamp": "00:18:49,586", "timestamp_s": 1129.0}, {"text": "very low latency around the world on a pay as you go model", "timestamp": "00:18:53,922", "timestamp_s": 1133.0}, {"text": "with DDoS endpoint protection. But also, as this is our", "timestamp": "00:18:57,762", "timestamp_s": 1137.0}, {"text": "beta service, it\u0027s also free. So if you\u0027d like to try", "timestamp": "00:19:01,858", "timestamp_s": 1141.0}, {"text": "it, I\u0027d love to hear from you, find out about your machine learning", "timestamp": "00:19:05,350", "timestamp_s": 1145.0}, {"text": "use case, and see whether edge computing could", "timestamp": "00:19:09,262", "timestamp_s": 1149.0}, {"text": "be the right solution for you. And I\u0027ll just end the same. But of course,", "timestamp": "00:19:12,798", "timestamp_s": 1152.0}, {"text": "our work doesn\u0027t end here. The team is striving", "timestamp": "00:19:16,462", "timestamp_s": 1156.0}, {"text": "to push the limits of our network and bring down the latency", "timestamp": "00:19:19,974", "timestamp_s": 1159.0}, {"text": "to just a few tens of milliseconds, and we believe this", "timestamp": "00:19:23,662", "timestamp_s": 1163.0}, {"text": "will further benefit sort of really mission", "timestamp": "00:19:26,950", "timestamp_s": 1166.0}, {"text": "critical use cases of AI at the edge.", "timestamp": "00:19:30,538", "timestamp_s": 1170.0}, {"text": "So with that, I hope you\u0027ve enjoyed the talk. Thank you for", "timestamp": "00:19:33,674", "timestamp_s": 1173.0}, {"text": "joining me today. And again, please do reach out if you have any", "timestamp": "00:19:37,098", "timestamp_s": 1177.0}, {"text": "questions or would like to discuss any of the technologies that I\u0027ve spoken", "timestamp": "00:19:40,674", "timestamp_s": 1180.0}, {"text": "about today, but for now, have a great conference.", "timestamp": "00:19:44,282", "timestamp_s": 1184.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'jyM0f5Gy9gA',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Global Intelligence Pipeline: How We’re Crafting Inference at the Edge
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>AI is a hot and rapidly developing topic in the cloud space. In this session, topics covered will include market trends, future directions, training, and inference. Get up to date on the latest AI trends and news, including the value cloud can deliver to AI and Gcore&rsquo;s Inference at the Edge, including real-life scenarios where the company helped customers using AI</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                GCor is a global cloud edge and AI solutions provider. Our vision is to connect the world to AI anywhere, anytime. The cornerstone of the company is our secure low latency network. Today, I'm going to focus on our AI as a service offerings.

              </li>
              
              <li>
                We leverage our CDN network with 180 points of presence. A user request will take just an average of 30 milliseconds end to end. And then perhaps a total of around 50 milliseconds to then get to an inference node where the actual machine inference takes place. Combined with an optimized inference round trip in under half a second.

              </li>
              
              <li>
                An example with a real time face avatar. Another example of real time translation from English to Luxembourgish. Created and powered by the cutting edge technology of G core AI cloud. From the minute I pressed send, the processing was in almost real time.

              </li>
              
              <li>
                Let's AI are a creative platform that allows you to generate images for anything. You can actually take a series of images generated by the platform and then combine together to form a video. It really shows the power of generative AI powered by GPU infrastructure.

              </li>
              
              <li>
                 edge product is actually being launched in beta this week. This gives you a serverless AI compute with very low latency around the world on a pay as you go model with DDoS endpoint protection. If you'd like to try it, I'd love to hear from you.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/jyM0f5Gy9gA.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:27,320'); seek(27.0)">
              Hi everyone, my name is Nikhil Taroni, head of AI products
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:31,168'); seek(31.0)">
              at GCor. First of all, thank you very much to the organizer of
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:34,608'); seek(34.0)">
              Conf 42 for having me here today, and I'm really
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:37,752'); seek(37.0)">
              excited to talk to you about our pioneering work building our global
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:41,400'); seek(41.0)">
              intelligence pipeline and its cornerstone technology inference
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:45,704'); seek(45.0)">
              at the edge. And during the talk, feel free
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:48,912'); seek(48.0)">
              to ping me on slack with any questions or comments and I'll do
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:52,160'); seek(52.0)">
              my best to answer. But for now, let's dive in.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:56,444'); seek(56.0)">
              As I'm here on behalf of GCor, let me begin by telling
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:59,972'); seek(59.0)">
              you a little bit more about us. We are a global
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:03,812'); seek(63.0)">
              cloud edge and AI solutions provider headquartered
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:08,332'); seek(68.0)">
              in Luxembourg, but with a global presence and
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:11,980'); seek(71.0)">
              our vision is to connect the world to AI anywhere,
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:15,940'); seek(75.0)">
              anytime. The cornerstone of the company is
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:19,790'); seek(79.0)">
              our secure low latency network, which consists of over 180
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:24,534'); seek(84.0)">
              CDN points of presence and 25 cloud locations,
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:28,974'); seek(88.0)">
              giving us an average response time of just 30 milliseconds.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:33,494'); seek(93.0)">
              We offer a range of cloud services covering infrastructure
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:37,038'); seek(97.0)">
              as a service, multi platform as a service.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:40,534'); seek(100.0)">
              But today, as we go at a machine learning conference,
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:43,846'); seek(103.0)">
              I'm going to focus on our AI as a service offerings and some of
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:47,186'); seek(107.0)">
              the work we've done there. To begin, we offer a range of
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:51,634'); seek(111.0)">
              AI services including GPU, bare metal
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:54,882'); seek(114.0)">
              and virtual machine instances, managed kubernetes clusters,
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:58,642'); seek(118.0)">
              and also a 5g platform that helps reduce the latency between
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:02:02,338'); seek(122.0)">
              your device and the model. But all of these services
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:05,858'); seek(125.0)">
              underpins what we call our global intelligence pipeline,
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:10,314'); seek(130.0)">
              which is designed to follow the steps taken by machine learning practitioners to
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:14,344'); seek(134.0)">
              train, deploy and scale AI applications
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:17,720'); seek(137.0)">
              in production. So starting on the left there,
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:21,504'); seek(141.0)">
              you can see that we offer direct access to high performance
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:24,968'); seek(144.0)">
              AI infrastructure acted by Nvidia GPU's.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:29,144'); seek(149.0)">
              This provides the raw computing power needed for intense AI training
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:32,696'); seek(152.0)">
              workloads. We then also offer a managed Kubernetes
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:36,264'); seek(156.0)">
              service which can also then utilize the GPU
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:39,784'); seek(159.0)">
              nodes to help you orchestrate your machine learning and AI workloads.
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:44,254'); seek(164.0)">
              So we then enable the deployment of workspaces in mlots platforms
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:48,350'); seek(168.0)">
              from our vendor partners and this helps you manage your machine learning lifecycle.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:53,414'); seek(173.0)">
              And finally, we specialize in the serving and inference of pre
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:57,094'); seek(177.0)">
              trained AI models and that's going to be the focus of my
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:00,550'); seek(180.0)">
              talk today. So, as many of you know, when it comes
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:03,974'); seek(183.0)">
              to training your large machine learning AI models,
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:06,918'); seek(186.0)">
              you really care about compute performance in order to accelerate
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:10,746'); seek(190.0)">
              your research and development. So to give you the best possible performance,
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:14,962'); seek(194.0)">
              we partner with Nvidia so that all of our
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:18,106'); seek(198.0)">
              GPU clusters are powered by 800 way a 100 or H
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:21,954'); seek(201.0)">
              100 gpu's within Vlink.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:25,114'); seek(205.0)">
              But for really large training jobs that span multiple compute nodes,
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:29,274'); seek(209.0)">
              it's equally important to have a very fast interconnect, providing direct
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:33,582'); seek(213.0)">
              GPU connection across multiple nodes.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:37,214'); seek(217.0)">
              All of our clusters are also connected with the latest Infiniband.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:41,094'); seek(221.0)">
              But now, once you've trained or perhaps fine tuned a large model
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:44,830'); seek(224.0)">
              for your use case, the question arises,
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:48,254'); seek(228.0)">
              where can I serve my model with low latency?
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:51,774'); seek(231.0)">
              This is a really important question for several reasons,
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:55,094'); seek(235.0)">
              the main one being because as you go from research and development to
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:59,192'); seek(239.0)">
              production of a business application of AI,
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:02,384'); seek(242.0)">
              your primary compute workload will move from training to
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:06,224'); seek(246.0)">
              inference. For many business critical applications,
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:10,104'); seek(250.0)">
              the end user needs a real time response, no matter
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:14,088'); seek(254.0)">
              where they are in the world. And this is becoming more and more important
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:18,592'); seek(258.0)">
              as the market is, of course rapidly evolving,
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:21,520'); seek(261.0)">
              with an increasing number of businesses not only testing out AI
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:25,144'); seek(265.0)">
              in pilots or group concepts, actually adopting
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:28,732'); seek(268.0)">
              AI applications in full scale production at
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:32,692'); seek(272.0)">
              enterprise scale. So as an example of that,
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:35,756'); seek(275.0)">
              you can see here a survey last year from McKinsey,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:39,644'); seek(279.0)">
              from enterprise leaders, and it showcased how
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:43,004'); seek(283.0)">
              over half of them are already adopting AI. And again,
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:46,300'); seek(286.0)">
              it just showcases just how prevalent AI
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:04:49,772'); seek(289.0)">
              is becoming, not only in pilots, but in actual production.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:04:53,464'); seek(293.0)">
              This not only drives the demand for inference compute,
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:04:56,720'); seek(296.0)">
              but also the need for scalable, reliable, and secure
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:00,104'); seek(300.0)">
              infrastructure that can maintain a very high level of service availability.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:04,904'); seek(304.0)">
              So, to give you an example, the application most of us are most familiar
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:08,520'); seek(308.0)">
              with is probably chatbots. So take
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:11,712'); seek(311.0)">
              an example here. You can see that if you take an
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:15,248'); seek(315.0)">
              off the shelf model such as Mistral Seven B and
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:19,020'); seek(319.0)">
              Runva locally, and I've taken a reasonably
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:23,348'); seek(323.0)">
              standard question around about 200 tokens, and got
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:27,020'); seek(327.0)">
              an answer around 20 tokens back and running
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:30,420'); seek(330.0)">
              that locally took around about 250 milliseconds.
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:34,604'); seek(334.0)">
              Now, to an end user, that really feels like real time.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:38,284'); seek(338.0)">
              But now, supposing you were sitting, say, in Tokyo, and you were submitting
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:42,172'); seek(342.0)">
              that request to a data center in the cloud in, say, the United States,
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:46,974'); seek(346.0)">
              then just the network latency could easily double
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:05:50,270'); seek(350.0)">
              or treble that at that time.
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:05:53,374'); seek(353.0)">
              So that when you then add in all sort of the inference time, the end
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:05:57,206'); seek(357.0)">
              to end processing could get close to a second,
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:00,694'); seek(360.0)">
              which would really damage the user experience.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:03,534'); seek(363.0)">
              Of course, there are many other use cases where you really
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:06,838'); seek(366.0)">
              care about a real time response, whether that's,
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:09,942'); seek(369.0)">
              for example, autonomous driving or any sort of virtual live
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:13,514'); seek(373.0)">
              streaming or even quality inspection use cases in industries
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:17,578'); seek(377.0)">
              such as mining or manufacturing. For all these applications,
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:21,338'); seek(381.0)">
              you of course need high performance compute for
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:25,642'); seek(385.0)">
              the fast inference, but you also need very low
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:29,354'); seek(389.0)">
              latency, and in many cases, it's also important for
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:33,042'); seek(393.0)">
              regulatory or privacy reasons, that the data is processed locally.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:38,004'); seek(398.0)">
              And for us that means in an edge location that
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:41,788'); seek(401.0)">
              is geographically close to the end user. So now,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:06:45,108'); seek(405.0)">
              supposing you're looking to run infront of
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:06:48,708'); seek(408.0)">
              your model, if you want to achieve that in real time, then there are
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:06:52,716'); seek(412.0)">
              three core requirements you have to work on.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:06:56,044'); seek(416.0)">
              The first of those is you need a distributed,
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:00,068'); seek(420.0)">
              powerful compute infrastructure around the world.
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:03,704'); seek(423.0)">
              But also you then need a very low latency backbone which
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:07,264'); seek(427.0)">
              connects a compute. You then also need
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:10,728'); seek(430.0)">
              runtime deployment and reconfigurability.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:13,984'); seek(433.0)">
              So let's start with the inference. And when
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:17,560'); seek(437.0)">
              we looked at running inference at the edge here at
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:20,888'); seek(440.0)">
              G core, we faced several challenges that required innovative solutions
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:25,128'); seek(445.0)">
              to help optimize performance and efficiency.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:28,524'); seek(448.0)">
              I'll focus on LLMs here, as they are the technology
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:33,292'); seek(453.0)">
              that gets the most attention in a minute. But of course, these techniques are
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:36,612'); seek(456.0)">
              also relevant to other technologies. So the first strategy
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:07:40,388'); seek(460.0)">
              that we used was operator fusion,
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:07:43,924'); seek(463.0)">
              and by merging edge and operators, this helps streamline computational
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:07:48,172'); seek(468.0)">
              tasks, which often leads to better latency and enhancing
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:07:52,044'); seek(472.0)">
              the responsiveness of AI models. We also employed quantization,
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:07:56,744'); seek(476.0)">
              which involves compressing the activations and weights of neural networks
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:00,448'); seek(480.0)">
              so they require fewer bits. Another strategy
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:03,744'); seek(483.0)">
              is compression with techniques such as Sparta T,
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:07,184'); seek(487.0)">
              where we trim unnecessary connections, or distillation,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:10,952'); seek(490.0)">
              where we train smaller models to mimic larger ones.
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:14,384'); seek(494.0)">
              Of course, with all these techniques, you've also got to balance
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:18,112'); seek(498.0)">
              the performance of the model with the accuracy and
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:21,788'); seek(501.0)">
              making sure you don't lose too much accuracy. And finally,
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:25,444'); seek(505.0)">
              the fourth technique, of course, is very well suited to
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:28,740'); seek(508.0)">
              GPU's is parallelization. Typically,
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:31,724'); seek(511.0)">
              we've implemented tense parallelism, distributing computation across
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:35,444'); seek(515.0)">
              multiple devices, and also pipeline parallelism to help
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:08:39,252'); seek(519.0)">
              efficiently manage larger models and help scale up our
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:08:42,564'); seek(522.0)">
              AI capabilities. So once we've optimized
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:08:45,892'); seek(525.0)">
              a computer model, the second piece of the puzzle is
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:08:49,470'); seek(529.0)">
              a network latency. Now, on this slide, I'm just
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:08:53,214'); seek(533.0)">
              showing you a map which shows the growth of 5G
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:08:57,118'); seek(537.0)">
              around the globe. And the reason I'm sharing that is,
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:00,342'); seek(540.0)">
              of course, over the last few years, 5G has enabled
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:05,062'); seek(545.0)">
              many of us, perhaps all of us, to stream really high
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:08,222'); seek(548.0)">
              quality content, such as videos, straight to our mobile devices,
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:13,294'); seek(553.0)">
              because of the ultra low latency that 5G
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:16,726'); seek(556.0)">
              provides. So we've taken those learnings,
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:21,014'); seek(561.0)">
              look to apply them also to AI. And so by
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:24,734'); seek(564.0)">
              leveraging our CDN network with 180 points of
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:28,198'); seek(568.0)">
              presence, what that means is that a user request will
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:32,110'); seek(572.0)">
              take just an average of 30 milliseconds end to end, to get
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:09:35,438'); seek(575.0)">
              to our network and back, and then perhaps a total of around 50
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:09:38,846'); seek(578.0)">
              milliseconds to then get to an inference node where the actual
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:09:42,800'); seek(582.0)">
              machine inference takes place. And so that round trip
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:09:46,152'); seek(586.0)">
              of around 50 milliseconds very fast
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:09:49,616'); seek(589.0)">
              compared to perhaps a few hundred milliseconds in a typical public
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:09:53,368'); seek(593.0)">
              cloud setting. So what that means is that provided you've also optimized
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:09:58,280'); seek(598.0)">
              the model inference, so that it takes perhaps between 104
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:01,928'); seek(601.0)">
              hundred milliseconds, you can achieve an end to
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:05,296'); seek(605.0)">
              end processing time of under half a second.
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:09,144'); seek(609.0)">
              And that's important because around half a second is around
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:12,784'); seek(612.0)">
              about the time which as a human we perceive that to
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:15,880'); seek(615.0)">
              be in real time. Any slower, you start to notice that lag.
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:20,424'); seek(620.0)">
              So again, to put that into more context, I said if you
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:23,952'); seek(623.0)">
              combine a very low latency network combined with
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:27,448'); seek(627.0)">
              an optimized inference round trip in under half a second,
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:31,824'); seek(631.0)">
              and that's applicable to a number of technologies.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:10:35,080'); seek(635.0)">
              So for example, automatic speech recognition,
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:10:38,244'); seek(638.0)">
              object detection, or text speech are all
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:10:41,684'); seek(641.0)">
              examples where this enables a real time
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:10:45,556'); seek(645.0)">
              response. So then the final piece of the puzzle,
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:10:48,676'); seek(648.0)">
              we've had to work on runtime deployment
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:10:52,308'); seek(652.0)">
              and reconfigurability in a simple and scalable
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:10:55,428'); seek(655.0)">
              manner to really enable this inference at the edge, at scale.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:00,124'); seek(660.0)">
              So to do this, we achieved this using a container
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:03,394'); seek(663.0)">
              as a service technology, so that we provide a single
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:07,298'); seek(667.0)">
              anycast endpoint that can be easily connected to a developer's
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:11,402'); seek(671.0)">
              application. So what that means is that
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:14,554'); seek(674.0)">
              no matter where in the world an end user is, the request to that
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:18,602'); seek(678.0)">
              endpoint is routed to the nearest CDN node and from
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:22,114'); seek(682.0)">
              there to the nearest inference node. So if we delve
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:25,914'); seek(685.0)">
              into a little bit more detail, you can see what's happening here under
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:11:29,626'); seek(689.0)">
              the hood. I apologize, a little bit small, but hopefully you can follow it.
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:11:34,244'); seek(694.0)">
              So at the top here, supposing you have a two end
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:11:38,052'); seek(698.0)">
              users, and let's say one of those is in rear vision Aero
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:11:41,996'); seek(701.0)">
              and one of those in say Kyoto. Now, the anycast
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:11:45,620'); seek(705.0)">
              endpoint is available globally. When each of those
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:11:49,140'); seek(709.0)">
              users sends the request, that request will go to their local CDN
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:11:53,244'); seek(713.0)">
              node, the user in Kyoto. There might be a CDN node in
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:11:56,828'); seek(716.0)">
              Kyoto itself. And similarly for revision Arrow, that request
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:00,526'); seek(720.0)">
              would go to the revision Arrow CDN node. Now after that
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:04,926'); seek(724.0)">
              we developed smart routing technology,
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:08,494'); seek(728.0)">
              and what that does is it routes the request to
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:12,390'); seek(732.0)">
              the nearest available inference region. So that's where we have some
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:16,830'); seek(736.0)">
              high performance compute, typically gpu's that will do the actual
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:21,102'); seek(741.0)">
              optimized inference. Now what that means is
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:24,258'); seek(744.0)">
              that not only does it guarantee the fastest response time for each
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:12:28,082'); seek(748.0)">
              of these individually, but it also ensures that the
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:12:31,634'); seek(751.0)">
              processing and the model itself also stay locally.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:12:35,682'); seek(755.0)">
              So in particular, the user in Kyoto, the inference
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:12:39,474'); seek(759.0)">
              will be in state Tokyo and their data, and that model
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:12:43,546'); seek(763.0)">
              will only ever be in Tokyo. And likewise for the user
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:12:46,906'); seek(766.0)">
              in Rio, in Brazil, their model and their arrangement would also take place
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:12:51,108'); seek(771.0)">
              locally in Brazil. That also actually means you
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:12:54,468'); seek(774.0)">
              could potentially have a different model in each region. So, for example,
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:12:58,276'); seek(778.0)">
              you could have a model that was trained only on japanese user data
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:01,796'); seek(781.0)">
              in Japan, and similarly for other world regions.
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:05,884'); seek(785.0)">
              And so that also helps maintain that sort of data privacy and
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:09,268'); seek(789.0)">
              locality that I was talking about earlier. The final piece
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:12,948'); seek(792.0)">
              of puzzle that I want to talk about here is that in each of these
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:16,036'); seek(796.0)">
              regions, we also have developed auto scaling
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:19,672'); seek(799.0)">
              autoscaling functionality.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:13:22,624'); seek(802.0)">
              So what that means is that the amount of compute scales
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:13:26,000'); seek(806.0)">
              up and down with demand. And that's really important because
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:13:29,552'); seek(809.0)">
              it means that you can scale up the compute when you need it, when there's
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:13:32,248'); seek(812.0)">
              lots of demand. But equally importantly, you can scale back down again when there
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:13:36,040'); seek(816.0)">
              isn't. And also that means you're not then paying for compute
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:13:40,120'); seek(820.0)">
              when you don't use it. So, tying all these things together,
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:13:44,464'); seek(824.0)">
              I'll just summarize by putting together our sort of full end to end
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:13:48,680'); seek(828.0)">
              architecture, and you'll see that we've combined high
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:13:51,880'); seek(831.0)">
              performance AI training infrastructure, and then that
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:13:55,072'); seek(835.0)">
              could be in a public cloud setting. Thus, for some customers where
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:13:58,640'); seek(838.0)">
              privacy is really important, we could also offer it in a private cloud setting.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:02,944'); seek(842.0)">
              And then if you combine that with this infinite set, this low network,
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:06,944'); seek(846.0)">
              and the infinite edge technology we're talking about today,
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:10,284'); seek(850.0)">
              you have a comprehensive global AIoT
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:14,020'); seek(854.0)">
              architecture that we believe is fit for today's most demanding and
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:14:17,812'); seek(857.0)">
              scalable AI applications. So with that,
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:14:21,356'); seek(861.0)">
              that's probably enough of me talking. What I'll showcase here,
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:14:24,932'); seek(864.0)">
              a few demos that showcase technology in action.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:14:28,524'); seek(868.0)">
              So the first of those is an example with a real time face
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:14:32,412'); seek(872.0)">
              avatar. And what you'll see here is at the top here, I'll be entering
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:14:36,588'); seek(876.0)">
              in some prompts. And what you should look out for is the
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:14:40,226'); seek(880.0)">
              way that the avatar of the person changes
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:14:43,658'); seek(883.0)">
              in real time as I type in those prompts.
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:14:47,154'); seek(887.0)">
              So for example, here, I'm going to type in portrait of Elon Musk.
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:14:50,322'); seek(890.0)">
              And you see that the face has changed, Elon Musk
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:14:53,874'); seek(893.0)">
              almost immediately. And now as I type Bill Gates again, that change
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:14:58,106'); seek(898.0)">
              was done in real time. And now moving on to Madonna
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:02,354'); seek(902.0)">
              and a few more examples here. But again, what's really impressive
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:05,932'); seek(905.0)">
              is the way that the change is done in real time compared
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:09,852'); seek(909.0)">
              to the typing of the prompt there. There's a Jeff Bezos
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:15:13,916'); seek(913.0)">
              when he had hair. So, another example I
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:15:17,228'); seek(917.0)">
              can show you here is of real time translation from English
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:15:21,268'); seek(921.0)">
              to Luxembourgish. Now, like most
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:15:24,412'); seek(924.0)">
              people in the world, I don't speak Luxembourgish, which is a
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:15:28,052'); seek(928.0)">
              local language of Luxembourg. But if I was in
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:15:31,568'); seek(931.0)">
              our head office and I needed to quickly translate something,
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:15:34,672'); seek(934.0)">
              then no problem. I could use a typical translation
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:15:38,608'); seek(938.0)">
              tool. Hello there. Allow me to introduce myself.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:15:43,024'); seek(943.0)">
              I am an advanced machine learning model specifically designed for
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:15:46,504'); seek(946.0)">
              voice to text translation from English to Luxembourgish.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:15:50,424'); seek(950.0)">
              I have been created and powered by the cutting edge technology of G
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:15:54,344'); seek(954.0)">
              core AI cloud. Great. And I'll press send,
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:15:59,084'); seek(959.0)">
              and you'll see that again in less than a second.
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:02,252'); seek(962.0)">
              Less half a second, I'd say. The translation happened,
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:06,044'); seek(966.0)">
              and I've received the luxembourgish translation
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:16:09,740'); seek(969.0)">
              of those words again, I really showcased, from the minute
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:16:13,220'); seek(973.0)">
              I pressed send, the processing was in almost real time.
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:16:17,364'); seek(977.0)">
              So, in the final example I'll show you today is some work
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:16:20,852'); seek(980.0)">
              we've done with our colleagues at let's AI.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:16:24,564'); seek(984.0)">
              Let's AI are a creative platform that allows you to generate images for
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:16:28,132'); seek(988.0)">
              anything, you know, simply by tagging it in a text.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:16:31,604'); seek(991.0)">
              We've worked with, let's see, I over the last few months, and they've been utilizing
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:16:34,956'); seek(994.0)">
              our H 100 AI infrastructure and inference
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:16:38,852'); seek(998.0)">
              services to both train their Generali models and
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:16:42,100'); seek(1002.0)">
              also serve them to their customers worldwide.
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:16:45,764'); seek(1005.0)">
              So what you see here is an example of a single image that was generated
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:16:49,452'); seek(1009.0)">
              by the platform. But I think what's really impressive
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:16:52,722'); seek(1012.0)">
              is that you can actually take a series of images
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:16:56,490'); seek(1016.0)">
              generated by the platform and then combine
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:00,026'); seek(1020.0)">
              together to form a video. So this is
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:17:03,266'); seek(1023.0)">
              an example of a video generated with Lepsey Eye,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:17:06,874'); seek(1026.0)">
              which I think really shows the power of generative AI powered
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:17:10,538'); seek(1030.0)">
              by GPU infrastructure.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:17:16,874'); seek(1036.0)">
              The rookie sensation Ricky Malone says surprises with an unbelievable
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:17:20,468'); seek(1040.0)">
              pole position at silver. It looks like Ricky Malone is joining forces with the
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:17:23,860'); seek(1043.0)">
              legendary f one team for the 1986 season.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:17:26,860'); seek(1046.0)">
              Ricky, after our crash, watching you lose yourself
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:17:30,076'); seek(1050.0)">
              was hard. Not just because of us, but seeing you
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:17:33,308'); seek(1053.0)">
              give into darkness. It wasn't only about you.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:17:37,188'); seek(1057.0)">
              I was hurt, too, trapped by resentment,
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:17:40,524'); seek(1060.0)">
              encouraging you to race again, to face that trauma.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:17:43,844'); seek(1063.0)">
              It's for both of us. Us. I need to see you conquer this.
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:17:47,934'); seek(1067.0)">
              Not to go back to what we had, but to find closure
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:17:51,550'); seek(1071.0)">
              for both of us to move on. This is about letting go,
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:17:55,222'); seek(1075.0)">
              forgiving each other, healing. By helping you return
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:17:58,926'); seek(1078.0)">
              to the track, I'm also finding my way back. It's about finding
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:18:03,142'); seek(1083.0)">
              peace, Ricky, for you and for me.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:18:16,234'); seek(1096.0)">
              So there you go. A completely generated video that I
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:18:20,674'); seek(1100.0)">
              certainly found very impressive. So we're almost at the end of the talk
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:18:24,234'); seek(1104.0)">
              here, and just want to let you know that if
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:18:27,802'); seek(1107.0)">
              you're interested in learning more about technology, our infrastructure, the edge
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:18:31,690'); seek(1111.0)">
              product is actually being launched in beta this week.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:18:35,274'); seek(1115.0)">
              So this lets you deploy your model globally with
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:18:38,538'); seek(1118.0)">
              a single endpoint, as I explained. Or you can also
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:18:41,938'); seek(1121.0)">
              choose an open source model out of the box from a model catalog,
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:18:46,018'); seek(1126.0)">
              which includes popular models such as mistral unstable
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:18:49,586'); seek(1129.0)">
              diffusion. So this gives you a serverless AI compute with
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:18:53,922'); seek(1133.0)">
              very low latency around the world on a pay as you go model
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:18:57,762'); seek(1137.0)">
              with DDoS endpoint protection. But also, as this is our
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:01,858'); seek(1141.0)">
              beta service, it's also free. So if you'd like to try
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:05,350'); seek(1145.0)">
              it, I'd love to hear from you, find out about your machine learning
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:19:09,262'); seek(1149.0)">
              use case, and see whether edge computing could
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:19:12,798'); seek(1152.0)">
              be the right solution for you. And I'll just end the same. But of course,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:19:16,462'); seek(1156.0)">
              our work doesn't end here. The team is striving
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:19:19,974'); seek(1159.0)">
              to push the limits of our network and bring down the latency
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:19:23,662'); seek(1163.0)">
              to just a few tens of milliseconds, and we believe this
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:19:26,950'); seek(1166.0)">
              will further benefit sort of really mission
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:19:30,538'); seek(1170.0)">
              critical use cases of AI at the edge.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:19:33,674'); seek(1173.0)">
              So with that, I hope you've enjoyed the talk. Thank you for
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:19:37,098'); seek(1177.0)">
              joining me today. And again, please do reach out if you have any
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:19:40,674'); seek(1180.0)">
              questions or would like to discuss any of the technologies that I've spoken
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:19:44,282'); seek(1184.0)">
              about today, but for now, have a great conference.
            </span>
            
            </div>
          </div>
          
          

          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2024" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 36 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Michele%20Taroni_ml.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Michele Taroni
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                     @ Gcore
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Michele Taroni"
                  data-url="https://www.conf42.com/ml2024"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2024"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <!-- Text -->
            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
              for a <a class="text-white" href="https://www.reddit.com/r/sanfrancisco/comments/1bz90f6/why_are_coffee_shops_in_sf_so_expensive/" target="_blank">price of a pumpkin latte</a>.
            </p>

            <!-- Form -->
            <form class="d-flex align-items-center justify-content-center mb-7 mb-md-9">

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Annual
              </span>

              <!-- Switch -->
              <div class="form-check form-check-dark form-switch mx-3">
                <input class="form-check-input" type="checkbox" id="billingSwitch" data-toggle="price" data-target=".price">
              </div>

              <!-- Label -->
              <span class="text-white text-opacity-80">
                Monthly
              </span>

            </form>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Delayed access</b> to all content
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Immediate access to Keynotes & Panels
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe to free newsletter <i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-0">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Community</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="8.34" data-monthly="10">8.34</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Access to <a href="https://conf42.circle.so/">Circle community platform</a>
                  </p>
                </div>

                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Immediate access</b> to all content
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank"><b>Live events!</b></a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <a href="https://conf42.circle.so/c/live-events/" target="_blank">Regular office hours, Q&As, CV reviews</a>
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Courses, quizes & certificates
                  </p>
                </div>
                
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Community chats
                  </p>
                </div>
                

                <!-- Button -->
                <a href="https://conf42.circle.so/checkout/subscribe" class="btn w-100 btn-primary">
                  Join the community (7 day free trial)<i class="fe fe-arrow-right ms-3"></i>
                </a>

              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>