<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Optimal Video Compression Using Pixel Shift Tracking</title>
    <meta name="description" content="Help us build a dystopian, machine-ated future!">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/Hitesh%20Saai%20Mananchery_ml.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Optimal Video Compression Using Pixel Shift Tracking | Conf42"/>
    <meta property="og:description" content="Revolutionize video compression in my talk! Video drives 85% of internet traffic, yet traditional methods hit limits. I’ll introduce R2S—Redundancy Removal using Shift—an ML-powered approach that slashes frame redundancy, competes legacy codecs, in optimizes storage. Discover its adaptability now"/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2025_Hitesh_Saai_Mananchery_compression_pixel_video"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/DEVSECOPS2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        DevSecOps 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-12-04
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/devsecops2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2026
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2026">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2026">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2026">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2026">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2026">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/dbd2026">
                            Database DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2026">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2026">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/agents2026">
                            AI Agents
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2026">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2026">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2026">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2026">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2026">
                            Chaos Engineering
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <!-- <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a> -->
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2025 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Help us build a dystopian, machine-ated future!
 -->
              <script>
                const event_date = new Date("2025-05-08T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2025-05-08T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "PUdtZnEgdkM"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://www.youtube.com/playlist?list=PLIuxSyKxlQrDbH1VBaoA60lLAAVqmiLPe" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi everyone.", "timestamp": "00:00:01,500", "timestamp_s": 1.0}, {"text": "I\u0027m Hitesh.", "timestamp": "00:00:02,400", "timestamp_s": 2.0}, {"text": "Today I\u0027m going to top on topic on video compression by using AI based approach.", "timestamp": "00:00:03,280", "timestamp_s": 3.0}, {"text": "And my topic is on optimal video compression using", "timestamp": "00:00:08,800", "timestamp_s": 8.0}, {"text": "pixel ship tracking method.", "timestamp": "00:00:12,090", "timestamp_s": 12.0}, {"text": "So before getting into the topic I would like to give a", "timestamp": "00:00:14,040", "timestamp_s": 14.0}, {"text": "quick introduction about myself.", "timestamp": "00:00:17,240", "timestamp_s": 17.0}, {"text": "I\u0027m ish.", "timestamp": "00:00:19,374", "timestamp_s": 19.0}, {"text": "I\u0027ve been working as a senior machine learning engineer for Expedia Group.", "timestamp": "00:00:20,234", "timestamp_s": 20.0}, {"text": "I have over seven years of experience in the field of machine learning and ai.", "timestamp": "00:00:24,884", "timestamp_s": 24.0}, {"text": "I have worked in several industries like in InsureTech fin FinTech, and", "timestamp": "00:00:29,154", "timestamp_s": 29.0}, {"text": "now I\u0027m working in travel industries.", "timestamp": "00:00:34,065", "timestamp_s": 34.0}, {"text": "I did my masters in mission learning and statistics.", "timestamp": "00:00:36,754", "timestamp_s": 36.0}, {"text": "And from that it\u0027s been quite a journey in the field of ai.", "timestamp": "00:00:39,625", "timestamp_s": 39.0}, {"text": "And we recently worked on this research idea on video compression, and that\u0027s", "timestamp": "00:00:42,705", "timestamp_s": 42.0}, {"text": "what I\u0027m going to talk about today.", "timestamp": "00:00:47,845", "timestamp_s": 47.0}, {"text": "Let\u0027s get into the topic.", "timestamp": "00:00:50,065", "timestamp_s": 50.0}, {"text": "So just to give a quick introduction in today\u0027s world.", "timestamp": "00:00:52,345", "timestamp_s": 52.0}, {"text": "Videos, traffic is comprised of almost 85 percentage of the internet traffic.", "timestamp": "00:00:56,210", "timestamp_s": 56.0}, {"text": "From social media alone we get around 10 petabytes of data every day gets processed", "timestamp": "00:01:01,870", "timestamp_s": 61.0}, {"text": "and stored into the cloud environments.", "timestamp": "00:01:07,850", "timestamp_s": 67.0}, {"text": "So there are around 20 different VDA compression methods, which", "timestamp": "00:01:11,070", "timestamp_s": 71.0}, {"text": "has been used, which has been used and being used in the industry.", "timestamp": "00:01:14,050", "timestamp_s": 74.0}, {"text": "And most of them are a rule-based algorithm approaches.", "timestamp": "00:01:17,840", "timestamp_s": 77.0}, {"text": "In recent times there has been a lot of research happening in the mission", "timestamp": "00:01:21,240", "timestamp_s": 81.0}, {"text": "learning field on Computeration side, on trying to use AI based approach", "timestamp": "00:01:25,550", "timestamp_s": 85.0}, {"text": "to do compressions of the videos.", "timestamp": "00:01:29,830", "timestamp_s": 89.0}, {"text": "And the main purpose of.", "timestamp": "00:01:32,110", "timestamp_s": 92.0}, {"text": "The research is happening in ML space for video compression that", "timestamp": "00:01:34,020", "timestamp_s": 94.0}, {"text": "using ml it can be used across a diverse video format, irrespective", "timestamp": "00:01:37,540", "timestamp_s": 97.0}, {"text": "of what format we are trying to use.", "timestamp": "00:01:41,860", "timestamp_s": 101.0}, {"text": "And also it can be tapped across any ML framework.", "timestamp": "00:01:44,090", "timestamp_s": 104.0}, {"text": "Irrespective of trying to just be possible in one framework.", "timestamp": "00:01:47,290", "timestamp_s": 107.0}, {"text": "It is framework.", "timestamp": "00:01:50,200", "timestamp_s": 110.0}, {"text": "Independent and also diverse in video formats.", "timestamp": "00:01:51,550", "timestamp_s": 111.0}, {"text": "We are pro, we are proposing an another approach over here and so", "timestamp": "00:01:54,980", "timestamp_s": 114.0}, {"text": "that\u0027s what I\u0027m gonna talk about.", "timestamp": "00:02:00,400", "timestamp_s": 120.0}, {"text": "So before getting into.", "timestamp": "00:02:01,660", "timestamp_s": 121.0}, {"text": "More detail about our idea.", "timestamp": "00:02:03,615", "timestamp_s": 123.0}, {"text": "I would just like to give some quick idea of how the video compressions,", "timestamp": "00:02:05,145", "timestamp_s": 125.0}, {"text": "what type of v compressions are done today, and and then we can", "timestamp": "00:02:09,635", "timestamp_s": 129.0}, {"text": "get into the topic of our approach on the pixel ship tracking method.", "timestamp": "00:02:12,875", "timestamp_s": 132.0}, {"text": "So in the current current traditional compressional algorithm, these are the", "timestamp": "00:02:18,230", "timestamp_s": 138.0}, {"text": "formats we have been using, which is the H 2 64 H 2 65, AB one B, P eight", "timestamp": "00:02:21,470", "timestamp_s": 141.0}, {"text": "all these things can, could be for some, could be familiar or un, but.", "timestamp": "00:02:26,690", "timestamp_s": 146.0}, {"text": "All of these traditional algorithm methods are being used to store all", "timestamp": "00:02:31,555", "timestamp_s": 151.0}, {"text": "these MP G four files, MP fours, MP five for audios and NPG files for videos.", "timestamp": "00:02:34,910", "timestamp_s": 154.0}, {"text": "And the algorithm which is being used at the backend for the compressions of the", "timestamp": "00:02:40,810", "timestamp_s": 160.0}, {"text": "videos or these algorithms basically.", "timestamp": "00:02:44,320", "timestamp_s": 164.0}, {"text": "So there are basically two types of compressions.", "timestamp": "00:02:47,140", "timestamp_s": 167.0}, {"text": "One is lossless compression and the loss compressions.", "timestamp": "00:02:49,399", "timestamp_s": 169.0}, {"text": "So loss compressions are the, mostly used format where when we try to compress data", "timestamp": "00:02:52,369", "timestamp_s": 172.0}, {"text": "or we, I try to write and store a data in term of in terms of video, we do see", "timestamp": "00:02:57,570", "timestamp_s": 177.0}, {"text": "some decrease in the quality of the video.", "timestamp": "00:03:02,609", "timestamp_s": 182.0}, {"text": "And that\u0027s the loss.", "timestamp": "00:03:05,179", "timestamp_s": 185.0}, {"text": "The loss e compressions unless lossless compression, which is more of the the high", "timestamp": "00:03:06,059", "timestamp_s": 186.0}, {"text": "definition videos, which we talk about.", "timestamp": "00:03:10,190", "timestamp_s": 190.0}, {"text": "But, most of the videos which you write or upload to any social", "timestamp": "00:03:12,109", "timestamp_s": 192.0}, {"text": "media or any cloud storages, all of them are being compressed.", "timestamp": "00:03:15,500", "timestamp_s": 195.0}, {"text": "And that\u0027s a lossy approach.", "timestamp": "00:03:19,730", "timestamp_s": 199.0}, {"text": "And the approach, which we are going to talk about today is", "timestamp": "00:03:21,524", "timestamp_s": 201.0}, {"text": "also a lossy based approach.", "timestamp": "00:03:24,029", "timestamp_s": 204.0}, {"text": "Logies are not basically something where the data will be lost rather it\u0027s just", "timestamp": "00:03:25,790", "timestamp_s": 205.0}, {"text": "the decrease in the quality of the video.", "timestamp": "00:03:29,795", "timestamp_s": 209.0}, {"text": "But from a normal human standpoint a human, viewpoint you won\u0027t, you", "timestamp": "00:03:32,234", "timestamp_s": 212.0}, {"text": "wouldn\u0027t see a lot of data losses, but granularly, if you try to see that there", "timestamp": "00:03:36,754", "timestamp_s": 216.0}, {"text": "will be a lot of data losses happening.", "timestamp": "00:03:40,790", "timestamp_s": 220.0}, {"text": "But that\u0027s the only thing which we lose.", "timestamp": "00:03:42,440", "timestamp_s": 222.0}, {"text": "But we e eventually we try to compress these videos and", "timestamp": "00:03:44,490", "timestamp_s": 224.0}, {"text": "store in a more optimal way.", "timestamp": "00:03:47,570", "timestamp_s": 227.0}, {"text": "And so that\u0027s the lossy approach.", "timestamp": "00:03:49,220", "timestamp_s": 229.0}, {"text": "And one of the approaches which we are approaching we are proposing", "timestamp": "00:03:50,870", "timestamp_s": 230.0}, {"text": "today is also a based approach.", "timestamp": "00:03:53,660", "timestamp_s": 233.0}, {"text": "Today in the ai machine learning space these are the, some of the areas that", "timestamp": "00:03:56,775", "timestamp_s": 236.0}, {"text": "researchers are happening on the video compressions which is tapped by the", "timestamp": "00:04:01,215", "timestamp_s": 241.0}, {"text": "encoders, VAE, which is a variant, auto encoders and deep con contextual network.", "timestamp": "00:04:05,145", "timestamp_s": 245.0}, {"text": "So we are our idea is also based on a deep contextual network over here, and that\u0027s", "timestamp": "00:04:10,855", "timestamp_s": 250.0}, {"text": "what I\u0027m going to talk talk about today.", "timestamp": "00:04:16,470", "timestamp_s": 256.0}, {"text": "For our approach which is the pixel point tracking approach", "timestamp": "00:04:18,979", "timestamp_s": 258.0}, {"text": "to do the video D compression.", "timestamp": "00:04:22,129", "timestamp_s": 262.0}, {"text": "Yeah, so this is a proposed method.", "timestamp": "00:04:23,929", "timestamp_s": 263.0}, {"text": "So the way we have approached this problem is basically trying to avoid the rid", "timestamp": "00:04:25,549", "timestamp_s": 265.0}, {"text": "then pixels in a video while storing.", "timestamp": "00:04:30,834", "timestamp_s": 270.0}, {"text": "So just to give a quick example, so videos are basically comprised of frames.", "timestamp": "00:04:33,924", "timestamp_s": 273.0}, {"text": "For any given video, let\u0027s see, even a five second video, there would be at", "timestamp": "00:04:39,069", "timestamp_s": 279.0}, {"text": "least 20 to 30 frames, which we have, which are the, basically the images.", "timestamp": "00:04:42,339", "timestamp_s": 282.0}, {"text": "So when you, when we see as a video, we saw a lot of things", "timestamp": "00:04:46,749", "timestamp_s": 286.0}, {"text": "moving here and there as a video.", "timestamp": "00:04:50,169", "timestamp_s": 290.0}, {"text": "But if you see as a frame.", "timestamp": "00:04:52,059", "timestamp_s": 292.0}, {"text": "Frame by frame, image by image.", "timestamp": "00:04:53,859", "timestamp_s": 293.0}, {"text": "We basically see the, there\u0027s a lot of redundancy happening from one frame", "timestamp": "00:04:56,469", "timestamp_s": 296.0}, {"text": "to another frame, which is basically storing the same pixels or the same", "timestamp": "00:05:00,239", "timestamp_s": 300.0}, {"text": "data from one frame to another frame.", "timestamp": "00:05:04,409", "timestamp_s": 304.0}, {"text": "And that\u0027s what we are trying to avoid by not storing those redundant", "timestamp": "00:05:06,539", "timestamp_s": 306.0}, {"text": "frames from one frame to another frame on all the subsequent frames.", "timestamp": "00:05:10,439", "timestamp_s": 310.0}, {"text": "And, reduce all those un datas and we are trying to optimize the", "timestamp": "00:05:14,219", "timestamp_s": 314.0}, {"text": "storage when we try to store using machine learning based approach.", "timestamp": "00:05:18,009", "timestamp_s": 318.0}, {"text": "So the way we are approaching, or we way we are trying to find this redundant pixel", "timestamp": "00:05:21,759", "timestamp_s": 321.0}, {"text": "is basically trying to track the pixels.", "timestamp": "00:05:26,769", "timestamp_s": 326.0}, {"text": "So for example, when a video has been taken so that you know that a video", "timestamp": "00:05:29,259", "timestamp_s": 329.0}, {"text": "moves in a particular directions, right?", "timestamp": "00:05:34,239", "timestamp_s": 334.0}, {"text": "So it can move from left to right or top to bottom, or it can move from left to", "timestamp": "00:05:35,949", "timestamp_s": 335.0}, {"text": "top or right to top or top to bottom.", "timestamp": "00:05:40,089", "timestamp_s": 340.0}, {"text": "The video can move any anyways.", "timestamp": "00:05:42,519", "timestamp_s": 342.0}, {"text": "So based on the moment of the videos using the coordinates, we are trying to", "timestamp": "00:05:44,049", "timestamp_s": 344.0}, {"text": "understand how far it has moved from a point A to point B. Based on that, we know", "timestamp": "00:05:47,769", "timestamp_s": 347.0}, {"text": "how far the new pixels we are going to get in the next frame, and what are the", "timestamp": "00:05:51,849", "timestamp_s": 351.0}, {"text": "other relevant pixels we are going to.", "timestamp": "00:05:55,479", "timestamp_s": 355.0}, {"text": "Get the next frame from the first frame, and we are trying to nullify those and", "timestamp": "00:05:57,564", "timestamp_s": 357.0}, {"text": "trying to put a black spots on those by doing surveillance already the size of", "timestamp": "00:06:01,904", "timestamp_s": 361.0}, {"text": "a frame or size of a image in the video.", "timestamp": "00:06:05,274", "timestamp_s": 365.0}, {"text": "So there are two different approaches.", "timestamp": "00:06:08,934", "timestamp_s": 368.0}, {"text": "One is single point trajectory method and the multi-point trajectory method.", "timestamp": "00:06:10,974", "timestamp_s": 370.0}, {"text": "So the single point trajectory method is basically using trying to find arbitrary", "timestamp": "00:06:15,104", "timestamp_s": 375.0}, {"text": "point and we are trying to track it.", "timestamp": "00:06:19,964", "timestamp_s": 379.0}, {"text": "And multi-point is basically on trying to use multiple points and trying to track", "timestamp": "00:06:21,554", "timestamp_s": 381.0}, {"text": "the video movement or the frames movement.", "timestamp": "00:06:25,824", "timestamp_s": 385.0}, {"text": "So I\u0027ll get into details now of starting with a single point trajectory.", "timestamp": "00:06:28,764", "timestamp_s": 388.0}, {"text": "So for a single point trajectory, what we basically do is we try to", "timestamp": "00:06:34,029", "timestamp_s": 394.0}, {"text": "find an arbitrary point in a in a video in the starting first frame.", "timestamp": "00:06:37,529", "timestamp_s": 397.0}, {"text": "And from there we try to basically track the point from one frame to another frame.", "timestamp": "00:06:41,259", "timestamp_s": 401.0}, {"text": "And this is where we are using a deep learning, a computer vision approach.", "timestamp": "00:06:46,869", "timestamp_s": 406.0}, {"text": "We\u0027re using a a concept called persistent independent prac", "timestamp": "00:06:50,769", "timestamp_s": 410.0}, {"text": "particles, which is called Pips.", "timestamp": "00:06:53,984", "timestamp_s": 413.0}, {"text": "It\u0027s an a research paper written by, another researchers and we", "timestamp": "00:06:56,514", "timestamp_s": 416.0}, {"text": "made use of that over here and to optimize that pips concept in a way.", "timestamp": "00:07:00,514", "timestamp_s": 420.0}, {"text": "And we are trying to achieve the video compression over here.", "timestamp": "00:07:05,384", "timestamp_s": 425.0}, {"text": "And that\u0027s our approach basically.", "timestamp": "00:07:08,384", "timestamp_s": 428.0}, {"text": "So we basically try to use a single point trajectory over here.", "timestamp": "00:07:10,214", "timestamp_s": 430.0}, {"text": "Which is basically trying to find arbitrary point in", "timestamp": "00:07:13,549", "timestamp_s": 433.0}, {"text": "the first frame of a video.", "timestamp": "00:07:16,259", "timestamp_s": 436.0}, {"text": "And from that we basically try to track where the particular object or a point", "timestamp": "00:07:17,724", "timestamp_s": 437.0}, {"text": "or a pixel is moving from one frame to another frame to subsequent frame.", "timestamp": "00:07:22,024", "timestamp_s": 442.0}, {"text": "Based on that, we know what\u0027s the, how many coordinates it\u0027s moving.", "timestamp": "00:07:25,799", "timestamp_s": 445.0}, {"text": "Based on that we try to see how many new pixels we are going to", "timestamp": "00:07:28,779", "timestamp_s": 448.0}, {"text": "get, and that\u0027s what we store.", "timestamp": "00:07:32,019", "timestamp_s": 452.0}, {"text": "We try to avoid the rest.", "timestamp": "00:07:33,669", "timestamp_s": 453.0}, {"text": "So the single point trajectory basically works.", "timestamp": "00:07:35,404", "timestamp_s": 455.0}, {"text": "Only in places where the objects are starting and the video is moving.", "timestamp": "00:07:39,519", "timestamp_s": 459.0}, {"text": "So there are three different ways a video can be seen.", "timestamp": "00:07:43,724", "timestamp_s": 463.0}, {"text": "So one is where the objects are static, where the video is moving or the camera", "timestamp": "00:07:47,154", "timestamp_s": 467.0}, {"text": "is moving, or the camera, or the camera is starting where the objects are moving.", "timestamp": "00:07:51,604", "timestamp_s": 471.0}, {"text": "It could be the both.", "timestamp": "00:07:56,799", "timestamp_s": 476.0}, {"text": "A camera and object could be moving at the same time in a video.", "timestamp": "00:07:57,489", "timestamp_s": 477.0}, {"text": "So there is three different approaches.", "timestamp": "00:08:00,219", "timestamp_s": 480.0}, {"text": "The single point tracking can solve only in scenarios where the objects are", "timestamp": "00:08:01,449", "timestamp_s": 481.0}, {"text": "static, but the but the camera is moving but Multipoint trajectory can do it.", "timestamp": "00:08:05,899", "timestamp_s": 485.0}, {"text": "Way better by trying to have multiple pixel point tracking trajectories.", "timestamp": "00:08:11,264", "timestamp_s": 491.0}, {"text": "And based on, we can try to get an average movement of it and we", "timestamp": "00:08:14,779", "timestamp_s": 494.0}, {"text": "try to avoid the readable pixels.", "timestamp": "00:08:18,079", "timestamp_s": 498.0}, {"text": "So before getting into Multipoint trajectory, I will just show you a quick", "timestamp": "00:08:20,629", "timestamp_s": 500.0}, {"text": "example of how this tracking looks like.", "timestamp": "00:08:24,559", "timestamp_s": 504.0}, {"text": "You can see here in this picture, there is a dog running.", "timestamp": "00:08:27,259", "timestamp_s": 507.0}, {"text": "This is a video where we are trying to track the nose of the dog.", "timestamp": "00:08:30,349", "timestamp_s": 510.0}, {"text": "So the idea is not to track an object here.", "timestamp": "00:08:34,634", "timestamp_s": 514.0}, {"text": "The idea is basically to track in particular pixel, and based", "timestamp": "00:08:37,114", "timestamp_s": 517.0}, {"text": "upon the pixel movement, we can identify what is the redundant", "timestamp": "00:08:40,804", "timestamp_s": 520.0}, {"text": "and the non-redundant part of it.", "timestamp": "00:08:44,249", "timestamp_s": 524.0}, {"text": "As I mentioned, this single point trajectory is achievable", "timestamp": "00:08:46,064", "timestamp_s": 526.0}, {"text": "through an to a not approach.", "timestamp": "00:08:49,034", "timestamp_s": 529.0}, {"text": "I would say like through a method where the objects are", "timestamp": "00:08:52,759", "timestamp_s": 532.0}, {"text": "static, where the camera is.", "timestamp": "00:08:55,999", "timestamp_s": 535.0}, {"text": "So that\u0027s what the single point tracking looks like.", "timestamp": "00:08:58,219", "timestamp_s": 538.0}, {"text": "When we try to track it using mission learnings and we are trying to use the", "timestamp": "00:09:00,399", "timestamp_s": 540.0}, {"text": "frames to see where the objects is moving.", "timestamp": "00:09:03,429", "timestamp_s": 543.0}, {"text": "The pixel point is moving.", "timestamp": "00:09:06,009", "timestamp_s": 546.0}, {"text": "So to talk about the multipoint trajectory as I mentioned, so", "timestamp": "00:09:08,289", "timestamp_s": 548.0}, {"text": "Multipoint trajectory basically works.", "timestamp": "00:09:12,259", "timestamp_s": 552.0}, {"text": "When when you try to put the pixel points, the trajectory points in", "timestamp": "00:09:14,029", "timestamp_s": 554.0}, {"text": "multiple places in like a grid format, in a 2D grid format.", "timestamp": "00:09:18,199", "timestamp_s": 558.0}, {"text": "And when by doing so, so now what it does is in a given frame let\u0027s say we have", "timestamp": "00:09:22,034", "timestamp_s": 562.0}, {"text": "a eight by eight frame where you put 64 points or 64 trajectory points, which can", "timestamp": "00:09:27,744", "timestamp_s": 567.0}, {"text": "track all the 64 positions within a grid where it could be a midpoint of every", "timestamp": "00:09:32,979", "timestamp_s": 572.0}, {"text": "small grid positions within the eight by pixel image, so by a by eight image size.", "timestamp": "00:09:37,579", "timestamp_s": 577.0}, {"text": "So by doing so, what happens is can also track.", "timestamp": "00:09:42,649", "timestamp_s": 582.0}, {"text": "Object movement.", "timestamp": "00:09:45,364", "timestamp_s": 585.0}, {"text": "It can also track the camera movements.", "timestamp": "00:09:46,179", "timestamp_s": 586.0}, {"text": "And by by calibrating all of those, we can try to find what is the only T part,", "timestamp": "00:09:48,609", "timestamp_s": 588.0}, {"text": "which is what are the non-redundant part which can we can expect in the", "timestamp": "00:09:53,779", "timestamp_s": 593.0}, {"text": "next frame compared to the first frame.", "timestamp": "00:09:57,014", "timestamp_s": 597.0}, {"text": "And this can mostly work in in a very advanced approaches where the videos", "timestamp": "00:09:58,814", "timestamp_s": 598.0}, {"text": "is very complex and that\u0027s where the multi-point trajectory element lead.", "timestamp": "00:10:03,274", "timestamp_s": 603.0}, {"text": "Be helpful to just give a quick visual of how the multipoint", "timestamp": "00:10:06,999", "timestamp_s": 606.0}, {"text": "like would, will look like.", "timestamp": "00:10:10,919", "timestamp_s": 610.0}, {"text": "Is from the previous video we saw that there was a dog and the dog", "timestamp": "00:10:13,049", "timestamp_s": 613.0}, {"text": "was moving and we were just pointing one and, I can go back here.", "timestamp": "00:10:16,429", "timestamp_s": 616.0}, {"text": "So you can see here, it\u0027s just tracking one trajectory and this tr", "timestamp": "00:10:20,809", "timestamp_s": 620.0}, {"text": "looks like it\u0027s going like a it looks like a, some kind of leaf, right?", "timestamp": "00:10:24,084", "timestamp_s": 624.0}, {"text": "So that\u0027s why, that\u0027s how it\u0027s moving.", "timestamp": "00:10:27,924", "timestamp_s": 627.0}, {"text": "But in this case, in this video, we can see that the dog the object as", "timestamp": "00:10:29,694", "timestamp_s": 629.0}, {"text": "far as the video, both are moving.", "timestamp": "00:10:34,474", "timestamp_s": 634.0}, {"text": "So a single point trajectory would not effectively can say", "timestamp": "00:10:36,269", "timestamp_s": 636.0}, {"text": "how the pixels are moving.", "timestamp": "00:10:39,269", "timestamp_s": 639.0}, {"text": "But by using a multi-point trajectory.", "timestamp": "00:10:40,809", "timestamp_s": 640.0}, {"text": "You can see here actually the how the entire video from one frame to another", "timestamp": "00:10:43,019", "timestamp_s": 643.0}, {"text": "frame, or at least this is like a, let\u0027s say it\u0027s a two second video, might be", "timestamp": "00:10:48,269", "timestamp_s": 648.0}, {"text": "we have four to five frames in this.", "timestamp": "00:10:51,839", "timestamp_s": 651.0}, {"text": "We can see from frame one to frame five, how far it has been shifted.", "timestamp": "00:10:53,969", "timestamp_s": 653.0}, {"text": "So this can give like an overview of how the pixels are", "timestamp": "00:10:57,509", "timestamp_s": 657.0}, {"text": "moving at different positions.", "timestamp": "00:11:02,114", "timestamp_s": 662.0}, {"text": "And based on that, every single positions we can see, what are the", "timestamp": "00:11:03,914", "timestamp_s": 663.0}, {"text": "pixels we need to store, what are the coordinates we need to store?", "timestamp": "00:11:07,544", "timestamp_s": 667.0}, {"text": "What are the quad, what are the position coordinates we, we can avoid storing and", "timestamp": "00:11:10,524", "timestamp_s": 670.0}, {"text": "we can retribute from the previous spring.", "timestamp": "00:11:13,944", "timestamp_s": 673.0}, {"text": "And that\u0027s what we are trying to do over here.", "timestamp": "00:11:15,934", "timestamp_s": 675.0}, {"text": "So let\u0027s get into the steps on how we have achieved it.", "timestamp": "00:11:18,604", "timestamp_s": 678.0}, {"text": "So for the compression step just to give a quick note, we in this approach", "timestamp": "00:11:22,294", "timestamp_s": 682.0}, {"text": "we are trying to prove that this is possible to pixel point tracking by", "timestamp": "00:11:26,004", "timestamp_s": 686.0}, {"text": "using a single trajectory method.", "timestamp": "00:11:29,374", "timestamp_s": 689.0}, {"text": "So we have used that as a proof of concept over here to display displayed", "timestamp": "00:11:30,814", "timestamp_s": 690.0}, {"text": "and show that this is possible.", "timestamp": "00:11:34,929", "timestamp_s": 694.0}, {"text": "And so as a step one, using a single point trajectory method.", "timestamp": "00:11:36,939", "timestamp_s": 696.0}, {"text": "We arbitrarily choose a point in a video.", "timestamp": "00:11:41,529", "timestamp_s": 701.0}, {"text": "So we are using a video.", "timestamp": "00:11:43,939", "timestamp_s": 703.0}, {"text": "We used a video where the objects are static, but the", "timestamp": "00:11:45,169", "timestamp_s": 705.0}, {"text": "video the camera is moving.", "timestamp": "00:11:47,869", "timestamp_s": 707.0}, {"text": "The video is moving.", "timestamp": "00:11:49,149", "timestamp_s": 709.0}, {"text": "Basically in the video, the camera is moving, sorry.", "timestamp": "00:11:50,649", "timestamp_s": 710.0}, {"text": "We use like a, let\u0027s say a midpoint, the in the frame.", "timestamp": "00:11:52,969", "timestamp_s": 712.0}, {"text": "And and we are tracking that point over here.", "timestamp": "00:11:55,584", "timestamp_s": 715.0}, {"text": "So we choose arbitrary point for the the pips to track the present", "timestamp": "00:11:57,434", "timestamp_s": 717.0}, {"text": "independent particles model to track.", "timestamp": "00:12:02,094", "timestamp_s": 722.0}, {"text": "And it basically process basically eight frames at a time.", "timestamp": "00:12:04,529", "timestamp_s": 724.0}, {"text": "So to have, to improve the accuracy, we are trying to use one frame at a", "timestamp": "00:12:07,989", "timestamp_s": 727.0}, {"text": "time to predict what bad the pixels are moving first, why that point is moving", "timestamp": "00:12:11,799", "timestamp_s": 731.0}, {"text": "from one frame to so from first frame to second frame for the given pixel point.", "timestamp": "00:12:15,739", "timestamp_s": 735.0}, {"text": "So we first, we place a random point.", "timestamp": "00:12:20,069", "timestamp_s": 740.0}, {"text": "Arbitrary point in the first frame, and then we try to track the frame from frame", "timestamp": "00:12:23,119", "timestamp_s": 743.0}, {"text": "by frame one frame to another frame.", "timestamp": "00:12:27,109", "timestamp_s": 747.0}, {"text": "While we are trying to track.", "timestamp": "00:12:28,919", "timestamp_s": 748.0}, {"text": "So let\u0027s say we were, we had a, we were at a point in frame one, and eventually", "timestamp": "00:12:30,209", "timestamp_s": 750.0}, {"text": "when we try to move from frame one to frame one, to frame two, let\u0027s say mode", "timestamp": "00:12:35,234", "timestamp_s": 755.0}, {"text": "four coordinates to the right, we know that there are, there is going to be.", "timestamp": "00:12:39,919", "timestamp_s": 759.0}, {"text": "A with of four pixels.", "timestamp": "00:12:43,439", "timestamp_s": 763.0}, {"text": "Four with of four size pixels going to come inside.", "timestamp": "00:12:45,953", "timestamp_s": 765.0}, {"text": "And I know the rest of that part on the left side of the first frame is gonna", "timestamp": "00:12:48,913", "timestamp_s": 768.0}, {"text": "be redundant and should be available.", "timestamp": "00:12:52,723", "timestamp_s": 772.0}, {"text": "Same pixels in the second frame.", "timestamp": "00:12:54,583", "timestamp_s": 774.0}, {"text": "So that\u0027s what we are going to nullify and direct delete that", "timestamp": "00:12:56,393", "timestamp_s": 776.0}, {"text": "and store only the non pixels.", "timestamp": "00:12:59,588", "timestamp_s": 779.0}, {"text": "And that\u0027s what the compression part does for one frame to the second frame.", "timestamp": "00:13:02,368", "timestamp_s": 782.0}, {"text": "And similarly, from second frame to the third frame to so on.", "timestamp": "00:13:06,598", "timestamp_s": 786.0}, {"text": "That\u0027s how we try to compress these.", "timestamp": "00:13:09,298", "timestamp_s": 789.0}, {"text": "So just give a quick idea of how that looks like.", "timestamp": "00:13:12,448", "timestamp_s": 792.0}, {"text": "You can see here in the frame one in the frame one, there\u0027s we can see that sorry.", "timestamp": "00:13:14,658", "timestamp_s": 794.0}, {"text": "So the framework, we can see that over here, that the.", "timestamp": "00:13:19,363", "timestamp_s": 799.0}, {"text": "This is the complete image and the, in the frame two, what ha what\u0027s happening is it", "timestamp": "00:13:23,418", "timestamp_s": 803.0}, {"text": "has mowed like few pixels to the right.", "timestamp": "00:13:27,858", "timestamp_s": 807.0}, {"text": "So when we are trying to do the compression, the second frame won\u0027t", "timestamp": "00:13:30,828", "timestamp_s": 810.0}, {"text": "look like how we see the second picture or second picture over here, rather.", "timestamp": "00:13:33,798", "timestamp_s": 813.0}, {"text": "It would look like the third picture in the image where it basically", "timestamp": "00:13:38,778", "timestamp_s": 818.0}, {"text": "all of the redundant pixels and it stores only the non-redundant pixel", "timestamp": "00:13:44,908", "timestamp_s": 824.0}, {"text": "in the storage for the second frame.", "timestamp": "00:13:49,148", "timestamp_s": 829.0}, {"text": "Similarly, we do it from the third frame, fourth frame, and so on.", "timestamp": "00:13:51,713", "timestamp_s": 831.0}, {"text": "And by doing so, we try as we are putting a black value of zero in terms", "timestamp": "00:13:54,833", "timestamp_s": 834.0}, {"text": "of pixel to all the redundant part we reduce the size during the compression", "timestamp": "00:13:58,583", "timestamp_s": 838.0}, {"text": "or this is how the compression part work.", "timestamp": "00:14:03,093", "timestamp_s": 843.0}, {"text": "And now I\u0027ll get into how the decompression part work.", "timestamp": "00:14:05,163", "timestamp_s": 845.0}, {"text": "So the decompression part is an interesting one.", "timestamp": "00:14:09,278", "timestamp_s": 849.0}, {"text": "It\u0027s a very intuitive approach.", "timestamp": "00:14:11,463", "timestamp_s": 851.0}, {"text": "So what we have done is so that in the process of this compressions, the", "timestamp": "00:14:12,633", "timestamp_s": 852.0}, {"text": "first frame will always remain intact.", "timestamp": "00:14:16,863", "timestamp_s": 856.0}, {"text": "That basically means like it could be whatever it is, the", "timestamp": "00:14:19,598", "timestamp_s": 859.0}, {"text": "first frame, it remains the same.", "timestamp": "00:14:22,718", "timestamp_s": 862.0}, {"text": "We don\u0027t because for the first frame there is nothing called render than pixel.", "timestamp": "00:14:24,653", "timestamp_s": 864.0}, {"text": "That\u0027s the first frame.", "timestamp": "00:14:28,013", "timestamp_s": 868.0}, {"text": "So first frame always stores the entire data that without with any", "timestamp": "00:14:29,118", "timestamp_s": 869.0}, {"text": "of the data points in the pixel data points, which is so called the pixels.", "timestamp": "00:14:33,508", "timestamp_s": 873.0}, {"text": "So now what happens during the decompression step over here is,", "timestamp": "00:14:37,253", "timestamp_s": 877.0}, {"text": "so during the compression, we know that from frame one to frame two.", "timestamp": "00:14:40,733", "timestamp_s": 880.0}, {"text": "Four, four coordinates to the right on the X axis.", "timestamp": "00:14:45,438", "timestamp_s": 885.0}, {"text": "So we, what we basically do is that\u0027s this, that\u0027s the only new width, which", "timestamp": "00:14:48,588", "timestamp_s": 888.0}, {"text": "we are looking from the second frame, and that\u0027s what we stored from the", "timestamp": "00:14:52,358", "timestamp_s": 892.0}, {"text": "second frame and we nullify the wrist.", "timestamp": "00:14:54,788", "timestamp_s": 894.0}, {"text": "So those nullified positions are stored as an array.", "timestamp": "00:14:56,918", "timestamp_s": 896.0}, {"text": "On, on, on collecting those coordinates positions alone, which is basically", "timestamp": "00:15:00,868", "timestamp_s": 900.0}, {"text": "the a, the X axis and the yxi points on basically let\u0027s say like a rectangle.", "timestamp": "00:15:05,578", "timestamp_s": 905.0}, {"text": "So it takes four coordinate points, and we store it for a reframe on", "timestamp": "00:15:11,428", "timestamp_s": 911.0}, {"text": "what has to be recomposed when we try to de do the decompressions.", "timestamp": "00:15:15,148", "timestamp_s": 915.0}, {"text": "So basically we, when we do the compression, we store all", "timestamp": "00:15:19,578", "timestamp_s": 919.0}, {"text": "the all the frames by storing only the non-resistant pixels.", "timestamp": "00:15:22,218", "timestamp_s": 922.0}, {"text": "And then we also stored a separate array, which basically holds the", "timestamp": "00:15:26,208", "timestamp_s": 926.0}, {"text": "holds the coordinates of the redundant positions, which can be obtained from", "timestamp": "00:15:30,068", "timestamp_s": 930.0}, {"text": "the previous pixel sorry, previous frame.", "timestamp": "00:15:34,108", "timestamp_s": 934.0}, {"text": "So how that basically would work is if you see here in the first image", "timestamp": "00:15:36,258", "timestamp_s": 936.0}, {"text": "the data retrieval frame, right?", "timestamp": "00:15:39,743", "timestamp_s": 939.0}, {"text": "So this is the first frame from the first frame to second frame.", "timestamp": "00:15:41,753", "timestamp_s": 941.0}, {"text": "If you see the second the.", "timestamp": "00:15:44,123", "timestamp_s": 944.0}, {"text": "LA where, wherever that shades, those are the non pixels.", "timestamp": "00:15:46,878", "timestamp_s": 946.0}, {"text": "Wherever it\u0027s blank, it\u0027s the ENT part.", "timestamp": "00:15:50,748", "timestamp_s": 950.0}, {"text": "So what it\u0027s basically showing us is over here from the first", "timestamp": "00:15:52,878", "timestamp_s": 952.0}, {"text": "frame to the second frame.", "timestamp": "00:15:56,478", "timestamp_s": 956.0}, {"text": "And it moved.", "timestamp": "00:15:58,078", "timestamp_s": 958.0}, {"text": "It has moved.", "timestamp": "00:15:58,648", "timestamp_s": 958.0}, {"text": "The point has moved like this, the camera has moved like this.", "timestamp": "00:15:59,298", "timestamp_s": 959.0}, {"text": "So it has moved from this position to move like little bit of, little", "timestamp": "00:16:01,638", "timestamp_s": 961.0}, {"text": "bit tilted towards downside.", "timestamp": "00:16:05,538", "timestamp_s": 965.0}, {"text": "So those are the new pixels just coming inside the second frame.", "timestamp": "00:16:06,888", "timestamp_s": 966.0}, {"text": "So that\u0027s what we are storing and we remove the rest of it.", "timestamp": "00:16:09,708", "timestamp_s": 969.0}, {"text": "To reconstruct those second frame with all the pixels.", "timestamp": "00:16:14,343", "timestamp_s": 974.0}, {"text": "I mean with all the remaining redundant part, to make it as a video at the end,", "timestamp": "00:16:18,138", "timestamp_s": 978.0}, {"text": "what we do is we take the redundant part from the first pixel because we sorry.", "timestamp": "00:16:22,638", "timestamp_s": 982.0}, {"text": "First frame.", "timestamp": "00:16:26,678", "timestamp_s": 986.0}, {"text": "We know the first frame is completely, intact where it has all their pixels from", "timestamp": "00:16:27,188", "timestamp_s": 987.0}, {"text": "the first frame, we take the T part and we which is basically the inverse position", "timestamp": "00:16:31,068", "timestamp_s": 991.0}, {"text": "of the second frames redundant position.", "timestamp": "00:16:35,648", "timestamp_s": 995.0}, {"text": "So the second frames redundant coordinates, will be the", "timestamp": "00:16:37,443", "timestamp_s": 997.0}, {"text": "reverse of the first frames.", "timestamp": "00:16:40,443", "timestamp_s": 1000.0}, {"text": "Coordinates positions so that\u0027s what, because that\u0027s why the", "timestamp": "00:16:42,313", "timestamp_s": 1002.0}, {"text": "video is moved like this.", "timestamp": "00:16:45,033", "timestamp_s": 1005.0}, {"text": "So we try to take the redundant part of the pixels, try to", "timestamp": "00:16:46,293", "timestamp_s": 1006.0}, {"text": "reconstruct the second frame.", "timestamp": "00:16:49,143", "timestamp_s": 1009.0}, {"text": "So second frame will be reconstructed.", "timestamp": "00:16:50,733", "timestamp_s": 1010.0}, {"text": "Now, similarly, we know that for the subsequent frames, for frame two,", "timestamp": "00:16:52,173", "timestamp_s": 1012.0}, {"text": "frame three and until the frame, and by doing so, we do the decompression.", "timestamp": "00:16:54,963", "timestamp_s": 1014.0}, {"text": "We bring back everything again.", "timestamp": "00:16:58,173", "timestamp_s": 1018.0}, {"text": "So that\u0027s how we are approaching this and that\u0027s how we do the decompression.", "timestamp": "00:16:59,943", "timestamp_s": 1019.0}, {"text": "And this is basically work.", "timestamp": "00:17:03,243", "timestamp_s": 1023.0}, {"text": "We have done the POC on the single point tracking.", "timestamp": "00:17:04,408", "timestamp_s": 1024.0}, {"text": "So in terms of the results over here yeah.", "timestamp": "00:17:08,463", "timestamp_s": 1028.0}, {"text": "So what we were able to achieve is the compression we try to do is", "timestamp": "00:17:11,223", "timestamp_s": 1031.0}, {"text": "like a 15 times a 15 time per frame.", "timestamp": "00:17:15,163", "timestamp_s": 1035.0}, {"text": "So that basically means we are taking like a 15 milliseconds times", "timestamp": "00:17:18,133", "timestamp_s": 1038.0}, {"text": "per it takes 15 milliseconds to do the compression of per frame.", "timestamp": "00:17:21,548", "timestamp_s": 1041.0}, {"text": "And and it resulting in size of 36 kilo 36 kilobytes.", "timestamp": "00:17:26,513", "timestamp_s": 1046.0}, {"text": "That\u0027s.", "timestamp": "00:17:30,353", "timestamp_s": 1050.0}, {"text": "Per frame, which we are trying to compress over here, and it takes", "timestamp": "00:17:32,723", "timestamp_s": 1052.0}, {"text": "around 15 milliseconds per frame.", "timestamp": "00:17:35,843", "timestamp_s": 1055.0}, {"text": "So let\u0027s say we have a thousand frames it would be basically 15,000 milliseconds.", "timestamp": "00:17:37,583", "timestamp_s": 1057.0}, {"text": "So similarly for decompression, we are trying we, it\u0027s taking", "timestamp": "00:17:42,023", "timestamp_s": 1062.0}, {"text": "around 15 milliseconds over here.", "timestamp": "00:17:45,383", "timestamp_s": 1065.0}, {"text": "And as we are decompressing, we need to reconstruct the frame.", "timestamp": "00:17:47,363", "timestamp_s": 1067.0}, {"text": "So that\u0027s add some extra time per frame and it reconstructs back the", "timestamp": "00:17:50,208", "timestamp_s": 1070.0}, {"text": "the images with each frames looks like around 238 kilobytes over here.", "timestamp": "00:17:54,493", "timestamp_s": 1074.0}, {"text": "And that\u0027s what it has been used.", "timestamp": "00:17:58,783", "timestamp_s": 1078.0}, {"text": "There could be a question of why the compression decompression takes a 15", "timestamp": "00:18:00,943", "timestamp_s": 1080.0}, {"text": "milliseconds and 15 milliseconds is basically the model when we are trying", "timestamp": "00:18:04,213", "timestamp_s": 1084.0}, {"text": "to do the compression, the model has to do the predictions aspect.", "timestamp": "00:18:08,413", "timestamp_s": 1088.0}, {"text": "So it has to do the predictions of where this pixel is moving from one point to", "timestamp": "00:18:11,023", "timestamp_s": 1091.0}, {"text": "the next from one frame to the next frame.", "timestamp": "00:18:15,133", "timestamp_s": 1095.0}, {"text": "So the model takes some.", "timestamp": "00:18:17,353", "timestamp_s": 1097.0}, {"text": "Few milliseconds.", "timestamp": "00:18:19,238", "timestamp_s": 1099.0}, {"text": "And also by, and also we have a builtin algorithm on top of it, which actually use", "timestamp": "00:18:20,138", "timestamp_s": 1100.0}, {"text": "those coordinates to nullify the nullify and store those redundant pixels into an", "timestamp": "00:18:25,063", "timestamp_s": 1105.0}, {"text": "array pixel coordinates into an array.", "timestamp": "00:18:29,963", "timestamp_s": 1109.0}, {"text": "And this just store the, and non-written pixels from the", "timestamp": "00:18:31,883", "timestamp_s": 1111.0}, {"text": "subsequent frames and so on.", "timestamp": "00:18:35,493", "timestamp_s": 1115.0}, {"text": "So that\u0027s why it takes 15 milliseconds and 50 like milliseconds per frame.", "timestamp": "00:18:37,443", "timestamp_s": 1117.0}, {"text": "And eventually this for.", "timestamp": "00:18:42,543", "timestamp_s": 1122.0}, {"text": "For like a one minute video, it takes around currently it\u0027s taking around close", "timestamp": "00:18:46,068", "timestamp_s": 1126.0}, {"text": "to a minute for a two minutes video.", "timestamp": "00:18:50,238", "timestamp_s": 1130.0}, {"text": "It takes close to a minute to do the compressions and store it and and and", "timestamp": "00:18:51,898", "timestamp_s": 1131.0}, {"text": "also the decompression takes pretty much close to two minutes to do that.", "timestamp": "00:18:55,663", "timestamp_s": 1135.0}, {"text": "So it\u0027s quite kind of little slow.", "timestamp": "00:18:58,623", "timestamp_s": 1138.0}, {"text": "The reason is we are trying to do the prediction per.", "timestamp": "00:19:00,833", "timestamp_s": 1140.0}, {"text": "But we can also try to do the predictions per eight frames.", "timestamp": "00:19:03,848", "timestamp_s": 1143.0}, {"text": "Let\u0027s say we have 64 frames in the video, and we can just do it in eight", "timestamp": "00:19:07,048", "timestamp_s": 1147.0}, {"text": "iterations by ha, by trying to predict each eight frames and trying to store it.", "timestamp": "00:19:10,408", "timestamp_s": 1150.0}, {"text": "But eventually what happened was the loss was more when we tried to do eight, eight", "timestamp": "00:19:14,858", "timestamp_s": 1154.0}, {"text": "frames, the prediction was dropping and eventually the data loss was increasing.", "timestamp": "00:19:19,148", "timestamp_s": 1159.0}, {"text": "We had to use per single frame at a time so that the accuracy is really good", "timestamp": "00:19:22,908", "timestamp_s": 1162.0}, {"text": "and the loss is less so that we can try to save lot of, data reduce the data", "timestamp": "00:19:26,688", "timestamp_s": 1166.0}, {"text": "losses and to trying to benchmark it against the existing traditional methods.", "timestamp": "00:19:31,618", "timestamp_s": 1171.0}, {"text": "And you can see that in this graph, right?", "timestamp": "00:19:37,388", "timestamp_s": 1177.0}, {"text": "So as we try to do the compression per eight frames, or per seven frames", "timestamp": "00:19:39,398", "timestamp_s": 1179.0}, {"text": "or per six frames, you can see that the the duction in the size is.", "timestamp": "00:19:43,193", "timestamp_s": 1183.0}, {"text": "When we try to do per eight frames, we are able to reduce the compression.", "timestamp": "00:19:48,633", "timestamp_s": 1188.0}, {"text": "We reduce the size like by 82%, but 82%.", "timestamp": "00:19:52,398", "timestamp_s": 1192.0}, {"text": "But compared to one frame, using using one frame for predictions by doing", "timestamp": "00:19:56,773", "timestamp_s": 1196.0}, {"text": "so we can reduce a lot of the size.", "timestamp": "00:20:00,933", "timestamp_s": 1200.0}, {"text": "And also it can be faster, but the problem is the reason that is", "timestamp": "00:20:03,043", "timestamp_s": 1203.0}, {"text": "able to reduce in size is because increasing number of frames to do", "timestamp": "00:20:06,723", "timestamp_s": 1206.0}, {"text": "the at time to do the prediction also adds a lot of losses to data.", "timestamp": "00:20:10,253", "timestamp_s": 1210.0}, {"text": "That\u0027s why we see the reduction in the total size when we do the compression.", "timestamp": "00:20:13,823", "timestamp_s": 1213.0}, {"text": "And you can see the right hand side graph where as we increase number", "timestamp": "00:20:16,973", "timestamp_s": 1216.0}, {"text": "of frames to use at time to do the prediction for all of the pixel moments.", "timestamp": "00:20:20,303", "timestamp_s": 1220.0}, {"text": "So if you use like eight frames, it just tries to.", "timestamp": "00:20:23,873", "timestamp_s": 1223.0}, {"text": "The arbitrary point and see where it is moving in the first eight", "timestamp": "00:20:27,113", "timestamp_s": 1227.0}, {"text": "pixels so that accuracy is going down because of that the way a working.", "timestamp": "00:20:30,683", "timestamp_s": 1230.0}, {"text": "The, rather than pixels, it also does the wrong thing because it eventually", "timestamp": "00:20:38,393", "timestamp_s": 1238.0}, {"text": "end up having a lot of data losses.", "timestamp": "00:20:42,768", "timestamp_s": 1242.0}, {"text": "And because of that, we can see that the number of the compression", "timestamp": "00:20:44,988", "timestamp_s": 1244.0}, {"text": "percentage is pretty high when we try this number of frames.", "timestamp": "00:20:47,623", "timestamp_s": 1247.0}, {"text": "But also the loss is also high.", "timestamp": "00:20:50,323", "timestamp_s": 1250.0}, {"text": "So then the righthand side graph, you can see that the loss is going", "timestamp": "00:20:52,063", "timestamp_s": 1252.0}, {"text": "pretty high when we try to increase the prediction per eight frames at.", "timestamp": "00:20:55,388", "timestamp_s": 1255.0}, {"text": "At a time.", "timestamp": "00:21:02,393", "timestamp_s": 1262.0}, {"text": "So if you try to do one frame, you can see the loss is very less close to 4%.", "timestamp": "00:21:02,893", "timestamp_s": 1262.0}, {"text": "Whereas if you try to use eight frames using pips plus it\u0027s", "timestamp": "00:21:06,853", "timestamp_s": 1266.0}, {"text": "around sound percent of data loss.", "timestamp": "00:21:09,973", "timestamp_s": 1269.0}, {"text": "So it\u0027s pretty high.", "timestamp": "00:21:11,353", "timestamp_s": 1271.0}, {"text": "Eventually you can see that the quality would be very not very good actually.", "timestamp": "00:21:12,193", "timestamp_s": 1272.0}, {"text": "So then you can see there\u0027s the reason for you to see that", "timestamp": "00:21:16,023", "timestamp_s": 1276.0}, {"text": "there are two lines over here.", "timestamp": "00:21:19,048", "timestamp_s": 1279.0}, {"text": "One is Pips and Pips Plus, plus.", "timestamp": "00:21:20,218", "timestamp_s": 1280.0}, {"text": "There are two different models.", "timestamp": "00:21:21,478", "timestamp_s": 1281.0}, {"text": "One is Pips.", "timestamp": "00:21:23,068", "timestamp_s": 1283.0}, {"text": "Which is initial version of pixel versus the version two of it, which tests", "timestamp": "00:21:24,733", "timestamp_s": 1284.0}, {"text": "better predictions on tracking the trajectories of the pixel point, which", "timestamp": "00:21:28,253", "timestamp_s": 1288.0}, {"text": "we are using to the, of the video to the.", "timestamp": "00:21:31,943", "timestamp_s": 1291.0}, {"text": "And that\u0027s why we try to use both the models to evaluate the performance", "timestamp": "00:21:37,643", "timestamp_s": 1297.0}, {"text": "and eventually in both the models using single frame per at a time", "timestamp": "00:21:41,033", "timestamp_s": 1301.0}, {"text": "to do the prediction does better.", "timestamp": "00:21:45,393", "timestamp_s": 1305.0}, {"text": "Because single frame instance, like using two frames at a time, so it", "timestamp": "00:21:46,923", "timestamp_s": 1306.0}, {"text": "can predict from one frame number one, to frame number two on how where", "timestamp": "00:21:50,283", "timestamp_s": 1310.0}, {"text": "the pixel has been actually shifted.", "timestamp": "00:21:53,823", "timestamp_s": 1313.0}, {"text": "And that\u0027s what the performance graph looks like.", "timestamp": "00:21:56,743", "timestamp_s": 1316.0}, {"text": "And we were able to achieve a better performance by using single frame", "timestamp": "00:21:58,913", "timestamp_s": 1318.0}, {"text": "predictions at the time in the model.", "timestamp": "00:22:03,443", "timestamp_s": 1323.0}, {"text": "So the loss was very much close to 4%.", "timestamp": "00:22:05,433", "timestamp_s": 1325.0}, {"text": "So where we were able to, 96 percentage of the the data and the loss is basically not", "timestamp": "00:22:07,893", "timestamp_s": 1327.0}, {"text": "like a visible loss where we can, where you will see black dots here and there.", "timestamp": "00:22:12,478", "timestamp_s": 1332.0}, {"text": "No, it\u0027s not like the visible, you might still see the video working fine.", "timestamp": "00:22:15,898", "timestamp_s": 1335.0}, {"text": "But but in terms of the quality, there\u0027s 4% reduction quality, but", "timestamp": "00:22:19,563", "timestamp_s": 1339.0}, {"text": "still, we were able to do that compression way better by producing", "timestamp": "00:22:23,853", "timestamp_s": 1343.0}, {"text": "the size of the storage of by 80%.", "timestamp": "00:22:28,503", "timestamp_s": 1348.0}, {"text": "That\u0027s something really great.", "timestamp": "00:22:31,513", "timestamp_s": 1351.0}, {"text": "Around 84, 80 4%.", "timestamp": "00:22:32,748", "timestamp_s": 1352.0}, {"text": "With just 4% loss in data.", "timestamp": "00:22:36,038", "timestamp_s": 1356.0}, {"text": "That, that\u0027s a good cutoff over here.", "timestamp": "00:22:37,708", "timestamp_s": 1357.0}, {"text": "And this is more of like an initial approach of using redundant", "timestamp": "00:22:39,328", "timestamp_s": 1359.0}, {"text": "concept over here to do the storage using ML based approach.", "timestamp": "00:22:42,358", "timestamp_s": 1362.0}, {"text": "So just further approaches and ideas for viewers who are listening", "timestamp": "00:22:47,648", "timestamp_s": 1367.0}, {"text": "to this we can try to use this on multiple point trajectories.", "timestamp": "00:22:52,150", "timestamp_s": 1372.0}, {"text": "That\u0027s what we are trying to work on for our next paper research paper where we", "timestamp": "00:22:56,588", "timestamp_s": 1376.0}, {"text": "are trying to improve this performance for more complex videos where we try to put", "timestamp": "00:23:00,478", "timestamp_s": 1380.0}, {"text": "their trajectories on multiple directions.", "timestamp": "00:23:04,688", "timestamp_s": 1384.0}, {"text": "And and the another approach is basically the object direction masking.", "timestamp": "00:23:07,398", "timestamp_s": 1387.0}, {"text": "This is basically works in places where, let\u0027s say in a given frame there are", "timestamp": "00:23:10,928", "timestamp_s": 1390.0}, {"text": "a human, a dog, or any kind of object.", "timestamp": "00:23:15,408", "timestamp_s": 1395.0}, {"text": "It can mask all those objects and understand the pixels in", "timestamp": "00:23:18,108", "timestamp_s": 1398.0}, {"text": "a very more very smooth way.", "timestamp": "00:23:20,808", "timestamp_s": 1400.0}, {"text": "Like it can put a mask on top of it and I can try to identify the same mask", "timestamp": "00:23:21,705", "timestamp_s": 1401.0}, {"text": "or the same person, the second pixel, and can eventually try to avoid those", "timestamp": "00:23:26,318", "timestamp_s": 1406.0}, {"text": "t pixels in theum frames by masking those object, masking those objects,", "timestamp": "00:23:29,678", "timestamp_s": 1409.0}, {"text": "and then other approach similarity.", "timestamp": "00:23:34,908", "timestamp_s": 1414.0}, {"text": "Such.", "timestamp": "00:23:36,318", "timestamp_s": 1416.0}, {"text": "Similarity search metrics is basically can be used where if you see any similar", "timestamp": "00:23:36,558", "timestamp_s": 1416.0}, {"text": "pixels which already available in the previous frame compared to the new frame.", "timestamp": "00:23:40,908", "timestamp_s": 1420.0}, {"text": "At every pixel level using similarity search metrics, using any kind of cosign", "timestamp": "00:23:44,363", "timestamp_s": 1424.0}, {"text": "similarities or any kind of dot product similarities, we can try to see how", "timestamp": "00:23:48,623", "timestamp_s": 1428.0}, {"text": "close these pixels are and we can try not to store those pixels, the subsequent", "timestamp": "00:23:51,923", "timestamp_s": 1431.0}, {"text": "frames so that we can reuse it and map and reuse these pixels in all those", "timestamp": "00:23:56,243", "timestamp_s": 1436.0}, {"text": "places when we try the decompression.", "timestamp": "00:24:00,233", "timestamp_s": 1440.0}, {"text": "So these are some of the approaches which we can try and open to anyone", "timestamp": "00:24:02,123", "timestamp_s": 1442.0}, {"text": "can give a try on this and try to see if we can come up with a better", "timestamp": "00:24:05,133", "timestamp_s": 1445.0}, {"text": "approaches or better solutions.", "timestamp": "00:24:09,408", "timestamp_s": 1449.0}, {"text": "Yeah, these are the future approaches and I\u0027m I\u0027m hoping machine learning and these", "timestamp": "00:24:11,433", "timestamp_s": 1451.0}, {"text": "AI models not only uses a lot of data to train themselves, but also I hope that", "timestamp": "00:24:16,173", "timestamp_s": 1456.0}, {"text": "gives a scope for us to use AI to also reduce, data storage because a lot of data", "timestamp": "00:24:22,053", "timestamp_s": 1462.0}, {"text": "storage in today\u0027s world is being used to train these machine learning models.", "timestamp": "00:24:28,663", "timestamp_s": 1468.0}, {"text": "In return, I hope these machine learning models can also contribute", "timestamp": "00:24:31,903", "timestamp_s": 1471.0}, {"text": "in a way where it can store things in a optimal way and reduce cost for us.", "timestamp": "00:24:34,693", "timestamp_s": 1474.0}, {"text": "Yeah, so that\u0027s a that\u0027s a good takeaway out of this.", "timestamp": "00:24:39,878", "timestamp_s": 1479.0}, {"text": "Talk that AI not only uses a lot of data, but it can also help us", "timestamp": "00:24:44,158", "timestamp_s": 1484.0}, {"text": "optimize these usage of data, a storage of the data, and this one such", "timestamp": "00:24:48,028", "timestamp_s": 1488.0}, {"text": "approach, which we tried and yeah.", "timestamp": "00:24:52,248", "timestamp_s": 1492.0}, {"text": "And.", "timestamp": "00:24:54,103", "timestamp_s": 1494.0}, {"text": "That\u0027s all.", "timestamp": "00:24:55,053", "timestamp_s": 1495.0}, {"text": "And these are some of the references.", "timestamp": "00:24:55,563", "timestamp_s": 1495.0}, {"text": "That\u0027s the research paper which you can look into and repose there.", "timestamp": "00:24:57,693", "timestamp_s": 1497.0}, {"text": "And these are some of the other references which we looked into to inspire from", "timestamp": "00:25:01,603", "timestamp_s": 1501.0}, {"text": "them and to work on these optimization approaches using deep learning methods.", "timestamp": "00:25:05,483", "timestamp_s": 1505.0}, {"text": "Especially we use the deep convolutional network methods over here.", "timestamp": "00:25:10,113", "timestamp_s": 1510.0}, {"text": "And that\u0027s what this video is all about.", "timestamp": "00:25:13,388", "timestamp_s": 1513.0}, {"text": "And I hope you all enjoyed my.", "timestamp": "00:25:16,118", "timestamp_s": 1516.0}, {"text": "Talk and feel free to reach out to me if you have any questions.", "timestamp": "00:25:18,623", "timestamp_s": 1518.0}, {"text": "Would love to answer and thank you.", "timestamp": "00:25:21,893", "timestamp_s": 1521.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: 'PUdtZnEgdkM',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Optimal Video Compression Using Pixel Shift Tracking
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>Revolutionize video compression in my talk! Video drives 85% of internet traffic, yet traditional methods hit limits. I’ll introduce R2S—Redundancy Removal using Shift—an ML-powered approach that slashes frame redundancy, competes legacy codecs, in optimizes storage. Discover its adaptability now</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./srt/ml2025_Hitesh_Saai_Mananchery.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:01,500'); seek(1.0)">
              Hi everyone.
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:02,400'); seek(2.0)">
              I'm Hitesh.
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:03,280'); seek(3.0)">
              Today I'm going to top on topic on video compression by using AI based approach.
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:08,800'); seek(8.0)">
              And my topic is on optimal video compression using
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:12,090'); seek(12.0)">
              pixel ship tracking method.
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:14,040'); seek(14.0)">
              So before getting into the topic I would like to give a
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:17,240'); seek(17.0)">
              quick introduction about myself.
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:19,374'); seek(19.0)">
              I'm ish.
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:20,234'); seek(20.0)">
              I've been working as a senior machine learning engineer for Expedia Group.
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:24,884'); seek(24.0)">
              I have over seven years of experience in the field of machine learning and ai.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:00:29,154'); seek(29.0)">
              I have worked in several industries like in InsureTech fin FinTech, and
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:00:34,065'); seek(34.0)">
              now I'm working in travel industries.
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:00:36,754'); seek(36.0)">
              I did my masters in mission learning and statistics.
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:00:39,625'); seek(39.0)">
              And from that it's been quite a journey in the field of ai.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:00:42,705'); seek(42.0)">
              And we recently worked on this research idea on video compression, and that's
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:00:47,845'); seek(47.0)">
              what I'm going to talk about today.
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:00:50,065'); seek(50.0)">
              Let's get into the topic.
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:00:52,345'); seek(52.0)">
              So just to give a quick introduction in today's world.
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:00:56,210'); seek(56.0)">
              Videos, traffic is comprised of almost 85 percentage of the internet traffic.
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:01,870'); seek(61.0)">
              From social media alone we get around 10 petabytes of data every day gets processed
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:07,850'); seek(67.0)">
              and stored into the cloud environments.
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:11,070'); seek(71.0)">
              So there are around 20 different VDA compression methods, which
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:14,050'); seek(74.0)">
              has been used, which has been used and being used in the industry.
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:17,840'); seek(77.0)">
              And most of them are a rule-based algorithm approaches.
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:21,240'); seek(81.0)">
              In recent times there has been a lot of research happening in the mission
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:01:25,550'); seek(85.0)">
              learning field on Computeration side, on trying to use AI based approach
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:01:29,830'); seek(89.0)">
              to do compressions of the videos.
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:01:32,110'); seek(92.0)">
              And the main purpose of.
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:01:34,020'); seek(94.0)">
              The research is happening in ML space for video compression that
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:01:37,540'); seek(97.0)">
              using ml it can be used across a diverse video format, irrespective
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:01:41,860'); seek(101.0)">
              of what format we are trying to use.
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:01:44,090'); seek(104.0)">
              And also it can be tapped across any ML framework.
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:01:47,290'); seek(107.0)">
              Irrespective of trying to just be possible in one framework.
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:01:50,200'); seek(110.0)">
              It is framework.
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:01:51,550'); seek(111.0)">
              Independent and also diverse in video formats.
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:01:54,980'); seek(114.0)">
              We are pro, we are proposing an another approach over here and so
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:00,400'); seek(120.0)">
              that's what I'm gonna talk about.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:01,660'); seek(121.0)">
              So before getting into.
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:03,615'); seek(123.0)">
              More detail about our idea.
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:05,145'); seek(125.0)">
              I would just like to give some quick idea of how the video compressions,
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:02:09,635'); seek(129.0)">
              what type of v compressions are done today, and and then we can
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:02:12,875'); seek(132.0)">
              get into the topic of our approach on the pixel ship tracking method.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:02:18,230'); seek(138.0)">
              So in the current current traditional compressional algorithm, these are the
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:02:21,470'); seek(141.0)">
              formats we have been using, which is the H 2 64 H 2 65, AB one B, P eight
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:02:26,690'); seek(146.0)">
              all these things can, could be for some, could be familiar or un, but.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:02:31,555'); seek(151.0)">
              All of these traditional algorithm methods are being used to store all
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:02:34,910'); seek(154.0)">
              these MP G four files, MP fours, MP five for audios and NPG files for videos.
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:02:40,810'); seek(160.0)">
              And the algorithm which is being used at the backend for the compressions of the
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:02:44,320'); seek(164.0)">
              videos or these algorithms basically.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:02:47,140'); seek(167.0)">
              So there are basically two types of compressions.
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:02:49,399'); seek(169.0)">
              One is lossless compression and the loss compressions.
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:02:52,369'); seek(172.0)">
              So loss compressions are the, mostly used format where when we try to compress data
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:02:57,570'); seek(177.0)">
              or we, I try to write and store a data in term of in terms of video, we do see
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:02,609'); seek(182.0)">
              some decrease in the quality of the video.
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:05,179'); seek(185.0)">
              And that's the loss.
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:03:06,059'); seek(186.0)">
              The loss e compressions unless lossless compression, which is more of the the high
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:03:10,190'); seek(190.0)">
              definition videos, which we talk about.
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:03:12,109'); seek(192.0)">
              But, most of the videos which you write or upload to any social
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:03:15,500'); seek(195.0)">
              media or any cloud storages, all of them are being compressed.
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:03:19,730'); seek(199.0)">
              And that's a lossy approach.
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:03:21,524'); seek(201.0)">
              And the approach, which we are going to talk about today is
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:03:24,029'); seek(204.0)">
              also a lossy based approach.
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:03:25,790'); seek(205.0)">
              Logies are not basically something where the data will be lost rather it's just
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:03:29,795'); seek(209.0)">
              the decrease in the quality of the video.
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:03:32,234'); seek(212.0)">
              But from a normal human standpoint a human, viewpoint you won't, you
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:03:36,754'); seek(216.0)">
              wouldn't see a lot of data losses, but granularly, if you try to see that there
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:03:40,790'); seek(220.0)">
              will be a lot of data losses happening.
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:03:42,440'); seek(222.0)">
              But that's the only thing which we lose.
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:03:44,490'); seek(224.0)">
              But we e eventually we try to compress these videos and
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:03:47,570'); seek(227.0)">
              store in a more optimal way.
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:03:49,220'); seek(229.0)">
              And so that's the lossy approach.
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:03:50,870'); seek(230.0)">
              And one of the approaches which we are approaching we are proposing
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:03:53,660'); seek(233.0)">
              today is also a based approach.
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:03:56,775'); seek(236.0)">
              Today in the ai machine learning space these are the, some of the areas that
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:04:01,215'); seek(241.0)">
              researchers are happening on the video compressions which is tapped by the
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:04:05,145'); seek(245.0)">
              encoders, VAE, which is a variant, auto encoders and deep con contextual network.
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:04:10,855'); seek(250.0)">
              So we are our idea is also based on a deep contextual network over here, and that's
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:04:16,470'); seek(256.0)">
              what I'm going to talk talk about today.
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:04:18,979'); seek(258.0)">
              For our approach which is the pixel point tracking approach
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:04:22,129'); seek(262.0)">
              to do the video D compression.
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:04:23,929'); seek(263.0)">
              Yeah, so this is a proposed method.
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:04:25,549'); seek(265.0)">
              So the way we have approached this problem is basically trying to avoid the rid
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:04:30,834'); seek(270.0)">
              then pixels in a video while storing.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:04:33,924'); seek(273.0)">
              So just to give a quick example, so videos are basically comprised of frames.
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:04:39,069'); seek(279.0)">
              For any given video, let's see, even a five second video, there would be at
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:04:42,339'); seek(282.0)">
              least 20 to 30 frames, which we have, which are the, basically the images.
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:04:46,749'); seek(286.0)">
              So when you, when we see as a video, we saw a lot of things
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:04:50,169'); seek(290.0)">
              moving here and there as a video.
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:04:52,059'); seek(292.0)">
              But if you see as a frame.
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:04:53,859'); seek(293.0)">
              Frame by frame, image by image.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:04:56,469'); seek(296.0)">
              We basically see the, there's a lot of redundancy happening from one frame
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:05:00,239'); seek(300.0)">
              to another frame, which is basically storing the same pixels or the same
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:05:04,409'); seek(304.0)">
              data from one frame to another frame.
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:05:06,539'); seek(306.0)">
              And that's what we are trying to avoid by not storing those redundant
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:05:10,439'); seek(310.0)">
              frames from one frame to another frame on all the subsequent frames.
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:05:14,219'); seek(314.0)">
              And, reduce all those un datas and we are trying to optimize the
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:05:18,009'); seek(318.0)">
              storage when we try to store using machine learning based approach.
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:05:21,759'); seek(321.0)">
              So the way we are approaching, or we way we are trying to find this redundant pixel
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:05:26,769'); seek(326.0)">
              is basically trying to track the pixels.
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:05:29,259'); seek(329.0)">
              So for example, when a video has been taken so that you know that a video
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:05:34,239'); seek(334.0)">
              moves in a particular directions, right?
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:05:35,949'); seek(335.0)">
              So it can move from left to right or top to bottom, or it can move from left to
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:05:40,089'); seek(340.0)">
              top or right to top or top to bottom.
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:05:42,519'); seek(342.0)">
              The video can move any anyways.
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:05:44,049'); seek(344.0)">
              So based on the moment of the videos using the coordinates, we are trying to
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:05:47,769'); seek(347.0)">
              understand how far it has moved from a point A to point B. Based on that, we know
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:05:51,849'); seek(351.0)">
              how far the new pixels we are going to get in the next frame, and what are the
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:05:55,479'); seek(355.0)">
              other relevant pixels we are going to.
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:05:57,564'); seek(357.0)">
              Get the next frame from the first frame, and we are trying to nullify those and
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:06:01,904'); seek(361.0)">
              trying to put a black spots on those by doing surveillance already the size of
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:06:05,274'); seek(365.0)">
              a frame or size of a image in the video.
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:06:08,934'); seek(368.0)">
              So there are two different approaches.
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:06:10,974'); seek(370.0)">
              One is single point trajectory method and the multi-point trajectory method.
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:06:15,104'); seek(375.0)">
              So the single point trajectory method is basically using trying to find arbitrary
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:06:19,964'); seek(379.0)">
              point and we are trying to track it.
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:06:21,554'); seek(381.0)">
              And multi-point is basically on trying to use multiple points and trying to track
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:06:25,824'); seek(385.0)">
              the video movement or the frames movement.
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:06:28,764'); seek(388.0)">
              So I'll get into details now of starting with a single point trajectory.
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:06:34,029'); seek(394.0)">
              So for a single point trajectory, what we basically do is we try to
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:06:37,529'); seek(397.0)">
              find an arbitrary point in a in a video in the starting first frame.
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:06:41,259'); seek(401.0)">
              And from there we try to basically track the point from one frame to another frame.
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:06:46,869'); seek(406.0)">
              And this is where we are using a deep learning, a computer vision approach.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:06:50,769'); seek(410.0)">
              We're using a a concept called persistent independent prac
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:06:53,984'); seek(413.0)">
              particles, which is called Pips.
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:06:56,514'); seek(416.0)">
              It's an a research paper written by, another researchers and we
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:07:00,514'); seek(420.0)">
              made use of that over here and to optimize that pips concept in a way.
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:07:05,384'); seek(425.0)">
              And we are trying to achieve the video compression over here.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:07:08,384'); seek(428.0)">
              And that's our approach basically.
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:07:10,214'); seek(430.0)">
              So we basically try to use a single point trajectory over here.
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:07:13,549'); seek(433.0)">
              Which is basically trying to find arbitrary point in
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:07:16,259'); seek(436.0)">
              the first frame of a video.
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:07:17,724'); seek(437.0)">
              And from that we basically try to track where the particular object or a point
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:07:22,024'); seek(442.0)">
              or a pixel is moving from one frame to another frame to subsequent frame.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:07:25,799'); seek(445.0)">
              Based on that, we know what's the, how many coordinates it's moving.
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:07:28,779'); seek(448.0)">
              Based on that we try to see how many new pixels we are going to
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:07:32,019'); seek(452.0)">
              get, and that's what we store.
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:07:33,669'); seek(453.0)">
              We try to avoid the rest.
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:07:35,404'); seek(455.0)">
              So the single point trajectory basically works.
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:07:39,519'); seek(459.0)">
              Only in places where the objects are starting and the video is moving.
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:07:43,724'); seek(463.0)">
              So there are three different ways a video can be seen.
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:07:47,154'); seek(467.0)">
              So one is where the objects are static, where the video is moving or the camera
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:07:51,604'); seek(471.0)">
              is moving, or the camera, or the camera is starting where the objects are moving.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:07:56,799'); seek(476.0)">
              It could be the both.
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:07:57,489'); seek(477.0)">
              A camera and object could be moving at the same time in a video.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:08:00,219'); seek(480.0)">
              So there is three different approaches.
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:08:01,449'); seek(481.0)">
              The single point tracking can solve only in scenarios where the objects are
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:08:05,899'); seek(485.0)">
              static, but the but the camera is moving but Multipoint trajectory can do it.
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:08:11,264'); seek(491.0)">
              Way better by trying to have multiple pixel point tracking trajectories.
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:08:14,779'); seek(494.0)">
              And based on, we can try to get an average movement of it and we
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:08:18,079'); seek(498.0)">
              try to avoid the readable pixels.
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:08:20,629'); seek(500.0)">
              So before getting into Multipoint trajectory, I will just show you a quick
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:08:24,559'); seek(504.0)">
              example of how this tracking looks like.
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:08:27,259'); seek(507.0)">
              You can see here in this picture, there is a dog running.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:08:30,349'); seek(510.0)">
              This is a video where we are trying to track the nose of the dog.
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:08:34,634'); seek(514.0)">
              So the idea is not to track an object here.
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:08:37,114'); seek(517.0)">
              The idea is basically to track in particular pixel, and based
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:08:40,804'); seek(520.0)">
              upon the pixel movement, we can identify what is the redundant
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:08:44,249'); seek(524.0)">
              and the non-redundant part of it.
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:08:46,064'); seek(526.0)">
              As I mentioned, this single point trajectory is achievable
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:08:49,034'); seek(529.0)">
              through an to a not approach.
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:08:52,759'); seek(532.0)">
              I would say like through a method where the objects are
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:08:55,999'); seek(535.0)">
              static, where the camera is.
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:08:58,219'); seek(538.0)">
              So that's what the single point tracking looks like.
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:09:00,399'); seek(540.0)">
              When we try to track it using mission learnings and we are trying to use the
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:09:03,429'); seek(543.0)">
              frames to see where the objects is moving.
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:09:06,009'); seek(546.0)">
              The pixel point is moving.
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:09:08,289'); seek(548.0)">
              So to talk about the multipoint trajectory as I mentioned, so
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:09:12,259'); seek(552.0)">
              Multipoint trajectory basically works.
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:09:14,029'); seek(554.0)">
              When when you try to put the pixel points, the trajectory points in
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:09:18,199'); seek(558.0)">
              multiple places in like a grid format, in a 2D grid format.
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:09:22,034'); seek(562.0)">
              And when by doing so, so now what it does is in a given frame let's say we have
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:09:27,744'); seek(567.0)">
              a eight by eight frame where you put 64 points or 64 trajectory points, which can
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:09:32,979'); seek(572.0)">
              track all the 64 positions within a grid where it could be a midpoint of every
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:09:37,579'); seek(577.0)">
              small grid positions within the eight by pixel image, so by a by eight image size.
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:09:42,649'); seek(582.0)">
              So by doing so, what happens is can also track.
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:09:45,364'); seek(585.0)">
              Object movement.
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:09:46,179'); seek(586.0)">
              It can also track the camera movements.
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:09:48,609'); seek(588.0)">
              And by by calibrating all of those, we can try to find what is the only T part,
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:09:53,779'); seek(593.0)">
              which is what are the non-redundant part which can we can expect in the
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:09:57,014'); seek(597.0)">
              next frame compared to the first frame.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:09:58,814'); seek(598.0)">
              And this can mostly work in in a very advanced approaches where the videos
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:10:03,274'); seek(603.0)">
              is very complex and that's where the multi-point trajectory element lead.
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:10:06,999'); seek(606.0)">
              Be helpful to just give a quick visual of how the multipoint
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:10:10,919'); seek(610.0)">
              like would, will look like.
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:10:13,049'); seek(613.0)">
              Is from the previous video we saw that there was a dog and the dog
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:10:16,429'); seek(616.0)">
              was moving and we were just pointing one and, I can go back here.
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:10:20,809'); seek(620.0)">
              So you can see here, it's just tracking one trajectory and this tr
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:10:24,084'); seek(624.0)">
              looks like it's going like a it looks like a, some kind of leaf, right?
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:10:27,924'); seek(627.0)">
              So that's why, that's how it's moving.
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:10:29,694'); seek(629.0)">
              But in this case, in this video, we can see that the dog the object as
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:10:34,474'); seek(634.0)">
              far as the video, both are moving.
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:10:36,269'); seek(636.0)">
              So a single point trajectory would not effectively can say
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:10:39,269'); seek(639.0)">
              how the pixels are moving.
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:10:40,809'); seek(640.0)">
              But by using a multi-point trajectory.
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:10:43,019'); seek(643.0)">
              You can see here actually the how the entire video from one frame to another
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:10:48,269'); seek(648.0)">
              frame, or at least this is like a, let's say it's a two second video, might be
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:10:51,839'); seek(651.0)">
              we have four to five frames in this.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:10:53,969'); seek(653.0)">
              We can see from frame one to frame five, how far it has been shifted.
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:10:57,509'); seek(657.0)">
              So this can give like an overview of how the pixels are
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:11:02,114'); seek(662.0)">
              moving at different positions.
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:11:03,914'); seek(663.0)">
              And based on that, every single positions we can see, what are the
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:11:07,544'); seek(667.0)">
              pixels we need to store, what are the coordinates we need to store?
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:11:10,524'); seek(670.0)">
              What are the quad, what are the position coordinates we, we can avoid storing and
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:11:13,944'); seek(673.0)">
              we can retribute from the previous spring.
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:11:15,934'); seek(675.0)">
              And that's what we are trying to do over here.
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:11:18,604'); seek(678.0)">
              So let's get into the steps on how we have achieved it.
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:11:22,294'); seek(682.0)">
              So for the compression step just to give a quick note, we in this approach
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:11:26,004'); seek(686.0)">
              we are trying to prove that this is possible to pixel point tracking by
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:11:29,374'); seek(689.0)">
              using a single trajectory method.
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:11:30,814'); seek(690.0)">
              So we have used that as a proof of concept over here to display displayed
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:11:34,929'); seek(694.0)">
              and show that this is possible.
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:11:36,939'); seek(696.0)">
              And so as a step one, using a single point trajectory method.
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:11:41,529'); seek(701.0)">
              We arbitrarily choose a point in a video.
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:11:43,939'); seek(703.0)">
              So we are using a video.
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:11:45,169'); seek(705.0)">
              We used a video where the objects are static, but the
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:11:47,869'); seek(707.0)">
              video the camera is moving.
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:11:49,149'); seek(709.0)">
              The video is moving.
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:11:50,649'); seek(710.0)">
              Basically in the video, the camera is moving, sorry.
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:11:52,969'); seek(712.0)">
              We use like a, let's say a midpoint, the in the frame.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:11:55,584'); seek(715.0)">
              And and we are tracking that point over here.
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:11:57,434'); seek(717.0)">
              So we choose arbitrary point for the the pips to track the present
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:12:02,094'); seek(722.0)">
              independent particles model to track.
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:12:04,529'); seek(724.0)">
              And it basically process basically eight frames at a time.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:12:07,989'); seek(727.0)">
              So to have, to improve the accuracy, we are trying to use one frame at a
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:12:11,799'); seek(731.0)">
              time to predict what bad the pixels are moving first, why that point is moving
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:12:15,739'); seek(735.0)">
              from one frame to so from first frame to second frame for the given pixel point.
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:12:20,069'); seek(740.0)">
              So we first, we place a random point.
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:12:23,119'); seek(743.0)">
              Arbitrary point in the first frame, and then we try to track the frame from frame
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:12:27,109'); seek(747.0)">
              by frame one frame to another frame.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:12:28,919'); seek(748.0)">
              While we are trying to track.
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:12:30,209'); seek(750.0)">
              So let's say we were, we had a, we were at a point in frame one, and eventually
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:12:35,234'); seek(755.0)">
              when we try to move from frame one to frame one, to frame two, let's say mode
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:12:39,919'); seek(759.0)">
              four coordinates to the right, we know that there are, there is going to be.
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:12:43,439'); seek(763.0)">
              A with of four pixels.
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:12:45,953'); seek(765.0)">
              Four with of four size pixels going to come inside.
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:12:48,913'); seek(768.0)">
              And I know the rest of that part on the left side of the first frame is gonna
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:12:52,723'); seek(772.0)">
              be redundant and should be available.
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:12:54,583'); seek(774.0)">
              Same pixels in the second frame.
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:12:56,393'); seek(776.0)">
              So that's what we are going to nullify and direct delete that
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:12:59,588'); seek(779.0)">
              and store only the non pixels.
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:13:02,368'); seek(782.0)">
              And that's what the compression part does for one frame to the second frame.
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:13:06,598'); seek(786.0)">
              And similarly, from second frame to the third frame to so on.
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:13:09,298'); seek(789.0)">
              That's how we try to compress these.
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:13:12,448'); seek(792.0)">
              So just give a quick idea of how that looks like.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:13:14,658'); seek(794.0)">
              You can see here in the frame one in the frame one, there's we can see that sorry.
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:13:19,363'); seek(799.0)">
              So the framework, we can see that over here, that the.
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:13:23,418'); seek(803.0)">
              This is the complete image and the, in the frame two, what ha what's happening is it
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:13:27,858'); seek(807.0)">
              has mowed like few pixels to the right.
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:13:30,828'); seek(810.0)">
              So when we are trying to do the compression, the second frame won't
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:13:33,798'); seek(813.0)">
              look like how we see the second picture or second picture over here, rather.
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:13:38,778'); seek(818.0)">
              It would look like the third picture in the image where it basically
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:13:44,908'); seek(824.0)">
              all of the redundant pixels and it stores only the non-redundant pixel
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:13:49,148'); seek(829.0)">
              in the storage for the second frame.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:13:51,713'); seek(831.0)">
              Similarly, we do it from the third frame, fourth frame, and so on.
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:13:54,833'); seek(834.0)">
              And by doing so, we try as we are putting a black value of zero in terms
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:13:58,583'); seek(838.0)">
              of pixel to all the redundant part we reduce the size during the compression
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:14:03,093'); seek(843.0)">
              or this is how the compression part work.
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:14:05,163'); seek(845.0)">
              And now I'll get into how the decompression part work.
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:14:09,278'); seek(849.0)">
              So the decompression part is an interesting one.
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:14:11,463'); seek(851.0)">
              It's a very intuitive approach.
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:14:12,633'); seek(852.0)">
              So what we have done is so that in the process of this compressions, the
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:14:16,863'); seek(856.0)">
              first frame will always remain intact.
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:14:19,598'); seek(859.0)">
              That basically means like it could be whatever it is, the
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:14:22,718'); seek(862.0)">
              first frame, it remains the same.
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:14:24,653'); seek(864.0)">
              We don't because for the first frame there is nothing called render than pixel.
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:14:28,013'); seek(868.0)">
              That's the first frame.
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:14:29,118'); seek(869.0)">
              So first frame always stores the entire data that without with any
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:14:33,508'); seek(873.0)">
              of the data points in the pixel data points, which is so called the pixels.
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:14:37,253'); seek(877.0)">
              So now what happens during the decompression step over here is,
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:14:40,733'); seek(880.0)">
              so during the compression, we know that from frame one to frame two.
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:14:45,438'); seek(885.0)">
              Four, four coordinates to the right on the X axis.
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:14:48,588'); seek(888.0)">
              So we, what we basically do is that's this, that's the only new width, which
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:14:52,358'); seek(892.0)">
              we are looking from the second frame, and that's what we stored from the
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:14:54,788'); seek(894.0)">
              second frame and we nullify the wrist.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:14:56,918'); seek(896.0)">
              So those nullified positions are stored as an array.
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:15:00,868'); seek(900.0)">
              On, on, on collecting those coordinates positions alone, which is basically
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:15:05,578'); seek(905.0)">
              the a, the X axis and the yxi points on basically let's say like a rectangle.
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:15:11,428'); seek(911.0)">
              So it takes four coordinate points, and we store it for a reframe on
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:15:15,148'); seek(915.0)">
              what has to be recomposed when we try to de do the decompressions.
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:15:19,578'); seek(919.0)">
              So basically we, when we do the compression, we store all
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:15:22,218'); seek(922.0)">
              the all the frames by storing only the non-resistant pixels.
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:15:26,208'); seek(926.0)">
              And then we also stored a separate array, which basically holds the
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:15:30,068'); seek(930.0)">
              holds the coordinates of the redundant positions, which can be obtained from
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:15:34,108'); seek(934.0)">
              the previous pixel sorry, previous frame.
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:15:36,258'); seek(936.0)">
              So how that basically would work is if you see here in the first image
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:15:39,743'); seek(939.0)">
              the data retrieval frame, right?
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:15:41,753'); seek(941.0)">
              So this is the first frame from the first frame to second frame.
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:15:44,123'); seek(944.0)">
              If you see the second the.
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:15:46,878'); seek(946.0)">
              LA where, wherever that shades, those are the non pixels.
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:15:50,748'); seek(950.0)">
              Wherever it's blank, it's the ENT part.
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:15:52,878'); seek(952.0)">
              So what it's basically showing us is over here from the first
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:15:56,478'); seek(956.0)">
              frame to the second frame.
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:15:58,078'); seek(958.0)">
              And it moved.
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:15:58,648'); seek(958.0)">
              It has moved.
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:15:59,298'); seek(959.0)">
              The point has moved like this, the camera has moved like this.
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:16:01,638'); seek(961.0)">
              So it has moved from this position to move like little bit of, little
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:16:05,538'); seek(965.0)">
              bit tilted towards downside.
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:16:06,888'); seek(966.0)">
              So those are the new pixels just coming inside the second frame.
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:16:09,708'); seek(969.0)">
              So that's what we are storing and we remove the rest of it.
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:16:14,343'); seek(974.0)">
              To reconstruct those second frame with all the pixels.
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:16:18,138'); seek(978.0)">
              I mean with all the remaining redundant part, to make it as a video at the end,
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:16:22,638'); seek(982.0)">
              what we do is we take the redundant part from the first pixel because we sorry.
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:16:26,678'); seek(986.0)">
              First frame.
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:16:27,188'); seek(987.0)">
              We know the first frame is completely, intact where it has all their pixels from
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:16:31,068'); seek(991.0)">
              the first frame, we take the T part and we which is basically the inverse position
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:16:35,648'); seek(995.0)">
              of the second frames redundant position.
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:16:37,443'); seek(997.0)">
              So the second frames redundant coordinates, will be the
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:16:40,443'); seek(1000.0)">
              reverse of the first frames.
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:16:42,313'); seek(1002.0)">
              Coordinates positions so that's what, because that's why the
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:16:45,033'); seek(1005.0)">
              video is moved like this.
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:16:46,293'); seek(1006.0)">
              So we try to take the redundant part of the pixels, try to
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:16:49,143'); seek(1009.0)">
              reconstruct the second frame.
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:16:50,733'); seek(1010.0)">
              So second frame will be reconstructed.
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:16:52,173'); seek(1012.0)">
              Now, similarly, we know that for the subsequent frames, for frame two,
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:16:54,963'); seek(1014.0)">
              frame three and until the frame, and by doing so, we do the decompression.
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:16:58,173'); seek(1018.0)">
              We bring back everything again.
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:16:59,943'); seek(1019.0)">
              So that's how we are approaching this and that's how we do the decompression.
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:17:03,243'); seek(1023.0)">
              And this is basically work.
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:17:04,408'); seek(1024.0)">
              We have done the POC on the single point tracking.
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:17:08,463'); seek(1028.0)">
              So in terms of the results over here yeah.
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:17:11,223'); seek(1031.0)">
              So what we were able to achieve is the compression we try to do is
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:17:15,163'); seek(1035.0)">
              like a 15 times a 15 time per frame.
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:17:18,133'); seek(1038.0)">
              So that basically means we are taking like a 15 milliseconds times
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:17:21,548'); seek(1041.0)">
              per it takes 15 milliseconds to do the compression of per frame.
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:17:26,513'); seek(1046.0)">
              And and it resulting in size of 36 kilo 36 kilobytes.
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:17:30,353'); seek(1050.0)">
              That's.
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:17:32,723'); seek(1052.0)">
              Per frame, which we are trying to compress over here, and it takes
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:17:35,843'); seek(1055.0)">
              around 15 milliseconds per frame.
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:17:37,583'); seek(1057.0)">
              So let's say we have a thousand frames it would be basically 15,000 milliseconds.
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:17:42,023'); seek(1062.0)">
              So similarly for decompression, we are trying we, it's taking
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:17:45,383'); seek(1065.0)">
              around 15 milliseconds over here.
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:17:47,363'); seek(1067.0)">
              And as we are decompressing, we need to reconstruct the frame.
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:17:50,208'); seek(1070.0)">
              So that's add some extra time per frame and it reconstructs back the
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:17:54,493'); seek(1074.0)">
              the images with each frames looks like around 238 kilobytes over here.
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:17:58,783'); seek(1078.0)">
              And that's what it has been used.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:18:00,943'); seek(1080.0)">
              There could be a question of why the compression decompression takes a 15
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:18:04,213'); seek(1084.0)">
              milliseconds and 15 milliseconds is basically the model when we are trying
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:18:08,413'); seek(1088.0)">
              to do the compression, the model has to do the predictions aspect.
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:18:11,023'); seek(1091.0)">
              So it has to do the predictions of where this pixel is moving from one point to
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:18:15,133'); seek(1095.0)">
              the next from one frame to the next frame.
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:18:17,353'); seek(1097.0)">
              So the model takes some.
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:18:19,238'); seek(1099.0)">
              Few milliseconds.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:18:20,138'); seek(1100.0)">
              And also by, and also we have a builtin algorithm on top of it, which actually use
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:18:25,063'); seek(1105.0)">
              those coordinates to nullify the nullify and store those redundant pixels into an
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:18:29,963'); seek(1109.0)">
              array pixel coordinates into an array.
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:18:31,883'); seek(1111.0)">
              And this just store the, and non-written pixels from the
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:18:35,493'); seek(1115.0)">
              subsequent frames and so on.
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:18:37,443'); seek(1117.0)">
              So that's why it takes 15 milliseconds and 50 like milliseconds per frame.
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:18:42,543'); seek(1122.0)">
              And eventually this for.
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:18:46,068'); seek(1126.0)">
              For like a one minute video, it takes around currently it's taking around close
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:18:50,238'); seek(1130.0)">
              to a minute for a two minutes video.
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:18:51,898'); seek(1131.0)">
              It takes close to a minute to do the compressions and store it and and and
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:18:55,663'); seek(1135.0)">
              also the decompression takes pretty much close to two minutes to do that.
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:18:58,623'); seek(1138.0)">
              So it's quite kind of little slow.
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:19:00,833'); seek(1140.0)">
              The reason is we are trying to do the prediction per.
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:19:03,848'); seek(1143.0)">
              But we can also try to do the predictions per eight frames.
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:19:07,048'); seek(1147.0)">
              Let's say we have 64 frames in the video, and we can just do it in eight
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:19:10,408'); seek(1150.0)">
              iterations by ha, by trying to predict each eight frames and trying to store it.
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:19:14,858'); seek(1154.0)">
              But eventually what happened was the loss was more when we tried to do eight, eight
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:19:19,148'); seek(1159.0)">
              frames, the prediction was dropping and eventually the data loss was increasing.
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:19:22,908'); seek(1162.0)">
              We had to use per single frame at a time so that the accuracy is really good
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:19:26,688'); seek(1166.0)">
              and the loss is less so that we can try to save lot of, data reduce the data
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:19:31,618'); seek(1171.0)">
              losses and to trying to benchmark it against the existing traditional methods.
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:19:37,388'); seek(1177.0)">
              And you can see that in this graph, right?
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:19:39,398'); seek(1179.0)">
              So as we try to do the compression per eight frames, or per seven frames
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:19:43,193'); seek(1183.0)">
              or per six frames, you can see that the the duction in the size is.
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:19:48,633'); seek(1188.0)">
              When we try to do per eight frames, we are able to reduce the compression.
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:19:52,398'); seek(1192.0)">
              We reduce the size like by 82%, but 82%.
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:19:56,773'); seek(1196.0)">
              But compared to one frame, using using one frame for predictions by doing
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:20:00,933'); seek(1200.0)">
              so we can reduce a lot of the size.
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:20:03,043'); seek(1203.0)">
              And also it can be faster, but the problem is the reason that is
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:20:06,723'); seek(1206.0)">
              able to reduce in size is because increasing number of frames to do
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:20:10,253'); seek(1210.0)">
              the at time to do the prediction also adds a lot of losses to data.
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:20:13,823'); seek(1213.0)">
              That's why we see the reduction in the total size when we do the compression.
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:20:16,973'); seek(1216.0)">
              And you can see the right hand side graph where as we increase number
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:20:20,303'); seek(1220.0)">
              of frames to use at time to do the prediction for all of the pixel moments.
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:20:23,873'); seek(1223.0)">
              So if you use like eight frames, it just tries to.
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:20:27,113'); seek(1227.0)">
              The arbitrary point and see where it is moving in the first eight
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:20:30,683'); seek(1230.0)">
              pixels so that accuracy is going down because of that the way a working.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:20:38,393'); seek(1238.0)">
              The, rather than pixels, it also does the wrong thing because it eventually
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:20:42,768'); seek(1242.0)">
              end up having a lot of data losses.
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:20:44,988'); seek(1244.0)">
              And because of that, we can see that the number of the compression
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:20:47,623'); seek(1247.0)">
              percentage is pretty high when we try this number of frames.
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:20:50,323'); seek(1250.0)">
              But also the loss is also high.
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:20:52,063'); seek(1252.0)">
              So then the righthand side graph, you can see that the loss is going
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:20:55,388'); seek(1255.0)">
              pretty high when we try to increase the prediction per eight frames at.
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:21:02,393'); seek(1262.0)">
              At a time.
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:21:02,893'); seek(1262.0)">
              So if you try to do one frame, you can see the loss is very less close to 4%.
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:21:06,853'); seek(1266.0)">
              Whereas if you try to use eight frames using pips plus it's
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:21:09,973'); seek(1269.0)">
              around sound percent of data loss.
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:21:11,353'); seek(1271.0)">
              So it's pretty high.
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:21:12,193'); seek(1272.0)">
              Eventually you can see that the quality would be very not very good actually.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:21:16,023'); seek(1276.0)">
              So then you can see there's the reason for you to see that
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:21:19,048'); seek(1279.0)">
              there are two lines over here.
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:21:20,218'); seek(1280.0)">
              One is Pips and Pips Plus, plus.
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:21:21,478'); seek(1281.0)">
              There are two different models.
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:21:23,068'); seek(1283.0)">
              One is Pips.
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:21:24,733'); seek(1284.0)">
              Which is initial version of pixel versus the version two of it, which tests
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:21:28,253'); seek(1288.0)">
              better predictions on tracking the trajectories of the pixel point, which
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:21:31,943'); seek(1291.0)">
              we are using to the, of the video to the.
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:21:37,643'); seek(1297.0)">
              And that's why we try to use both the models to evaluate the performance
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:21:41,033'); seek(1301.0)">
              and eventually in both the models using single frame per at a time
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:21:45,393'); seek(1305.0)">
              to do the prediction does better.
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:21:46,923'); seek(1306.0)">
              Because single frame instance, like using two frames at a time, so it
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:21:50,283'); seek(1310.0)">
              can predict from one frame number one, to frame number two on how where
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:21:53,823'); seek(1313.0)">
              the pixel has been actually shifted.
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:21:56,743'); seek(1316.0)">
              And that's what the performance graph looks like.
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:21:58,913'); seek(1318.0)">
              And we were able to achieve a better performance by using single frame
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:22:03,443'); seek(1323.0)">
              predictions at the time in the model.
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:22:05,433'); seek(1325.0)">
              So the loss was very much close to 4%.
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:22:07,893'); seek(1327.0)">
              So where we were able to, 96 percentage of the the data and the loss is basically not
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:22:12,478'); seek(1332.0)">
              like a visible loss where we can, where you will see black dots here and there.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:22:15,898'); seek(1335.0)">
              No, it's not like the visible, you might still see the video working fine.
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:22:19,563'); seek(1339.0)">
              But but in terms of the quality, there's 4% reduction quality, but
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:22:23,853'); seek(1343.0)">
              still, we were able to do that compression way better by producing
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:22:28,503'); seek(1348.0)">
              the size of the storage of by 80%.
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:22:31,513'); seek(1351.0)">
              That's something really great.
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:22:32,748'); seek(1352.0)">
              Around 84, 80 4%.
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:22:36,038'); seek(1356.0)">
              With just 4% loss in data.
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:22:37,708'); seek(1357.0)">
              That, that's a good cutoff over here.
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:22:39,328'); seek(1359.0)">
              And this is more of like an initial approach of using redundant
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:22:42,358'); seek(1362.0)">
              concept over here to do the storage using ML based approach.
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:22:47,648'); seek(1367.0)">
              So just further approaches and ideas for viewers who are listening
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:22:52,150'); seek(1372.0)">
              to this we can try to use this on multiple point trajectories.
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:22:56,588'); seek(1376.0)">
              That's what we are trying to work on for our next paper research paper where we
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:23:00,478'); seek(1380.0)">
              are trying to improve this performance for more complex videos where we try to put
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:23:04,688'); seek(1384.0)">
              their trajectories on multiple directions.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:23:07,398'); seek(1387.0)">
              And and the another approach is basically the object direction masking.
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:23:10,928'); seek(1390.0)">
              This is basically works in places where, let's say in a given frame there are
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:23:15,408'); seek(1395.0)">
              a human, a dog, or any kind of object.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:23:18,108'); seek(1398.0)">
              It can mask all those objects and understand the pixels in
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:23:20,808'); seek(1400.0)">
              a very more very smooth way.
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:23:21,705'); seek(1401.0)">
              Like it can put a mask on top of it and I can try to identify the same mask
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:23:26,318'); seek(1406.0)">
              or the same person, the second pixel, and can eventually try to avoid those
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:23:29,678'); seek(1409.0)">
              t pixels in theum frames by masking those object, masking those objects,
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:23:34,908'); seek(1414.0)">
              and then other approach similarity.
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:23:36,318'); seek(1416.0)">
              Such.
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:23:36,558'); seek(1416.0)">
              Similarity search metrics is basically can be used where if you see any similar
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:23:40,908'); seek(1420.0)">
              pixels which already available in the previous frame compared to the new frame.
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:23:44,363'); seek(1424.0)">
              At every pixel level using similarity search metrics, using any kind of cosign
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:23:48,623'); seek(1428.0)">
              similarities or any kind of dot product similarities, we can try to see how
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:23:51,923'); seek(1431.0)">
              close these pixels are and we can try not to store those pixels, the subsequent
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:23:56,243'); seek(1436.0)">
              frames so that we can reuse it and map and reuse these pixels in all those
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:24:00,233'); seek(1440.0)">
              places when we try the decompression.
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:24:02,123'); seek(1442.0)">
              So these are some of the approaches which we can try and open to anyone
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:24:05,133'); seek(1445.0)">
              can give a try on this and try to see if we can come up with a better
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:24:09,408'); seek(1449.0)">
              approaches or better solutions.
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:24:11,433'); seek(1451.0)">
              Yeah, these are the future approaches and I'm I'm hoping machine learning and these
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:24:16,173'); seek(1456.0)">
              AI models not only uses a lot of data to train themselves, but also I hope that
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:24:22,053'); seek(1462.0)">
              gives a scope for us to use AI to also reduce, data storage because a lot of data
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:24:28,663'); seek(1468.0)">
              storage in today's world is being used to train these machine learning models.
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:24:31,903'); seek(1471.0)">
              In return, I hope these machine learning models can also contribute
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:24:34,693'); seek(1474.0)">
              in a way where it can store things in a optimal way and reduce cost for us.
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:24:39,878'); seek(1479.0)">
              Yeah, so that's a that's a good takeaway out of this.
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:24:44,158'); seek(1484.0)">
              Talk that AI not only uses a lot of data, but it can also help us
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:24:48,028'); seek(1488.0)">
              optimize these usage of data, a storage of the data, and this one such
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:24:52,248'); seek(1492.0)">
              approach, which we tried and yeah.
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:24:54,103'); seek(1494.0)">
              And.
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:24:55,053'); seek(1495.0)">
              That's all.
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:24:55,563'); seek(1495.0)">
              And these are some of the references.
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:24:57,693'); seek(1497.0)">
              That's the research paper which you can look into and repose there.
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:25:01,603'); seek(1501.0)">
              And these are some of the other references which we looked into to inspire from
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:25:05,483'); seek(1505.0)">
              them and to work on these optimization approaches using deep learning methods.
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:25:10,113'); seek(1510.0)">
              Especially we use the deep convolutional network methods over here.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:25:13,388'); seek(1513.0)">
              And that's what this video is all about.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:25:16,118'); seek(1516.0)">
              And I hope you all enjoyed my.
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:25:18,623'); seek(1518.0)">
              Talk and feel free to reach out to me if you have any questions.
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:25:21,893'); seek(1521.0)">
              Would love to answer and thank you.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Hitesh%20Saai%20Mananchery%20-%20Conf42%20Machine%20Learning%202025.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Hitesh%20Saai%20Mananchery%20-%20Conf42%20Machine%20Learning%202025.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2025" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 136 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/Hitesh%20Saai%20Mananchery_ml.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Hitesh Saai Mananchery
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Senior Machine Learning Engineer @ Expedia Group
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://arxiv.org/abs/2406.19630" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Hitesh Saai Mananchery's LinkedIn account" />
                  </a>
                  
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by Hitesh Saai Mananchery"
                  data-url="https://www.conf42.com/ml2025"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2025"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4 justify-content-center">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Access to all content</b>
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe for FREE<i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2026
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2026">
                  DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2026">
                  Machine Learning 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2026">
                  Site Reliability Engineering (SRE) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2026">
                  Cloud Native 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2026">
                  Golang 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/dbd2026">
                  Database DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2026">
                  Large Language Models (LLMs) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2026">
                  Observability 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/agents2026">
                  AI Agents 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2026">
                  DevSecOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2026">
                  Prompt Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2026">
                  Platform Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2026">
                  MLOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2026">
                  Chaos Engineering 2026
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>