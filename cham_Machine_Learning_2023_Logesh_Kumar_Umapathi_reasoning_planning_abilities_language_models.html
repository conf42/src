<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-77190356-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-77190356-3');
    </script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="stylesheet" href="https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.css" />
    <link rel="stylesheet" href="./assets/css/libs.bundle.css" />
    <link rel="stylesheet" href="./assets/css/theme.bundle.css" />
    <link rel="stylesheet" href="./assets/css/various.css" />

    <title>Conf42: Unlocking reasoning and planning abilities in Large language models</title>
    <meta name="description" content="Like the Machines need our help to take over the world">

    
    <meta name="image" property="og:image" content="https://www.conf42.com/assets/headshots/https://conf42.github.io/static/headshots/ml_logesh_kumar_umapathi.png">
    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Unlocking reasoning and planning abilities in Large language models | Conf42"/>
    <meta property="og:description" content="We will explore the latest breakthroughs and discuss how LLMs can be used to solve complex problems that require reasoning and planning. By unlocking these capabilities, LLMs can be used to build sophisticated chatbots, intelligent assistants, and other NLP applications"/>
    <meta property="og:url" content="https://conf42.com/Machine_Learning_2023_Logesh_Kumar_Umapathi_reasoning_planning_abilities_language_models"/>
    

    <link rel="shortcut icon" href="./assets/favicon/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png">
    <link rel="manifest" href="./assets/favicon/site.webmanifest">

    

  <!-- Reddit Pixel -->
  <script>
  !function(w,d){if(!w.rdt){var p=w.rdt=function(){p.sendEvent?p.sendEvent.apply(p,arguments):p.callQueue.push(arguments)};p.callQueue=[];var t=d.createElement("script");t.src="https://www.redditstatic.com/ads/pixel.js",t.async=!0;var s=d.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}}(window,document);rdt('init','a2_e019g7ndfhrm', {"optOut":false,"useDecimalCurrencyValues":true,"aaid":"<AAID-HERE>"});rdt('track', 'PageVisit');
  </script>
  <!-- DO NOT MODIFY UNLESS TO REPLACE A USER IDENTIFIER -->
  <!-- End Reddit Pixel -->

  </head>
  <body>

    <!-- NAVBAR -->
    
    <!-- <nav class="navbar navbar-expand-lg navbar-light bg-light"> -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    
      <div class="container">
    
        <!-- Brand -->
        <a class="navbar-brand" href="./">
          <img src="./assets/conf42/conf42_logo_black_small.png" class="navbar-brand-img" alt="...">
        </a>
    
        <!-- Toggler -->
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <!-- Collapse -->
        <div class="collapse navbar-collapse" id="navbarCollapse">
    
          <!-- Toggler -->
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fe fe-x"></i>
          </button>
    
          <!-- Navigation -->
          <ul class="navbar-nav ms-auto">

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Events
              </a>
              <div class="dropdown-menu dropdown-menu-xl p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-6">
                    <!-- <div class="dropdown-img-start" style="background-image: url(./assets/splash/IOT2025_Event_Splash.png);"> -->
                    <div class="dropdown-img-start">
                      <!-- Heading -->
                      <h4 class="fw-bold text-white mb-0">
                        Featured event
                      </h4>
                      <!-- Text -->
                      <p class="fs-sm text-white">
                        Internet of Things (IoT) 2025
                      </p>
                      <p class="fs-sm text-white">
                        Premiere 2025-12-18
                      </p>
                      <!-- Button -->
                      <a href="https://www.conf42.com/iot2025" class="btn btn-sm btn-white shadow-dark fonFt-size-sm">
                        Learn more
                      </a>
                    </div>
                  </div>
                  <div class="col-12 col-lg-6">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
    
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2026
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2026">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2026">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2026">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2026">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2026">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/dbd2026">
                            Database DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2026">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2026">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/agents2026">
                            AI Agents
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2026">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2026">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2026">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2026">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2026">
                            Chaos Engineering
                          </a>
                          
                        
                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            2025
                          </h6>
                          <!-- List -->
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devops2025">
                            DevOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/python2025">
                            Python
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ce2025">
                            Chaos Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/cloud2025">
                            Cloud Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/llms2025">
                            Large Language Models (LLMs)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/golang2025">
                            Golang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/sre2025">
                            Site Reliability Engineering (SRE)
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/ml2025">
                            Machine Learning
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/obs2025">
                            Observability
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/quantum2025">
                            Quantum Computing
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/rustlang2025">
                            Rustlang
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/platform2025">
                            Platform Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/mlops2025">
                            MLOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/im2025">
                            Incident Management
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/kubenative2025">
                            Kube Native
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/js2025">
                            JavaScript
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/prompt2025">
                            Prompt Engineering
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/robotics2025">
                            Robotics
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/devsecops2025">
                            DevSecOps
                          </a>
                          
                          <a class="dropdown-item" href="https://www.conf42.com/iot2025">
                            Internet of Things (IoT)
                          </a>
                          
                        

                          <!-- Heading -->
                          <h6 class="dropdown-header mt-5">
                            Info
                          </h6>
                          <a class="dropdown-item" href="./code-of-conduct">
                            Code of Conduct
                          </a>
    
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" id="navbarLandings" data-bs-toggle="dropdown" href="#" aria-haspopup="true" aria-expanded="false">
                Community
              </a>
              <div class="dropdown-menu dropdown-menu-l p-0" aria-labelledby="navbarLandings">
                <div class="row gx-0">
                  <div class="col-12 col-lg-3">
                    <div class="dropdown-body">
                      <div class="row gx-0">
                        <div class="col-12">
                          <!-- <a class="dropdown-item" href="https://conf42.circle.so/">
                            <b>Community platform login</b>
                          </a> -->
                          <a class="dropdown-item" href="https://discord.gg/mvHyZzRGaQ" target="_blank">
                            Discord
                          </a>
                          <a class="dropdown-item" href="./hall-of-fame">
                            Hall of Fame
                          </a>
                          <a class="dropdown-item" href="./speakers">
                            Speakers
                          </a>
                          <a class="dropdown-item" href="https://www.papercall.io/events?cfps-scope=&keywords=conf42" target="_blank">
                            Become a speaker (CFPs)
                          </a>
                          <a class="dropdown-item" href="./testimonials">
                            Testimonials
                          </a>
                          <a class="dropdown-item" href="./about">
                            About the team
                          </a>
                        </div>
                      </div> <!-- / .row -->
                    </div>
                  </div>
                </div> <!-- / .row -->
              </div>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./podcast">
                Podcast
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./blog">
                Blog
              </a>
            </li>

            <li class="nav-item">
              <a class="nav-link" href="./sponsor">
                Sponsor
              </a>
            </li>
          </ul>
    
          <!-- Button -->
          <a class="navbar-btn btn btn-sm btn-primary lift ms-auto" href="#register">
            Join the community!
          </a>
    
        </div>
    
      </div>
    </nav>



<style>
.text-selected {
  background-color: #42ba96!important;
  color: white;
}
</style>
	

    <!-- WELCOME -->
    <section class="py-5 py-md-10" style="background-color: #198B91;">

      <!-- Shape -->
      <div class="shape shape-blur-3 svg-shim text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 text-center" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-2 fw-bold text-white">
              Conf42 Machine Learning 2023 - Online
            </h1>

            <h2 class="text-white">
              
              Content unlocked! Welcome to the community!
              
            </h2>

            <!-- Text -->
            <p class="lead mb-0 text-white-75">
              
              <!-- Like the Machines need our help to take over the world
 -->
              <script>
                const event_date = new Date("2023-05-18T17:00:00.000+00:00");
                const local_timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;
                const local_date = new Date("2023-05-18T17:00:00.000+00:00");
                // const local_offset = new Date().getTimezoneOffset() / 60;
                // local_date.setHours(local_date.getHours() + local_offset);
                document.getElementById("localtime").innerHTML = local_date + " in " + local_timezone
              </script>
            </p>

            <!-- Buttons -->
            <div class="text-center mt-5">
              
              
              <a class="btn btn-danger lift mb-3" data-bigpicture='{"ytSrc": "1K6M7o7FTy4"}' href="#">
                <i class="fe fe-youtube me-2"></i>
                Watch this talk
              </a>
              
              
              <a class="btn btn-info lift mb-3" data-bigpicture='{"ytSrc": "_nG0p3Dl4No"}' href="#">
                <i class="fe fe-eye me-2"></i>
                Watch Premiere
              </a>
              
              <!-- 
              <a class="btn btn-danger lift mb-3" href="https://youtube.com/playlist?list=PLIuxSyKxlQrA5sw0GIZ7Ib-Re1U38sSyx" target="_blank">
                <i class="fe fe-youtube me-2"></i>
                Playlist
              </a>
               -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>
      </div>
    </div>

    
    <!-- VIDEO -->
    <section class="pt-2 sticky">
      <div class="container">
        <div class="row justify-content-center">

          <div id="video-container" class="col-9 col-lg-12 mb-5">

          <!-- Video -->

            <!-- 1. The <iframe> (and video player) will replace this <div> tag. -->
            <div id="player" class="sticky"></div>

            <script>
              
              var transcript = [{"text": "Hi, thank you for your interest in this session. So in this", "timestamp": "00:00:23,290", "timestamp_s": 23.0}, {"text": "session unlocking reasoning and planning abilities in large", "timestamp": "00:00:26,892", "timestamp_s": 26.0}, {"text": "language models, I would like to take you through the different", "timestamp": "00:00:30,700", "timestamp_s": 30.0}, {"text": "methodologies and techniques to elicit reasoning abilities", "timestamp": "00:00:34,092", "timestamp_s": 34.0}, {"text": "from llms. So I\u0027ll be taking you through the", "timestamp": "00:00:38,514", "timestamp_s": 38.0}, {"text": "recent research works related to this.", "timestamp": "00:00:42,284", "timestamp_s": 42.0}, {"text": "So, about myself, I\u0027m logesh Kumar Umapathi,", "timestamp": "00:00:45,580", "timestamp_s": 45.0}, {"text": "a lead measure learning research engineer at Sama. So my", "timestamp": "00:00:49,250", "timestamp_s": 49.0}, {"text": "research interests includes biomedical,", "timestamp": "00:00:53,012", "timestamp_s": 53.0}, {"text": "NLP, large language models and code generation.", "timestamp": "00:00:56,666", "timestamp_s": 56.0}, {"text": "So you can reach me through these social", "timestamp": "00:01:00,762", "timestamp_s": 60.0}, {"text": "media channels. And I\u0027m also involved", "timestamp": "00:01:04,920", "timestamp_s": 64.0}, {"text": "in maintaining can open source package called mutate", "timestamp": "00:01:09,390", "timestamp_s": 69.0}, {"text": "which is about synthesizing data from large language models.", "timestamp": "00:01:13,230", "timestamp_s": 73.0}, {"text": "So the agenda for this session is we\u0027ll start", "timestamp": "00:01:17,266", "timestamp_s": 77.0}, {"text": "with understanding what is reasoning and how", "timestamp": "00:01:21,116", "timestamp_s": 81.0}, {"text": "the reasoning can be measured and is measured", "timestamp": "00:01:24,812", "timestamp_s": 84.0}, {"text": "in the research literature. And also", "timestamp": "00:01:28,018", "timestamp_s": 88.0}, {"text": "in the bulk of the session we will be discussing about how", "timestamp": "00:01:32,590", "timestamp_s": 92.0}, {"text": "to elicit reasoning. We\u0027ll be discussing different techniques", "timestamp": "00:01:36,352", "timestamp_s": 96.0}, {"text": "like direct prompting, direct one shot generation", "timestamp": "00:01:40,134", "timestamp_s": 100.0}, {"text": "of the solution, and then recursive and iterative prompting in", "timestamp": "00:01:44,026", "timestamp_s": 104.0}, {"text": "which we will be discussing techniques", "timestamp": "00:01:48,068", "timestamp_s": 108.0}, {"text": "to recursively and iteratively let the LLM generate the", "timestamp": "00:01:51,882", "timestamp_s": 111.0}, {"text": "solution. And then we will be discussing about tool usage,", "timestamp": "00:01:56,472", "timestamp_s": 116.0}, {"text": "which is the most popular one. Now with", "timestamp": "00:02:02,630", "timestamp_s": 122.0}, {"text": "the advent of hugging GPT and", "timestamp": "00:02:06,780", "timestamp_s": 126.0}, {"text": "hugging face agents and so on. So what", "timestamp": "00:02:11,210", "timestamp_s": 131.0}, {"text": "is reasoning? So, reasoning can be defined", "timestamp": "00:02:14,668", "timestamp_s": 134.0}, {"text": "as an ability to make inference from the given", "timestamp": "00:02:18,582", "timestamp_s": 138.0}, {"text": "evidences and logic. So there are different", "timestamp": "00:02:22,224", "timestamp_s": 142.0}, {"text": "types of reasoning like common sense mathematical and", "timestamp": "00:02:25,600", "timestamp_s": 145.0}, {"text": "symbolic reasoning. And reasoning can also be", "timestamp": "00:02:29,376", "timestamp_s": 149.0}, {"text": "defined as an ability to break", "timestamp": "00:02:33,730", "timestamp_s": 153.0}, {"text": "down a bigger problem into a smaller", "timestamp": "00:02:37,956", "timestamp_s": 157.0}, {"text": "solvable problems, and these recursively solve", "timestamp": "00:02:41,706", "timestamp_s": 161.0}, {"text": "the sub problems to solve these bigger problem.", "timestamp": "00:02:44,974", "timestamp_s": 164.0}, {"text": "Finally, so this can be considered", "timestamp": "00:02:49,080", "timestamp_s": 169.0}, {"text": "as a broad definition of", "timestamp": "00:02:52,798", "timestamp_s": 172.0}, {"text": "reasoning. So now that we know what is reasoning or", "timestamp": "00:02:56,236", "timestamp_s": 176.0}, {"text": "a broader definition of what we are trying with reasoning,", "timestamp": "00:03:00,124", "timestamp_s": 180.0}, {"text": "let\u0027s see how it\u0027s measured in the literature.", "timestamp": "00:03:04,178", "timestamp_s": 184.0}, {"text": "So in literature the reasoning is", "timestamp": "00:03:07,470", "timestamp_s": 187.0}, {"text": "usually measured as these separate categories,", "timestamp": "00:03:10,912", "timestamp_s": 190.0}, {"text": "mathematical reasoning, common sense reasoning and symbolic reasoning.", "timestamp": "00:03:15,366", "timestamp_s": 195.0}, {"text": "In mathematical reasoning, it\u0027s usually measured with math", "timestamp": "00:03:19,318", "timestamp_s": 199.0}, {"text": "world problems, usually math world problems that are", "timestamp": "00:03:23,578", "timestamp_s": 203.0}, {"text": "available online. So GSM eight k is about", "timestamp": "00:03:27,988", "timestamp_s": 207.0}, {"text": "grade school math world problems. This is from Opena.", "timestamp": "00:03:31,828", "timestamp_s": 211.0}, {"text": "And then the other data sets are benchmarks", "timestamp": "00:03:36,218", "timestamp_s": 216.0}, {"text": "also related to that. And then for common sense reasoning we", "timestamp": "00:03:40,078", "timestamp_s": 220.0}, {"text": "have arc a two reasoning challenge from allen", "timestamp": "00:03:43,928", "timestamp_s": 223.0}, {"text": "AI. So there we have science", "timestamp": "00:03:47,758", "timestamp_s": 227.0}, {"text": "question answering to measure the common sense", "timestamp": "00:03:54,146", "timestamp_s": 234.0}, {"text": "reasoning of the models. Then we have CsQA,", "timestamp": "00:03:57,532", "timestamp_s": 237.0}, {"text": "which is common sense question answering. And then we have strategy Qa", "timestamp": "00:04:01,398", "timestamp_s": 241.0}, {"text": "from Malin Aa. So these data sets", "timestamp": "00:04:05,462", "timestamp_s": 245.0}, {"text": "or benchmarks help in measuring the common sense ability of", "timestamp": "00:04:09,718", "timestamp_s": 249.0}, {"text": "these models. So to give an example, one of the questions", "timestamp": "00:04:13,028", "timestamp_s": 253.0}, {"text": "could be like,", "timestamp": "00:04:16,292", "timestamp_s": 256.0}, {"text": "would Aristotle have used a", "timestamp": "00:04:22,790", "timestamp_s": 262.0}, {"text": "keyboard? So this could be a question in that data", "timestamp": "00:04:26,952", "timestamp_s": 266.0}, {"text": "set, the model has to reduce that when", "timestamp": "00:04:30,600", "timestamp_s": 270.0}, {"text": "the keyboard was invented", "timestamp": "00:04:34,584", "timestamp_s": 274.0}, {"text": "and when Aristotle existed, and then it should deduce", "timestamp": "00:04:38,162", "timestamp_s": 278.0}, {"text": "whether it\u0027s possible or not. So these type of reasoning is covered", "timestamp": "00:04:41,778", "timestamp_s": 281.0}, {"text": "in common sense reasoning. Then we have symbolic reasoning,", "timestamp": "00:04:45,778", "timestamp_s": 285.0}, {"text": "which was mostly introduced by Jason V in", "timestamp": "00:04:49,078", "timestamp_s": 289.0}, {"text": "his chain of thoughts paper. So we have last letter concatenation", "timestamp": "00:04:52,608", "timestamp_s": 292.0}, {"text": "and coin flip type problems. These. So this", "timestamp": "00:04:57,206", "timestamp_s": 297.0}, {"text": "is how mostly the reasoning is measured in the", "timestamp": "00:05:00,852", "timestamp_s": 300.0}, {"text": "literature. To give an example of sample benchmark,", "timestamp": "00:05:04,148", "timestamp_s": 304.0}, {"text": "we have taken a snapshot of what is", "timestamp": "00:05:07,722", "timestamp_s": 307.0}, {"text": "available in GPT four technical review.", "timestamp": "00:05:11,172", "timestamp_s": 311.0}, {"text": "So this gives us an overview of how the reasoning", "timestamp": "00:05:14,712", "timestamp_s": 314.0}, {"text": "is measured and what the current state of things. So we can", "timestamp": "00:05:18,862", "timestamp_s": 318.0}, {"text": "see that the reasoning tasks like GSM eight k", "timestamp": "00:05:22,712", "timestamp_s": 322.0}, {"text": "and a two reasoning, the sort of for that", "timestamp": "00:05:26,472", "timestamp_s": 326.0}, {"text": "currently is 96 percentage and 92 percentage.", "timestamp": "00:05:29,868", "timestamp_s": 329.0}, {"text": "So now that we know what is reasoning and how is it measured,", "timestamp": "00:05:34,090", "timestamp_s": 334.0}, {"text": "let\u0027s see how and what are the methodology to elicit", "timestamp": "00:05:38,354", "timestamp_s": 338.0}, {"text": "reasoning. And before even going to that, let\u0027s see", "timestamp": "00:05:41,862", "timestamp_s": 341.0}, {"text": "why there is a need to elicit reasoning.", "timestamp": "00:05:46,830", "timestamp_s": 346.0}, {"text": "So given the size of these models,", "timestamp": "00:05:50,358", "timestamp_s": 350.0}, {"text": "this huge 175,000,000,000, 540,000,000,000 models,", "timestamp": "00:05:53,802", "timestamp_s": 353.0}, {"text": "one can think that why wouldn\u0027t reasoning be", "timestamp": "00:05:59,090", "timestamp_s": 359.0}, {"text": "come or generated by default by these", "timestamp": "00:06:03,364", "timestamp_s": 363.0}, {"text": "models? Why there is a need to elicit it? We\u0027ll first", "timestamp": "00:06:06,472", "timestamp_s": 366.0}, {"text": "try to address that and then come to the different", "timestamp": "00:06:10,152", "timestamp_s": 370.0}, {"text": "methodologies of eliciting reasoning.", "timestamp": "00:06:13,720", "timestamp_s": 373.0}, {"text": "So yesterday I tried this prompt in Chat GPT", "timestamp": "00:06:16,722", "timestamp_s": 376.0}, {"text": "for this session. So if you can see, I\u0027ve tried to ask Chat", "timestamp": "00:06:20,866", "timestamp_s": 380.0}, {"text": "GPT to take the last letters of the word Augusta", "timestamp": "00:06:25,218", "timestamp_s": 385.0}, {"text": "ducking and concatenate them using a space.", "timestamp": "00:06:29,026", "timestamp_s": 389.0}, {"text": "So can see that the model has detected the", "timestamp": "00:06:33,312", "timestamp_s": 393.0}, {"text": "last words incorrectly. It has detected last letters incorrectly as", "timestamp": "00:06:36,752", "timestamp_s": 396.0}, {"text": "a G and G. And the final answer because", "timestamp": "00:06:40,548", "timestamp_s": 400.0}, {"text": "of that is also wrong. But when", "timestamp": "00:06:44,676", "timestamp_s": 404.0}, {"text": "we break down that, the same problems into", "timestamp": "00:06:49,252", "timestamp_s": 409.0}, {"text": "three different problems. So what are the words in", "timestamp": "00:06:52,836", "timestamp_s": 412.0}, {"text": "Augusta adaking? These model is able to come up with the words,", "timestamp": "00:06:56,244", "timestamp_s": 416.0}, {"text": "and then what are the last letters of these words? It\u0027s able to come up", "timestamp": "00:07:00,710", "timestamp_s": 420.0}, {"text": "with the last letters, AAG correctly. And when", "timestamp": "00:07:04,072", "timestamp_s": 424.0}, {"text": "I ask it to concatenate it, it\u0027s able to concatenate it. So this is", "timestamp": "00:07:07,848", "timestamp_s": 427.0}, {"text": "why we would need eliciting techniques", "timestamp": "00:07:11,612", "timestamp_s": 431.0}, {"text": "to elicit reasoning. So these models,", "timestamp": "00:07:16,402", "timestamp_s": 436.0}, {"text": "as the objective of its training, are not trained to", "timestamp": "00:07:21,230", "timestamp_s": 441.0}, {"text": "do reasoning, or at least from", "timestamp": "00:07:25,056", "timestamp_s": 445.0}, {"text": "my understanding, it\u0027s not trained to do reasoning.", "timestamp": "00:07:28,512", "timestamp_s": 448.0}, {"text": "It still has the tendency to do text completion", "timestamp": "00:07:33,250", "timestamp_s": 453.0}, {"text": "so that\u0027s why we would need the methodologies that we are", "timestamp": "00:07:38,370", "timestamp_s": 458.0}, {"text": "going to discuss in the further slides for eliciting", "timestamp": "00:07:41,908", "timestamp_s": 461.0}, {"text": "these reasoning. So let\u0027s start with probably", "timestamp": "00:07:46,554", "timestamp_s": 466.0}, {"text": "the most popular and also from my", "timestamp": "00:07:50,404", "timestamp_s": 470.0}, {"text": "understanding, these methodology which kick started", "timestamp": "00:07:54,052", "timestamp_s": 474.0}, {"text": "all the different prompting", "timestamp": "00:07:58,044", "timestamp_s": 478.0}, {"text": "techniques to elicit reasoning, the chain of", "timestamp": "00:08:01,666", "timestamp_s": 481.0}, {"text": "thought prompting. So in chain of thought prompting, the authors", "timestamp": "00:08:04,828", "timestamp_s": 484.0}, {"text": "JSon V had tried to do so what", "timestamp": "00:08:09,398", "timestamp_s": 489.0}, {"text": "they have tried to do is for all the mathematical and", "timestamp": "00:08:13,088", "timestamp_s": 493.0}, {"text": "other reasoning related questions,", "timestamp": "00:08:18,830", "timestamp_s": 498.0}, {"text": "instead of asking the direct answers to the model.", "timestamp": "00:08:22,050", "timestamp_s": 502.0}, {"text": "If we ask the model to generate step by step", "timestamp": "00:08:25,428", "timestamp_s": 505.0}, {"text": "reason and then generate the final answers,", "timestamp": "00:08:28,756", "timestamp_s": 508.0}, {"text": "answers. Finally, they found that the model tend to", "timestamp": "00:08:32,698", "timestamp_s": 512.0}, {"text": "do tend to generate answers", "timestamp": "00:08:36,612", "timestamp_s": 516.0}, {"text": "better. The accuracy of generation of answers was better.", "timestamp": "00:08:40,270", "timestamp_s": 520.0}, {"text": "So here, if you see the question, Roger has five", "timestamp": "00:08:44,040", "timestamp_s": 524.0}, {"text": "tennis balls, he buys two more cans of tennis balls,", "timestamp": "00:08:47,676", "timestamp_s": 527.0}, {"text": "each can has three tennis balls. How many tennis", "timestamp": "00:08:51,282", "timestamp_s": 531.0}, {"text": "balls does he have now? So there in the answer,", "timestamp": "00:08:55,058", "timestamp_s": 535.0}, {"text": "as a one shot example, they have explained the different steps", "timestamp": "00:08:58,268", "timestamp_s": 538.0}, {"text": "that can be deduced from this question and then the final answer.", "timestamp": "00:09:02,182", "timestamp_s": 542.0}, {"text": "So for a new question that the model sees here,", "timestamp": "00:09:06,256", "timestamp_s": 546.0}, {"text": "the cafeteria example, the model would come up", "timestamp": "00:09:09,344", "timestamp_s": 549.0}, {"text": "with a similar chain", "timestamp": "00:09:12,772", "timestamp_s": 552.0}, {"text": "of steps and then it would generate an answer", "timestamp": "00:09:16,922", "timestamp_s": 556.0}, {"text": "from this. So these methodology", "timestamp": "00:09:20,900", "timestamp_s": 560.0}, {"text": "has resulted or has shown to give", "timestamp": "00:09:24,558", "timestamp_s": 564.0}, {"text": "better results. You can see across all", "timestamp": "00:09:28,456", "timestamp_s": 568.0}, {"text": "the reasoning data sets and across all the", "timestamp": "00:09:32,472", "timestamp_s": 572.0}, {"text": "different models, this approach seems to give better results.", "timestamp": "00:09:35,948", "timestamp_s": 575.0}, {"text": "And there is another variation of it from Wang", "timestamp": "00:09:40,162", "timestamp_s": 580.0}, {"text": "et al. It\u0027s called as self consistency.", "timestamp": "00:09:44,258", "timestamp_s": 584.0}, {"text": "So in the chain of thought prompting, initial chain of thought prompting, the answers", "timestamp": "00:09:48,146", "timestamp_s": 588.0}, {"text": "are generated using greedy decoding. So there is only one generation", "timestamp": "00:09:52,358", "timestamp_s": 592.0}, {"text": "for a given prompt. So in the self consistencies,", "timestamp": "00:09:56,854", "timestamp_s": 596.0}, {"text": "the authors have tried to do sampling", "timestamp": "00:10:00,682", "timestamp_s": 600.0}, {"text": "based decoding to generate multiple generations", "timestamp": "00:10:04,458", "timestamp_s": 604.0}, {"text": "for a given prompt. And then they consider the most,", "timestamp": "00:10:08,634", "timestamp_s": 608.0}, {"text": "or the majority voted answers which are similar", "timestamp": "00:10:12,260", "timestamp_s": 612.0}, {"text": "or which are same, and then they evaluate that", "timestamp": "00:10:15,864", "timestamp_s": 615.0}, {"text": "particular answers against the evaluation set.", "timestamp": "00:10:19,352", "timestamp_s": 619.0}, {"text": "So that way the model performs better even than", "timestamp": "00:10:24,970", "timestamp_s": 624.0}, {"text": "chain of thought prompting. So their intuition", "timestamp": "00:10:29,292", "timestamp_s": 629.0}, {"text": "is that if a", "timestamp": "00:10:33,378", "timestamp_s": 633.0}, {"text": "model comes up with majority of solutions, a majority of", "timestamp": "00:10:36,828", "timestamp_s": 636.0}, {"text": "methods to come up with the same solution,", "timestamp": "00:10:40,976", "timestamp_s": 640.0}, {"text": "then they consider that it\u0027s most likely that that is a", "timestamp": "00:10:44,110", "timestamp_s": 644.0}, {"text": "proper and correct answer. So that\u0027s the intuition", "timestamp": "00:10:47,808", "timestamp_s": 647.0}, {"text": "for that and can extension to", "timestamp": "00:10:51,318", "timestamp_s": 651.0}, {"text": "chain of thought. Is that so? The challenge", "timestamp": "00:10:55,092", "timestamp_s": 655.0}, {"text": "with chain of thought is we are leaving", "timestamp": "00:10:58,778", "timestamp_s": 658.0}, {"text": "the arithmetic operations when it comes to mathematical", "timestamp": "00:11:02,602", "timestamp_s": 662.0}, {"text": "reasoning. We are leaving that to the", "timestamp": "00:11:06,302", "timestamp_s": 666.0}, {"text": "llms. So we all know that llms", "timestamp": "00:11:10,040", "timestamp_s": 670.0}, {"text": "lack even simple arithmetic abilities.", "timestamp": "00:11:14,894", "timestamp_s": 674.0}, {"text": "So in this paper, program aided", "timestamp": "00:11:19,314", "timestamp_s": 679.0}, {"text": "language models. So the authors have tried a", "timestamp": "00:11:22,818", "timestamp_s": 682.0}, {"text": "clever methodology where they have offloaded", "timestamp": "00:11:27,050", "timestamp_s": 687.0}, {"text": "the arithmetic calculations to the Python interpreter.", "timestamp": "00:11:32,670", "timestamp_s": 692.0}, {"text": "So the way they have done is they have created few", "timestamp": "00:11:36,566", "timestamp_s": 696.0}, {"text": "short prompts. So each With a question like we saw in China", "timestamp": "00:11:40,372", "timestamp_s": 700.0}, {"text": "of thought prompting. And they divided the", "timestamp": "00:11:44,058", "timestamp_s": 704.0}, {"text": "solutions, they have represented it", "timestamp": "00:11:48,548", "timestamp_s": 708.0}, {"text": "as a Python problem. So here you can see these", "timestamp": "00:11:52,068", "timestamp_s": 712.0}, {"text": "tennis ball, they have deduced the tennis ball", "timestamp": "00:11:55,672", "timestamp_s": 715.0}, {"text": "value from the question, and then what are the balls", "timestamp": "00:11:59,326", "timestamp_s": 719.0}, {"text": "that are bought? And then these answer. So this way", "timestamp": "00:12:03,006", "timestamp_s": 723.0}, {"text": "they have converted that to a pythonic solution.", "timestamp": "00:12:06,332", "timestamp_s": 726.0}, {"text": "So this way, for a new problem based on", "timestamp": "00:12:10,898", "timestamp_s": 730.0}, {"text": "the examples that are there in Fusot,", "timestamp": "00:12:14,668", "timestamp_s": 734.0}, {"text": "the model generates a similar Python", "timestamp": "00:12:17,634", "timestamp_s": 737.0}, {"text": "problem, reducing the question and then coming up", "timestamp": "00:12:21,950", "timestamp_s": 741.0}, {"text": "with the final answer. So to get the final answer,", "timestamp": "00:12:25,648", "timestamp_s": 745.0}, {"text": "these generated solution is executed", "timestamp": "00:12:28,816", "timestamp_s": 748.0}, {"text": "in the Python interpreter and that is considered as the final solution.", "timestamp": "00:12:32,922", "timestamp_s": 752.0}, {"text": "So this performed better than Chain of thought as you", "timestamp": "00:12:37,290", "timestamp_s": 757.0}, {"text": "can see in the results across all the mathematical reasoning", "timestamp": "00:12:41,348", "timestamp_s": 761.0}, {"text": "benchmarks. The main reason is we are using", "timestamp": "00:12:45,198", "timestamp_s": 765.0}, {"text": "llms for its advantages,", "timestamp": "00:12:49,048", "timestamp_s": 769.0}, {"text": "for its strengths, and these we", "timestamp": "00:12:53,430", "timestamp_s": 773.0}, {"text": "are offloading the weakness of llms to the Python", "timestamp": "00:12:56,888", "timestamp_s": 776.0}, {"text": "interpreter. And another variation of this", "timestamp": "00:13:00,898", "timestamp_s": 780.0}, {"text": "prompting, or this type of prompting, is plan and solve prompting.", "timestamp": "00:13:04,652", "timestamp_s": 784.0}, {"text": "So this is mostly to address the", "timestamp": "00:13:08,818", "timestamp_s": 788.0}, {"text": "performance of zero short chain of thought prompting.", "timestamp": "00:13:13,130", "timestamp_s": 793.0}, {"text": "So zero short chain of thought prompting is usually done by this", "timestamp": "00:13:16,742", "timestamp_s": 796.0}, {"text": "prompt where we ask, given a question, we ask let\u0027s", "timestamp": "00:13:20,912", "timestamp_s": 800.0}, {"text": "think step by step, and the model will come up with step by step thought", "timestamp": "00:13:24,682", "timestamp_s": 804.0}, {"text": "process and the final answer. But this wasn\u0027t working", "timestamp": "00:13:29,636", "timestamp_s": 809.0}, {"text": "that well, mainly due to different reasons. One of that", "timestamp": "00:13:33,736", "timestamp_s": 813.0}, {"text": "is the arithmetic ability, as we saw before. And then there", "timestamp": "00:13:37,272", "timestamp_s": 817.0}, {"text": "was few inference steps that are missed by the model", "timestamp": "00:13:43,128", "timestamp_s": 823.0}, {"text": "and few inference steps that are not converted", "timestamp": "00:13:47,132", "timestamp_s": 827.0}, {"text": "to solutions. In these zero shot can of thought", "timestamp": "00:13:51,122", "timestamp_s": 831.0}, {"text": "prompting. So this is rectified by a methodology", "timestamp": "00:13:54,620", "timestamp_s": 834.0}, {"text": "called as plan and solve prompting.", "timestamp": "00:13:58,274", "timestamp_s": 838.0}, {"text": "In these, the authors authors", "timestamp": "00:14:02,090", "timestamp_s": 842.0}, {"text": "try a different style of prompting called let\u0027s prompting.", "timestamp": "00:14:05,446", "timestamp_s": 845.0}, {"text": "That is, let\u0027s first understand the problem and devise a plan", "timestamp": "00:14:09,046", "timestamp_s": 849.0}, {"text": "to solve the problem. Then let\u0027s carry out the plan and solve these", "timestamp": "00:14:12,656", "timestamp_s": 852.0}, {"text": "problem step by step. So they ask", "timestamp": "00:14:16,228", "timestamp_s": 856.0}, {"text": "the model to come up with the plan first and then the solution", "timestamp": "00:14:19,652", "timestamp_s": 859.0}, {"text": "based on the plan that it has derived. So this way, these model,", "timestamp": "00:14:22,926", "timestamp_s": 862.0}, {"text": "they have show that the model performs better than", "timestamp": "00:14:27,270", "timestamp_s": 867.0}, {"text": "zero short chain of thoughts prompting,", "timestamp": "00:14:32,950", "timestamp_s": 872.0}, {"text": "and even they have shown that it performs better than few", "timestamp": "00:14:36,882", "timestamp_s": 876.0}, {"text": "short chain of thought prompting in some cases.", "timestamp": "00:14:41,020", "timestamp_s": 881.0}, {"text": "So until now we have seen methodologies of how to", "timestamp": "00:14:44,410", "timestamp_s": 884.0}, {"text": "inference or how to do in context, learning to", "timestamp": "00:14:47,888", "timestamp_s": 887.0}, {"text": "incontext, learning to elicit", "timestamp": "00:14:51,872", "timestamp_s": 891.0}, {"text": "reasoning abilities from llms.", "timestamp": "00:14:56,350", "timestamp_s": 896.0}, {"text": "But there are techniques that can be used to", "timestamp": "00:15:00,370", "timestamp_s": 900.0}, {"text": "fine tune our large language models", "timestamp": "00:15:07,090", "timestamp_s": 907.0}, {"text": "to elicit or improve the reasoning abilities", "timestamp": "00:15:10,842", "timestamp_s": 910.0}, {"text": "so we\u0027ll be seeing that in this section of", "timestamp": "00:15:14,382", "timestamp_s": 914.0}, {"text": "the talk. So one paper that does that is learning", "timestamp": "00:15:17,688", "timestamp_s": 917.0}, {"text": "math reasoning from cell sample, the correct and partially correct solution.", "timestamp": "00:15:22,200", "timestamp_s": 922.0}, {"text": "Here the authors have authors use", "timestamp": "00:15:27,210", "timestamp_s": 927.0}, {"text": "LLM. I think in these case they have used GPT Neo 2.7", "timestamp": "00:15:31,068", "timestamp_s": 931.0}, {"text": "billion model. So for", "timestamp": "00:15:36,012", "timestamp_s": 936.0}, {"text": "a given set of question, they ask the model to generate a", "timestamp": "00:15:39,324", "timestamp_s": 939.0}, {"text": "solution, a pythonic solution, and then they", "timestamp": "00:15:42,752", "timestamp_s": 942.0}, {"text": "evaluate the answer. When the answer matches with the ground truth or gold", "timestamp": "00:15:46,592", "timestamp_s": 946.0}, {"text": "answers that they have, they use these solution, they use", "timestamp": "00:15:50,422", "timestamp_s": 950.0}, {"text": "that in the fine tuning data set. Similarly they generate", "timestamp": "00:15:54,036", "timestamp_s": 954.0}, {"text": "solutions for whatever generations", "timestamp": "00:15:58,394", "timestamp_s": 958.0}, {"text": "that had got correct answers.", "timestamp": "00:16:02,330", "timestamp_s": 962.0}, {"text": "They filter those generation and then they", "timestamp": "00:16:05,886", "timestamp_s": 965.0}, {"text": "iteratively fine tune the same model on that,", "timestamp": "00:16:09,320", "timestamp_s": 969.0}, {"text": "same model on that. So they not only use", "timestamp": "00:16:12,760", "timestamp_s": 972.0}, {"text": "the fully correct solution, they also have introduced", "timestamp": "00:16:16,316", "timestamp_s": 976.0}, {"text": "a methodology to utilize partially correct solutions.", "timestamp": "00:16:20,178", "timestamp_s": 980.0}, {"text": "So the way they do partially correct solution is", "timestamp": "00:16:23,954", "timestamp_s": 983.0}, {"text": "they have a gold", "timestamp": "00:16:28,830", "timestamp_s": 988.0}, {"text": "solutions where they have outputs for individual", "timestamp": "00:16:34,590", "timestamp_s": 994.0}, {"text": "steps, as you see here and these similarly we", "timestamp": "00:16:39,936", "timestamp_s": 999.0}, {"text": "have a generated solution with individual outputs", "timestamp": "00:16:43,492", "timestamp_s": 1003.0}, {"text": "from each of these steps. So whenever there is a match between", "timestamp": "00:16:47,258", "timestamp_s": 1007.0}, {"text": "these individual steps in gold and the generated", "timestamp": "00:16:52,130", "timestamp_s": 1012.0}, {"text": "one, they consider that as a partially correct solution and", "timestamp": "00:16:55,726", "timestamp_s": 1015.0}, {"text": "then they use that to further fine tune the model.", "timestamp": "00:16:59,832", "timestamp_s": 1019.0}, {"text": "So they have shown in their paper", "timestamp": "00:17:03,208", "timestamp_s": 1023.0}, {"text": "that this type of iterative fine tuning on the", "timestamp": "00:17:06,796", "timestamp_s": 1026.0}, {"text": "model generated solutions,", "timestamp": "00:17:10,892", "timestamp_s": 1030.0}, {"text": "there is an improvement in mathematical reasoning", "timestamp": "00:17:14,490", "timestamp_s": 1034.0}, {"text": "abilities of the model. So if you can see, the green", "timestamp": "00:17:18,418", "timestamp_s": 1038.0}, {"text": "ones are the one which are fine tuned only on fully", "timestamp": "00:17:21,760", "timestamp_s": 1041.0}, {"text": "correct solution and the orange ones are the one that are self", "timestamp": "00:17:25,718", "timestamp_s": 1045.0}, {"text": "sampled with fully correct and partially correct solutions.", "timestamp": "00:17:29,696", "timestamp_s": 1049.0}, {"text": "And we can also observe that the pass at one rate is", "timestamp": "00:17:34,050", "timestamp_s": 1054.0}, {"text": "not improved. So the authors, authors comment that", "timestamp": "00:17:37,828", "timestamp_s": 1057.0}, {"text": "this is mainly because the nature of", "timestamp": "00:17:42,052", "timestamp_s": 1062.0}, {"text": "these training facilitates the", "timestamp": "00:17:46,710", "timestamp_s": 1066.0}, {"text": "model to generate diverse set of solutions and it", "timestamp": "00:17:50,008", "timestamp_s": 1070.0}, {"text": "does not make the model to favor any one particular solution.", "timestamp": "00:17:54,952", "timestamp_s": 1074.0}, {"text": "That\u0027s why the pass at one is not improved much, but you can", "timestamp": "00:17:59,182", "timestamp_s": 1079.0}, {"text": "see other improvements in other passet k values.", "timestamp": "00:18:02,812", "timestamp_s": 1082.0}, {"text": "So another paper that does something similar is", "timestamp": "00:18:07,890", "timestamp_s": 1087.0}, {"text": "self taught reasoner bootstrapping, reasoning with reasoning or", "timestamp": "00:18:11,852", "timestamp_s": 1091.0}, {"text": "star. So here in this methodology,", "timestamp": "00:18:15,536", "timestamp_s": 1095.0}, {"text": "the authors generate rational", "timestamp": "00:18:19,390", "timestamp_s": 1099.0}, {"text": "and answers from an existing large language model.", "timestamp": "00:18:23,882", "timestamp_s": 1103.0}, {"text": "And then whenever the answer is correct for that", "timestamp": "00:18:27,892", "timestamp_s": 1107.0}, {"text": "particular gold standards, when they compare it with", "timestamp": "00:18:31,476", "timestamp_s": 1111.0}, {"text": "the gold ground root data set that they have, they take", "timestamp": "00:18:34,868", "timestamp_s": 1114.0}, {"text": "that, they put that into a fine tuning coppers along with", "timestamp": "00:18:38,616", "timestamp_s": 1118.0}, {"text": "as a triplet, as question, rational and answer. So whenever", "timestamp": "00:18:42,696", "timestamp_s": 1122.0}, {"text": "the answer is wrong, they hint the model", "timestamp": "00:18:46,526", "timestamp_s": 1126.0}, {"text": "to generate a correct rationale by giving the correct answer from the ground", "timestamp": "00:18:49,816", "timestamp_s": 1129.0}, {"text": "truth. So they ask the model to generate a rational and then they", "timestamp": "00:18:53,762", "timestamp_s": 1133.0}, {"text": "put that back into the fine tuning mixture.", "timestamp": "00:18:57,276", "timestamp_s": 1137.0}, {"text": "So that way they fine tune the model again so", "timestamp": "00:19:00,630", "timestamp_s": 1140.0}, {"text": "that fine tuned model has a better ability to generate rational.", "timestamp": "00:19:04,720", "timestamp_s": 1144.0}, {"text": "So these do this iteratively and then they have", "timestamp": "00:19:08,422", "timestamp_s": 1148.0}, {"text": "a final model. So this has", "timestamp": "00:19:12,052", "timestamp_s": 1152.0}, {"text": "proved to improve the mathematical reasoning", "timestamp": "00:19:15,332", "timestamp_s": 1155.0}, {"text": "abilities even by using only the partial", "timestamp": "00:19:19,098", "timestamp_s": 1159.0}, {"text": "training data set. So if you can see, the few short and", "timestamp": "00:19:23,490", "timestamp_s": 1163.0}, {"text": "then fine tuned abilities of the GPTJ model has", "timestamp": "00:19:26,952", "timestamp_s": 1166.0}, {"text": "improved from 5.8 to 10.7 here. So another", "timestamp": "00:19:30,952", "timestamp_s": 1170.0}, {"text": "variation to this approach is this is more of distilling from", "timestamp": "00:19:34,920", "timestamp_s": 1174.0}, {"text": "a large language model, a paper called specializing", "timestamp": "00:19:38,652", "timestamp_s": 1178.0}, {"text": "smaller language models towards multistep reasoning by", "timestamp": "00:19:42,066", "timestamp_s": 1182.0}, {"text": "few et al. Here the authors have tried to distill", "timestamp": "00:19:45,708", "timestamp_s": 1185.0}, {"text": "the reasoning steps as well as the solution", "timestamp": "00:19:50,910", "timestamp_s": 1190.0}, {"text": "from a large language model, a bigger model like from GPT-3", "timestamp": "00:19:54,806", "timestamp_s": 1194.0}, {"text": "and then they fine tuned a smaller model like different t five versions,", "timestamp": "00:19:59,776", "timestamp_s": 1199.0}, {"text": "different t five versions 250,000,000 760,000,003", "timestamp": "00:20:03,978", "timestamp_s": 1203.0}, {"text": "billion. So they tried two different", "timestamp": "00:20:08,532", "timestamp_s": 1208.0}, {"text": "variations. One is fine tuning only", "timestamp": "00:20:12,100", "timestamp_s": 1212.0}, {"text": "on answers and then fine tuning on both answers and", "timestamp": "00:20:15,640", "timestamp_s": 1215.0}, {"text": "chain of thought steps. So they found that", "timestamp": "00:20:19,464", "timestamp_s": 1219.0}, {"text": "fine tuning on chain of thought and answers", "timestamp": "00:20:22,888", "timestamp_s": 1222.0}, {"text": "are giving better accuracy as the model also", "timestamp": "00:20:27,130", "timestamp_s": 1227.0}, {"text": "tries to understand the rationale of the answers. And we", "timestamp": "00:20:30,796", "timestamp_s": 1230.0}, {"text": "could see the improvement here. Similarly,", "timestamp": "00:20:34,508", "timestamp_s": 1234.0}, {"text": "they have tried that not only to vanilla Tfi but also to", "timestamp": "00:20:37,698", "timestamp_s": 1237.0}, {"text": "flan t five. So flan t five shows a better improvement", "timestamp": "00:20:41,568", "timestamp_s": 1241.0}, {"text": "compared to the vanilla t five models. So another", "timestamp": "00:20:46,070", "timestamp_s": 1246.0}, {"text": "recent approach in distilling is", "timestamp": "00:20:50,690", "timestamp_s": 1250.0}, {"text": "these distilling step by step paper from Hashe et", "timestamp": "00:20:54,548", "timestamp_s": 1254.0}, {"text": "al. So here for an unlabeled", "timestamp": "00:20:58,618", "timestamp_s": 1258.0}, {"text": "set of data set, they use a large language model like", "timestamp": "00:21:02,266", "timestamp_s": 1262.0}, {"text": "a palm or a palm or a gpt-3", "timestamp": "00:21:06,264", "timestamp_s": 1266.0}, {"text": "models to generate labels. Not only labels,", "timestamp": "00:21:10,328", "timestamp_s": 1270.0}, {"text": "they also ask the model to generate the rational or chain", "timestamp": "00:21:13,982", "timestamp_s": 1273.0}, {"text": "of starts for this particular answer,", "timestamp": "00:21:17,214", "timestamp_s": 1277.0}, {"text": "particular answer. And then when they distill", "timestamp": "00:21:20,908", "timestamp_s": 1280.0}, {"text": "it and train a smaller model, they train it on an objective", "timestamp": "00:21:24,082", "timestamp_s": 1284.0}, {"text": "similar to a multitask planning. So they ask the model", "timestamp": "00:21:27,714", "timestamp_s": 1287.0}, {"text": "to predict a label as well as the rational", "timestamp": "00:21:31,440", "timestamp_s": 1291.0}, {"text": "for it instead of concatenating the rational and", "timestamp": "00:21:34,758", "timestamp_s": 1294.0}, {"text": "label as one chunk. They had approached", "timestamp": "00:21:38,048", "timestamp_s": 1298.0}, {"text": "this as a multitask planning. And then they have shown that these gives", "timestamp": "00:21:41,242", "timestamp_s": 1301.0}, {"text": "a better improvement in improving", "timestamp": "00:21:44,932", "timestamp_s": 1304.0}, {"text": "the smaller models reasoning", "timestamp": "00:21:49,066", "timestamp_s": 1309.0}, {"text": "abilities. So the loss they have done is", "timestamp": "00:21:54,222", "timestamp_s": 1314.0}, {"text": "they had taken a weighted loss of label", "timestamp": "00:21:58,072", "timestamp_s": 1318.0}, {"text": "loss as well as the rational loss generation of", "timestamp": "00:22:01,582", "timestamp_s": 1321.0}, {"text": "rational. So they show that these models,", "timestamp": "00:22:04,728", "timestamp_s": 1324.0}, {"text": "the fine tuned model in this distilling step by step model performs", "timestamp": "00:22:08,226", "timestamp_s": 1328.0}, {"text": "even better than a 540,000,000,000 model in", "timestamp": "00:22:12,418", "timestamp_s": 1332.0}, {"text": "540,000,000,000 models, a few short generations.", "timestamp": "00:22:16,524", "timestamp_s": 1336.0}, {"text": "So you could see that t five to 20 million sound,", "timestamp": "00:22:20,310", "timestamp_s": 1340.0}, {"text": "70 million and 11 billion doing a better job", "timestamp": "00:22:23,776", "timestamp_s": 1343.0}, {"text": "in the mathematical reasoning and common", "timestamp": "00:22:27,088", "timestamp_s": 1347.0}, {"text": "sense Qa common sense Qa", "timestamp": "00:22:31,380", "timestamp_s": 1351.0}, {"text": "task. So until now we saw how", "timestamp": "00:22:34,842", "timestamp_s": 1354.0}, {"text": "a generation is made at one shot, that is,", "timestamp": "00:22:38,916", "timestamp_s": 1358.0}, {"text": "given a set of prompt with few shot or zero shot examples.", "timestamp": "00:22:42,644", "timestamp_s": 1362.0}, {"text": "The model generates in one shot the reasoning", "timestamp": "00:22:47,198", "timestamp_s": 1367.0}, {"text": "as well as the answer for the given problem.", "timestamp": "00:22:51,774", "timestamp_s": 1371.0}, {"text": "But as a human like how,", "timestamp": "00:22:55,690", "timestamp_s": 1375.0}, {"text": "if we had, if we approach a problem iteratively,", "timestamp": "00:22:59,052", "timestamp_s": 1379.0}, {"text": "we have a better chance to solve the problem more", "timestamp": "00:23:02,754", "timestamp_s": 1382.0}, {"text": "accurately. So, similar intuition has been tried", "timestamp": "00:23:06,284", "timestamp_s": 1386.0}, {"text": "with these llms. So we will be seeing those", "timestamp": "00:23:09,916", "timestamp_s": 1389.0}, {"text": "methodologies in the papers in this section.", "timestamp": "00:23:14,350", "timestamp_s": 1394.0}, {"text": "So one paper that implements is least", "timestamp": "00:23:17,430", "timestamp_s": 1397.0}, {"text": "to most prompting. So the", "timestamp": "00:23:20,916", "timestamp_s": 1400.0}, {"text": "idea of this paper is that they have broken down the", "timestamp": "00:23:24,916", "timestamp_s": 1404.0}, {"text": "approach into two stages. The first stage they", "timestamp": "00:23:28,948", "timestamp_s": 1408.0}, {"text": "prompt these model to come up with sub questions. So given", "timestamp": "00:23:33,784", "timestamp_s": 1413.0}, {"text": "a broader question, they prompt the model to come up with", "timestamp": "00:23:37,640", "timestamp_s": 1417.0}, {"text": "sub questions. And in the stage two", "timestamp": "00:23:41,528", "timestamp_s": 1421.0}, {"text": "they sequentially ask the model to solve the questions one", "timestamp": "00:23:45,160", "timestamp_s": 1425.0}, {"text": "by one. So for example, for the question given here,", "timestamp": "00:23:49,228", "timestamp_s": 1429.0}, {"text": "the first stage, the model will come up with sub questions,", "timestamp": "00:23:53,244", "timestamp_s": 1433.0}, {"text": "and in the second stage the original question is appended with the", "timestamp": "00:23:57,004", "timestamp_s": 1437.0}, {"text": "sub question and the model has to answer that sub", "timestamp": "00:24:00,992", "timestamp_s": 1440.0}, {"text": "question. And then the second sub question will be appended to", "timestamp": "00:24:04,672", "timestamp_s": 1444.0}, {"text": "the first one and the overall one. And then the model has to", "timestamp": "00:24:08,432", "timestamp_s": 1448.0}, {"text": "answer that and then until it comes up with the final answer.", "timestamp": "00:24:12,388", "timestamp_s": 1452.0}, {"text": "So this way the author has shown that the model does", "timestamp": "00:24:16,308", "timestamp_s": 1456.0}, {"text": "better compared to the vanilla", "timestamp": "00:24:20,244", "timestamp_s": 1460.0}, {"text": "chain of thought prompting that we saw before. So this", "timestamp": "00:24:24,078", "timestamp_s": 1464.0}, {"text": "is an example prompts that\u0027s been implemented", "timestamp": "00:24:28,008", "timestamp_s": 1468.0}, {"text": "as part of this paper here. These have for the decomposition", "timestamp": "00:24:32,958", "timestamp_s": 1472.0}, {"text": "stage where they ask the model to decompose the question into", "timestamp": "00:24:37,378", "timestamp_s": 1477.0}, {"text": "different questions.", "timestamp": "00:24:41,260", "timestamp_s": 1481.0}, {"text": "These were these few short examples that was given. And then", "timestamp": "00:24:44,572", "timestamp_s": 1484.0}, {"text": "for the new set of example following this few shot,", "timestamp": "00:24:48,124", "timestamp_s": 1488.0}, {"text": "the model has to come up with sub questions.", "timestamp": "00:24:51,398", "timestamp_s": 1491.0}, {"text": "And the second part,", "timestamp": "00:24:57,150", "timestamp_s": 1497.0}, {"text": "second stage where for problem solving, these are all the", "timestamp": "00:25:00,176", "timestamp_s": 1500.0}, {"text": "few short examples that were given for the model to", "timestamp": "00:25:03,748", "timestamp_s": 1503.0}, {"text": "solve the sub problem.", "timestamp": "00:25:07,844", "timestamp_s": 1507.0}, {"text": "So another paper that implemented the recursive or", "timestamp": "00:25:11,970", "timestamp_s": 1511.0}, {"text": "iterative prompting is", "timestamp": "00:25:15,992", "timestamp_s": 1515.0}, {"text": "plan, eliminate and track. So they have done this in an interesting setting", "timestamp": "00:25:20,296", "timestamp_s": 1520.0}, {"text": "where they have tried to evaluate and embodied the agent on", "timestamp": "00:25:24,590", "timestamp_s": 1524.0}, {"text": "a data set called as half world", "timestamp": "00:25:28,172", "timestamp_s": 1528.0}, {"text": "data set, which is about evaluating", "timestamp": "00:25:31,836", "timestamp_s": 1531.0}, {"text": "the abilities of the agent to follow a given task", "timestamp": "00:25:35,826", "timestamp_s": 1535.0}, {"text": "given the text word environment and a visual equivalent of", "timestamp": "00:25:39,318", "timestamp_s": 1539.0}, {"text": "it. So they have", "timestamp": "00:25:43,152", "timestamp_s": 1543.0}, {"text": "broken down their approach into different modules. One is a", "timestamp": "00:25:49,470", "timestamp_s": 1549.0}, {"text": "planner module which is also can LLM. So it takes in the", "timestamp": "00:25:52,708", "timestamp_s": 1552.0}, {"text": "instruction, it tries to convert that into a plan", "timestamp": "00:25:56,308", "timestamp_s": 1556.0}, {"text": "that the agent needs to follow. And then there is an eliminator.", "timestamp": "00:26:00,212", "timestamp_s": 1560.0}, {"text": "So eliminator based on the visual input and", "timestamp": "00:26:04,030", "timestamp_s": 1564.0}, {"text": "also on the visual input of what is", "timestamp": "00:26:07,272", "timestamp_s": 1567.0}, {"text": "there in the environment. The eliminator", "timestamp": "00:26:10,552", "timestamp_s": 1570.0}, {"text": "tries to eliminate whatever that", "timestamp": "00:26:14,526", "timestamp_s": 1574.0}, {"text": "the agent sees and what it needs to focus", "timestamp": "00:26:17,884", "timestamp_s": 1577.0}, {"text": "on. And these the actor does the action and the tracker", "timestamp": "00:26:21,084", "timestamp_s": 1581.0}, {"text": "tracks whether a given task is finished or not. Once it\u0027s finished,", "timestamp": "00:26:25,186", "timestamp_s": 1585.0}, {"text": "it is updating the progress. So this overall approach is", "timestamp": "00:26:28,998", "timestamp_s": 1588.0}, {"text": "in a way it\u0027s similar to what has been followed in auto", "timestamp": "00:26:33,870", "timestamp_s": 1593.0}, {"text": "GPT and Baby Aga and all those applications.", "timestamp": "00:26:37,414", "timestamp_s": 1597.0}, {"text": "So if you see here first for the task, heat some apple and", "timestamp": "00:26:42,430", "timestamp_s": 1602.0}, {"text": "put it in the fridge. The LLMs first comes up with a plan. Take an", "timestamp": "00:26:45,892", "timestamp_s": 1605.0}, {"text": "apple, heat the apple, place the apple in fridge,", "timestamp": "00:26:49,588", "timestamp_s": 1609.0}, {"text": "and then an eliminator eliminates what", "timestamp": "00:26:54,050", "timestamp_s": 1614.0}, {"text": "are the things that are not important for this particular", "timestamp": "00:26:58,788", "timestamp_s": 1618.0}, {"text": "task to be completed. And an actor picks up", "timestamp": "00:27:02,660", "timestamp_s": 1622.0}, {"text": "the, excuse me,", "timestamp": "00:27:05,948", "timestamp_s": 1625.0}, {"text": "the actor picks up the action", "timestamp": "00:27:09,308", "timestamp_s": 1629.0}, {"text": "that is more suitable for that particular task.", "timestamp": "00:27:13,858", "timestamp_s": 1633.0}, {"text": "And then a tracker tracks the progress of it.", "timestamp": "00:27:17,074", "timestamp_s": 1637.0}, {"text": "Another interesting paper that does this", "timestamp": "00:27:24,290", "timestamp_s": 1644.0}, {"text": "iterative prompting is describe, explain,", "timestamp": "00:27:28,388", "timestamp_s": 1648.0}, {"text": "plan and select. So in this paper, the authors", "timestamp": "00:27:32,248", "timestamp_s": 1652.0}, {"text": "have tried to use an LLM to solve or", "timestamp": "00:27:36,190", "timestamp_s": 1656.0}, {"text": "to play Minecraft. So minecraft,", "timestamp": "00:27:40,424", "timestamp_s": 1660.0}, {"text": "as you\u0027d know, it\u0027s an open ended game. So they have used llms", "timestamp": "00:27:43,822", "timestamp_s": 1663.0}, {"text": "to play the minecraft. So here again,", "timestamp": "00:27:47,986", "timestamp_s": 1667.0}, {"text": "similar to what we saw before,", "timestamp": "00:27:52,492", "timestamp_s": 1672.0}, {"text": "they have split the approach", "timestamp": "00:27:55,610", "timestamp_s": 1675.0}, {"text": "into different modules. One is planner module,", "timestamp": "00:27:58,902", "timestamp_s": 1678.0}, {"text": "selector module and explainer module, and then a", "timestamp": "00:28:02,662", "timestamp_s": 1682.0}, {"text": "describer module. So the first, for example", "timestamp": "00:28:06,592", "timestamp_s": 1686.0}, {"text": "for these task how to mine one diamond from scratch.", "timestamp": "00:28:11,072", "timestamp_s": 1691.0}, {"text": "The planner module comes up with a set of plans of what are", "timestamp": "00:28:15,170", "timestamp_s": 1695.0}, {"text": "the tasks that needs to be done by the agent.", "timestamp": "00:28:18,788", "timestamp_s": 1698.0}, {"text": "So here from the different set of ushot", "timestamp": "00:28:22,804", "timestamp_s": 1702.0}, {"text": "examples in the ground truth plan, the planner would", "timestamp": "00:28:26,158", "timestamp_s": 1706.0}, {"text": "come up with an actual plan that needs to be executed.", "timestamp": "00:28:29,512", "timestamp_s": 1709.0}, {"text": "And then the selector, based on its knowledge of the", "timestamp": "00:28:32,942", "timestamp_s": 1712.0}, {"text": "environment, it selects in that given step what", "timestamp": "00:28:36,732", "timestamp_s": 1716.0}, {"text": "a goal that needs to be achieved. First based", "timestamp": "00:28:40,588", "timestamp_s": 1720.0}, {"text": "on prioritizing", "timestamp": "00:28:43,836", "timestamp_s": 1723.0}, {"text": "the different tasks involved.", "timestamp": "00:28:48,270", "timestamp_s": 1728.0}, {"text": "And then that particular task is executed by", "timestamp": "00:28:52,270", "timestamp_s": 1732.0}, {"text": "an executor. And that result of the executor is", "timestamp": "00:28:55,968", "timestamp_s": 1735.0}, {"text": "given as a description by the descriptor. So it says,", "timestamp": "00:28:59,552", "timestamp_s": 1739.0}, {"text": "if it finishes a goal, it says I finished goal g zero,", "timestamp": "00:29:02,676", "timestamp_s": 1742.0}, {"text": "and then the selector goes to the next", "timestamp": "00:29:06,420", "timestamp_s": 1746.0}, {"text": "task or next goal and so on. So this", "timestamp": "00:29:10,500", "timestamp_s": 1750.0}, {"text": "is done recursively,", "timestamp": "00:29:13,688", "timestamp_s": 1753.0}, {"text": "this is done by an LLM, it is prone to failures.", "timestamp": "00:29:17,670", "timestamp_s": 1757.0}, {"text": "So when a particular plan has failed,", "timestamp": "00:29:20,798", "timestamp_s": 1760.0}, {"text": "so these descriptor says I fail on this particular goal.", "timestamp": "00:29:23,870", "timestamp_s": 1763.0}, {"text": "And then it also gives the details of the environment.", "timestamp": "00:29:27,890", "timestamp_s": 1767.0}, {"text": "So based on that, an explainer explains what could", "timestamp": "00:29:31,474", "timestamp_s": 1771.0}, {"text": "have actually gone wrong and it explains what needs to be done.", "timestamp": "00:29:35,292", "timestamp_s": 1775.0}, {"text": "And then that goes to the planner. So planner then does", "timestamp": "00:29:39,630", "timestamp_s": 1779.0}, {"text": "the replanning again. Replanning again.", "timestamp": "00:29:43,472", "timestamp_s": 1783.0}, {"text": "And then this process continues until the final objective is", "timestamp": "00:29:47,168", "timestamp_s": 1787.0}, {"text": "met. So this is again a very interesting", "timestamp": "00:29:51,076", "timestamp_s": 1791.0}, {"text": "paper. I would urge the audience", "timestamp": "00:29:54,468", "timestamp_s": 1794.0}, {"text": "to go to the GitHub repo and go through there. They have done a", "timestamp": "00:29:58,826", "timestamp_s": 1798.0}, {"text": "wonderful implementation of their approach.", "timestamp": "00:30:02,808", "timestamp_s": 1802.0}, {"text": "So until now we have seen how recursive", "timestamp": "00:30:10,150", "timestamp_s": 1810.0}, {"text": "and iterative prompting can be used to elicit", "timestamp": "00:30:14,238", "timestamp_s": 1814.0}, {"text": "reason. So now the", "timestamp": "00:30:18,322", "timestamp_s": 1818.0}, {"text": "recent advancements have been enabled these LLMs", "timestamp": "00:30:22,268", "timestamp_s": 1822.0}, {"text": "to use tools. So that comes in handy to", "timestamp": "00:30:26,722", "timestamp_s": 1826.0}, {"text": "make the model even more accurate when it comes to reasoning", "timestamp": "00:30:30,720", "timestamp_s": 1830.0}, {"text": "and planning. So you\u0027ll see a few examples of", "timestamp": "00:30:34,822", "timestamp_s": 1834.0}, {"text": "how the tool usage is implemented", "timestamp": "00:30:38,256", "timestamp_s": 1838.0}, {"text": "in some of the literature work.", "timestamp": "00:30:41,482", "timestamp_s": 1841.0}, {"text": "So here the paper is react, reason and hacked.", "timestamp": "00:30:45,090", "timestamp_s": 1845.0}, {"text": "So in these paper, the authors,", "timestamp": "00:30:48,922", "timestamp_s": 1848.0}, {"text": "Yoert hall had broken down a", "timestamp": "00:30:52,462", "timestamp_s": 1852.0}, {"text": "reasoning question to", "timestamp": "00:30:58,136", "timestamp_s": 1858.0}, {"text": "use a tool like searching Wikipedia or", "timestamp": "00:31:03,752", "timestamp_s": 1863.0}, {"text": "looking up Wikipedia, and then do and", "timestamp": "00:31:07,932", "timestamp_s": 1867.0}, {"text": "come up with an answer based on that. So if you see here", "timestamp": "00:31:11,756", "timestamp_s": 1871.0}, {"text": "for this reasoning question, when the model", "timestamp": "00:31:15,500", "timestamp_s": 1875.0}, {"text": "tries to come up with a direct answer, it gets it", "timestamp": "00:31:18,816", "timestamp_s": 1878.0}, {"text": "wrong. Even with cot, this is getting it wrong because", "timestamp": "00:31:22,208", "timestamp_s": 1882.0}, {"text": "for this particular question, aside from Apple remote,", "timestamp": "00:31:26,336", "timestamp_s": 1886.0}, {"text": "what other devices can control the program Apple remote was", "timestamp": "00:31:30,042", "timestamp_s": 1890.0}, {"text": "originally designed to interact with? It needs an external", "timestamp": "00:31:34,052", "timestamp_s": 1894.0}, {"text": "information for the model to be relied on.", "timestamp": "00:31:38,202", "timestamp_s": 1898.0}, {"text": "So both these approaches are failing there.", "timestamp": "00:31:41,830", "timestamp_s": 1901.0}, {"text": "So in act approach, what they", "timestamp": "00:31:45,112", "timestamp_s": 1905.0}, {"text": "do is they come up with different set", "timestamp": "00:31:49,192", "timestamp_s": 1909.0}, {"text": "of, so they have two variations. One is act only approach.", "timestamp": "00:31:52,296", "timestamp_s": 1912.0}, {"text": "So in act only approach they come up with different actions that needs to", "timestamp": "00:31:56,610", "timestamp_s": 1916.0}, {"text": "be taken and then they come up with an answer.", "timestamp": "00:32:00,588", "timestamp_s": 1920.0}, {"text": "Then we have react which is based on reason and act which", "timestamp": "00:32:05,404", "timestamp_s": 1925.0}, {"text": "is the actual paper. So first they come up with a different thought", "timestamp": "00:32:09,148", "timestamp_s": 1929.0}, {"text": "and what act needs to be done, action needs to be done. And what", "timestamp": "00:32:13,120", "timestamp_s": 1933.0}, {"text": "is the observation that is done from this action.", "timestamp": "00:32:16,912", "timestamp_s": 1936.0}, {"text": "So based on that, that gets passed on to the next thought and", "timestamp": "00:32:20,742", "timestamp_s": 1940.0}, {"text": "that is used to do the second act, and then observation and so", "timestamp": "00:32:24,484", "timestamp_s": 1944.0}, {"text": "on. Finally they come up with these can answer.", "timestamp": "00:32:28,308", "timestamp_s": 1948.0}, {"text": "So this way they iteratively prompt it. First thought", "timestamp": "00:32:31,252", "timestamp_s": 1951.0}, {"text": "one is done and these act one action is generated", "timestamp": "00:32:35,016", "timestamp_s": 1955.0}, {"text": "based on that. Once we have this, once the model generates", "timestamp": "00:32:39,230", "timestamp_s": 1959.0}, {"text": "search the apple remote, the keyword is used to", "timestamp": "00:32:42,830", "timestamp_s": 1962.0}, {"text": "search the Wikipedia and then an observation is appended to", "timestamp": "00:32:46,348", "timestamp_s": 1966.0}, {"text": "the generation. So based on that a thought", "timestamp": "00:32:50,092", "timestamp_s": 1970.0}, {"text": "two is done until the model generates finish", "timestamp": "00:32:53,436", "timestamp_s": 1973.0}, {"text": "as one of the actions. So this is react,", "timestamp": "00:32:57,488", "timestamp_s": 1977.0}, {"text": "reason and act.", "timestamp": "00:33:01,174", "timestamp_s": 1981.0}, {"text": "Another paper that uses tools is", "timestamp": "00:33:06,750", "timestamp_s": 1986.0}, {"text": "camelion plug and play compositional reasoning with", "timestamp": "00:33:10,288", "timestamp_s": 1990.0}, {"text": "large language models. So here the authors have used", "timestamp": "00:33:13,732", "timestamp_s": 1993.0}, {"text": "tool based reasoning and compulsion", "timestamp": "00:33:18,132", "timestamp_s": 1998.0}, {"text": "for answering science question", "timestamp": "00:33:22,778", "timestamp_s": 2002.0}, {"text": "answers as well as to answer table", "timestamp": "00:33:26,120", "timestamp_s": 2006.0}, {"text": "based word problems. So here", "timestamp": "00:33:31,006", "timestamp_s": 2011.0}, {"text": "in this science based question answering or", "timestamp": "00:33:34,712", "timestamp_s": 2014.0}, {"text": "common sense question answering, here the image is given", "timestamp": "00:33:38,764", "timestamp_s": 2018.0}, {"text": "and the question is what is the direction of this push? And then an", "timestamp": "00:33:42,556", "timestamp_s": 2022.0}, {"text": "image is given and there is a question related to this.", "timestamp": "00:33:46,476", "timestamp_s": 2026.0}, {"text": "So the LLM first tries to come up", "timestamp": "00:33:51,070", "timestamp_s": 2031.0}, {"text": "with or decomposes this problem into set of", "timestamp": "00:33:54,992", "timestamp_s": 2034.0}, {"text": "tools that it needs to call. And then there is a separate", "timestamp": "00:33:59,472", "timestamp_s": 2039.0}, {"text": "set of prompts that are available for each of these", "timestamp": "00:34:02,842", "timestamp_s": 2042.0}, {"text": "tools, which gets executed sequentially", "timestamp": "00:34:06,212", "timestamp_s": 2046.0}, {"text": "to invoke that particular tool", "timestamp": "00:34:09,994", "timestamp_s": 2049.0}, {"text": "and get these answers that get appended to the", "timestamp": "00:34:13,592", "timestamp_s": 2053.0}, {"text": "original prompt. And these the process continues to get the", "timestamp": "00:34:16,888", "timestamp_s": 2056.0}, {"text": "final answer. For example, for this question where we have", "timestamp": "00:34:20,408", "timestamp_s": 2060.0}, {"text": "image and then a set of options, which is the main persuasive apple", "timestamp": "00:34:25,050", "timestamp_s": 2065.0}, {"text": "used in this ad. So this particular image", "timestamp": "00:34:29,218", "timestamp_s": 2069.0}, {"text": "is of an ADC. Paper plates now carry", "timestamp": "00:34:33,218", "timestamp_s": 2073.0}, {"text": "the Sierra Club seal of approval. So it\u0027s an", "timestamp": "00:34:36,774", "timestamp_s": 2076.0}, {"text": "ad. And then we have different options", "timestamp": "00:34:40,336", "timestamp_s": 2080.0}, {"text": "whether this ad conveys petals, ethos or", "timestamp": "00:34:44,672", "timestamp_s": 2084.0}, {"text": "logos, and these has", "timestamp": "00:34:50,050", "timestamp_s": 2090.0}, {"text": "different options. So what the Cameleon does is it", "timestamp": "00:34:53,732", "timestamp_s": 2093.0}, {"text": "first tries to call the text deductor as a", "timestamp": "00:34:57,252", "timestamp_s": 2097.0}, {"text": "tool, and the text deductor deducts the text", "timestamp": "00:35:01,028", "timestamp_s": 2101.0}, {"text": "and then it calls the knowledge retrieval. So knowledge retrieval", "timestamp": "00:35:05,430", "timestamp_s": 2105.0}, {"text": "based on the input that is there, the knowledge retrieval", "timestamp": "00:35:10,310", "timestamp_s": 2110.0}, {"text": "tries to come up with its inference of", "timestamp": "00:35:13,358", "timestamp_s": 2113.0}, {"text": "the overall perspective of question and the information", "timestamp": "00:35:17,532", "timestamp_s": 2117.0}, {"text": "that is available at that point. This is from", "timestamp": "00:35:21,308", "timestamp_s": 2121.0}, {"text": "call to an opena API. And then", "timestamp": "00:35:26,140", "timestamp_s": 2126.0}, {"text": "there is a solution generator which creates a descriptive", "timestamp": "00:35:29,360", "timestamp_s": 2129.0}, {"text": "solution of what needs to be done, and then the answer", "timestamp": "00:35:33,302", "timestamp_s": 2133.0}, {"text": "generator, which could be a rule based approach to generate the answers", "timestamp": "00:35:36,560", "timestamp_s": 2136.0}, {"text": "from the solution that was generated by the model.", "timestamp": "00:35:40,218", "timestamp_s": 2140.0}, {"text": "So these way this paper uses different tools,", "timestamp": "00:35:43,972", "timestamp_s": 2143.0}, {"text": "right from hugging face models,", "timestamp": "00:35:47,690", "timestamp_s": 2147.0}, {"text": "and then open a GPT models iteratively,", "timestamp": "00:35:51,090", "timestamp_s": 2151.0}, {"text": "and also the other models like text deductor to", "timestamp": "00:35:55,086", "timestamp_s": 2155.0}, {"text": "come up with a final solution.", "timestamp": "00:35:58,488", "timestamp_s": 2158.0}, {"text": "Another example is the tab math world", "timestamp": "00:36:04,810", "timestamp_s": 2164.0}, {"text": "problem solving data set, wherein for a given tabular", "timestamp": "00:36:09,290", "timestamp_s": 2169.0}, {"text": "example, for a question that was asked,", "timestamp": "00:36:13,850", "timestamp_s": 2173.0}, {"text": "the model has to come up with set of answers. So here the", "timestamp": "00:36:17,196", "timestamp_s": 2177.0}, {"text": "model again uses different tools like knowledge retriever to", "timestamp": "00:36:21,088", "timestamp_s": 2181.0}, {"text": "retrieve the knowledge that it has related", "timestamp": "00:36:24,768", "timestamp_s": 2184.0}, {"text": "to the question that was asked. And then it goes to the table", "timestamp": "00:36:28,806", "timestamp_s": 2188.0}, {"text": "verbalizer to verbalize what is there in the table,", "timestamp": "00:36:32,666", "timestamp_s": 2192.0}, {"text": "and then for all the calculation that is offloaded", "timestamp": "00:36:35,626", "timestamp_s": 2195.0}, {"text": "to a Python program and interpreter. And then", "timestamp": "00:36:38,698", "timestamp_s": 2198.0}, {"text": "we have a program verifier which verifies whether the program is correct,", "timestamp": "00:36:42,552", "timestamp_s": 2202.0}, {"text": "and then the program is executed and the answer is generated", "timestamp": "00:36:46,888", "timestamp_s": 2206.0}, {"text": "from it. So let\u0027s see how a prompt", "timestamp": "00:36:50,686", "timestamp_s": 2210.0}, {"text": "looks like for this.", "timestamp": "00:36:54,562", "timestamp_s": 2214.0}, {"text": "So here as we can see,", "timestamp": "00:36:59,130", "timestamp_s": 2219.0}, {"text": "the instruction or the prompt has different", "timestamp": "00:37:02,764", "timestamp_s": 2222.0}, {"text": "tools that the model can use and then it also has the", "timestamp": "00:37:06,924", "timestamp_s": 2226.0}, {"text": "context of what is the question and what are all the options", "timestamp": "00:37:10,848", "timestamp_s": 2230.0}, {"text": "that are there in these question and metadata of the image.", "timestamp": "00:37:14,496", "timestamp_s": 2234.0}, {"text": "And the model has to generate the set of modules", "timestamp": "00:37:18,190", "timestamp_s": 2238.0}, {"text": "that it has to call, set of steps that it has", "timestamp": "00:37:21,818", "timestamp_s": 2241.0}, {"text": "to execute, whether it has to execute text reductor first,", "timestamp": "00:37:25,652", "timestamp_s": 2245.0}, {"text": "knowledge retrieval solution generator and answer generator.", "timestamp": "00:37:29,060", "timestamp_s": 2249.0}, {"text": "So this way these model comes up with steps", "timestamp": "00:37:32,718", "timestamp_s": 2252.0}, {"text": "and then each of these separate tools are", "timestamp": "00:37:36,478", "timestamp_s": 2256.0}, {"text": "prompted to get the output. And then finally all", "timestamp": "00:37:40,392", "timestamp_s": 2260.0}, {"text": "these outputs from these individual tools are concatenated", "timestamp": "00:37:44,088", "timestamp_s": 2264.0}, {"text": "into one sequentially to generate the final", "timestamp": "00:37:47,938", "timestamp_s": 2267.0}, {"text": "answer. So yeah,", "timestamp": "00:37:51,180", "timestamp_s": 2271.0}, {"text": "that\u0027s pretty much I had for today. So there is", "timestamp": "00:37:54,492", "timestamp_s": 2274.0}, {"text": "a lot that has come out recently.", "timestamp": "00:37:58,032", "timestamp_s": 2278.0}, {"text": "Probably I might not have had a", "timestamp": "00:38:01,710", "timestamp_s": 2281.0}, {"text": "chance to include it here, like tool formers, hugging GPT and so", "timestamp": "00:38:04,864", "timestamp_s": 2284.0}, {"text": "on, but I", "timestamp": "00:38:08,832", "timestamp_s": 2288.0}, {"text": "would like to acknowledge the sources", "timestamp": "00:38:14,244", "timestamp_s": 2294.0}, {"text": "for this presentation. One is augment language", "timestamp": "00:38:17,946", "timestamp_s": 2297.0}, {"text": "models survey from Milan", "timestamp": "00:38:21,402", "timestamp_s": 2301.0}, {"text": "et al. And towards reasoning language models survey from Huang", "timestamp": "00:38:25,562", "timestamp_s": 2305.0}, {"text": "et al. And then these blog posts. I will also urge", "timestamp": "00:38:29,182", "timestamp_s": 2309.0}, {"text": "the audience to go through these", "timestamp": "00:38:32,910", "timestamp_s": 2312.0}, {"text": "papers and these blog posts if you\u0027d", "timestamp": "00:38:36,776", "timestamp_s": 2316.0}, {"text": "like to learn further on this topic. So thank", "timestamp": "00:38:40,798", "timestamp_s": 2320.0}, {"text": "you very much for your attention and", "timestamp": "00:38:44,568", "timestamp_s": 2324.0}, {"text": "looking forward to hearing your feedback on these session", "timestamp": "00:38:48,830", "timestamp_s": 2328.0}, {"text": "and also to have discussions on this topic can", "timestamp": "00:38:52,726", "timestamp_s": 2332.0}, {"text": "be discussed today. Thank you.", "timestamp": "00:38:56,448", "timestamp_s": 2336.0}];
              

              var tag = document.createElement('script');

              tag.src = "https://www.youtube.com/iframe_api";
              var firstScriptTag = document.getElementsByTagName('script')[0];
              firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

              // 3. This function creates an <iframe> (and YouTube player)
              //    after the API code downloads.
              var player;
              function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                  height: '100%',
                  width: '100%',
                  videoId: '1K6M7o7FTy4',
                  playerVars: {
                    'playsinline': 1
                  },
                  events: {
                    'onReady': onPlayerReady,
                    // 'onStateChange': onPlayerStateChange
                  }
                });
              }
              function onPlayerReady(event) {
                console.log("Player ready");
                var sec = Number(location.href.split("#")[1]);
                if (sec){
                  player.seekTo(sec, true);
                }
                player.playVideo();
                highlightParagraph();
              }
              // find the number of the paragraph
              function findParagraph(sec){
                for (var i = 1; i < transcript.length; i++) {
                  if (transcript[i].timestamp_s > sec){
                    return i - 1;
                  }
                }
                return transcript.length - 1;
              }
              // move the video to the desired second
              function seek(sec){
                if(player){
                  player.playVideo();
                  player.seekTo(sec, true);
                }
                location.href = location.href.split("#")[0] + "#" + sec;
                highlightParagraph(sec);
              }
              // highlight the right paragraph
              var prevParagraph;
              function highlightParagraph(sec) {
                var currentTime = sec;
                if (!currentTime && player) {
                  currentTime = player.getCurrentTime();
                }
                if (!currentTime){
                  console.log("No current time")
                  return;
                }
                var currentParagraph = findParagraph(currentTime);
                if (currentParagraph !== prevParagraph){
                  prevParagraph = currentParagraph;
                  Array.from(document.getElementsByClassName("transcript-chunks")).forEach((e) => {
                    e.classList.remove('text-selected');
                  });
                  var body = document.getElementById("chunk-"+currentParagraph);
                  body.classList.add('text-selected');
                }
              }
              time_update_interval = setInterval(highlightParagraph, 1000);
            </script>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>
    

    <!-- CONTENT -->
    <section class="pt-2">
      <div class="container">
        <div class="row justify-content-center">

          <div class="col-12 mb-5">
            <h1>
              Unlocking reasoning and planning abilities in Large language models
            </h1>
            
            <h3 class="bg-white">
              Video size:
              <a href="javascript:void(0);" onclick="resizeVideo(25)"><i class="fe fe-zoom-out me-2"></i></a>
              <a href="javascript:void(0);" onclick="resizeVideo(50)"><i class="fe fe-zoom-in me-2"></i></a>
            </h3>
            
          </div>

          <div class="col-12 mb-5">
            <h3>
              Abstract
            </h3>
<!-- Text -->
<p>We will explore the latest breakthroughs and discuss how LLMs can be used to solve complex problems that require reasoning and planning. By unlocking these capabilities, LLMs can be used to build sophisticated chatbots, intelligent assistants, and other NLP applications</p>
<!-- End Text -->
          </div>

          
          

          <div class="col-12 mb-5">
            <h3>
              Summary
            </h3>
            <ul>
              
              <li>
                In this session, logesh Kumar Umapathi will take you through the different methodologies and techniques to elicit reasoning abilities from llms. His research interests include biomedical, NLP, large language models and code generation.

              </li>
              
              <li>
                In literature the reasoning is usually measured as these separate categories, mathematical reasoning, common sense reasoning and symbolic reasoning. So now that we know what is reasoning and how is it measured, let's see how and what are the methodology to elicit reasoning.

              </li>
              
              <li>
                Chain of thought prompting is one of the most popular techniques to elicit reasoning. Another variation of this prompting, or this type of prompting, is plan and solve prompting. These methods have shown to give better results across all the reasoning data sets.

              </li>
              
              <li>
                So one paper is learning math reasoning from cell sample, the correct and partially correct solution. Another recent approach in distilling is these step by step paper from Hashe et al. This has proved to improve the mathematical reasoning abilities even by using only the partial training data set.

              </li>
              
              <li>
                One paper that implements is least to most prompting. First stage prompts model to come up with sub questions. In stage two they sequentially ask the model to solve the questions one by one. This way the author has shown that the model does better compared to the vanilla chain of thought prompting.

              </li>
              
              <li>
                Another paper that implemented the recursive or iterative prompting is plan, eliminate and track. They have tried to evaluate and embodied the agent on a data set called as half world data set. And these the actor does the action and the tracker tracks whether a given task is finished or not.

              </li>
              
              <li>
                Another interesting paper that does this iterative prompting is describe, explain, plan and select. Another paper uses plug and play tools for answering science questions. Recent advancements have enabled LLMs to use tools to make the model even more accurate when it comes to reasoning and planning.
              </li>
              
            </ul>
          </div>

          <div class="col-12 mb-5">
            <h3>
              Transcript
            </h3>
            <span class="text-muted">
              This transcript was autogenerated. To make changes, <a href="https://github.com/conf42/src/edit/main/./assemblyai/1K6M7o7FTy4.srt" target="_blank">submit a PR</a>.
            </span>
            <div>
            
            <span id="chunk-0" class="transcript-chunks" onclick="console.log('00:00:23,290'); seek(23.0)">
              Hi, thank you for your interest in this session. So in this
            </span>
            
            <span id="chunk-1" class="transcript-chunks" onclick="console.log('00:00:26,892'); seek(26.0)">
              session unlocking reasoning and planning abilities in large
            </span>
            
            <span id="chunk-2" class="transcript-chunks" onclick="console.log('00:00:30,700'); seek(30.0)">
              language models, I would like to take you through the different
            </span>
            
            <span id="chunk-3" class="transcript-chunks" onclick="console.log('00:00:34,092'); seek(34.0)">
              methodologies and techniques to elicit reasoning abilities
            </span>
            
            <span id="chunk-4" class="transcript-chunks" onclick="console.log('00:00:38,514'); seek(38.0)">
              from llms. So I'll be taking you through the
            </span>
            
            <span id="chunk-5" class="transcript-chunks" onclick="console.log('00:00:42,284'); seek(42.0)">
              recent research works related to this.
            </span>
            
            <span id="chunk-6" class="transcript-chunks" onclick="console.log('00:00:45,580'); seek(45.0)">
              So, about myself, I'm logesh Kumar Umapathi,
            </span>
            
            <span id="chunk-7" class="transcript-chunks" onclick="console.log('00:00:49,250'); seek(49.0)">
              a lead measure learning research engineer at Sama. So my
            </span>
            
            <span id="chunk-8" class="transcript-chunks" onclick="console.log('00:00:53,012'); seek(53.0)">
              research interests includes biomedical,
            </span>
            
            <span id="chunk-9" class="transcript-chunks" onclick="console.log('00:00:56,666'); seek(56.0)">
              NLP, large language models and code generation.
            </span>
            
            <span id="chunk-10" class="transcript-chunks" onclick="console.log('00:01:00,762'); seek(60.0)">
              So you can reach me through these social
            </span>
            
            <span id="chunk-11" class="transcript-chunks" onclick="console.log('00:01:04,920'); seek(64.0)">
              media channels. And I'm also involved
            </span>
            
            <span id="chunk-12" class="transcript-chunks" onclick="console.log('00:01:09,390'); seek(69.0)">
              in maintaining can open source package called mutate
            </span>
            
            <span id="chunk-13" class="transcript-chunks" onclick="console.log('00:01:13,230'); seek(73.0)">
              which is about synthesizing data from large language models.
            </span>
            
            <span id="chunk-14" class="transcript-chunks" onclick="console.log('00:01:17,266'); seek(77.0)">
              So the agenda for this session is we'll start
            </span>
            
            <span id="chunk-15" class="transcript-chunks" onclick="console.log('00:01:21,116'); seek(81.0)">
              with understanding what is reasoning and how
            </span>
            
            <span id="chunk-16" class="transcript-chunks" onclick="console.log('00:01:24,812'); seek(84.0)">
              the reasoning can be measured and is measured
            </span>
            
            <span id="chunk-17" class="transcript-chunks" onclick="console.log('00:01:28,018'); seek(88.0)">
              in the research literature. And also
            </span>
            
            <span id="chunk-18" class="transcript-chunks" onclick="console.log('00:01:32,590'); seek(92.0)">
              in the bulk of the session we will be discussing about how
            </span>
            
            <span id="chunk-19" class="transcript-chunks" onclick="console.log('00:01:36,352'); seek(96.0)">
              to elicit reasoning. We'll be discussing different techniques
            </span>
            
            <span id="chunk-20" class="transcript-chunks" onclick="console.log('00:01:40,134'); seek(100.0)">
              like direct prompting, direct one shot generation
            </span>
            
            <span id="chunk-21" class="transcript-chunks" onclick="console.log('00:01:44,026'); seek(104.0)">
              of the solution, and then recursive and iterative prompting in
            </span>
            
            <span id="chunk-22" class="transcript-chunks" onclick="console.log('00:01:48,068'); seek(108.0)">
              which we will be discussing techniques
            </span>
            
            <span id="chunk-23" class="transcript-chunks" onclick="console.log('00:01:51,882'); seek(111.0)">
              to recursively and iteratively let the LLM generate the
            </span>
            
            <span id="chunk-24" class="transcript-chunks" onclick="console.log('00:01:56,472'); seek(116.0)">
              solution. And then we will be discussing about tool usage,
            </span>
            
            <span id="chunk-25" class="transcript-chunks" onclick="console.log('00:02:02,630'); seek(122.0)">
              which is the most popular one. Now with
            </span>
            
            <span id="chunk-26" class="transcript-chunks" onclick="console.log('00:02:06,780'); seek(126.0)">
              the advent of hugging GPT and
            </span>
            
            <span id="chunk-27" class="transcript-chunks" onclick="console.log('00:02:11,210'); seek(131.0)">
              hugging face agents and so on. So what
            </span>
            
            <span id="chunk-28" class="transcript-chunks" onclick="console.log('00:02:14,668'); seek(134.0)">
              is reasoning? So, reasoning can be defined
            </span>
            
            <span id="chunk-29" class="transcript-chunks" onclick="console.log('00:02:18,582'); seek(138.0)">
              as an ability to make inference from the given
            </span>
            
            <span id="chunk-30" class="transcript-chunks" onclick="console.log('00:02:22,224'); seek(142.0)">
              evidences and logic. So there are different
            </span>
            
            <span id="chunk-31" class="transcript-chunks" onclick="console.log('00:02:25,600'); seek(145.0)">
              types of reasoning like common sense mathematical and
            </span>
            
            <span id="chunk-32" class="transcript-chunks" onclick="console.log('00:02:29,376'); seek(149.0)">
              symbolic reasoning. And reasoning can also be
            </span>
            
            <span id="chunk-33" class="transcript-chunks" onclick="console.log('00:02:33,730'); seek(153.0)">
              defined as an ability to break
            </span>
            
            <span id="chunk-34" class="transcript-chunks" onclick="console.log('00:02:37,956'); seek(157.0)">
              down a bigger problem into a smaller
            </span>
            
            <span id="chunk-35" class="transcript-chunks" onclick="console.log('00:02:41,706'); seek(161.0)">
              solvable problems, and these recursively solve
            </span>
            
            <span id="chunk-36" class="transcript-chunks" onclick="console.log('00:02:44,974'); seek(164.0)">
              the sub problems to solve these bigger problem.
            </span>
            
            <span id="chunk-37" class="transcript-chunks" onclick="console.log('00:02:49,080'); seek(169.0)">
              Finally, so this can be considered
            </span>
            
            <span id="chunk-38" class="transcript-chunks" onclick="console.log('00:02:52,798'); seek(172.0)">
              as a broad definition of
            </span>
            
            <span id="chunk-39" class="transcript-chunks" onclick="console.log('00:02:56,236'); seek(176.0)">
              reasoning. So now that we know what is reasoning or
            </span>
            
            <span id="chunk-40" class="transcript-chunks" onclick="console.log('00:03:00,124'); seek(180.0)">
              a broader definition of what we are trying with reasoning,
            </span>
            
            <span id="chunk-41" class="transcript-chunks" onclick="console.log('00:03:04,178'); seek(184.0)">
              let's see how it's measured in the literature.
            </span>
            
            <span id="chunk-42" class="transcript-chunks" onclick="console.log('00:03:07,470'); seek(187.0)">
              So in literature the reasoning is
            </span>
            
            <span id="chunk-43" class="transcript-chunks" onclick="console.log('00:03:10,912'); seek(190.0)">
              usually measured as these separate categories,
            </span>
            
            <span id="chunk-44" class="transcript-chunks" onclick="console.log('00:03:15,366'); seek(195.0)">
              mathematical reasoning, common sense reasoning and symbolic reasoning.
            </span>
            
            <span id="chunk-45" class="transcript-chunks" onclick="console.log('00:03:19,318'); seek(199.0)">
              In mathematical reasoning, it's usually measured with math
            </span>
            
            <span id="chunk-46" class="transcript-chunks" onclick="console.log('00:03:23,578'); seek(203.0)">
              world problems, usually math world problems that are
            </span>
            
            <span id="chunk-47" class="transcript-chunks" onclick="console.log('00:03:27,988'); seek(207.0)">
              available online. So GSM eight k is about
            </span>
            
            <span id="chunk-48" class="transcript-chunks" onclick="console.log('00:03:31,828'); seek(211.0)">
              grade school math world problems. This is from Opena.
            </span>
            
            <span id="chunk-49" class="transcript-chunks" onclick="console.log('00:03:36,218'); seek(216.0)">
              And then the other data sets are benchmarks
            </span>
            
            <span id="chunk-50" class="transcript-chunks" onclick="console.log('00:03:40,078'); seek(220.0)">
              also related to that. And then for common sense reasoning we
            </span>
            
            <span id="chunk-51" class="transcript-chunks" onclick="console.log('00:03:43,928'); seek(223.0)">
              have arc a two reasoning challenge from allen
            </span>
            
            <span id="chunk-52" class="transcript-chunks" onclick="console.log('00:03:47,758'); seek(227.0)">
              AI. So there we have science
            </span>
            
            <span id="chunk-53" class="transcript-chunks" onclick="console.log('00:03:54,146'); seek(234.0)">
              question answering to measure the common sense
            </span>
            
            <span id="chunk-54" class="transcript-chunks" onclick="console.log('00:03:57,532'); seek(237.0)">
              reasoning of the models. Then we have CsQA,
            </span>
            
            <span id="chunk-55" class="transcript-chunks" onclick="console.log('00:04:01,398'); seek(241.0)">
              which is common sense question answering. And then we have strategy Qa
            </span>
            
            <span id="chunk-56" class="transcript-chunks" onclick="console.log('00:04:05,462'); seek(245.0)">
              from Malin Aa. So these data sets
            </span>
            
            <span id="chunk-57" class="transcript-chunks" onclick="console.log('00:04:09,718'); seek(249.0)">
              or benchmarks help in measuring the common sense ability of
            </span>
            
            <span id="chunk-58" class="transcript-chunks" onclick="console.log('00:04:13,028'); seek(253.0)">
              these models. So to give an example, one of the questions
            </span>
            
            <span id="chunk-59" class="transcript-chunks" onclick="console.log('00:04:16,292'); seek(256.0)">
              could be like,
            </span>
            
            <span id="chunk-60" class="transcript-chunks" onclick="console.log('00:04:22,790'); seek(262.0)">
              would Aristotle have used a
            </span>
            
            <span id="chunk-61" class="transcript-chunks" onclick="console.log('00:04:26,952'); seek(266.0)">
              keyboard? So this could be a question in that data
            </span>
            
            <span id="chunk-62" class="transcript-chunks" onclick="console.log('00:04:30,600'); seek(270.0)">
              set, the model has to reduce that when
            </span>
            
            <span id="chunk-63" class="transcript-chunks" onclick="console.log('00:04:34,584'); seek(274.0)">
              the keyboard was invented
            </span>
            
            <span id="chunk-64" class="transcript-chunks" onclick="console.log('00:04:38,162'); seek(278.0)">
              and when Aristotle existed, and then it should deduce
            </span>
            
            <span id="chunk-65" class="transcript-chunks" onclick="console.log('00:04:41,778'); seek(281.0)">
              whether it's possible or not. So these type of reasoning is covered
            </span>
            
            <span id="chunk-66" class="transcript-chunks" onclick="console.log('00:04:45,778'); seek(285.0)">
              in common sense reasoning. Then we have symbolic reasoning,
            </span>
            
            <span id="chunk-67" class="transcript-chunks" onclick="console.log('00:04:49,078'); seek(289.0)">
              which was mostly introduced by Jason V in
            </span>
            
            <span id="chunk-68" class="transcript-chunks" onclick="console.log('00:04:52,608'); seek(292.0)">
              his chain of thoughts paper. So we have last letter concatenation
            </span>
            
            <span id="chunk-69" class="transcript-chunks" onclick="console.log('00:04:57,206'); seek(297.0)">
              and coin flip type problems. These. So this
            </span>
            
            <span id="chunk-70" class="transcript-chunks" onclick="console.log('00:05:00,852'); seek(300.0)">
              is how mostly the reasoning is measured in the
            </span>
            
            <span id="chunk-71" class="transcript-chunks" onclick="console.log('00:05:04,148'); seek(304.0)">
              literature. To give an example of sample benchmark,
            </span>
            
            <span id="chunk-72" class="transcript-chunks" onclick="console.log('00:05:07,722'); seek(307.0)">
              we have taken a snapshot of what is
            </span>
            
            <span id="chunk-73" class="transcript-chunks" onclick="console.log('00:05:11,172'); seek(311.0)">
              available in GPT four technical review.
            </span>
            
            <span id="chunk-74" class="transcript-chunks" onclick="console.log('00:05:14,712'); seek(314.0)">
              So this gives us an overview of how the reasoning
            </span>
            
            <span id="chunk-75" class="transcript-chunks" onclick="console.log('00:05:18,862'); seek(318.0)">
              is measured and what the current state of things. So we can
            </span>
            
            <span id="chunk-76" class="transcript-chunks" onclick="console.log('00:05:22,712'); seek(322.0)">
              see that the reasoning tasks like GSM eight k
            </span>
            
            <span id="chunk-77" class="transcript-chunks" onclick="console.log('00:05:26,472'); seek(326.0)">
              and a two reasoning, the sort of for that
            </span>
            
            <span id="chunk-78" class="transcript-chunks" onclick="console.log('00:05:29,868'); seek(329.0)">
              currently is 96 percentage and 92 percentage.
            </span>
            
            <span id="chunk-79" class="transcript-chunks" onclick="console.log('00:05:34,090'); seek(334.0)">
              So now that we know what is reasoning and how is it measured,
            </span>
            
            <span id="chunk-80" class="transcript-chunks" onclick="console.log('00:05:38,354'); seek(338.0)">
              let's see how and what are the methodology to elicit
            </span>
            
            <span id="chunk-81" class="transcript-chunks" onclick="console.log('00:05:41,862'); seek(341.0)">
              reasoning. And before even going to that, let's see
            </span>
            
            <span id="chunk-82" class="transcript-chunks" onclick="console.log('00:05:46,830'); seek(346.0)">
              why there is a need to elicit reasoning.
            </span>
            
            <span id="chunk-83" class="transcript-chunks" onclick="console.log('00:05:50,358'); seek(350.0)">
              So given the size of these models,
            </span>
            
            <span id="chunk-84" class="transcript-chunks" onclick="console.log('00:05:53,802'); seek(353.0)">
              this huge 175,000,000,000, 540,000,000,000 models,
            </span>
            
            <span id="chunk-85" class="transcript-chunks" onclick="console.log('00:05:59,090'); seek(359.0)">
              one can think that why wouldn't reasoning be
            </span>
            
            <span id="chunk-86" class="transcript-chunks" onclick="console.log('00:06:03,364'); seek(363.0)">
              come or generated by default by these
            </span>
            
            <span id="chunk-87" class="transcript-chunks" onclick="console.log('00:06:06,472'); seek(366.0)">
              models? Why there is a need to elicit it? We'll first
            </span>
            
            <span id="chunk-88" class="transcript-chunks" onclick="console.log('00:06:10,152'); seek(370.0)">
              try to address that and then come to the different
            </span>
            
            <span id="chunk-89" class="transcript-chunks" onclick="console.log('00:06:13,720'); seek(373.0)">
              methodologies of eliciting reasoning.
            </span>
            
            <span id="chunk-90" class="transcript-chunks" onclick="console.log('00:06:16,722'); seek(376.0)">
              So yesterday I tried this prompt in Chat GPT
            </span>
            
            <span id="chunk-91" class="transcript-chunks" onclick="console.log('00:06:20,866'); seek(380.0)">
              for this session. So if you can see, I've tried to ask Chat
            </span>
            
            <span id="chunk-92" class="transcript-chunks" onclick="console.log('00:06:25,218'); seek(385.0)">
              GPT to take the last letters of the word Augusta
            </span>
            
            <span id="chunk-93" class="transcript-chunks" onclick="console.log('00:06:29,026'); seek(389.0)">
              ducking and concatenate them using a space.
            </span>
            
            <span id="chunk-94" class="transcript-chunks" onclick="console.log('00:06:33,312'); seek(393.0)">
              So can see that the model has detected the
            </span>
            
            <span id="chunk-95" class="transcript-chunks" onclick="console.log('00:06:36,752'); seek(396.0)">
              last words incorrectly. It has detected last letters incorrectly as
            </span>
            
            <span id="chunk-96" class="transcript-chunks" onclick="console.log('00:06:40,548'); seek(400.0)">
              a G and G. And the final answer because
            </span>
            
            <span id="chunk-97" class="transcript-chunks" onclick="console.log('00:06:44,676'); seek(404.0)">
              of that is also wrong. But when
            </span>
            
            <span id="chunk-98" class="transcript-chunks" onclick="console.log('00:06:49,252'); seek(409.0)">
              we break down that, the same problems into
            </span>
            
            <span id="chunk-99" class="transcript-chunks" onclick="console.log('00:06:52,836'); seek(412.0)">
              three different problems. So what are the words in
            </span>
            
            <span id="chunk-100" class="transcript-chunks" onclick="console.log('00:06:56,244'); seek(416.0)">
              Augusta adaking? These model is able to come up with the words,
            </span>
            
            <span id="chunk-101" class="transcript-chunks" onclick="console.log('00:07:00,710'); seek(420.0)">
              and then what are the last letters of these words? It's able to come up
            </span>
            
            <span id="chunk-102" class="transcript-chunks" onclick="console.log('00:07:04,072'); seek(424.0)">
              with the last letters, AAG correctly. And when
            </span>
            
            <span id="chunk-103" class="transcript-chunks" onclick="console.log('00:07:07,848'); seek(427.0)">
              I ask it to concatenate it, it's able to concatenate it. So this is
            </span>
            
            <span id="chunk-104" class="transcript-chunks" onclick="console.log('00:07:11,612'); seek(431.0)">
              why we would need eliciting techniques
            </span>
            
            <span id="chunk-105" class="transcript-chunks" onclick="console.log('00:07:16,402'); seek(436.0)">
              to elicit reasoning. So these models,
            </span>
            
            <span id="chunk-106" class="transcript-chunks" onclick="console.log('00:07:21,230'); seek(441.0)">
              as the objective of its training, are not trained to
            </span>
            
            <span id="chunk-107" class="transcript-chunks" onclick="console.log('00:07:25,056'); seek(445.0)">
              do reasoning, or at least from
            </span>
            
            <span id="chunk-108" class="transcript-chunks" onclick="console.log('00:07:28,512'); seek(448.0)">
              my understanding, it's not trained to do reasoning.
            </span>
            
            <span id="chunk-109" class="transcript-chunks" onclick="console.log('00:07:33,250'); seek(453.0)">
              It still has the tendency to do text completion
            </span>
            
            <span id="chunk-110" class="transcript-chunks" onclick="console.log('00:07:38,370'); seek(458.0)">
              so that's why we would need the methodologies that we are
            </span>
            
            <span id="chunk-111" class="transcript-chunks" onclick="console.log('00:07:41,908'); seek(461.0)">
              going to discuss in the further slides for eliciting
            </span>
            
            <span id="chunk-112" class="transcript-chunks" onclick="console.log('00:07:46,554'); seek(466.0)">
              these reasoning. So let's start with probably
            </span>
            
            <span id="chunk-113" class="transcript-chunks" onclick="console.log('00:07:50,404'); seek(470.0)">
              the most popular and also from my
            </span>
            
            <span id="chunk-114" class="transcript-chunks" onclick="console.log('00:07:54,052'); seek(474.0)">
              understanding, these methodology which kick started
            </span>
            
            <span id="chunk-115" class="transcript-chunks" onclick="console.log('00:07:58,044'); seek(478.0)">
              all the different prompting
            </span>
            
            <span id="chunk-116" class="transcript-chunks" onclick="console.log('00:08:01,666'); seek(481.0)">
              techniques to elicit reasoning, the chain of
            </span>
            
            <span id="chunk-117" class="transcript-chunks" onclick="console.log('00:08:04,828'); seek(484.0)">
              thought prompting. So in chain of thought prompting, the authors
            </span>
            
            <span id="chunk-118" class="transcript-chunks" onclick="console.log('00:08:09,398'); seek(489.0)">
              JSon V had tried to do so what
            </span>
            
            <span id="chunk-119" class="transcript-chunks" onclick="console.log('00:08:13,088'); seek(493.0)">
              they have tried to do is for all the mathematical and
            </span>
            
            <span id="chunk-120" class="transcript-chunks" onclick="console.log('00:08:18,830'); seek(498.0)">
              other reasoning related questions,
            </span>
            
            <span id="chunk-121" class="transcript-chunks" onclick="console.log('00:08:22,050'); seek(502.0)">
              instead of asking the direct answers to the model.
            </span>
            
            <span id="chunk-122" class="transcript-chunks" onclick="console.log('00:08:25,428'); seek(505.0)">
              If we ask the model to generate step by step
            </span>
            
            <span id="chunk-123" class="transcript-chunks" onclick="console.log('00:08:28,756'); seek(508.0)">
              reason and then generate the final answers,
            </span>
            
            <span id="chunk-124" class="transcript-chunks" onclick="console.log('00:08:32,698'); seek(512.0)">
              answers. Finally, they found that the model tend to
            </span>
            
            <span id="chunk-125" class="transcript-chunks" onclick="console.log('00:08:36,612'); seek(516.0)">
              do tend to generate answers
            </span>
            
            <span id="chunk-126" class="transcript-chunks" onclick="console.log('00:08:40,270'); seek(520.0)">
              better. The accuracy of generation of answers was better.
            </span>
            
            <span id="chunk-127" class="transcript-chunks" onclick="console.log('00:08:44,040'); seek(524.0)">
              So here, if you see the question, Roger has five
            </span>
            
            <span id="chunk-128" class="transcript-chunks" onclick="console.log('00:08:47,676'); seek(527.0)">
              tennis balls, he buys two more cans of tennis balls,
            </span>
            
            <span id="chunk-129" class="transcript-chunks" onclick="console.log('00:08:51,282'); seek(531.0)">
              each can has three tennis balls. How many tennis
            </span>
            
            <span id="chunk-130" class="transcript-chunks" onclick="console.log('00:08:55,058'); seek(535.0)">
              balls does he have now? So there in the answer,
            </span>
            
            <span id="chunk-131" class="transcript-chunks" onclick="console.log('00:08:58,268'); seek(538.0)">
              as a one shot example, they have explained the different steps
            </span>
            
            <span id="chunk-132" class="transcript-chunks" onclick="console.log('00:09:02,182'); seek(542.0)">
              that can be deduced from this question and then the final answer.
            </span>
            
            <span id="chunk-133" class="transcript-chunks" onclick="console.log('00:09:06,256'); seek(546.0)">
              So for a new question that the model sees here,
            </span>
            
            <span id="chunk-134" class="transcript-chunks" onclick="console.log('00:09:09,344'); seek(549.0)">
              the cafeteria example, the model would come up
            </span>
            
            <span id="chunk-135" class="transcript-chunks" onclick="console.log('00:09:12,772'); seek(552.0)">
              with a similar chain
            </span>
            
            <span id="chunk-136" class="transcript-chunks" onclick="console.log('00:09:16,922'); seek(556.0)">
              of steps and then it would generate an answer
            </span>
            
            <span id="chunk-137" class="transcript-chunks" onclick="console.log('00:09:20,900'); seek(560.0)">
              from this. So these methodology
            </span>
            
            <span id="chunk-138" class="transcript-chunks" onclick="console.log('00:09:24,558'); seek(564.0)">
              has resulted or has shown to give
            </span>
            
            <span id="chunk-139" class="transcript-chunks" onclick="console.log('00:09:28,456'); seek(568.0)">
              better results. You can see across all
            </span>
            
            <span id="chunk-140" class="transcript-chunks" onclick="console.log('00:09:32,472'); seek(572.0)">
              the reasoning data sets and across all the
            </span>
            
            <span id="chunk-141" class="transcript-chunks" onclick="console.log('00:09:35,948'); seek(575.0)">
              different models, this approach seems to give better results.
            </span>
            
            <span id="chunk-142" class="transcript-chunks" onclick="console.log('00:09:40,162'); seek(580.0)">
              And there is another variation of it from Wang
            </span>
            
            <span id="chunk-143" class="transcript-chunks" onclick="console.log('00:09:44,258'); seek(584.0)">
              et al. It's called as self consistency.
            </span>
            
            <span id="chunk-144" class="transcript-chunks" onclick="console.log('00:09:48,146'); seek(588.0)">
              So in the chain of thought prompting, initial chain of thought prompting, the answers
            </span>
            
            <span id="chunk-145" class="transcript-chunks" onclick="console.log('00:09:52,358'); seek(592.0)">
              are generated using greedy decoding. So there is only one generation
            </span>
            
            <span id="chunk-146" class="transcript-chunks" onclick="console.log('00:09:56,854'); seek(596.0)">
              for a given prompt. So in the self consistencies,
            </span>
            
            <span id="chunk-147" class="transcript-chunks" onclick="console.log('00:10:00,682'); seek(600.0)">
              the authors have tried to do sampling
            </span>
            
            <span id="chunk-148" class="transcript-chunks" onclick="console.log('00:10:04,458'); seek(604.0)">
              based decoding to generate multiple generations
            </span>
            
            <span id="chunk-149" class="transcript-chunks" onclick="console.log('00:10:08,634'); seek(608.0)">
              for a given prompt. And then they consider the most,
            </span>
            
            <span id="chunk-150" class="transcript-chunks" onclick="console.log('00:10:12,260'); seek(612.0)">
              or the majority voted answers which are similar
            </span>
            
            <span id="chunk-151" class="transcript-chunks" onclick="console.log('00:10:15,864'); seek(615.0)">
              or which are same, and then they evaluate that
            </span>
            
            <span id="chunk-152" class="transcript-chunks" onclick="console.log('00:10:19,352'); seek(619.0)">
              particular answers against the evaluation set.
            </span>
            
            <span id="chunk-153" class="transcript-chunks" onclick="console.log('00:10:24,970'); seek(624.0)">
              So that way the model performs better even than
            </span>
            
            <span id="chunk-154" class="transcript-chunks" onclick="console.log('00:10:29,292'); seek(629.0)">
              chain of thought prompting. So their intuition
            </span>
            
            <span id="chunk-155" class="transcript-chunks" onclick="console.log('00:10:33,378'); seek(633.0)">
              is that if a
            </span>
            
            <span id="chunk-156" class="transcript-chunks" onclick="console.log('00:10:36,828'); seek(636.0)">
              model comes up with majority of solutions, a majority of
            </span>
            
            <span id="chunk-157" class="transcript-chunks" onclick="console.log('00:10:40,976'); seek(640.0)">
              methods to come up with the same solution,
            </span>
            
            <span id="chunk-158" class="transcript-chunks" onclick="console.log('00:10:44,110'); seek(644.0)">
              then they consider that it's most likely that that is a
            </span>
            
            <span id="chunk-159" class="transcript-chunks" onclick="console.log('00:10:47,808'); seek(647.0)">
              proper and correct answer. So that's the intuition
            </span>
            
            <span id="chunk-160" class="transcript-chunks" onclick="console.log('00:10:51,318'); seek(651.0)">
              for that and can extension to
            </span>
            
            <span id="chunk-161" class="transcript-chunks" onclick="console.log('00:10:55,092'); seek(655.0)">
              chain of thought. Is that so? The challenge
            </span>
            
            <span id="chunk-162" class="transcript-chunks" onclick="console.log('00:10:58,778'); seek(658.0)">
              with chain of thought is we are leaving
            </span>
            
            <span id="chunk-163" class="transcript-chunks" onclick="console.log('00:11:02,602'); seek(662.0)">
              the arithmetic operations when it comes to mathematical
            </span>
            
            <span id="chunk-164" class="transcript-chunks" onclick="console.log('00:11:06,302'); seek(666.0)">
              reasoning. We are leaving that to the
            </span>
            
            <span id="chunk-165" class="transcript-chunks" onclick="console.log('00:11:10,040'); seek(670.0)">
              llms. So we all know that llms
            </span>
            
            <span id="chunk-166" class="transcript-chunks" onclick="console.log('00:11:14,894'); seek(674.0)">
              lack even simple arithmetic abilities.
            </span>
            
            <span id="chunk-167" class="transcript-chunks" onclick="console.log('00:11:19,314'); seek(679.0)">
              So in this paper, program aided
            </span>
            
            <span id="chunk-168" class="transcript-chunks" onclick="console.log('00:11:22,818'); seek(682.0)">
              language models. So the authors have tried a
            </span>
            
            <span id="chunk-169" class="transcript-chunks" onclick="console.log('00:11:27,050'); seek(687.0)">
              clever methodology where they have offloaded
            </span>
            
            <span id="chunk-170" class="transcript-chunks" onclick="console.log('00:11:32,670'); seek(692.0)">
              the arithmetic calculations to the Python interpreter.
            </span>
            
            <span id="chunk-171" class="transcript-chunks" onclick="console.log('00:11:36,566'); seek(696.0)">
              So the way they have done is they have created few
            </span>
            
            <span id="chunk-172" class="transcript-chunks" onclick="console.log('00:11:40,372'); seek(700.0)">
              short prompts. So each With a question like we saw in China
            </span>
            
            <span id="chunk-173" class="transcript-chunks" onclick="console.log('00:11:44,058'); seek(704.0)">
              of thought prompting. And they divided the
            </span>
            
            <span id="chunk-174" class="transcript-chunks" onclick="console.log('00:11:48,548'); seek(708.0)">
              solutions, they have represented it
            </span>
            
            <span id="chunk-175" class="transcript-chunks" onclick="console.log('00:11:52,068'); seek(712.0)">
              as a Python problem. So here you can see these
            </span>
            
            <span id="chunk-176" class="transcript-chunks" onclick="console.log('00:11:55,672'); seek(715.0)">
              tennis ball, they have deduced the tennis ball
            </span>
            
            <span id="chunk-177" class="transcript-chunks" onclick="console.log('00:11:59,326'); seek(719.0)">
              value from the question, and then what are the balls
            </span>
            
            <span id="chunk-178" class="transcript-chunks" onclick="console.log('00:12:03,006'); seek(723.0)">
              that are bought? And then these answer. So this way
            </span>
            
            <span id="chunk-179" class="transcript-chunks" onclick="console.log('00:12:06,332'); seek(726.0)">
              they have converted that to a pythonic solution.
            </span>
            
            <span id="chunk-180" class="transcript-chunks" onclick="console.log('00:12:10,898'); seek(730.0)">
              So this way, for a new problem based on
            </span>
            
            <span id="chunk-181" class="transcript-chunks" onclick="console.log('00:12:14,668'); seek(734.0)">
              the examples that are there in Fusot,
            </span>
            
            <span id="chunk-182" class="transcript-chunks" onclick="console.log('00:12:17,634'); seek(737.0)">
              the model generates a similar Python
            </span>
            
            <span id="chunk-183" class="transcript-chunks" onclick="console.log('00:12:21,950'); seek(741.0)">
              problem, reducing the question and then coming up
            </span>
            
            <span id="chunk-184" class="transcript-chunks" onclick="console.log('00:12:25,648'); seek(745.0)">
              with the final answer. So to get the final answer,
            </span>
            
            <span id="chunk-185" class="transcript-chunks" onclick="console.log('00:12:28,816'); seek(748.0)">
              these generated solution is executed
            </span>
            
            <span id="chunk-186" class="transcript-chunks" onclick="console.log('00:12:32,922'); seek(752.0)">
              in the Python interpreter and that is considered as the final solution.
            </span>
            
            <span id="chunk-187" class="transcript-chunks" onclick="console.log('00:12:37,290'); seek(757.0)">
              So this performed better than Chain of thought as you
            </span>
            
            <span id="chunk-188" class="transcript-chunks" onclick="console.log('00:12:41,348'); seek(761.0)">
              can see in the results across all the mathematical reasoning
            </span>
            
            <span id="chunk-189" class="transcript-chunks" onclick="console.log('00:12:45,198'); seek(765.0)">
              benchmarks. The main reason is we are using
            </span>
            
            <span id="chunk-190" class="transcript-chunks" onclick="console.log('00:12:49,048'); seek(769.0)">
              llms for its advantages,
            </span>
            
            <span id="chunk-191" class="transcript-chunks" onclick="console.log('00:12:53,430'); seek(773.0)">
              for its strengths, and these we
            </span>
            
            <span id="chunk-192" class="transcript-chunks" onclick="console.log('00:12:56,888'); seek(776.0)">
              are offloading the weakness of llms to the Python
            </span>
            
            <span id="chunk-193" class="transcript-chunks" onclick="console.log('00:13:00,898'); seek(780.0)">
              interpreter. And another variation of this
            </span>
            
            <span id="chunk-194" class="transcript-chunks" onclick="console.log('00:13:04,652'); seek(784.0)">
              prompting, or this type of prompting, is plan and solve prompting.
            </span>
            
            <span id="chunk-195" class="transcript-chunks" onclick="console.log('00:13:08,818'); seek(788.0)">
              So this is mostly to address the
            </span>
            
            <span id="chunk-196" class="transcript-chunks" onclick="console.log('00:13:13,130'); seek(793.0)">
              performance of zero short chain of thought prompting.
            </span>
            
            <span id="chunk-197" class="transcript-chunks" onclick="console.log('00:13:16,742'); seek(796.0)">
              So zero short chain of thought prompting is usually done by this
            </span>
            
            <span id="chunk-198" class="transcript-chunks" onclick="console.log('00:13:20,912'); seek(800.0)">
              prompt where we ask, given a question, we ask let's
            </span>
            
            <span id="chunk-199" class="transcript-chunks" onclick="console.log('00:13:24,682'); seek(804.0)">
              think step by step, and the model will come up with step by step thought
            </span>
            
            <span id="chunk-200" class="transcript-chunks" onclick="console.log('00:13:29,636'); seek(809.0)">
              process and the final answer. But this wasn't working
            </span>
            
            <span id="chunk-201" class="transcript-chunks" onclick="console.log('00:13:33,736'); seek(813.0)">
              that well, mainly due to different reasons. One of that
            </span>
            
            <span id="chunk-202" class="transcript-chunks" onclick="console.log('00:13:37,272'); seek(817.0)">
              is the arithmetic ability, as we saw before. And then there
            </span>
            
            <span id="chunk-203" class="transcript-chunks" onclick="console.log('00:13:43,128'); seek(823.0)">
              was few inference steps that are missed by the model
            </span>
            
            <span id="chunk-204" class="transcript-chunks" onclick="console.log('00:13:47,132'); seek(827.0)">
              and few inference steps that are not converted
            </span>
            
            <span id="chunk-205" class="transcript-chunks" onclick="console.log('00:13:51,122'); seek(831.0)">
              to solutions. In these zero shot can of thought
            </span>
            
            <span id="chunk-206" class="transcript-chunks" onclick="console.log('00:13:54,620'); seek(834.0)">
              prompting. So this is rectified by a methodology
            </span>
            
            <span id="chunk-207" class="transcript-chunks" onclick="console.log('00:13:58,274'); seek(838.0)">
              called as plan and solve prompting.
            </span>
            
            <span id="chunk-208" class="transcript-chunks" onclick="console.log('00:14:02,090'); seek(842.0)">
              In these, the authors authors
            </span>
            
            <span id="chunk-209" class="transcript-chunks" onclick="console.log('00:14:05,446'); seek(845.0)">
              try a different style of prompting called let's prompting.
            </span>
            
            <span id="chunk-210" class="transcript-chunks" onclick="console.log('00:14:09,046'); seek(849.0)">
              That is, let's first understand the problem and devise a plan
            </span>
            
            <span id="chunk-211" class="transcript-chunks" onclick="console.log('00:14:12,656'); seek(852.0)">
              to solve the problem. Then let's carry out the plan and solve these
            </span>
            
            <span id="chunk-212" class="transcript-chunks" onclick="console.log('00:14:16,228'); seek(856.0)">
              problem step by step. So they ask
            </span>
            
            <span id="chunk-213" class="transcript-chunks" onclick="console.log('00:14:19,652'); seek(859.0)">
              the model to come up with the plan first and then the solution
            </span>
            
            <span id="chunk-214" class="transcript-chunks" onclick="console.log('00:14:22,926'); seek(862.0)">
              based on the plan that it has derived. So this way, these model,
            </span>
            
            <span id="chunk-215" class="transcript-chunks" onclick="console.log('00:14:27,270'); seek(867.0)">
              they have show that the model performs better than
            </span>
            
            <span id="chunk-216" class="transcript-chunks" onclick="console.log('00:14:32,950'); seek(872.0)">
              zero short chain of thoughts prompting,
            </span>
            
            <span id="chunk-217" class="transcript-chunks" onclick="console.log('00:14:36,882'); seek(876.0)">
              and even they have shown that it performs better than few
            </span>
            
            <span id="chunk-218" class="transcript-chunks" onclick="console.log('00:14:41,020'); seek(881.0)">
              short chain of thought prompting in some cases.
            </span>
            
            <span id="chunk-219" class="transcript-chunks" onclick="console.log('00:14:44,410'); seek(884.0)">
              So until now we have seen methodologies of how to
            </span>
            
            <span id="chunk-220" class="transcript-chunks" onclick="console.log('00:14:47,888'); seek(887.0)">
              inference or how to do in context, learning to
            </span>
            
            <span id="chunk-221" class="transcript-chunks" onclick="console.log('00:14:51,872'); seek(891.0)">
              incontext, learning to elicit
            </span>
            
            <span id="chunk-222" class="transcript-chunks" onclick="console.log('00:14:56,350'); seek(896.0)">
              reasoning abilities from llms.
            </span>
            
            <span id="chunk-223" class="transcript-chunks" onclick="console.log('00:15:00,370'); seek(900.0)">
              But there are techniques that can be used to
            </span>
            
            <span id="chunk-224" class="transcript-chunks" onclick="console.log('00:15:07,090'); seek(907.0)">
              fine tune our large language models
            </span>
            
            <span id="chunk-225" class="transcript-chunks" onclick="console.log('00:15:10,842'); seek(910.0)">
              to elicit or improve the reasoning abilities
            </span>
            
            <span id="chunk-226" class="transcript-chunks" onclick="console.log('00:15:14,382'); seek(914.0)">
              so we'll be seeing that in this section of
            </span>
            
            <span id="chunk-227" class="transcript-chunks" onclick="console.log('00:15:17,688'); seek(917.0)">
              the talk. So one paper that does that is learning
            </span>
            
            <span id="chunk-228" class="transcript-chunks" onclick="console.log('00:15:22,200'); seek(922.0)">
              math reasoning from cell sample, the correct and partially correct solution.
            </span>
            
            <span id="chunk-229" class="transcript-chunks" onclick="console.log('00:15:27,210'); seek(927.0)">
              Here the authors have authors use
            </span>
            
            <span id="chunk-230" class="transcript-chunks" onclick="console.log('00:15:31,068'); seek(931.0)">
              LLM. I think in these case they have used GPT Neo 2.7
            </span>
            
            <span id="chunk-231" class="transcript-chunks" onclick="console.log('00:15:36,012'); seek(936.0)">
              billion model. So for
            </span>
            
            <span id="chunk-232" class="transcript-chunks" onclick="console.log('00:15:39,324'); seek(939.0)">
              a given set of question, they ask the model to generate a
            </span>
            
            <span id="chunk-233" class="transcript-chunks" onclick="console.log('00:15:42,752'); seek(942.0)">
              solution, a pythonic solution, and then they
            </span>
            
            <span id="chunk-234" class="transcript-chunks" onclick="console.log('00:15:46,592'); seek(946.0)">
              evaluate the answer. When the answer matches with the ground truth or gold
            </span>
            
            <span id="chunk-235" class="transcript-chunks" onclick="console.log('00:15:50,422'); seek(950.0)">
              answers that they have, they use these solution, they use
            </span>
            
            <span id="chunk-236" class="transcript-chunks" onclick="console.log('00:15:54,036'); seek(954.0)">
              that in the fine tuning data set. Similarly they generate
            </span>
            
            <span id="chunk-237" class="transcript-chunks" onclick="console.log('00:15:58,394'); seek(958.0)">
              solutions for whatever generations
            </span>
            
            <span id="chunk-238" class="transcript-chunks" onclick="console.log('00:16:02,330'); seek(962.0)">
              that had got correct answers.
            </span>
            
            <span id="chunk-239" class="transcript-chunks" onclick="console.log('00:16:05,886'); seek(965.0)">
              They filter those generation and then they
            </span>
            
            <span id="chunk-240" class="transcript-chunks" onclick="console.log('00:16:09,320'); seek(969.0)">
              iteratively fine tune the same model on that,
            </span>
            
            <span id="chunk-241" class="transcript-chunks" onclick="console.log('00:16:12,760'); seek(972.0)">
              same model on that. So they not only use
            </span>
            
            <span id="chunk-242" class="transcript-chunks" onclick="console.log('00:16:16,316'); seek(976.0)">
              the fully correct solution, they also have introduced
            </span>
            
            <span id="chunk-243" class="transcript-chunks" onclick="console.log('00:16:20,178'); seek(980.0)">
              a methodology to utilize partially correct solutions.
            </span>
            
            <span id="chunk-244" class="transcript-chunks" onclick="console.log('00:16:23,954'); seek(983.0)">
              So the way they do partially correct solution is
            </span>
            
            <span id="chunk-245" class="transcript-chunks" onclick="console.log('00:16:28,830'); seek(988.0)">
              they have a gold
            </span>
            
            <span id="chunk-246" class="transcript-chunks" onclick="console.log('00:16:34,590'); seek(994.0)">
              solutions where they have outputs for individual
            </span>
            
            <span id="chunk-247" class="transcript-chunks" onclick="console.log('00:16:39,936'); seek(999.0)">
              steps, as you see here and these similarly we
            </span>
            
            <span id="chunk-248" class="transcript-chunks" onclick="console.log('00:16:43,492'); seek(1003.0)">
              have a generated solution with individual outputs
            </span>
            
            <span id="chunk-249" class="transcript-chunks" onclick="console.log('00:16:47,258'); seek(1007.0)">
              from each of these steps. So whenever there is a match between
            </span>
            
            <span id="chunk-250" class="transcript-chunks" onclick="console.log('00:16:52,130'); seek(1012.0)">
              these individual steps in gold and the generated
            </span>
            
            <span id="chunk-251" class="transcript-chunks" onclick="console.log('00:16:55,726'); seek(1015.0)">
              one, they consider that as a partially correct solution and
            </span>
            
            <span id="chunk-252" class="transcript-chunks" onclick="console.log('00:16:59,832'); seek(1019.0)">
              then they use that to further fine tune the model.
            </span>
            
            <span id="chunk-253" class="transcript-chunks" onclick="console.log('00:17:03,208'); seek(1023.0)">
              So they have shown in their paper
            </span>
            
            <span id="chunk-254" class="transcript-chunks" onclick="console.log('00:17:06,796'); seek(1026.0)">
              that this type of iterative fine tuning on the
            </span>
            
            <span id="chunk-255" class="transcript-chunks" onclick="console.log('00:17:10,892'); seek(1030.0)">
              model generated solutions,
            </span>
            
            <span id="chunk-256" class="transcript-chunks" onclick="console.log('00:17:14,490'); seek(1034.0)">
              there is an improvement in mathematical reasoning
            </span>
            
            <span id="chunk-257" class="transcript-chunks" onclick="console.log('00:17:18,418'); seek(1038.0)">
              abilities of the model. So if you can see, the green
            </span>
            
            <span id="chunk-258" class="transcript-chunks" onclick="console.log('00:17:21,760'); seek(1041.0)">
              ones are the one which are fine tuned only on fully
            </span>
            
            <span id="chunk-259" class="transcript-chunks" onclick="console.log('00:17:25,718'); seek(1045.0)">
              correct solution and the orange ones are the one that are self
            </span>
            
            <span id="chunk-260" class="transcript-chunks" onclick="console.log('00:17:29,696'); seek(1049.0)">
              sampled with fully correct and partially correct solutions.
            </span>
            
            <span id="chunk-261" class="transcript-chunks" onclick="console.log('00:17:34,050'); seek(1054.0)">
              And we can also observe that the pass at one rate is
            </span>
            
            <span id="chunk-262" class="transcript-chunks" onclick="console.log('00:17:37,828'); seek(1057.0)">
              not improved. So the authors, authors comment that
            </span>
            
            <span id="chunk-263" class="transcript-chunks" onclick="console.log('00:17:42,052'); seek(1062.0)">
              this is mainly because the nature of
            </span>
            
            <span id="chunk-264" class="transcript-chunks" onclick="console.log('00:17:46,710'); seek(1066.0)">
              these training facilitates the
            </span>
            
            <span id="chunk-265" class="transcript-chunks" onclick="console.log('00:17:50,008'); seek(1070.0)">
              model to generate diverse set of solutions and it
            </span>
            
            <span id="chunk-266" class="transcript-chunks" onclick="console.log('00:17:54,952'); seek(1074.0)">
              does not make the model to favor any one particular solution.
            </span>
            
            <span id="chunk-267" class="transcript-chunks" onclick="console.log('00:17:59,182'); seek(1079.0)">
              That's why the pass at one is not improved much, but you can
            </span>
            
            <span id="chunk-268" class="transcript-chunks" onclick="console.log('00:18:02,812'); seek(1082.0)">
              see other improvements in other passet k values.
            </span>
            
            <span id="chunk-269" class="transcript-chunks" onclick="console.log('00:18:07,890'); seek(1087.0)">
              So another paper that does something similar is
            </span>
            
            <span id="chunk-270" class="transcript-chunks" onclick="console.log('00:18:11,852'); seek(1091.0)">
              self taught reasoner bootstrapping, reasoning with reasoning or
            </span>
            
            <span id="chunk-271" class="transcript-chunks" onclick="console.log('00:18:15,536'); seek(1095.0)">
              star. So here in this methodology,
            </span>
            
            <span id="chunk-272" class="transcript-chunks" onclick="console.log('00:18:19,390'); seek(1099.0)">
              the authors generate rational
            </span>
            
            <span id="chunk-273" class="transcript-chunks" onclick="console.log('00:18:23,882'); seek(1103.0)">
              and answers from an existing large language model.
            </span>
            
            <span id="chunk-274" class="transcript-chunks" onclick="console.log('00:18:27,892'); seek(1107.0)">
              And then whenever the answer is correct for that
            </span>
            
            <span id="chunk-275" class="transcript-chunks" onclick="console.log('00:18:31,476'); seek(1111.0)">
              particular gold standards, when they compare it with
            </span>
            
            <span id="chunk-276" class="transcript-chunks" onclick="console.log('00:18:34,868'); seek(1114.0)">
              the gold ground root data set that they have, they take
            </span>
            
            <span id="chunk-277" class="transcript-chunks" onclick="console.log('00:18:38,616'); seek(1118.0)">
              that, they put that into a fine tuning coppers along with
            </span>
            
            <span id="chunk-278" class="transcript-chunks" onclick="console.log('00:18:42,696'); seek(1122.0)">
              as a triplet, as question, rational and answer. So whenever
            </span>
            
            <span id="chunk-279" class="transcript-chunks" onclick="console.log('00:18:46,526'); seek(1126.0)">
              the answer is wrong, they hint the model
            </span>
            
            <span id="chunk-280" class="transcript-chunks" onclick="console.log('00:18:49,816'); seek(1129.0)">
              to generate a correct rationale by giving the correct answer from the ground
            </span>
            
            <span id="chunk-281" class="transcript-chunks" onclick="console.log('00:18:53,762'); seek(1133.0)">
              truth. So they ask the model to generate a rational and then they
            </span>
            
            <span id="chunk-282" class="transcript-chunks" onclick="console.log('00:18:57,276'); seek(1137.0)">
              put that back into the fine tuning mixture.
            </span>
            
            <span id="chunk-283" class="transcript-chunks" onclick="console.log('00:19:00,630'); seek(1140.0)">
              So that way they fine tune the model again so
            </span>
            
            <span id="chunk-284" class="transcript-chunks" onclick="console.log('00:19:04,720'); seek(1144.0)">
              that fine tuned model has a better ability to generate rational.
            </span>
            
            <span id="chunk-285" class="transcript-chunks" onclick="console.log('00:19:08,422'); seek(1148.0)">
              So these do this iteratively and then they have
            </span>
            
            <span id="chunk-286" class="transcript-chunks" onclick="console.log('00:19:12,052'); seek(1152.0)">
              a final model. So this has
            </span>
            
            <span id="chunk-287" class="transcript-chunks" onclick="console.log('00:19:15,332'); seek(1155.0)">
              proved to improve the mathematical reasoning
            </span>
            
            <span id="chunk-288" class="transcript-chunks" onclick="console.log('00:19:19,098'); seek(1159.0)">
              abilities even by using only the partial
            </span>
            
            <span id="chunk-289" class="transcript-chunks" onclick="console.log('00:19:23,490'); seek(1163.0)">
              training data set. So if you can see, the few short and
            </span>
            
            <span id="chunk-290" class="transcript-chunks" onclick="console.log('00:19:26,952'); seek(1166.0)">
              then fine tuned abilities of the GPTJ model has
            </span>
            
            <span id="chunk-291" class="transcript-chunks" onclick="console.log('00:19:30,952'); seek(1170.0)">
              improved from 5.8 to 10.7 here. So another
            </span>
            
            <span id="chunk-292" class="transcript-chunks" onclick="console.log('00:19:34,920'); seek(1174.0)">
              variation to this approach is this is more of distilling from
            </span>
            
            <span id="chunk-293" class="transcript-chunks" onclick="console.log('00:19:38,652'); seek(1178.0)">
              a large language model, a paper called specializing
            </span>
            
            <span id="chunk-294" class="transcript-chunks" onclick="console.log('00:19:42,066'); seek(1182.0)">
              smaller language models towards multistep reasoning by
            </span>
            
            <span id="chunk-295" class="transcript-chunks" onclick="console.log('00:19:45,708'); seek(1185.0)">
              few et al. Here the authors have tried to distill
            </span>
            
            <span id="chunk-296" class="transcript-chunks" onclick="console.log('00:19:50,910'); seek(1190.0)">
              the reasoning steps as well as the solution
            </span>
            
            <span id="chunk-297" class="transcript-chunks" onclick="console.log('00:19:54,806'); seek(1194.0)">
              from a large language model, a bigger model like from GPT-3
            </span>
            
            <span id="chunk-298" class="transcript-chunks" onclick="console.log('00:19:59,776'); seek(1199.0)">
              and then they fine tuned a smaller model like different t five versions,
            </span>
            
            <span id="chunk-299" class="transcript-chunks" onclick="console.log('00:20:03,978'); seek(1203.0)">
              different t five versions 250,000,000 760,000,003
            </span>
            
            <span id="chunk-300" class="transcript-chunks" onclick="console.log('00:20:08,532'); seek(1208.0)">
              billion. So they tried two different
            </span>
            
            <span id="chunk-301" class="transcript-chunks" onclick="console.log('00:20:12,100'); seek(1212.0)">
              variations. One is fine tuning only
            </span>
            
            <span id="chunk-302" class="transcript-chunks" onclick="console.log('00:20:15,640'); seek(1215.0)">
              on answers and then fine tuning on both answers and
            </span>
            
            <span id="chunk-303" class="transcript-chunks" onclick="console.log('00:20:19,464'); seek(1219.0)">
              chain of thought steps. So they found that
            </span>
            
            <span id="chunk-304" class="transcript-chunks" onclick="console.log('00:20:22,888'); seek(1222.0)">
              fine tuning on chain of thought and answers
            </span>
            
            <span id="chunk-305" class="transcript-chunks" onclick="console.log('00:20:27,130'); seek(1227.0)">
              are giving better accuracy as the model also
            </span>
            
            <span id="chunk-306" class="transcript-chunks" onclick="console.log('00:20:30,796'); seek(1230.0)">
              tries to understand the rationale of the answers. And we
            </span>
            
            <span id="chunk-307" class="transcript-chunks" onclick="console.log('00:20:34,508'); seek(1234.0)">
              could see the improvement here. Similarly,
            </span>
            
            <span id="chunk-308" class="transcript-chunks" onclick="console.log('00:20:37,698'); seek(1237.0)">
              they have tried that not only to vanilla Tfi but also to
            </span>
            
            <span id="chunk-309" class="transcript-chunks" onclick="console.log('00:20:41,568'); seek(1241.0)">
              flan t five. So flan t five shows a better improvement
            </span>
            
            <span id="chunk-310" class="transcript-chunks" onclick="console.log('00:20:46,070'); seek(1246.0)">
              compared to the vanilla t five models. So another
            </span>
            
            <span id="chunk-311" class="transcript-chunks" onclick="console.log('00:20:50,690'); seek(1250.0)">
              recent approach in distilling is
            </span>
            
            <span id="chunk-312" class="transcript-chunks" onclick="console.log('00:20:54,548'); seek(1254.0)">
              these distilling step by step paper from Hashe et
            </span>
            
            <span id="chunk-313" class="transcript-chunks" onclick="console.log('00:20:58,618'); seek(1258.0)">
              al. So here for an unlabeled
            </span>
            
            <span id="chunk-314" class="transcript-chunks" onclick="console.log('00:21:02,266'); seek(1262.0)">
              set of data set, they use a large language model like
            </span>
            
            <span id="chunk-315" class="transcript-chunks" onclick="console.log('00:21:06,264'); seek(1266.0)">
              a palm or a palm or a gpt-3
            </span>
            
            <span id="chunk-316" class="transcript-chunks" onclick="console.log('00:21:10,328'); seek(1270.0)">
              models to generate labels. Not only labels,
            </span>
            
            <span id="chunk-317" class="transcript-chunks" onclick="console.log('00:21:13,982'); seek(1273.0)">
              they also ask the model to generate the rational or chain
            </span>
            
            <span id="chunk-318" class="transcript-chunks" onclick="console.log('00:21:17,214'); seek(1277.0)">
              of starts for this particular answer,
            </span>
            
            <span id="chunk-319" class="transcript-chunks" onclick="console.log('00:21:20,908'); seek(1280.0)">
              particular answer. And then when they distill
            </span>
            
            <span id="chunk-320" class="transcript-chunks" onclick="console.log('00:21:24,082'); seek(1284.0)">
              it and train a smaller model, they train it on an objective
            </span>
            
            <span id="chunk-321" class="transcript-chunks" onclick="console.log('00:21:27,714'); seek(1287.0)">
              similar to a multitask planning. So they ask the model
            </span>
            
            <span id="chunk-322" class="transcript-chunks" onclick="console.log('00:21:31,440'); seek(1291.0)">
              to predict a label as well as the rational
            </span>
            
            <span id="chunk-323" class="transcript-chunks" onclick="console.log('00:21:34,758'); seek(1294.0)">
              for it instead of concatenating the rational and
            </span>
            
            <span id="chunk-324" class="transcript-chunks" onclick="console.log('00:21:38,048'); seek(1298.0)">
              label as one chunk. They had approached
            </span>
            
            <span id="chunk-325" class="transcript-chunks" onclick="console.log('00:21:41,242'); seek(1301.0)">
              this as a multitask planning. And then they have shown that these gives
            </span>
            
            <span id="chunk-326" class="transcript-chunks" onclick="console.log('00:21:44,932'); seek(1304.0)">
              a better improvement in improving
            </span>
            
            <span id="chunk-327" class="transcript-chunks" onclick="console.log('00:21:49,066'); seek(1309.0)">
              the smaller models reasoning
            </span>
            
            <span id="chunk-328" class="transcript-chunks" onclick="console.log('00:21:54,222'); seek(1314.0)">
              abilities. So the loss they have done is
            </span>
            
            <span id="chunk-329" class="transcript-chunks" onclick="console.log('00:21:58,072'); seek(1318.0)">
              they had taken a weighted loss of label
            </span>
            
            <span id="chunk-330" class="transcript-chunks" onclick="console.log('00:22:01,582'); seek(1321.0)">
              loss as well as the rational loss generation of
            </span>
            
            <span id="chunk-331" class="transcript-chunks" onclick="console.log('00:22:04,728'); seek(1324.0)">
              rational. So they show that these models,
            </span>
            
            <span id="chunk-332" class="transcript-chunks" onclick="console.log('00:22:08,226'); seek(1328.0)">
              the fine tuned model in this distilling step by step model performs
            </span>
            
            <span id="chunk-333" class="transcript-chunks" onclick="console.log('00:22:12,418'); seek(1332.0)">
              even better than a 540,000,000,000 model in
            </span>
            
            <span id="chunk-334" class="transcript-chunks" onclick="console.log('00:22:16,524'); seek(1336.0)">
              540,000,000,000 models, a few short generations.
            </span>
            
            <span id="chunk-335" class="transcript-chunks" onclick="console.log('00:22:20,310'); seek(1340.0)">
              So you could see that t five to 20 million sound,
            </span>
            
            <span id="chunk-336" class="transcript-chunks" onclick="console.log('00:22:23,776'); seek(1343.0)">
              70 million and 11 billion doing a better job
            </span>
            
            <span id="chunk-337" class="transcript-chunks" onclick="console.log('00:22:27,088'); seek(1347.0)">
              in the mathematical reasoning and common
            </span>
            
            <span id="chunk-338" class="transcript-chunks" onclick="console.log('00:22:31,380'); seek(1351.0)">
              sense Qa common sense Qa
            </span>
            
            <span id="chunk-339" class="transcript-chunks" onclick="console.log('00:22:34,842'); seek(1354.0)">
              task. So until now we saw how
            </span>
            
            <span id="chunk-340" class="transcript-chunks" onclick="console.log('00:22:38,916'); seek(1358.0)">
              a generation is made at one shot, that is,
            </span>
            
            <span id="chunk-341" class="transcript-chunks" onclick="console.log('00:22:42,644'); seek(1362.0)">
              given a set of prompt with few shot or zero shot examples.
            </span>
            
            <span id="chunk-342" class="transcript-chunks" onclick="console.log('00:22:47,198'); seek(1367.0)">
              The model generates in one shot the reasoning
            </span>
            
            <span id="chunk-343" class="transcript-chunks" onclick="console.log('00:22:51,774'); seek(1371.0)">
              as well as the answer for the given problem.
            </span>
            
            <span id="chunk-344" class="transcript-chunks" onclick="console.log('00:22:55,690'); seek(1375.0)">
              But as a human like how,
            </span>
            
            <span id="chunk-345" class="transcript-chunks" onclick="console.log('00:22:59,052'); seek(1379.0)">
              if we had, if we approach a problem iteratively,
            </span>
            
            <span id="chunk-346" class="transcript-chunks" onclick="console.log('00:23:02,754'); seek(1382.0)">
              we have a better chance to solve the problem more
            </span>
            
            <span id="chunk-347" class="transcript-chunks" onclick="console.log('00:23:06,284'); seek(1386.0)">
              accurately. So, similar intuition has been tried
            </span>
            
            <span id="chunk-348" class="transcript-chunks" onclick="console.log('00:23:09,916'); seek(1389.0)">
              with these llms. So we will be seeing those
            </span>
            
            <span id="chunk-349" class="transcript-chunks" onclick="console.log('00:23:14,350'); seek(1394.0)">
              methodologies in the papers in this section.
            </span>
            
            <span id="chunk-350" class="transcript-chunks" onclick="console.log('00:23:17,430'); seek(1397.0)">
              So one paper that implements is least
            </span>
            
            <span id="chunk-351" class="transcript-chunks" onclick="console.log('00:23:20,916'); seek(1400.0)">
              to most prompting. So the
            </span>
            
            <span id="chunk-352" class="transcript-chunks" onclick="console.log('00:23:24,916'); seek(1404.0)">
              idea of this paper is that they have broken down the
            </span>
            
            <span id="chunk-353" class="transcript-chunks" onclick="console.log('00:23:28,948'); seek(1408.0)">
              approach into two stages. The first stage they
            </span>
            
            <span id="chunk-354" class="transcript-chunks" onclick="console.log('00:23:33,784'); seek(1413.0)">
              prompt these model to come up with sub questions. So given
            </span>
            
            <span id="chunk-355" class="transcript-chunks" onclick="console.log('00:23:37,640'); seek(1417.0)">
              a broader question, they prompt the model to come up with
            </span>
            
            <span id="chunk-356" class="transcript-chunks" onclick="console.log('00:23:41,528'); seek(1421.0)">
              sub questions. And in the stage two
            </span>
            
            <span id="chunk-357" class="transcript-chunks" onclick="console.log('00:23:45,160'); seek(1425.0)">
              they sequentially ask the model to solve the questions one
            </span>
            
            <span id="chunk-358" class="transcript-chunks" onclick="console.log('00:23:49,228'); seek(1429.0)">
              by one. So for example, for the question given here,
            </span>
            
            <span id="chunk-359" class="transcript-chunks" onclick="console.log('00:23:53,244'); seek(1433.0)">
              the first stage, the model will come up with sub questions,
            </span>
            
            <span id="chunk-360" class="transcript-chunks" onclick="console.log('00:23:57,004'); seek(1437.0)">
              and in the second stage the original question is appended with the
            </span>
            
            <span id="chunk-361" class="transcript-chunks" onclick="console.log('00:24:00,992'); seek(1440.0)">
              sub question and the model has to answer that sub
            </span>
            
            <span id="chunk-362" class="transcript-chunks" onclick="console.log('00:24:04,672'); seek(1444.0)">
              question. And then the second sub question will be appended to
            </span>
            
            <span id="chunk-363" class="transcript-chunks" onclick="console.log('00:24:08,432'); seek(1448.0)">
              the first one and the overall one. And then the model has to
            </span>
            
            <span id="chunk-364" class="transcript-chunks" onclick="console.log('00:24:12,388'); seek(1452.0)">
              answer that and then until it comes up with the final answer.
            </span>
            
            <span id="chunk-365" class="transcript-chunks" onclick="console.log('00:24:16,308'); seek(1456.0)">
              So this way the author has shown that the model does
            </span>
            
            <span id="chunk-366" class="transcript-chunks" onclick="console.log('00:24:20,244'); seek(1460.0)">
              better compared to the vanilla
            </span>
            
            <span id="chunk-367" class="transcript-chunks" onclick="console.log('00:24:24,078'); seek(1464.0)">
              chain of thought prompting that we saw before. So this
            </span>
            
            <span id="chunk-368" class="transcript-chunks" onclick="console.log('00:24:28,008'); seek(1468.0)">
              is an example prompts that's been implemented
            </span>
            
            <span id="chunk-369" class="transcript-chunks" onclick="console.log('00:24:32,958'); seek(1472.0)">
              as part of this paper here. These have for the decomposition
            </span>
            
            <span id="chunk-370" class="transcript-chunks" onclick="console.log('00:24:37,378'); seek(1477.0)">
              stage where they ask the model to decompose the question into
            </span>
            
            <span id="chunk-371" class="transcript-chunks" onclick="console.log('00:24:41,260'); seek(1481.0)">
              different questions.
            </span>
            
            <span id="chunk-372" class="transcript-chunks" onclick="console.log('00:24:44,572'); seek(1484.0)">
              These were these few short examples that was given. And then
            </span>
            
            <span id="chunk-373" class="transcript-chunks" onclick="console.log('00:24:48,124'); seek(1488.0)">
              for the new set of example following this few shot,
            </span>
            
            <span id="chunk-374" class="transcript-chunks" onclick="console.log('00:24:51,398'); seek(1491.0)">
              the model has to come up with sub questions.
            </span>
            
            <span id="chunk-375" class="transcript-chunks" onclick="console.log('00:24:57,150'); seek(1497.0)">
              And the second part,
            </span>
            
            <span id="chunk-376" class="transcript-chunks" onclick="console.log('00:25:00,176'); seek(1500.0)">
              second stage where for problem solving, these are all the
            </span>
            
            <span id="chunk-377" class="transcript-chunks" onclick="console.log('00:25:03,748'); seek(1503.0)">
              few short examples that were given for the model to
            </span>
            
            <span id="chunk-378" class="transcript-chunks" onclick="console.log('00:25:07,844'); seek(1507.0)">
              solve the sub problem.
            </span>
            
            <span id="chunk-379" class="transcript-chunks" onclick="console.log('00:25:11,970'); seek(1511.0)">
              So another paper that implemented the recursive or
            </span>
            
            <span id="chunk-380" class="transcript-chunks" onclick="console.log('00:25:15,992'); seek(1515.0)">
              iterative prompting is
            </span>
            
            <span id="chunk-381" class="transcript-chunks" onclick="console.log('00:25:20,296'); seek(1520.0)">
              plan, eliminate and track. So they have done this in an interesting setting
            </span>
            
            <span id="chunk-382" class="transcript-chunks" onclick="console.log('00:25:24,590'); seek(1524.0)">
              where they have tried to evaluate and embodied the agent on
            </span>
            
            <span id="chunk-383" class="transcript-chunks" onclick="console.log('00:25:28,172'); seek(1528.0)">
              a data set called as half world
            </span>
            
            <span id="chunk-384" class="transcript-chunks" onclick="console.log('00:25:31,836'); seek(1531.0)">
              data set, which is about evaluating
            </span>
            
            <span id="chunk-385" class="transcript-chunks" onclick="console.log('00:25:35,826'); seek(1535.0)">
              the abilities of the agent to follow a given task
            </span>
            
            <span id="chunk-386" class="transcript-chunks" onclick="console.log('00:25:39,318'); seek(1539.0)">
              given the text word environment and a visual equivalent of
            </span>
            
            <span id="chunk-387" class="transcript-chunks" onclick="console.log('00:25:43,152'); seek(1543.0)">
              it. So they have
            </span>
            
            <span id="chunk-388" class="transcript-chunks" onclick="console.log('00:25:49,470'); seek(1549.0)">
              broken down their approach into different modules. One is a
            </span>
            
            <span id="chunk-389" class="transcript-chunks" onclick="console.log('00:25:52,708'); seek(1552.0)">
              planner module which is also can LLM. So it takes in the
            </span>
            
            <span id="chunk-390" class="transcript-chunks" onclick="console.log('00:25:56,308'); seek(1556.0)">
              instruction, it tries to convert that into a plan
            </span>
            
            <span id="chunk-391" class="transcript-chunks" onclick="console.log('00:26:00,212'); seek(1560.0)">
              that the agent needs to follow. And then there is an eliminator.
            </span>
            
            <span id="chunk-392" class="transcript-chunks" onclick="console.log('00:26:04,030'); seek(1564.0)">
              So eliminator based on the visual input and
            </span>
            
            <span id="chunk-393" class="transcript-chunks" onclick="console.log('00:26:07,272'); seek(1567.0)">
              also on the visual input of what is
            </span>
            
            <span id="chunk-394" class="transcript-chunks" onclick="console.log('00:26:10,552'); seek(1570.0)">
              there in the environment. The eliminator
            </span>
            
            <span id="chunk-395" class="transcript-chunks" onclick="console.log('00:26:14,526'); seek(1574.0)">
              tries to eliminate whatever that
            </span>
            
            <span id="chunk-396" class="transcript-chunks" onclick="console.log('00:26:17,884'); seek(1577.0)">
              the agent sees and what it needs to focus
            </span>
            
            <span id="chunk-397" class="transcript-chunks" onclick="console.log('00:26:21,084'); seek(1581.0)">
              on. And these the actor does the action and the tracker
            </span>
            
            <span id="chunk-398" class="transcript-chunks" onclick="console.log('00:26:25,186'); seek(1585.0)">
              tracks whether a given task is finished or not. Once it's finished,
            </span>
            
            <span id="chunk-399" class="transcript-chunks" onclick="console.log('00:26:28,998'); seek(1588.0)">
              it is updating the progress. So this overall approach is
            </span>
            
            <span id="chunk-400" class="transcript-chunks" onclick="console.log('00:26:33,870'); seek(1593.0)">
              in a way it's similar to what has been followed in auto
            </span>
            
            <span id="chunk-401" class="transcript-chunks" onclick="console.log('00:26:37,414'); seek(1597.0)">
              GPT and Baby Aga and all those applications.
            </span>
            
            <span id="chunk-402" class="transcript-chunks" onclick="console.log('00:26:42,430'); seek(1602.0)">
              So if you see here first for the task, heat some apple and
            </span>
            
            <span id="chunk-403" class="transcript-chunks" onclick="console.log('00:26:45,892'); seek(1605.0)">
              put it in the fridge. The LLMs first comes up with a plan. Take an
            </span>
            
            <span id="chunk-404" class="transcript-chunks" onclick="console.log('00:26:49,588'); seek(1609.0)">
              apple, heat the apple, place the apple in fridge,
            </span>
            
            <span id="chunk-405" class="transcript-chunks" onclick="console.log('00:26:54,050'); seek(1614.0)">
              and then an eliminator eliminates what
            </span>
            
            <span id="chunk-406" class="transcript-chunks" onclick="console.log('00:26:58,788'); seek(1618.0)">
              are the things that are not important for this particular
            </span>
            
            <span id="chunk-407" class="transcript-chunks" onclick="console.log('00:27:02,660'); seek(1622.0)">
              task to be completed. And an actor picks up
            </span>
            
            <span id="chunk-408" class="transcript-chunks" onclick="console.log('00:27:05,948'); seek(1625.0)">
              the, excuse me,
            </span>
            
            <span id="chunk-409" class="transcript-chunks" onclick="console.log('00:27:09,308'); seek(1629.0)">
              the actor picks up the action
            </span>
            
            <span id="chunk-410" class="transcript-chunks" onclick="console.log('00:27:13,858'); seek(1633.0)">
              that is more suitable for that particular task.
            </span>
            
            <span id="chunk-411" class="transcript-chunks" onclick="console.log('00:27:17,074'); seek(1637.0)">
              And then a tracker tracks the progress of it.
            </span>
            
            <span id="chunk-412" class="transcript-chunks" onclick="console.log('00:27:24,290'); seek(1644.0)">
              Another interesting paper that does this
            </span>
            
            <span id="chunk-413" class="transcript-chunks" onclick="console.log('00:27:28,388'); seek(1648.0)">
              iterative prompting is describe, explain,
            </span>
            
            <span id="chunk-414" class="transcript-chunks" onclick="console.log('00:27:32,248'); seek(1652.0)">
              plan and select. So in this paper, the authors
            </span>
            
            <span id="chunk-415" class="transcript-chunks" onclick="console.log('00:27:36,190'); seek(1656.0)">
              have tried to use an LLM to solve or
            </span>
            
            <span id="chunk-416" class="transcript-chunks" onclick="console.log('00:27:40,424'); seek(1660.0)">
              to play Minecraft. So minecraft,
            </span>
            
            <span id="chunk-417" class="transcript-chunks" onclick="console.log('00:27:43,822'); seek(1663.0)">
              as you'd know, it's an open ended game. So they have used llms
            </span>
            
            <span id="chunk-418" class="transcript-chunks" onclick="console.log('00:27:47,986'); seek(1667.0)">
              to play the minecraft. So here again,
            </span>
            
            <span id="chunk-419" class="transcript-chunks" onclick="console.log('00:27:52,492'); seek(1672.0)">
              similar to what we saw before,
            </span>
            
            <span id="chunk-420" class="transcript-chunks" onclick="console.log('00:27:55,610'); seek(1675.0)">
              they have split the approach
            </span>
            
            <span id="chunk-421" class="transcript-chunks" onclick="console.log('00:27:58,902'); seek(1678.0)">
              into different modules. One is planner module,
            </span>
            
            <span id="chunk-422" class="transcript-chunks" onclick="console.log('00:28:02,662'); seek(1682.0)">
              selector module and explainer module, and then a
            </span>
            
            <span id="chunk-423" class="transcript-chunks" onclick="console.log('00:28:06,592'); seek(1686.0)">
              describer module. So the first, for example
            </span>
            
            <span id="chunk-424" class="transcript-chunks" onclick="console.log('00:28:11,072'); seek(1691.0)">
              for these task how to mine one diamond from scratch.
            </span>
            
            <span id="chunk-425" class="transcript-chunks" onclick="console.log('00:28:15,170'); seek(1695.0)">
              The planner module comes up with a set of plans of what are
            </span>
            
            <span id="chunk-426" class="transcript-chunks" onclick="console.log('00:28:18,788'); seek(1698.0)">
              the tasks that needs to be done by the agent.
            </span>
            
            <span id="chunk-427" class="transcript-chunks" onclick="console.log('00:28:22,804'); seek(1702.0)">
              So here from the different set of ushot
            </span>
            
            <span id="chunk-428" class="transcript-chunks" onclick="console.log('00:28:26,158'); seek(1706.0)">
              examples in the ground truth plan, the planner would
            </span>
            
            <span id="chunk-429" class="transcript-chunks" onclick="console.log('00:28:29,512'); seek(1709.0)">
              come up with an actual plan that needs to be executed.
            </span>
            
            <span id="chunk-430" class="transcript-chunks" onclick="console.log('00:28:32,942'); seek(1712.0)">
              And then the selector, based on its knowledge of the
            </span>
            
            <span id="chunk-431" class="transcript-chunks" onclick="console.log('00:28:36,732'); seek(1716.0)">
              environment, it selects in that given step what
            </span>
            
            <span id="chunk-432" class="transcript-chunks" onclick="console.log('00:28:40,588'); seek(1720.0)">
              a goal that needs to be achieved. First based
            </span>
            
            <span id="chunk-433" class="transcript-chunks" onclick="console.log('00:28:43,836'); seek(1723.0)">
              on prioritizing
            </span>
            
            <span id="chunk-434" class="transcript-chunks" onclick="console.log('00:28:48,270'); seek(1728.0)">
              the different tasks involved.
            </span>
            
            <span id="chunk-435" class="transcript-chunks" onclick="console.log('00:28:52,270'); seek(1732.0)">
              And then that particular task is executed by
            </span>
            
            <span id="chunk-436" class="transcript-chunks" onclick="console.log('00:28:55,968'); seek(1735.0)">
              an executor. And that result of the executor is
            </span>
            
            <span id="chunk-437" class="transcript-chunks" onclick="console.log('00:28:59,552'); seek(1739.0)">
              given as a description by the descriptor. So it says,
            </span>
            
            <span id="chunk-438" class="transcript-chunks" onclick="console.log('00:29:02,676'); seek(1742.0)">
              if it finishes a goal, it says I finished goal g zero,
            </span>
            
            <span id="chunk-439" class="transcript-chunks" onclick="console.log('00:29:06,420'); seek(1746.0)">
              and then the selector goes to the next
            </span>
            
            <span id="chunk-440" class="transcript-chunks" onclick="console.log('00:29:10,500'); seek(1750.0)">
              task or next goal and so on. So this
            </span>
            
            <span id="chunk-441" class="transcript-chunks" onclick="console.log('00:29:13,688'); seek(1753.0)">
              is done recursively,
            </span>
            
            <span id="chunk-442" class="transcript-chunks" onclick="console.log('00:29:17,670'); seek(1757.0)">
              this is done by an LLM, it is prone to failures.
            </span>
            
            <span id="chunk-443" class="transcript-chunks" onclick="console.log('00:29:20,798'); seek(1760.0)">
              So when a particular plan has failed,
            </span>
            
            <span id="chunk-444" class="transcript-chunks" onclick="console.log('00:29:23,870'); seek(1763.0)">
              so these descriptor says I fail on this particular goal.
            </span>
            
            <span id="chunk-445" class="transcript-chunks" onclick="console.log('00:29:27,890'); seek(1767.0)">
              And then it also gives the details of the environment.
            </span>
            
            <span id="chunk-446" class="transcript-chunks" onclick="console.log('00:29:31,474'); seek(1771.0)">
              So based on that, an explainer explains what could
            </span>
            
            <span id="chunk-447" class="transcript-chunks" onclick="console.log('00:29:35,292'); seek(1775.0)">
              have actually gone wrong and it explains what needs to be done.
            </span>
            
            <span id="chunk-448" class="transcript-chunks" onclick="console.log('00:29:39,630'); seek(1779.0)">
              And then that goes to the planner. So planner then does
            </span>
            
            <span id="chunk-449" class="transcript-chunks" onclick="console.log('00:29:43,472'); seek(1783.0)">
              the replanning again. Replanning again.
            </span>
            
            <span id="chunk-450" class="transcript-chunks" onclick="console.log('00:29:47,168'); seek(1787.0)">
              And then this process continues until the final objective is
            </span>
            
            <span id="chunk-451" class="transcript-chunks" onclick="console.log('00:29:51,076'); seek(1791.0)">
              met. So this is again a very interesting
            </span>
            
            <span id="chunk-452" class="transcript-chunks" onclick="console.log('00:29:54,468'); seek(1794.0)">
              paper. I would urge the audience
            </span>
            
            <span id="chunk-453" class="transcript-chunks" onclick="console.log('00:29:58,826'); seek(1798.0)">
              to go to the GitHub repo and go through there. They have done a
            </span>
            
            <span id="chunk-454" class="transcript-chunks" onclick="console.log('00:30:02,808'); seek(1802.0)">
              wonderful implementation of their approach.
            </span>
            
            <span id="chunk-455" class="transcript-chunks" onclick="console.log('00:30:10,150'); seek(1810.0)">
              So until now we have seen how recursive
            </span>
            
            <span id="chunk-456" class="transcript-chunks" onclick="console.log('00:30:14,238'); seek(1814.0)">
              and iterative prompting can be used to elicit
            </span>
            
            <span id="chunk-457" class="transcript-chunks" onclick="console.log('00:30:18,322'); seek(1818.0)">
              reason. So now the
            </span>
            
            <span id="chunk-458" class="transcript-chunks" onclick="console.log('00:30:22,268'); seek(1822.0)">
              recent advancements have been enabled these LLMs
            </span>
            
            <span id="chunk-459" class="transcript-chunks" onclick="console.log('00:30:26,722'); seek(1826.0)">
              to use tools. So that comes in handy to
            </span>
            
            <span id="chunk-460" class="transcript-chunks" onclick="console.log('00:30:30,720'); seek(1830.0)">
              make the model even more accurate when it comes to reasoning
            </span>
            
            <span id="chunk-461" class="transcript-chunks" onclick="console.log('00:30:34,822'); seek(1834.0)">
              and planning. So you'll see a few examples of
            </span>
            
            <span id="chunk-462" class="transcript-chunks" onclick="console.log('00:30:38,256'); seek(1838.0)">
              how the tool usage is implemented
            </span>
            
            <span id="chunk-463" class="transcript-chunks" onclick="console.log('00:30:41,482'); seek(1841.0)">
              in some of the literature work.
            </span>
            
            <span id="chunk-464" class="transcript-chunks" onclick="console.log('00:30:45,090'); seek(1845.0)">
              So here the paper is react, reason and hacked.
            </span>
            
            <span id="chunk-465" class="transcript-chunks" onclick="console.log('00:30:48,922'); seek(1848.0)">
              So in these paper, the authors,
            </span>
            
            <span id="chunk-466" class="transcript-chunks" onclick="console.log('00:30:52,462'); seek(1852.0)">
              Yoert hall had broken down a
            </span>
            
            <span id="chunk-467" class="transcript-chunks" onclick="console.log('00:30:58,136'); seek(1858.0)">
              reasoning question to
            </span>
            
            <span id="chunk-468" class="transcript-chunks" onclick="console.log('00:31:03,752'); seek(1863.0)">
              use a tool like searching Wikipedia or
            </span>
            
            <span id="chunk-469" class="transcript-chunks" onclick="console.log('00:31:07,932'); seek(1867.0)">
              looking up Wikipedia, and then do and
            </span>
            
            <span id="chunk-470" class="transcript-chunks" onclick="console.log('00:31:11,756'); seek(1871.0)">
              come up with an answer based on that. So if you see here
            </span>
            
            <span id="chunk-471" class="transcript-chunks" onclick="console.log('00:31:15,500'); seek(1875.0)">
              for this reasoning question, when the model
            </span>
            
            <span id="chunk-472" class="transcript-chunks" onclick="console.log('00:31:18,816'); seek(1878.0)">
              tries to come up with a direct answer, it gets it
            </span>
            
            <span id="chunk-473" class="transcript-chunks" onclick="console.log('00:31:22,208'); seek(1882.0)">
              wrong. Even with cot, this is getting it wrong because
            </span>
            
            <span id="chunk-474" class="transcript-chunks" onclick="console.log('00:31:26,336'); seek(1886.0)">
              for this particular question, aside from Apple remote,
            </span>
            
            <span id="chunk-475" class="transcript-chunks" onclick="console.log('00:31:30,042'); seek(1890.0)">
              what other devices can control the program Apple remote was
            </span>
            
            <span id="chunk-476" class="transcript-chunks" onclick="console.log('00:31:34,052'); seek(1894.0)">
              originally designed to interact with? It needs an external
            </span>
            
            <span id="chunk-477" class="transcript-chunks" onclick="console.log('00:31:38,202'); seek(1898.0)">
              information for the model to be relied on.
            </span>
            
            <span id="chunk-478" class="transcript-chunks" onclick="console.log('00:31:41,830'); seek(1901.0)">
              So both these approaches are failing there.
            </span>
            
            <span id="chunk-479" class="transcript-chunks" onclick="console.log('00:31:45,112'); seek(1905.0)">
              So in act approach, what they
            </span>
            
            <span id="chunk-480" class="transcript-chunks" onclick="console.log('00:31:49,192'); seek(1909.0)">
              do is they come up with different set
            </span>
            
            <span id="chunk-481" class="transcript-chunks" onclick="console.log('00:31:52,296'); seek(1912.0)">
              of, so they have two variations. One is act only approach.
            </span>
            
            <span id="chunk-482" class="transcript-chunks" onclick="console.log('00:31:56,610'); seek(1916.0)">
              So in act only approach they come up with different actions that needs to
            </span>
            
            <span id="chunk-483" class="transcript-chunks" onclick="console.log('00:32:00,588'); seek(1920.0)">
              be taken and then they come up with an answer.
            </span>
            
            <span id="chunk-484" class="transcript-chunks" onclick="console.log('00:32:05,404'); seek(1925.0)">
              Then we have react which is based on reason and act which
            </span>
            
            <span id="chunk-485" class="transcript-chunks" onclick="console.log('00:32:09,148'); seek(1929.0)">
              is the actual paper. So first they come up with a different thought
            </span>
            
            <span id="chunk-486" class="transcript-chunks" onclick="console.log('00:32:13,120'); seek(1933.0)">
              and what act needs to be done, action needs to be done. And what
            </span>
            
            <span id="chunk-487" class="transcript-chunks" onclick="console.log('00:32:16,912'); seek(1936.0)">
              is the observation that is done from this action.
            </span>
            
            <span id="chunk-488" class="transcript-chunks" onclick="console.log('00:32:20,742'); seek(1940.0)">
              So based on that, that gets passed on to the next thought and
            </span>
            
            <span id="chunk-489" class="transcript-chunks" onclick="console.log('00:32:24,484'); seek(1944.0)">
              that is used to do the second act, and then observation and so
            </span>
            
            <span id="chunk-490" class="transcript-chunks" onclick="console.log('00:32:28,308'); seek(1948.0)">
              on. Finally they come up with these can answer.
            </span>
            
            <span id="chunk-491" class="transcript-chunks" onclick="console.log('00:32:31,252'); seek(1951.0)">
              So this way they iteratively prompt it. First thought
            </span>
            
            <span id="chunk-492" class="transcript-chunks" onclick="console.log('00:32:35,016'); seek(1955.0)">
              one is done and these act one action is generated
            </span>
            
            <span id="chunk-493" class="transcript-chunks" onclick="console.log('00:32:39,230'); seek(1959.0)">
              based on that. Once we have this, once the model generates
            </span>
            
            <span id="chunk-494" class="transcript-chunks" onclick="console.log('00:32:42,830'); seek(1962.0)">
              search the apple remote, the keyword is used to
            </span>
            
            <span id="chunk-495" class="transcript-chunks" onclick="console.log('00:32:46,348'); seek(1966.0)">
              search the Wikipedia and then an observation is appended to
            </span>
            
            <span id="chunk-496" class="transcript-chunks" onclick="console.log('00:32:50,092'); seek(1970.0)">
              the generation. So based on that a thought
            </span>
            
            <span id="chunk-497" class="transcript-chunks" onclick="console.log('00:32:53,436'); seek(1973.0)">
              two is done until the model generates finish
            </span>
            
            <span id="chunk-498" class="transcript-chunks" onclick="console.log('00:32:57,488'); seek(1977.0)">
              as one of the actions. So this is react,
            </span>
            
            <span id="chunk-499" class="transcript-chunks" onclick="console.log('00:33:01,174'); seek(1981.0)">
              reason and act.
            </span>
            
            <span id="chunk-500" class="transcript-chunks" onclick="console.log('00:33:06,750'); seek(1986.0)">
              Another paper that uses tools is
            </span>
            
            <span id="chunk-501" class="transcript-chunks" onclick="console.log('00:33:10,288'); seek(1990.0)">
              camelion plug and play compositional reasoning with
            </span>
            
            <span id="chunk-502" class="transcript-chunks" onclick="console.log('00:33:13,732'); seek(1993.0)">
              large language models. So here the authors have used
            </span>
            
            <span id="chunk-503" class="transcript-chunks" onclick="console.log('00:33:18,132'); seek(1998.0)">
              tool based reasoning and compulsion
            </span>
            
            <span id="chunk-504" class="transcript-chunks" onclick="console.log('00:33:22,778'); seek(2002.0)">
              for answering science question
            </span>
            
            <span id="chunk-505" class="transcript-chunks" onclick="console.log('00:33:26,120'); seek(2006.0)">
              answers as well as to answer table
            </span>
            
            <span id="chunk-506" class="transcript-chunks" onclick="console.log('00:33:31,006'); seek(2011.0)">
              based word problems. So here
            </span>
            
            <span id="chunk-507" class="transcript-chunks" onclick="console.log('00:33:34,712'); seek(2014.0)">
              in this science based question answering or
            </span>
            
            <span id="chunk-508" class="transcript-chunks" onclick="console.log('00:33:38,764'); seek(2018.0)">
              common sense question answering, here the image is given
            </span>
            
            <span id="chunk-509" class="transcript-chunks" onclick="console.log('00:33:42,556'); seek(2022.0)">
              and the question is what is the direction of this push? And then an
            </span>
            
            <span id="chunk-510" class="transcript-chunks" onclick="console.log('00:33:46,476'); seek(2026.0)">
              image is given and there is a question related to this.
            </span>
            
            <span id="chunk-511" class="transcript-chunks" onclick="console.log('00:33:51,070'); seek(2031.0)">
              So the LLM first tries to come up
            </span>
            
            <span id="chunk-512" class="transcript-chunks" onclick="console.log('00:33:54,992'); seek(2034.0)">
              with or decomposes this problem into set of
            </span>
            
            <span id="chunk-513" class="transcript-chunks" onclick="console.log('00:33:59,472'); seek(2039.0)">
              tools that it needs to call. And then there is a separate
            </span>
            
            <span id="chunk-514" class="transcript-chunks" onclick="console.log('00:34:02,842'); seek(2042.0)">
              set of prompts that are available for each of these
            </span>
            
            <span id="chunk-515" class="transcript-chunks" onclick="console.log('00:34:06,212'); seek(2046.0)">
              tools, which gets executed sequentially
            </span>
            
            <span id="chunk-516" class="transcript-chunks" onclick="console.log('00:34:09,994'); seek(2049.0)">
              to invoke that particular tool
            </span>
            
            <span id="chunk-517" class="transcript-chunks" onclick="console.log('00:34:13,592'); seek(2053.0)">
              and get these answers that get appended to the
            </span>
            
            <span id="chunk-518" class="transcript-chunks" onclick="console.log('00:34:16,888'); seek(2056.0)">
              original prompt. And these the process continues to get the
            </span>
            
            <span id="chunk-519" class="transcript-chunks" onclick="console.log('00:34:20,408'); seek(2060.0)">
              final answer. For example, for this question where we have
            </span>
            
            <span id="chunk-520" class="transcript-chunks" onclick="console.log('00:34:25,050'); seek(2065.0)">
              image and then a set of options, which is the main persuasive apple
            </span>
            
            <span id="chunk-521" class="transcript-chunks" onclick="console.log('00:34:29,218'); seek(2069.0)">
              used in this ad. So this particular image
            </span>
            
            <span id="chunk-522" class="transcript-chunks" onclick="console.log('00:34:33,218'); seek(2073.0)">
              is of an ADC. Paper plates now carry
            </span>
            
            <span id="chunk-523" class="transcript-chunks" onclick="console.log('00:34:36,774'); seek(2076.0)">
              the Sierra Club seal of approval. So it's an
            </span>
            
            <span id="chunk-524" class="transcript-chunks" onclick="console.log('00:34:40,336'); seek(2080.0)">
              ad. And then we have different options
            </span>
            
            <span id="chunk-525" class="transcript-chunks" onclick="console.log('00:34:44,672'); seek(2084.0)">
              whether this ad conveys petals, ethos or
            </span>
            
            <span id="chunk-526" class="transcript-chunks" onclick="console.log('00:34:50,050'); seek(2090.0)">
              logos, and these has
            </span>
            
            <span id="chunk-527" class="transcript-chunks" onclick="console.log('00:34:53,732'); seek(2093.0)">
              different options. So what the Cameleon does is it
            </span>
            
            <span id="chunk-528" class="transcript-chunks" onclick="console.log('00:34:57,252'); seek(2097.0)">
              first tries to call the text deductor as a
            </span>
            
            <span id="chunk-529" class="transcript-chunks" onclick="console.log('00:35:01,028'); seek(2101.0)">
              tool, and the text deductor deducts the text
            </span>
            
            <span id="chunk-530" class="transcript-chunks" onclick="console.log('00:35:05,430'); seek(2105.0)">
              and then it calls the knowledge retrieval. So knowledge retrieval
            </span>
            
            <span id="chunk-531" class="transcript-chunks" onclick="console.log('00:35:10,310'); seek(2110.0)">
              based on the input that is there, the knowledge retrieval
            </span>
            
            <span id="chunk-532" class="transcript-chunks" onclick="console.log('00:35:13,358'); seek(2113.0)">
              tries to come up with its inference of
            </span>
            
            <span id="chunk-533" class="transcript-chunks" onclick="console.log('00:35:17,532'); seek(2117.0)">
              the overall perspective of question and the information
            </span>
            
            <span id="chunk-534" class="transcript-chunks" onclick="console.log('00:35:21,308'); seek(2121.0)">
              that is available at that point. This is from
            </span>
            
            <span id="chunk-535" class="transcript-chunks" onclick="console.log('00:35:26,140'); seek(2126.0)">
              call to an opena API. And then
            </span>
            
            <span id="chunk-536" class="transcript-chunks" onclick="console.log('00:35:29,360'); seek(2129.0)">
              there is a solution generator which creates a descriptive
            </span>
            
            <span id="chunk-537" class="transcript-chunks" onclick="console.log('00:35:33,302'); seek(2133.0)">
              solution of what needs to be done, and then the answer
            </span>
            
            <span id="chunk-538" class="transcript-chunks" onclick="console.log('00:35:36,560'); seek(2136.0)">
              generator, which could be a rule based approach to generate the answers
            </span>
            
            <span id="chunk-539" class="transcript-chunks" onclick="console.log('00:35:40,218'); seek(2140.0)">
              from the solution that was generated by the model.
            </span>
            
            <span id="chunk-540" class="transcript-chunks" onclick="console.log('00:35:43,972'); seek(2143.0)">
              So these way this paper uses different tools,
            </span>
            
            <span id="chunk-541" class="transcript-chunks" onclick="console.log('00:35:47,690'); seek(2147.0)">
              right from hugging face models,
            </span>
            
            <span id="chunk-542" class="transcript-chunks" onclick="console.log('00:35:51,090'); seek(2151.0)">
              and then open a GPT models iteratively,
            </span>
            
            <span id="chunk-543" class="transcript-chunks" onclick="console.log('00:35:55,086'); seek(2155.0)">
              and also the other models like text deductor to
            </span>
            
            <span id="chunk-544" class="transcript-chunks" onclick="console.log('00:35:58,488'); seek(2158.0)">
              come up with a final solution.
            </span>
            
            <span id="chunk-545" class="transcript-chunks" onclick="console.log('00:36:04,810'); seek(2164.0)">
              Another example is the tab math world
            </span>
            
            <span id="chunk-546" class="transcript-chunks" onclick="console.log('00:36:09,290'); seek(2169.0)">
              problem solving data set, wherein for a given tabular
            </span>
            
            <span id="chunk-547" class="transcript-chunks" onclick="console.log('00:36:13,850'); seek(2173.0)">
              example, for a question that was asked,
            </span>
            
            <span id="chunk-548" class="transcript-chunks" onclick="console.log('00:36:17,196'); seek(2177.0)">
              the model has to come up with set of answers. So here the
            </span>
            
            <span id="chunk-549" class="transcript-chunks" onclick="console.log('00:36:21,088'); seek(2181.0)">
              model again uses different tools like knowledge retriever to
            </span>
            
            <span id="chunk-550" class="transcript-chunks" onclick="console.log('00:36:24,768'); seek(2184.0)">
              retrieve the knowledge that it has related
            </span>
            
            <span id="chunk-551" class="transcript-chunks" onclick="console.log('00:36:28,806'); seek(2188.0)">
              to the question that was asked. And then it goes to the table
            </span>
            
            <span id="chunk-552" class="transcript-chunks" onclick="console.log('00:36:32,666'); seek(2192.0)">
              verbalizer to verbalize what is there in the table,
            </span>
            
            <span id="chunk-553" class="transcript-chunks" onclick="console.log('00:36:35,626'); seek(2195.0)">
              and then for all the calculation that is offloaded
            </span>
            
            <span id="chunk-554" class="transcript-chunks" onclick="console.log('00:36:38,698'); seek(2198.0)">
              to a Python program and interpreter. And then
            </span>
            
            <span id="chunk-555" class="transcript-chunks" onclick="console.log('00:36:42,552'); seek(2202.0)">
              we have a program verifier which verifies whether the program is correct,
            </span>
            
            <span id="chunk-556" class="transcript-chunks" onclick="console.log('00:36:46,888'); seek(2206.0)">
              and then the program is executed and the answer is generated
            </span>
            
            <span id="chunk-557" class="transcript-chunks" onclick="console.log('00:36:50,686'); seek(2210.0)">
              from it. So let's see how a prompt
            </span>
            
            <span id="chunk-558" class="transcript-chunks" onclick="console.log('00:36:54,562'); seek(2214.0)">
              looks like for this.
            </span>
            
            <span id="chunk-559" class="transcript-chunks" onclick="console.log('00:36:59,130'); seek(2219.0)">
              So here as we can see,
            </span>
            
            <span id="chunk-560" class="transcript-chunks" onclick="console.log('00:37:02,764'); seek(2222.0)">
              the instruction or the prompt has different
            </span>
            
            <span id="chunk-561" class="transcript-chunks" onclick="console.log('00:37:06,924'); seek(2226.0)">
              tools that the model can use and then it also has the
            </span>
            
            <span id="chunk-562" class="transcript-chunks" onclick="console.log('00:37:10,848'); seek(2230.0)">
              context of what is the question and what are all the options
            </span>
            
            <span id="chunk-563" class="transcript-chunks" onclick="console.log('00:37:14,496'); seek(2234.0)">
              that are there in these question and metadata of the image.
            </span>
            
            <span id="chunk-564" class="transcript-chunks" onclick="console.log('00:37:18,190'); seek(2238.0)">
              And the model has to generate the set of modules
            </span>
            
            <span id="chunk-565" class="transcript-chunks" onclick="console.log('00:37:21,818'); seek(2241.0)">
              that it has to call, set of steps that it has
            </span>
            
            <span id="chunk-566" class="transcript-chunks" onclick="console.log('00:37:25,652'); seek(2245.0)">
              to execute, whether it has to execute text reductor first,
            </span>
            
            <span id="chunk-567" class="transcript-chunks" onclick="console.log('00:37:29,060'); seek(2249.0)">
              knowledge retrieval solution generator and answer generator.
            </span>
            
            <span id="chunk-568" class="transcript-chunks" onclick="console.log('00:37:32,718'); seek(2252.0)">
              So this way these model comes up with steps
            </span>
            
            <span id="chunk-569" class="transcript-chunks" onclick="console.log('00:37:36,478'); seek(2256.0)">
              and then each of these separate tools are
            </span>
            
            <span id="chunk-570" class="transcript-chunks" onclick="console.log('00:37:40,392'); seek(2260.0)">
              prompted to get the output. And then finally all
            </span>
            
            <span id="chunk-571" class="transcript-chunks" onclick="console.log('00:37:44,088'); seek(2264.0)">
              these outputs from these individual tools are concatenated
            </span>
            
            <span id="chunk-572" class="transcript-chunks" onclick="console.log('00:37:47,938'); seek(2267.0)">
              into one sequentially to generate the final
            </span>
            
            <span id="chunk-573" class="transcript-chunks" onclick="console.log('00:37:51,180'); seek(2271.0)">
              answer. So yeah,
            </span>
            
            <span id="chunk-574" class="transcript-chunks" onclick="console.log('00:37:54,492'); seek(2274.0)">
              that's pretty much I had for today. So there is
            </span>
            
            <span id="chunk-575" class="transcript-chunks" onclick="console.log('00:37:58,032'); seek(2278.0)">
              a lot that has come out recently.
            </span>
            
            <span id="chunk-576" class="transcript-chunks" onclick="console.log('00:38:01,710'); seek(2281.0)">
              Probably I might not have had a
            </span>
            
            <span id="chunk-577" class="transcript-chunks" onclick="console.log('00:38:04,864'); seek(2284.0)">
              chance to include it here, like tool formers, hugging GPT and so
            </span>
            
            <span id="chunk-578" class="transcript-chunks" onclick="console.log('00:38:08,832'); seek(2288.0)">
              on, but I
            </span>
            
            <span id="chunk-579" class="transcript-chunks" onclick="console.log('00:38:14,244'); seek(2294.0)">
              would like to acknowledge the sources
            </span>
            
            <span id="chunk-580" class="transcript-chunks" onclick="console.log('00:38:17,946'); seek(2297.0)">
              for this presentation. One is augment language
            </span>
            
            <span id="chunk-581" class="transcript-chunks" onclick="console.log('00:38:21,402'); seek(2301.0)">
              models survey from Milan
            </span>
            
            <span id="chunk-582" class="transcript-chunks" onclick="console.log('00:38:25,562'); seek(2305.0)">
              et al. And towards reasoning language models survey from Huang
            </span>
            
            <span id="chunk-583" class="transcript-chunks" onclick="console.log('00:38:29,182'); seek(2309.0)">
              et al. And then these blog posts. I will also urge
            </span>
            
            <span id="chunk-584" class="transcript-chunks" onclick="console.log('00:38:32,910'); seek(2312.0)">
              the audience to go through these
            </span>
            
            <span id="chunk-585" class="transcript-chunks" onclick="console.log('00:38:36,776'); seek(2316.0)">
              papers and these blog posts if you'd
            </span>
            
            <span id="chunk-586" class="transcript-chunks" onclick="console.log('00:38:40,798'); seek(2320.0)">
              like to learn further on this topic. So thank
            </span>
            
            <span id="chunk-587" class="transcript-chunks" onclick="console.log('00:38:44,568'); seek(2324.0)">
              you very much for your attention and
            </span>
            
            <span id="chunk-588" class="transcript-chunks" onclick="console.log('00:38:48,830'); seek(2328.0)">
              looking forward to hearing your feedback on these session
            </span>
            
            <span id="chunk-589" class="transcript-chunks" onclick="console.log('00:38:52,726'); seek(2332.0)">
              and also to have discussions on this topic can
            </span>
            
            <span id="chunk-590" class="transcript-chunks" onclick="console.log('00:38:56,448'); seek(2336.0)">
              be discussed today. Thank you.
            </span>
            
            </div>
          </div>
          
          

          
          <div class="col-12 mb-5">
            <h3>
              Slides
            </h3>
            <iframe src="https://conf42.github.io/static/slides/Logesh%20Kumar%20Umapathi%20-%20Conf42%20Machine%20Learning%202023.pdf" width="100%" height="500px"></iframe>
            <a href="https://conf42.github.io/static/slides/Logesh%20Kumar%20Umapathi%20-%20Conf42%20Machine%20Learning%202023.pdf" class="btn btn-xs btn-info shadow lift" style="background-color: #198B91;" target="_blank">
              <i class="fe fe-paperclip me-2"></i>
              Download slides (PDF)
            </a>
          </div>
          

          <div class="col-12 mb-2 text-center">
            <div class="text-center mb-5">
              <a href="https://www.conf42.com/ml2023" class="btn btn-sm btn-danger shadow lift" style="background-color: #198B91;">
                <i class="fe fe-grid me-2"></i>
                See all 13 talks at this event!
              </a>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- PHOTO -->
    <section class="pt-8 pb-6">
      <div class="container">

        <div class="row align-items-center">
          <div class="col-12 col-md-6 col-lg-7">

            <div class="mb-8 mb-md-0">

              <!-- Image -->
              <img src="https://conf42.github.io/static/headshots/ml_logesh_kumar_umapathi.png" alt="..." class="screenshot img-fluid mw-md-110 float-end me-md-6 mb-6 mb-md-0">

            </div>

          </div>
          <div class="col-12 col-md-6 col-lg-5">

            <!-- List -->
            <div class="d-flex">

              <!-- Body -->
              <div class="ms-5">

                <!-- Author 1 -->
                <h2 class="me-2">
                  Logesh Kumar Umapathi
                </h2>
                <h3 class="me-2">
                  <span class="text-muted">
                    Lead ML Research Engineer @ Saama Technologies
                  </span>
                </h3>

                <p class="text-uppercase text-muted me-2 mb-3">
                  
                  <a href="https://www.linkedin.com/in/logeshkumaru/" target="_blank" class="mr-3">
                    <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="Logesh Kumar Umapathi's LinkedIn account" />
                  </a>
                  
                  
                  <a href="https://twitter.com/@logesh_umapathi" target="_blank">
                    <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="Logesh Kumar Umapathi's twitter account" />
                  </a>
                  
                </p>
                

                <br />

                <a
                  href="https://twitter.com/share?ref_src=twsrc%5Etfw"
                  class="twitter-share-button"

                  data-text="Check out this talk by @logesh_umapathi"
                  data-url="https://www.conf42.com/ml2023"
                  data-via="conf42com"
                  data-related=""
                  data-show-count="false"
                >
                  Tweet
                </a>
                <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

                <br />

                <script src="https://platform.linkedin.com/in.js" type="text/javascript">lang: en_US</script>
                <script type="IN/Share" data-url="https://www.conf42.com/ml2023"></script>
              </div>

            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>






    <!-- WELCOME -->
    <section class="pt-8 pt-md-11 pb-10 pb-md-15 bg-info" id="register">

      <!-- Shape -->
      <div class="shape shape-blur-3 text-white">
        <svg viewBox="0 0 1738 487" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1420.92s713.43 457.505 0 485.868C707.502 514.231 0 0 0 0z" fill="url(#paint0_linear)"/><defs><linearGradient id="paint0_linear" x1="0" y1="0" x2="1049.98" y2="912.68" gradientUnits="userSpaceOnUse"><stop stop-color="currentColor" stop-opacity=".075"/><stop offset="1" stop-color="currentColor" stop-opacity="0"/></linearGradient></defs></svg>      </div>

      <!-- Content -->
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Heading -->
            <h1 class="display-2 text-white">
              Join the community!
            </h1>

            <p class="lead text-white text-opacity-80 mb-6 mb-md-8">
              Learn for free, join the best tech learning community 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->

    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-light">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- PRICING -->
    <section class="mt-n8 mt-md-n15">
      <div class="container">
        <div class="row gx-4 justify-content-center">
          <div class="col-12 col-md-6">

            <!-- Card -->
            <div class="card shadow-lg mb-6 mb-md-1">
              <div class="card-body">

                <!-- Preheading -->
                <div class="text-center mb-3">
                  <span class="badge rounded-pill bg-primary-soft">
                    <span class="h6 text-uppercase">Newsletter</span>
                  </span>
                </div>

                <!-- Price -->
                <div class="d-flex justify-content-center">
                  <span class="h2 mb-0 mt-2">$</span>
                  <span class="price display-2 mb-0" data-annual="0" data-monthly="0">0</span>
                  <span class="h2 align-self-end mb-1">/mo</span>
                </div>

                <!-- Text -->
                <p class="text-center text-muted mb-5">
                </p>

              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    Event notifications, weekly newsletter
                  </p>
                </div>
              
                <div class="d-flex">
                  <div class="badge badge-rounded-circle bg-success-soft mt-1 me-4">
                    <i class="fe fe-check"></i>
                  </div>
                  <p>
                    <b>Access to all content</b>
                  </p>
                </div>
              
              
              </div>
            </div>

            <!-- Card -->
            <div class="card shadow-lg mb-6 border border-success">
              <div class="card-body">

                <script>
    function gtag_report_conversion(url) {
      var callback = function () {
        if (typeof(url) != 'undefined') {
          window.location = url;
        }
      };
      gtag('event', 'conversion', {
          'send_to': 'AW-882275635/jLVTCPbt1N8CELPq2aQD',
          'event_callback': callback
      });
      return false;
    }
</script>

<!-- Form -->
<link rel="stylesheet" href="https://emailoctopus.com/bundles/emailoctopuslist/css/1.6/form.css">
<p class="emailoctopus-success-message text-success"></p>
<p class="emailoctopus-error-message text-danger"></p>
<form
    action="https://emailoctopus.com/lists/a3ba0cb5-7524-11eb-a3d0-06b4694bee2a/members/embedded/1.3/add"
    method="post"
    data-message-success="Thanks! Check your email for further directions!"
    data-message-missing-email-address="Your email address is required."
    data-message-invalid-email-address="Your email address looks incorrect, please try again."
    data-message-bot-submission-error="This doesn't look like a human submission."
    data-message-consent-required="Please check the checkbox to indicate your consent."
    data-message-invalid-parameters-error="This form has missing or invalid fields."
    data-message-unknown-error="Sorry, an unknown error has occurred. Please try again later."
    class="emailoctopus-form"
    data-sitekey="6LdYsmsUAAAAAPXVTt-ovRsPIJ_IVhvYBBhGvRV6"
>
<div class="form-floating emailoctopus-form-row">
    <input type="email" class="form-control form-control-flush" name="field_0" id="field_0" placeholder="Email" required>
    <label for="field_0">Email address</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_1" id="field_1" placeholder="First Name" required>
    <label for="field_1">First Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_2" id="field_2" placeholder="Last Name" required>
    <label for="field_2">Last Name</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_4" id="field_4" placeholder="Company" required>
    <label for="field_4">Company</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_5" id="field_5" placeholder="Job Title" required>
    <label for="field_5">Job Title</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <input type="text" class="form-control form-control-flush" name="field_3" id="field_3" placeholder="Phone">
    <label for="field_3">Phone Number</label>
</div>
<div class="form-floating emailoctopus-form-row">
    <select type="text" class="form-control form-control-flush" name="field_7" id="country-source" required
    oninput="updateCountry()"
    >
    <!-- Country names and Country Name -->
    <option value="">Please select your country</option>
    <option value="Afghanistan">Afghanistan</option>
    <option value="Aland Islands">Aland Islands</option>
    <option value="Albania">Albania</option>
    <option value="Algeria">Algeria</option>
    <option value="American Samoa">American Samoa</option>
    <option value="Andorra">Andorra</option>
    <option value="Angola">Angola</option>
    <option value="Anguilla">Anguilla</option>
    <option value="Antarctica">Antarctica</option>
    <option value="Antigua and Barbuda">Antigua and Barbuda</option>
    <option value="Argentina">Argentina</option>
    <option value="Armenia">Armenia</option>
    <option value="Aruba">Aruba</option>
    <option value="Australia">Australia</option>
    <option value="Austria">Austria</option>
    <option value="Azerbaijan">Azerbaijan</option>
    <option value="Bahamas">Bahamas</option>
    <option value="Bahrain">Bahrain</option>
    <option value="Bangladesh">Bangladesh</option>
    <option value="Barbados">Barbados</option>
    <option value="Belarus">Belarus</option>
    <option value="Belgium">Belgium</option>
    <option value="Belize">Belize</option>
    <option value="Benin">Benin</option>
    <option value="Bermuda">Bermuda</option>
    <option value="Bhutan">Bhutan</option>
    <option value="Bolivia">Bolivia</option>
    <option value="Bonaire, Sint Eustatius and Saba">Bonaire, Sint Eustatius and Saba</option>
    <option value="Bosnia and Herzegovina">Bosnia and Herzegovina</option>
    <option value="Botswana">Botswana</option>
    <option value="Bouvet Island">Bouvet Island</option>
    <option value="Brazil">Brazil</option>
    <option value="British Indian Ocean Territory">British Indian Ocean Territory</option>
    <option value="Brunei Darussalam">Brunei Darussalam</option>
    <option value="Bulgaria">Bulgaria</option>
    <option value="Burkina Faso">Burkina Faso</option>
    <option value="Burundi">Burundi</option>
    <option value="Cambodia">Cambodia</option>
    <option value="Cameroon">Cameroon</option>
    <option value="Canada">Canada</option>
    <option value="Cape Verde">Cape Verde</option>
    <option value="Cayman Islands">Cayman Islands</option>
    <option value="Central African Republic">Central African Republic</option>
    <option value="Chad">Chad</option>
    <option value="Chile">Chile</option>
    <option value="China">China</option>
    <option value="Christmas Island">Christmas Island</option>
    <option value="Cocos (Keeling) Islands">Cocos (Keeling) Islands</option>
    <option value="Colombia">Colombia</option>
    <option value="Comoros">Comoros</option>
    <option value="Congo">Congo</option>
    <option value="Congo, Democratic Republic of the Congo">Congo, Democratic Republic of the Congo</option>
    <option value="Cook Islands">Cook Islands</option>
    <option value="Costa Rica">Costa Rica</option>
    <option value="Cote D'Ivoire">Cote D'Ivoire</option>
    <option value="Croatia">Croatia</option>
    <option value="Cuba">Cuba</option>
    <option value="Curacao">Curacao</option>
    <option value="Cyprus">Cyprus</option>
    <option value="Czech Republic">Czech Republic</option>
    <option value="Denmark">Denmark</option>
    <option value="Djibouti">Djibouti</option>
    <option value="Dominica">Dominica</option>
    <option value="Dominican Republic">Dominican Republic</option>
    <option value="Ecuador">Ecuador</option>
    <option value="Egypt">Egypt</option>
    <option value="El Salvador">El Salvador</option>
    <option value="Equatorial Guinea">Equatorial Guinea</option>
    <option value="Eritrea">Eritrea</option>
    <option value="Estonia">Estonia</option>
    <option value="Ethiopia">Ethiopia</option>
    <option value="Falkland Islands (Malvinas)">Falkland Islands (Malvinas)</option>
    <option value="Faroe Islands">Faroe Islands</option>
    <option value="Fiji">Fiji</option>
    <option value="Finland">Finland</option>
    <option value="France">France</option>
    <option value="French Guiana">French Guiana</option>
    <option value="French Polynesia">French Polynesia</option>
    <option value="French Southern Territories">French Southern Territories</option>
    <option value="Gabon">Gabon</option>
    <option value="Gambia">Gambia</option>
    <option value="Georgia">Georgia</option>
    <option value="Germany">Germany</option>
    <option value="Ghana">Ghana</option>
    <option value="Gibraltar">Gibraltar</option>
    <option value="Greece">Greece</option>
    <option value="Greenland">Greenland</option>
    <option value="Grenada">Grenada</option>
    <option value="Guadeloupe">Guadeloupe</option>
    <option value="Guam">Guam</option>
    <option value="Guatemala">Guatemala</option>
    <option value="Guernsey">Guernsey</option>
    <option value="Guinea">Guinea</option>
    <option value="Guinea-Bissau">Guinea-Bissau</option>
    <option value="Guyana">Guyana</option>
    <option value="Haiti">Haiti</option>
    <option value="Heard Island and Mcdonald Islands">Heard Island and Mcdonald Islands</option>
    <option value="Holy See (Vatican City State)">Holy See (Vatican City State)</option>
    <option value="Honduras">Honduras</option>
    <option value="Hong Kong">Hong Kong</option>
    <option value="Hungary">Hungary</option>
    <option value="Iceland">Iceland</option>
    <option value="India">India</option>
    <option value="Indonesia">Indonesia</option>
    <option value="Iran, Islamic Republic of">Iran, Islamic Republic of</option>
    <option value="Iraq">Iraq</option>
    <option value="Ireland">Ireland</option>
    <option value="Isle of Man">Isle of Man</option>
    <option value="Israel">Israel</option>
    <option value="Italy">Italy</option>
    <option value="Jamaica">Jamaica</option>
    <option value="Japan">Japan</option>
    <option value="Jersey">Jersey</option>
    <option value="Jordan">Jordan</option>
    <option value="Kazakhstan">Kazakhstan</option>
    <option value="Kenya">Kenya</option>
    <option value="Kiribati">Kiribati</option>
    <option value="Korea, Democratic People's Republic of">Korea, Democratic People's Republic of</option>
    <option value="Korea, Republic of">Korea, Republic of</option>
    <option value="Kosovo">Kosovo</option>
    <option value="Kuwait">Kuwait</option>
    <option value="Kyrgyzstan">Kyrgyzstan</option>
    <option value="Lao People's Democratic Republic">Lao People's Democratic Republic</option>
    <option value="Latvia">Latvia</option>
    <option value="Lebanon">Lebanon</option>
    <option value="Lesotho">Lesotho</option>
    <option value="Liberia">Liberia</option>
    <option value="Libyan Arab Jamahiriya">Libyan Arab Jamahiriya</option>
    <option value="Liechtenstein">Liechtenstein</option>
    <option value="Lithuania">Lithuania</option>
    <option value="Luxembourg">Luxembourg</option>
    <option value="Macao">Macao</option>
    <option value="Macedonia, the Former Yugoslav Republic of">Macedonia, the Former Yugoslav Republic of</option>
    <option value="Madagascar">Madagascar</option>
    <option value="Malawi">Malawi</option>
    <option value="Malaysia">Malaysia</option>
    <option value="Maldives">Maldives</option>
    <option value="Mali">Mali</option>
    <option value="Malta">Malta</option>
    <option value="Marshall Islands">Marshall Islands</option>
    <option value="Martinique">Martinique</option>
    <option value="Mauritania">Mauritania</option>
    <option value="Mauritius">Mauritius</option>
    <option value="Mayotte">Mayotte</option>
    <option value="Mexico">Mexico</option>
    <option value="Micronesia, Federated States of">Micronesia, Federated States of</option>
    <option value="Moldova, Republic of">Moldova, Republic of</option>
    <option value="Monaco">Monaco</option>
    <option value="Mongolia">Mongolia</option>
    <option value="Montenegro">Montenegro</option>
    <option value="Montserrat">Montserrat</option>
    <option value="Morocco">Morocco</option>
    <option value="Mozambique">Mozambique</option>
    <option value="Myanmar">Myanmar</option>
    <option value="Namibia">Namibia</option>
    <option value="Nauru">Nauru</option>
    <option value="Nepal">Nepal</option>
    <option value="Netherlands">Netherlands</option>
    <option value="Netherlands Antilles">Netherlands Antilles</option>
    <option value="New Caledonia">New Caledonia</option>
    <option value="New Zealand">New Zealand</option>
    <option value="Nicaragua">Nicaragua</option>
    <option value="Niger">Niger</option>
    <option value="Nigeria">Nigeria</option>
    <option value="Niue">Niue</option>
    <option value="Norfolk Island">Norfolk Island</option>
    <option value="Northern Mariana Islands">Northern Mariana Islands</option>
    <option value="Norway">Norway</option>
    <option value="Oman">Oman</option>
    <option value="Pakistan">Pakistan</option>
    <option value="Palau">Palau</option>
    <option value="Palestinian Territory, Occupied">Palestinian Territory, Occupied</option>
    <option value="Panama">Panama</option>
    <option value="Papua New Guinea">Papua New Guinea</option>
    <option value="Paraguay">Paraguay</option>
    <option value="Peru">Peru</option>
    <option value="Philippines">Philippines</option>
    <option value="Pitcairn">Pitcairn</option>
    <option value="Poland">Poland</option>
    <option value="Portugal">Portugal</option>
    <option value="Puerto Rico">Puerto Rico</option>
    <option value="Qatar">Qatar</option>
    <option value="Reunion">Reunion</option>
    <option value="Romania">Romania</option>
    <option value="Russian Federation">Russian Federation</option>
    <option value="Rwanda">Rwanda</option>
    <option value="Saint Barthelemy">Saint Barthelemy</option>
    <option value="Saint Helena">Saint Helena</option>
    <option value="Saint Kitts and Nevis">Saint Kitts and Nevis</option>
    <option value="Saint Lucia">Saint Lucia</option>
    <option value="Saint Martin">Saint Martin</option>
    <option value="Saint Pierre and Miquelon">Saint Pierre and Miquelon</option>
    <option value="Saint Vincent and the Grenadines">Saint Vincent and the Grenadines</option>
    <option value="Samoa">Samoa</option>
    <option value="San Marino">San Marino</option>
    <option value="Sao Tome and Principe">Sao Tome and Principe</option>
    <option value="Saudi Arabia">Saudi Arabia</option>
    <option value="Senegal">Senegal</option>
    <option value="Serbia">Serbia</option>
    <option value="Serbia and Montenegro">Serbia and Montenegro</option>
    <option value="Seychelles">Seychelles</option>
    <option value="Sierra Leone">Sierra Leone</option>
    <option value="Singapore">Singapore</option>
    <option value="Sint Maarten">Sint Maarten</option>
    <option value="Slovakia">Slovakia</option>
    <option value="Slovenia">Slovenia</option>
    <option value="Solomon Islands">Solomon Islands</option>
    <option value="Somalia">Somalia</option>
    <option value="South Africa">South Africa</option>
    <option value="South Georgia and the South Sandwich Islands">South Georgia and the South Sandwich Islands</option>
    <option value="South Sudan">South Sudan</option>
    <option value="Spain">Spain</option>
    <option value="Sri Lanka">Sri Lanka</option>
    <option value="Sudan">Sudan</option>
    <option value="Suriname">Suriname</option>
    <option value="Svalbard and Jan Mayen">Svalbard and Jan Mayen</option>
    <option value="Swaziland">Swaziland</option>
    <option value="Sweden">Sweden</option>
    <option value="Switzerland">Switzerland</option>
    <option value="Syrian Arab Republic">Syrian Arab Republic</option>
    <option value="Taiwan, Province of China">Taiwan, Province of China</option>
    <option value="Tajikistan">Tajikistan</option>
    <option value="Tanzania, United Republic of">Tanzania, United Republic of</option>
    <option value="Thailand">Thailand</option>
    <option value="Timor-Leste">Timor-Leste</option>
    <option value="Togo">Togo</option>
    <option value="Tokelau">Tokelau</option>
    <option value="Tonga">Tonga</option>
    <option value="Trinidad and Tobago">Trinidad and Tobago</option>
    <option value="Tunisia">Tunisia</option>
    <option value="Turkey">Turkey</option>
    <option value="Turkmenistan">Turkmenistan</option>
    <option value="Turks and Caicos Islands">Turks and Caicos Islands</option>
    <option value="Tuvalu">Tuvalu</option>
    <option value="Uganda">Uganda</option>
    <option value="Ukraine">Ukraine</option>
    <option value="United Arab Emirates">United Arab Emirates</option>
    <option value="United Kingdom">United Kingdom</option>
    <option value="United States">United States</option>
    <option value="United States Minor Outlying Islands">United States Minor Outlying Islands</option>
    <option value="Uruguay">Uruguay</option>
    <option value="Uzbekistan">Uzbekistan</option>
    <option value="Vanuatu">Vanuatu</option>
    <option value="Venezuela">Venezuela</option>
    <option value="Viet Nam">Viet Nam</option>
    <option value="Virgin Islands, British">Virgin Islands, British</option>
    <option value="Virgin Islands, U.s.">Virgin Islands, U.s.</option>
    <option value="Wallis and Futuna">Wallis and Futuna</option>
    <option value="Western Sahara">Western Sahara</option>
    <option value="Yemen">Yemen</option>
    <option value="Zambia">Zambia</option>
    <option value="Zimbabwe">Zimbabwe</option>
    </select>
    <label for="field_7">Country</label>
</div>
<input id="country-destination" name="field_7" type="hidden">
<input id="tz-country" name="field_8" type="hidden">

<input
    name="field_6"
    type="hidden"
    value="Machine Learning"
>

<div class="emailoctopus-form-row-consent">
    <input
    type="checkbox"
    id="consent"
    name="consent"
    >
    <label for="consent">
    I consent to the following terms:
    </label>
    <a href="https://www.conf42.com/terms-and-conditions.pdf" target="_blank">
    Terms and Conditions
    </a>
    &amp;
    <a href="./code-of-conduct" target="_blank">
    Code of Conduct
    </a>
</div>
<div
    aria-hidden="true"
    class="emailoctopus-form-row-hp"
>
    <input
    type="text"
    name="hpc4b27b6e-eb38-11e9-be00-06b4694bee2a"
    tabindex="-1"
    autocomplete="nope"
    >
</div>
<div class="mt-6 emailoctopus-form-row-subscribe">
    <input
    type="hidden"
    name="successRedirectUrl"
    >
    <button class="btn w-100 btn-success lift" type="submit" onclick="gtag_report_conversion(); rdt('track', 'SignUp');">
    Subscribe for FREE<i class="fe fe-arrow-right ms-3"></i>
    </button>
</div>
</form>

<!-- <script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-recaptcha.js"></script> -->
<script src="https://emailoctopus.com/bundles/emailoctopuslist/js/1.6/form-embed.js"></script>

              </div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x svg-shim text-dark">
        <svg viewBox="0 0 2880 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 48h2880V0h-720C1442.5 52 720 0 720 0H0v48z" fill="currentColor"/></svg>      </div>
    </div>

    <!-- FOOTER -->
    <footer class="py-8 py-md-11 bg-dark">
      <div class="container">
        <div class="row">

          <div class="col-12 col-md-4 col-lg-3">
            <!-- Brand -->
            <img src="./assets/conf42/conf42_logo_white_small.png" alt="..." class="footer-brand img-fluid mb-2">
    
            <!-- Text -->
            <p class="text-gray-700 mb-2">
              Online tech events
            </p>
    
            <!-- Social -->
            <ul class="list-unstyled list-inline list-social mb-5">
              <li class="list-inline-item list-social-item me-3">
                <a href="https://www.linkedin.com/company/49110720/" class="text-decoration-none">
                  <img src="./assets/img/icons/social/linkedin.svg" class="list-social-icon" alt="...">
                </a>
              </li>
              <li class="list-inline-item list-social-item me-3">
                <a href="https://twitter.com/conf42com" class="text-decoration-none">
                  <img src="./assets/img/icons/social/twitter.svg" class="list-social-icon" alt="...">
                </a>
              </li>
            </ul>

            <!-- QR Code -->
            <img src="./assets/conf42/CONF42.QR.png" style="width: 100px;" class="mb-5 img-fluid" />
          </div>


          <div class="col-12 col-md-4 col-lg-3">
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2026
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2026">
                  DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2026">
                  Machine Learning 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2026">
                  Site Reliability Engineering (SRE) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2026">
                  Cloud Native 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2026">
                  Golang 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/dbd2026">
                  Database DevOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2026">
                  Large Language Models (LLMs) 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2026">
                  Observability 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/agents2026">
                  AI Agents 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2026">
                  DevSecOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2026">
                  Prompt Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2026">
                  Platform Engineering 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2026">
                  MLOps 2026
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2026">
                  Chaos Engineering 2026
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2025
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2025">
                  DevOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2025">
                  Python 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2025">
                  Chaos Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2025">
                  Cloud Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2025">
                  Large Language Models (LLMs) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2025">
                  Golang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2025">
                  Site Reliability Engineering (SRE) 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2025">
                  Machine Learning 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2025">
                  Observability 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2025">
                  Quantum Computing 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2025">
                  Rustlang 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2025">
                  Platform Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mlops2025">
                  MLOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2025">
                  Incident Management 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2025">
                  Kube Native 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2025">
                  JavaScript 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2025">
                  Prompt Engineering 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/robotics2025">
                  Robotics 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2025">
                  DevSecOps 2025
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2025">
                  Internet of Things (IoT) 2025
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2024
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2024">
                  DevOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2024">
                  Chaos Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2024">
                  Python 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2024">
                  Cloud Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/llms2024">
                  Large Language Models (LLMs) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2024">
                  Golang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2024">
                  Site Reliability Engineering (SRE) 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2024">
                  Machine Learning 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2024">
                  Observability 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2024">
                  Quantum Computing 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2024">
                  Rustlang 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2024">
                  Platform Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2024">
                  Kube Native 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2024">
                  Incident Management 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2024">
                  JavaScript 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/prompt2024">
                  Prompt Engineering 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2024">
                  DevSecOps 2024
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2024">
                  Internet of Things (IoT) 2024
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2023
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devops2023">
                  DevOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2023">
                  Chaos Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2023">
                  Python 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2023">
                  Cloud Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2023">
                  Golang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2023">
                  Site Reliability Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2023">
                  Machine Learning 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/obs2023">
                  Observability 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2023">
                  Quantum Computing 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2023">
                  Rustlang 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/platform2023">
                  Platform Engineering 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2023">
                  Kube Native 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2023">
                  Incident Management 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2023">
                  JavaScript 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2023">
                  DevSecOps 2023
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/iot2023">
                  Internet of Things (IoT) 2023
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2022
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2022">
                  Python 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/mobile2022">
                  Mobile 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2022">
                  Chaos Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2022">
                  Golang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2022">
                  Cloud Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2022">
                  Machine Learning 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2022">
                  Site Reliability Engineering 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/quantum2022">
                  Quantum Computing 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/rustlang2022">
                  Rustlang 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/im2022">
                  Incident Management 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/kubenative2022">
                  Kube Native 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2022">
                  JavaScript 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2022">
                  DevSecOps 2022
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/web2022">
                  Web 3.0 2022
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2021
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2021">
                  Chaos Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/enterprise2021">
                  Enterprise Software 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/cloud2021">
                  Cloud Native 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/python2021">
                  Python 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/golang2021">
                  Golang 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ml2021">
                  Machine Learning 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2021">
                  Site Reliability Engineering 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2021">
                  JavaScript 2021
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/devsecops2021">
                  DevSecOps 2021
                </a>
              </li>
            
            </ul>
          
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Events 2020
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-6 mb-md-8 mb-lg-0">
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/ce2020">
                  Chaos Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/oss2020">
                  Open Source Showcase 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/sre2020">
                  Site Reliability Engineering 2020
                </a>
              </li>
            
              <li class="mb-3">
                <a class="text-reset" href="https://www.conf42.com/js2020">
                  JavaScript 2020
                </a>
              </li>
            
            </ul>
          
          </div>

          
          <div class="col-12 col-md-4 offset-md-4 col-lg-3 offset-lg-0">

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Community
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./support" class="text-reset">
                  Support us
                </a>
              </li>
              <li class="mb-3">
                <a href="./speakers" class="text-reset">
                  Speakers
                </a>
              </li>
              <li class="mb-3">
                <a href="./hall-of-fame" class="text-reset">
                  Hall of fame
                </a>
              </li>
              <li class="mb-3">
                <a href="https://discord.gg/DnyHgrC7jC" class="text-reset" target="_blank">
                  Discord
                </a>
              </li>
              <li class="mb-3">
                <a href="./about" class="text-reset">
                  About the team
                </a>
              </li>
            </ul>

            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Sponsors
            </h6>
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./sponsor" class="text-reset" target="_blank">
                  Sponsorship
                </a>
              </li>
              <li class="mb-3">
                <a href="mailto:mark@conf42.com?subject=We would like to sponsor" class="text-reset" target="_blank">
                  Request the Prospectus
                </a>
              </li>
              <li class="mb-3">
                <a href="https://drive.google.com/drive/folders/1tT2lspLQgj3sdfxG9FwDVkBUt-TYSPGe?usp=sharing" class="text-reset" target="_blank">
                  Media kit
                </a>
              </li>
            </ul>
    
          </div>


          <div class="col-12 col-md-4 col-lg-3">
    
            <!-- Heading -->
            <h6 class="fw-bold text-uppercase text-gray-700">
              Legal
            </h6>
    
            <!-- List -->
            <ul class="list-unstyled text-muted mb-0">
              <li class="mb-3">
                <a href="./code-of-conduct" class="text-reset">
                  Code of Conduct
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/terms-and-conditions.pdf" class="text-reset" target="_blank">
                  Terms and Conditions
                </a>
              </li>
              <li class="mb-3">
                <a href="https://www.conf42.com/privacy-policy.pdf" class="text-reset" target="_blank">
                  Privacy policy
                </a>
              </li>
            </ul>
          </div>


        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </footer>

    <!-- JAVASCRIPT -->
    <!-- Map JS -->
    <script src='https://api.mapbox.com/mapbox-gl-js/v0.53.0/mapbox-gl.js'></script>
    
    <!-- Vendor JS -->
    <script src="./assets/js/vendor.bundle.js"></script>
    
    <!-- Theme JS -->
    <script src="./assets/js/theme.bundle.js"></script>

    <!-- Various JS -->
    <script src="./assets/js/various.js"></script>

    <script src='https://cdn.jsdelivr.net/npm/@widgetbot/crate@3' async defer>
      new Crate({
          notifications: true,
          indicator: true,
          server: '814240231606714368', // Conf42.com
          channel: '814240231788249115' // #community
      })
    </script>
  </body>
</html>